<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Lua, This month</title><link>https://github.com/trending/lua?since=monthly</link><description>The top repositories on GitHub for lua, measured monthly</description><pubDate>Fri, 08 Nov 2019 01:07:45 GMT</pubDate><lastBuildDate>Fri, 08 Nov 2019 01:07:45 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>apache/incubator-apisix #1 in Lua, This month</title><link>https://github.com/apache/incubator-apisix</link><description>&lt;p&gt;&lt;i&gt;Cloud-Native Microservices API Gateway&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;
&lt;p&gt;&lt;a href="README_CN.md"&gt;中文&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-apisix" class="anchor" aria-hidden="true" href="#apisix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;APISIX&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/apache/incubator-apisix" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1ed9f512514c97c413e71e4c8f5240edeefb11fc/68747470733a2f2f7472617669732d63692e6f72672f6170616368652f696e63756261746f722d6170697369782e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/apache/incubator-apisix.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/apache/incubator-apisix/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/8051e9938a1ab39cf002818dfceb6b6092f34d68/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;QQ group&lt;/strong&gt;: 552030619&lt;/li&gt;
&lt;li&gt;Mail list: Mail to &lt;a href="mailto:dev-subscribe@apisix.apache.org"&gt;dev-subscribe@apisix.apache.org&lt;/a&gt;, follow the reply to subscribe the mail list.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gitter.im/apisix/community?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/568da9652db68475b3c235e1274c91d42c378149/68747470733a2f2f6261646765732e6769747465722e696d2f6170697369782f636f6d6d756e6974792e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/apisix/community.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/intent/follow?screen_name=apisixfast" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8aeaef778a0e54bb395d635f5b1bfdf8a48abde2/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f617069736978666173742e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f77" alt="Twitter" data-canonical-src="https://img.shields.io/twitter/follow/apisixfast.svg?style=social&amp;amp;label=Follow" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;APISIX is a cloud-native microservices API gateway, delivering the ultimate performance, security, open source and scalable platform for all your APIs and microservices.&lt;/p&gt;
&lt;p&gt;APISIX is based on Nginx and etcd. Compared with traditional API gateways, APISIX has dynamic routing and plug-in hot loading, which is especially suitable for API management under micro-service system.&lt;/p&gt;
&lt;p&gt;&lt;a href="#Installation"&gt;Installation&lt;/a&gt; | &lt;a href="doc/README.md"&gt;Documentation&lt;/a&gt; | &lt;a href="#development-manual-of-apisix"&gt;Development ENV&lt;/a&gt; | &lt;a href="FAQ.md"&gt;FAQ&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-why-apisix" class="anchor" aria-hidden="true" href="#why-apisix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why APISIX?&lt;/h2&gt;
&lt;p&gt;If you are building a website, mobile device or IoT (Internet of Things) application, you may need to use an API gateway to handle interface traffic.&lt;/p&gt;
&lt;p&gt;APISIX is a cloud-based microservices API gateway that handles traditional north-south traffic and handles east-west traffic between services.&lt;/p&gt;
&lt;p&gt;APISIX provides dynamic load balancing, authentication, rate limiting, other plugins through plugin mechanisms, and supports plugins you develop yourself.&lt;/p&gt;
&lt;p&gt;For more detailed information, see the &lt;a href="https://www.iresty.com/download/Choosing%20the%20Right%20Microservice%20API%20Gateway%20for%20the%20Enterprise%20User.pdf" rel="nofollow"&gt;White Paper&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="doc/images/apisix.png"&gt;&lt;img src="doc/images/apisix.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Run Environment&lt;/strong&gt;: Both OpenResty and Tengine are supported.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cloud-Native&lt;/strong&gt;: Platform agnostic, No vendor lock-in, APISIX can run from bare-metal to Kubernetes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins.md"&gt;Hot Updates And Hot Plugins&lt;/a&gt;&lt;/strong&gt;: Continuously updates its configurations and plugins without restarts!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic Load Balancing&lt;/strong&gt;: Round-robin load balancing with weight.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hash-based Load Balancing&lt;/strong&gt;: Load balance with consistent hashing sessions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/https.md"&gt;SSL&lt;/a&gt;&lt;/strong&gt;: Dynamically load an SSL certificate.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HTTP(S) Forward Proxy&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/health-check.md"&gt;Health Checks&lt;/a&gt;&lt;/strong&gt;：Enable health check on the upstream node, and will automatically filter unhealthy nodes during load balancing to ensure system stability.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Circuit-Breaker&lt;/strong&gt;: Intelligent tracking of unhealthy upstream services.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Authentications&lt;/strong&gt;: &lt;a href="doc/plugins/key-auth.md"&gt;key-auth&lt;/a&gt;, &lt;a href="doc/plugins/jwt-auth.md"&gt;JWT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/limit-req.md"&gt;Limit-req&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/limit-count.md"&gt;Limit-count&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/limit-conn.md"&gt;Limit-concurrency&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/proxy-rewrite.md"&gt;Proxy Rewrite&lt;/a&gt;&lt;/strong&gt;: Support for rewriting the &lt;code&gt;host&lt;/code&gt;, &lt;code&gt;uri&lt;/code&gt;, &lt;code&gt;schema&lt;/code&gt;, &lt;code&gt;enable_websocket&lt;/code&gt;, &lt;code&gt;headers&lt;/code&gt; information upstream of the request.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenTracing: &lt;a href="doc/plugins/zipkin.md"&gt;support Apache Skywalking and Zipkin&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Monitoring And Metrics&lt;/strong&gt;: &lt;a href="doc/plugins/prometheus.md"&gt;Prometheus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/grpc-proxy.md"&gt;gRPC proxy&lt;/a&gt;&lt;/strong&gt;：Proxying gRPC traffic.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/grpc-transcoding.md"&gt;gRPC transcoding&lt;/a&gt;&lt;/strong&gt;：Supports protocol transcoding so that clients can access your gRPC API by using HTTP/JSON.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/serverless.md"&gt;Serverless&lt;/a&gt;&lt;/strong&gt;: Invoke functions in each phase in APISIX.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Custom plugins&lt;/strong&gt;: Allows hooking of common phases, such as &lt;code&gt;rewrite&lt;/code&gt;, &lt;code&gt;access&lt;/code&gt;, &lt;code&gt;header filer&lt;/code&gt;, &lt;code&gt;body filter&lt;/code&gt; and &lt;code&gt;log&lt;/code&gt;, also allows to hook the &lt;code&gt;balancer&lt;/code&gt; stage.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dashboard&lt;/strong&gt;: Built-in dashboard to control APISIX.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Version Control&lt;/strong&gt;: Supports rollbacks of operations.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CLI&lt;/strong&gt;: start\stop\reload APISIX through the command line.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;REST API&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Proxy Websocket&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IPv6&lt;/strong&gt;: Use IPv6 to match route.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clustering&lt;/strong&gt;: APISIX nodes are stateless, creates clustering of the configuration center, please refer to &lt;a href="https://github.com/etcd-io/etcd/blob/master/Documentation/v2/clustering.md"&gt;etcd Clustering Guide&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: plug-in mechanism is easy to extend.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;High performance&lt;/strong&gt;: The single-core QPS reaches 24k with an average delay of less than 0.6 milliseconds.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Anti-ReDoS(Regular expression Denial of Service)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IP Whitelist/Blacklist&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IdP&lt;/strong&gt;: Support external authentication services, such as Auth0, okta, etc., users can use this to connect to Oauth2.0 and other authentication methods.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/stand-alone.md"&gt;Stand-alone mode&lt;/a&gt;&lt;/strong&gt;: Supports to load route rules from local yaml file, it is more friendly such as under the kubernetes(k8s).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Global Rule&lt;/strong&gt;: Allows to run any plugin for all request, eg: limit rate, IP filter etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/stream-proxy.md"&gt;TCP/UDP Proxy&lt;/a&gt;&lt;/strong&gt;: Dynamic TCP/UDP proxy.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/mqtt-proxy.md"&gt;Dynamic MQTT Proxy&lt;/a&gt;&lt;/strong&gt;: Supports to load balance MQTT by &lt;code&gt;client_id&lt;/code&gt;, both support MQTT &lt;a href="http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html" rel="nofollow"&gt;3.1.*&lt;/a&gt;, &lt;a href="https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html" rel="nofollow"&gt;5.0&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ACL&lt;/strong&gt;: TODO.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bot detection&lt;/strong&gt;: TODO.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-online-demo-dashboard" class="anchor" aria-hidden="true" href="#online-demo-dashboard"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Online Demo Dashboard&lt;/h2&gt;
&lt;p&gt;We provide an online dashboard &lt;a href="http://apisix.iresty.com" rel="nofollow"&gt;demo version&lt;/a&gt;， make it easier for you to understand APISIX.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;APISIX Installed and tested in the following systems(OpenResty MUST &amp;gt;= 1.15.8.1, or Tengine &amp;gt;= 2.3.2):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CentOS 7&lt;/li&gt;
&lt;li&gt;Ubuntu 16.04&lt;/li&gt;
&lt;li&gt;Ubuntu 18.04&lt;/li&gt;
&lt;li&gt;Debian 9&lt;/li&gt;
&lt;li&gt;Debian 10&lt;/li&gt;
&lt;li&gt;macOS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ARM64&lt;/strong&gt; Ubuntu 18.04&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are four ways to install APISIX:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if you are using CentOS 7, it is recommended to use &lt;a href="#install-from-rpm-for-centos-7"&gt;RPM&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;if you are using macOS, only git clone and install by manual are supported. Please take a look at &lt;a href="doc/dev-manual.md"&gt;dev manual&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;other systems please use &lt;a href="#install-from-luarocks-not-support-macos"&gt;Luarocks&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;You can also install from &lt;a href="https://github.com/iresty/docker-apisix"&gt;Docker image&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The main steps to install APISIX:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Runtime dependency: OpenResty or Tengine.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenResty: Reference &lt;a href="http://openresty.org/en/installation.html" rel="nofollow"&gt;http://openresty.org/en/installation.html&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Tengine: Please take a look at this installation step script &lt;a href=".travis/linux_tengine_runner.sh"&gt;Install Tengine at Ubuntu&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Configuration center: Reference &lt;a href="https://github.com/etcd-io/etcd"&gt;etcd&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NOTE&lt;/em&gt;: APISIX currently only supports the v2 protocol storage to etcd, but the latest version of etcd (starting with 3.4) has turned off the v2 protocol by default. You need to add &lt;code&gt;--enable-v2=true&lt;/code&gt; to the startup parameter to enable the v2 protocol. The development of the v3 protocol supporting etcd has begun and will soon be available.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install APISIX service.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-install-from-rpm-for-centos-7" class="anchor" aria-hidden="true" href="#install-from-rpm-for-centos-7"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install from RPM for CentOS 7&lt;/h3&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo yum install yum-utils
sudo yum-config-manager --add-repo https://openresty.org/package/centos/openresty.repo
sudo yum install -y openresty etcd
sudo service etcd start

sudo yum install -y https://github.com/apache/incubator-apisix/releases/download/v0.8/apisix-0.8-0.el7.noarch.rpm&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can try APISIX with the &lt;a href="#quickstart"&gt;&lt;strong&gt;Quickstart&lt;/strong&gt;&lt;/a&gt; now.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-install-from-luarocks-not-support-macos" class="anchor" aria-hidden="true" href="#install-from-luarocks-not-support-macos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install from Luarocks (not support macOS)&lt;/h3&gt;
&lt;h5&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h5&gt;
&lt;p&gt;APISIX is based on &lt;a href="https://openresty.org/" rel="nofollow"&gt;OpenResty&lt;/a&gt; or &lt;a href="http://tengine.taobao.org/" rel="nofollow"&gt;Tengine&lt;/a&gt;, the configures data storage and distribution via &lt;a href="https://github.com/etcd-io/etcd"&gt;etcd&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We recommend that you use &lt;a href="https://luarocks.org/" rel="nofollow"&gt;luarocks&lt;/a&gt; to install APISIX, and for different operating systems have different dependencies, see more: &lt;a href="doc/install-dependencies.md"&gt;Install Dependencies&lt;/a&gt;&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-install-apisix" class="anchor" aria-hidden="true" href="#install-apisix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install APISIX&lt;/h5&gt;
&lt;p&gt;APISIX is installed by running the following commands in your terminal.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;install the master branch via curl&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo sh -c &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;curl -fsSL https://raw.githubusercontent.com/apache/incubator-apisix/master/utils/install-apisix.sh&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;install the specified version via Luarock:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; install apisix with version v0.8&lt;/span&gt;
sudo luarocks install --lua-dir=/path/openresty/luajit apisix 0.8

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; old luarocks may not support `lua-dir`, we can remove option `lua-dir`&lt;/span&gt;
sudo luarocks install apisix 0.8&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;Installation complete&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If all goes well, you will see the message like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    apisix 0.7-0 is now built and installed in /usr/local/apisix/deps (license: Apache License 2.0)

    + sudo rm -f /usr/local/bin/apisix
    + sudo ln -s /usr/local/apisix/deps/bin/apisix /usr/local/bin/apisix
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Congratulations, you have already installed APISIX successfully.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-development-manual-of-apisix" class="anchor" aria-hidden="true" href="#development-manual-of-apisix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development Manual of APISIX&lt;/h2&gt;
&lt;p&gt;If you are a developer, you can view the &lt;a href="doc/dev-manual.md"&gt;dev manual&lt;/a&gt; for more details.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-quickstart" class="anchor" aria-hidden="true" href="#quickstart"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quickstart&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;start server:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo apisix start&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;note&lt;/em&gt;: If you are in a development environment, start server by command &lt;code&gt;make run&lt;/code&gt;.&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;try limit count plugin&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Limit count plugin is a good start to try APISIX,
you can follow the &lt;a href="doc/plugins/limit-count.md"&gt;documentation of limit count&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Then you can try more &lt;a href="doc/README.md#plugins"&gt;plugins&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-deploy-to-the-cloud" class="anchor" aria-hidden="true" href="#deploy-to-the-cloud"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deploy to the Cloud&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-aws" class="anchor" aria-hidden="true" href="#aws"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;AWS&lt;/h3&gt;
&lt;p&gt;The recommended approach is to deploy APISIX with &lt;a href="https://aws.amazon.com/cdk/" rel="nofollow"&gt;AWS CDK&lt;/a&gt; on &lt;a href="https://aws.amazon.com/fargate/" rel="nofollow"&gt;AWS Fargate&lt;/a&gt; which helps you decouple the APISIX layer and the upstream layer on top of a fully-managed and secure serverless container compute environment with autoscaling capabilities.&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://github.com/pahud/cdk-samples/blob/master/typescript/apisix/README.md"&gt;this guide&lt;/a&gt; by &lt;a href="https://github.com/pahud"&gt;Pahud Hsieh&lt;/a&gt; and learn how to provision the recommended architecture 100% in AWS CDK.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-dashboard" class="anchor" aria-hidden="true" href="#dashboard"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dashboard&lt;/h2&gt;
&lt;p&gt;APISIX has the built-in dashboard，open &lt;code&gt;http://127.0.0.1:9080/apisix/dashboard/&lt;/code&gt; with a browser and try it.&lt;/p&gt;
&lt;p&gt;Do not need to fill the user name and password, log in directly.&lt;/p&gt;
&lt;p&gt;Dashboard allow any remote IP by default, and you can modify &lt;code&gt;allow_admin&lt;/code&gt; in &lt;code&gt;conf/config.yaml&lt;/code&gt; by yourself, to list the list of IPs allowed to access.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-benchmark" class="anchor" aria-hidden="true" href="#benchmark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Benchmark&lt;/h2&gt;
&lt;p&gt;Using Google Cloud's 4 core server, APISIX's QPS reach to 60,000 with a latency of only 500 microseconds.&lt;/p&gt;
&lt;p&gt;You can view the &lt;a href="doc/benchmark.md"&gt;benchmark documentation&lt;/a&gt; for more detailed information.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-architecture-design" class="anchor" aria-hidden="true" href="#architecture-design"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Architecture Design&lt;/h2&gt;
&lt;p&gt;&lt;a href="doc/architecture-design.md"&gt;Development Documentation&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-videos-and-articles" class="anchor" aria-hidden="true" href="#videos-and-articles"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Videos And Articles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;2019.10.30 &lt;a href="https://www.upyun.com/opentalk/440.html" rel="nofollow"&gt;Introduction to Apache APISIX Microservice Gateway Extreme Performance Architecture(Chinese)&lt;/a&gt; .&lt;/li&gt;
&lt;li&gt;2019.8.31 &lt;a href="https://www.upyun.com/opentalk/433.html" rel="nofollow"&gt;APISIX technology selection, testing and continuous integration(Chinese)&lt;/a&gt; .&lt;/li&gt;
&lt;li&gt;2019.8.31 &lt;a href="https://www.upyun.com/opentalk/437.html" rel="nofollow"&gt;APISIX high performance practice 2(Chinese)&lt;/a&gt; .&lt;/li&gt;
&lt;li&gt;2019.7.6 &lt;a href="https://www.upyun.com/opentalk/429.html" rel="nofollow"&gt;APISIX high performance practice(Chinese)&lt;/a&gt; .&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-who-uses-apisix" class="anchor" aria-hidden="true" href="#who-uses-apisix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Who Uses APISIX?&lt;/h2&gt;
&lt;p&gt;A wide variety of companies and organizations use APISIX for research, production and commercial product.
Here is the User Wall of APISIX.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="doc/images/user-wall.jpg"&gt;&lt;img src="doc/images/user-wall.jpg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Users are encouraged to add themselves to the &lt;a href="doc/powered-by.md"&gt;Powered By&lt;/a&gt; page.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-landscape" class="anchor" aria-hidden="true" href="#landscape"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Landscape&lt;/h2&gt;
&lt;p&gt;APISIX enriches the &lt;a href="https://landscape.cncf.io/category=api-gateway&amp;amp;format=card-mode&amp;amp;grouping=category" rel="nofollow"&gt;CNCF API Gateway Landscape&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="doc/images/cncf-landscope.jpg"&gt;&lt;img src="doc/images/cncf-landscope.jpg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-faq" class="anchor" aria-hidden="true" href="#faq"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FAQ&lt;/h2&gt;
&lt;p&gt;There are often some questions asked by developers in the community. We have arranged them in the &lt;a href="FAQ.md"&gt;FAQ&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If your concerns are not among them, please submit issue to communicate with us.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;See &lt;a href="Contributing.md"&gt;CONTRIBUTING&lt;/a&gt; for details on submitting patches and the contribution workflow.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;inspired by Kong and Orange.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>apache</author><guid isPermaLink="false">https://github.com/apache/incubator-apisix</guid><pubDate>Fri, 08 Nov 2019 00:01:00 GMT</pubDate></item><item><title>phillipi/pix2pix #2 in Lua, This month</title><link>https://github.com/phillipi/pix2pix</link><description>&lt;p&gt;&lt;i&gt;Image-to-image translation with conditional adversarial nets&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pix2pix" class="anchor" aria-hidden="true" href="#pix2pix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;pix2pix&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://phillipi.github.io/pix2pix/" rel="nofollow"&gt;Project&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/1611.07004" rel="nofollow"&gt;Arxiv&lt;/a&gt; |
&lt;a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"&gt;PyTorch&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Torch implementation for learning a mapping from input images to output images, for example:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="imgs/examples.jpg"&gt;&lt;img src="imgs/examples.jpg" width="900px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Image-to-Image Translation with Conditional Adversarial Networks&lt;br&gt;
&lt;a href="http://web.mit.edu/phillipi/" rel="nofollow"&gt;Phillip Isola&lt;/a&gt;, &lt;a href="https://people.eecs.berkeley.edu/~junyanz/" rel="nofollow"&gt;Jun-Yan Zhu&lt;/a&gt;, &lt;a href="https://people.eecs.berkeley.edu/~tinghuiz/" rel="nofollow"&gt;Tinghui Zhou&lt;/a&gt;, &lt;a href="https://people.eecs.berkeley.edu/~efros/" rel="nofollow"&gt;Alexei A. Efros&lt;/a&gt;&lt;br&gt;
CVPR, 2017.&lt;/p&gt;
&lt;p&gt;On some tasks, decent results can be obtained fairly quickly and on small datasets. For example, to learn to generate facades (example shown above), we trained on just 400 images for about 2 hours (on a single Pascal Titan X GPU). However, for harder problems it may be important to train on far larger datasets, and for many hours or even days.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Please check out our &lt;a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"&gt;PyTorch&lt;/a&gt; implementation for pix2pix and CycleGAN. The PyTorch version is under active development and can produce results comparable to or better than this Torch version.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Linux or OSX&lt;/li&gt;
&lt;li&gt;NVIDIA GPU + CUDA CuDNN (CPU mode and CUDA without CuDNN may work with minimal modification, but untested)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Install torch and dependencies from &lt;a href="https://github.com/torch/distro"&gt;https://github.com/torch/distro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install torch packages &lt;code&gt;nngraph&lt;/code&gt; and &lt;code&gt;display&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;luarocks install nngraph
luarocks install https://raw.githubusercontent.com/szym/display/master/display-scm-0.rockspec&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Clone this repo:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone git@github.com:phillipi/pix2pix.git
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; pix2pix&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Download the dataset (e.g., &lt;a href="http://cmp.felk.cvut.cz/~tylecr1/facade/" rel="nofollow"&gt;CMP Facades&lt;/a&gt;):&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bash ./datasets/download_dataset.sh facades&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Train the model&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=./datasets/facades name=facades_generation which_direction=BtoA th train.lua&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;(CPU only) The same training command without using a GPU or CUDNN. Setting the environment variables &lt;code&gt;gpu=0 cudnn=0&lt;/code&gt; forces CPU only&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=./datasets/facades name=facades_generation which_direction=BtoA gpu=0 cudnn=0 batchSize=10 save_epoch_freq=5 th train.lua&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;(Optionally) start the display server to view results as the model trains. ( See &lt;a href="#display-ui"&gt;Display UI&lt;/a&gt; for more details):&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;th -ldisplay.start 8000 0.0.0.0&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Finally, test the model:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=./datasets/facades name=facades_generation which_direction=BtoA phase=val th test.lua&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The test results will be saved to an html file here: &lt;code&gt;./results/facades_generation/latest_net_G_val/index.html&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-train" class="anchor" aria-hidden="true" href="#train"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=/path/to/data/ name=expt_name which_direction=AtoB th train.lua&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Switch &lt;code&gt;AtoB&lt;/code&gt; to &lt;code&gt;BtoA&lt;/code&gt; to train translation in opposite direction.&lt;/p&gt;
&lt;p&gt;Models are saved to &lt;code&gt;./checkpoints/expt_name&lt;/code&gt; (can be changed by passing &lt;code&gt;checkpoint_dir=your_dir&lt;/code&gt; in train.lua).&lt;/p&gt;
&lt;p&gt;See &lt;code&gt;opt&lt;/code&gt; in train.lua for additional training options.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-test" class="anchor" aria-hidden="true" href="#test"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Test&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=/path/to/data/ name=expt_name which_direction=AtoB phase=val th test.lua&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will run the model named &lt;code&gt;expt_name&lt;/code&gt; in direction &lt;code&gt;AtoB&lt;/code&gt; on all images in &lt;code&gt;/path/to/data/val&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Result images, and a webpage to view them, are saved to &lt;code&gt;./results/expt_name&lt;/code&gt; (can be changed by passing &lt;code&gt;results_dir=your_dir&lt;/code&gt; in test.lua).&lt;/p&gt;
&lt;p&gt;See &lt;code&gt;opt&lt;/code&gt; in test.lua for additional testing options.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-datasets" class="anchor" aria-hidden="true" href="#datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Datasets&lt;/h2&gt;
&lt;p&gt;Download the datasets using the following script. Some of the datasets are collected by other researchers. Please cite their papers if you use the data.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bash ./datasets/download_dataset.sh dataset_name&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;facades&lt;/code&gt;: 400 images from &lt;a href="http://cmp.felk.cvut.cz/~tylecr1/facade/" rel="nofollow"&gt;CMP Facades dataset&lt;/a&gt;. [&lt;a href="datasets/bibtex/facades.tex"&gt;Citation&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cityscapes&lt;/code&gt;: 2975 images from the &lt;a href="https://www.cityscapes-dataset.com/" rel="nofollow"&gt;Cityscapes training set&lt;/a&gt;.  [&lt;a href="datasets/bibtex/cityscapes.tex"&gt;Citation&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;maps&lt;/code&gt;: 1096 training images scraped from Google Maps&lt;/li&gt;
&lt;li&gt;&lt;code&gt;edges2shoes&lt;/code&gt;: 50k training images from &lt;a href="http://vision.cs.utexas.edu/projects/finegrained/utzap50k/" rel="nofollow"&gt;UT Zappos50K dataset&lt;/a&gt;. Edges are computed by &lt;a href="https://github.com/s9xie/hed"&gt;HED&lt;/a&gt; edge detector + post-processing.
[&lt;a href="datasets/bibtex/shoes.tex"&gt;Citation&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;edges2handbags&lt;/code&gt;: 137K Amazon Handbag images from &lt;a href="https://github.com/junyanz/iGAN"&gt;iGAN project&lt;/a&gt;. Edges are computed by &lt;a href="https://github.com/s9xie/hed"&gt;HED&lt;/a&gt; edge detector + post-processing. [&lt;a href="datasets/bibtex/handbags.tex"&gt;Citation&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;night2day&lt;/code&gt;: around 20K natural scene images from  &lt;a href="http://transattr.cs.brown.edu/" rel="nofollow"&gt;Transient Attributes dataset&lt;/a&gt; [&lt;a href="datasets/bibtex/transattr.tex"&gt;Citation&lt;/a&gt;]. To train a &lt;code&gt;day2night&lt;/code&gt; pix2pix model, you need to add &lt;code&gt;which_direction=BtoA&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-models" class="anchor" aria-hidden="true" href="#models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Models&lt;/h2&gt;
&lt;p&gt;Download the pre-trained models with the following script. You need to rename the model (e.g., &lt;code&gt;facades_label2image&lt;/code&gt; to &lt;code&gt;/checkpoints/facades/latest_net_G.t7&lt;/code&gt;) after the download has finished.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bash ./models/download_model.sh model_name&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;facades_label2image&lt;/code&gt; (label -&amp;gt; facade): trained on the CMP Facades dataset.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cityscapes_label2image&lt;/code&gt; (label -&amp;gt; street scene): trained on the Cityscapes dataset.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cityscapes_image2label&lt;/code&gt; (street scene -&amp;gt; label): trained on the Cityscapes dataset.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;edges2shoes&lt;/code&gt; (edge -&amp;gt; photo): trained on UT Zappos50K dataset.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;edges2handbags&lt;/code&gt; (edge -&amp;gt; photo): trained on Amazon handbags images.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;day2night&lt;/code&gt; (daytime scene -&amp;gt; nighttime scene): trained on around 100 &lt;a href="http://transattr.cs.brown.edu/" rel="nofollow"&gt;webcams&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-setup-training-and-test-data" class="anchor" aria-hidden="true" href="#setup-training-and-test-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup Training and Test data&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-generating-pairs" class="anchor" aria-hidden="true" href="#generating-pairs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generating Pairs&lt;/h3&gt;
&lt;p&gt;We provide a python script to generate training data in the form of pairs of images {A,B}, where A and B are two different depictions of the same underlying scene. For example, these might be pairs {label map, photo} or {bw image, color image}. Then we can learn to translate A to B or B to A:&lt;/p&gt;
&lt;p&gt;Create folder &lt;code&gt;/path/to/data&lt;/code&gt; with subfolders &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt;. &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt; should each have their own subfolders &lt;code&gt;train&lt;/code&gt;, &lt;code&gt;val&lt;/code&gt;, &lt;code&gt;test&lt;/code&gt;, etc. In &lt;code&gt;/path/to/data/A/train&lt;/code&gt;, put training images in style A. In &lt;code&gt;/path/to/data/B/train&lt;/code&gt;, put the corresponding images in style B. Repeat same for other data splits (&lt;code&gt;val&lt;/code&gt;, &lt;code&gt;test&lt;/code&gt;, etc).&lt;/p&gt;
&lt;p&gt;Corresponding images in a pair {A,B} must be the same size and have the same filename, e.g., &lt;code&gt;/path/to/data/A/train/1.jpg&lt;/code&gt; is considered to correspond to &lt;code&gt;/path/to/data/B/train/1.jpg&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once the data is formatted this way, call:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python scripts/combine_A_and_B.py --fold_A /path/to/data/A --fold_B /path/to/data/B --fold_AB /path/to/data&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will combine each pair of images (A,B) into a single image file, ready for training.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-notes-on-colorization" class="anchor" aria-hidden="true" href="#notes-on-colorization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notes on Colorization&lt;/h3&gt;
&lt;p&gt;No need to run &lt;code&gt;combine_A_and_B.py&lt;/code&gt; for colorization. Instead, you need to prepare some natural images and set &lt;code&gt;preprocess=colorization&lt;/code&gt; in the script. The program will automatically convert each RGB image into Lab color space, and create  &lt;code&gt;L -&amp;gt; ab&lt;/code&gt; image pair during the training. Also set &lt;code&gt;input_nc=1&lt;/code&gt; and &lt;code&gt;output_nc=2&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-extracting-edges" class="anchor" aria-hidden="true" href="#extracting-edges"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Extracting Edges&lt;/h3&gt;
&lt;p&gt;We provide python and Matlab scripts to extract coarse edges from photos. Run &lt;code&gt;scripts/edges/batch_hed.py&lt;/code&gt; to compute &lt;a href="https://github.com/s9xie/hed"&gt;HED&lt;/a&gt; edges. Run &lt;code&gt;scripts/edges/PostprocessHED.m&lt;/code&gt; to simplify edges with additional post-processing steps. Check the code documentation for more details.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-evaluating-labels2photos-on-cityscapes" class="anchor" aria-hidden="true" href="#evaluating-labels2photos-on-cityscapes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Evaluating Labels2Photos on Cityscapes&lt;/h3&gt;
&lt;p&gt;We provide scripts for running the evaluation of the Labels2Photos task on the Cityscapes &lt;strong&gt;validation&lt;/strong&gt; set. We assume that you have installed &lt;code&gt;caffe&lt;/code&gt; (and &lt;code&gt;pycaffe&lt;/code&gt;) in your system. If not, see the &lt;a href="http://caffe.berkeleyvision.org/installation.html" rel="nofollow"&gt;official website&lt;/a&gt; for installation instructions. Once &lt;code&gt;caffe&lt;/code&gt; is successfully installed, download the pre-trained FCN-8s semantic segmentation model (512MB) by running&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bash ./scripts/eval_cityscapes/download_fcn8s.sh&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then make sure &lt;code&gt;./scripts/eval_cityscapes/&lt;/code&gt; is in your system's python path. If not, run the following command to add it&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; PYTHONPATH=&lt;span class="pl-smi"&gt;${PYTHONPATH}&lt;/span&gt;:./scripts/eval_cityscapes/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now you can run the following command to evaluate your predictions:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python ./scripts/eval_cityscapes/evaluate.py --cityscapes_dir /path/to/original/cityscapes/dataset/ --result_dir /path/to/your/predictions/ --output_dir /path/to/output/directory/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Images stored under &lt;code&gt;--result_dir&lt;/code&gt; should contain your model predictions on the Cityscapes &lt;strong&gt;validation&lt;/strong&gt; split, and have the original Cityscapes naming convention (e.g., &lt;code&gt;frankfurt_000001_038418_leftImg8bit.png&lt;/code&gt;). The script will output a text file under &lt;code&gt;--output_dir&lt;/code&gt; containing the metric.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Further notes&lt;/strong&gt;: The pre-trained model is &lt;strong&gt;not&lt;/strong&gt; supposed to work on Cityscapes in the original resolution (1024x2048) as it was trained on 256x256 images that are upsampled to 1024x2048. The purpose of the resizing was to 1) keep the label maps in the original high resolution untouched and 2) avoid the need of changing the standard FCN training code for Cityscapes. To get the &lt;em&gt;ground-truth&lt;/em&gt; numbers in the paper, you need to resize the original Cityscapes images to 256x256 before running the evaluation code.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-display-ui" class="anchor" aria-hidden="true" href="#display-ui"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Display UI&lt;/h2&gt;
&lt;p&gt;Optionally, for displaying images during training and test, use the &lt;a href="https://github.com/szym/display"&gt;display package&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install it with: &lt;code&gt;luarocks install https://raw.githubusercontent.com/szym/display/master/display-scm-0.rockspec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Then start the server with: &lt;code&gt;th -ldisplay.start&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Open this URL in your browser: &lt;a href="http://localhost:8000" rel="nofollow"&gt;http://localhost:8000&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By default, the server listens on localhost. Pass &lt;code&gt;0.0.0.0&lt;/code&gt; to allow external connections on any interface:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;th -ldisplay.start 8000 0.0.0.0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then open &lt;code&gt;http://(hostname):(port)/&lt;/code&gt; in your browser to load the remote desktop.&lt;/p&gt;
&lt;p&gt;L1 error is plotted to the display by default. Set the environment variable &lt;code&gt;display_plot&lt;/code&gt; to a comma-separated list of values &lt;code&gt;errL1&lt;/code&gt;, &lt;code&gt;errG&lt;/code&gt; and &lt;code&gt;errD&lt;/code&gt; to visualize the L1, generator, and discriminator error respectively. For example, to plot only the generator and discriminator errors to the display instead of the default L1 error, set &lt;code&gt;display_plot="errG,errD"&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you use this code for your research, please cite our paper &lt;a href="https://arxiv.org/pdf/1611.07004v1.pdf" rel="nofollow"&gt;Image-to-Image Translation Using Conditional Adversarial Networks&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{pix2pix2017,
  title={Image-to-Image Translation with Conditional Adversarial Networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  journal={CVPR},
  year={2017}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-cat-paper-collection" class="anchor" aria-hidden="true" href="#cat-paper-collection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cat Paper Collection&lt;/h2&gt;
&lt;p&gt;If you love cats, and love reading cool graphics, vision, and learning papers, please check out the Cat Paper Collection:&lt;br&gt;
&lt;a href="https://github.com/junyanz/CatPapers"&gt;[Github]&lt;/a&gt; &lt;a href="http://people.eecs.berkeley.edu/~junyanz/cat/cat_papers.html" rel="nofollow"&gt;[Webpage]&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Code borrows heavily from &lt;a href="https://github.com/soumith/dcgan.torch"&gt;DCGAN&lt;/a&gt;. The data loader is modified from &lt;a href="https://github.com/soumith/dcgan.torch"&gt;DCGAN&lt;/a&gt; and  &lt;a href="https://github.com/pathak22/context-encoder"&gt;Context-Encoder&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>phillipi</author><guid isPermaLink="false">https://github.com/phillipi/pix2pix</guid><pubDate>Fri, 08 Nov 2019 00:02:00 GMT</pubDate></item><item><title>koreader/koreader #3 in Lua, This month</title><link>https://github.com/koreader/koreader</link><description>&lt;p&gt;&lt;i&gt;An ebook reader application supporting PDF, DjVu, EPUB, FB2 and many more formats, running on Cervantes, Kindle, Kobo, PocketBook and Android devices&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://koreader.rocks" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/koreader/koreader.github.io/master/koreader-logo.png" alt="KOReader" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-koreader-is-a-document-viewer-primarily-aimed-at-e-ink-readers" class="anchor" aria-hidden="true" href="#koreader-is-a-document-viewer-primarily-aimed-at-e-ink-readers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;KOReader is a document viewer primarily aimed at e-ink readers.&lt;/h4&gt;
&lt;p&gt;&lt;a href="COPYING"&gt;&lt;img src="https://camo.githubusercontent.com/033ef9556c67859b957ffe63a93075c10a7e56ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6b6f7265616465722f6b6f726561646572" alt="AGPL Licence" data-canonical-src="https://img.shields.io/github/license/koreader/koreader" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/koreader/koreader/releases"&gt;&lt;img src="https://camo.githubusercontent.com/883f780194f853b83ac6c6e2bd940e73de6aa68b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f6b6f7265616465722f6b6f7265616465722e737667" alt="Latest release" data-canonical-src="https://img.shields.io/github/release/koreader/koreader.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/koreader/koreader" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2c8d7da701c59df6cdabc34d155c84a24b3fd59d/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6b6f7265616465722f6b6f7265616465723f636f6c6f723d726564" alt="Gitter" data-canonical-src="https://img.shields.io/gitter/room/koreader/koreader?color=red" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://www.mobileread.com/forums/forumdisplay.php?f=276" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/00d0f986eb9ea70c8ccc81439c153f8868d7ab75/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f666f72756d2d6f6e5f6d6f62696c65726561642d6c6967687467726579" alt="Mobileread" data-canonical-src="https://img.shields.io/badge/forum-on_mobileread-lightgrey" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://circleci.com/gh/koreader/koreader" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/73e6d0be2e4e8ef045bca27695494010cab19bb9/68747470733a2f2f636972636c6563692e636f6d2f67682f6b6f7265616465722f6b6f7265616465722e7376673f7374796c653d736869656c64" alt="Build Status" data-canonical-src="https://circleci.com/gh/koreader/koreader.svg?style=shield" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/koreader/koreader" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/57a5d0cb5f109e01f9d129fcd38e7ff24daf5e7a/68747470733a2f2f636f6465636f762e696f2f67682f6b6f7265616465722f6b6f7265616465722f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage Status" data-canonical-src="https://codecov.io/gh/koreader/koreader/branch/master/graph/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/koreader/koreader/releases"&gt;Download&lt;/a&gt; •
&lt;a href="https://github.com/koreader/koreader/wiki"&gt;Wiki&lt;/a&gt; •
&lt;a href="http://koreader.rocks/doc/" rel="nofollow"&gt;Developer docs&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-main-features" class="anchor" aria-hidden="true" href="#main-features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Main features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;portable&lt;/strong&gt;: runs on embedded devices (Cervantes, Kindle, Kobo, PocketBook), Android and Linux computers. Developers can run a KOReader emulator in Linux and MacOS.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;multi-format documents&lt;/strong&gt;: supports fixed page formats (PDF, DjVu, CBT, CBZ) and reflowable e-book formats (EPUB, FB2, Mobi, DOC, CHM, TXT). Scanned PDF/DjVu documents can also be reflowed with the built-in K2pdfopt library.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;full-featured reading&lt;/strong&gt;: multi-lingual user interface with a highly customizable reader view and many typesetting options. You can set arbitrary page margins, override line spacing and choose external fonts and styles. It has multi-lingual hyphenation dictionaries bundled into the application.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;integrated&lt;/strong&gt; with &lt;em&gt;calibre&lt;/em&gt; (search metadata, receive ebooks wirelessly, browse library via OPDS),  &lt;em&gt;Evernote&lt;/em&gt; (export hightlights), &lt;em&gt;Wallabag&lt;/em&gt;, &lt;em&gt;Wikipedia&lt;/em&gt;, &lt;em&gt;Google Translate&lt;/em&gt; and other content providers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;optimized for e-ink devices&lt;/strong&gt;: custom UI without animation, with paginated menus, adjustable text contrast, and easy zoom to fit content or page in paged media.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;extensible&lt;/strong&gt;: via plugins&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;and much more&lt;/strong&gt;: look up words with StarDict dictionaries / Wikipedia, add your own online OPDS catalogs and RSS feeds, share ebooks with other KOReader devices wirelessly, online over-the-air software updates, an FTP client, an SSH server, …&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please check the &lt;a href="https://github.com/koreader/koreader/wiki"&gt;wiki&lt;/a&gt; to discover more features and to help us document them.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-screenshots" class="anchor" aria-hidden="true" href="#screenshots"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Screenshots&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/koreader/koreader-artwork/raw/master/koreader-menu.png"&gt;&lt;img src="https://github.com/koreader/koreader-artwork/raw/master/koreader-menu-thumbnail.png" alt="" width="200px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/koreader/koreader-artwork/raw/master/koreader-footnotes.png"&gt;&lt;img src="https://github.com/koreader/koreader-artwork/raw/master/koreader-footnotes-thumbnail.png" alt="" width="200px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/koreader/koreader-artwork/raw/master/koreader-dictionary.png"&gt;&lt;img src="https://github.com/koreader/koreader-artwork/raw/master/koreader-dictionary-thumbnail.png" alt="" width="200px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;Please follow the model specific steps for your device:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/koreader/koreader/wiki/Installation-on-Android-devices"&gt;Android&lt;/a&gt; •
&lt;a href="https://github.com/koreader/koreader/wiki/Installation-on-BQ-devices"&gt;Cervantes&lt;/a&gt; •
&lt;a href="https://github.com/koreader/koreader/wiki/Installation-on-Kindle-devices"&gt;Kindle&lt;/a&gt; •
&lt;a href="https://github.com/koreader/koreader/wiki/Installation-on-Kobo-devices"&gt;Kobo&lt;/a&gt; •
&lt;a href="https://github.com/koreader/koreader/wiki/Installation-on-desktop-linux"&gt;Linux&lt;/a&gt; •
&lt;a href="https://github.com/koreader/koreader/wiki/Installation-on-PocketBook-devices"&gt;Pocketbook&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-development" class="anchor" aria-hidden="true" href="#development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development&lt;/h2&gt;
&lt;p&gt;&lt;a href="doc/Building.md"&gt;Setting a build environment&lt;/a&gt; •
&lt;a href="doc/Collaborating_with_Git.md"&gt;Collaborating with Git&lt;/a&gt; •
&lt;a href="doc/Building_targets.md"&gt;Building targets&lt;/a&gt; •
&lt;a href="doc/Porting.md"&gt;Porting&lt;/a&gt; •
&lt;a href="http://koreader.rocks/doc/" rel="nofollow"&gt;Developer docs&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-support" class="anchor" aria-hidden="true" href="#support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support&lt;/h2&gt;
&lt;p&gt;KOReader is developed and supported by volunteers all around the world. There are many ways you can help:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/koreader/koreader/issues?q=is%3Aopen+is%3Aissue+label%3Abug"&gt;fix bugs&lt;/a&gt; and &lt;a href="https://github.com/koreader/koreader/issues?q=is%3Aopen+is%3Aissue+label%3Aenhancement"&gt;implement new features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.transifex.com/projects/p/koreader/" rel="nofollow"&gt;translate the program into your language&lt;/a&gt; or improve an existing translation&lt;/li&gt;
&lt;li&gt;document lesser-known features on the &lt;a href="https://github.com/koreader/koreader/wiki"&gt;wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;help others with your knowledge on the &lt;a href="http://www.mobileread.com/forums/forumdisplay.php?f=276" rel="nofollow"&gt;forum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At this moment we don't support any form of monetary donation, but you can create a &lt;a href="https://www.bountysource.com/teams/koreader" rel="nofollow"&gt;bounty&lt;/a&gt; for the specific bug or feature request you want and motivate others to do the work.&lt;/p&gt;
&lt;p&gt;Also if you have and old Pocketbook device you don't want, we might find it useful to tinker a bit with that platform. Please contact us through the forum or GitHub.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributors&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/koreader/koreader/commits/master"&gt;&lt;img src="https://camo.githubusercontent.com/75c8b96ee1d36b3093c2badb046de84e40cb0cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6173742d636f6d6d69742f6b6f7265616465722f6b6f7265616465723f636f6c6f723d6f72616e6765" alt="Last commit" data-canonical-src="https://img.shields.io/github/last-commit/koreader/koreader?color=orange" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/koreader/koreader/pulse"&gt;&lt;img src="https://camo.githubusercontent.com/43528411e156c1cd009a1ccc12209e60f3ec67c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f6b6f7265616465722f6b6f726561646572" alt="Commit activity" data-canonical-src="https://img.shields.io/github/commit-activity/m/koreader/koreader" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://sourcerer.io/fame/Frenzie/koreader/koreader/links/0" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8e4984409651142fb03456c3d1736870d73d4ea5/68747470733a2f2f736f757263657265722e696f2f66616d652f4672656e7a69652f6b6f7265616465722f6b6f7265616465722f696d616765732f30" alt="0" data-canonical-src="https://sourcerer.io/fame/Frenzie/koreader/koreader/images/0" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://sourcerer.io/fame/Frenzie/koreader/koreader/links/1" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/283a67bf2acafbaa7c123c110b905e687ce20469/68747470733a2f2f736f757263657265722e696f2f66616d652f4672656e7a69652f6b6f7265616465722f6b6f7265616465722f696d616765732f31" alt="1" data-canonical-src="https://sourcerer.io/fame/Frenzie/koreader/koreader/images/1" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://sourcerer.io/fame/Frenzie/koreader/koreader/links/2" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e49e22d8b991f85fc5adc99237617b3111c7b1b9/68747470733a2f2f736f757263657265722e696f2f66616d652f4672656e7a69652f6b6f7265616465722f6b6f7265616465722f696d616765732f32" alt="2" data-canonical-src="https://sourcerer.io/fame/Frenzie/koreader/koreader/images/2" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://sourcerer.io/fame/Frenzie/koreader/koreader/links/3" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/94d3e9f322cd82baecc22df73036e399ad737317/68747470733a2f2f736f757263657265722e696f2f66616d652f4672656e7a69652f6b6f7265616465722f6b6f7265616465722f696d616765732f33" alt="3" data-canonical-src="https://sourcerer.io/fame/Frenzie/koreader/koreader/images/3" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://sourcerer.io/fame/Frenzie/koreader/koreader/links/4" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/4e43aaaf41df36b54378a7dd3902d12a7915f718/68747470733a2f2f736f757263657265722e696f2f66616d652f4672656e7a69652f6b6f7265616465722f6b6f7265616465722f696d616765732f34" alt="4" data-canonical-src="https://sourcerer.io/fame/Frenzie/koreader/koreader/images/4" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://sourcerer.io/fame/Frenzie/koreader/koreader/links/5" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3dd987e284c998f798e32350b2452391556d06b7/68747470733a2f2f736f757263657265722e696f2f66616d652f4672656e7a69652f6b6f7265616465722f6b6f7265616465722f696d616765732f35" alt="5" data-canonical-src="https://sourcerer.io/fame/Frenzie/koreader/koreader/images/5" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://sourcerer.io/fame/Frenzie/koreader/koreader/links/6" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3be57a1f4b60ecae0b18a3209a314b0df4186f5e/68747470733a2f2f736f757263657265722e696f2f66616d652f4672656e7a69652f6b6f7265616465722f6b6f7265616465722f696d616765732f36" alt="6" data-canonical-src="https://sourcerer.io/fame/Frenzie/koreader/koreader/images/6" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://sourcerer.io/fame/Frenzie/koreader/koreader/links/7" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/149b0dc2f3e1b535f52f8d0012855bf0d1049d21/68747470733a2f2f736f757263657265722e696f2f66616d652f4672656e7a69652f6b6f7265616465722f6b6f7265616465722f696d616765732f37" alt="7" data-canonical-src="https://sourcerer.io/fame/Frenzie/koreader/koreader/images/7" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>koreader</author><guid isPermaLink="false">https://github.com/koreader/koreader</guid><pubDate>Fri, 08 Nov 2019 00:03:00 GMT</pubDate></item><item><title>cmusatyalab/openface #4 in Lua, This month</title><link>https://github.com/cmusatyalab/openface</link><description>&lt;p&gt;&lt;i&gt;Face recognition with deep neural networks.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-openface-----" class="anchor" aria-hidden="true" href="#openface-----"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;OpenFace • &lt;a href="http://travis-ci.org/cmusatyalab/openface" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/7649857bc22a4061aea8a38706cc64b6bca51e45/68747470733a2f2f7472617669732d63692e6f72672f636d7573617479616c61622f6f70656e666163652e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/cmusatyalab/openface.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://github.com/cmusatyalab/openface/releases"&gt;&lt;img src="https://camo.githubusercontent.com/009f288da0baa589849c22cdbc1185bfeaf924ab/687474703a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d302e322e312d626c75652e7376673f7374796c653d666c6174" alt="Release" data-canonical-src="http://img.shields.io/badge/release-0.2.1-blue.svg?style=flat" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/0257a158db7f15a3a2b76dfd75be916fda130867/687474703a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4170616368652d2d322d626c75652e7376673f7374796c653d666c6174" alt="License" data-canonical-src="http://img.shields.io/badge/license-Apache--2-blue.svg?style=flat" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://gitter.im/cmusatyalab/openface" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Free and open source face recognition with
deep neural networks.&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;Website: &lt;a href="http://cmusatyalab.github.io/openface/" rel="nofollow"&gt;http://cmusatyalab.github.io/openface/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://openface-api.readthedocs.org/en/latest/index.html" rel="nofollow"&gt;API Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Join the
&lt;a href="https://groups.google.com/forum/#!forum/cmu-openface" rel="nofollow"&gt;cmu-openface group&lt;/a&gt;
or the
&lt;a href="https://gitter.im/cmusatyalab/openface" rel="nofollow"&gt;gitter chat&lt;/a&gt;
for discussions and installation issues.&lt;/li&gt;
&lt;li&gt;Development discussions and bugs reports are on the
&lt;a href="https://github.com/cmusatyalab/openface/issues"&gt;issue tracker&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;This research was supported by the National Science Foundation (NSF)
under grant number CNS-1518865.  Additional support
was provided by the Intel Corporation, Google, Vodafone, NVIDIA, and the
Conklin Kistler family fund.  Any opinions, findings, conclusions or
recommendations expressed in this material are those of the authors
and should not be attributed to their employers or funding sources.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-whats-in-this-repository" class="anchor" aria-hidden="true" href="#whats-in-this-repository"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What's in this repository?&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/batch-represent"&gt;batch-represent&lt;/a&gt;: Generate representations from
a batch of images. &lt;a href="https://gist.github.com/bamos/f03037f5df7e05ad0cc8"&gt;Example directory structure.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/demos/web"&gt;demos/web&lt;/a&gt;: Real-time web demo.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/demos/compare.py"&gt;demos/compare.py&lt;/a&gt;: Demo to compare two images.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/demos/vis-outputs.lua"&gt;demos/vis-outputs.lua&lt;/a&gt;: Demo to
visualize the network's outputs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/demos/classifier.py"&gt;demos/classifier.py&lt;/a&gt;: Demo to train and use classifiers.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/blob/master/demos/classifier_webcam.py"&gt;demos/classifier_webcam.py&lt;/a&gt;: Demo to use a trained classifier on a webcam stream.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/blob/master/evaluation"&gt;evaluation&lt;/a&gt;: LFW accuracy evaluation scripts.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/openface"&gt;openface&lt;/a&gt;: Python library code.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/models"&gt;models&lt;/a&gt;: Model directory for openface and 3rd party libraries.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/tests"&gt;tests&lt;/a&gt;: Tests for scripts and library code, including neural network training.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/training"&gt;training&lt;/a&gt;: Scripts to train new OpenFace neural network models.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/util"&gt;util&lt;/a&gt;: Utility scripts.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-citations" class="anchor" aria-hidden="true" href="#citations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citations&lt;/h1&gt;
&lt;p&gt;Please cite OpenFace in your publications if it helps your research.
The following is a &lt;a href="http://www.bibtex.org/" rel="nofollow"&gt;BibTeX&lt;/a&gt; and plaintext reference for our
&lt;a href="http://reports-archive.adm.cs.cmu.edu/anon/anon/2016/CMU-CS-16-118.pdf" rel="nofollow"&gt;OpenFace tech report&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@techreport{amos2016openface,
  title={OpenFace: A general-purpose face recognition
    library with mobile applications},
  author={Amos, Brandon and Bartosz Ludwiczuk and Satyanarayanan, Mahadev},
  year={2016},
  institution={CMU-CS-16-118, CMU School of Computer Science},
}

B. Amos, B. Ludwiczuk, M. Satyanarayanan,
"Openface: A general-purpose face recognition library with mobile applications,"
CMU-CS-16-118, CMU School of Computer Science, Tech. Rep., 2016.
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;&lt;a id="user-content-licensing" class="anchor" aria-hidden="true" href="#licensing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Licensing&lt;/h1&gt;
&lt;p&gt;Unless otherwise stated, the source code and trained Torch and Python
model files are copyright Carnegie Mellon University and licensed
under the &lt;a href="./LICENSE"&gt;Apache 2.0 License&lt;/a&gt;.
Portions from the following third party sources have
been modified and are included in this repository.
These portions are noted in the source files and are
copyright their respective authors with
the licenses listed.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Project&lt;/th&gt;
&lt;th&gt;Modified&lt;/th&gt;
&lt;th&gt;License&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/Atcold/torch-TripletEmbedding"&gt;Atcold/torch-TripletEmbedding&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;MIT&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/facebook/fbnn"&gt;facebook/fbnn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;BSD&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>cmusatyalab</author><guid isPermaLink="false">https://github.com/cmusatyalab/openface</guid><pubDate>Fri, 08 Nov 2019 00:04:00 GMT</pubDate></item><item><title>Kong/kong #5 in Lua, This month</title><link>https://github.com/Kong/kong</link><description>&lt;p&gt;&lt;i&gt;🦍 The Cloud-Native API Gateway &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://konghq.com/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9e4fe7914c7357861223aa535d7ca9858253c96e/68747470733a2f2f6b6f6e6768712e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f30352f6b6f6e672d6c6f676f2d6769746875622d726561646d652e706e67" alt="" data-canonical-src="https://konghq.com/wp-content/uploads/2018/05/kong-logo-github-readme.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/Kong/kong/branches" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/032b58c2a2e0a2a8dbb0c1fe60a0236e1042b7ad/68747470733a2f2f7472617669732d63692e6f72672f4b6f6e672f6b6f6e672e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/Kong/kong.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/Kong/kong/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/8051e9938a1ab39cf002818dfceb6b6092f34d68/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://twitter.com/intent/follow?screen_name=thekonginc" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/295bb78a3be8393e728bb4ad7470bd98a1c5062d/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f7468656b6f6e67696e632e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f77" alt="Twitter" data-canonical-src="https://img.shields.io/twitter/follow/thekonginc.svg?style=social&amp;amp;label=Follow" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kong is a cloud-native, fast, scalable, and distributed Microservice
Abstraction Layer &lt;em&gt;(also known as an API Gateway, API Middleware or in some
cases Service Mesh)&lt;/em&gt;. Made available as an open-source project in 2015, its
core values are high performance and extensibility.&lt;/p&gt;
&lt;p&gt;Actively maintained, Kong is widely used in production at companies ranging
from startups to Global 5000 as well as government organizations.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://konghq.com/install" rel="nofollow"&gt;Installation&lt;/a&gt; |
&lt;a href="https://docs.konghq.com" rel="nofollow"&gt;Documentation&lt;/a&gt; |
&lt;a href="https://discuss.konghq.com" rel="nofollow"&gt;Forum&lt;/a&gt; |
&lt;a href="https://konghq.com/blog" rel="nofollow"&gt;Blog&lt;/a&gt; |
IRC (freenode): &lt;a href="https://webchat.freenode.net/?channels=kong" rel="nofollow"&gt;#kong&lt;/a&gt; |
&lt;a href="https://bintray.com/kong/kong-nightly/master" rel="nofollow"&gt;Nightly Builds&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-summary" class="anchor" aria-hidden="true" href="#summary"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#why-kong"&gt;&lt;strong&gt;Why Kong?&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#features"&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#distributions"&gt;&lt;strong&gt;Distributions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#development"&gt;&lt;strong&gt;Development&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#enterprise-support--demo"&gt;&lt;strong&gt;Enterprise Support &amp;amp; Demo&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;&lt;strong&gt;License&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-why-kong" class="anchor" aria-hidden="true" href="#why-kong"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why Kong?&lt;/h2&gt;
&lt;p&gt;If you are building for the web, mobile, or IoT (Internet of Things) you will
likely end up needing common functionality to run your actual software. Kong
can help by acting as a gateway (or a sidecar) for microservices requests while
providing load balancing, logging, authentication, rate-limiting,
transformations, and more through plugins.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://konghq.com/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d4d0dcb22c223db0bf2e301aab0dddb3015f1729/68747470733a2f2f6b6f6e6768712e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f30352f6b6f6e672d62656e65666974732d6769746875622d726561646d652e706e67" alt="" data-canonical-src="https://konghq.com/wp-content/uploads/2018/05/kong-benefits-github-readme.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cloud-Native&lt;/strong&gt;: Platform agnostic, Kong can run from bare metal to
Kubernetes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic Load Balancing&lt;/strong&gt;: Load balance traffic across multiple upstream
services.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hash-based Load Balancing&lt;/strong&gt;: Load balance with consistent hashing/sticky
sessions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Circuit-Breaker&lt;/strong&gt;: Intelligent tracking of unhealthy upstream services.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Health Checks:&lt;/strong&gt; Active and passive monitoring of your upstream services.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Service Discovery&lt;/strong&gt;: Resolve SRV records in third-party DNS resolvers like
Consul.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Serverless&lt;/strong&gt;: Invoke and secure AWS Lambda or OpenWhisk functions directly
from Kong.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WebSockets&lt;/strong&gt;: Communicate to your upstream services via WebSockets.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gRPC&lt;/strong&gt;: Communicate to your gRPC services and observe your traffic with logging
and observability plugins&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OAuth2.0&lt;/strong&gt;: Easily add OAuth2.0 authentication to your APIs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Logging&lt;/strong&gt;: Log requests and responses to your system over HTTP, TCP, UDP,
or to disk.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: ACL, Bot detection, whitelist/blacklist IPs, etc...&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Syslog&lt;/strong&gt;: Logging to System log.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SSL&lt;/strong&gt;: Setup a Specific SSL Certificate for an underlying service or API.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Monitoring&lt;/strong&gt;: Live monitoring provides key load and performance server
metrics.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Forward Proxy&lt;/strong&gt;: Make Kong connect to intermediary transparent HTTP proxies.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Authentications&lt;/strong&gt;: HMAC, JWT, Basic, and more.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rate-limiting&lt;/strong&gt;: Block and throttle requests based on many variables.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformations&lt;/strong&gt;: Add, remove, or manipulate HTTP requests and responses.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt;: Cache and serve responses at the proxy layer.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CLI&lt;/strong&gt;: Control your Kong cluster from the command line.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;REST API&lt;/strong&gt;: Kong can be operated with its RESTful API for maximum
flexibility.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Geo-Replicated&lt;/strong&gt;: Configs are always up-to-date across different regions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Failure Detection &amp;amp; Recovery&lt;/strong&gt;: Kong is unaffected if one of your Cassandra
nodes goes down.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clustering&lt;/strong&gt;: All Kong nodes auto-join the cluster keeping their config
updated across nodes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: Distributed by nature, Kong scales horizontally by simply
adding nodes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt;: Kong handles load with ease by scaling and using NGINX at
the core.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plugins&lt;/strong&gt;: Extendable architecture for adding functionality to Kong and
APIs.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more info about plugins and integrations, you can check out the &lt;a href="https://docs.konghq.com/hub/" rel="nofollow"&gt;Kong
Hub&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-distributions" class="anchor" aria-hidden="true" href="#distributions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Distributions&lt;/h2&gt;
&lt;p&gt;Kong comes in many shapes. While this repository contains its core's source
code, other repos are also under active development:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/docker-kong"&gt;Kong Docker&lt;/a&gt;: A Dockerfile for
running Kong in Docker.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/kong/releases"&gt;Kong Packages&lt;/a&gt;: Pre-built packages
for Debian, Red Hat, and OS X distributions (shipped with each release).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/kong-vagrant"&gt;Kong Vagrant&lt;/a&gt;: A Vagrantfile for
provisioning a development-ready environment for Kong.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/homebrew-kong"&gt;Kong Homebrew&lt;/a&gt;: Homebrew Formula
for Kong.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/kong-dist-cloudformation"&gt;Kong CloudFormation&lt;/a&gt;:
Kong in a 1-click deployment for AWS EC2.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://aws.amazon.com/marketplace/pp/B06WP4TNKL" rel="nofollow"&gt;Kong AWS AMI&lt;/a&gt;: Kong AMI on
the AWS Marketplace.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/kong-dist-azure"&gt;Kong on Microsoft Azure&lt;/a&gt;: Run Kong
using Azure Resource Manager.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/heroku/heroku-kong"&gt;Kong on Heroku&lt;/a&gt;: Deploy Kong on
Heroku in one click.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.instaclustr.com/solutions/managed-cassandra-for-kong/" rel="nofollow"&gt;Kong and Instaclustr&lt;/a&gt;: Let
Instaclustr manage your Cassandra cluster.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/kubernetes-ingress-controller"&gt;Kubernetes Ingress Controller for Kong&lt;/a&gt;:
Use Kong for Kubernetes Ingress.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bintray.com/kong/kong-nightly/master" rel="nofollow"&gt;Nightly Builds&lt;/a&gt;: Builds of the master branch available
every morning at about 9AM PST.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-development" class="anchor" aria-hidden="true" href="#development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development&lt;/h2&gt;
&lt;p&gt;If you are planning on developing on Kong, you'll need a development
installation. The &lt;code&gt;next&lt;/code&gt; branch holds the latest unreleased source code.&lt;/p&gt;
&lt;p&gt;You can read more about writing your own plugins in the &lt;a href="https://docs.konghq.com/latest/plugin-development/" rel="nofollow"&gt;Plugin Development
Guide&lt;/a&gt;, or browse an
online version of Kong's source code documentation in the &lt;a href="https://docs.konghq.com/latest/pdk/" rel="nofollow"&gt;Plugin Development
Kit (PDK) Reference&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h4&gt;
&lt;p&gt;You can use Docker / docker-compose and a mounted volume to develop Kong by
following the instructions on &lt;a href="https://github.com/Kong/kong-build-tools#developing-kong"&gt;Kong/kong-build-tools&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-vagrant" class="anchor" aria-hidden="true" href="#vagrant"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Vagrant&lt;/h4&gt;
&lt;p&gt;You can use a Vagrant box running Kong and Postgres that you can find at
&lt;a href="https://github.com/Kong/kong-vagrant"&gt;Kong/kong-vagrant&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-source-install" class="anchor" aria-hidden="true" href="#source-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source Install&lt;/h4&gt;
&lt;p&gt;Kong mostly is an OpenResty application made of Lua source files, but also
requires some additional third-party dependencies. We recommend installing
those by following the source install instructions at
&lt;a href="https://docs.konghq.com/install/source/" rel="nofollow"&gt;https://docs.konghq.com/install/source/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Instead of following the second step (Install Kong), clone this repository
and install the latest Lua sources instead of the currently released ones:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ git clone https://github.com/Kong/kong
$ &lt;span class="pl-c1"&gt;cd&lt;/span&gt; kong/

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; you might want to switch to the development branch. See CONTRIBUTING.md&lt;/span&gt;
$ git checkout next

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; install the Lua sources&lt;/span&gt;
$ luarocks make&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-running-for-development" class="anchor" aria-hidden="true" href="#running-for-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running for development&lt;/h4&gt;
&lt;p&gt;Check out the &lt;a href="https://github.com/Kong/kong/blob/next/kong.conf.default#L244"&gt;development section&lt;/a&gt;
of the default configuration file for properties to tweak in order to ease
the development process for Kong.&lt;/p&gt;
&lt;p&gt;Modifying the &lt;a href="https://github.com/openresty/lua-nginx-module#lua_package_path"&gt;&lt;code&gt;lua_package_path&lt;/code&gt;&lt;/a&gt;
and &lt;a href="https://github.com/openresty/lua-nginx-module#lua_package_cpath"&gt;&lt;code&gt;lua_package_cpath&lt;/code&gt;&lt;/a&gt;
directives will allow Kong to find your custom plugin's source code wherever it
might be in your system.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-tests" class="anchor" aria-hidden="true" href="#tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tests&lt;/h4&gt;
&lt;p&gt;Install the development dependencies (&lt;a href="https://github.com/Olivine-Labs/busted"&gt;busted&lt;/a&gt;, &lt;a href="https://github.com/mpeterv/luacheck"&gt;luacheck&lt;/a&gt;) with:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ make dev&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Kong relies on three test suites using the &lt;a href="https://github.com/Olivine-Labs/busted"&gt;busted&lt;/a&gt; testing library:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Unit tests&lt;/li&gt;
&lt;li&gt;Integration tests, which require Postgres and Cassandra to be up and running&lt;/li&gt;
&lt;li&gt;Plugins tests, which require Postgres to be running&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first can simply be run after installing busted and running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make test
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, the integration and plugins tests will spawn a Kong instance and
perform their tests against it. As so, consult/edit the &lt;code&gt;spec/kong_tests.conf&lt;/code&gt;
configuration file to make your test instance point to your Postgres/Cassandra
servers, depending on your needs.&lt;/p&gt;
&lt;p&gt;You can run the integration tests (assuming &lt;strong&gt;both&lt;/strong&gt; Postgres and Cassandra are
running and configured according to &lt;code&gt;spec/kong_tests.conf&lt;/code&gt;) with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make test-integration
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the plugins tests with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make test-plugins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, all suites can be run at once by simply using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make test-all
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Consult the &lt;a href=".ci/run_tests.sh"&gt;run_tests.sh&lt;/a&gt; script for a more advanced example
usage of the tests suites and the Makefile.&lt;/p&gt;
&lt;p&gt;Finally, a very useful tool in Lua development (as with many other dynamic
languages) is performing static linting of your code. You can use &lt;a href="https://github.com/mpeterv/luacheck"&gt;luacheck&lt;/a&gt;
(installed with &lt;code&gt;make dev&lt;/code&gt;) for this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make lint
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-makefile" class="anchor" aria-hidden="true" href="#makefile"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Makefile&lt;/h4&gt;
&lt;p&gt;When developing, you can use the &lt;code&gt;Makefile&lt;/code&gt; for doing the following operations:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="right"&gt;Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;install&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Install the Kong luarock globally&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;dev&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Install development dependencies&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;lint&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Lint Lua files in &lt;code&gt;kong/&lt;/code&gt; and &lt;code&gt;spec/&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;test&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Run the unit tests suite&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;test-integration&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Run the integration tests suite&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;test-plugins&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Run the plugins test suite&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;test-all&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Run all unit + integration + plugins tests at once&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-enterprise-support--demo" class="anchor" aria-hidden="true" href="#enterprise-support--demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Enterprise Support &amp;amp; Demo&lt;/h2&gt;
&lt;p&gt;If you are working in a large organization you should learn more about &lt;a href="https://konghq.com/kong-enterprise-edition/" rel="nofollow"&gt;Kong
Enterprise&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;Copyright 2016-2019 Kong Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Kong</author><guid isPermaLink="false">https://github.com/Kong/kong</guid><pubDate>Fri, 08 Nov 2019 00:05:00 GMT</pubDate></item><item><title>junyanz/CycleGAN #6 in Lua, This month</title><link>https://github.com/junyanz/CycleGAN</link><description>&lt;p&gt;&lt;i&gt;Software that can generate photos from paintings,  turn horses into zebras,  perform style transfer, and more.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="imgs/horse2zebra.gif"&gt;&lt;img src="imgs/horse2zebra.gif" align="right" width="384" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-cyclegan" class="anchor" aria-hidden="true" href="#cyclegan"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CycleGAN&lt;/h1&gt;
&lt;h3&gt;&lt;a id="user-content-pytorch--project-page----paper" class="anchor" aria-hidden="true" href="#pytorch--project-page----paper"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"&gt;PyTorch&lt;/a&gt; | &lt;a href="https://junyanz.github.io/CycleGAN/" rel="nofollow"&gt;project page&lt;/a&gt; |   &lt;a href="https://arxiv.org/pdf/1703.10593.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Torch implementation for learning an image-to-image translation (i.e. &lt;a href="https://github.com/phillipi/pix2pix"&gt;pix2pix&lt;/a&gt;) &lt;strong&gt;without&lt;/strong&gt; input-output pairs, for example:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/69cbc0371777fba5d251a564e2f8a8f38d1bf43f/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f7465617365725f686967685f7265732e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/69cbc0371777fba5d251a564e2f8a8f38d1bf43f/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f7465617365725f686967685f7265732e6a7067" width="1000px" data-canonical-src="https://junyanz.github.io/CycleGAN/images/teaser_high_res.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://junyanz.github.io/CycleGAN/" rel="nofollow"&gt;Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks&lt;/a&gt;&lt;br&gt;
&lt;a href="https://people.eecs.berkeley.edu/~junyanz/" rel="nofollow"&gt;Jun-Yan Zhu&lt;/a&gt;*,  &lt;a href="https://taesung.me/" rel="nofollow"&gt;Taesung Park&lt;/a&gt;*, &lt;a href="http://web.mit.edu/phillipi/" rel="nofollow"&gt;Phillip Isola&lt;/a&gt;, &lt;a href="https://people.eecs.berkeley.edu/~efros/" rel="nofollow"&gt;Alexei A. Efros&lt;/a&gt;&lt;br&gt;
Berkeley AI Research Lab, UC Berkeley&lt;br&gt;
In ICCV 2017. (* equal contributions)&lt;/p&gt;
&lt;p&gt;This package includes CycleGAN, &lt;a href="https://github.com/phillipi/pix2pix"&gt;pix2pix&lt;/a&gt;, as well as other methods like &lt;a href="https://arxiv.org/abs/1605.09782" rel="nofollow"&gt;BiGAN&lt;/a&gt;/&lt;a href="https://ishmaelbelghazi.github.io/ALI/" rel="nofollow"&gt;ALI&lt;/a&gt; and Apple's paper &lt;a href="https://arxiv.org/pdf/1612.07828.pdf" rel="nofollow"&gt;S+U learning&lt;/a&gt;.&lt;br&gt;
The code was written by &lt;a href="https://github.com/junyanz"&gt;Jun-Yan Zhu&lt;/a&gt; and &lt;a href="https://github.com/taesung"&gt;Taesung Park&lt;/a&gt;.&lt;br&gt;
&lt;strong&gt;Update&lt;/strong&gt;: Please check out &lt;a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"&gt;PyTorch&lt;/a&gt; implementation for CycleGAN and pix2pix.
The PyTorch version is under active development and can produce results comparable or better than this Torch version.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-other-implementations" class="anchor" aria-hidden="true" href="#other-implementations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other implementations:&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/leehomyc/cyclegan-1"&gt; [Tensorflow]&lt;/a&gt; (by Harry Yang),
&lt;a href="https://github.com/architrathore/CycleGAN/"&gt;[Tensorflow]&lt;/a&gt; (by Archit Rathore),
&lt;a href="https://github.com/vanhuyz/CycleGAN-TensorFlow"&gt;[Tensorflow]&lt;/a&gt; (by Van Huy),
&lt;a href="https://github.com/XHUJOY/CycleGAN-tensorflow"&gt;[Tensorflow]&lt;/a&gt; (by Xiaowei Hu), 
&lt;a href="https://github.com/LynnHo/CycleGAN-Tensorflow-Simple"&gt; [Tensorflow-simple]&lt;/a&gt; (by Zhenliang He),
&lt;a href="https://github.com/luoxier/CycleGAN_Tensorlayer"&gt; [TensorLayer]&lt;/a&gt; (by luoxier),
&lt;a href="https://github.com/Aixile/chainer-cyclegan"&gt;[Chainer]&lt;/a&gt; (by Yanghua Jin),
&lt;a href="https://github.com/yunjey/mnist-svhn-transfer"&gt;[Minimal PyTorch]&lt;/a&gt; (by yunjey),
&lt;a href="https://github.com/Ldpe2G/DeepLearningForFun/tree/master/Mxnet-Scala/CycleGAN"&gt;[Mxnet]&lt;/a&gt; (by Ldpe2G),
&lt;a href="https://github.com/tjwei/GANotebooks"&gt;[lasagne/Keras]&lt;/a&gt; (by tjwei), 
&lt;a href="https://github.com/simontomaskarlsson/CycleGAN-Keras"&gt;[Keras]&lt;/a&gt; (by Simon Karlsson)&lt;/p&gt;

&lt;h2&gt;&lt;a id="user-content-applications" class="anchor" aria-hidden="true" href="#applications"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Applications&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-monet-paintings-to-photos" class="anchor" aria-hidden="true" href="#monet-paintings-to-photos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Monet Paintings to Photos&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2296236e17ff15eb5a077fdb62df498b9d000a19/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f7061696e74696e673270686f746f2e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/2296236e17ff15eb5a077fdb62df498b9d000a19/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f7061696e74696e673270686f746f2e6a7067" width="1000px" data-canonical-src="https://junyanz.github.io/CycleGAN/images/painting2photo.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-collection-style-transfer" class="anchor" aria-hidden="true" href="#collection-style-transfer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Collection Style Transfer&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1862adecd202ba420847653d9a119f9fed9a3abd/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f70686f746f327061696e74696e672e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/1862adecd202ba420847653d9a119f9fed9a3abd/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f70686f746f327061696e74696e672e6a7067" width="1000px" data-canonical-src="https://junyanz.github.io/CycleGAN/images/photo2painting.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-object-transfiguration" class="anchor" aria-hidden="true" href="#object-transfiguration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Object Transfiguration&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2fadde78dccf4d61f1294933c3e8083c07a303c7/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f6f626a656374732e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/2fadde78dccf4d61f1294933c3e8083c07a303c7/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f6f626a656374732e6a7067" width="1000px" data-canonical-src="https://junyanz.github.io/CycleGAN/images/objects.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-season-transfer" class="anchor" aria-hidden="true" href="#season-transfer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Season Transfer&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e3625979058468277d346b0ee3e7ef8cc399fd51/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f736561736f6e2e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/e3625979058468277d346b0ee3e7ef8cc399fd51/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f736561736f6e2e6a7067" width="1000px" data-canonical-src="https://junyanz.github.io/CycleGAN/images/season.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-photo-enhancement-narrow-depth-of-field" class="anchor" aria-hidden="true" href="#photo-enhancement-narrow-depth-of-field"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Photo Enhancement: Narrow depth of field&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b0610154e3c2a959c0d1acd43cfff304d1df88bd/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f70686f746f5f656e68616e63656d656e742e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/b0610154e3c2a959c0d1acd43cfff304d1df88bd/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f70686f746f5f656e68616e63656d656e742e6a7067" width="1000px" data-canonical-src="https://junyanz.github.io/CycleGAN/images/photo_enhancement.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Linux or OSX&lt;/li&gt;
&lt;li&gt;NVIDIA GPU + CUDA CuDNN (CPU mode and CUDA without CuDNN may work with minimal modification, but untested)&lt;/li&gt;
&lt;li&gt;For MAC users, you need the Linux/GNU commands &lt;code&gt;gfind&lt;/code&gt; and &lt;code&gt;gwc&lt;/code&gt;, which can be installed with &lt;code&gt;brew install findutils coreutils&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Install torch and dependencies from &lt;a href="https://github.com/torch/distro"&gt;https://github.com/torch/distro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install torch packages &lt;code&gt;nngraph&lt;/code&gt;, &lt;code&gt;class&lt;/code&gt;, &lt;code&gt;display&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;luarocks install nngraph
luarocks install class
luarocks install https://raw.githubusercontent.com/szym/display/master/display-scm-0.rockspec&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Clone this repo:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/junyanz/CycleGAN
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; CycleGAN&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-apply-a-pre-trained-model" class="anchor" aria-hidden="true" href="#apply-a-pre-trained-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Apply a Pre-trained Model&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Download the test photos (taken by &lt;a href="https://www.flickr.com/photos/aaefros" rel="nofollow"&gt;Alexei Efros&lt;/a&gt;):&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;bash ./datasets/download_dataset.sh ae_photos
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Download the pre-trained model &lt;code&gt;style_cezanne&lt;/code&gt; (For CPU model, use &lt;code&gt;style_cezanne_cpu&lt;/code&gt;):&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;bash ./pretrained_models/download_model.sh style_cezanne
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Now, let's generate Paul Cézanne style images:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;DATA_ROOT=./datasets/ae_photos name=style_cezanne_pretrained model=one_direction_test phase=test loadSize=256 fineSize=256 resize_or_crop="scale_width" th test.lua
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The test results will be saved to &lt;code&gt;./results/style_cezanne_pretrained/latest_test/index.html&lt;/code&gt;.&lt;br&gt;
Please refer to &lt;a href="#model-zoo"&gt;Model Zoo&lt;/a&gt; for more pre-trained models.
&lt;code&gt;./examples/test_vangogh_style_on_ae_photos.sh&lt;/code&gt; is an example script that downloads the pretrained Van Gogh style network and runs it on Efros's photos.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-train" class="anchor" aria-hidden="true" href="#train"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Download a dataset (e.g. zebra and horse images from ImageNet):&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bash ./datasets/download_dataset.sh horse2zebra&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Train a model:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=./datasets/horse2zebra name=horse2zebra_model th train.lua&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;(CPU only) The same training command without using a GPU or CUDNN. Setting the environment variables &lt;code&gt;gpu=0 cudnn=0&lt;/code&gt; forces CPU only&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=./datasets/horse2zebra name=horse2zebra_model gpu=0 cudnn=0 th train.lua&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;(Optionally) start the display server to view results as the model trains. (See &lt;a href="#display-ui"&gt;Display UI&lt;/a&gt; for more details):&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;th -ldisplay.start 8000 0.0.0.0&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-test" class="anchor" aria-hidden="true" href="#test"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Test&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Finally, test the model:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=./datasets/horse2zebra name=horse2zebra_model phase=test th test.lua&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The test results will be saved to an HTML file here: &lt;code&gt;./results/horse2zebra_model/latest_test/index.html&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-model-zoo" class="anchor" aria-hidden="true" href="#model-zoo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model Zoo&lt;/h2&gt;
&lt;p&gt;Download the pre-trained models with the following script. The model will be saved to &lt;code&gt;./checkpoints/model_name/latest_net_G.t7&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bash ./pretrained_models/download_model.sh model_name&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;orange2apple&lt;/code&gt; (orange -&amp;gt; apple) and &lt;code&gt;apple2orange&lt;/code&gt;: trained on ImageNet categories &lt;code&gt;apple&lt;/code&gt; and &lt;code&gt;orange&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;horse2zebra&lt;/code&gt; (horse -&amp;gt; zebra) and &lt;code&gt;zebra2horse&lt;/code&gt; (zebra -&amp;gt; horse): trained on ImageNet categories &lt;code&gt;horse&lt;/code&gt; and &lt;code&gt;zebra&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;style_monet&lt;/code&gt; (landscape photo -&amp;gt; Monet painting style),  &lt;code&gt;style_vangogh&lt;/code&gt; (landscape photo  -&amp;gt; Van Gogh painting style), &lt;code&gt;style_ukiyoe&lt;/code&gt; (landscape photo  -&amp;gt; Ukiyo-e painting style), &lt;code&gt;style_cezanne&lt;/code&gt; (landscape photo  -&amp;gt; Cezanne painting style): trained on paintings and Flickr landscape photos.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;monet2photo&lt;/code&gt; (Monet paintings -&amp;gt; real landscape): trained on paintings and Flickr landscape photographs.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cityscapes_photo2label&lt;/code&gt; (street scene -&amp;gt; label) and &lt;code&gt;cityscapes_label2photo&lt;/code&gt; (label -&amp;gt; street scene): trained on the Cityscapes dataset.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;map2sat&lt;/code&gt; (map -&amp;gt; aerial photo) and &lt;code&gt;sat2map&lt;/code&gt; (aerial photo -&amp;gt; map): trained on Google maps.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;iphone2dslr_flower&lt;/code&gt; (iPhone photos of flowers -&amp;gt; DSLR photos of flowers): trained on Flickr photos.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CPU models can be downloaded using:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bash pretrained_models/download_model.sh &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;name&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;_cpu&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;, where &lt;code&gt;&amp;lt;name&amp;gt;&lt;/code&gt; can be &lt;code&gt;horse2zebra&lt;/code&gt;, &lt;code&gt;style_monet&lt;/code&gt;, etc. You just need to append &lt;code&gt;_cpu&lt;/code&gt; to the target model.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-training-and-test-details" class="anchor" aria-hidden="true" href="#training-and-test-details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training and Test Details&lt;/h2&gt;
&lt;p&gt;To train a model,&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=/path/to/data/ name=expt_name th train.lua&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Models are saved to &lt;code&gt;./checkpoints/expt_name&lt;/code&gt; (can be changed by passing &lt;code&gt;checkpoint_dir=your_dir&lt;/code&gt; in train.lua).&lt;br&gt;
See &lt;code&gt;opt_train&lt;/code&gt; in &lt;code&gt;options.lua&lt;/code&gt; for additional training options.&lt;/p&gt;
&lt;p&gt;To test the model,&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=/path/to/data/ name=expt_name phase=test th test.lua&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will run the model named &lt;code&gt;expt_name&lt;/code&gt; in both directions on all images in &lt;code&gt;/path/to/data/testA&lt;/code&gt; and &lt;code&gt;/path/to/data/testB&lt;/code&gt;.&lt;br&gt;
A webpage with result images will be saved to &lt;code&gt;./results/expt_name&lt;/code&gt; (can be changed by passing &lt;code&gt;results_dir=your_dir&lt;/code&gt; in test.lua).&lt;br&gt;
See &lt;code&gt;opt_test&lt;/code&gt; in &lt;code&gt;options.lua&lt;/code&gt; for additional test options. Please use &lt;code&gt;model=one_direction_test&lt;/code&gt; if you only would like to generate outputs of the trained network in only one direction, and specify &lt;code&gt;which_direction=AtoB&lt;/code&gt; or &lt;code&gt;which_direction=BtoA&lt;/code&gt; to set the direction.&lt;/p&gt;
&lt;p&gt;There are other options that can be used. For example, you can specify &lt;code&gt;resize_or_crop=crop&lt;/code&gt; option to avoid resizing the image to squares. This is indeed how we trained GTA2Cityscapes model in the projet &lt;a href="https://junyanz.github.io/CycleGAN/" rel="nofollow"&gt;webpage&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/1711.03213.pdf" rel="nofollow"&gt;Cycada&lt;/a&gt; model. We prepared the images at 1024px resolution, and used &lt;code&gt;resize_or_crop=crop fineSize=360&lt;/code&gt; to work with the cropped images of size 360x360. We also used &lt;code&gt;lambda_identity=1.0&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-datasets" class="anchor" aria-hidden="true" href="#datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Datasets&lt;/h2&gt;
&lt;p&gt;Download the datasets using the following script. Many of the datasets were collected by other researchers. Please cite their papers if you use the data.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bash ./datasets/download_dataset.sh dataset_name&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;facades&lt;/code&gt;: 400 images from the &lt;a href="http://cmp.felk.cvut.cz/~tylecr1/facade/" rel="nofollow"&gt;CMP Facades dataset&lt;/a&gt;. [&lt;a href="datasets/bibtex/facades.tex"&gt;Citation&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cityscapes&lt;/code&gt;: 2975 images from the &lt;a href="https://www.cityscapes-dataset.com/" rel="nofollow"&gt;Cityscapes training set&lt;/a&gt;. [&lt;a href="datasets/bibtex/cityscapes.tex"&gt;Citation&lt;/a&gt;]. Note: Due to license issue, we do not host the dataset on our repo. Please download the dataset directly from the Cityscapes webpage. Please refer to &lt;code&gt;./datasets/prepare_cityscapes_dataset.py&lt;/code&gt; for more detail.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;maps&lt;/code&gt;: 1096 training images scraped from Google Maps.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;horse2zebra&lt;/code&gt;: 939 horse images and 1177 zebra images downloaded from &lt;a href="http://www.image-net.org/" rel="nofollow"&gt;ImageNet&lt;/a&gt; using the keywords &lt;code&gt;wild horse&lt;/code&gt; and &lt;code&gt;zebra&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;apple2orange&lt;/code&gt;: 996 apple images and 1020 orange images downloaded from &lt;a href="http://www.image-net.org/" rel="nofollow"&gt;ImageNet&lt;/a&gt; using the keywords &lt;code&gt;apple&lt;/code&gt; and &lt;code&gt;navel orange&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;summer2winter_yosemite&lt;/code&gt;: 1273 summer Yosemite images and 854 winter Yosemite images were downloaded using Flickr API. See more details in our paper.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;monet2photo&lt;/code&gt;, &lt;code&gt;vangogh2photo&lt;/code&gt;, &lt;code&gt;ukiyoe2photo&lt;/code&gt;, &lt;code&gt;cezanne2photo&lt;/code&gt;: The art images were downloaded from &lt;a href="https://www.wikiart.org/" rel="nofollow"&gt;Wikiart&lt;/a&gt;. The real photos are downloaded from Flickr using the combination of the tags &lt;em&gt;landscape&lt;/em&gt; and &lt;em&gt;landscapephotography&lt;/em&gt;. The training set size of each class is Monet:1074, Cezanne:584, Van Gogh:401, Ukiyo-e:1433, Photographs:6853.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;iphone2dslr_flower&lt;/code&gt;: both classes of images were downloaded from Flickr. The training set size of each class is iPhone:1813, DSLR:3316. See more details in our paper.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-display-ui" class="anchor" aria-hidden="true" href="#display-ui"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Display UI&lt;/h2&gt;
&lt;p&gt;Optionally, for displaying images during training and test, use the &lt;a href="https://github.com/szym/display"&gt;display package&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install it with: &lt;code&gt;luarocks install https://raw.githubusercontent.com/szym/display/master/display-scm-0.rockspec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Then start the server with: &lt;code&gt;th -ldisplay.start&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Open this URL in your browser: &lt;a href="http://localhost:8000" rel="nofollow"&gt;http://localhost:8000&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By default, the server listens on localhost. Pass &lt;code&gt;0.0.0.0&lt;/code&gt; to allow external connections on any interface:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;th -ldisplay.start 8000 0.0.0.0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then open &lt;code&gt;http://(hostname):(port)/&lt;/code&gt; in your browser to load the remote desktop.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-setup-training-and-test-data" class="anchor" aria-hidden="true" href="#setup-training-and-test-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup Training and Test data&lt;/h2&gt;
&lt;p&gt;To train CycleGAN model on your own datasets, you need to create a data folder with two subdirectories &lt;code&gt;trainA&lt;/code&gt; and &lt;code&gt;trainB&lt;/code&gt; that contain images from domain A and B. You can test your model on your training set by setting &lt;code&gt;phase='train'&lt;/code&gt; in  &lt;code&gt;test.lua&lt;/code&gt;. You can also create subdirectories &lt;code&gt;testA&lt;/code&gt; and &lt;code&gt;testB&lt;/code&gt; if you have test data.&lt;/p&gt;
&lt;p&gt;You should &lt;strong&gt;not&lt;/strong&gt; expect our method to work on just any random combination of input and output datasets (e.g. &lt;code&gt;cats&amp;lt;-&amp;gt;keyboards&lt;/code&gt;). From our experiments, we find it works better if two datasets share similar visual content. For example, &lt;code&gt;landscape painting&amp;lt;-&amp;gt;landscape photographs&lt;/code&gt; works much better than &lt;code&gt;portrait painting &amp;lt;-&amp;gt; landscape photographs&lt;/code&gt;. &lt;code&gt;zebras&amp;lt;-&amp;gt;horses&lt;/code&gt; achieves compelling results while &lt;code&gt;cats&amp;lt;-&amp;gt;dogs&lt;/code&gt; completely fails.  See the following section for more discussion.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-failure-cases" class="anchor" aria-hidden="true" href="#failure-cases"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Failure cases&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/757b691307b52fe8a0806dde3a560dc068dbf5b3/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f6661696c7572655f707574696e2e6a7067"&gt;&lt;img align="left" src="https://camo.githubusercontent.com/757b691307b52fe8a0806dde3a560dc068dbf5b3/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f6661696c7572655f707574696e2e6a7067" width="320" data-canonical-src="https://junyanz.github.io/CycleGAN/images/failure_putin.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Our model does not work well when the test image is rather different from the images on which the model is trained, as is the case in the figure to the left (we trained on horses and zebras without riders, but test here one a horse with a rider).  See additional typical failure cases &lt;a href="https://junyanz.github.io/CycleGAN/images/failures.jpg" rel="nofollow"&gt;here&lt;/a&gt;. On translation tasks that involve color and texture changes, like many of those reported above, the method often succeeds. We have also explored tasks that require geometric changes, with little success. For example, on the task of &lt;code&gt;dog&amp;lt;-&amp;gt;cat&lt;/code&gt; transfiguration, the learned translation degenerates into making minimal changes to the input. We also observe a lingering gap between the results achievable with paired training data and those achieved by our unpaired method. In some cases, this gap may be very hard -- or even impossible,-- to close: for example, our method sometimes permutes the labels for tree and building in the output of the cityscapes photos-&amp;gt;labels task.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you use this code for your research, please cite our &lt;a href="https://junyanz.github.io/CycleGAN/" rel="nofollow"&gt;paper&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@inproceedings{CycleGAN2017,
  title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networkss},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},
  year={2017}
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-related-projects" class="anchor" aria-hidden="true" href="#related-projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Related Projects:&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/phillipi/pix2pix"&gt;pix2pix&lt;/a&gt;: Image-to-image translation using conditional adversarial nets&lt;br&gt;
&lt;a href="https://github.com/junyanz/iGAN"&gt;iGAN&lt;/a&gt;: Interactive Image Generation via Generative Adversarial Networks&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-cat-paper-collection" class="anchor" aria-hidden="true" href="#cat-paper-collection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cat Paper Collection&lt;/h2&gt;
&lt;p&gt;If you love cats, and love reading cool graphics, vision, and ML papers, please check out the Cat Paper &lt;a href="https://github.com/junyanz/CatPapers"&gt;Collection&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Code borrows from &lt;a href="https://github.com/phillipi/pix2pix"&gt;pix2pix&lt;/a&gt; and &lt;a href="https://github.com/soumith/dcgan.torch"&gt;DCGAN&lt;/a&gt;. The data loader is modified from &lt;a href="https://github.com/soumith/dcgan.torch"&gt;DCGAN&lt;/a&gt; and  &lt;a href="https://github.com/pathak22/context-encoder"&gt;Context-Encoder&lt;/a&gt;. The generative network is adopted from &lt;a href="https://github.com/jcjohnson/neural-style"&gt;neural-style&lt;/a&gt; with &lt;a href="https://github.com/DmitryUlyanov/texture_nets/blob/master/InstanceNormalization.lua"&gt;Instance Normalization&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>junyanz</author><guid isPermaLink="false">https://github.com/junyanz/CycleGAN</guid><pubDate>Fri, 08 Nov 2019 00:06:00 GMT</pubDate></item><item><title>rubbertoe98/FiveM-Scripts #7 in Lua, This month</title><link>https://github.com/rubbertoe98/FiveM-Scripts</link><description>&lt;p&gt;&lt;i&gt;Compilation of my publically released FiveM code&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-fivem-scripts" class="anchor" aria-hidden="true" href="#fivem-scripts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FiveM-Scripts&lt;/h1&gt;
&lt;p&gt;Compilation of my publicly released code&lt;/p&gt;
&lt;p&gt;Feel free to make improvements with PRs&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>rubbertoe98</author><guid isPermaLink="false">https://github.com/rubbertoe98/FiveM-Scripts</guid><pubDate>Fri, 08 Nov 2019 00:07:00 GMT</pubDate></item><item><title>cardwing/Codes-for-Lane-Detection #8 in Lua, This month</title><link>https://github.com/cardwing/Codes-for-Lane-Detection</link><description>&lt;p&gt;&lt;i&gt;Learning Lightweight Lane Detection CNNs by Self Attention Distillation (ICCV 2019)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;Codes for &lt;a href="https://arxiv.org/abs/1908.00821" rel="nofollow"&gt;"Learning Lightweight Lane Detection CNNs by Self Attention Distillation"&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repo also contains Tensorflow implementation of &lt;a href="https://arxiv.org/abs/1712.06080" rel="nofollow"&gt;"Spatial As Deep: Spatial CNN for Traffic Scene Understanding"&lt;/a&gt;. (SCNN-Tensorflow)&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-news" class="anchor" aria-hidden="true" href="#news"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;News&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="./ERFNet-CULane-PyTorch"&gt;ERFNet-CULane-PyTorch&lt;/a&gt; has been released. (It can achieve &lt;strong&gt;73.1&lt;/strong&gt; F1-measure in CULane testing set)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="./ENet-Label-Torch"&gt;ENet-Label-Torch&lt;/a&gt;, &lt;a href="./ENet-TuSimple-Torch"&gt;ENet-TuSimple-Torch&lt;/a&gt; and &lt;a href="./ENet-BDD100K-Torch"&gt;ENet-BDD100K-Torch&lt;/a&gt; have been released.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Key features:&lt;/p&gt;
&lt;p&gt;(1) ENet-label is a &lt;strong&gt;light-weight&lt;/strong&gt; lane detection model based on &lt;a href="https://arxiv.org/abs/1606.02147" rel="nofollow"&gt;ENet&lt;/a&gt; and adopts &lt;strong&gt;self attention distillation&lt;/strong&gt; (more details can be found in our paper).&lt;/p&gt;
&lt;p&gt;(2) It has &lt;strong&gt;20&lt;/strong&gt; × fewer parameters and runs &lt;strong&gt;10&lt;/strong&gt; × faster compared to the state-of-the-art SCNN, and achieves &lt;strong&gt;72.0&lt;/strong&gt; (F1-measure) on CULane testing set (better than SCNN which achieves 71.6). It also achieves &lt;strong&gt;96.64%&lt;/strong&gt; accuracy in TuSimple testing set (better than SCNN which achieves 96.53%) and &lt;strong&gt;36.56%&lt;/strong&gt; accuracy in BDD100K testing set (better than SCNN which achieves 35.79%).&lt;/p&gt;
&lt;p&gt;(3) Applying ENet-SAD to &lt;a href="https://unsupervised-llamas.com/llamas/" rel="nofollow"&gt;LLAMAS&lt;/a&gt; dataset yields &lt;strong&gt;0.635&lt;/strong&gt; mAP in the &lt;a href="https://unsupervised-llamas.com/llamas/benchmark_multi" rel="nofollow"&gt;multi-class lane marker segmentation task&lt;/a&gt;, which is much better than the baseline algorithm which achieves 0.500 mAP. Details can be found in &lt;a href="https://github.com/cardwing/unsupervised_llamas/tree/master/ENet-SAD-Simple"&gt;this repo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;(Do not hesitate to try our model!!!)&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Multi-GPU training has been supported. Just change BATCH_SIZE and GPU_NUM in global_config.py, and then use &lt;code&gt;CUDA_VISIBLE_DEVICES="0,1,2,3" python file_name.py&lt;/code&gt;. Thanks @ yujincheng08.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;&lt;a id="user-content-content" class="anchor" aria-hidden="true" href="#content"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Content&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#Installation"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Datasets"&gt;Datasets&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#TuSimple"&gt;TuSimple&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#CULane"&gt;CULane&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#BDD100K"&gt;BDD100K&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#SCNN-Tensorflow"&gt;SCNN-Tensorflow&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#Test"&gt;Test&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Train"&gt;Train&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#Performance"&gt;Performance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Others"&gt;Others&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#Citation"&gt;Citation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Acknowledgement"&gt;Acknowledgement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Contact"&gt;Contact&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Install necessary packages:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;    conda create -n tensorflow_gpu pip python=3.5
    source activate tensorflow_gpu
    pip install --upgrade tensorflow-gpu==1.3.0
    pip3 install -r SCNN-Tensorflow/lane-detection-model/requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Download VGG-16:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Download the vgg.npy &lt;a href="https://github.com/machrisaa/tensorflow-vgg"&gt;here&lt;/a&gt; and put it in SCNN-Tensorflow/lane-detection-model/data.&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Pre-trained model for testing:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Download the pre-trained model &lt;a href="https://drive.google.com/open?id=1-E0Bws7-v35vOVfqEXDTJdfovUTQ2sf5" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-datasets" class="anchor" aria-hidden="true" href="#datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Datasets&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-tusimple" class="anchor" aria-hidden="true" href="#tusimple"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TuSimple&lt;/h2&gt;
&lt;p&gt;The ground-truth labels of TuSimple testing set is now available at &lt;a href="https://github.com/TuSimple/tusimple-benchmark/issues/3"&gt;TuSimple&lt;/a&gt;. The annotated training (#frame = 3268) and validation labels (#frame = 358) can be found &lt;a href="https://github.com/cardwing/Codes-for-Lane-Detection/issues/11"&gt;here&lt;/a&gt;, please use them (list-name.txt) to replace the train_gt.txt and val_gt.txt in &lt;a href="./SCNN-Tensorflow/lane-detection-model/tools/train_lanenet.py"&gt;train_lanenet.py&lt;/a&gt;. Moreover, you need to resize the image to 256 x 512 instead of 288 x 800 in TuSimple. Remember to change the maximum index of rows and columns, and detailed explanations can be seen &lt;a href="https://github.com/cardwing/Codes-for-Lane-Detection/issues/18"&gt;here&lt;/a&gt;. Please evaluate your pred.json using the labels and &lt;a href="https://github.com/TuSimple/tusimple-benchmark/blob/master/evaluate/lane.py"&gt;this script&lt;/a&gt;. Besides, to generate pred.json, you can refer to &lt;a href="https://github.com/cardwing/Codes-for-Lane-Detection/issues/4"&gt;this issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-culane" class="anchor" aria-hidden="true" href="#culane"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CULane&lt;/h2&gt;
&lt;p&gt;The whole dataset is available at &lt;a href="https://xingangpan.github.io/projects/CULane.html" rel="nofollow"&gt;CULane&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-bdd100k" class="anchor" aria-hidden="true" href="#bdd100k"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;BDD100K&lt;/h2&gt;
&lt;p&gt;The whole dataset is available at &lt;a href="http://bdd-data.berkeley.edu/" rel="nofollow"&gt;BDD100K&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-scnn-tensorflow" class="anchor" aria-hidden="true" href="#scnn-tensorflow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SCNN-Tensorflow&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-test" class="anchor" aria-hidden="true" href="#test"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Test&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;cd SCNN-Tensorflow/lane-detection-model
CUDA_VISIBLE_DEVICES="0" python tools/test_lanenet.py --weights_path path/to/model_weights_file --image_path path/to/image_name_list --save_dir to_be_saved_dir
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that path/to/image_name_list should be like &lt;a href="./SCNN-Tensorflow/lane-detection-model/demo_file/test_img.txt"&gt;test_img.txt&lt;/a&gt;. Now, you get the probability maps from our model. To get the final performance, you need to follow &lt;a href="https://github.com/XingangPan/SCNN"&gt;SCNN&lt;/a&gt; to get curve lines from probability maps as well as calculate precision, recall and F1-measure.&lt;/p&gt;
&lt;p&gt;Reminder: you should check &lt;a href="./SCNN-Tensorflow/lane-detection-model/data_provider/lanenet_data_processor.py"&gt;lanenet_data_processor.py&lt;/a&gt; and &lt;a href="./SCNN-Tensorflow/lane-detection-model/data_provider/lanenet_data_processor.py"&gt;lanenet_data_processor_test.py&lt;/a&gt; to ensure that the processing of image path is right. You are recommended to use the absolute path in your image path list. Besides, this code needs batch size used in training and testing to be consistent. To enable arbitrary batch size in the testing phase, please refer to &lt;a href="https://github.com/cardwing/Codes-for-Lane-Detection/issues/10"&gt;this issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-train" class="anchor" aria-hidden="true" href="#train"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES="0" python tools/train_lanenet.py --net vgg --dataset_dir path/to/CULane-dataset/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that path/to/CULane-dataset/ should contain files like &lt;a href="./SCNN-Tensorflow/lane-detection-model/demo_file/train_gt.txt"&gt;train_gt.txt&lt;/a&gt; and &lt;a href="./SCNN-Tensorflow/lane-detection-model/demo_file/train_gt.txt"&gt;val_gt.txt&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-performance" class="anchor" aria-hidden="true" href="#performance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Performance&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;TuSimple testing set:&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Model&lt;/th&gt;
&lt;th align="center"&gt;Accuracy&lt;/th&gt;
&lt;th align="center"&gt;FP&lt;/th&gt;
&lt;th align="center"&gt;FN&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/XingangPan/SCNN"&gt;SCNN-Torch&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;96.53%&lt;/td&gt;
&lt;td align="center"&gt;0.0617&lt;/td&gt;
&lt;td align="center"&gt;0.0180&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;SCNN-Tensorflow&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;ENet-Label-Torch&lt;/td&gt;
&lt;td align="center"&gt;96.64%&lt;/td&gt;
&lt;td align="center"&gt;0.0602&lt;/td&gt;
&lt;td align="center"&gt;0.0205&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The pre-trained model for testing is here. (coming soon!) Note that in TuSimple, SCNN-Torch is based on ResNet-101 while SCNN-Tensorflow is based on VGG-16. In CULane and BDD100K, both SCNN-Torch and SCNN-Tensorflow are based on VGG-16.&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;CULane testing set (F1-measure):&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Category&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://github.com/XingangPan/SCNN"&gt;SCNN-Torch&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;SCNN-Tensorflow&lt;/th&gt;
&lt;th align="center"&gt;ENet-Label-Torch&lt;/th&gt;
&lt;th align="center"&gt;ERFNet-CULane-PyTorch&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Normal&lt;/td&gt;
&lt;td align="center"&gt;90.6&lt;/td&gt;
&lt;td align="center"&gt;90.2&lt;/td&gt;
&lt;td align="center"&gt;90.7&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;91.5&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Crowded&lt;/td&gt;
&lt;td align="center"&gt;69.7&lt;/td&gt;
&lt;td align="center"&gt;71.9&lt;/td&gt;
&lt;td align="center"&gt;70.8&lt;/td&gt;
&lt;td align="center"&gt;71.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Night&lt;/td&gt;
&lt;td align="center"&gt;66.1&lt;/td&gt;
&lt;td align="center"&gt;64.6&lt;/td&gt;
&lt;td align="center"&gt;65.9&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;67.1&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;No line&lt;/td&gt;
&lt;td align="center"&gt;43.4&lt;/td&gt;
&lt;td align="center"&gt;45.8&lt;/td&gt;
&lt;td align="center"&gt;44.7&lt;/td&gt;
&lt;td align="center"&gt;45.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Shadow&lt;/td&gt;
&lt;td align="center"&gt;66.9&lt;/td&gt;
&lt;td align="center"&gt;73.8&lt;/td&gt;
&lt;td align="center"&gt;70.6&lt;/td&gt;
&lt;td align="center"&gt;71.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Arrow&lt;/td&gt;
&lt;td align="center"&gt;84.1&lt;/td&gt;
&lt;td align="center"&gt;83.8&lt;/td&gt;
&lt;td align="center"&gt;85.8&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;87.2&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Dazzle light&lt;/td&gt;
&lt;td align="center"&gt;58.5&lt;/td&gt;
&lt;td align="center"&gt;59.5&lt;/td&gt;
&lt;td align="center"&gt;64.4&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;66.0&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Curve&lt;/td&gt;
&lt;td align="center"&gt;64.4&lt;/td&gt;
&lt;td align="center"&gt;63.4&lt;/td&gt;
&lt;td align="center"&gt;65.4&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;66.3&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Crossroad&lt;/td&gt;
&lt;td align="center"&gt;1990&lt;/td&gt;
&lt;td align="center"&gt;4137&lt;/td&gt;
&lt;td align="center"&gt;2729&lt;/td&gt;
&lt;td align="center"&gt;2199&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Total&lt;/td&gt;
&lt;td align="center"&gt;71.6&lt;/td&gt;
&lt;td align="center"&gt;71.3&lt;/td&gt;
&lt;td align="center"&gt;72.0&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;73.1&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Runtime(ms)&lt;/td&gt;
&lt;td align="center"&gt;133.5&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;td align="center"&gt;13.4&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;10.2&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Parameter(M)&lt;/td&gt;
&lt;td align="center"&gt;20.72&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;0.98&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;2.49&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The pre-trained model for testing is &lt;a href="https://drive.google.com/open?id=1-E0Bws7-v35vOVfqEXDTJdfovUTQ2sf5" rel="nofollow"&gt;here&lt;/a&gt;. Note that you need to exchange the order of VGG-MEAN in test_lanenet.py and change the order of input images from RGB to BGR since the pre-trained model uses opencv to read images. You can further boost the performance by referring to &lt;a href="https://github.com/cardwing/Codes-for-Lane-Detection/issues/5"&gt;this issue&lt;/a&gt;.&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;BDD100K testing set:&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Model&lt;/th&gt;
&lt;th align="center"&gt;Accuracy&lt;/th&gt;
&lt;th align="center"&gt;IoU&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/XingangPan/SCNN"&gt;SCNN-Torch&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;35.79%&lt;/td&gt;
&lt;td align="center"&gt;15.84&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;SCNN-Tensorflow&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;ENet-Label-Torch&lt;/td&gt;
&lt;td align="center"&gt;36.56%&lt;/td&gt;
&lt;td align="center"&gt;16.02&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The accuracy and IoU of lane pixels are computed. The pre-trained model for testing is here. (coming soon!)&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-others" class="anchor" aria-hidden="true" href="#others"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Others&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you use the codes, please cite the following publications:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{hou2019learning,
  title={Learning Lightweight Lane Detection CNNs by Self Attention Distillation},
  author={Hou, Yuenan and Ma, Zheng and Liu, Chunxiao and Loy, Chen Change},
  journal={arXiv preprint arXiv:1908.00821},
  year={2019}
}

@inproceedings{pan2018SCNN,  
  author = {Xingang Pan, Jianping Shi, Ping Luo, Xiaogang Wang, and Xiaoou Tang},  
  title = {Spatial As Deep: Spatial CNN for Traffic Scene Understanding},  
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},  
  month = {February},  
  year = {2018}  
}

@misc{hou2019agnostic,
    title={Agnostic Lane Detection},
    author={Yuenan Hou},
    year={2019},
    eprint={1905.03704},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgement" class="anchor" aria-hidden="true" href="#acknowledgement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;This repo is built upon &lt;a href="https://github.com/XingangPan/SCNN"&gt;SCNN&lt;/a&gt; and &lt;a href="https://github.com/MaybeShewill-CV/lanenet-lane-detection"&gt;LaneNet&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h2&gt;
&lt;p&gt;If you have any problems in reproducing the results, just raise an issue in this repo.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-to-do-list" class="anchor" aria-hidden="true" href="#to-do-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;To-Do List&lt;/h2&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Test SCNN-Tensorflow in TuSimple and BDD100K&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; Provide detailed instructions to run SCNN-Tensorflow in TuSimple and BDD100K&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; Upload our light-weight model (ENet-SAD) and its training &amp;amp; testing scripts&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>cardwing</author><guid isPermaLink="false">https://github.com/cardwing/Codes-for-Lane-Detection</guid><pubDate>Fri, 08 Nov 2019 00:08:00 GMT</pubDate></item><item><title>orlabs/orange #9 in Lua, This month</title><link>https://github.com/orlabs/orange</link><description>&lt;p&gt;&lt;i&gt;OpenResty/Nginx Gateway for API Monitoring and Management.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-orange" class="anchor" aria-hidden="true" href="#orange"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Orange&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/sumory/orange/releases/latest"&gt;&lt;img src="https://camo.githubusercontent.com/860421e6b9bd5927da7605b2052a1edaeb263734/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f73756d6f72792f6f72616e67652e737667" alt="GitHub release" data-canonical-src="https://img.shields.io/github/release/sumory/orange.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://github.com/sumory/orange/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/fd2573a24f7e9a5331155e96db622476152e3250/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f73756d6f72792f6f72616e67652e737667" alt="license" data-canonical-src="https://img.shields.io/github/license/sumory/orange.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="./README_zh.md"&gt;中文&lt;/a&gt; | &lt;a href="./README.md"&gt;English&lt;/a&gt; | &lt;a href="http://orange.sumory.com" rel="nofollow"&gt;Website&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A Gateway based on OpenResty(Nginx + Lua) for API Monitoring and Management.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-install--usages" class="anchor" aria-hidden="true" href="#install--usages"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install &amp;amp; Usages&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-install-of-production-environment-not-support-macos" class="anchor" aria-hidden="true" href="#install-of-production-environment-not-support-macos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install of Production Environment (Not Support macOS)&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-1-install-dependencies" class="anchor" aria-hidden="true" href="#1-install-dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1) Install Dependencies&lt;/h4&gt;
&lt;p&gt;We recommend that you use &lt;a href="https://luarocks.org/" rel="nofollow"&gt;luarocks&lt;/a&gt; to install &lt;code&gt;Orange&lt;/code&gt; to reduce problems caused by dependency extensions in different operating system releases.&lt;/p&gt;
&lt;p&gt;System dependencies (&lt;code&gt;openresty&lt;/code&gt;, &lt;code&gt;resty-cli&lt;/code&gt;, &lt;code&gt;luarocks&lt;/code&gt;, etc.) necessary to install &lt;code&gt;Orange&lt;/code&gt; on different operating systems, See: &lt;a href="docs/install-dependencies.md"&gt;Install Dependencies&lt;/a&gt; Document.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-2-install-lor-framework" class="anchor" aria-hidden="true" href="#2-install-lor-framework"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2) Install Lor Framework&lt;/h4&gt;
&lt;p&gt;Check the &lt;a href="https://github.com/sumory/lor"&gt;official documentation&lt;/a&gt; for &lt;code&gt;Lor Framework&lt;/code&gt; or execute the following command.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/sumory/lor.git
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; lor
sudo make install&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-3-install-orange" class="anchor" aria-hidden="true" href="#3-install-orange"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3) Install Orange&lt;/h4&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;curl -Lo install.sh https://raw.githubusercontent.com/orlabs/orange/master/install/install-orange.sh
sudo sh install.sh&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After the installation process is completed, the output message &lt;code&gt;orange 0.8-0 is now installed in /usr/local/orange/deps (license: MIT)&lt;/code&gt; indicates that the installation was successful.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-4-import-mysql" class="anchor" aria-hidden="true" href="#4-import-mysql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4) Import MySQL&lt;/h4&gt;
&lt;p&gt;Requirements: MySQL Version 5.5+&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Login to the &lt;code&gt;MySQL&lt;/code&gt; client, create an &lt;code&gt;orange&lt;/code&gt; database.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Import the data table (&lt;code&gt;/usr/local/orange/conf/orange-v0.8.0.sql&lt;/code&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Modify the &lt;code&gt;Orange&lt;/code&gt; configuration file (&lt;code&gt;/usr/local/orange/conf/orange.conf&lt;/code&gt;) &lt;code&gt;MySQL&lt;/code&gt; related configuration.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-5-start-orange" class="anchor" aria-hidden="true" href="#5-start-orange"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;5) Start Orange&lt;/h4&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo orange start&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After the &lt;code&gt;Orange&lt;/code&gt; launches successfully, the &lt;code&gt;dashboard&lt;/code&gt; and &lt;code&gt;API Server&lt;/code&gt; are started:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Access &lt;code&gt;Dashboard&lt;/code&gt; via &lt;code&gt;http://localhost:9999&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Access &lt;code&gt;API Server&lt;/code&gt; via &lt;code&gt;http://localhost:7777&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At this point, &lt;code&gt;Orange&lt;/code&gt; has all been installed and configured, please enjoy it.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-install-of-development-environment-not-support-macos" class="anchor" aria-hidden="true" href="#install-of-development-environment-not-support-macos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install of Development Environment (Not Support macOS)&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-1-dependencies-and-lor" class="anchor" aria-hidden="true" href="#1-dependencies-and-lor"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1) Dependencies and Lor&lt;/h4&gt;
&lt;p&gt;Please use the &lt;a href="#1-install-dependencies"&gt;Install Dependencies&lt;/a&gt; and &lt;a href="#2-install-lor-framework"&gt;Install Lor Framework&lt;/a&gt; methods in &lt;a href="#install-of-production-environment-not-support-macos"&gt;Install of Production Environment&lt;/a&gt; to install.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-2-install-orange" class="anchor" aria-hidden="true" href="#2-install-orange"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2) Install Orange&lt;/h4&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/orlabs/orange.git
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; orange
sodu make dev&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After the installation process is completed, the output message &lt;code&gt;Stopping after installing dependencies for orange-master 1.0-0&lt;/code&gt; indicates that the installation was successful.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-3-import-mysql" class="anchor" aria-hidden="true" href="#3-import-mysql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3) Import MySQL&lt;/h4&gt;
&lt;p&gt;Please use the &lt;a href="#4-import-mysql"&gt;Import MySQL&lt;/a&gt; methods in &lt;a href="#install-of-production-environment-not-support-macos"&gt;Install of Production Environment&lt;/a&gt; to import.&lt;/p&gt;
&lt;p&gt;Note: Install &lt;code&gt;Orange&lt;/code&gt; in &lt;code&gt;Development Environment&lt;/code&gt;, the &lt;code&gt;MySQL Data Table&lt;/code&gt; file and the &lt;code&gt;Orange Config&lt;/code&gt; file are located in the &lt;code&gt;conf&lt;/code&gt; folder of the current project.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-4-start-orange" class="anchor" aria-hidden="true" href="#4-start-orange"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4) Start Orange&lt;/h4&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo ./bin/orange start&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Access method after the successful startup of &lt;code&gt;Orange&lt;/code&gt;, please refer to: &lt;a href="#5-start-orange"&gt;Start Orange&lt;/a&gt; in &lt;a href="#install-of-production-environment-not-support-macos"&gt;Install of Production Environment&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-usages" class="anchor" aria-hidden="true" href="#usages"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usages&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-cli-tools" class="anchor" aria-hidden="true" href="#cli-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CLI tools&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;orange help&lt;/code&gt; to check usages:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;Usage: orange COMMAND [OPTIONS]

The commands are:

start   Start the Orange Gateway
stop    Stop current Orange
reload  Reload the config of Orange
restart Restart Orange
store   Init/Update/Backup Orange store
version Show the version of Orange
&lt;span class="pl-c1"&gt;help&lt;/span&gt;    Show &lt;span class="pl-c1"&gt;help&lt;/span&gt; tips&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-documents" class="anchor" aria-hidden="true" href="#documents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documents&lt;/h2&gt;
&lt;p&gt;Find more about &lt;code&gt;Orange&lt;/code&gt; on its &lt;a href="http://orange.sumory.com/docs" rel="nofollow"&gt;website&lt;/a&gt;. There is only a Chinese version for now.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://store.docker.com/community/images/syhily/orange" rel="nofollow"&gt;https://store.docker.com/community/images/syhily/orange&lt;/a&gt; maintained by &lt;a href="https://github.com/syhily"&gt;@syhily&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/syhily"&gt;@syhily&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lhmwzy"&gt;@lhmwzy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/spacewander"&gt;@spacewander&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/noname007"&gt;@noname007&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/itchenyi"&gt;@itchenyi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Near-Zhang"&gt;@Near-Zhang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/khlipeng"&gt;@khlipeng&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wujunze"&gt;@wujunze&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/shuaijinchao"&gt;@shuaijinchao&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/EasonFeng5870"&gt;@EasonFeng5870&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhjwpku"&gt;@zhjwpku&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-see-also" class="anchor" aria-hidden="true" href="#see-also"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;See also&lt;/h2&gt;
&lt;p&gt;The plugin architecture is highly inspired by &lt;a href="https://github.com/Mashape/kong"&gt;Kong&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a href="./LICENSE"&gt;MIT&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>orlabs</author><guid isPermaLink="false">https://github.com/orlabs/orange</guid><pubDate>Fri, 08 Nov 2019 00:09:00 GMT</pubDate></item><item><title>skywind3000/z.lua #10 in Lua, This month</title><link>https://github.com/skywind3000/z.lua</link><description>&lt;p&gt;&lt;i&gt;A new cd command that helps you navigate faster by learning your habits :zap:&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-zlua" class="anchor" aria-hidden="true" href="#zlua"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;z.lua&lt;/h1&gt;
&lt;p&gt;A command line tool which helps you navigate faster by learning your habits &lt;g-emoji class="g-emoji" alias="zap" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a1.png"&gt;⚡️&lt;/g-emoji&gt;&lt;/p&gt;
&lt;p&gt;An alternative to &lt;a href="https://github.com/rupa/z"&gt;z.sh&lt;/a&gt; with windows and posix shells support and various improvements.&lt;/p&gt;
&lt;p&gt;【&lt;a href="README.cn.md"&gt;README in Chinese | 中文文档&lt;/a&gt;】&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-description" class="anchor" aria-hidden="true" href="#description"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Description&lt;/h2&gt;
&lt;p&gt;z.lua is a faster way to navigate your filesystem. It tracks your most used directories, based on 'frecency'.  After  a  short  learning  phase, z will take you to the most 'frecent' directory that matches ALL of the regexes given on the command line, in order.&lt;/p&gt;
&lt;p&gt;For example, &lt;code&gt;z foo bar&lt;/code&gt; would match &lt;code&gt;/foo/bar&lt;/code&gt; but not &lt;code&gt;/bar/foo&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;10x&lt;/strong&gt; times faster than &lt;strong&gt;fasd&lt;/strong&gt; and &lt;strong&gt;autojump&lt;/strong&gt;, &lt;strong&gt;3x&lt;/strong&gt; times faster than &lt;strong&gt;z.sh&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Available for &lt;strong&gt;posix shells&lt;/strong&gt;: bash, zsh, dash, sh, ash, ksh, busybox and etc.&lt;/li&gt;
&lt;li&gt;Available for Fish Shell, Power Shell and Windows cmd.&lt;/li&gt;
&lt;li&gt;&lt;a href="#enhanced-matching"&gt;Enhanced matching algorithm&lt;/a&gt; takes you to where ever you want precisely.&lt;/li&gt;
&lt;li&gt;Allow updating database only if &lt;code&gt;$PWD&lt;/code&gt; changed with "$_ZL_ADD_ONCE" set to 1.&lt;/li&gt;
&lt;li&gt;Interactive selection enables you to choose where to go before cd.&lt;/li&gt;
&lt;li&gt;Intergrated with FZF (optional) for interactive selection and completion.&lt;/li&gt;
&lt;li&gt;Quickly go back to a parent directory instead of typing "cd ../../..".&lt;/li&gt;
&lt;li&gt;Corresponding experience in different shells and operating systems.&lt;/li&gt;
&lt;li&gt;Compatible with Lua 5.1, 5.2 and 5.3+&lt;/li&gt;
&lt;li&gt;Self contained, distributed as a single &lt;code&gt;z.lua&lt;/code&gt; script, no other dependence.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;z foo       &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; cd to most frecent dir matching foo&lt;/span&gt;
z foo bar   &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; cd to most frecent dir matching foo and bar&lt;/span&gt;
z -r foo    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; cd to the highest ranked dir matching foo&lt;/span&gt;
z -t foo    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; cd to most recently accessed dir matching foo&lt;/span&gt;
z -l foo    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; list matches instead of cd&lt;/span&gt;
z -c foo    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; restrict matches to subdirs of $PWD&lt;/span&gt;
z -e foo    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; echo the best match, don't cd&lt;/span&gt;
z -i foo    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; cd with interactive selection&lt;/span&gt;
z -I foo    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; cd with interactive selection using fzf&lt;/span&gt;
z -b foo    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; cd to the parent directory starting with foo&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-install" class="anchor" aria-hidden="true" href="#install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Bash:&lt;/p&gt;
&lt;p&gt;put something like this in your &lt;code&gt;.bashrc&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;eval "$(lua /path/to/z.lua --init bash)"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the default matching algorithm is similar to z.sh to keep compatible, you may like the enhanced matching algorithm for productivity:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;eval "$(lua /path/to/z.lua --init bash enhanced once)"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and perhaps this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export _ZL_ECHO=1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;if you want &lt;code&gt;z.lua&lt;/code&gt; print the new directory after cd.&lt;/p&gt;
&lt;p&gt;If you want &lt;code&gt;fzf&lt;/code&gt; tab completion use:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;eval "$(lua /path/to/z.lua --init bash enhanced once fzf)"
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Zsh:&lt;/p&gt;
&lt;p&gt;put something like this in your &lt;code&gt;.zshrc&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;eval "$(lua /path/to/z.lua --init zsh)"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Options like "enhanced" and "once" can be used after &lt;code&gt;--init&lt;/code&gt; too. It can also be initialized from "skywind3000/z.lua" with your zsh plugin managers (antigen / oh-my-zsh).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Posix Shells:&lt;/p&gt;
&lt;p&gt;put something like this in your &lt;code&gt;.profile&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;eval "$(lua /path/to/z.lua --init posix)"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For old shells like ksh (Korn Shell), some features are missing, you can try:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;eval "$(lua /path/to/z.lua --init posix legacy)"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To generate old posix compatible script.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fish Shell:&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;~/.config/fish/conf.d/z.fish&lt;/code&gt; with following code&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;source (lua /path/to/z.lua --init fish | psub)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fish version &lt;code&gt;2.4.0&lt;/code&gt; or above is required.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lua /path/to/z.lua --init fish &amp;gt; ~/.config/fish/conf.d/z.fish
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is another way to initialize z.lua in fish shell, but remember to regenerate z.fish if z.lua has been updated or moved.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Power Shell:&lt;/p&gt;
&lt;p&gt;put something like this in your &lt;code&gt;profile.ps1&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;iex ($(lua /path/to/z.lua --init powershell) -join "`n") 
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Windows cmd (with clink):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;copy z.lua and z.cmd to clink's home directory&lt;/li&gt;
&lt;li&gt;Add clink's home to &lt;code&gt;%PATH%&lt;/code&gt; (z.cmd can be called anywhere)&lt;/li&gt;
&lt;li&gt;Ensure that "lua" can be called in &lt;code&gt;%PATH%&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Windows cmder:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;copy z.lua and z.cmd to cmder/vendor&lt;/li&gt;
&lt;li&gt;Add cmder/vendor to &lt;code&gt;%PATH%&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Ensure that "lua" can be called in &lt;code&gt;%PATH%&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-options" class="anchor" aria-hidden="true" href="#options"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Options&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;set &lt;code&gt;$_ZL_CMD&lt;/code&gt; in .bashrc/.zshrc to change the command (default z).&lt;/li&gt;
&lt;li&gt;set &lt;code&gt;$_ZL_DATA&lt;/code&gt; in .bashrc/.zshrc to change the datafile (default ~/.zlua).&lt;/li&gt;
&lt;li&gt;set &lt;code&gt;$_ZL_NO_PROMPT_COMMAND&lt;/code&gt; if you're handling PROMPT_COMMAND yourself.&lt;/li&gt;
&lt;li&gt;set &lt;code&gt;$_ZL_EXCLUDE_DIRS&lt;/code&gt; to a comma separated list of dirs to exclude.&lt;/li&gt;
&lt;li&gt;set &lt;code&gt;$_ZL_ADD_ONCE&lt;/code&gt; to '1' to update database only if &lt;code&gt;$PWD&lt;/code&gt; changed.&lt;/li&gt;
&lt;li&gt;set &lt;code&gt;$_ZL_MAXAGE&lt;/code&gt; to define a aging threshold (default is 5000).&lt;/li&gt;
&lt;li&gt;set &lt;code&gt;$_ZL_CD&lt;/code&gt; to specify your own cd command.&lt;/li&gt;
&lt;li&gt;set &lt;code&gt;$_ZL_ECHO&lt;/code&gt; to 1 to display new directory name after cd.&lt;/li&gt;
&lt;li&gt;set &lt;code&gt;$_ZL_MATCH_MODE&lt;/code&gt; to 1 to enable enhanced matching.&lt;/li&gt;
&lt;li&gt;set &lt;code&gt;$_ZL_NO_CHECK&lt;/code&gt; to 1 to disable path validation, use &lt;code&gt;z --purge&lt;/code&gt; to clean&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-aging" class="anchor" aria-hidden="true" href="#aging"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Aging&lt;/h2&gt;
&lt;p&gt;The rank of directories maintained by z.lua undergoes aging based on a simple formula. The rank of each entry is incremented  every  time  it  is accessed.  When the sum of ranks is over 5000 (&lt;code&gt;$_ZL_MAXAGE&lt;/code&gt;), all ranks are multiplied by 0.9. Entries with a rank lower than 1 are forgotten.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-frecency" class="anchor" aria-hidden="true" href="#frecency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Frecency&lt;/h2&gt;
&lt;p&gt;Frecency is a portmanteau of 'recent' and 'frequency'. It is a weighted rank that depends on how often and how recently something occurred. As far as I know, Mozilla came up with the term.&lt;/p&gt;
&lt;p&gt;To z.lua, a directory that has low ranking but has been accessed recently will quickly  have higher rank than a directory accessed frequently a long time ago. Frecency is determined at runtime.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-default-matching" class="anchor" aria-hidden="true" href="#default-matching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Default Matching&lt;/h2&gt;
&lt;p&gt;By default, z.lua uses default matching algorithm similar to the original z.sh. Paths must be match all of the regexes in order.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;cd to a directory contains foo:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;z foo
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cd to a directory ends with foo:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;z foo$
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;use multiple arguments:&lt;/p&gt;
&lt;p&gt;Assuming the following database:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;10   /home/user/work/inbox
30   /home/user/mail/inbox
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;"z in"&lt;/code&gt; would cd into &lt;code&gt;/home/user/mail/inbox&lt;/code&gt; as the higher weighted entry. However you can pass multiple arguments to z.lua to prefer a different entry. In the above example, &lt;code&gt;"z w in"&lt;/code&gt; would then change directory to &lt;code&gt;/home/user/work/inbox&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-enhanced-matching" class="anchor" aria-hidden="true" href="#enhanced-matching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Enhanced Matching&lt;/h2&gt;
&lt;p&gt;Enhanced matching can be enabled by exporting the environment:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; _ZL_MATCH_MODE=1&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or, append a &lt;code&gt;enhanced&lt;/code&gt; after &lt;code&gt;--init xxx&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;eval&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;lua /path/to/z.lua --init bash enhanced&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For a given set of queries (the set of command-line arguments passed to z.lua), a path is a match if and only if:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Queries match the path in order (same as default method).&lt;/li&gt;
&lt;li&gt;The last query matches the last segment of the path.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If no match is found, it will fall back to default matching method.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;match the last segment of the path:&lt;/p&gt;
&lt;p&gt;Assuming the following database:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;10   /home/user/workspace
20   /home/user/workspace/project1
30   /home/user/workspace/project2
40   /home/user/workspace/project3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you use &lt;code&gt;"z wo"&lt;/code&gt; in enhanced matching mode, only the &lt;code&gt;/home/user/work&lt;/code&gt; will be matched, because according to rule No.2 it is the only path whose last segment matches &lt;code&gt;"wo"&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Since the last segment of a path is always easier to be recalled, it is sane to give it higher priority. You can also achieve this by typing &lt;code&gt;"z space$"&lt;/code&gt; in both methods, but &lt;code&gt;"z wo"&lt;/code&gt; is easier to type.&lt;/p&gt;
&lt;p&gt;Tips for rule No.2:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you want your last query &lt;strong&gt;not only&lt;/strong&gt; to match the last segment of the path, append '$' as the last query. eg. &lt;code&gt;"z wo $"&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If you want your last query &lt;strong&gt;not&lt;/strong&gt; to match the last segment of the path, append '/' as the last query. eg. &lt;code&gt;"z wo /"&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cd to the existent path if there is no match:&lt;/p&gt;
&lt;p&gt;Sometimes if you use:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;z foo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And there is no matching result in the database, but there is an existent directory which can be accessed with the name "foo" from current directory, "&lt;code&gt;z foo&lt;/code&gt;" will just work as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd foo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, in the enhanced matching method, you can always use &lt;code&gt;z&lt;/code&gt; like &lt;code&gt;cd&lt;/code&gt; to change directory even if the new directory is untracked (hasn't been accessed).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Skip the current directory:&lt;/p&gt;
&lt;p&gt;When you are calling &lt;code&gt;z xxx&lt;/code&gt; but the best match is the current directory, z.lua will choose the 2nd best match result for you. Assuming the database:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;10   /Users/Great_Wall/.rbenv/versions/2.4.1/lib/ruby/gems
20   /Library/Ruby/Gems/2.0.0/gems
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When I use &lt;code&gt;z gems&lt;/code&gt; by default, it will take me to &lt;code&gt;/Library/Ruby/Gems/2.0.0/gems&lt;/code&gt;, but it's not what I want, so I press up arrow and execute &lt;code&gt;z gems&lt;/code&gt; again, it will take me to &lt;code&gt;/Users/Great_Wall/.rbenv/versions/2.4.1/lib/ruby/gems&lt;/code&gt; and this what I want.&lt;/p&gt;
&lt;p&gt;Of course, I can always use &lt;code&gt;z env gems&lt;/code&gt; to indicate what I want precisely. Skip the current directory means when you use &lt;code&gt;z xxx&lt;/code&gt; you always want to change directory instead of stay in the same directory and do nothing if current directory is the best match.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The default matching method is designed to be compatible with original z.sh, but the enhanced matching method is much more handy and exclusive to z.lua.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-add-once" class="anchor" aria-hidden="true" href="#add-once"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Add Once&lt;/h2&gt;
&lt;p&gt;By default, z.lua will add current directory to database each time before display command prompt (correspond with z.sh). But there is an option to allow z.lua add path only if current working directory changed.&lt;/p&gt;
&lt;p&gt;To enable this, you can set &lt;code&gt;$_ZL_ADD_ONCE&lt;/code&gt; to &lt;code&gt;1&lt;/code&gt; before init z.lua. Or you can initialize z.lua on linux like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;eval&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;lua /path/to/z.lua --init bash once&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c1"&gt;eval&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;lua /path/to/z.lua --init zsh once&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c1"&gt;source&lt;/span&gt; (lua /path/to/z.lua --init fish once &lt;span class="pl-k"&gt;|&lt;/span&gt; psub)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With &lt;code&gt;add once&lt;/code&gt; mode off (default), z.lua will consider the time you spent in the directory (like z.sh). When this mode is on, consider the times you accessed the directory (like autojump), and that could be much faster on slow hardware.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-interactive-selection" class="anchor" aria-hidden="true" href="#interactive-selection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive Selection&lt;/h2&gt;
&lt;p&gt;When there are multiple matches found, using &lt;code&gt;z -i&lt;/code&gt; will display a list:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ z -i soft
3:  0.25        /home/data/software
2:  3.75        /home/skywind/tmp/comma/software
1:  21          /home/skywind/software
&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; {CURSOR}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And then you can input the number and choose where to go before actual cd. eg. input 3 to cd to &lt;code&gt;/home/data/software&lt;/code&gt;. And if you just press ENTER and input nothing, it will just quit and stay where you were.&lt;/p&gt;
&lt;p&gt;NOTE: for fish shell, this feature requires fish 2.7.0 or above.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-fzf-supports" class="anchor" aria-hidden="true" href="#fzf-supports"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FZF Supports&lt;/h2&gt;
&lt;p&gt;From version 1.1.0, a new option &lt;code&gt;"-I"&lt;/code&gt; will allow you to use fzf to select when there are multiple matches.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/fzf.png"&gt;&lt;img src="images/fzf.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When we use &lt;code&gt;"z -I vim"&lt;/code&gt;，12 paths contains keyword "vim" has been matched and ordered by their frecent value, the higher frecent comes with the higher rank. Then without cd to the highest ranked path, z.lua passes all the candidates to fzf.&lt;/p&gt;
&lt;p&gt;Now you can input some space separated keywords (no order required) or use &lt;code&gt;CTRL+J&lt;/code&gt;/&lt;code&gt;CTRL+K&lt;/code&gt; (same as &lt;code&gt;UP&lt;/code&gt;/&lt;code&gt;DOWN&lt;/code&gt;) to select where you want to go, or &lt;code&gt;ESC&lt;/code&gt; / &lt;code&gt;CTRL&lt;/code&gt;+&lt;code&gt;D&lt;/code&gt;/&lt;code&gt;G&lt;/code&gt; to give up.&lt;/p&gt;
&lt;p&gt;Of course, you can always give more keywords to &lt;code&gt;z&lt;/code&gt; command to match your destination precisely. &lt;code&gt;"z -I"&lt;/code&gt; is similar to &lt;code&gt;"z -i"&lt;/code&gt;, but use fzf. Both &lt;code&gt;"-i"&lt;/code&gt; and &lt;code&gt;"-I"&lt;/code&gt; provide you another way for path navigation.&lt;/p&gt;
&lt;p&gt;Usually, &lt;code&gt;z -I&lt;/code&gt; can be aliased to &lt;code&gt;zf&lt;/code&gt; (z + fuzzy finder) for convenience. If there are only one path matched, &lt;code&gt;z -I&lt;/code&gt; will jump to it directly, fzf will only be invoked for multiple matches. &lt;code&gt;"z -I ."&lt;/code&gt; or &lt;code&gt;"zf ."&lt;/code&gt; can be used to use fzf select from entire database.&lt;/p&gt;
&lt;p&gt;For more information about this, please visit &lt;a href="https://github.com/skywind3000/z.lua/wiki/Effective-with-fzf"&gt;wiki - effective with fzf&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;NOTE: For fish shell, this feature requires fish 2.7.0 or above. You can specify fzf executable in &lt;code&gt;$_ZL_FZF&lt;/code&gt; environment variable, &lt;code&gt;"fzf"&lt;/code&gt; will be called by default.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-jump-backwards" class="anchor" aria-hidden="true" href="#jump-backwards"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Jump Backwards&lt;/h2&gt;
&lt;p&gt;New option &lt;code&gt;"-b"&lt;/code&gt; can quickly go back to a specific parent directory in bash instead of typing "cd ../../.." redundantly.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;(No argument)&lt;/strong&gt;: &lt;code&gt;cd&lt;/code&gt; into the project root, the project root the nearest parent directory with &lt;code&gt;.git&lt;/code&gt;/&lt;code&gt;.hg&lt;/code&gt;/&lt;code&gt;.svn&lt;/code&gt; in it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(One argument)&lt;/strong&gt;: &lt;code&gt;cd&lt;/code&gt; into the closest parent starting with keyword, if not find, go to the parent containing keyword.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(Two arguments)&lt;/strong&gt;: replace the first value with the second one (in the current path).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's start by aliasing &lt;code&gt;z -b&lt;/code&gt; to &lt;code&gt;zb&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; go all the way up to the project root (in this case, the one that has .git in it)&lt;/span&gt;
&lt;span class="pl-k"&gt;~&lt;/span&gt;/github/lorem/src/public$ zb
  =&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;cd&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/github/lorem

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; cd into to the first parent directory named g*&lt;/span&gt;
&lt;span class="pl-k"&gt;~&lt;/span&gt;/github/vimium/src/public$ zb g
  =&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;cd&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/github

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; goto the site directory quickly&lt;/span&gt;
&lt;span class="pl-k"&gt;~&lt;/span&gt;/github/demo/src/org/main/site/utils/file/reader/whatever$ zb si
  =&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;cd&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/github/demo/src/org/main/site

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; substitute jekyll with ghost&lt;/span&gt;
&lt;span class="pl-k"&gt;~&lt;/span&gt;/github/jekyll/test$ zb jekyll ghost
  =&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;cd&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/github/ghost/test&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Backward jumping can also be used with &lt;code&gt;$_ZL_ECHO&lt;/code&gt; option (echo $PWD after cd), which makes it possible to combine them with other tools without actually changing the working directory (eg. &lt;code&gt;ls `zb git` &lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Environment variable &lt;code&gt;$_ZL_ROOT_MARKERS&lt;/code&gt; is a comma separated list for project root locating, and can be redefined as:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; _ZL_ROOT_MARKERS=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;.git,.svn,.hg,.root,package.json&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you want &lt;code&gt;zb&lt;/code&gt; jump back to a parent directory contains a &lt;code&gt;.root&lt;/code&gt; or &lt;code&gt;package.json&lt;/code&gt; in it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bonus&lt;/strong&gt;: &lt;code&gt;zb ..&lt;/code&gt; equals to &lt;code&gt;cd ..&lt;/code&gt;, &lt;code&gt;zb ...&lt;/code&gt; equals to &lt;code&gt;cd ../..&lt;/code&gt; and &lt;code&gt;zb ....&lt;/code&gt; equals to &lt;code&gt;cd ../../..&lt;/code&gt;, and so on. Finally, &lt;code&gt;zb ..20&lt;/code&gt; equals to &lt;code&gt;cd (..)x20&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-completion" class="anchor" aria-hidden="true" href="#completion"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Completion&lt;/h2&gt;
&lt;p&gt;For zsh/fish, completion can be triggered by &lt;code&gt;z foo&amp;lt;tab&amp;gt;&lt;/code&gt;. and a list of candidates will display in zsh / fish:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/complete-1.png"&gt;&lt;img src="images/complete-1.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Press &lt;code&gt;&amp;lt;tab&amp;gt;&lt;/code&gt; again, you can select your destination in a visualized way.&lt;/p&gt;
&lt;p&gt;Bash is not as powerful as zsh/fish, so we introduced fzf-completion for bash, initialize your z.lua and append &lt;code&gt;fzf&lt;/code&gt; keyword after &lt;code&gt;--init&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;eval&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;lua /path/to/z.lua --init bash enhanced once &lt;span class="pl-c1"&gt;echo&lt;/span&gt; fzf&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then press &lt;code&gt;&amp;lt;tab&amp;gt;&lt;/code&gt; after &lt;code&gt;z xxx&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/complete-2.png"&gt;&lt;img src="images/complete-2.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;With the help of fzf, completion in bash is much easier now.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;z.lua&lt;/code&gt; can cooperate with &lt;a href="https://github.com/changyuheng/fz"&gt;fz&lt;/a&gt; for &lt;strong&gt;better completion&lt;/strong&gt; result in both bash and zsh, for more information see &lt;a href="https://github.com/skywind3000/z.lua/wiki/FAQ#fzsh-for-better-completion"&gt;FAQ&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;NOTE: To enable this, command &lt;code&gt;fzf&lt;/code&gt; must be found in &lt;code&gt;$PATH&lt;/code&gt; before initialization.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-most-recently-accessed-path" class="anchor" aria-hidden="true" href="#most-recently-accessed-path"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Most Recently Accessed Path&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;z.lua&lt;/code&gt; provides a fast way to visit MRU directories without typing any keyword. That is &lt;code&gt;dirstack&lt;/code&gt;, which records recently visited paths and can be manipulated by &lt;code&gt;z -&lt;/code&gt;, &lt;code&gt;z --&lt;/code&gt; and &lt;code&gt;z -{num}&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; display current dir stack&lt;/span&gt;
$ z --    
 0  /home/skywind/work/match/memory-match
 1  /home/skywind/.local/etc
 2  /home/skywind/software/vifm-0.9.1
 3  /home/skywind/work
 4  /home/skywind/work/match

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; cd to the 2nd directory in the stack&lt;/span&gt;
$ z -2
  =&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;cd&lt;/span&gt; /home/skywind/software/vifm-0.9.1

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; popup stacktop (cd to previous directory), same as "z -0"&lt;/span&gt;
$ z -
  =&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;cd&lt;/span&gt; -&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;dirstack&lt;/code&gt; is calculated from z.lua's database, and has no dependency on shells or systems. You will not lost records after re-login, and history can be shared across shells and sessions.&lt;/p&gt;
&lt;p&gt;There is another way to access MRU directories interactively by utilizing parameter &lt;code&gt;-I&lt;/code&gt; (fzf) and &lt;code&gt;-t&lt;/code&gt; (sort by time):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;alias&lt;/span&gt; zh=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;z -I -t .&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The new alias &lt;code&gt;zh&lt;/code&gt; (jump to history) is very easy to input:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/mru.png"&gt;&lt;img src="images/mru.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The first column indicates how many seconds ago you have visited, and the second column is the path name. With &lt;code&gt;zh&lt;/code&gt;, you can type some character to use string matching in fzf, or use &lt;code&gt;&amp;lt;Up&amp;gt;&lt;/code&gt;/&lt;code&gt;&amp;lt;Down&amp;gt;&lt;/code&gt; (as well as &lt;code&gt;CTRL+j/k&lt;/code&gt;) to move the selector (red &lt;code&gt;&amp;gt;&lt;/code&gt;) up and down.&lt;/p&gt;
&lt;p&gt;At last, press &lt;code&gt;&amp;lt;enter&amp;gt;&lt;/code&gt; to accept or &lt;code&gt;&amp;lt;ESC&amp;gt;&lt;/code&gt; to give up.&lt;/p&gt;
&lt;p&gt;Remember to enable the &lt;a href="#enhanced-matching"&gt;enhanced matching&lt;/a&gt; algorithm, the current working directory can be skipped with it.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tips" class="anchor" aria-hidden="true" href="#tips"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tips&lt;/h2&gt;
&lt;p&gt;Recommended aliases you may find useful:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;alias&lt;/span&gt; zz=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;z -c&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;      &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; restrict matches to subdirs of $PWD&lt;/span&gt;
&lt;span class="pl-c1"&gt;alias&lt;/span&gt; zi=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;z -i&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;      &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; cd with interactive selection&lt;/span&gt;
&lt;span class="pl-c1"&gt;alias&lt;/span&gt; zf=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;z -I&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;      &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; use fzf to select in multiple matches&lt;/span&gt;
&lt;span class="pl-c1"&gt;alias&lt;/span&gt; zb=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;z -b&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;      &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; quickly cd to the parent directory&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Import data from z.sh：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;cat &lt;span class="pl-k"&gt;~&lt;/span&gt;/.z &lt;span class="pl-k"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/.zlua&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Import data from autojump：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;FN=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;$HOME&lt;/span&gt;/.local/share/autojump/autojump.txt&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
awk -F &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;\t&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;{print $2 "|" $1 "|" 0}&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-smi"&gt;$FN&lt;/span&gt; &lt;span class="pl-k"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/.zlua&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Don't forget to read the &lt;a href="https://github.com/skywind3000/z.lua/wiki/FAQ"&gt;Frequently Asked Questions&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-benchmark" class="anchor" aria-hidden="true" href="#benchmark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Benchmark&lt;/h2&gt;
&lt;p&gt;The slowest part is adding path to history data file. It will run every time when you press enter (installed in $PROMPT_COMMAND). So I profile it on my NAS:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ &lt;span class="pl-k"&gt;time&lt;/span&gt; autojump --add /tmp
real    0m0.352s
user    0m0.077s
sys     0m0.185s

$ &lt;span class="pl-k"&gt;time&lt;/span&gt; fasd -A /tmp
real    0m0.618s
user    0m0.076s
sys     0m0.242s

$ &lt;span class="pl-k"&gt;time&lt;/span&gt; _z --add /tmp
real    0m0.194s
user    0m0.046s
sys     0m0.154s

$ &lt;span class="pl-k"&gt;time&lt;/span&gt; _zlua --add /tmp
real    0m0.052s
user    0m0.015s
sys     0m0.030s&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you see, z.lua is the fastest one and requires less resource.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-reputation" class="anchor" aria-hidden="true" href="#reputation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reputation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;"I like this in principal. I’m pretty damn predictable at the command line and far too lazy to make shortcuts"&lt;/li&gt;
&lt;li&gt;"It feels far more intuitive and it's so incredibly convenient to be able to jump between folders I'm working in without having to traverse an entire tree. The shell used to feel so constraining for me, but tools like this are making me enjoy it so much more. "&lt;/li&gt;
&lt;li&gt;"I can finally have autojump-like functionality on my Raspberry Pi 1 without waiting 30 seconds every time I open a new shell. Thanks z.lua devs."&lt;/li&gt;
&lt;li&gt;"Anyway, z.lua is a promising project. If you only need directory jumping, it may be the best choice."&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-history" class="anchor" aria-hidden="true" href="#history"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;History&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;1.7.3 (2019-09-07): use &lt;a href="http://keplerproject.github.io/luafilesystem/" rel="nofollow"&gt;lua-filesystem&lt;/a&gt; package if possible when &lt;code&gt;$_ZL_USE_LFS&lt;/code&gt; is &lt;code&gt;1&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;1.7.2 (2019-08-01): Improve bash/zsh shell compatibility by &lt;a href="https://github.com/barlik"&gt;@barlik&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;1.7.1 (2019-06-07): Fixed: &lt;code&gt;$_ZL_DATA&lt;/code&gt; failure on Linux sometimes.&lt;/li&gt;
&lt;li&gt;1.7.0 (2019-03-09): Support &lt;a href="https://github.com/skywind3000/z.lua/wiki/FAQ#how-to-integrate-zlua-to-ranger-"&gt;ranger&lt;/a&gt;, fix ReplaceFile issue in luajit (windows).&lt;/li&gt;
&lt;li&gt;1.6.0 (2019-03-04): optimize with ffi module (luajit builtin module).&lt;/li&gt;
&lt;li&gt;1.5.11 (2019-03-02): fixed: os.path.isdir doesn't work for symbol link folders.&lt;/li&gt;
&lt;li&gt;1.5.10 (2019-03-01): Prevent writing file racing.&lt;/li&gt;
&lt;li&gt;1.5.9 (2019-02-25): &lt;code&gt;z -b&lt;/code&gt; should not match current directory (close #56).&lt;/li&gt;
&lt;li&gt;1.5.8 (2019-02-21): new &lt;code&gt;$_ZL_FZF_HEIGHT&lt;/code&gt; to control &lt;code&gt;--height&lt;/code&gt; parameter in fzf.&lt;/li&gt;
&lt;li&gt;1.5.7 (2019-02-21): rename &lt;code&gt;$_ZL_FZF_SORT&lt;/code&gt; to &lt;code&gt;$_ZL_INT_SORT&lt;/code&gt; it will affect both &lt;code&gt;-i&lt;/code&gt; and &lt;code&gt;-I&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;1.5.6 (2019-02-20): set &lt;code&gt;$_ZL_FZF_SORT&lt;/code&gt; to 1 to sort directories by alphabet in fzf.&lt;/li&gt;
&lt;li&gt;1.5.5 (2019-02-20): &lt;code&gt;$_ZL_FZF_FLAG&lt;/code&gt; can be used to override fzf flags, default to "+s -e".&lt;/li&gt;
&lt;li&gt;1.5.4 (2019-02-19): fixed: file/path existence detection fails on read-only fs (closed &lt;a href="https://github.com/skywind3000/z.lua/issues/49"&gt;#49&lt;/a&gt; by &lt;a href="https://github.com/contrun"&gt;@contrun&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;1.5.3 (2019-02-17): new &lt;code&gt;$_ZL_FZF_FLAG&lt;/code&gt; for passing additional flags to fzf, add &lt;code&gt;-e&lt;/code&gt; argument to fzf.&lt;/li&gt;
&lt;li&gt;1.5.2 (2019-02-16): be aware of all arguments in fzf completion.&lt;/li&gt;
&lt;li&gt;1.5.1 (2019-02-15): new: simulated dir stack by &lt;code&gt;z -&lt;/code&gt;, &lt;code&gt;z --&lt;/code&gt; and &lt;code&gt;z -{num}&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;1.5.0 (2019-02-14): fixed minor issues in backward jumping.&lt;/li&gt;
&lt;li&gt;1.4.7 (2019-02-13): Don't use regex in backward jumping (use plain text instead).&lt;/li&gt;
&lt;li&gt;1.4.6 (2019-02-12): change: &lt;code&gt;_ZL_EXCLUDE_DIRS&lt;/code&gt; to a comma separated list of dirs to exclude.&lt;/li&gt;
&lt;li&gt;1.4.5 (2019-02-10): improve bash fzf completion and posix compatibility.&lt;/li&gt;
&lt;li&gt;1.4.4 (2019-02-10): supports legacy posix shells like ksh, init with &lt;code&gt;z.lua --init posix legacy&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;1.4.3 (2019-02-08): fixed minor issues.&lt;/li&gt;
&lt;li&gt;1.4.2 (2019-02-06): you can disabled path validation by &lt;code&gt;$_ZL_NO_CHECK&lt;/code&gt;, and use &lt;code&gt;z --purge&lt;/code&gt; to clear bad paths manually.&lt;/li&gt;
&lt;li&gt;1.4.1 (2019-02-06): fzf tab-completion in bash (&lt;a href="https://github.com/BarbUk"&gt;@BarbUk&lt;/a&gt;), fixed hang in fish shell (close &lt;a href="https://github.com/skywind3000/z.lua/issues/29"&gt;#29&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;1.4.0 (2019-02-04): Ported to Power Shell (&lt;a href="https://github.com/manhong2112"&gt;@manhong2112&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;1.3.0 (2019-02-04): Backward jumping, prevent "cd ../../.." repeatly.&lt;/li&gt;
&lt;li&gt;1.2.0 (2019-02-03): Upgrade string lib and path lib.&lt;/li&gt;
&lt;li&gt;1.1.0 (2019-02-02): New option '-I' to use fzf to select from multiple matches.&lt;/li&gt;
&lt;li&gt;1.0.0 (2019-02-01): Fixed minor issues and make it stable.&lt;/li&gt;
&lt;li&gt;0.5.0 (2019-01-21): Ported to Fish Shell (&lt;a href="https://github.com/TeddyDD"&gt;@TeddyDD&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;0.4.1 (2019-01-20): Don't return failed exit code when $_ZL_ECHO is unbind (Mario Rodas).&lt;/li&gt;
&lt;li&gt;0.4.0 (2019-01-17): new enhanced matching algorithm，can be enabled by appending &lt;code&gt;enhanced&lt;/code&gt; keyword after &lt;code&gt;--init&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;0.3.0 (2018-12-26): new option &lt;code&gt;-i&lt;/code&gt; to enable interactive selection.&lt;/li&gt;
&lt;li&gt;0.2.0 (2018-11-25): new option &lt;code&gt;$_ZL_ADD_ONCE&lt;/code&gt; to enable updating datafile only if &lt;code&gt;$PWD&lt;/code&gt; changed.&lt;/li&gt;
&lt;li&gt;0.1.0 (2018-04-30): supports windows cmd, cmder and conemu.&lt;/li&gt;
&lt;li&gt;0.0.0 (2018-03-21): initial commit, compatible with original z.sh.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-help" class="anchor" aria-hidden="true" href="#help"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Help&lt;/h2&gt;
&lt;p&gt;This project needs help for the tasks below:&lt;/p&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Support csh/tcsh.&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Completion: Actually I got little knowledge in completion, and need help to improve it.&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Completion: Implement completion for Power Shell.&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Completion: Implement completion for different arguments.&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Packaging: make it possible to be installed easily in different systems or popular plugin managers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-thanks" class="anchor" aria-hidden="true" href="#thanks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Thanks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Thanks to &lt;a href="https://github.com/rupa"&gt;@rupa&lt;/a&gt; for inspiring me to start this project.&lt;/li&gt;
&lt;li&gt;Thanks to &lt;a href="https://github.com/vigneshwaranr"&gt;@vigneshwaranr&lt;/a&gt; and &lt;a href="https://github.com/shyiko"&gt;@shyiko&lt;/a&gt; for inspiring me the backward jumping.&lt;/li&gt;
&lt;li&gt;Thanks to &lt;a href="https://github.com/TeddyDD"&gt;@TeddyDD&lt;/a&gt; for Fish Shell porting.&lt;/li&gt;
&lt;li&gt;Thanks to &lt;a href="https://github.com/manhong2112"&gt;@manhong2112&lt;/a&gt; for Power Shell porting.&lt;/li&gt;
&lt;li&gt;Thanks to &lt;a href="https://github.com/BarbUk"&gt;@BarbUk&lt;/a&gt; for fzf completion in Bash.&lt;/li&gt;
&lt;li&gt;Thanks to &lt;a href="https://github.com/barlik"&gt;@barlik&lt;/a&gt; for many improvements.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And many others.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Licensed under MIT license.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>skywind3000</author><guid isPermaLink="false">https://github.com/skywind3000/z.lua</guid><pubDate>Fri, 08 Nov 2019 00:10:00 GMT</pubDate></item><item><title>Stephan-S/FS19_AutoDrive #11 in Lua, This month</title><link>https://github.com/Stephan-S/FS19_AutoDrive</link><description>&lt;p&gt;&lt;i&gt;FS19 version of AutoDrive - Developer Version&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-fs19_autodrive" class="anchor" aria-hidden="true" href="#fs19_autodrive"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FS19_AutoDrive&lt;/h1&gt;
&lt;p&gt;FS19 version of AutoDrive&lt;/p&gt;
&lt;p&gt;If you want to support my development effort, the best way is to open issues on any bugs you encounter or for features you would like to be added to the mod.&lt;/p&gt;
&lt;p&gt;Wer die Weiterentwicklung des Mods unterstützen möchte, kann dies am Besten durch fleißiges Erstellen von Issues zu gefundenen Bugs und/oder gewünschten Erweiterungen zum Mod tun.&lt;/p&gt;
&lt;p&gt;If you like my work, feel free to buy me a coffee (of which I drink quite a lot :D )
&lt;a href="https://www.buymeacoffee.com/9Di7EUSI2" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/031fc5a134cdca5ae3460822aba371e63f794233/68747470733a2f2f7777772e6275796d6561636f666665652e636f6d2f6173736574732f696d672f637573746f6d5f696d616765732f6f72616e67655f696d672e706e67" alt="Buy Me A Coffee" data-canonical-src="https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.paypal.me/StephanSchlosser" rel="nofollow"&gt;https://www.paypal.me/StephanSchlosser&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Stephan-S</author><guid isPermaLink="false">https://github.com/Stephan-S/FS19_AutoDrive</guid><pubDate>Fri, 08 Nov 2019 00:11:00 GMT</pubDate></item><item><title>lcpz/awesome-copycats #12 in Lua, This month</title><link>https://github.com/lcpz/awesome-copycats</link><description>&lt;p&gt;&lt;i&gt;Awesome WM themes&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body rst" data-path="README.rst"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;a name="user-content-awesome-wm-copycats"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-awesome-wm-copycats" class="anchor" aria-hidden="true" href="#awesome-wm-copycats"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Awesome WM Copycats&lt;/h2&gt;
&lt;a name="user-content-themes-for-awesome-wm-4-x"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-themes-for-awesome-wm-4x" class="anchor" aria-hidden="true" href="#themes-for-awesome-wm-4x"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Themes for Awesome WM 4.x&lt;/h3&gt;
&lt;table frame="void" rules="none"&gt;


&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;th&gt;Author:&lt;/th&gt;&lt;td&gt;Luca CPZ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;th&gt;Version:&lt;/th&gt;&lt;td&gt;git&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;th&gt;License:&lt;/th&gt;&lt;td&gt;&lt;a href="http://creativecommons.org/licenses/by-nc-sa/4.0" rel="nofollow"&gt;BY-NC-SA&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;th&gt;Source:&lt;/th&gt;&lt;td&gt;&lt;a href="https://github.com/lcpz/awesome-copycats"&gt;https://github.com/lcpz/awesome-copycats&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;a name="user-content-description"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-description" class="anchor" aria-hidden="true" href="#description"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Description&lt;/h2&gt;
&lt;p&gt;A set of themes for the &lt;a href="http://github.com/awesomeWM/awesome"&gt;Awesome&lt;/a&gt; window manager, version 4.x.&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://github.com/lcpz/awesome-copycats/branches"&gt;branches&lt;/a&gt; for previous versions.&lt;/p&gt;
&lt;a name="user-content-purpose"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-purpose" class="anchor" aria-hidden="true" href="#purpose"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Purpose&lt;/h2&gt;
&lt;p&gt;The main purpose of this repository is to spread ready to use configurations, which can also serve as a cookbook for customisation.&lt;/p&gt;
&lt;p&gt;A secondary aim is to add new themes only when they constitute different UI/UX designs.&lt;/p&gt;
&lt;a name="user-content-features"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Modularity&lt;/li&gt;
&lt;li&gt;Autohide widgets&lt;/li&gt;
&lt;li&gt;Autostart windowless processes&lt;/li&gt;
&lt;li&gt;Fast MPD and volume shortcuts (first time this trick has been used in Awesome)&lt;/li&gt;
&lt;li&gt;Shortcuts for copying to the clipboard, toggle wiboxes, widgets popups, screenshots capture, moving and magnifying clients&lt;/li&gt;
&lt;li&gt;Quake drop-down terminal&lt;/li&gt;
&lt;li&gt;Calendar with current day highlighted and months switch with a click/scroll&lt;/li&gt;
&lt;li&gt;Notifications for new mails, current song, volume level, hdd critical state, low battery&lt;/li&gt;
&lt;li&gt;OpenWeatherMap integration&lt;/li&gt;
&lt;li&gt;Net carrier status notifier&lt;/li&gt;
&lt;li&gt;Symbolic tag names&lt;/li&gt;
&lt;li&gt;DWM-like textual layoutbox&lt;/li&gt;
&lt;li&gt;Cairo wibar&lt;/li&gt;
&lt;li&gt;Custom layouts&lt;/li&gt;
&lt;li&gt;No borders when there's only one visible client&lt;/li&gt;
&lt;li&gt;Freedesktop.org compliant menu and desktop icons&lt;/li&gt;
&lt;li&gt;Vi-like client focus&lt;/li&gt;
&lt;li&gt;Non-empty tag browsing&lt;/li&gt;
&lt;li&gt;On-the-fly useless gaps resize&lt;/li&gt;
&lt;li&gt;Dynamic tagging&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-gallery"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-gallery" class="anchor" aria-hidden="true" href="#gallery"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gallery&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Multicolor&lt;/strong&gt;, inspired by &lt;a href="https://github.com/lucamanni/awesome"&gt;lucamanni&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a530dae2a0d21167806a119281e85b739ecbf0fc/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3635302e706e67"&gt;&lt;img alt="http://dotshare.it/public/images/uploads/650.png" src="https://camo.githubusercontent.com/a530dae2a0d21167806a119281e85b739ecbf0fc/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3635302e706e67" data-canonical-src="http://dotshare.it/public/images/uploads/650.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Powerarrow&lt;/strong&gt;, porting of &lt;a href="https://github.com/romockee/powerarrow"&gt;romockee&lt;/a&gt;'s&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/f8a2d783ddd33ce79a236ae60239ea7807438955/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f313435332e706e67"&gt;&lt;img alt="http://dotshare.it/public/images/uploads/1453.png" src="https://camo.githubusercontent.com/f8a2d783ddd33ce79a236ae60239ea7807438955/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f313435332e706e67" data-canonical-src="http://dotshare.it/public/images/uploads/1453.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Powerarrow Dark&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/24cda4a3f2b1182eb856faf7dbb570723eb1edce/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3634392e6a7067"&gt;&lt;img alt="http://dotshare.it/public/images/uploads/649.jpg" src="https://camo.githubusercontent.com/24cda4a3f2b1182eb856faf7dbb570723eb1edce/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3634392e6a7067" data-canonical-src="http://dotshare.it/public/images/uploads/649.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Steamburn&lt;/strong&gt;, porting of &lt;a href="http://ok100.deviantart.com/art/DWM-January-2013-348656846" rel="nofollow"&gt;ok100&lt;/a&gt;'s dwm&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/c5e634a00b34160155d2f7c69b1cc8b72af441b8/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3634382e706e67"&gt;&lt;img alt="http://dotshare.it/public/images/uploads/648.png" src="https://camo.githubusercontent.com/c5e634a00b34160155d2f7c69b1cc8b72af441b8/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3634382e706e67" data-canonical-src="http://dotshare.it/public/images/uploads/648.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Blackburn&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/baad9ea0598f50e7c7edad3bf93810baf7b05651/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3535332e706e67"&gt;&lt;img alt="http://dotshare.it/public/images/uploads/553.png" src="https://camo.githubusercontent.com/baad9ea0598f50e7c7edad3bf93810baf7b05651/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3535332e706e67" data-canonical-src="http://dotshare.it/public/images/uploads/553.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dremora&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/4289372b4b4f6c4c9a5bbd34004cb5cb506066aa/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3635322e706e67"&gt;&lt;img alt="http://dotshare.it/public/images/uploads/652.png" src="https://camo.githubusercontent.com/4289372b4b4f6c4c9a5bbd34004cb5cb506066aa/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3635322e706e67" data-canonical-src="http://dotshare.it/public/images/uploads/652.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rainbow&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/074a6012d89c1ed6d64529c05e2b1ac68a83bc75/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3630362e706e67"&gt;&lt;img alt="http://dotshare.it/public/images/uploads/606.png" src="https://camo.githubusercontent.com/074a6012d89c1ed6d64529c05e2b1ac68a83bc75/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3630362e706e67" data-canonical-src="http://dotshare.it/public/images/uploads/606.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Holo&lt;/strong&gt;, requested by &lt;a href="https://bbs.archlinux.org/viewtopic.php?pid=1307158#p1307158" rel="nofollow"&gt;amouly&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2b793575c3ce79633f1adfebedeb0f1044cdd516/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3635312e6a7067"&gt;&lt;img alt="http://dotshare.it/public/images/uploads/651.jpg" src="https://camo.githubusercontent.com/2b793575c3ce79633f1adfebedeb0f1044cdd516/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3635312e6a7067" data-canonical-src="http://dotshare.it/public/images/uploads/651.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Copland&lt;/strong&gt;, inspired by &lt;a href="http://dotshare.it/dots/499" rel="nofollow"&gt;foozer&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/741266ce773c62c4c4a50c228281fc8b5927bb4d/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3635352e706e67"&gt;&lt;img alt="http://dotshare.it/public/images/uploads/655.png" src="https://camo.githubusercontent.com/741266ce773c62c4c4a50c228281fc8b5927bb4d/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f3635352e706e67" data-canonical-src="http://dotshare.it/public/images/uploads/655.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Vertex&lt;/strong&gt;, requested by &lt;a href="https://github.com/lcpz/awesome-copycats/issues/53"&gt;swordfischer&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/529ce51efbafee9cdbc95724693ee85b120ea9dc/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f313433322e6a7067"&gt;&lt;img alt="http://dotshare.it/public/images/uploads/1432.jpg" src="https://camo.githubusercontent.com/529ce51efbafee9cdbc95724693ee85b120ea9dc/687474703a2f2f646f7473686172652e69742f7075626c69632f696d616765732f75706c6f6164732f313433322e6a7067" data-canonical-src="http://dotshare.it/public/images/uploads/1432.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;a name="user-content-installation"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ git clone --recursive https://github.com/lcpz/awesome-copycats.git
$ mv -bv awesome-copycats/&lt;span class="pl-k"&gt;*&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/.config/awesome &lt;span class="pl-k"&gt;&amp;amp;&amp;amp;&lt;/span&gt; rm -rf awesome-copycats&lt;/pre&gt;&lt;/div&gt;
&lt;a name="user-content-usage"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;p&gt;The modular structure allows to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;set variables&lt;/li&gt;
&lt;li&gt;define startup processes&lt;/li&gt;
&lt;li&gt;change keybindings and layouts&lt;/li&gt;
&lt;li&gt;set client properties&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;in &lt;code&gt;rc.lua&lt;/code&gt;, and&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;configure widgets&lt;/li&gt;
&lt;li&gt;define wiboxes and screen settings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;in &lt;code&gt;theme.lua&lt;/code&gt;, so that you just need to change &lt;code&gt;chosen_theme&lt;/code&gt; variable in &lt;code&gt;rc.lua&lt;/code&gt; to preserve your preferences &lt;em&gt;and&lt;/em&gt; switch the theme, instead of having file redundancy.&lt;/p&gt;
&lt;p&gt;Just do the following:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ &lt;span class="pl-c1"&gt;cd&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/.config/awesome
$ cp rc.lua.template rc.lua&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, set the variable &lt;code&gt;chosen_theme&lt;/code&gt; in &lt;code&gt;rc.lua&lt;/code&gt; to your preferred theme, do your settings, and restart Awesome (&lt;code&gt;Mod4 + ctrl + r&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;To customize a theme, head over to &lt;code&gt;themes/$chosen_theme/theme.lua&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Otherwise, if you want to be synced with upstream, modify the theme path in &lt;code&gt;rc.lua&lt;/code&gt; like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-diff"&gt;&lt;pre&gt;&lt;span class="pl-md"&gt;&lt;span class="pl-md"&gt;-&lt;/span&gt;beautiful.init(string.format("%s/.config/awesome/themes/%s/theme.lua", os.getenv("HOME"), chosen_theme))&lt;/span&gt;
&lt;span class="pl-mi1"&gt;&lt;span class="pl-mi1"&gt;+&lt;/span&gt;beautiful.init(string.format("%s/.config/awesome/themes/%s/theme-personal.lua", os.getenv("HOME"), chosen_theme))&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;then, copy &lt;code&gt;theme.lua&lt;/code&gt; to &lt;code&gt;theme-personal.lua&lt;/code&gt; and do your customizations there.&lt;/p&gt;
&lt;p&gt;This way, you can safely &lt;code&gt;git pull&lt;/code&gt; anytime.&lt;/p&gt;
&lt;a name="user-content-notes"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-notes" class="anchor" aria-hidden="true" href="#notes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notes&lt;/h2&gt;
&lt;p&gt;Complements are provided by &lt;a href="https://github.com/lcpz/lain"&gt;lain&lt;/a&gt; and &lt;a href="https://github.com/lcpz/awesome-freedesktop"&gt;freedesktop&lt;/a&gt;. &lt;strong&gt;Be sure&lt;/strong&gt; to satisfy their dependencies.&lt;/p&gt;
&lt;p&gt;The fonts used in the screenshots are: &lt;a href="http://terminus-font.sourceforge.net" rel="nofollow"&gt;Terminus&lt;/a&gt; (Multicolor, Powerarrow, Powerarrow Dark), &lt;a href="https://fonts.google.com/specimen/Roboto" rel="nofollow"&gt;Roboto&lt;/a&gt; (Holo, Vertex) and &lt;a href="http://www.fial.com/~scott/tamsyn-font" rel="nofollow"&gt;Tamsyn&lt;/a&gt; (other ones).&lt;/p&gt;
&lt;p&gt;As taglist font, Blackburn and Dremora use &lt;a href="https://github.com/lcpz/dots/tree/master/.fonts"&gt;Icons&lt;/a&gt;, Vertex uses &lt;a href="https://github.com/FortAwesome/Font-Awesome"&gt;FontAwesome&lt;/a&gt;: be sure to have bitmaps enabled if running under Debian or &lt;a href="https://wiki.ubuntu.com/Fonts#Enabling_Bitmapped_Fonts" rel="nofollow"&gt;Ubuntu&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Due the removal of support for bitmap fonts in Pango &lt;a href="https://github.com/lcpz/awesome-copycats/issues/269"&gt;1.44&lt;/a&gt;, the current main font is Terminus (OTB version). Under Arch Linux, use &lt;code&gt;community/terminus-font-otb&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Every theme has a &lt;a href="https://github.com/lcpz/dots/tree/master/.colors"&gt;colorscheme&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can also configure the &lt;code&gt;city_id&lt;/code&gt; in the following snippet in &lt;code&gt;/.config/awesome/themes/&amp;lt;&amp;lt;CHOSEN_THEME&amp;gt;&amp;gt;/theme.lua&lt;/code&gt; to get the correct weather information (we suggest doing it in your &lt;code&gt;theme-personal.lua&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;-- Weather
   local weathericon = wibox.widget.imagebox(theme.widget_weather)
   theme.weather = lain.widget.weather({
       city_id = 2643743, -- placeholder (London)
       notification_preset = { font = "Terminus 10", fg = theme.fg_normal },
       weather_na_markup = markup.fontfg(theme.font, "#eca4c4", "N/A "),
       settings = function()
           descr = weather_now["weather"][1]["description"]:lower()
           units = math.floor(weather_now["main"]["temp"])
           widget:set_markup(markup.fontfg(theme.font, "#eca4c4", descr .. " @ " .. units .. "°C "))
       end
   })
&lt;/pre&gt;
&lt;p&gt;You can find your &lt;code&gt;city_id&lt;/code&gt; in &lt;a href="http://bulk.openweathermap.org/sample/city.list.json.gz" rel="nofollow"&gt;city.list.json.gz&lt;/a&gt; after you extract it.&lt;/p&gt;
&lt;p&gt;Additional default software used:&lt;/p&gt;
&lt;pre&gt;dmenu firefox mpc mpd scrot unclutter xsel slock
&lt;/pre&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>lcpz</author><guid isPermaLink="false">https://github.com/lcpz/awesome-copycats</guid><pubDate>Fri, 08 Nov 2019 00:12:00 GMT</pubDate></item><item><title>ntop/ntopng #13 in Lua, This month</title><link>https://github.com/ntop/ntopng</link><description>&lt;p&gt;&lt;i&gt;Web-based Traffic and Security Network Traffic Monitoring&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0f789abcef232035c05e0d2e82afa3cc3be46485/687474703a2f2f7777772e6e746f702e6f72672f77702d636f6e74656e742f75706c6f6164732f323031312f30382f6e746f706e672d69636f6e2d313530783135302e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/0f789abcef232035c05e0d2e82afa3cc3be46485/687474703a2f2f7777772e6e746f702e6f72672f77702d636f6e74656e742f75706c6f6164732f323031312f30382f6e746f706e672d69636f6e2d313530783135302e706e67" alt="ntop" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/58e2a1ecfff62d8ecc9d74633bd1013f26e06cba/687474703a2f2f7777772e6e746f702e6f72672f77702d636f6e74656e742f75706c6f6164732f323031352f30352f6e746f702e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/58e2a1ecfff62d8ecc9d74633bd1013f26e06cba/687474703a2f2f7777772e6e746f702e6f72672f77702d636f6e74656e742f75706c6f6164732f323031352f30352f6e746f702e706e67" alt="ntop" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-ntopng" class="anchor" aria-hidden="true" href="#ntopng"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ntopng&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/ntop/ntopng" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/fcefa979c56cbd9b453ab836872c72129593d4c2/68747470733a2f2f7472617669732d63692e6f72672f6e746f702f6e746f706e672e706e673f6272616e63683d646576" alt="Build Status" data-canonical-src="https://travis-ci.org/ntop/ntopng.png?branch=dev" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/ntop/ntopng/alerts" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a4c0a084a81545bf198eeeb6a86c7ebdda454c9d/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f672f6e746f702f6e746f706e672e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138" alt="Total Alerts" data-canonical-src="https://img.shields.io/lgtm/alerts/g/ntop/ntopng.svg?logo=lgtm&amp;amp;logoWidth=18" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h3&gt;
&lt;p&gt;ntopng is a web-based network traffic monitoring application released under GPLv3. It is the new incarnation of the original ntop written in 1998, and now revamped in terms of performance, usability, and features.&lt;/p&gt;
&lt;p&gt;While you can read more about ntopng on the ntop web site (&lt;a href="http://www.ntop.org" rel="nofollow"&gt;http://www.ntop.org&lt;/a&gt;), we suggest you to start reading the &lt;a href="https://github.com/ntop/ntopng/blob/dev/doc/README.md"&gt;doc/README.md&lt;/a&gt; file for learning how to compile and use ntopng.&lt;/p&gt;
&lt;p&gt;If instead of source code you prefer to use a pre-built package, please go to &lt;a href="http://packages.ntop.org" rel="nofollow"&gt;http://packages.ntop.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We build binary packages for the following platforms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu Linux Server x64&lt;/li&gt;
&lt;li&gt;CentOS/RedHat Linux x64&lt;/li&gt;
&lt;li&gt;Windows x64&lt;/li&gt;
&lt;li&gt;RaspberryPI/BeagleBoard ARM (based on Ubuntu Linux)&lt;/li&gt;
&lt;li&gt;Ubiquity Networks EdgeRouter (MIPS)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Enjoy.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h3&gt;
&lt;p&gt;If you want to learn more about ntopng please visit the &lt;a href="https://www.ntop.org/guides/ntopng/" rel="nofollow"&gt;User's Guide&lt;/a&gt; and the &lt;a href="https://www.ntop.org/guides/ntopng/api/index.html" rel="nofollow"&gt;API Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-details" class="anchor" aria-hidden="true" href="#details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Details&lt;/h3&gt;
&lt;p&gt;For more information about ntopng, please visit &lt;a href="https://www.ntop.org/products/traffic-analysis/ntop/" rel="nofollow"&gt;http://ntop.org&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ntop</author><guid isPermaLink="false">https://github.com/ntop/ntopng</guid><pubDate>Fri, 08 Nov 2019 00:13:00 GMT</pubDate></item><item><title>karpathy/char-rnn #14 in Lua, This month</title><link>https://github.com/karpathy/char-rnn</link><description>&lt;p&gt;&lt;i&gt;Multi-layer Recurrent Neural Networks (LSTM, GRU, RNN) for character-level language models in Torch&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="Readme.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-char-rnn" class="anchor" aria-hidden="true" href="#char-rnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;char-rnn&lt;/h1&gt;
&lt;p&gt;This code implements &lt;strong&gt;multi-layer Recurrent Neural Network&lt;/strong&gt; (RNN, LSTM, and GRU) for training/sampling from character-level language models. In other words the model takes one text file as input and trains a Recurrent Neural Network that learns to predict the next character in a sequence. The RNN can then be used to generate text character by character that will look like the original training data. The context of this code base is described in detail in my &lt;a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" rel="nofollow"&gt;blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are new to Torch/Lua/Neural Nets, it might be helpful to know that this code is really just a slightly more fancy version of this &lt;a href="https://gist.github.com/karpathy/d4dee566867f8291f086"&gt;100-line gist&lt;/a&gt; that I wrote in Python/numpy. The code in this repo additionally: allows for multiple layers, uses an LSTM instead of a vanilla RNN, has more supporting code for model checkpointing, and is of course much more efficient since it uses mini-batches and can run on a GPU.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-update-torch-rnn" class="anchor" aria-hidden="true" href="#update-torch-rnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Update: torch-rnn&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://cs.stanford.edu/people/jcjohns/" rel="nofollow"&gt;Justin Johnson&lt;/a&gt; (@jcjohnson) recently re-implemented char-rnn from scratch with a much nicer/smaller/cleaner/faster Torch code base. It's under the name &lt;a href="https://github.com/jcjohnson/torch-rnn"&gt;torch-rnn&lt;/a&gt;. It uses Adam for optimization and hard-codes the RNN/LSTM forward/backward passes for space/time efficiency. This also avoids headaches with cloning models in this repo. In other words, torch-rnn should be the default char-rnn implemention to use now instead of the one in this code base.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h2&gt;
&lt;p&gt;This code is written in Lua and requires &lt;a href="http://torch.ch/" rel="nofollow"&gt;Torch&lt;/a&gt;. If you're on Ubuntu, installing Torch in your home directory may look something like:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ curl -s https://raw.githubusercontent.com/torch/ezinstall/master/install-deps &lt;span class="pl-k"&gt;|&lt;/span&gt; bash
$ git clone https://github.com/torch/distro.git &lt;span class="pl-k"&gt;~&lt;/span&gt;/torch --recursive
$ &lt;span class="pl-c1"&gt;cd&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/torch&lt;span class="pl-k"&gt;;&lt;/span&gt; 
$ ./install.sh      &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; and enter "yes" at the end to modify your bashrc&lt;/span&gt;
$ &lt;span class="pl-c1"&gt;source&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/.bashrc&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See the Torch installation documentation for more details. After Torch is installed we need to get a few more packages using &lt;a href="https://luarocks.org/" rel="nofollow"&gt;LuaRocks&lt;/a&gt; (which already came with the Torch install). In particular:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ luarocks install nngraph 
$ luarocks install optim
$ luarocks install nn&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you'd like to train on an NVIDIA GPU using CUDA (this can be to about 15x faster), you'll of course need the GPU, and you will have to install the &lt;a href="https://developer.nvidia.com/cuda-toolkit" rel="nofollow"&gt;CUDA Toolkit&lt;/a&gt;. Then get the &lt;code&gt;cutorch&lt;/code&gt; and &lt;code&gt;cunn&lt;/code&gt; packages:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ luarocks install cutorch
$ luarocks install cunn&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you'd like to use OpenCL GPU instead (e.g. ATI cards), you will instead need to install the &lt;code&gt;cltorch&lt;/code&gt; and &lt;code&gt;clnn&lt;/code&gt; packages, and then use the option &lt;code&gt;-opencl 1&lt;/code&gt; during training (&lt;a href="https://github.com/hughperkins/cltorch/issues"&gt;cltorch issues&lt;/a&gt;):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ luarocks install cltorch
$ luarocks install clnn&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-data" class="anchor" aria-hidden="true" href="#data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data&lt;/h3&gt;
&lt;p&gt;All input data is stored inside the &lt;code&gt;data/&lt;/code&gt; directory. You'll notice that there is an example dataset included in the repo (in folder &lt;code&gt;data/tinyshakespeare&lt;/code&gt;) which consists of a subset of works of Shakespeare. I'm providing a few more datasets on &lt;a href="http://cs.stanford.edu/people/karpathy/char-rnn/" rel="nofollow"&gt;this page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Your own data&lt;/strong&gt;: If you'd like to use your own data then create a single file &lt;code&gt;input.txt&lt;/code&gt; and place it into a folder in the &lt;code&gt;data/&lt;/code&gt; directory. For example, &lt;code&gt;data/some_folder/input.txt&lt;/code&gt;. The first time you run the training script it will do some preprocessing and write two more convenience cache files into &lt;code&gt;data/some_folder&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dataset sizes&lt;/strong&gt;: Note that if your data is too small (1MB is already considered very small) the RNN won't learn very effectively. Remember that it has to learn everything completely from scratch. Conversely if your data is large (more than about 2MB), feel confident to increase &lt;code&gt;rnn_size&lt;/code&gt; and train a bigger model (see details of training below). It will work &lt;em&gt;significantly better&lt;/em&gt;. For example with 6MB you can easily go up to &lt;code&gt;rnn_size&lt;/code&gt; 300 or even more. The biggest that fits on my GPU and that I've trained with this code is &lt;code&gt;rnn_size&lt;/code&gt; 700 with &lt;code&gt;num_layers&lt;/code&gt; 3 (2 is default).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-training" class="anchor" aria-hidden="true" href="#training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training&lt;/h3&gt;
&lt;p&gt;Start training the model using &lt;code&gt;train.lua&lt;/code&gt;. As a sanity check, to run on the included example dataset simply try:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ th train.lua -gpuid -1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that here we are setting the flag &lt;code&gt;gpuid&lt;/code&gt; to -1, which tells the code to train using CPU, otherwise it defaults to GPU 0.  There are many other flags for various options. Consult &lt;code&gt;$ th train.lua -help&lt;/code&gt; for comprehensive settings. Here's another example that trains a bigger network and also shows how you can run on your own custom dataset (this already assumes that &lt;code&gt;data/some_folder/input.txt&lt;/code&gt; exists):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ th train.lua -data_dir data/some_folder -rnn_size 512 -num_layers 2 -dropout 0.5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Checkpoints.&lt;/strong&gt; While the model is training it will periodically write checkpoint files to the &lt;code&gt;cv&lt;/code&gt; folder. The frequency with which these checkpoints are written is controlled with number of iterations, as specified with the &lt;code&gt;eval_val_every&lt;/code&gt; option (e.g. if this is 1 then a checkpoint is written every iteration). The filename of these checkpoints contains a very important number: the &lt;strong&gt;loss&lt;/strong&gt;. For example, a checkpoint with filename &lt;code&gt;lm_lstm_epoch0.95_2.0681.t7&lt;/code&gt; indicates that at this point the model was on epoch 0.95 (i.e. it has almost done one full pass over the training data), and the loss on validation data was 2.0681. This number is very important because the lower it is, the better the checkpoint works. Once you start to generate data (discussed below), you will want to use the model checkpoint that reports the lowest validation loss. Notice that this might not necessarily be the last checkpoint at the end of training (due to possible overfitting).&lt;/p&gt;
&lt;p&gt;Another important quantities to be aware of are &lt;code&gt;batch_size&lt;/code&gt; (call it B), &lt;code&gt;seq_length&lt;/code&gt; (call it S), and the &lt;code&gt;train_frac&lt;/code&gt; and &lt;code&gt;val_frac&lt;/code&gt; settings. The batch size specifies how many streams of data are processed in parallel at one time. The sequence length specifies the length of each stream, which is also the limit at which the gradients can propagate backwards in time. For example, if &lt;code&gt;seq_length&lt;/code&gt; is 20, then the gradient signal will never backpropagate more than 20 time steps, and the model might not &lt;em&gt;find&lt;/em&gt; dependencies longer than this length in number of characters. Thus, if you have a very difficult dataset where there are a lot of long-term dependencies you will want to increase this setting. Now, if at runtime your input text file has N characters, these first all get split into chunks of size &lt;code&gt;BxS&lt;/code&gt;. These chunks then get allocated across three splits: train/val/test according to the &lt;code&gt;frac&lt;/code&gt; settings. By default &lt;code&gt;train_frac&lt;/code&gt; is 0.95 and &lt;code&gt;val_frac&lt;/code&gt; is 0.05, which means that 95% of our data chunks will be trained on and 5% of the chunks will be used to estimate the validation loss (and hence the generalization). If your data is small, it's possible that with the default settings you'll only have very few chunks in total (for example 100). This is bad: In these cases you may want to decrease batch size or sequence length.&lt;/p&gt;
&lt;p&gt;Note that you can also initialize parameters from a previously saved checkpoint using &lt;code&gt;init_from&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-sampling" class="anchor" aria-hidden="true" href="#sampling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sampling&lt;/h3&gt;
&lt;p&gt;Given a checkpoint file (such as those written to &lt;code&gt;cv&lt;/code&gt;) we can generate new text. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ th sample.lua cv/some_checkpoint.t7 -gpuid -1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Make sure that if your checkpoint was trained with GPU it is also sampled from with GPU, or vice versa. Otherwise the code will (currently) complain. As with the train script, see &lt;code&gt;$ th sample.lua -help&lt;/code&gt; for full options. One important one is (for example) &lt;code&gt;-length 10000&lt;/code&gt; which would generate 10,000 characters (default = 2000).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Temperature&lt;/strong&gt;. An important parameter you may want to play with is &lt;code&gt;-temperature&lt;/code&gt;, which takes a number in range (0, 1] (0 not included), default = 1. The temperature is dividing the predicted log probabilities before the Softmax, so lower temperature will cause the model to make more likely, but also more boring and conservative predictions. Higher temperatures cause the model to take more chances and increase diversity of results, but at a cost of more mistakes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Priming&lt;/strong&gt;. It's also possible to prime the model with some starting text using &lt;code&gt;-primetext&lt;/code&gt;. This starts out the RNN with some hardcoded characters to &lt;em&gt;warm&lt;/em&gt; it up with some context before it starts generating text. E.g. a fun primetext might be &lt;code&gt;-primetext "the meaning of life is "&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Training with GPU but sampling on CPU&lt;/strong&gt;. Right now the solution is to use the &lt;code&gt;convert_gpu_cpu_checkpoint.lua&lt;/code&gt; script to convert your GPU checkpoint to a CPU checkpoint. In near future you will not have to do this explicitly. E.g.:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ th convert_gpu_cpu_checkpoint.lua cv/lm_lstm_epoch30.00_1.3950.t7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;will create a new file &lt;code&gt;cv/lm_lstm_epoch30.00_1.3950.t7_cpu.t7&lt;/code&gt; that you can use with the sample script and with &lt;code&gt;-gpuid -1&lt;/code&gt; for CPU mode.&lt;/p&gt;
&lt;p&gt;Happy sampling!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tips-and-tricks" class="anchor" aria-hidden="true" href="#tips-and-tricks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tips and Tricks&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-monitoring-validation-loss-vs-training-loss" class="anchor" aria-hidden="true" href="#monitoring-validation-loss-vs-training-loss"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Monitoring Validation Loss vs. Training Loss&lt;/h3&gt;
&lt;p&gt;If you're somewhat new to Machine Learning or Neural Networks it can take a bit of expertise to get good models. The most important quantity to keep track of is the difference between your training loss (printed during training) and the validation loss (printed once in a while when the RNN is run on the validation data (by default every 1000 iterations)). In particular:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If your training loss is much lower than validation loss then this means the network might be &lt;strong&gt;overfitting&lt;/strong&gt;. Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on.&lt;/li&gt;
&lt;li&gt;If your training/validation loss are about equal then your model is &lt;strong&gt;underfitting&lt;/strong&gt;. Increase the size of your model (either number of layers or the raw number of neurons per layer)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-approximate-number-of-parameters" class="anchor" aria-hidden="true" href="#approximate-number-of-parameters"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Approximate number of parameters&lt;/h3&gt;
&lt;p&gt;The two most important parameters that control the model are &lt;code&gt;rnn_size&lt;/code&gt; and &lt;code&gt;num_layers&lt;/code&gt;. I would advise that you always use &lt;code&gt;num_layers&lt;/code&gt; of either 2/3. The &lt;code&gt;rnn_size&lt;/code&gt; can be adjusted based on how much data you have. The two important quantities to keep track of here are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The number of parameters in your model. This is printed when you start training.&lt;/li&gt;
&lt;li&gt;The size of your dataset. 1MB file is approximately 1 million characters.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These two should be about the same order of magnitude. It's a little tricky to tell. Here are some examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I have a 100MB dataset and I'm using the default parameter settings (which currently print 150K parameters). My data size is significantly larger (100 mil &amp;gt;&amp;gt; 0.15 mil), so I expect to heavily underfit. I am thinking I can comfortably afford to make &lt;code&gt;rnn_size&lt;/code&gt; larger.&lt;/li&gt;
&lt;li&gt;I have a 10MB dataset and running a 10 million parameter model. I'm slightly nervous and I'm carefully monitoring my validation loss. If it's larger than my training loss then I may want to try to increase dropout a bit and see if that heps the validation loss.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-best-models-strategy" class="anchor" aria-hidden="true" href="#best-models-strategy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Best models strategy&lt;/h3&gt;
&lt;p&gt;The winning strategy to obtaining very good models (if you have the compute time) is to always err on making the network larger (as large as you're willing to wait for it to compute) and then try different dropout values (between 0,1). Whatever model has the best validation performance (the loss, written in the checkpoint filename, low is good) is the one you should use in the end.&lt;/p&gt;
&lt;p&gt;It is very common in deep learning to run many different models with many different hyperparameter settings, and in the end take whatever checkpoint gave the best validation performance.&lt;/p&gt;
&lt;p&gt;By the way, the size of your training and validation splits are also parameters. Make sure you have a decent amount of data in your validation set or otherwise the validation performance will be noisy and not very informative.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-additional-pointers-and-acknowledgements" class="anchor" aria-hidden="true" href="#additional-pointers-and-acknowledgements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Additional Pointers and Acknowledgements&lt;/h2&gt;
&lt;p&gt;This code was originally based on Oxford University Machine Learning class &lt;a href="https://github.com/oxford-cs-ml-2015/practical6"&gt;practical 6&lt;/a&gt;, which is in turn based on &lt;a href="https://github.com/wojciechz/learning_to_execute"&gt;learning to execute&lt;/a&gt; code from Wojciech Zaremba. Chunks of it were also developed in collaboration with my labmate &lt;a href="http://cs.stanford.edu/people/jcjohns/" rel="nofollow"&gt;Justin Johnson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To learn more about RNN language models I recommend looking at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://skillsmatter.com/skillscasts/6611-visualizing-and-understanding-recurrent-networks" rel="nofollow"&gt;My recent talk&lt;/a&gt; on char-rnn&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1308.0850" rel="nofollow"&gt;Generating Sequences With Recurrent Neural Networks&lt;/a&gt; by Alex Graves&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf" rel="nofollow"&gt;Generating Text with Recurrent Neural Networks&lt;/a&gt; by Ilya Sutskever&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.fit.vutbr.cz/~imikolov/rnnlm/thesis.pdf" rel="nofollow"&gt;Tomas Mikolov's Thesis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;MIT&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>karpathy</author><guid isPermaLink="false">https://github.com/karpathy/char-rnn</guid><pubDate>Fri, 08 Nov 2019 00:14:00 GMT</pubDate></item><item><title>nagadomi/waifu2x #15 in Lua, This month</title><link>https://github.com/nagadomi/waifu2x</link><description>&lt;p&gt;&lt;i&gt;Image Super-Resolution for Anime-Style Art&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-waifu2x" class="anchor" aria-hidden="true" href="#waifu2x"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;waifu2x&lt;/h1&gt;
&lt;p&gt;Image Super-Resolution for Anime-style art using Deep Convolutional Neural Networks.
And it supports photo.&lt;/p&gt;
&lt;p&gt;The demo application can be found at &lt;a href="http://waifu2x.udp.jp/" rel="nofollow"&gt;http://waifu2x.udp.jp/&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note that I only provide this website and this repository. Other software or website claiming "waifu2x" has nothing to do with me.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-summary" class="anchor" aria-hidden="true" href="#summary"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Summary&lt;/h2&gt;
&lt;p&gt;Click to see the slide show.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/nagadomi/waifu2x/master/images/slide.png"&gt;&lt;img src="https://raw.githubusercontent.com/nagadomi/waifu2x/master/images/slide.png" alt="slide" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-references" class="anchor" aria-hidden="true" href="#references"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;References&lt;/h2&gt;
&lt;p&gt;waifu2x is inspired by SRCNN [1]. 2D character picture (HatsuneMiku) is licensed under CC BY-NC by piapro [2].&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[1] Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang, "Image Super-Resolution Using Deep Convolutional Networks", &lt;a href="http://arxiv.org/abs/1501.00092" rel="nofollow"&gt;http://arxiv.org/abs/1501.00092&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[2] "For Creators", &lt;a href="http://piapro.net/en_for_creators.html" rel="nofollow"&gt;http://piapro.net/en_for_creators.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-public-ami" class="anchor" aria-hidden="true" href="#public-ami"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Public AMI&lt;/h2&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-third-party-software" class="anchor" aria-hidden="true" href="#third-party-software"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Third Party Software&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/nagadomi/waifu2x/wiki/Third-Party"&gt;Third-Party&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you are a windows user, I recommend you to use &lt;a href="https://github.com/lltcggie/waifu2x-caffe"&gt;waifu2x-caffe&lt;/a&gt;(Just download from &lt;code&gt;releases&lt;/code&gt; tab), &lt;a href="https://github.com/nihui/waifu2x-ncnn-vulkan"&gt;waifu2x-ncnn-vulkan&lt;/a&gt; or &lt;a href="https://github.com/DeadSix27/waifu2x-converter-cpp"&gt;waifu2x-conver-cpp&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-hardware" class="anchor" aria-hidden="true" href="#hardware"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hardware&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;NVIDIA GPU&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-platform" class="anchor" aria-hidden="true" href="#platform"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Platform&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://torch.ch/" rel="nofollow"&gt;Torch7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.nvidia.com/cuda-toolkit" rel="nofollow"&gt;NVIDIA CUDA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-luarocks-packages-excludes-torch7s-default-packages" class="anchor" aria-hidden="true" href="#luarocks-packages-excludes-torch7s-default-packages"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LuaRocks packages (excludes torch7's default packages)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;lua-csnappy&lt;/li&gt;
&lt;li&gt;md5&lt;/li&gt;
&lt;li&gt;uuid&lt;/li&gt;
&lt;li&gt;csvigo&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kernelsauce/turbo"&gt;turbo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-setting-up-the-command-line-tool-environment" class="anchor" aria-hidden="true" href="#setting-up-the-command-line-tool-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setting Up the Command Line Tool Environment&lt;/h3&gt;
&lt;p&gt;(on Ubuntu 16.04)&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-install-cuda" class="anchor" aria-hidden="true" href="#install-cuda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install CUDA&lt;/h4&gt;
&lt;p&gt;See: &lt;a href="http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-linux/#ubuntu-installation" rel="nofollow"&gt;NVIDIA CUDA Getting Started Guide for Linux&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Download &lt;a href="http://developer.nvidia.com/cuda-downloads" rel="nofollow"&gt;CUDA&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Note: Torch does not supported CUDA10. CUDA9.2 is recommended.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo dpkg -i cuda-repo-ubuntu1404_7.5-18_amd64.deb
sudo apt-get update
sudo apt-get install cuda
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-install-package" class="anchor" aria-hidden="true" href="#install-package"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install Package&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install libsnappy-dev
sudo apt-get install libgraphicsmagick1-dev
sudo apt-get install libssl1.0-dev # for web server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: waifu2x requires little-cms2 linked graphicsmagick. if you use macOS/homebrew, See &lt;a href="https://github.com/nagadomi/waifu2x/issues/174#issuecomment-384466451"&gt;#174&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-install-torch7" class="anchor" aria-hidden="true" href="#install-torch7"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install Torch7&lt;/h4&gt;
&lt;p&gt;See: &lt;a href="http://torch.ch/docs/getting-started.html" rel="nofollow"&gt;Getting started with Torch&lt;/a&gt;. For CUDA9.x/CUDA8.x, see &lt;a href="https://github.com/nagadomi/waifu2x/issues/222"&gt;#222&lt;/a&gt;, For CUDA10, see &lt;a href="https://github.com/nagadomi/waifu2x/issues/253#issuecomment-445448928"&gt;#253&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-getting-waifu2x" class="anchor" aria-hidden="true" href="#getting-waifu2x"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting waifu2x&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;git clone --depth 1 https://github.com/nagadomi/waifu2x.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and install lua modules.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd waifu2x
./install_lua_modules.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-validation" class="anchor" aria-hidden="true" href="#validation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Validation&lt;/h4&gt;
&lt;p&gt;Testing the waifu2x command line tool.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;th waifu2x.lua
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-web-application" class="anchor" aria-hidden="true" href="#web-application"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web Application&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;th web.lua
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;View at: &lt;a href="http://localhost:8812/" rel="nofollow"&gt;http://localhost:8812/&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-command-line-tools" class="anchor" aria-hidden="true" href="#command-line-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Command line tools&lt;/h2&gt;
&lt;p&gt;Notes: If you have cuDNN library, than you can use cuDNN with &lt;code&gt;-force_cudnn 1&lt;/code&gt; option. cuDNN is too much faster than default kernel. If you got GPU out of memory error, you can avoid it with &lt;code&gt;-crop_size&lt;/code&gt; option (e.g. &lt;code&gt;-crop_size 128&lt;/code&gt;).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-noise-reduction" class="anchor" aria-hidden="true" href="#noise-reduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Noise Reduction&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;th waifu2x.lua -m noise -noise_level 1 -i input_image.png -o output_image.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;th waifu2x.lua -m noise -noise_level 0 -i input_image.png -o output_image.png
th waifu2x.lua -m noise -noise_level 2 -i input_image.png -o output_image.png
th waifu2x.lua -m noise -noise_level 3 -i input_image.png -o output_image.png
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-2x-upscaling" class="anchor" aria-hidden="true" href="#2x-upscaling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2x Upscaling&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;th waifu2x.lua -m scale -i input_image.png -o output_image.png
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-noise-reduction--2x-upscaling" class="anchor" aria-hidden="true" href="#noise-reduction--2x-upscaling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Noise Reduction + 2x Upscaling&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;th waifu2x.lua -m noise_scale -noise_level 1 -i input_image.png -o output_image.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;th waifu2x.lua -m noise_scale -noise_level 0 -i input_image.png -o output_image.png
th waifu2x.lua -m noise_scale -noise_level 2 -i input_image.png -o output_image.png
th waifu2x.lua -m noise_scale -noise_level 3 -i input_image.png -o output_image.png
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-batch-conversion" class="anchor" aria-hidden="true" href="#batch-conversion"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Batch conversion&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;find /path/to/imagedir -name "*.png" -o -name "*.jpg" &amp;gt; image_list.txt
th waifu2x.lua -m scale -l ./image_list.txt -o /path/to/outputdir/prefix_%d.png
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output format supports &lt;code&gt;%s&lt;/code&gt; and &lt;code&gt;%d&lt;/code&gt;(e.g. %06d). &lt;code&gt;%s&lt;/code&gt; will be replaced the basename of the source filename. &lt;code&gt;%d&lt;/code&gt; will be replaced a sequence number.
For example, when input filename is &lt;code&gt;piyo.png&lt;/code&gt;, &lt;code&gt;%s_%03d.png&lt;/code&gt; will be replaced &lt;code&gt;piyo_001.png&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;See also &lt;code&gt;th waifu2x.lua -h&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-using-photo-model" class="anchor" aria-hidden="true" href="#using-photo-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using photo model&lt;/h3&gt;
&lt;p&gt;Please add &lt;code&gt;-model_dir models/photo&lt;/code&gt; to command line option, if you want to use photo model.
For example,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;th waifu2x.lua -model_dir models/photo -m scale -i input_image.png -o output_image.png
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-video-encoding" class="anchor" aria-hidden="true" href="#video-encoding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Video Encoding&lt;/h3&gt;
&lt;p&gt;* &lt;code&gt;avconv&lt;/code&gt; is alias of &lt;code&gt;ffmpeg&lt;/code&gt; on Ubuntu 14.04.&lt;/p&gt;
&lt;p&gt;Extracting images and audio from a video. (range: 00:09:00 ~ 00:12:00)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir frames
avconv -i data/raw.avi -ss 00:09:00 -t 00:03:00 -r 24 -f image2 frames/%06d.png
avconv -i data/raw.avi -ss 00:09:00 -t 00:03:00 audio.mp3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Generating a image list.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;find ./frames -name "*.png" |sort &amp;gt; data/frame.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;waifu2x (for example, noise reduction)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir new_frames
th waifu2x.lua -m noise -noise_level 1 -resume 1 -l data/frame.txt -o new_frames/%d.png
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Generating a video from waifu2xed images and audio.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;avconv -f image2 -framerate 24 -i new_frames/%d.png -i audio.mp3 -r 24 -vcodec libx264 -crf 16 video.mp4
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-train-your-own-model" class="anchor" aria-hidden="true" href="#train-your-own-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train Your Own Model&lt;/h2&gt;
&lt;p&gt;Note1: If you have cuDNN library, you can use cudnn kernel with &lt;code&gt;-backend cudnn&lt;/code&gt; option. And, you can convert trained cudnn model to cunn model with &lt;code&gt;tools/rebuild.lua&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Note2: The command that was used to train for waifu2x's pretrained models is available at &lt;code&gt;appendix/train_upconv_7_art.sh&lt;/code&gt;, &lt;code&gt;appendix/train_upconv_7_photo.sh&lt;/code&gt;. Maybe it is helpful.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-data-preparation" class="anchor" aria-hidden="true" href="#data-preparation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Preparation&lt;/h3&gt;
&lt;p&gt;Genrating a file list.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;find /path/to/image/dir -name "*.png" &amp;gt; data/image_list.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should use noise free images. In my case, waifu2x is trained with 6000 high-resolution-noise-free-PNG images.&lt;/p&gt;
&lt;p&gt;Converting training data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;th convert_data.lua
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-train-a-noise-reductionlevel1-model" class="anchor" aria-hidden="true" href="#train-a-noise-reductionlevel1-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train a Noise Reduction(level1) model&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;mkdir models/my_model
th train.lua -model_dir models/my_model -method noise -noise_level 1 -test images/miku_noisy.png
# usage
th waifu2x.lua -model_dir models/my_model -m noise -noise_level 1 -i images/miku_noisy.png -o output.png
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can check the performance of model with &lt;code&gt;models/my_model/noise1_best.png&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-train-a-noise-reductionlevel2-model" class="anchor" aria-hidden="true" href="#train-a-noise-reductionlevel2-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train a Noise Reduction(level2) model&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;th train.lua -model_dir models/my_model -method noise -noise_level 2 -test images/miku_noisy.png
# usage
th waifu2x.lua -model_dir models/my_model -m noise -noise_level 2 -i images/miku_noisy.png -o output.png
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can check the performance of model with &lt;code&gt;models/my_model/noise2_best.png&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-train-a-2x-upscaling-model" class="anchor" aria-hidden="true" href="#train-a-2x-upscaling-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train a 2x UpScaling model&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;th train.lua -model upconv_7 -model_dir models/my_model -method scale -scale 2 -test images/miku_small.png
# usage
th waifu2x.lua -model_dir models/my_model -m scale -scale 2 -i images/miku_small.png -o output.png
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can check the performance of model with &lt;code&gt;models/my_model/scale2.0x_best.png&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-train-a-2x-and-noise-reduction-fusion-model" class="anchor" aria-hidden="true" href="#train-a-2x-and-noise-reduction-fusion-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train a 2x and noise reduction fusion model&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;th train.lua -model upconv_7 -model_dir models/my_model -method noise_scale -scale 2 -noise_level 1 -test images/miku_small.png
# usage
th waifu2x.lua -model_dir models/my_model -m noise_scale -scale 2 -noise_level 1 -i images/miku_small.png -o output.png
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can check the performance of model with &lt;code&gt;models/my_model/noise1_scale2.0x_best.png&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h2&gt;
&lt;p&gt;( Docker image is available at &lt;a href="https://hub.docker.com/r/nagadomi/waifu2x" rel="nofollow"&gt;https://hub.docker.com/r/nagadomi/waifu2x&lt;/a&gt; )&lt;/p&gt;
&lt;p&gt;Requires &lt;code&gt;nvidia-docker&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker build -t waifu2x .
nvidia-docker run -p 8812:8812 waifu2x th web.lua
nvidia-docker run -v `pwd`/images:/images waifu2x th waifu2x.lua -force_cudnn 1 -m scale -scale 2 -i /images/miku_small.png -o /images/output.png
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that running waifu2x in without &lt;a href="https://devblogs.nvidia.com/parallelforall/cuda-pro-tip-understand-fat-binaries-jit-caching/" rel="nofollow"&gt;JIT caching&lt;/a&gt; is very slow, which is what would happen if you use docker.
For a workaround, you can mount a host volume to the &lt;code&gt;CUDA_CACHE_PATH&lt;/code&gt;, for instance,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nvidia-docker run -v $PWD/ComputeCache:/root/.nv/ComputeCache waifu2x th waifu2x.lua --help
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>nagadomi</author><guid isPermaLink="false">https://github.com/nagadomi/waifu2x</guid><pubDate>Fri, 08 Nov 2019 00:15:00 GMT</pubDate></item><item><title>ledgetech/lua-resty-http #16 in Lua, This month</title><link>https://github.com/ledgetech/lua-resty-http</link><description>&lt;p&gt;&lt;i&gt;Lua HTTP client cosocket driver for OpenResty / ngx_lua.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-lua-resty-http" class="anchor" aria-hidden="true" href="#lua-resty-http"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;lua-resty-http&lt;/h1&gt;
&lt;p&gt;Lua HTTP client cosocket driver for &lt;a href="http://openresty.org/" rel="nofollow"&gt;OpenResty&lt;/a&gt; / &lt;a href="https://github.com/openresty/lua-nginx-module"&gt;ngx_lua&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-status" class="anchor" aria-hidden="true" href="#status"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Status&lt;/h1&gt;
&lt;p&gt;Production ready.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;HTTP 1.0 and 1.1&lt;/li&gt;
&lt;li&gt;SSL&lt;/li&gt;
&lt;li&gt;Streaming interface to the response body, for predictable memory usage&lt;/li&gt;
&lt;li&gt;Alternative simple interface for singleshot requests without manual connection step&lt;/li&gt;
&lt;li&gt;Chunked and non-chunked transfer encodings&lt;/li&gt;
&lt;li&gt;Keepalive&lt;/li&gt;
&lt;li&gt;Pipelining&lt;/li&gt;
&lt;li&gt;Trailers&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-api" class="anchor" aria-hidden="true" href="#api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;API&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#new"&gt;new&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#connect"&gt;connect&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#connect_proxy"&gt;connect_proxy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#set_proxy_options"&gt;set_proxy_options&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#set_timeout"&gt;set_timeout&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#set_timeouts"&gt;set_timeouts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ssl_handshake"&gt;ssl_handshake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#set_keepalive"&gt;set_keepalive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#get_reused_times"&gt;get_reused_times&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#close"&gt;close&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#request"&gt;request&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#request_uri"&gt;request_uri&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#request_pipeline"&gt;request_pipeline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#response"&gt;Response&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#resbody_reader"&gt;body_reader&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#resread_body"&gt;read_body&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#resread_trailers"&gt;read_trailers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#proxy"&gt;Proxy&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#proxy_request"&gt;proxy_request&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#proxy_response"&gt;proxy_response&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#utility"&gt;Utility&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#parse_uri"&gt;parse_uri&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#get_client_body_reader"&gt;get_client_body_reader&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-synopsis" class="anchor" aria-hidden="true" href="#synopsis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Synopsis&lt;/h2&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;lua_package_path&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/path/to/lua-resty-http/lib/?.lua;;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-c1"&gt;server&lt;/span&gt; {


  location &lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-c1"&gt;simpleinterface&lt;/span&gt; {
    resolver &lt;span class="pl-c1"&gt;8.8&lt;/span&gt;.8.8;  &lt;span class="pl-k"&gt;#&lt;/span&gt; use &lt;span class="pl-c1"&gt;Google&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;s open DNS server for an example&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;    content_by_lua_block {&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- For simple singleshot requests, use the URI interface.&lt;/span&gt;
&lt;span class="pl-s"&gt;      local http = require "resty.http"&lt;/span&gt;
&lt;span class="pl-s"&gt;      local httpc = http.new()&lt;/span&gt;
&lt;span class="pl-s"&gt;      local res, err = httpc:request_uri("http://example.com/helloworld", {&lt;/span&gt;
&lt;span class="pl-s"&gt;        method = "POST",&lt;/span&gt;
&lt;span class="pl-s"&gt;        body = "a=1&amp;amp;b=2",&lt;/span&gt;
&lt;span class="pl-s"&gt;        headers = {&lt;/span&gt;
&lt;span class="pl-s"&gt;          ["Content-Type"] = "application/x-www-form-urlencoded",&lt;/span&gt;
&lt;span class="pl-s"&gt;        },&lt;/span&gt;
&lt;span class="pl-s"&gt;        keepalive_timeout = 60,&lt;/span&gt;
&lt;span class="pl-s"&gt;        keepalive_pool = 10&lt;/span&gt;
&lt;span class="pl-s"&gt;      })&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      if not res then&lt;/span&gt;
&lt;span class="pl-s"&gt;        ngx.say("failed to request: ", err)&lt;/span&gt;
&lt;span class="pl-s"&gt;        return&lt;/span&gt;
&lt;span class="pl-s"&gt;      end&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- In this simple form, there is no manual connection step, so the body is read&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- all in one go, including any trailers, and the connection closed or keptalive&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- for you.&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      ngx.status = res.status&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      for k,v in pairs(res.headers) do&lt;/span&gt;
&lt;span class="pl-s"&gt;          --&lt;/span&gt;
&lt;span class="pl-s"&gt;      end&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      ngx.say(res.body)&lt;/span&gt;
&lt;span class="pl-s"&gt;    }&lt;/span&gt;
&lt;span class="pl-s"&gt;  }&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;  location /genericinterface {&lt;/span&gt;
&lt;span class="pl-s"&gt;    content_by_lua_block {&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      local http = require "resty.http"&lt;/span&gt;
&lt;span class="pl-s"&gt;      local httpc = http.new()&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- The generic form gives us more control. We must connect manually.&lt;/span&gt;
&lt;span class="pl-s"&gt;      httpc:set_timeout(500)&lt;/span&gt;
&lt;span class="pl-s"&gt;      httpc:connect("127.0.0.1", 80)&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- And request using a path, rather than a full URI.&lt;/span&gt;
&lt;span class="pl-s"&gt;      local res, err = httpc:request({&lt;/span&gt;
&lt;span class="pl-s"&gt;          path = "/helloworld",&lt;/span&gt;
&lt;span class="pl-s"&gt;          headers = {&lt;/span&gt;
&lt;span class="pl-s"&gt;              ["Host"] = "example.com",&lt;/span&gt;
&lt;span class="pl-s"&gt;          },&lt;/span&gt;
&lt;span class="pl-s"&gt;      })&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      if not res then&lt;/span&gt;
&lt;span class="pl-s"&gt;        ngx.say("failed to request: ", err)&lt;/span&gt;
&lt;span class="pl-s"&gt;        return&lt;/span&gt;
&lt;span class="pl-s"&gt;      end&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- Now we can use the body_reader iterator, to stream the body according to our desired chunk size.&lt;/span&gt;
&lt;span class="pl-s"&gt;      local reader = res.body_reader&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      repeat&lt;/span&gt;
&lt;span class="pl-s"&gt;        local chunk, err = reader(8192)&lt;/span&gt;
&lt;span class="pl-s"&gt;        if err then&lt;/span&gt;
&lt;span class="pl-s"&gt;          ngx.log(ngx.ERR, err)&lt;/span&gt;
&lt;span class="pl-s"&gt;          break&lt;/span&gt;
&lt;span class="pl-s"&gt;        end&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;        if chunk then&lt;/span&gt;
&lt;span class="pl-s"&gt;          -- process&lt;/span&gt;
&lt;span class="pl-s"&gt;        end&lt;/span&gt;
&lt;span class="pl-s"&gt;      until not chunk&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      local ok, err = httpc:set_keepalive()&lt;/span&gt;
&lt;span class="pl-s"&gt;      if not ok then&lt;/span&gt;
&lt;span class="pl-s"&gt;        ngx.say("failed to set keepalive: ", err)&lt;/span&gt;
&lt;span class="pl-s"&gt;        return&lt;/span&gt;
&lt;span class="pl-s"&gt;      end&lt;/span&gt;
&lt;span class="pl-s"&gt;    }&lt;/span&gt;
&lt;span class="pl-s"&gt;  }&lt;/span&gt;
&lt;span class="pl-s"&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-connection" class="anchor" aria-hidden="true" href="#connection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Connection&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-new" class="anchor" aria-hidden="true" href="#new"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;new&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: httpc = http.new()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Creates the http object. In case of failures, returns &lt;code&gt;nil&lt;/code&gt; and a string describing the error.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-connect" class="anchor" aria-hidden="true" href="#connect"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;connect&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: ok, err = httpc:connect(host, port, options_table?)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;syntax: ok, err = httpc:connect("unix:/path/to/unix.sock", options_table?)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Attempts to connect to the web server.&lt;/p&gt;
&lt;p&gt;Before actually resolving the host name and connecting to the remote backend, this method will always look up the connection pool for matched idle connections created by previous calls of this method.&lt;/p&gt;
&lt;p&gt;An optional Lua table can be specified as the last argument to this method to specify various connect options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pool&lt;/code&gt;
: Specifies a custom name for the connection pool being used. If omitted, then the connection pool name will be generated from the string template &lt;code&gt;&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;&lt;/code&gt; or &lt;code&gt;&amp;lt;unix-socket-path&amp;gt;&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-connect_proxy" class="anchor" aria-hidden="true" href="#connect_proxy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;connect_proxy&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: ok, err = httpc:connect_proxy(proxy_uri, scheme, host, port, proxy_authorization)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Attempts to connect to the web server through the given proxy server. The method accepts the following arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;proxy_uri&lt;/code&gt; - Full URI of the proxy server to use (e.g. &lt;code&gt;http://proxy.example.com:3128/&lt;/code&gt;). Note: Only &lt;code&gt;http&lt;/code&gt; protocol is supported.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;scheme&lt;/code&gt; - The protocol to use between the proxy server and the remote host (&lt;code&gt;http&lt;/code&gt; or &lt;code&gt;https&lt;/code&gt;). If &lt;code&gt;https&lt;/code&gt; is specified as the scheme, &lt;code&gt;connect_proxy()&lt;/code&gt; makes a &lt;code&gt;CONNECT&lt;/code&gt; request to establish a TCP tunnel to the remote host through the proxy server.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host&lt;/code&gt; - The hostname of the remote host to connect to.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;port&lt;/code&gt; - The port of the remote host to connect to.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;proxy_authorization&lt;/code&gt; - The &lt;code&gt;Proxy-Authorization&lt;/code&gt; header value sent to the proxy server via &lt;code&gt;CONNECT&lt;/code&gt; when the &lt;code&gt;scheme&lt;/code&gt; is &lt;code&gt;https&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If an error occurs during the connection attempt, this method returns &lt;code&gt;nil&lt;/code&gt; with a string describing the error. If the connection was successfully established, the method returns &lt;code&gt;1&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;There's a few key points to keep in mind when using this api:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the scheme is &lt;code&gt;https&lt;/code&gt;, you need to perform the TLS handshake with the remote server manually using the &lt;code&gt;ssl_handshake()&lt;/code&gt; method before sending any requests through the proxy tunnel.&lt;/li&gt;
&lt;li&gt;If the scheme is &lt;code&gt;http&lt;/code&gt;, you need to ensure that the requests you send through the connections conforms to &lt;a href="https://tools.ietf.org/html/rfc7230" rel="nofollow"&gt;RFC 7230&lt;/a&gt; and especially &lt;a href="https://tools.ietf.org/html/rfc7230#section-5.3.2" rel="nofollow"&gt;Section 5.3.2.&lt;/a&gt; which states that the request target must be in absolute form. In practice, this means that when you use &lt;code&gt;send_request()&lt;/code&gt;, the &lt;code&gt;path&lt;/code&gt; must be an absolute URI to the resource (e.g. &lt;code&gt;http://example.com/index.html&lt;/code&gt; instead of just &lt;code&gt;/index.html&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-set_timeout" class="anchor" aria-hidden="true" href="#set_timeout"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;set_timeout&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: httpc:set_timeout(time)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Sets the timeout (in ms) protection for subsequent operations, including the &lt;code&gt;connect&lt;/code&gt; method.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-set_timeouts" class="anchor" aria-hidden="true" href="#set_timeouts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;set_timeouts&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: httpc:set_timeouts(connect_timeout, send_timeout, read_timeout)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Sets the connect timeout threshold, send timeout threshold, and read timeout threshold, respectively, in milliseconds, for subsequent socket operations (connect, send, receive, and iterators returned from receiveuntil).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ssl_handshake" class="anchor" aria-hidden="true" href="#ssl_handshake"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ssl_handshake&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: session, err = httpc:ssl_handshake(session, host, verify)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Performs an SSL handshake on the TCP connection, only available in ngx_lua &amp;gt; v0.9.11&lt;/p&gt;
&lt;p&gt;See docs for &lt;a href="https://github.com/openresty/lua-nginx-module#ngxsockettcp"&gt;ngx.socket.tcp&lt;/a&gt; for details.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-set_keepalive" class="anchor" aria-hidden="true" href="#set_keepalive"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;set_keepalive&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: ok, err = httpc:set_keepalive(max_idle_timeout, pool_size)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Attempts to puts the current connection into the ngx_lua cosocket connection pool.&lt;/p&gt;
&lt;p&gt;You can specify the max idle timeout (in ms) when the connection is in the pool and the maximal size of the pool every nginx worker process.&lt;/p&gt;
&lt;p&gt;Only call this method in the place you would have called the &lt;code&gt;close&lt;/code&gt; method instead. Calling this method will immediately turn the current http object into the &lt;code&gt;closed&lt;/code&gt; state. Any subsequent operations other than &lt;code&gt;connect()&lt;/code&gt; on the current object will return the &lt;code&gt;closed&lt;/code&gt; error.&lt;/p&gt;
&lt;p&gt;Note that calling this instead of &lt;code&gt;close&lt;/code&gt; is "safe" in that it will conditionally close depending on the type of request. Specifically, a &lt;code&gt;1.0&lt;/code&gt; request without &lt;code&gt;Connection: Keep-Alive&lt;/code&gt; will be closed, as will a &lt;code&gt;1.1&lt;/code&gt; request with &lt;code&gt;Connection: Close&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In case of success, returns &lt;code&gt;1&lt;/code&gt;. In case of errors, returns &lt;code&gt;nil, err&lt;/code&gt;. In the case where the connection is conditionally closed as described above, returns &lt;code&gt;2&lt;/code&gt; and the error string &lt;code&gt;connection must be closed&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-set_proxy_options" class="anchor" aria-hidden="true" href="#set_proxy_options"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;set_proxy_options&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: httpc:set_proxy_options(opts)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Configure an http proxy to be used with this client instance. The &lt;code&gt;opts&lt;/code&gt; is a table that accepts the following fields:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;http_proxy&lt;/code&gt; - an URI to a proxy server to be used with http requests&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http_proxy_authorization&lt;/code&gt; - a default &lt;code&gt;Proxy-Authorization&lt;/code&gt; header value to be used with &lt;code&gt;http_proxy&lt;/code&gt;, e.g. &lt;code&gt;Basic ZGVtbzp0ZXN0&lt;/code&gt;, which will be overriden if the &lt;code&gt;Proxy-Authorization&lt;/code&gt; request header is present.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;https_proxy&lt;/code&gt; - an URI to a proxy server to be used with https requests&lt;/li&gt;
&lt;li&gt;&lt;code&gt;https_proxy_authorization&lt;/code&gt; - as &lt;code&gt;http_proxy_authorization&lt;/code&gt; but for use with &lt;code&gt;https_proxy&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;no_proxy&lt;/code&gt; - a comma separated list of hosts that should not be proxied.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that proxy options are only applied when using the high-level &lt;code&gt;request_uri()&lt;/code&gt; API.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-get_reused_times" class="anchor" aria-hidden="true" href="#get_reused_times"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;get_reused_times&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: times, err = httpc:get_reused_times()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This method returns the (successfully) reused times for the current connection. In case of error, it returns &lt;code&gt;nil&lt;/code&gt; and a string describing the error.&lt;/p&gt;
&lt;p&gt;If the current connection does not come from the built-in connection pool, then this method always returns &lt;code&gt;0&lt;/code&gt;, that is, the connection has never been reused (yet). If the connection comes from the connection pool, then the return value is always non-zero. So this method can also be used to determine if the current connection comes from the pool.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-close" class="anchor" aria-hidden="true" href="#close"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;close&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: ok, err = http:close()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Closes the current connection and returns the status.&lt;/p&gt;
&lt;p&gt;In case of success, returns &lt;code&gt;1&lt;/code&gt;. In case of errors, returns &lt;code&gt;nil&lt;/code&gt; with a string describing the error.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-requesting" class="anchor" aria-hidden="true" href="#requesting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requesting&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-request" class="anchor" aria-hidden="true" href="#request"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;request&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: res, err = httpc:request(params)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Returns a &lt;code&gt;res&lt;/code&gt; table or &lt;code&gt;nil&lt;/code&gt; and an error message.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;params&lt;/code&gt; table accepts the following fields:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;version&lt;/code&gt; The HTTP version number, currently supporting 1.0 or 1.1.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;method&lt;/code&gt; The HTTP method string.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;path&lt;/code&gt; The path string.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;query&lt;/code&gt; The query string, presented as either a literal string or Lua table..&lt;/li&gt;
&lt;li&gt;&lt;code&gt;headers&lt;/code&gt; A table of request headers.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;body&lt;/code&gt; The request body as a string, or an iterator function (see &lt;a href="#get_client_body_reader"&gt;get_client_body_reader&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ssl_verify&lt;/code&gt; Verify SSL cert matches hostname&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When the request is successful, &lt;code&gt;res&lt;/code&gt; will contain the following fields:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;status&lt;/code&gt; The status code.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reason&lt;/code&gt; The status reason phrase.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;headers&lt;/code&gt; A table of headers. Multiple headers with the same field name will be presented as a table of values.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;has_body&lt;/code&gt; A boolean flag indicating if there is a body to be read.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;body_reader&lt;/code&gt; An iterator function for reading the body in a streaming fashion.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;read_body&lt;/code&gt; A method to read the entire body into a string.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;read_trailers&lt;/code&gt; A method to merge any trailers underneath the headers, after reading the body.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-request_uri" class="anchor" aria-hidden="true" href="#request_uri"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;request_uri&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: res, err = httpc:request_uri(uri, params)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The simple interface. Options supplied in the &lt;code&gt;params&lt;/code&gt; table are the same as in the generic interface, and will override components found in the uri itself.&lt;/p&gt;
&lt;p&gt;There are 3 additional parameters for controlling keepalives:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;keepalive&lt;/code&gt; Set to &lt;code&gt;false&lt;/code&gt; to disable keepalives and immediately close the connection.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;keepalive_timeout&lt;/code&gt; The maximal idle timeout (ms). Defaults to &lt;code&gt;lua_socket_keepalive_timeout&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;keepalive_pool&lt;/code&gt; The maximum number of connections in the pool. Defaults to &lt;code&gt;lua_socket_pool_size&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this mode, there is no need to connect manually first. The connection is made on your behalf, suiting cases where you simply need to grab a URI without too much hassle.&lt;/p&gt;
&lt;p&gt;Additionally there is no ability to stream the response body in this mode. If the request is successful, &lt;code&gt;res&lt;/code&gt; will contain the following fields:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;status&lt;/code&gt; The status code.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;headers&lt;/code&gt; A table of headers.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;body&lt;/code&gt; The response body as a string.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-request_pipeline" class="anchor" aria-hidden="true" href="#request_pipeline"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;request_pipeline&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: responses, err = httpc:request_pipeline(params)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This method works as per the &lt;a href="#request"&gt;request&lt;/a&gt; method above, but &lt;code&gt;params&lt;/code&gt; is instead a table of param tables. Each request is sent in order, and &lt;code&gt;responses&lt;/code&gt; is returned as a table of response handles. For example:&lt;/p&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;local&lt;/span&gt; responses &lt;span class="pl-k"&gt;=&lt;/span&gt; httpc:&lt;span class="pl-c1"&gt;request_pipeline&lt;/span&gt;{
  {
    path &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/b&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
  },
  {
    path &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/c&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
  },
  {
    path &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/d&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
  }
}

&lt;span class="pl-k"&gt;for&lt;/span&gt; i,r &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;ipairs&lt;/span&gt;(responses) &lt;span class="pl-k"&gt;do&lt;/span&gt;
  &lt;span class="pl-k"&gt;if&lt;/span&gt; r.&lt;span class="pl-smi"&gt;status&lt;/span&gt; &lt;span class="pl-k"&gt;then&lt;/span&gt;
    ngx.&lt;span class="pl-c1"&gt;say&lt;/span&gt;(r.&lt;span class="pl-smi"&gt;status&lt;/span&gt;)
    ngx.&lt;span class="pl-c1"&gt;say&lt;/span&gt;(r:&lt;span class="pl-c1"&gt;read_body&lt;/span&gt;())
  &lt;span class="pl-k"&gt;end&lt;/span&gt;
&lt;span class="pl-k"&gt;end&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Due to the nature of pipelining, no responses are actually read until you attempt to use the response fields (status / headers etc). And since the responses are read off in order, you must read the entire body (and any trailers if you have them), before attempting to read the next response.&lt;/p&gt;
&lt;p&gt;Note this doesn't preclude the use of the streaming response body reader. Responses can still be streamed, so long as the entire body is streamed before attempting to access the next response.&lt;/p&gt;
&lt;p&gt;Be sure to test at least one field (such as status) before trying to use the others, in case a socket read error has occurred.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-response" class="anchor" aria-hidden="true" href="#response"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Response&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-resbody_reader" class="anchor" aria-hidden="true" href="#resbody_reader"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;res.body_reader&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;body_reader&lt;/code&gt; iterator can be used to stream the response body in chunk sizes of your choosing, as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;local&lt;/span&gt; reader &lt;span class="pl-k"&gt;=&lt;/span&gt; res.&lt;span class="pl-smi"&gt;body_reader&lt;/span&gt;

&lt;span class="pl-k"&gt;repeat&lt;/span&gt;
  &lt;span class="pl-k"&gt;local&lt;/span&gt; chunk, err &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;reader&lt;/span&gt;(&lt;span class="pl-c1"&gt;8192&lt;/span&gt;)
  &lt;span class="pl-k"&gt;if&lt;/span&gt; err &lt;span class="pl-k"&gt;then&lt;/span&gt;
    ngx.&lt;span class="pl-c1"&gt;log&lt;/span&gt;(ngx.&lt;span class="pl-smi"&gt;ERR&lt;/span&gt;, err)
    &lt;span class="pl-k"&gt;break&lt;/span&gt;
  &lt;span class="pl-k"&gt;end&lt;/span&gt;

  &lt;span class="pl-k"&gt;if&lt;/span&gt; chunk &lt;span class="pl-k"&gt;then&lt;/span&gt;
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;--&lt;/span&gt; process&lt;/span&gt;
  &lt;span class="pl-k"&gt;end&lt;/span&gt;
&lt;span class="pl-k"&gt;until&lt;/span&gt; &lt;span class="pl-k"&gt;not&lt;/span&gt; chunk&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If the reader is called with no arguments, the behaviour depends on the type of connection. If the response is encoded as chunked, then the iterator will return the chunks as they arrive. If not, it will simply return the entire body.&lt;/p&gt;
&lt;p&gt;Note that the size provided is actually a &lt;strong&gt;maximum&lt;/strong&gt; size. So in the chunked transfer case, you may get chunks smaller than the size you ask, as a remainder of the actual HTTP chunks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-resread_body" class="anchor" aria-hidden="true" href="#resread_body"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;res:read_body&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: body, err = res:read_body()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Reads the entire body into a local string.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-resread_trailers" class="anchor" aria-hidden="true" href="#resread_trailers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;res:read_trailers&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: res:read_trailers()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This merges any trailers underneath the &lt;code&gt;res.headers&lt;/code&gt; table itself. Must be called after reading the body.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-proxy" class="anchor" aria-hidden="true" href="#proxy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Proxy&lt;/h1&gt;
&lt;p&gt;There are two convenience methods for when one simply wishes to proxy the current request to the connected upstream, and safely send it downstream to the client, as a reverse proxy. A complete example:&lt;/p&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;local&lt;/span&gt; http &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;require&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;resty.http&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;local&lt;/span&gt; httpc &lt;span class="pl-k"&gt;=&lt;/span&gt; http.&lt;span class="pl-c1"&gt;new&lt;/span&gt;()

httpc:&lt;span class="pl-c1"&gt;set_timeout&lt;/span&gt;(&lt;span class="pl-c1"&gt;500&lt;/span&gt;)
&lt;span class="pl-k"&gt;local&lt;/span&gt; ok, err &lt;span class="pl-k"&gt;=&lt;/span&gt; httpc:&lt;span class="pl-c1"&gt;connect&lt;/span&gt;(HOST, PORT)

&lt;span class="pl-k"&gt;if&lt;/span&gt; &lt;span class="pl-k"&gt;not&lt;/span&gt; ok &lt;span class="pl-k"&gt;then&lt;/span&gt;
  ngx.&lt;span class="pl-c1"&gt;log&lt;/span&gt;(ngx.&lt;span class="pl-smi"&gt;ERR&lt;/span&gt;, err)
  &lt;span class="pl-k"&gt;return&lt;/span&gt;
&lt;span class="pl-k"&gt;end&lt;/span&gt;

httpc:&lt;span class="pl-c1"&gt;set_timeout&lt;/span&gt;(&lt;span class="pl-c1"&gt;2000&lt;/span&gt;)
httpc:&lt;span class="pl-c1"&gt;proxy_response&lt;/span&gt;(httpc:&lt;span class="pl-c1"&gt;proxy_request&lt;/span&gt;())
httpc:&lt;span class="pl-c1"&gt;set_keepalive&lt;/span&gt;()&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-proxy_request" class="anchor" aria-hidden="true" href="#proxy_request"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;proxy_request&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: local res, err = httpc:proxy_request(request_body_chunk_size?)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Performs a request using the current client request arguments, effectively proxying to the connected upstream. The request body will be read in a streaming fashion, according to &lt;code&gt;request_body_chunk_size&lt;/code&gt; (see &lt;a href="#get_client_body_reader"&gt;documentation on the client body reader&lt;/a&gt; below).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-proxy_response" class="anchor" aria-hidden="true" href="#proxy_response"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;proxy_response&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: httpc:proxy_response(res, chunksize?)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Sets the current response based on the given &lt;code&gt;res&lt;/code&gt;. Ensures that hop-by-hop headers are not sent downstream, and will read the response according to &lt;code&gt;chunksize&lt;/code&gt; (see &lt;a href="#resbody_reader"&gt;documentation on the body reader&lt;/a&gt; above).&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-utility" class="anchor" aria-hidden="true" href="#utility"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Utility&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-parse_uri" class="anchor" aria-hidden="true" href="#parse_uri"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;parse_uri&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: local scheme, host, port, path, query? = unpack(httpc:parse_uri(uri, query_in_path?))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This is a convenience function allowing one to more easily use the generic interface, when the input data is a URI.&lt;/p&gt;
&lt;p&gt;As of version &lt;code&gt;0.10&lt;/code&gt;, the optional &lt;code&gt;query_in_path&lt;/code&gt; parameter was added, which specifies whether the querystring is to be included in the &lt;code&gt;path&lt;/code&gt; return value, or separately as its own return value. This defaults to &lt;code&gt;true&lt;/code&gt; in order to maintain backwards compatibility. When set to &lt;code&gt;false&lt;/code&gt;, &lt;code&gt;path&lt;/code&gt; will only include the path, and &lt;code&gt;query&lt;/code&gt; will contain the URI args, not including the &lt;code&gt;?&lt;/code&gt; delimiter.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-get_client_body_reader" class="anchor" aria-hidden="true" href="#get_client_body_reader"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;get_client_body_reader&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: reader, err = httpc:get_client_body_reader(chunksize?, sock?)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Returns an iterator function which can be used to read the downstream client request body in a streaming fashion. You may also specify an optional default chunksize (default is &lt;code&gt;65536&lt;/code&gt;), or an already established socket in
place of the client request.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;local&lt;/span&gt; req_reader &lt;span class="pl-k"&gt;=&lt;/span&gt; httpc:&lt;span class="pl-c1"&gt;get_client_body_reader&lt;/span&gt;()

&lt;span class="pl-k"&gt;repeat&lt;/span&gt;
  &lt;span class="pl-k"&gt;local&lt;/span&gt; chunk, err &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;req_reader&lt;/span&gt;(&lt;span class="pl-c1"&gt;8192&lt;/span&gt;)
  &lt;span class="pl-k"&gt;if&lt;/span&gt; err &lt;span class="pl-k"&gt;then&lt;/span&gt;
    ngx.&lt;span class="pl-c1"&gt;log&lt;/span&gt;(ngx.&lt;span class="pl-smi"&gt;ERR&lt;/span&gt;, err)
    &lt;span class="pl-k"&gt;break&lt;/span&gt;
  &lt;span class="pl-k"&gt;end&lt;/span&gt;

  &lt;span class="pl-k"&gt;if&lt;/span&gt; chunk &lt;span class="pl-k"&gt;then&lt;/span&gt;
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;--&lt;/span&gt; process&lt;/span&gt;
  &lt;span class="pl-k"&gt;end&lt;/span&gt;
&lt;span class="pl-k"&gt;until&lt;/span&gt; &lt;span class="pl-k"&gt;not&lt;/span&gt; chunk&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This iterator can also be used as the value for the body field in request params, allowing one to stream the request body into a proxied upstream request.&lt;/p&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;local&lt;/span&gt; client_body_reader, err &lt;span class="pl-k"&gt;=&lt;/span&gt; httpc:&lt;span class="pl-c1"&gt;get_client_body_reader&lt;/span&gt;()

&lt;span class="pl-k"&gt;local&lt;/span&gt; res, err &lt;span class="pl-k"&gt;=&lt;/span&gt; httpc:&lt;span class="pl-c1"&gt;request&lt;/span&gt;{
   path &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/helloworld&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
   body &lt;span class="pl-k"&gt;=&lt;/span&gt; client_body_reader,
}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If &lt;code&gt;sock&lt;/code&gt; is specified,&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-author" class="anchor" aria-hidden="true" href="#author"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Author&lt;/h1&gt;
&lt;p&gt;James Hurst &lt;a href="mailto:james@pintsized.co.uk"&gt;james@pintsized.co.uk&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Originally started life based on &lt;a href="https://github.com/bakins/lua-resty-http-simple"&gt;https://github.com/bakins/lua-resty-http-simple&lt;/a&gt;. Cosocket docs and implementation borrowed from the other lua-resty-* cosocket modules.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-licence" class="anchor" aria-hidden="true" href="#licence"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Licence&lt;/h1&gt;
&lt;p&gt;This module is licensed under the 2-clause BSD license.&lt;/p&gt;
&lt;p&gt;Copyright (c) 2013-2016, James Hurst &lt;a href="mailto:james@pintsized.co.uk"&gt;james@pintsized.co.uk&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All rights reserved.&lt;/p&gt;
&lt;p&gt;Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ledgetech</author><guid isPermaLink="false">https://github.com/ledgetech/lua-resty-http</guid><pubDate>Fri, 08 Nov 2019 00:16:00 GMT</pubDate></item></channel></rss>