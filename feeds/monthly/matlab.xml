<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: MATLAB, This month</title><link>https://github.com/trending/matlab?since=monthly</link><description>The top repositories on GitHub for matlab, measured monthly</description><pubDate>Wed, 08 Jan 2020 01:08:37 GMT</pubDate><lastBuildDate>Wed, 08 Jan 2020 01:08:37 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>Borye/machine-learning-coursera-1 #1 in MATLAB, This month</title><link>https://github.com/Borye/machine-learning-coursera-1</link><description>&lt;p&gt;&lt;i&gt;This repo is specially created for all the work done my me as a part of Coursera's Machine Learning Course.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-coursera" class="anchor" aria-hidden="true" href="#machine-learning-coursera"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;machine-learning-coursera&lt;/h1&gt;
&lt;p&gt;This repo is specially created for all the work done my me as a part of Coursera's Machine Learning Course.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Borye</author><guid isPermaLink="false">https://github.com/Borye/machine-learning-coursera-1</guid><pubDate>Wed, 08 Jan 2020 00:01:00 GMT</pubDate></item><item><title>atinesh-s/Coursera-Machine-Learning-Stanford #2 in MATLAB, This month</title><link>https://github.com/atinesh-s/Coursera-Machine-Learning-Stanford</link><description>&lt;p&gt;&lt;i&gt;Machine learning-Stanford University&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-coursera" class="anchor" aria-hidden="true" href="#machine-learning-coursera"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning (Coursera)&lt;/h1&gt;
&lt;p&gt;This is my solution to all the programming assignments and quizzes of Machine-Learning (Coursera) taught by Andrew Ng. After completing this course you will get a broad idea of Machine learning algorithms. Try to solve all the assignments by yourself first, but if you get stuck somewhere then feel free to browse the code.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Lectures Slides&lt;/li&gt;
&lt;li&gt;Solution to programming assignment&lt;/li&gt;
&lt;li&gt;Solution to Quizzes&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-certificate" class="anchor" aria-hidden="true" href="#certificate"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Certificate&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/account/accomplishments/certificate/GDDBFB572MUQ" rel="nofollow"&gt;Verified Certificate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-references" class="anchor" aria-hidden="true" href="#references"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.coursera.org/learn/machine-learning" rel="nofollow"&gt;[1] Machine Learning - Stanford University&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>atinesh-s</author><guid isPermaLink="false">https://github.com/atinesh-s/Coursera-Machine-Learning-Stanford</guid><pubDate>Wed, 08 Jan 2020 00:02:00 GMT</pubDate></item><item><title>HuangCongQing/Algorithms_MathModels #3 in MATLAB, This month</title><link>https://github.com/HuangCongQing/Algorithms_MathModels</link><description>&lt;p&gt;&lt;i&gt;【国赛】【美赛】数学建模相关算法 MATLAB实现（2018年初整理）&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-algorithms_mathmodels" class="anchor" aria-hidden="true" href="#algorithms_mathmodels"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Algorithms_MathModels&lt;/h1&gt;
&lt;p&gt;数学建模相关算法 MATLAB实现&lt;/p&gt;
&lt;p&gt;Fork或借鉴请注明出处 &lt;a href="https://github.com/HuangCongQing"&gt;@ChungKing&lt;/a&gt; . Thx&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;国赛论文资料： 链接：&lt;a href="https://pan.baidu.com/s/1xz8kbFauskpzenlgv4koiQ" rel="nofollow"&gt;https://pan.baidu.com/s/1xz8kbFauskpzenlgv4koiQ&lt;/a&gt;
提取码：3kjt&lt;/li&gt;
&lt;li&gt;美赛资料：链接：&lt;a href="https://github.com/HuangCongQing/Algorithms_MathModels/issues/2#issuecomment-565820094"&gt;https://github.com/HuangCongQing/Algorithms_MathModels/issues/2#issuecomment-565820094&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;数模学习视频：链接：&lt;a href="https://pan.baidu.com/s/1TcL5q1he6YfYFNBi9ZzSlw" rel="nofollow"&gt;https://pan.baidu.com/s/1TcL5q1he6YfYFNBi9ZzSlw&lt;/a&gt;
提取码：osbm&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;本项目为数学建模竞赛中所学习使用的相关算法的MATLAB实现。部分参考于&lt;a href="https://github.com/NarcissusHliangZhao/Algorithm_Implementation_in_MatModel"&gt;NarcissusHliangZhao&lt;/a&gt; 。Thanks。 具体内容包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;《MATLAB 神经网络30个案例分析》&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;《基于MATLAB的高等数学问题求解》&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;模拟退火算法-最优路径&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;层次分析法(AHP)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;元胞自动机(Cellular Automata)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;模糊数学模型(Fuzzy Mathematical Model&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;目标规划(Goal Programming)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;图论(Graph Theory)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;灰色系统建模(Grey System)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;启发式算法(Heuristic Algorithm)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;免疫算法(Immune Algorithm)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;整数规划(Integer Programming)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;《MATLAB智能算法案例》(Intelligence Algorithm)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;插值(Interpolation)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;线性规划(Linear Programming)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多元分析(Multivarite Analysis)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;神经网络(Neural Network)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;非线性规划(Non Linear Programming)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;常微分方程(Oridinary Differential Equation)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;偏微分方程(Partial Differential Equation)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;偏最小二乘法(Partial Least Squares)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;《模式识别与机器学习》(Pattern Recognition and Machine Learning)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;回归分析(Regression Analysis)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;时间序列模型(Time Series)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-下载单个文件夹或文件" class="anchor" aria-hidden="true" href="#下载单个文件夹或文件"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;下载单个文件夹或文件&lt;/h5&gt;
&lt;p&gt;&lt;a href="http://downgit.zhoudaxiaa.com/" rel="nofollow"&gt;http://downgit.zhoudaxiaa.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;将github文件夹或文件&lt;strong&gt;链接&lt;/strong&gt;复制粘贴入DownGit中，选择download即可;&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;&lt;a id="user-content-related-links" class="anchor" aria-hidden="true" href="#related-links"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Related links&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/19714813/answer/18748623" rel="nofollow"&gt;如何入门参与&lt;em&gt;数学建模&lt;/em&gt;？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;论坛——&lt;a href="http://www.mathor.com/forum.php" rel="nofollow"&gt;校苑数模|数学建模&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-大学生相关" class="anchor" aria-hidden="true" href="#大学生相关"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;大学生相关&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/J2r4WQ3GFUy_t0mNe_s5IA" rel="nofollow"&gt;给我们大学生推荐的自学网站（App）&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/kWJi___BTCdj5STTxaAz8Q" rel="nofollow"&gt;大学毕业生采访&amp;amp;&amp;amp;大学四年总结分享&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;希望对大家有所帮助！&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LICENSE&lt;/h3&gt;
&lt;p&gt;本项目全部内容遵守 MIT 许可协议.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0cf016a535bd9d48eeddd9a867838339defd455a/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f343334303737322d313539363566646135636465303238312e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430"&gt;&lt;img src="https://camo.githubusercontent.com/0cf016a535bd9d48eeddd9a867838339defd455a/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f343334303737322d313539363566646135636465303238312e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430" alt="" data-canonical-src="https://upload-images.jianshu.io/upload_images/4340772-15965fda5cde0281.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>HuangCongQing</author><guid isPermaLink="false">https://github.com/HuangCongQing/Algorithms_MathModels</guid><pubDate>Wed, 08 Jan 2020 00:03:00 GMT</pubDate></item><item><title>luanfujun/deep-photo-styletransfer #4 in MATLAB, This month</title><link>https://github.com/luanfujun/deep-photo-styletransfer</link><description>&lt;p&gt;&lt;i&gt;Code and data for paper "Deep Photo Style Transfer": https://arxiv.org/abs/1703.07511 &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deep-photo-styletransfer" class="anchor" aria-hidden="true" href="#deep-photo-styletransfer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;deep-photo-styletransfer&lt;/h1&gt;
&lt;p&gt;Code and data for paper "&lt;a href="https://arxiv.org/abs/1703.07511" rel="nofollow"&gt;Deep Photo Style Transfer&lt;/a&gt;"&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;This software is published for academic and non-commercial use only.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h2&gt;
&lt;p&gt;This code is based on torch. It has been tested on Ubuntu 14.04 LTS.&lt;/p&gt;
&lt;p&gt;Dependencies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/torch/torch7"&gt;Torch&lt;/a&gt; (with &lt;a href="https://github.com/soumith/matio-ffi.torch"&gt;matio-ffi&lt;/a&gt; and &lt;a href="https://github.com/szagoruyko/loadcaffe"&gt;loadcaffe&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mathworks.com/" rel="nofollow"&gt;Matlab&lt;/a&gt; or &lt;a href="https://www.gnu.org/software/octave/" rel="nofollow"&gt;Octave&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CUDA backend:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://developer.nvidia.com/cuda-downloads" rel="nofollow"&gt;CUDA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.nvidia.com/cudnn" rel="nofollow"&gt;cudnn&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Download VGG-19:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sh models/download_models.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compile &lt;code&gt;cuda_utils.cu&lt;/code&gt; (Adjust &lt;code&gt;PREFIX&lt;/code&gt; and &lt;code&gt;NVCC_PREFIX&lt;/code&gt; in &lt;code&gt;makefile&lt;/code&gt; for your machine):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;make clean &amp;amp;&amp;amp; make
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick start&lt;/h3&gt;
&lt;p&gt;To generate all results (in &lt;code&gt;examples/&lt;/code&gt;) using the provided scripts, simply run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;run('gen_laplacian/gen_laplacian.m')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in Matlab or Octave and then&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python gen_all.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in Python. The final output will be in &lt;code&gt;examples/final_results/&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Basic usage&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Given input and style images with semantic segmentation masks, put them in &lt;code&gt;examples/&lt;/code&gt; respectively. They will have the following filename form: &lt;code&gt;examples/input/in&amp;lt;id&amp;gt;.png&lt;/code&gt;, &lt;code&gt;examples/style/tar&amp;lt;id&amp;gt;.png&lt;/code&gt; and &lt;code&gt;examples/segmentation/in&amp;lt;id&amp;gt;.png&lt;/code&gt;, &lt;code&gt;examples/segmentation/tar&amp;lt;id&amp;gt;.png&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;Compute the matting Laplacian matrix using &lt;code&gt;gen_laplacian/gen_laplacian.m&lt;/code&gt; in Matlab. The output matrix will have the following filename form: &lt;code&gt;gen_laplacian/Input_Laplacian_3x3_1e-7_CSR&amp;lt;id&amp;gt;.mat&lt;/code&gt;;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Note: Please make sure that the content image resolution is consistent for Matting Laplacian computation in Matlab and style transfer in Torch, otherwise the result won't be correct.&lt;/strong&gt;&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Run the following script to generate segmented intermediate result:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;th neuralstyle_seg.lua -content_image &amp;lt;input&amp;gt; -style_image &amp;lt;style&amp;gt; -content_seg &amp;lt;inputMask&amp;gt; -style_seg &amp;lt;styleMask&amp;gt; -index &amp;lt;id&amp;gt; -serial &amp;lt;intermediate_folder&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="4"&gt;
&lt;li&gt;Run the following script to generate final result:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;th deepmatting_seg.lua -content_image &amp;lt;input&amp;gt; -style_image &amp;lt;style&amp;gt; -content_seg &amp;lt;inputMask&amp;gt; -style_seg &amp;lt;styleMask&amp;gt; -index &amp;lt;id&amp;gt; -init_image &amp;lt;intermediate_folder/out&amp;lt;id&amp;gt;_t_1000.png&amp;gt; -serial &amp;lt;final_folder&amp;gt; -f_radius 15 -f_edge 0.01
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can pass &lt;code&gt;-backend cudnn&lt;/code&gt; and &lt;code&gt;-cudnn_autotune&lt;/code&gt; to both Lua scripts (step 3.
and 4.) to potentially improve speed and memory usage. &lt;code&gt;libcudnn.so&lt;/code&gt; must be in
your &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt;. This requires &lt;a href="https://github.com/soumith/cudnn.torch"&gt;cudnn.torch&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-image-segmentation" class="anchor" aria-hidden="true" href="#image-segmentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image segmentation&lt;/h3&gt;
&lt;p&gt;Note: In the main paper we generate all comparison results using automatic scene segmentation algorithm modified from &lt;a href="https://arxiv.org/abs/1606.00915" rel="nofollow"&gt;DilatedNet&lt;/a&gt;. Manual segmentation enables more diverse tasks hence we provide the masks in &lt;code&gt;examples/segmentation/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The mask colors we used (you could add more colors in &lt;code&gt;ExtractMask&lt;/code&gt; function in two &lt;code&gt;*.lua&lt;/code&gt; files):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Color variable&lt;/th&gt;
&lt;th&gt;RGB Value&lt;/th&gt;
&lt;th&gt;Hex Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;blue&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0 0 255&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0000ff&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;green&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0 255 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;00ff00&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;black&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0 0 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;000000&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;white&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;255 255 255&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ffffff&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;red&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;255 0 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ff0000&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;yellow&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;255 255 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ffff00&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;grey&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;128 128 128&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;808080&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;lightblue&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0 255 255&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;00ffff&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;purple&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;255 0 255&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ff00ff &lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here are some automatic and manual tools for creating a segmentation mask for a photo image:&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-automatic" class="anchor" aria-hidden="true" href="#automatic"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Automatic:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://sceneparsing.csail.mit.edu/" rel="nofollow"&gt;MIT Scene Parsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.unc.edu/~jtighe/Papers/ECCV10/" rel="nofollow"&gt;SuperParsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://people.csail.mit.edu/celiu/LabelTransfer/" rel="nofollow"&gt;Nonparametric Scene Parsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html" rel="nofollow"&gt;Berkeley Contour Detection and Image Segmentation Resources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/torrvision/crfasrnn"&gt;CRF-RNN for Semantic Image Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/belltailjp/selective_search_py"&gt;Selective Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DrSleep/tensorflow-deeplab-lfov"&gt;DeepLab-TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-manual" class="anchor" aria-hidden="true" href="#manual"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Manual:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://helpx.adobe.com/photoshop/using/making-quick-selections.html" rel="nofollow"&gt;Photoshop Quick Selection Tool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.gimp.org/en/gimp-tools-selection.html" rel="nofollow"&gt;GIMP Selection Tool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://gmic.eu/gimp.shtml" rel="nofollow"&gt;GIMP G'MIC Interactive Foreground Extraction tool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;p&gt;Here are some results from our algorithm (from left to right are input, style and our output):&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in3.png"&gt;&lt;img src="examples/input/in3.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar3.png"&gt;&lt;img src="examples/style/tar3.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_3.png"&gt;&lt;img src="examples/refine_posterization/refine_3.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in4.png"&gt;&lt;img src="examples/input/in4.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar4.png"&gt;&lt;img src="examples/style/tar4.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_4.png"&gt;&lt;img src="examples/refine_posterization/refine_4.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in13.png"&gt;&lt;img src="examples/input/in13.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar13.png"&gt;&lt;img src="examples/style/tar13.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_13.png"&gt;&lt;img src="examples/refine_posterization/refine_13.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in9.png"&gt;&lt;img src="examples/input/in9.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar9.png"&gt;&lt;img src="examples/style/tar9.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_9.png"&gt;&lt;img src="examples/refine_posterization/refine_9.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in20.png"&gt;&lt;img src="examples/input/in20.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar20.png"&gt;&lt;img src="examples/style/tar20.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_20.png"&gt;&lt;img src="examples/refine_posterization/refine_20.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in1.png"&gt;&lt;img src="examples/input/in1.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar1.png"&gt;&lt;img src="examples/style/tar1.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_1.png"&gt;&lt;img src="examples/refine_posterization/refine_1.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in39.png"&gt;&lt;img src="examples/input/in39.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar39.png"&gt;&lt;img src="examples/style/tar39.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_39.png"&gt;&lt;img src="examples/refine_posterization/refine_39.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in57.png"&gt;&lt;img src="examples/input/in57.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar57.png"&gt;&lt;img src="examples/style/tar57.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_57.png"&gt;&lt;img src="examples/refine_posterization/refine_57.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in47.png"&gt;&lt;img src="examples/input/in47.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar47.png"&gt;&lt;img src="examples/style/tar47.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_47.png"&gt;&lt;img src="examples/refine_posterization/refine_47.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in58.png"&gt;&lt;img src="examples/input/in58.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar58.png"&gt;&lt;img src="examples/style/tar58.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_58.png"&gt;&lt;img src="examples/refine_posterization/refine_58.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in51.png"&gt;&lt;img src="examples/input/in51.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar51.png"&gt;&lt;img src="examples/style/tar51.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_51.png"&gt;&lt;img src="examples/refine_posterization/refine_51.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in7.png"&gt;&lt;img src="examples/input/in7.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar7.png"&gt;&lt;img src="examples/style/tar7.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_7.png"&gt;&lt;img src="examples/refine_posterization/refine_7.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in23.png"&gt;&lt;img src="examples/input/in23.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in23.png"&gt;&lt;img src="examples/input/in23.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/final_results/best23_t_1000.png"&gt;&lt;img src="examples/final_results/best23_t_1000.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in16.png"&gt;&lt;img src="examples/input/in16.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar16.png"&gt;&lt;img src="examples/style/tar16.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_16.png"&gt;&lt;img src="examples/refine_posterization/refine_16.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in30.png"&gt;&lt;img src="examples/input/in30.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar30.png"&gt;&lt;img src="examples/style/tar30.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_30.png"&gt;&lt;img src="examples/refine_posterization/refine_30.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in2.png"&gt;&lt;img src="examples/input/in2.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar2.png"&gt;&lt;img src="examples/style/tar2.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/final_results/best2_t_1000.png"&gt;&lt;img src="examples/final_results/best2_t_1000.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in11.png"&gt;&lt;img src="examples/input/in11.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar11.png"&gt;&lt;img src="examples/style/tar11.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_11.png"&gt;&lt;img src="examples/refine_posterization/refine_11.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgement" class="anchor" aria-hidden="true" href="#acknowledgement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgement&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Our torch implementation is based on Justin Johnson's &lt;a href="https://github.com/jcjohnson/neural-style"&gt;code&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;We use Anat Levin's Matlab &lt;a href="http://www.wisdom.weizmann.ac.il/~levina/matting.tar.gz" rel="nofollow"&gt;code&lt;/a&gt; to compute the matting Laplacian matrix.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you find this work useful for your research, please cite:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{luan2017deep,
  title={Deep Photo Style Transfer},
  author={Luan, Fujun and Paris, Sylvain and Shechtman, Eli and Bala, Kavita},
  journal={arXiv preprint arXiv:1703.07511},
  year={2017}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h2&gt;
&lt;p&gt;Feel free to contact me if there is any question (Fujun Luan &lt;a href="mailto:fl356@cornell.edu"&gt;fl356@cornell.edu&lt;/a&gt;).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>luanfujun</author><guid isPermaLink="false">https://github.com/luanfujun/deep-photo-styletransfer</guid><pubDate>Wed, 08 Jan 2020 00:04:00 GMT</pubDate></item><item><title>AvaisP/machine-learning-programming-assignments-coursera-andrew-ng #5 in MATLAB, This month</title><link>https://github.com/AvaisP/machine-learning-programming-assignments-coursera-andrew-ng</link><description>&lt;p&gt;&lt;i&gt;Solutions to Andrew NG's machine learning course on Coursera&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-programming-assignments-coursera-andrew-ng" class="anchor" aria-hidden="true" href="#machine-learning-programming-assignments-coursera-andrew-ng"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;machine-learning-programming-assignments-coursera-andrew-ng&lt;/h1&gt;
&lt;p&gt;Solutions to Andrew NG's machine learning course on Coursera&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>AvaisP</author><guid isPermaLink="false">https://github.com/AvaisP/machine-learning-programming-assignments-coursera-andrew-ng</guid><pubDate>Wed, 08 Jan 2020 00:05:00 GMT</pubDate></item></channel></rss>