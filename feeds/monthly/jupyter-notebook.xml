<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Jupyter Notebook, This month</title><link>https://github.com/trending/jupyter-notebook?since=monthly</link><description>The top repositories on GitHub for jupyter-notebook, measured monthly</description><pubDate>Tue, 04 Feb 2020 01:05:37 GMT</pubDate><lastBuildDate>Tue, 04 Feb 2020 01:05:37 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>CoreyMSchafer/code_snippets #1 in Jupyter Notebook, This month</title><link>https://github.com/CoreyMSchafer/code_snippets</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-code_snippets" class="anchor" aria-hidden="true" href="#code_snippets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;code_snippets&lt;/h1&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>CoreyMSchafer</author><guid isPermaLink="false">https://github.com/CoreyMSchafer/code_snippets</guid><pubDate>Tue, 04 Feb 2020 00:01:00 GMT</pubDate></item><item><title>lexfridman/mit-deep-learning #2 in Jupyter Notebook, This month</title><link>https://github.com/lexfridman/mit-deep-learning</link><description>&lt;p&gt;&lt;i&gt;Tutorials, assignments, and competitions for MIT Deep Learning related courses.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-mit-deep-learning" class="anchor" aria-hidden="true" href="#mit-deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MIT Deep Learning&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://deeplearning.mit.edu/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/42d3d635cdb0e88dee786c6edc1f41e0902faa2b/68747470733a2f2f646565706c6561726e696e672e6d69742e6564752f66696c65732f696d616765732f6d69745f646565705f6c6561726e696e672e706e67" data-canonical-src="https://deeplearning.mit.edu/files/images/mit_deep_learning.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repository is a collection of tutorials for &lt;a href="https://deeplearning.mit.edu/" rel="nofollow"&gt;MIT Deep Learning&lt;/a&gt; courses. More added as courses progress.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tutorial-deep-learning-basics" class="anchor" aria-hidden="true" href="#tutorial-deep-learning-basics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorial: Deep Learning Basics&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb"&gt;&lt;img src="https://camo.githubusercontent.com/0d2d7920619e3df257f1c677431968ff491a5e80/68747470733a2f2f692e696d6775722e636f6d2f6a3446714275522e676966" data-canonical-src="https://i.imgur.com/j4FqBuR.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tutorial accompanies the &lt;a href="https://www.youtube.com/watch?list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf&amp;amp;v=O5xeyoRL95U" rel="nofollow"&gt;lecture on Deep Learning Basics&lt;/a&gt;. It presents several concepts in deep learning, demonstrating the first two (feed forward and convolutional neural networks) and providing pointers to tutorials on the others. This is a good place to start.&lt;/p&gt;
&lt;p&gt;Links: [ &lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb"&gt;Jupyter Notebook&lt;/a&gt; ]
[ &lt;a href="https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb" rel="nofollow"&gt;Google Colab&lt;/a&gt; ]
[ &lt;a href="https://medium.com/tensorflow/mit-deep-learning-basics-introduction-and-overview-with-tensorflow-355bcd26baf0" rel="nofollow"&gt;Blog Post&lt;/a&gt; ]
[ &lt;a href="https://www.youtube.com/watch?list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf&amp;amp;v=O5xeyoRL95U" rel="nofollow"&gt;Lecture Video&lt;/a&gt; ]&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tutorial-driving-scene-segmentation" class="anchor" aria-hidden="true" href="#tutorial-driving-scene-segmentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorial: Driving Scene Segmentation&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_driving_scene_segmentation/tutorial_driving_scene_segmentation.ipynb"&gt;&lt;img src="images/thumb_driving_scene_segmentation.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tutorial demostrates semantic segmentation with a state-of-the-art model (DeepLab) on a sample video from the MIT Driving Scene Segmentation Dataset.&lt;/p&gt;
&lt;p&gt;Links: [ &lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_driving_scene_segmentation/tutorial_driving_scene_segmentation.ipynb"&gt;Jupyter Notebook&lt;/a&gt; ]
[ &lt;a href="https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_driving_scene_segmentation/tutorial_driving_scene_segmentation.ipynb" rel="nofollow"&gt;Google Colab&lt;/a&gt; ]&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tutorial-generative-adversarial-networks-gans" class="anchor" aria-hidden="true" href="#tutorial-generative-adversarial-networks-gans"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorial: Generative Adversarial Networks (GANs)&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_gans/tutorial_gans.ipynb"&gt;&lt;img src="images/thumb_mushroom_biggan.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tutorial explores generative adversarial networks (GANs) starting with BigGAN, the state-of-the-art conditional GAN.&lt;/p&gt;
&lt;p&gt;Links: [ &lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_gans/tutorial_gans.ipynb"&gt;Jupyter Notebook&lt;/a&gt; ]
[ &lt;a href="https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_gans/tutorial_gans.ipynb" rel="nofollow"&gt;Google Colab&lt;/a&gt; ]&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-deeptraffic-deep-reinforcement-learning-competition" class="anchor" aria-hidden="true" href="#deeptraffic-deep-reinforcement-learning-competition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DeepTraffic Deep Reinforcement Learning Competition&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://selfdrivingcars.mit.edu/deeptraffic" rel="nofollow"&gt;&lt;img src="images/thumb_deeptraffic.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;DeepTraffic is a deep reinforcement learning competition. The goal is to create a neural network that drives a vehicle (or multiple vehicles) as fast as possible through dense highway traffic.&lt;/p&gt;
&lt;p&gt;Links: [ &lt;a href="https://github.com/lexfridman/deeptraffic"&gt;GitHub&lt;/a&gt; ] [ &lt;a href="https://selfdrivingcars.mit.edu/deeptraffic" rel="nofollow"&gt;Website&lt;/a&gt; ] [ &lt;a href="https://arxiv.org/abs/1801.02805" rel="nofollow"&gt;Paper&lt;/a&gt; ]&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-team" class="anchor" aria-hidden="true" href="#team"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Team&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://lexfridman.com" rel="nofollow"&gt;Lex Fridman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~liding/" rel="nofollow"&gt;Li Ding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~jterwill/" rel="nofollow"&gt;Jack Terwilliger&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~glazermi/" rel="nofollow"&gt;Michael Glazer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~patsekin/" rel="nofollow"&gt;Aleksandr Patsekin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~aishni/" rel="nofollow"&gt;Aishni Parab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~aladawy/" rel="nofollow"&gt;Dina AlAdawy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~henris/" rel="nofollow"&gt;Henri Schmidt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>lexfridman</author><guid isPermaLink="false">https://github.com/lexfridman/mit-deep-learning</guid><pubDate>Tue, 04 Feb 2020 00:02:00 GMT</pubDate></item><item><title>ageron/handson-ml2 #3 in Jupyter Notebook, This month</title><link>https://github.com/ageron/handson-ml2</link><description>&lt;p&gt;&lt;i&gt;A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-notebooks" class="anchor" aria-hidden="true" href="#machine-learning-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning Notebooks&lt;/h1&gt;
&lt;p&gt;This project aims at teaching you the fundamentals of Machine Learning in
python. It contains the example code and solutions to the exercises in the second edition of my O'Reilly book &lt;a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/" rel="nofollow"&gt;Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/bdec1a5ed5a56e2ab3fc0c4decda7081bd62d662/68747470733a2f2f696d616765732d6e612e73736c2d696d616765732d616d617a6f6e2e636f6d2f696d616765732f492f353161715963315179724c2e5f53583337395f424f312c3230342c3230332c3230305f2e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/bdec1a5ed5a56e2ab3fc0c4decda7081bd62d662/68747470733a2f2f696d616765732d6e612e73736c2d696d616765732d616d617a6f6e2e636f6d2f696d616765732f492f353161715963315179724c2e5f53583337395f424f312c3230342c3230332c3230305f2e6a7067" title="book" width="150" data-canonical-src="https://images-na.ssl-images-amazon.com/images/I/51aqYc1QyrL._SX379_BO1,204,203,200_.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you are looking for the first edition notebooks, check out &lt;a href="https://github.com/ageron/handson-ml"&gt;ageron/handson-ml&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-want-to-play-with-these-notebooks-online-without-having-to-install-anything" class="anchor" aria-hidden="true" href="#want-to-play-with-these-notebooks-online-without-having-to-install-anything"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Want to play with these notebooks online without having to install anything?&lt;/h3&gt;
&lt;p&gt;Use any of the following services.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: Please be aware that these services provide temporary environments: anything you do will be deleted after a while, so make sure you download any data you care about.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Recommended&lt;/strong&gt;: open this repository in &lt;a href="https://colab.research.google.com/github/ageron/handson-ml2/blob/master/" rel="nofollow"&gt;Colaboratory&lt;/a&gt;:
&lt;a href="https://colab.research.google.com/github/ageron/handson-ml2/blob/master/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e69988217d15707bdd8b6b27f1d7d53a0dd00af7/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f696d672f636f6c61625f66617669636f6e2e69636f" width="90" data-canonical-src="https://colab.research.google.com/img/colab_favicon.ico" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Or open it in &lt;a href="https://mybinder.org/v2/gh/ageron/handson-ml2/master" rel="nofollow"&gt;Binder&lt;/a&gt;:
&lt;a href="https://mybinder.org/v2/gh/ageron/handson-ml2/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/69ea8abed4df43bca4c671b965aeffef2c4f897a/68747470733a2f2f6d61747468696173627573736f6e6e6965722e636f6d2f706f7374732f696d672f62696e6465725f6c6f676f5f313238783132382e706e67" width="90" data-canonical-src="https://matthiasbussonnier.com/posts/img/binder_logo_128x128.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Note&lt;/em&gt;: Most of the time, Binder starts up quickly and works great, but when handson-ml2 is updated, Binder creates a new environment from scratch, and this can take quite some time.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Or open it in &lt;a href="https://beta.deepnote.com/launch?template=data-science&amp;amp;url=https%3A//github.com/ageron/handson-ml2/blob/master/index.ipynb" rel="nofollow"&gt;Deepnote&lt;/a&gt;:
&lt;a href="https://beta.deepnote.com/launch?template=data-science&amp;amp;url=https%3A//github.com/ageron/handson-ml2/blob/master/index.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3fae03be31b768100aa2a800d2cc3b6650c6cd48/68747470733a2f2f7777772e646565706e6f74652e636f6d2f7374617469632f696c6c757374726174696f6e2e706e67" width="150" data-canonical-src="https://www.deepnote.com/static/illustration.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-just-want-to-quickly-look-at-some-notebooks-without-executing-any-code" class="anchor" aria-hidden="true" href="#just-want-to-quickly-look-at-some-notebooks-without-executing-any-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Just want to quickly look at some notebooks, without executing any code?&lt;/h3&gt;
&lt;p&gt;Browse this repository using &lt;a href="https://nbviewer.jupyter.org/github/ageron/handson-ml2/blob/master/index.ipynb" rel="nofollow"&gt;jupyter.org's notebook viewer&lt;/a&gt;:
&lt;a href="https://nbviewer.jupyter.org/github/ageron/handson-ml2/blob/master/index.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/079030b4c39b76eafa0c6c3a5bd18112aafe42dd/68747470733a2f2f6a7570797465722e6f72672f6173736574732f6e61765f6c6f676f2e737667" width="150" data-canonical-src="https://jupyter.org/assets/nav_logo.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: &lt;a href="index.ipynb"&gt;github.com's notebook viewer&lt;/a&gt; also works but it is slower and the math equations are not always displayed correctly.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-want-to-run-this-project-using-a-docker-image" class="anchor" aria-hidden="true" href="#want-to-run-this-project-using-a-docker-image"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Want to run this project using a Docker image?&lt;/h3&gt;
&lt;p&gt;Read the &lt;a href="https://github.com/ageron/handson-ml2/tree/master/docker"&gt;Docker instructions&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-want-to-install-this-project-on-your-own-machine" class="anchor" aria-hidden="true" href="#want-to-install-this-project-on-your-own-machine"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Want to install this project on your own machine?&lt;/h3&gt;
&lt;p&gt;Start by installing &lt;a href="https://www.anaconda.com/distribution/" rel="nofollow"&gt;Anaconda&lt;/a&gt; (or &lt;a href="https://docs.conda.io/en/latest/miniconda.html" rel="nofollow"&gt;Miniconda&lt;/a&gt;), &lt;a href="https://git-scm.com/downloads" rel="nofollow"&gt;git&lt;/a&gt;, and if you have a TensorFlow-compatible GPU, install the &lt;a href="https://www.nvidia.com/Download/index.aspx" rel="nofollow"&gt;GPU driver&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Next, clone this project by opening a terminal and typing the following commands (do not type the first &lt;code&gt;$&lt;/code&gt; signs on each line, they just indicate that these are terminal commands):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/ageron/handson-ml2.git
$ cd handson-ml2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to use a GPU, then edit &lt;code&gt;environment.yml&lt;/code&gt; (or &lt;code&gt;environment-windows.yml&lt;/code&gt; on Windows) and replace &lt;code&gt;tensorflow=2.0.0&lt;/code&gt; with &lt;code&gt;tensorflow-gpu=2.0.0&lt;/code&gt;. Also replace &lt;code&gt;tensorflow-serving-api==2.0.0&lt;/code&gt; with &lt;code&gt;tensorflow-serving-api-gpu==2.0.0&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Next, run the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda env create -f environment.yml # or environment-windows.yml on Windows
$ conda activate tf2
$ python -m ipykernel install --user --name=python3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then if you're on Windows, run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pip install --no-index -f https://github.com/Kojoley/atari-py/releases atari_py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, start Jupyter:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you need further instructions, read the &lt;a href="INSTALL.md"&gt;detailed installation instructions&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributors&lt;/h2&gt;
&lt;p&gt;I would like to thank everyone who contributed to this project, either by providing useful feedback, filing issues or submitting Pull Requests. Special thanks go to Haesun Park who helped on some of the exercise solutions, and to Steven Bunkley and Ziembla who created the &lt;code&gt;docker&lt;/code&gt; directory.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ageron</author><guid isPermaLink="false">https://github.com/ageron/handson-ml2</guid><pubDate>Tue, 04 Feb 2020 00:03:00 GMT</pubDate></item><item><title>jakevdp/PythonDataScienceHandbook #4 in Jupyter Notebook, This month</title><link>https://github.com/jakevdp/PythonDataScienceHandbook</link><description>&lt;p&gt;&lt;i&gt;Python Data Science Handbook: full text in Jupyter Notebooks&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-python-data-science-handbook" class="anchor" aria-hidden="true" href="#python-data-science-handbook"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python Data Science Handbook&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://mybinder.org/v2/gh/jakevdp/PythonDataScienceHandbook/master?filepath=notebooks%2FIndex.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repository contains the entire &lt;a href="http://shop.oreilly.com/product/0636920034919.do" rel="nofollow"&gt;Python Data Science Handbook&lt;/a&gt;, in the form of (free!) Jupyter notebooks.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="notebooks/figures/PDSH-cover.png"&gt;&lt;img src="notebooks/figures/PDSH-cover.png" alt="cover image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-use-this-book" class="anchor" aria-hidden="true" href="#how-to-use-this-book"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to Use this Book&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Read the book in its entirety online at &lt;a href="https://jakevdp.github.io/PythonDataScienceHandbook/" rel="nofollow"&gt;https://jakevdp.github.io/PythonDataScienceHandbook/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the code using the Jupyter notebooks available in this repository's &lt;a href="notebooks"&gt;notebooks&lt;/a&gt; directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Launch executable versions of these notebooks using &lt;a href="http://colab.research.google.com" rel="nofollow"&gt;Google Colab&lt;/a&gt;: &lt;a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Launch a live notebook server with these notebooks using &lt;a href="https://beta.mybinder.org/" rel="nofollow"&gt;binder&lt;/a&gt;: &lt;a href="https://mybinder.org/v2/gh/jakevdp/PythonDataScienceHandbook/master?filepath=notebooks%2FIndex.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Buy the printed book through &lt;a href="http://shop.oreilly.com/product/0636920034919.do" rel="nofollow"&gt;O'Reilly Media&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-about" class="anchor" aria-hidden="true" href="#about"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About&lt;/h2&gt;
&lt;p&gt;The book was written and tested with Python 3.5, though other Python versions (including Python 2.7) should work in nearly all cases.&lt;/p&gt;
&lt;p&gt;The book introduces the core libraries essential for working with data in Python: particularly &lt;a href="http://ipython.org" rel="nofollow"&gt;IPython&lt;/a&gt;, &lt;a href="http://numpy.org" rel="nofollow"&gt;NumPy&lt;/a&gt;, &lt;a href="http://pandas.pydata.org" rel="nofollow"&gt;Pandas&lt;/a&gt;, &lt;a href="http://matplotlib.org" rel="nofollow"&gt;Matplotlib&lt;/a&gt;, &lt;a href="http://scikit-learn.org" rel="nofollow"&gt;Scikit-Learn&lt;/a&gt;, and related packages.
Familiarity with Python as a language is assumed; if you need a quick introduction to the language itself, see the free companion project,
&lt;a href="https://github.com/jakevdp/WhirlwindTourOfPython"&gt;A Whirlwind Tour of Python&lt;/a&gt;: it's a fast-paced introduction to the Python language aimed at researchers and scientists.&lt;/p&gt;
&lt;p&gt;See &lt;a href="http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;Index.ipynb&lt;/a&gt; for an index of the notebooks available to accompany the text.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-software" class="anchor" aria-hidden="true" href="#software"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Software&lt;/h2&gt;
&lt;p&gt;The code in the book was tested with Python 3.5, though most (but not all) will also work correctly with Python 2.7 and other older Python versions.&lt;/p&gt;
&lt;p&gt;The packages I used to run the code in the book are listed in &lt;a href="requirements.txt"&gt;requirements.txt&lt;/a&gt; (Note that some of these exact version numbers may not be available on your platform: you may have to tweak them for your own use).
To install the requirements using &lt;a href="http://conda.pydata.org" rel="nofollow"&gt;conda&lt;/a&gt;, run the following at the command-line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda install --file requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To create a stand-alone environment named &lt;code&gt;PDSH&lt;/code&gt; with Python 3.5 and all the required package versions, run the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda create -n PDSH python=3.5 --file requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can read more about using conda environments in the &lt;a href="http://conda.pydata.org/docs/using/envs.html" rel="nofollow"&gt;Managing Environments&lt;/a&gt; section of the conda documentation.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-code" class="anchor" aria-hidden="true" href="#code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code&lt;/h3&gt;
&lt;p&gt;The code in this repository, including all code samples in the notebooks listed above, is released under the &lt;a href="LICENSE-CODE"&gt;MIT license&lt;/a&gt;. Read more at the &lt;a href="https://opensource.org/licenses/MIT" rel="nofollow"&gt;Open Source Initiative&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-text" class="anchor" aria-hidden="true" href="#text"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Text&lt;/h3&gt;
&lt;p&gt;The text content of the book is released under the &lt;a href="LICENSE-TEXT"&gt;CC-BY-NC-ND license&lt;/a&gt;. Read more at &lt;a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode" rel="nofollow"&gt;Creative Commons&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jakevdp</author><guid isPermaLink="false">https://github.com/jakevdp/PythonDataScienceHandbook</guid><pubDate>Tue, 04 Feb 2020 00:04:00 GMT</pubDate></item><item><title>google/trax #5 in Jupyter Notebook, This month</title><link>https://github.com/google/trax</link><description>&lt;p&gt;&lt;i&gt;Trax â€” your path to advanced deep learning&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-trax--your-path-to-advanced-deep-learning" class="anchor" aria-hidden="true" href="#trax--your-path-to-advanced-deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Trax â€” your path to advanced deep learning&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/bddfc5e8ae531f274dd98ab357d4a5d5f0683cd4/68747470733a2f2f696d616765732e706578656c732e636f6d2f70686f746f732f3436313737322f706578656c732d70686f746f2d3436313737322e6a7065673f646c266669743d63726f702663726f703d656e74726f707926773d333226683d3231"&gt;&lt;img src="https://camo.githubusercontent.com/bddfc5e8ae531f274dd98ab357d4a5d5f0683cd4/68747470733a2f2f696d616765732e706578656c732e636f6d2f70686f746f732f3436313737322f706578656c732d70686f746f2d3436313737322e6a7065673f646c266669743d63726f702663726f703d656e74726f707926773d333226683d3231" alt="train tracks" data-canonical-src="https://images.pexels.com/photos/461772/pexels-photo-461772.jpeg?dl&amp;amp;fit=crop&amp;amp;crop=entropy&amp;amp;w=32&amp;amp;h=21" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://badge.fury.io/py/trax" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c3ddd29ad9780045cf67e6db455d947a7335c483/68747470733a2f2f62616467652e667572792e696f2f70792f747261782e737667" alt="PyPI version" data-canonical-src="https://badge.fury.io/py/trax.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/google/trax/issues"&gt;&lt;img src="https://camo.githubusercontent.com/80b7490db8d31f8f8ed019832a5c80e2e81fb73d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f676f6f676c652f747261782e737667" alt="GitHub Issues" data-canonical-src="https://img.shields.io/github/issues/google/trax.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="CONTRIBUTING.md"&gt;&lt;img src="https://camo.githubusercontent.com/8f697c48adc5026cc6d83dd45e42b9b93ee1803c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e747269627574696f6e732d77656c636f6d652d627269676874677265656e2e737667" alt="Contributions welcome" data-canonical-src="https://img.shields.io/badge/contributions-welcome-brightgreen.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opensource.org/licenses/Apache-2.0" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/dc5c93f4ddfa92aaed4ace74e89dbc075f7810c8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d627269676874677265656e2e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-brightgreen.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/trax-ml/community" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/fed5b5512498193ce4bba599fd94cd12b9f56491/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6e776a732f6e772e6a732e737667" alt="Gitter" data-canonical-src="https://img.shields.io/gitter/room/nwjs/nw.js.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/google/trax"&gt;Trax&lt;/a&gt; helps you understand and explore advanced deep learning.
We &lt;a href="#structure"&gt;focus&lt;/a&gt; on making Trax code clear while pushing advanced models like
&lt;a href="https://github.com/google/trax/tree/master/trax/models/reformer"&gt;Reformer&lt;/a&gt; to their limits.
Trax is actively used and maintained in the &lt;a href="https://research.google.com/teams/brain/" rel="nofollow"&gt;Google Brain team&lt;/a&gt;.
Give it a try, &lt;a href="https://gitter.im/trax-ml/community" rel="nofollow"&gt;talk to us&lt;/a&gt;
or &lt;a href="https://github.com/google/trax/issues"&gt;open an issue&lt;/a&gt; if needed.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-use-trax" class="anchor" aria-hidden="true" href="#use-trax"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Use Trax&lt;/h3&gt;
&lt;p&gt;You can use Trax either as a library from your own python scripts and notebooks
or as a binary from the shell, which can be more convenient for training large models.
Trax includes a number of deep learning models (ResNet, Transformer, RNNs, ...)
and has bindings to a large number of deep learning datasets, including
&lt;a href="https://github.com/tensorflow/tensor2tensor"&gt;Tensor2Tensor&lt;/a&gt; and &lt;a href="https://www.tensorflow.org/datasets/catalog/overview" rel="nofollow"&gt;TensorFlow datasets&lt;/a&gt;.
It runs without any changes on CPUs, GPUs and TPUs.&lt;/p&gt;
&lt;p&gt;To see how to use Trax as a library, take a look at this &lt;a href="https://colab.research.google.com/github/google/trax/blob/master/trax/intro.ipynb" rel="nofollow"&gt;quick start colab&lt;/a&gt;
which explains how to create data in python, connect it to a Transformer model in Trax, train it and run inference.
You can select a CPU or GPU runtime, or even get a free 8-core TPU as
runtime. With TPUs in colab you need to set extra flags as demonstrated in these
&lt;a href="https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/text_generation.ipynb" rel="nofollow"&gt;training&lt;/a&gt;
and &lt;a href="https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/image_generation.ipynb" rel="nofollow"&gt;inference&lt;/a&gt; colabs.&lt;/p&gt;
&lt;p&gt;To use Trax as a binary and not forget all the parameters (model type, learning
rate, other hyper-paramters and training settings), we recommend &lt;a href="https://github.com/google/gin-config"&gt;gin-config&lt;/a&gt;.
Take a look at &lt;a href="https://github.com/google/trax/blob/master/trax/configs/mlp_mnist.gin"&gt;an example gin config&lt;/a&gt;
for training a simple MLP on MNIST and run it as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python -m trax.trainer --config_file=$PWD/trax/configs/mlp_mnist.gin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a more advanced example, you can train a &lt;a href="https://github.com/google/trax/tree/master/trax/models/reformer"&gt;Reformer&lt;/a&gt;
on &lt;a href="https://arxiv.org/abs/1707.08819" rel="nofollow"&gt;Imagenet64&lt;/a&gt; to generate images &lt;a href="https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/image_generation.ipynb" rel="nofollow"&gt;like this&lt;/a&gt;
with the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python -m trax.trainer --config_file=$PWD/trax/configs/reformer_imagenet64.gin
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-structure" class="anchor" aria-hidden="true" href="#structure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Structure&lt;/h3&gt;
&lt;p&gt;Trax code is structured in a way that allows you to understand deep learning
from scratch. We start with basic maths and go through layers, models,
supervised and reinforcement learning. We get to advanced deep learning
results, including recent papers such as &lt;a href="https://arxiv.org/abs/2001.04451" rel="nofollow"&gt;Reformer - The Efficient Transformer&lt;/a&gt;,
selected for oral presentation at &lt;a href="https://iclr.cc/Conferences/2020/" rel="nofollow"&gt;ICLR 2020&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The main steps needed to understand deep learning correspond to sub-directories
in Trax code:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/google/trax/tree/master/trax/math"&gt;math/&lt;/a&gt; â€” basic math operations and ways to accelerate them on GPUs and TPUs (through &lt;a href="https://github.com/google/jax"&gt;JAX&lt;/a&gt; and &lt;a href="https://www.tensorflow.org/" rel="nofollow"&gt;TensorFlow&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/trax/tree/master/trax/layers"&gt;layers/&lt;/a&gt; are the basic building blocks of neural networks and here you'll find how they are build and all the needed ones&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/trax/tree/master/trax/models"&gt;models/&lt;/a&gt; contains all basic models (MLP, ResNet, Transformer, ...) and a number of new research models&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/trax/tree/master/trax/optimizers"&gt;optimizers/&lt;/a&gt; is a directory with optimizers needed for deep learning&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/trax/tree/master/trax/supervised"&gt;supervised/&lt;/a&gt; contains the utilities needed to run supervised learning and the Trainer class&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/trax/tree/master/trax/rl"&gt;rl/&lt;/a&gt; contains our work on reinforcement learning&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-development" class="anchor" aria-hidden="true" href="#development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development&lt;/h3&gt;
&lt;p&gt;To get the most recent update on Trax development, &lt;a href="https://gitter.im/trax-ml/community" rel="nofollow"&gt;chat with us&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Most common supervised learning models in Trax are running and should have clear
code â€” if this is not the case, please &lt;a href="https://github.com/google/trax/issues"&gt;open an issue&lt;/a&gt;
or, even better, send along a pull request (see &lt;a href="CONTRIBUTING.md"&gt;our contribution doc&lt;/a&gt;).
In Trax we value documentation, examples and colabs so if you find any
problems with those, please report it and contribute a solution.&lt;/p&gt;
&lt;p&gt;We are still improving a few smaller parts of &lt;a href="https://github.com/google/trax/tree/master/trax/layers"&gt;layers&lt;/a&gt;,
planning to update the &lt;a href="https://github.com/google/trax/tree/master/trax/supervised"&gt;supervised&lt;/a&gt; API and
heavily working on the &lt;a href="https://github.com/google/trax/tree/master/trax/rl"&gt;rl&lt;/a&gt; part,
so expect these parts to change over the next few months. We are also working hard
to improve our documentation and examples and we welcome help with that.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>google</author><guid isPermaLink="false">https://github.com/google/trax</guid><pubDate>Tue, 04 Feb 2020 00:05:00 GMT</pubDate></item><item><title>practicalAI/practicalAI #6 in Jupyter Notebook, This month</title><link>https://github.com/practicalAI/practicalAI</link><description>&lt;p&gt;&lt;i&gt;ðŸ“š A practical approach to machine learning.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;div align="center"&gt;
&lt;a href="https://practicalai.me" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/practicalAI/images/master/images/logo.png" width="200" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;p&gt;A &lt;i&gt;&lt;b&gt;practical&lt;/b&gt;&lt;/i&gt; approach to machine learning.&lt;/p&gt;
&lt;a href="https://github.com/practicalAI/practicalAI"&gt;
&lt;img src="https://camo.githubusercontent.com/c1b6c20adc52e06a1c58218665169097a63bd549/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70726163746963616c41492f70726163746963616c41492e7376673f7374796c653d736f6369616c266c6162656c3d53746172" data-canonical-src="https://img.shields.io/github/stars/practicalAI/practicalAI.svg?style=social&amp;amp;label=Star" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://www.linkedin.com/company/practicalai-me" rel="nofollow"&gt;
&lt;img src="https://camo.githubusercontent.com/19c0cf9ba93aa446aa855a0203c46ee39841cba9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7374796c652d2d3565626130302e7376673f6c6162656c3d4c696e6b6564496e266c6f676f3d6c696e6b6564696e267374796c653d736f6369616c" data-canonical-src="https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&amp;amp;logo=linkedin&amp;amp;style=social" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://twitter.com/practicalAIme" rel="nofollow"&gt;
&lt;img src="https://camo.githubusercontent.com/1a44bef694d0cd085f8365eac5ff9b5f85568043/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f70726163746963616c41496d652e7376673f6c6162656c3d466f6c6c6f77267374796c653d736f6369616c" data-canonical-src="https://img.shields.io/twitter/follow/practicalAIme.svg?label=Follow&amp;amp;style=social" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;p&gt;&lt;sub&gt;Created by
&lt;a href="https://goku.me" rel="nofollow"&gt;Goku Mohandas&lt;/a&gt; and
&lt;a href="https://github.com/practicalAI/practicalAI/graphs/contributors"&gt;
contributors
&lt;/a&gt;
&lt;/sub&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-notebooks" class="anchor" aria-hidden="true" href="#notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notebooks&lt;/h2&gt;
&lt;ul&gt;
    &lt;li&gt;
        &lt;g-emoji class="g-emoji" alias="earth_americas" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f30e.png"&gt;ðŸŒŽ&lt;/g-emoji&gt; â†’ &lt;a href="https://practicalai.me" rel="nofollow"&gt;https://practicalai.me&lt;/a&gt;
    &lt;/li&gt;
    &lt;li&gt;
        &lt;g-emoji class="g-emoji" alias="books" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4da.png"&gt;ðŸ“š&lt;/g-emoji&gt; Illustrative ML notebooks in &lt;a href="https://tensorflow.org" rel="nofollow"&gt;TensorFlow 2.0 + Keras&lt;/a&gt;.
    &lt;/li&gt;
    &lt;li&gt;
        &lt;g-emoji class="g-emoji" alias="hammer_and_pick" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2692.png"&gt;âš’ï¸&lt;/g-emoji&gt; Build robust models using the functional API w/ custom components
    &lt;/li&gt;
    &lt;li&gt;
        &lt;g-emoji class="g-emoji" alias="package" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4e6.png"&gt;ðŸ“¦&lt;/g-emoji&gt; Train using simple yet highly customizable loops to build products fast
    &lt;/li&gt;
    &lt;li&gt;
        If you prefer Jupyter Notebooks or want to add/fix content, check out the &lt;a href="https://github.com/practicalAI/practicalAI/tree/master/notebooks"&gt;notebooks&lt;/a&gt; directory.
    &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="2"&gt;
        &lt;h4 align="center"&gt;&lt;a id="user-content-basic-ml" class="anchor" aria-hidden="true" href="#basic-ml"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Basic ML&lt;/h4&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center"&gt;&lt;b&gt;Basics&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Machine Learning&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Tools&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Deep Learning&lt;/b&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="4"&gt;
        &lt;ul&gt;
            &lt;li&gt;Learn Python basics with notebooks.&lt;/li&gt;
            &lt;li&gt;Use data science libraries like &lt;a href="https://www.numpy.org/" rel="nofollow"&gt;NumPy&lt;/a&gt; and &lt;a href="https://pandas.pydata.org/" rel="nofollow"&gt;Pandas&lt;/a&gt;.&lt;/li&gt;
            &lt;li&gt;Implement basic ML models in &lt;a href="https://www.tensorflow.org/overview/" rel="nofollow"&gt;TensorFlow 2.0 + Keras&lt;/a&gt;.&lt;/li&gt;
            &lt;li&gt;Create deep learning models for improved performance.&lt;/li&gt;
        &lt;/ul&gt;
        &lt;/td&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/00_Notebooks.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="notebook" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png"&gt;ðŸ““&lt;/g-emoji&gt; Notebooks&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/04_Linear_Regression.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="chart_with_upwards_trend" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4c8.png"&gt;ðŸ“ˆ&lt;/g-emoji&gt; Linear Regression&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/07_Data_and_Models.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="mag_right" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f50e.png"&gt;ðŸ”Ž&lt;/g-emoji&gt; Data &amp;amp; Models&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/10_Convolutional_Neural_Networks.ipynb" rel="nofollow"&gt;ï¸&lt;g-emoji class="g-emoji" alias="framed_picture" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5bc.png"&gt;ðŸ–¼&lt;/g-emoji&gt; Convolutional Neural Networks&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/01_Python.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="snake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f40d.png"&gt;ðŸ&lt;/g-emoji&gt; Python&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/05_Logistic_Regression.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="bar_chart" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png"&gt;ðŸ“Š&lt;/g-emoji&gt; Logistic Regression&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/08_Utilities.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="hammer_and_wrench" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e0.png"&gt;ðŸ› &lt;/g-emoji&gt; Utilities&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/11_Embeddings.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="crown" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f451.png"&gt;ðŸ‘‘&lt;/g-emoji&gt; Embeddings&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/02_NumPy.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="1234" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f522.png"&gt;ðŸ”¢&lt;/g-emoji&gt; NumPy&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/06_Multilayer_Perceptrons.ipynb" rel="nofollow"&gt;ï¸&lt;g-emoji class="g-emoji" alias="control_knobs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f39b.png"&gt;ðŸŽ›&lt;/g-emoji&gt; Multilayer Perceptrons&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/09_Preprocessing.ipynb" rel="nofollow"&gt;ï¸&lt;g-emoji class="g-emoji" alias="scissors" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2702.png"&gt;âœ‚ï¸&lt;/g-emoji&gt; Preprocessing&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/12_Recurrent_Neural_Networks.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="green_book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d7.png"&gt;ðŸ“—&lt;/g-emoji&gt; Recurrent Neural Networks&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/03_Pandas.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="panda_face" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f43c.png"&gt;ðŸ¼&lt;/g-emoji&gt; Pandas&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="2"&gt;&lt;h4 align="center"&gt;&lt;a id="user-content-production-ml" class="anchor" aria-hidden="true" href="#production-ml"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Production ML&lt;/h4&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center"&gt;&lt;b&gt;Local&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Applications&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Scale&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Miscellaneous&lt;/b&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="3"&gt;
        &lt;ul&gt;
            &lt;li&gt;Setup your local environment for ML.&lt;/li&gt;
            &lt;li&gt;Wrap your ML in RESTful APIs using &lt;a href="http://flask.pocoo.org/" rel="nofollow"&gt;Flask&lt;/a&gt; to create applications.&lt;/li&gt;
            &lt;li&gt;Standardize and scale your ML applications with &lt;a href="https://www.docker.com/" rel="nofollow"&gt;Docker&lt;/a&gt; and &lt;a href="https://kubernetes.io/" rel="nofollow"&gt;Kubernetes&lt;/a&gt;.&lt;/li&gt;
            &lt;li&gt;Deploy simple and scalable ML workflows using &lt;a href="https://www.kubeflow.org/" rel="nofollow"&gt;Kubeflow&lt;/a&gt;.&lt;/li&gt;
        &lt;/ul&gt;
        &lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="computer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png"&gt;ðŸ’»&lt;/g-emoji&gt; Local Setup&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="evergreen_tree" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f332.png"&gt;ðŸŒ²&lt;/g-emoji&gt; Logging&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="whale" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f433.png"&gt;ðŸ³&lt;/g-emoji&gt; Docker&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="handshake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f91d.png"&gt;ðŸ¤&lt;/g-emoji&gt; Distributed Training&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="snake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f40d.png"&gt;ðŸ&lt;/g-emoji&gt; ML Scripts&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="funeral_urn" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26b1.png"&gt;âš±ï¸&lt;/g-emoji&gt; Flask Applications&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="ship" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a2.png"&gt;ðŸš¢&lt;/g-emoji&gt; Kubernetes&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="battery" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f50b.png"&gt;ðŸ”‹&lt;/g-emoji&gt; Databases&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="white_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png"&gt;âœ…&lt;/g-emoji&gt; Unit Tests&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="ocean" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f30a.png"&gt;ðŸŒŠ&lt;/g-emoji&gt; Kubeflow&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="closed_lock_with_key" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f510.png"&gt;ðŸ”&lt;/g-emoji&gt; Authentication&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="2"&gt;&lt;h4 align="center"&gt;&lt;a id="user-content-advanced-ml" class="anchor" aria-hidden="true" href="#advanced-ml"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Advanced ML&lt;/h4&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center"&gt;&lt;b&gt;General&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Sequential&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Popular&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Miscellaneous&lt;/b&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="3"&gt;
        &lt;ul&gt;
            &lt;li&gt;Dive into architectural and interpretable advancements in neural networks.&lt;/li&gt;
            &lt;li&gt;Implement state-of-the-art NLP techniques.&lt;/li&gt;
            &lt;li&gt;Learn about popular deep learning algorithms used for generation, time-series, etc.&lt;/li&gt;
        &lt;/ul&gt;
        &lt;/td&gt;
        &lt;td&gt;ðŸ§ Attention&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="bee" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f41d.png"&gt;ðŸ&lt;/g-emoji&gt; Transformers&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="performing_arts" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3ad.png"&gt;ðŸŽ­&lt;/g-emoji&gt; Generative Adversarial Networks&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png"&gt;ðŸ”®&lt;/g-emoji&gt; Autoencoders&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="racing_car" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3ce.png"&gt;ðŸŽï¸&lt;/g-emoji&gt; Highway Networks&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="japanese_ogre" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f479.png"&gt;ðŸ‘¹&lt;/g-emoji&gt; BERT, GPT2, XLNet&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="8ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3b1.png"&gt;ðŸŽ±&lt;/g-emoji&gt; Bayesian Deep Learning&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="spider" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f577.png"&gt;ðŸ•·ï¸&lt;/g-emoji&gt; Graph Neural Networks&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="droplet" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a7.png"&gt;ðŸ’§&lt;/g-emoji&gt; Residual Networks&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="clock9" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f558.png"&gt;ðŸ•˜&lt;/g-emoji&gt; Temporal CNNs&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="cherries" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f352.png"&gt;ðŸ’&lt;/g-emoji&gt; Reinforcement Learning&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="2"&gt;&lt;h4 align="center"&gt;&lt;a id="user-content-topics" class="anchor" aria-hidden="true" href="#topics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Topics&lt;/h4&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center"&gt;&lt;b&gt;Computer Vision&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Natural Language&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Unsupervised Learning&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Miscellaneous&lt;/b&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="4"&gt;
        &lt;ul&gt;
            &lt;li&gt;Learn how to use deep learning for computer vision tasks.&lt;/li&gt;
            &lt;li&gt;Implement techniques for natural language tasks.&lt;/li&gt;
            &lt;li&gt;Derive insights from unlabeled data using unsupervised learning.&lt;/li&gt;
        &lt;/ul&gt;
        &lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="camera_flash" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f8.png"&gt;ðŸ“¸&lt;/g-emoji&gt; Image Recognition&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png"&gt;ðŸ“–&lt;/g-emoji&gt; Text classification&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="dango" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f361.png"&gt;ðŸ¡&lt;/g-emoji&gt; Clustering&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="alarm_clock" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/23f0.png"&gt;â°&lt;/g-emoji&gt; Time-series Analysis&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="framed_picture" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5bc.png"&gt;ðŸ–¼ï¸&lt;/g-emoji&gt; Image Segmentation&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="speech_balloon" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ac.png"&gt;ðŸ’¬&lt;/g-emoji&gt; Named Entity Recognition&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="houses" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3d8.png"&gt;ðŸ˜ï¸&lt;/g-emoji&gt; Topic Modeling&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="shopping_cart" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6d2.png"&gt;ðŸ›’&lt;/g-emoji&gt; Recommendation Systems&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="art" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3a8.png"&gt;ðŸŽ¨&lt;/g-emoji&gt; Image Generation&lt;/td&gt;
        &lt;td&gt;ðŸ§  Knowledge Graphs&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="dart" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png"&gt;ðŸŽ¯&lt;/g-emoji&gt; One-shot Learning&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="card_file_box" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5c3.png"&gt;ðŸ—ƒï¸&lt;/g-emoji&gt; Interpretability&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-updates" class="anchor" aria-hidden="true" href="#updates"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Updates&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://practicalai.me/#newsletter" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="mailbox_with_mail" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ec.png"&gt;ðŸ“¬&lt;/g-emoji&gt; Newsletter&lt;/a&gt; - Subscribe to get updates on new content.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>practicalAI</author><guid isPermaLink="false">https://github.com/practicalAI/practicalAI</guid><pubDate>Tue, 04 Feb 2020 00:06:00 GMT</pubDate></item><item><title>deepmind/deepmind-research #7 in Jupyter Notebook, This month</title><link>https://github.com/deepmind/deepmind-research</link><description>&lt;p&gt;&lt;i&gt;This repository contains implementations and illustrative code to accompany DeepMind publications&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deepmind-research" class="anchor" aria-hidden="true" href="#deepmind-research"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DeepMind Research&lt;/h1&gt;
&lt;p&gt;This repository contains implementations and illustrative code to accompany
DeepMind publications. Along with publishing papers to accompany research
conducted at DeepMind, we release open-source
&lt;a href="https://deepmind.com/research/open-source/open-source-environments/" rel="nofollow"&gt;environments&lt;/a&gt;,
&lt;a href="https://deepmind.com/research/open-source/open-source-datasets/" rel="nofollow"&gt;data sets&lt;/a&gt;,
and &lt;a href="https://deepmind.com/research/open-source/open-source-code/" rel="nofollow"&gt;code&lt;/a&gt; to
enable the broader research community to engage with our work and build upon it,
with the ultimate goal of accelerating scientific progress to benefit society.
For example, you can build on our implementations of the
&lt;a href="https://github.com/deepmind/dqn"&gt;Deep Q-Network&lt;/a&gt; or
&lt;a href="https://github.com/deepmind/dnc"&gt;Differential Neural Computer&lt;/a&gt;, or experiment
in the same environments we use for our research, such as
&lt;a href="https://github.com/deepmind/lab"&gt;DeepMind Lab&lt;/a&gt; or
&lt;a href="https://github.com/deepmind/pysc2"&gt;StarCraft II&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you enjoy building tools, environments, software libraries, and other
infrastructure of the kind listed below, you can view open positions to work in
related areas on our &lt;a href="https://deepmind.com/careers/" rel="nofollow"&gt;careers page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For a full list of our publications, please see
&lt;a href="https://deepmind.com/research/publications/" rel="nofollow"&gt;https://deepmind.com/research/publications/&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-projects" class="anchor" aria-hidden="true" href="#projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Projects&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="alphafold_casp13"&gt;AlphaFold CASP13&lt;/a&gt;, Nature 2020&lt;/li&gt;
&lt;li&gt;&lt;a href="unrestricted_advx"&gt;Unrestricted Adversarial Challenge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="hierarchical_probabilistic_unet"&gt;Hierarchical Probabilistic U-Net (HPU-Net)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="scratchgan"&gt;Training Language GANs from Scratch&lt;/a&gt;, NeurIPS 2019&lt;/li&gt;
&lt;li&gt;&lt;a href="tvt"&gt;Temporal Value Transport&lt;/a&gt;, Nature Communications 2019&lt;/li&gt;
&lt;li&gt;&lt;a href="curl"&gt;Continual Unsupervised Representation Learning (CURL)&lt;/a&gt;, NeurIPS 2019&lt;/li&gt;
&lt;li&gt;&lt;a href="transporter"&gt;Unsupervised Learning of Object Keypoints (Transporter)&lt;/a&gt;, NeurIPS 2019&lt;/li&gt;
&lt;li&gt;&lt;a href="bigbigan"&gt;BigBiGAN&lt;/a&gt;, NeurIPS 2019&lt;/li&gt;
&lt;li&gt;&lt;a href="cs_gan"&gt;Deep Compressed Sensing&lt;/a&gt;, ICML 2019&lt;/li&gt;
&lt;li&gt;&lt;a href="side_effects_penalties"&gt;Side Effects Penalties&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="PrediNet"&gt;PrediNet Architecture and Relations Game Datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="unsupervised_adversarial_training"&gt;Unsupervised Adversarial Training&lt;/a&gt;, NeurIPS 2019&lt;/li&gt;
&lt;li&gt;&lt;a href="graph_matching_networks"&gt;Graph Matching Networks for Learning the Similarity of Graph Structured
Objects&lt;/a&gt;, ICML 2019&lt;/li&gt;
&lt;li&gt;&lt;a href="regal"&gt;REGAL: Transfer Learning for Fast Optimization of Computation Graphs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;This is not an official Google product.&lt;/em&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>deepmind</author><guid isPermaLink="false">https://github.com/deepmind/deepmind-research</guid><pubDate>Tue, 04 Feb 2020 00:07:00 GMT</pubDate></item><item><title>Pierian-Data/Complete-Python-3-Bootcamp #8 in Jupyter Notebook, This month</title><link>https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</link><description>&lt;p&gt;&lt;i&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-complete-python-3-bootcamp" class="anchor" aria-hidden="true" href="#complete-python-3-bootcamp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Complete-Python-3-Bootcamp&lt;/h1&gt;
&lt;p&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/p&gt;
&lt;p&gt;Get it now for 95% off with the link:
&lt;a href="https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB" rel="nofollow"&gt;https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Pierian-Data</author><guid isPermaLink="false">https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</guid><pubDate>Tue, 04 Feb 2020 00:08:00 GMT</pubDate></item><item><title>CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers #9 in Jupyter Notebook, This month</title><link>https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</link><description>&lt;p&gt;&lt;i&gt;aka "Bayesian Methods for Hackers": An introduction to Bayesian methods + probabilistic programming with a computation/understanding-first, mathematics-second point of view. All in pure Python ;)  &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-bayesian-methods-for-hackers" class="anchor" aria-hidden="true" href="#bayesian-methods-for-hackers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/" rel="nofollow"&gt;Bayesian Methods for Hackers&lt;/a&gt;&lt;/h1&gt;
&lt;h4&gt;&lt;a id="user-content-using-python-and-pymc" class="anchor" aria-hidden="true" href="#using-python-and-pymc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;em&gt;Using Python and PyMC&lt;/em&gt;&lt;/h4&gt;
&lt;p&gt;The Bayesian method is the natural approach to inference, yet it is hidden from readers behind chapters of slow, mathematical analysis. The typical text on Bayesian inference involves two to three chapters on probability theory, then enters what Bayesian inference is. Unfortunately, due to mathematical intractability of most Bayesian models, the reader is only shown simple, artificial examples. This can leave the user with a &lt;em&gt;so-what&lt;/em&gt; feeling about Bayesian inference. In fact, this was the author's own prior opinion.&lt;/p&gt;
&lt;p&gt;After some recent success of Bayesian methods in machine-learning competitions, I decided to investigate the subject again. Even with my mathematical background, it took me three straight-days of reading examples and trying to put the pieces together to understand the methods. There was simply not enough literature bridging theory to practice. The problem with my misunderstanding was the disconnect between Bayesian mathematics and probabilistic programming. That being said, I suffered then so the reader would not have to now. This book attempts to bridge the gap.&lt;/p&gt;
&lt;p&gt;If Bayesian inference is the destination, then mathematical analysis is a particular path towards it. On the other hand, computing power is cheap enough that we can afford to take an alternate route via probabilistic programming. The latter path is much more useful, as it denies the necessity of mathematical intervention at each step, that is, we remove often-intractable mathematical analysis as a prerequisite to Bayesian inference. Simply put, this latter computational path proceeds via small intermediate jumps from beginning to end, where as the first path proceeds by enormous leaps, often landing far away from our target. Furthermore, without a strong mathematical background, the analysis required by the first path cannot even take place.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Bayesian Methods for Hackers&lt;/em&gt; is designed as an introduction to Bayesian inference from a computational/understanding-first, and mathematics-second, point of view. Of course as an introductory book, we can only leave it at that: an introductory book. For the mathematically trained, they may cure the curiosity this text generates with other texts designed with mathematical analysis in mind. For the enthusiast with less mathematical background, or one who is not interested in the mathematics but simply the practice of Bayesian methods, this text should be sufficient and entertaining.&lt;/p&gt;
&lt;p&gt;The choice of PyMC as the probabilistic programming language is two-fold. As of this writing, there is currently no central resource for examples and explanations in the PyMC universe. The official documentation assumes prior knowledge of Bayesian inference and probabilistic programming. We hope this book encourages users at every level to look at PyMC. Secondly, with recent core developments and popularity of the scientific stack in Python, PyMC is likely to become a core component soon enough.&lt;/p&gt;
&lt;p&gt;PyMC does have dependencies to run, namely NumPy and (optionally) SciPy. To not limit the user, the examples in this book will rely only on PyMC, NumPy, SciPy and Matplotlib.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-printed-version-by-addison-wesley" class="anchor" aria-hidden="true" href="#printed-version-by-addison-wesley"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Printed Version by Addison-Wesley&lt;/h2&gt;
&lt;div&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e991336533f43ff762cbf7713516f4215640d402/687474703a2f2f7777772d66702e70656172736f6e68696768657265642e636f6d2f6173736574732f6869702f696d616765732f626967636f766572732f303133333930323833382e6a7067"&gt;&lt;img title="Bayesian Methods for Hackersg" src="https://camo.githubusercontent.com/e991336533f43ff762cbf7713516f4215640d402/687474703a2f2f7777772d66702e70656172736f6e68696768657265642e636f6d2f6173736574732f6869702f696d616765732f626967636f766572732f303133333930323833382e6a7067" align="right" height="200" data-canonical-src="http://www-fp.pearsonhighered.com/assets/hip/images/bigcovers/0133902838.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Bayesian Methods for Hackers is now available as a printed book!&lt;/strong&gt; You can pick up a copy on &lt;a href="http://www.amazon.com/Bayesian-Methods-Hackers-Probabilistic-Addison-Wesley/dp/0133902838" rel="nofollow"&gt;Amazon&lt;/a&gt;. What are the differences between the online version and the printed version?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Additional Chapter on Bayesian A/B testing&lt;/li&gt;
&lt;li&gt;Updated examples&lt;/li&gt;
&lt;li&gt;Answers to the end of chapter questions&lt;/li&gt;
&lt;li&gt;Additional explanation, and rewritten sections to aid the reader.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h2&gt;
&lt;p&gt;See the project homepage &lt;a href="http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/" rel="nofollow"&gt;here&lt;/a&gt; for examples, too.&lt;/p&gt;
&lt;p&gt;The below chapters are rendered via the &lt;em&gt;nbviewer&lt;/em&gt; at
&lt;a href="http://nbviewer.jupyter.org/" rel="nofollow"&gt;nbviewer.jupyter.org/&lt;/a&gt;, and is read-only and rendered in real-time.
Interactive notebooks + examples can be downloaded by cloning!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-pymc2" class="anchor" aria-hidden="true" href="#pymc2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyMC2&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Prologue/Prologue.ipynb" rel="nofollow"&gt;&lt;strong&gt;Prologue:&lt;/strong&gt;&lt;/a&gt; Why we do it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/Ch1_Introduction_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 1: Introduction to Bayesian Methods&lt;/strong&gt;&lt;/a&gt;
Introduction to the philosophy and practice of Bayesian methods and answering the question, "What is probabilistic programming?" Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Inferring human behaviour changes from text message rates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 2: A little more on PyMC&lt;/strong&gt;&lt;/a&gt;
We explore modeling Bayesian problems using Python's PyMC library through examples. How do we create Bayesian models? Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detecting the frequency of cheating students, while avoiding liars&lt;/li&gt;
&lt;li&gt;Calculating probabilities of the Challenger space-shuttle disaster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter3_MCMC/Ch3_IntroMCMC_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 3: Opening the Black Box of MCMC&lt;/strong&gt;&lt;/a&gt;
We discuss how MCMC operates and diagnostic tools. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bayesian clustering with mixture models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter4_TheGreatestTheoremNeverTold/Ch4_LawOfLargeNumbers_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 4: The Greatest Theorem Never Told&lt;/strong&gt;&lt;/a&gt;
We explore an incredibly useful, and dangerous, theorem: The Law of Large Numbers. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Exploring a Kaggle dataset and the pitfalls of naive analysis&lt;/li&gt;
&lt;li&gt;How to sort Reddit comments from best to worst (not as easy as you think)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter5_LossFunctions/Ch5_LossFunctions_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 5: Would you rather lose an arm or a leg?&lt;/strong&gt;&lt;/a&gt;
The introduction of loss functions and their (awesome) use in Bayesian methods.  Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solving the &lt;em&gt;Price is Right&lt;/em&gt;'s Showdown&lt;/li&gt;
&lt;li&gt;Optimizing financial predictions&lt;/li&gt;
&lt;li&gt;Winning solution to the Kaggle Dark World's competition&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter6_Priorities/Ch6_Priors_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 6: Getting our &lt;em&gt;prior&lt;/em&gt;-ities straight&lt;/strong&gt;&lt;/a&gt;
Probably the most important chapter. We draw on expert opinions to answer questions. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multi-Armed Bandits and the Bayesian Bandit solution.&lt;/li&gt;
&lt;li&gt;What is the relationship between data sample size and prior?&lt;/li&gt;
&lt;li&gt;Estimating financial unknowns using expert priors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We explore useful tips to be objective in analysis as well as common pitfalls of priors.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pymc3" class="anchor" aria-hidden="true" href="#pymc3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyMC3&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Prologue/Prologue.ipynb" rel="nofollow"&gt;&lt;strong&gt;Prologue:&lt;/strong&gt;&lt;/a&gt; Why we do it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/Ch1_Introduction_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 1: Introduction to Bayesian Methods&lt;/strong&gt;&lt;/a&gt;
Introduction to the philosophy and practice of Bayesian methods and answering the question, "What is probabilistic programming?" Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Inferring human behaviour changes from text message rates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 2: A little more on PyMC&lt;/strong&gt;&lt;/a&gt;
We explore modeling Bayesian problems using Python's PyMC library through examples. How do we create Bayesian models? Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detecting the frequency of cheating students, while avoiding liars&lt;/li&gt;
&lt;li&gt;Calculating probabilities of the Challenger space-shuttle disaster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter3_MCMC/Ch3_IntroMCMC_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 3: Opening the Black Box of MCMC&lt;/strong&gt;&lt;/a&gt;
We discuss how MCMC operates and diagnostic tools. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bayesian clustering with mixture models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter4_TheGreatestTheoremNeverTold/Ch4_LawOfLargeNumbers_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 4: The Greatest Theorem Never Told&lt;/strong&gt;&lt;/a&gt;
We explore an incredibly useful, and dangerous, theorem: The Law of Large Numbers. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Exploring a Kaggle dataset and the pitfalls of naive analysis&lt;/li&gt;
&lt;li&gt;How to sort Reddit comments from best to worst (not as easy as you think)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter5_LossFunctions/Ch5_LossFunctions_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 5: Would you rather lose an arm or a leg?&lt;/strong&gt;&lt;/a&gt;
The introduction of loss functions and their (awesome) use in Bayesian methods.  Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solving the &lt;em&gt;Price is Right&lt;/em&gt;'s Showdown&lt;/li&gt;
&lt;li&gt;Optimizing financial predictions&lt;/li&gt;
&lt;li&gt;Winning solution to the Kaggle Dark World's competition&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter6_Priorities/Ch6_Priors_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 6: Getting our &lt;em&gt;prior&lt;/em&gt;-ities straight&lt;/strong&gt;&lt;/a&gt;
Probably the most important chapter. We draw on expert opinions to answer questions. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multi-Armed Bandits and the Bayesian Bandit solution.&lt;/li&gt;
&lt;li&gt;What is the relationship between data sample size and prior?&lt;/li&gt;
&lt;li&gt;Estimating financial unknowns using expert priors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We explore useful tips to be objective in analysis as well as common pitfalls of priors.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;More questions about PyMC?&lt;/strong&gt;
Please post your modeling, convergence, or any other PyMC question on &lt;a href="http://stats.stackexchange.com/" rel="nofollow"&gt;cross-validated&lt;/a&gt;, the statistics stack-exchange.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-the-book" class="anchor" aria-hidden="true" href="#using-the-book"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using the book&lt;/h2&gt;
&lt;p&gt;The book can be read in three different ways, starting from most recommended to least recommended:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The most recommended option is to clone the repository to download the .ipynb files to your local machine. If you have Jupyter installed, you can view the
chapters in your browser &lt;em&gt;plus&lt;/em&gt; edit and run the code provided (and try some practice questions). This is the preferred option to read
this book, though it comes with some dependencies.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jupyter is a requirement to view the ipynb files. It can be downloaded &lt;a href="http://jupyter.org/" rel="nofollow"&gt;here&lt;/a&gt;. Jupyter notebooks can be run by &lt;code&gt;(your-virtualenv) ~/path/to/the/book/Chapter1_Introduction $ jupyter notebook&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;For Linux users, you should not have a problem installing NumPy, SciPy, Matplotlib and PyMC. For Windows users, check out &lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/" rel="nofollow"&gt;pre-compiled versions&lt;/a&gt; if you have difficulty.&lt;/li&gt;
&lt;li&gt;In the styles/ directory are a number of files (.matplotlirc) that used to make things pretty. These are not only designed for the book, but they offer many improvements over the default settings of matplotlib.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second, preferred, option is to use the nbviewer.jupyter.org site, which display Jupyter notebooks in the browser (&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/Ch1_Introduction_PyMC2.ipynb" rel="nofollow"&gt;example&lt;/a&gt;).
The contents are updated synchronously as commits are made to the book. You can use the Contents section above to link to the chapters.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PDFs are the least-preferred method to read the book, as PDFs are static and non-interactive. If PDFs are desired, they can be created dynamically using the &lt;a href="https://github.com/jupyter/nbconvert"&gt;nbconvert&lt;/a&gt; utility.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-installation-and-configuration" class="anchor" aria-hidden="true" href="#installation-and-configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation and configuration&lt;/h2&gt;
&lt;p&gt;If you would like to run the Jupyter notebooks locally, (option 1. above), you'll need to install the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Jupyter is a requirement to view the ipynb files. It can be downloaded &lt;a href="http://jupyter.org/install.html" rel="nofollow"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Necessary packages are PyMC, NumPy, SciPy and Matplotlib.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For Linux/OSX users, you should not have a problem installing the above, &lt;a href="http://www.penandpants.com/2012/02/24/install-python/" rel="nofollow"&gt;&lt;em&gt;except for Matplotlib on OSX&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For Windows users, check out &lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/" rel="nofollow"&gt;pre-compiled versions&lt;/a&gt; if you have difficulty.&lt;/li&gt;
&lt;li&gt;also recommended, for data-mining exercises, are &lt;a href="https://github.com/praw-dev/praw"&gt;PRAW&lt;/a&gt; and &lt;a href="https://github.com/kennethreitz/requests"&gt;requests&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;New to Python or Jupyter, and help with the namespaces? Check out &lt;a href="http://stackoverflow.com/questions/12987624/confusion-between-numpy-scipy-matplotlib-and-pylab" rel="nofollow"&gt;this answer&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the styles/ directory are a number of files that are customized for the notebook.
These are not only designed for the book, but they offer many improvements over the
default settings of matplotlib and the Jupyter notebook. The in notebook style has not been finalized yet.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-development" class="anchor" aria-hidden="true" href="#development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development&lt;/h2&gt;
&lt;p&gt;This book has an unusual development design. The content is open-sourced, meaning anyone can be an author.
Authors submit content or revisions using the GitHub interface.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-how-to-contribute" class="anchor" aria-hidden="true" href="#how-to-contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to contribute&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-what-to-contribute" class="anchor" aria-hidden="true" href="#what-to-contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What to contribute?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The current chapter list is not finalized. If you see something that is missing (MCMC, MAP, Bayesian networks, good prior choices, Potential classes etc.),
feel free to start there.&lt;/li&gt;
&lt;li&gt;Cleaning up Python code and making code more PyMC-esque&lt;/li&gt;
&lt;li&gt;Giving better explanations&lt;/li&gt;
&lt;li&gt;Spelling/grammar mistakes&lt;/li&gt;
&lt;li&gt;Suggestions&lt;/li&gt;
&lt;li&gt;Contributing to the Jupyter notebook styles&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-commiting" class="anchor" aria-hidden="true" href="#commiting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Commiting&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;All commits are welcome, even if they are minor ;)&lt;/li&gt;
&lt;li&gt;If you are unfamiliar with Github, you can email me contributions to the email below.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-reviews" class="anchor" aria-hidden="true" href="#reviews"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reviews&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;these are satirical, but real&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;"No, but it looks good" - &lt;a href="https://twitter.com/JohnDCook/status/359672133695184896" rel="nofollow"&gt;John D. Cook&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"I ... read this book ... I like it!" - &lt;a href="http://www.andrewgelman.com/2013/07/21/bayes-related" rel="nofollow"&gt;Andrew Gelman&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"This book is a godsend, and a direct refutation to that 'hmph! you don't know maths, piss off!' school of thought...
The publishing model is so unusual. Not only is it open source but it relies on pull requests from anyone in order to progress the book. This is ingenious and heartening" - &lt;a href="http://www.reddit.com/r/Python/comments/1alnal/probabilistic_programming_and_bayesian_methods/" rel="nofollow"&gt;excited Reddit user&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributions-and-thanks" class="anchor" aria-hidden="true" href="#contributions-and-thanks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributions and Thanks&lt;/h2&gt;
&lt;p&gt;Thanks to all our contributing authors, including (in chronological order):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Authors&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.camdp.com" rel="nofollow"&gt;Cameron Davidson-Pilon&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://stefgibson.com" rel="nofollow"&gt;Stef Gibson&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bigsnarf.wordpress.com/" rel="nofollow"&gt;Vincent Ohprecio&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/larsman"&gt;Lars Buitinck&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://github.com/pmagwene"&gt;Paul Magwene&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Carreau"&gt;Matthias Bussonnier&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/JensRantil"&gt;Jens Rantil&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/y-p"&gt;y-p&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.etano.net/" rel="nofollow"&gt;Ethan Brown&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://jonathanwhitmore.com/" rel="nofollow"&gt;Jonathan Whitmore&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/matrig"&gt;Mattia Rigotti&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/colibius"&gt;Colby Lemon&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/gustavdelius"&gt;Gustav W Delius&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.mathisonian.com/" rel="nofollow"&gt;Matthew Conlen&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/radford"&gt;Jim Radford&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://baniverso.com/" rel="nofollow"&gt;Vannessa Sabino&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/thomasbratt"&gt;Thomas Bratt&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/nisanharamati"&gt;Nisan Haramati&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/bgrant"&gt;Robert Grant&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/xcthulhu"&gt;Matthew Wampler-Doty&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/yarikoptic"&gt;Yaroslav Halchenko&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/alexgarel"&gt;Alex Garel&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://twitter.com/sash_ko" rel="nofollow"&gt;Oleksandr Lysenko&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/liori"&gt;liori&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/ducky427"&gt;ducky427&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/pablooliveira"&gt;Pablo de Oliveira Castro&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/sergeyfogelson"&gt;sergeyfogelson&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://neurotheory.columbia.edu/~mrigotti/" rel="nofollow"&gt;Mattia Rigotti&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/mbauman"&gt;Matt Bauman&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.andrewduberstein.com/" rel="nofollow"&gt;Andrew Duberstein&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://cebe.cc/" rel="nofollow"&gt;Carsten Brandt&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://web2docx.com" rel="nofollow"&gt;Bob Jansen&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/ugurthemaster"&gt;ugurthemaster&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/williamscott"&gt;William Scott&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://twitter.com/minrk" rel="nofollow"&gt;Min RK&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Bulwersator"&gt;Bulwersator&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/elpres"&gt;elpres&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/hackaugusto"&gt;Augusto Hack&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/michaf"&gt;Michael Feldmann&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Youki"&gt;Youki&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://jensrantil.github.io" rel="nofollow"&gt;Jens Rantil&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kyleam.com" rel="nofollow"&gt;Kyle Meyer&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ericmart.in" rel="nofollow"&gt;Eric Martin&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Inconditus"&gt;Inconditus&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/Kleptine"&gt;Kleptine&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/slayton"&gt;Stuart Layton&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/tritemio"&gt;Antonino Ingargiola&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/vsl9"&gt;vsl9&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/tom-christie"&gt;Tom Christie&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/bclow"&gt;bclow&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://sjp.co.nz/" rel="nofollow"&gt;Simon Potter&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/GarthSnyder"&gt;Garth Snyder&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://twitter.com/pushmatrix" rel="nofollow"&gt;Daniel Beauchamp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.philippsinger.info" rel="nofollow"&gt;Philipp Singer&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/gbenmartin"&gt;gbenmartin&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://twitter.com/Springcoil" rel="nofollow"&gt;Peadar Coyle&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We would like to thank the Python community for building an amazing architecture. We would like to thank the
statistics community for building an amazing architecture.&lt;/p&gt;
&lt;p&gt;Similarly, the book is only possible because of the &lt;a href="http://github.com/pymc-devs/pymc"&gt;PyMC&lt;/a&gt; library. A big thanks to the core devs of PyMC: Chris Fonnesbeck, Anand Patil, David Huard and John Salvatier.&lt;/p&gt;
&lt;p&gt;One final thanks. This book was generated by Jupyter Notebook, a wonderful tool for developing in Python. We thank the IPython/Jupyter
community for developing the Notebook interface. All Jupyter notebook files are available for download on the GitHub repository.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h4&gt;
&lt;p&gt;Contact the main author, Cam Davidson-Pilon at &lt;a href="mailto:cam.davidson.pilon@gmail.com"&gt;cam.davidson.pilon@gmail.com&lt;/a&gt; or &lt;a href="https://twitter.com/cmrn_dp" rel="nofollow"&gt;@cmrndp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/090a62cab61c2a7115a3d8f4f99bffe5f1c75a26/687474703a2f2f692e696d6775722e636f6d2f5a623739515a622e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/090a62cab61c2a7115a3d8f4f99bffe5f1c75a26/687474703a2f2f692e696d6775722e636f6d2f5a623739515a622e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/Zb79QZb.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>CamDavidsonPilon</author><guid isPermaLink="false">https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</guid><pubDate>Tue, 04 Feb 2020 00:09:00 GMT</pubDate></item><item><title>fastai/fastai2 #10 in Jupyter Notebook, This month</title><link>https://github.com/fastai/fastai2</link><description>&lt;p&gt;&lt;i&gt;Temporary home for fastai v2 while it's being developed&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;
&lt;h1&gt;&lt;a id="user-content-welcome-to-fastai-v2" class="anchor" aria-hidden="true" href="#welcome-to-fastai-v2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Welcome to fastai v2&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;NB: This is still in early development. Use v1 unless you want to contribute to the next version of fastai&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing&lt;/h2&gt;
&lt;p&gt;You can get all the necessary dependencies by simply installing fastai v1: &lt;code&gt;conda install -c fastai -c pytorch fastai&lt;/code&gt;. Or alternatively you can automatically install the dependencies into a new environment:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/fastai/fastai2
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; fastai2
conda env create -f environment.yml
&lt;span class="pl-c1"&gt;source&lt;/span&gt; activate fastai2&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, you can install fastai v2 with pip: &lt;code&gt;pip install fastai2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Or you can use an editable install (which is probably the best approach at the moment, since fastai v2 is under heavy development):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/fastai/fastai2
cd fastai2
pip install -e .[dev]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should also use an editable install of &lt;a href="https://github.com/fastai/fastcore"&gt;&lt;code&gt;fastcore&lt;/code&gt;&lt;/a&gt; to go with it.&lt;/p&gt;
&lt;p&gt;To use &lt;code&gt;fastai2.medical.imaging&lt;/code&gt; you'll also need to:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install pyarrow
pip install pydicom kornia opencv-python scikit-image&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-tests" class="anchor" aria-hidden="true" href="#tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tests&lt;/h2&gt;
&lt;p&gt;To run the tests in parallel, launch:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;nbdev_test_nbs&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;make &lt;span class="pl-c1"&gt;test&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;After you clone this repository, please run &lt;code&gt;nbdev_install_git_hooks&lt;/code&gt; in your terminal. This sets up git hooks, which clean up the notebooks to remove the extraneous stuff stored in the notebooks (e.g. which cells you ran) which causes unnecessary merge conflicts.&lt;/p&gt;
&lt;p&gt;Before submitting a PR, check that the local library and notebooks match. The script &lt;code&gt;nbdev_diff_nbs&lt;/code&gt; can let you know if there is a difference between the local library and the notebooks.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you made a change to the notebooks in one of the exported cells, you can export it to the library with &lt;code&gt;nbdev_build_lib&lt;/code&gt; or &lt;code&gt;make fastai2&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If you made a change to the library, you can export it back to the notebooks with &lt;code&gt;nbdev_update_lib&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fastai</author><guid isPermaLink="false">https://github.com/fastai/fastai2</guid><pubDate>Tue, 04 Feb 2020 00:10:00 GMT</pubDate></item><item><title>aimacode/aima-python #11 in Jupyter Notebook, This month</title><link>https://github.com/aimacode/aima-python</link><description>&lt;p&gt;&lt;i&gt;Python implementation of algorithms from Russell And Norvig's "Artificial Intelligence - A Modern Approach"&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;div align="center"&gt;
  &lt;a href="http://aima.cs.berkeley.edu/" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/aimacode/aima-python/master/images/aima_logo.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;
&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-aima-python--" class="anchor" aria-hidden="true" href="#aima-python--"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;aima-python&lt;/code&gt; &lt;a href="https://travis-ci.org/aimacode/aima-python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/01177a7ca5a96309e258148841f9c5c82ff80993/68747470733a2f2f7472617669732d63692e6f72672f61696d61636f64652f61696d612d707974686f6e2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/aimacode/aima-python.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="http://mybinder.org/repo/aimacode/aima-python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/70c5b4d050d4019f4f20b170d75679a9316ac5e5/687474703a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="http://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Python code for the book &lt;em&gt;&lt;a href="http://aima.cs.berkeley.edu" rel="nofollow"&gt;Artificial Intelligence: A Modern Approach&lt;/a&gt;.&lt;/em&gt; You can use this in conjunction with a course on AI, or for study on your own. We're looking for &lt;a href="https://github.com/aimacode/aima-python/blob/master/CONTRIBUTING.md"&gt;solid contributors&lt;/a&gt; to help.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-structure-of-the-project" class="anchor" aria-hidden="true" href="#structure-of-the-project"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Structure of the Project&lt;/h2&gt;
&lt;p&gt;When complete, this project will have Python implementations for all the pseudocode algorithms in the book, as well as tests and examples of use. For each major topic, such as &lt;code&gt;nlp&lt;/code&gt; (natural language processing), we provide the following  files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;nlp.py&lt;/code&gt;: Implementations of all the pseudocode algorithms, and necessary support functions/classes/data.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tests/test_nlp.py&lt;/code&gt;: A lightweight test suite, using &lt;code&gt;assert&lt;/code&gt; statements, designed for use with &lt;a href="http://pytest.org/latest/" rel="nofollow"&gt;&lt;code&gt;py.test&lt;/code&gt;&lt;/a&gt;, but also usable on their own.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nlp.ipynb&lt;/code&gt;: A Jupyter (IPython) notebook that explains and gives examples of how to use the code.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nlp_apps.ipynb&lt;/code&gt;: A Jupyter notebook that gives example applications of the code.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-python-34-and-up" class="anchor" aria-hidden="true" href="#python-34-and-up"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python 3.4 and up&lt;/h2&gt;
&lt;p&gt;This code requires Python 3.4 or later, and does not run in Python 2. You can &lt;a href="https://www.python.org/downloads" rel="nofollow"&gt;install Python&lt;/a&gt; or use a browser-based Python interpreter such as &lt;a href="https://repl.it/languages/python3" rel="nofollow"&gt;repl.it&lt;/a&gt;.
You can run the code in an IDE, or from the command line with &lt;code&gt;python -i filename.py&lt;/code&gt; where the &lt;code&gt;-i&lt;/code&gt; option puts you in an interactive loop where you can run Python functions. All notebooks are available in a &lt;a href="http://mybinder.org/repo/aimacode/aima-python" rel="nofollow"&gt;binder environment&lt;/a&gt;. Alternatively, visit &lt;a href="http://jupyter.org/" rel="nofollow"&gt;jupyter.org&lt;/a&gt; for instructions on setting up your own Jupyter notebook environment.&lt;/p&gt;
&lt;p&gt;There is a sibling &lt;a href="https://github.com/rajatjain1997/aima-docker"&gt;aima-docker&lt;/a&gt; project that shows you how to use docker containers to run more complex problems in more complex software environments.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation-guide" class="anchor" aria-hidden="true" href="#installation-guide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation Guide&lt;/h2&gt;
&lt;p&gt;To download the repository:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git clone https://github.com/aimacode/aima-python.git&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Then you need to install the basic dependencies to run the project on your system:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd aima-python
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You also need to fetch the datasets from the &lt;a href="https://github.com/aimacode/aima-data"&gt;&lt;code&gt;aima-data&lt;/code&gt;&lt;/a&gt; repository:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git submodule init
git submodule update
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wait for the datasets to download, it may take a while. Once they are downloaded, you need to install &lt;code&gt;pytest&lt;/code&gt;, so that you can run the test suite:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pip install pytest&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Then to run the tests:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py.test&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And you are good to go!&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-index-of-algorithms" class="anchor" aria-hidden="true" href="#index-of-algorithms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Index of Algorithms&lt;/h1&gt;
&lt;p&gt;Here is a table of algorithms, the figure, name of the algorithm in the book and in the repository, and the file where they are implemented in the repository. This chart was made for the third edition of the book and is being updated for the upcoming fourth edition. Empty implementations are a good place for contributors to look for an issue. The &lt;a href="https://github.com/aimacode/aima-pseudocode"&gt;aima-pseudocode&lt;/a&gt; project describes all the algorithms from the book. An asterisk next to the file name denotes the algorithm is not fully implemented. Another great place for contributors to start is by adding tests and writing on the notebooks. You can see which algorithms have tests and notebook sections below. If the algorithm you want to work on is covered, don't worry! You can still add more tests and provide some examples of use in the notebook!&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;strong&gt;Figure&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;Name (in 3&lt;sup&gt;rd&lt;/sup&gt; edition)&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;Name (in repository)&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;File&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;Tests&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;Notebook&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;Random-Vacuum-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;RandomVacuumAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;Model-Based-Vacuum-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;ModelBasedVacuumAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.1&lt;/td&gt;
&lt;td align="left"&gt;Environment&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Environment&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.1&lt;/td&gt;
&lt;td align="left"&gt;Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Agent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.3&lt;/td&gt;
&lt;td align="left"&gt;Table-Driven-Vacuum-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;TableDrivenVacuumAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.7&lt;/td&gt;
&lt;td align="left"&gt;Table-Driven-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;TableDrivenAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.8&lt;/td&gt;
&lt;td align="left"&gt;Reflex-Vacuum-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;ReflexVacuumAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.10&lt;/td&gt;
&lt;td align="left"&gt;Simple-Reflex-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;SimpleReflexAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.12&lt;/td&gt;
&lt;td align="left"&gt;Model-Based-Reflex-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;ReflexAgentWithState&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;Problem&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Problem&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;Node&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Node&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;Queue&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Queue&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/utils.py"&gt;&lt;code&gt;utils.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;No Need&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.1&lt;/td&gt;
&lt;td align="left"&gt;Simple-Problem-Solving-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;SimpleProblemSolvingAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.2&lt;/td&gt;
&lt;td align="left"&gt;Romania&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;romania&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.7&lt;/td&gt;
&lt;td align="left"&gt;Tree-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;depth/breadth_first_tree_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.7&lt;/td&gt;
&lt;td align="left"&gt;Graph-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;depth/breadth_first_graph_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.11&lt;/td&gt;
&lt;td align="left"&gt;Breadth-First-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;breadth_first_graph_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.14&lt;/td&gt;
&lt;td align="left"&gt;Uniform-Cost-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;uniform_cost_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.17&lt;/td&gt;
&lt;td align="left"&gt;Depth-Limited-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;depth_limited_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.18&lt;/td&gt;
&lt;td align="left"&gt;Iterative-Deepening-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;iterative_deepening_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.22&lt;/td&gt;
&lt;td align="left"&gt;Best-First-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;best_first_graph_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.24&lt;/td&gt;
&lt;td align="left"&gt;A*-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;astar_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.26&lt;/td&gt;
&lt;td align="left"&gt;Recursive-Best-First-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;recursive_best_first_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.2&lt;/td&gt;
&lt;td align="left"&gt;Hill-Climbing&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;hill_climbing&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.5&lt;/td&gt;
&lt;td align="left"&gt;Simulated-Annealing&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;simulated_annealing&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.8&lt;/td&gt;
&lt;td align="left"&gt;Genetic-Algorithm&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;genetic_algorithm&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.11&lt;/td&gt;
&lt;td align="left"&gt;And-Or-Graph-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;and_or_graph_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.21&lt;/td&gt;
&lt;td align="left"&gt;Online-DFS-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;online_dfs_agent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.24&lt;/td&gt;
&lt;td align="left"&gt;LRTA*-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;LRTAStarAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;5.3&lt;/td&gt;
&lt;td align="left"&gt;Minimax-Decision&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;minimax_decision&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/games.py"&gt;&lt;code&gt;games.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;5.7&lt;/td&gt;
&lt;td align="left"&gt;Alpha-Beta-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;alphabeta_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/games.py"&gt;&lt;code&gt;games.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;6&lt;/td&gt;
&lt;td align="left"&gt;CSP&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;CSP&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/csp.py"&gt;&lt;code&gt;csp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;6.3&lt;/td&gt;
&lt;td align="left"&gt;AC-3&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;AC3&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/csp.py"&gt;&lt;code&gt;csp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;6.5&lt;/td&gt;
&lt;td align="left"&gt;Backtracking-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;backtracking_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/csp.py"&gt;&lt;code&gt;csp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;6.8&lt;/td&gt;
&lt;td align="left"&gt;Min-Conflicts&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;min_conflicts&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/csp.py"&gt;&lt;code&gt;csp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;6.11&lt;/td&gt;
&lt;td align="left"&gt;Tree-CSP-Solver&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;tree_csp_solver&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/csp.py"&gt;&lt;code&gt;csp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7&lt;/td&gt;
&lt;td align="left"&gt;KB&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;KB&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.1&lt;/td&gt;
&lt;td align="left"&gt;KB-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;KB_AgentProgram&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.7&lt;/td&gt;
&lt;td align="left"&gt;Propositional Logic Sentence&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Expr&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/utils.py"&gt;&lt;code&gt;utils.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.10&lt;/td&gt;
&lt;td align="left"&gt;TT-Entails&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;tt_entails&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.12&lt;/td&gt;
&lt;td align="left"&gt;PL-Resolution&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;pl_resolution&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.14&lt;/td&gt;
&lt;td align="left"&gt;Convert to CNF&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;to_cnf&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.15&lt;/td&gt;
&lt;td align="left"&gt;PL-FC-Entails?&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;pl_fc_entails&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.17&lt;/td&gt;
&lt;td align="left"&gt;DPLL-Satisfiable?&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;dpll_satisfiable&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.18&lt;/td&gt;
&lt;td align="left"&gt;WalkSAT&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;WalkSAT&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.20&lt;/td&gt;
&lt;td align="left"&gt;Hybrid-Wumpus-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;HybridWumpusAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.22&lt;/td&gt;
&lt;td align="left"&gt;SATPlan&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;SAT_plan&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;9&lt;/td&gt;
&lt;td align="left"&gt;Subst&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;subst&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;9.1&lt;/td&gt;
&lt;td align="left"&gt;Unify&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;unify&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;9.3&lt;/td&gt;
&lt;td align="left"&gt;FOL-FC-Ask&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;fol_fc_ask&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;9.6&lt;/td&gt;
&lt;td align="left"&gt;FOL-BC-Ask&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;fol_bc_ask&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;10.1&lt;/td&gt;
&lt;td align="left"&gt;Air-Cargo-problem&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;air_cargo&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;10.2&lt;/td&gt;
&lt;td align="left"&gt;Spare-Tire-Problem&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;spare_tire&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;10.3&lt;/td&gt;
&lt;td align="left"&gt;Three-Block-Tower&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;three_block_tower&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;10.7&lt;/td&gt;
&lt;td align="left"&gt;Cake-Problem&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;have_cake_and_eat_cake_too&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;10.9&lt;/td&gt;
&lt;td align="left"&gt;Graphplan&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;GraphPlan&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;10.13&lt;/td&gt;
&lt;td align="left"&gt;Partial-Order-Planner&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;PartialOrderPlanner&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;11.1&lt;/td&gt;
&lt;td align="left"&gt;Job-Shop-Problem-With-Resources&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;job_shop_problem&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;11.5&lt;/td&gt;
&lt;td align="left"&gt;Hierarchical-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;hierarchical_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;11.8&lt;/td&gt;
&lt;td align="left"&gt;Angelic-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;angelic_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;11.10&lt;/td&gt;
&lt;td align="left"&gt;Doubles-tennis&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;double_tennis_problem&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;13&lt;/td&gt;
&lt;td align="left"&gt;Discrete Probability Distribution&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;ProbDist&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;13.1&lt;/td&gt;
&lt;td align="left"&gt;DT-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;DTAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;14.9&lt;/td&gt;
&lt;td align="left"&gt;Enumeration-Ask&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;enumeration_ask&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;14.11&lt;/td&gt;
&lt;td align="left"&gt;Elimination-Ask&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;elimination_ask&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;14.13&lt;/td&gt;
&lt;td align="left"&gt;Prior-Sample&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;prior_sample&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;14.14&lt;/td&gt;
&lt;td align="left"&gt;Rejection-Sampling&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;rejection_sampling&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;14.15&lt;/td&gt;
&lt;td align="left"&gt;Likelihood-Weighting&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;likelihood_weighting&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;14.16&lt;/td&gt;
&lt;td align="left"&gt;Gibbs-Ask&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;gibbs_ask&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;15.4&lt;/td&gt;
&lt;td align="left"&gt;Forward-Backward&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;forward_backward&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;15.6&lt;/td&gt;
&lt;td align="left"&gt;Fixed-Lag-Smoothing&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;fixed_lag_smoothing&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;15.17&lt;/td&gt;
&lt;td align="left"&gt;Particle-Filtering&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;particle_filtering&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;16.9&lt;/td&gt;
&lt;td align="left"&gt;Information-Gathering-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;InformationGatheringAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;17.4&lt;/td&gt;
&lt;td align="left"&gt;Value-Iteration&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;value_iteration&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/mdp.py"&gt;&lt;code&gt;mdp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;17.7&lt;/td&gt;
&lt;td align="left"&gt;Policy-Iteration&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;policy_iteration&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/mdp.py"&gt;&lt;code&gt;mdp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;17.9&lt;/td&gt;
&lt;td align="left"&gt;POMDP-Value-Iteration&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;pomdp_value_iteration&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/mdp.py"&gt;&lt;code&gt;mdp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18.5&lt;/td&gt;
&lt;td align="left"&gt;Decision-Tree-Learning&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;DecisionTreeLearner&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/learning.py"&gt;&lt;code&gt;learning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18.8&lt;/td&gt;
&lt;td align="left"&gt;Cross-Validation&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;cross_validation&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/learning.py"&gt;&lt;code&gt;learning.py&lt;/code&gt;&lt;/a&gt;*&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18.11&lt;/td&gt;
&lt;td align="left"&gt;Decision-List-Learning&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;DecisionListLearner&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/learning.py"&gt;&lt;code&gt;learning.py&lt;/code&gt;&lt;/a&gt;*&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18.24&lt;/td&gt;
&lt;td align="left"&gt;Back-Prop-Learning&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;BackPropagationLearner&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/learning.py"&gt;&lt;code&gt;learning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18.34&lt;/td&gt;
&lt;td align="left"&gt;AdaBoost&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;AdaBoost&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/learning.py"&gt;&lt;code&gt;learning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;19.2&lt;/td&gt;
&lt;td align="left"&gt;Current-Best-Learning&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;current_best_learning&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="knowledge.py"&gt;&lt;code&gt;knowledge.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;19.3&lt;/td&gt;
&lt;td align="left"&gt;Version-Space-Learning&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;version_space_learning&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="knowledge.py"&gt;&lt;code&gt;knowledge.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;19.8&lt;/td&gt;
&lt;td align="left"&gt;Minimal-Consistent-Det&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;minimal_consistent_det&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="knowledge.py"&gt;&lt;code&gt;knowledge.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;19.12&lt;/td&gt;
&lt;td align="left"&gt;FOIL&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;FOIL_container&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="knowledge.py"&gt;&lt;code&gt;knowledge.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;21.2&lt;/td&gt;
&lt;td align="left"&gt;Passive-ADP-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;PassiveADPAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/rl.py"&gt;&lt;code&gt;rl.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;21.4&lt;/td&gt;
&lt;td align="left"&gt;Passive-TD-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;PassiveTDAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/rl.py"&gt;&lt;code&gt;rl.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;21.8&lt;/td&gt;
&lt;td align="left"&gt;Q-Learning-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;QLearningAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/rl.py"&gt;&lt;code&gt;rl.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;22.1&lt;/td&gt;
&lt;td align="left"&gt;HITS&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;HITS&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/nlp.py"&gt;&lt;code&gt;nlp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;23&lt;/td&gt;
&lt;td align="left"&gt;Chart-Parse&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Chart&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/nlp.py"&gt;&lt;code&gt;nlp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;23.5&lt;/td&gt;
&lt;td align="left"&gt;CYK-Parse&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;CYK_parse&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/nlp.py"&gt;&lt;code&gt;nlp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;25.9&lt;/td&gt;
&lt;td align="left"&gt;Monte-Carlo-Localization&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;monte_carlo_localization&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-index-of-data-structures" class="anchor" aria-hidden="true" href="#index-of-data-structures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Index of data structures&lt;/h1&gt;
&lt;p&gt;Here is a table of the implemented data structures, the figure, name of the implementation in the repository, and the file where they are implemented.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;strong&gt;Figure&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;Name (in repository)&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;File&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.2&lt;/td&gt;
&lt;td align="left"&gt;romania_map&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.9&lt;/td&gt;
&lt;td align="left"&gt;vacumm_world&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.23&lt;/td&gt;
&lt;td align="left"&gt;one_dim_state_space&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;6.1&lt;/td&gt;
&lt;td align="left"&gt;australia_map&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.13&lt;/td&gt;
&lt;td align="left"&gt;wumpus_world_inference&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.16&lt;/td&gt;
&lt;td align="left"&gt;horn_clauses_KB&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;17.1&lt;/td&gt;
&lt;td align="left"&gt;sequential_decision_environment&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/mdp.py"&gt;&lt;code&gt;mdp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18.2&lt;/td&gt;
&lt;td align="left"&gt;waiting_decision_tree&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/learning.py"&gt;&lt;code&gt;learning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgements&lt;/h1&gt;
&lt;p&gt;Many thanks for contributions over the years. I got bug reports, corrected code, and other support from Darius Bacon, Phil Ruggera, Peng Shao, Amit Patil, Ted Nienstedt, Jim Martin, Ben Catanzariti, and others. Now that the project is on GitHub, you can see the &lt;a href="https://github.com/aimacode/aima-python/graphs/contributors"&gt;contributors&lt;/a&gt; who are doing a great job of actively improving the project. Many thanks to all contributors, especially &lt;a href="https://github.com/darius"&gt;@darius&lt;/a&gt;, &lt;a href="https://github.com/SnShine"&gt;@SnShine&lt;/a&gt;, &lt;a href="https://github.com/reachtarunhere"&gt;@reachtarunhere&lt;/a&gt;, &lt;a href="https://github.com/antmarakis"&gt;@antmarakis&lt;/a&gt;, &lt;a href="https://github.com/Chipe1"&gt;@Chipe1&lt;/a&gt;, &lt;a href="https://github.com/ad71"&gt;@ad71&lt;/a&gt; and &lt;a href="https://github.com/MariannaSpyrakou"&gt;@MariannaSpyrakou&lt;/a&gt;.&lt;/p&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>aimacode</author><guid isPermaLink="false">https://github.com/aimacode/aima-python</guid><pubDate>Tue, 04 Feb 2020 00:11:00 GMT</pubDate></item><item><title>jeffheaton/t81_558_deep_learning #12 in Jupyter Notebook, This month</title><link>https://github.com/jeffheaton/t81_558_deep_learning</link><description>&lt;p&gt;&lt;i&gt;Washington University (in St. Louis) Course T81-558: Applications of Deep Neural Networks&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-t81-558applications-of-deep-neural-networks" class="anchor" aria-hidden="true" href="#t81-558applications-of-deep-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;T81 558:Applications of Deep Neural Networks&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://www.wustl.edu" rel="nofollow"&gt;Washington University in St. Louis&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Instructor: &lt;a href="https://sites.wustl.edu/jeffheaton/" rel="nofollow"&gt;Jeff Heaton&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The content of this course changes as technology evolves&lt;/strong&gt;, to keep up to date with changes &lt;a href="https://github.com/jeffheaton"&gt;follow me on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Section 2. Spring 2020, Monday, 2:30 PM - 5:20 PM Online &amp;amp; Cupples I / 215&lt;/li&gt;
&lt;li&gt;Section 1. Spring 2020, Monday, 6:00 PM - 9:00 PM Online &amp;amp; Cupples I / 215&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-course-description" class="anchor" aria-hidden="true" href="#course-description"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course Description&lt;/h1&gt;
&lt;p&gt;Deep learning is a group of exciting new technologies for neural networks. Through a combination of advanced training techniques and neural network architectural components, it is now possible to create neural networks that can handle tabular data, images, text, and audio as both input and output. Deep learning allows a neural network to learn hierarchies of information in a way that is like the function of the human brain. This course will introduce the student to classic neural network structures, Convolution Neural Networks (CNN), Long Short-Term Memory (LSTM), Gated Recurrent Neural Networks (GRU), General Adversarial Networks (GAN) and reinforcement learning. Application of these architectures to computer vision, time series, security, natural language processing (NLP), and data generation will be covered. High Performance Computing (HPC) aspects will demonstrate how deep learning can be leveraged both on graphical processing units (GPUs), as well as grids. Focus is primarily upon the application of deep learning to problems, with some introduction to mathematical foundations. Students will use the Python programming language to implement deep learning using Google TensorFlow and Keras. It is not necessary to know Python prior to this course; however, familiarity of at least one programming language is assumed. This course will be delivered in a hybrid format that includes both classroom and online instruction.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-objectives" class="anchor" aria-hidden="true" href="#objectives"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Objectives&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Explain how neural networks (deep and otherwise) compare to other machine learning models.&lt;/li&gt;
&lt;li&gt;Determine when a deep neural network would be a good choice for a particular problem.&lt;/li&gt;
&lt;li&gt;Demonstrate your understanding of the material through a final project uploaded to GitHub.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;&lt;a id="user-content-syllabus" class="anchor" aria-hidden="true" href="#syllabus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Syllabus&lt;/h1&gt;
&lt;p&gt;This syllabus presents the expected class schedule, due dates, and reading assignments.  &lt;a href="https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/pdf/t81_558_spring2020_syllabus.pdf" rel="nofollow"&gt;Download current syllabus.&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Module&lt;/th&gt;
&lt;th&gt;Content&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_01_1_overview.ipynb"&gt;Module 1&lt;/a&gt;&lt;br&gt;&lt;strong&gt;Meet on 01/13/2020&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 1: Python Preliminaries&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;Part 1.1: Course Overview&lt;/li&gt;&lt;li&gt;Part 1.2: Introduction to Python&lt;/li&gt;&lt;li&gt;Part 1.3: Python Lists, Dictionaries, Sets &amp;amp; JSON&lt;/li&gt;&lt;li&gt;Part 1.4: File Handling&lt;/li&gt;&lt;li&gt;Part 1.5: Functions, Lambdas, and Map/ReducePython Preliminaries&lt;/li&gt;&lt;li&gt;&lt;strong&gt;We will meet on campus this week!&lt;/strong&gt; (first meeting)&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_02_1_python_pandas.ipynb"&gt;Module 2&lt;/a&gt;&lt;br&gt;Week of 01/27/2020&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 2: Python for Machine Learning&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;	Part 2.1: Introduction to Pandas for Deep Learning&lt;/li&gt;&lt;li&gt;Part 2.2: Encoding Categorical Values in Pandas&lt;/li&gt;&lt;li&gt;Part 2.3: Grouping, Sorting, and Shuffling&lt;/li&gt;&lt;li&gt;Part 2.4: Using Apply and Map in Pandas&lt;/li&gt;&lt;li&gt;Part 2.5: Feature Engineering in Padas&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class1.ipynb"&gt;Module 1 Assignment&lt;/a&gt; Due: 01/28/2020&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_03_1_neural_net.ipynb"&gt;Module 3&lt;/a&gt;&lt;br&gt;Week of 02/03/2020&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 3: TensorFlow and Keras for Neural Networks&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;Part 3.1: Deep Learning and Neural Network Introduction&lt;/li&gt;&lt;li&gt;Part 3.2: Introduction to Tensorflow &amp;amp; Keras&lt;/li&gt;&lt;li&gt;Part 3.3: Saving and Loading a Keras Neural Network&lt;/li&gt;&lt;li&gt;Part 3.4: Early Stopping in Keras to Prevent Overfitting&lt;/li&gt;&lt;li&gt;Part 3.5: Extracting Keras Weights and Manual Neural Network Calculation&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class2.ipynb"&gt;Module 2: Assignment&lt;/a&gt; due: 02/04/2020&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_04_1_feature_encode.ipynb"&gt;Module 4&lt;/a&gt;&lt;br&gt;Week of 02/10/2020&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 4: Training for Tabular Data&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;Part 4.1: Encoding a Feature Vector for Keras Deep Learning&lt;/li&gt;&lt;li&gt;Part 4.2: Keras Multiclass Classification for Deep Neural Networks with ROC and AUC&lt;/li&gt;&lt;li&gt;Part 4.3: Keras Regression for Deep Neural Networks with RMSE&lt;/li&gt;&lt;li&gt;Part 4.4: Backpropagation, Nesterov Momentum, and ADAM Training&lt;/li&gt;&lt;li&gt;Part 4.5: Neural Network RMSE and Log Loss Error Calculation from Scratch&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class3.ipynb"&gt;Module 3 Assignment&lt;/a&gt; due: 02/11/2020&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_05_1_reg_ridge_lasso.ipynb"&gt;Module 5&lt;/a&gt;&lt;br&gt;Week of 02/17/2020&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 5: Regularization and Dropout&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;Part 5.1: Introduction to Regularization: Ridge and Lasso&lt;/li&gt;&lt;li&gt;Part 5.2: Using K-Fold Cross Validation with Keras&lt;/li&gt;&lt;li&gt;Part 5.3: Using L1 and L2 Regularization with Keras to Decrease Overfitting&lt;/li&gt;&lt;li&gt;Part 5.4: Drop Out for Keras to Decrease Overfitting&lt;/li&gt;&lt;li&gt;Part 5.5: Bootstrapping and Benchmarking Hyperparameters&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class4.ipynb"&gt;Module 4 Assignment&lt;/a&gt; due: 02/18/2020&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_06_1_python_images.ipynb"&gt;Module 6&lt;/a&gt;&lt;br&gt;&lt;strong&gt;Meet on 02/24/2020&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 6: CNN for Vision&lt;/strong&gt;&lt;ul&gt;	Part 6.1: Image Processing in Python&lt;li&gt;Part 6.2: Keras Neural Networks for MINST and Fashion MINST&lt;/li&gt;&lt;li&gt;Part 6.3: Implementing a ResNet in Keras&lt;/li&gt;&lt;li&gt;Part 6.4: Computer Vision with OpenCV&lt;/li&gt;&lt;li&gt;Part 6.5: Recognizing Multiple Images with Darknet&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class5.ipynb"&gt;Module 5 Assignment&lt;/a&gt; due: 02/25/2020&lt;/li&gt;&lt;li&gt;&lt;strong&gt;We will meet on campus this week!&lt;/strong&gt; (2nd Meeting)&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_07_1_gan_intro.ipynb"&gt;Module 7&lt;/a&gt;&lt;br&gt;Week of 03/02/2020&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 7: GAN&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;Part 7.1: Introduction to GANS for Image and Data Generation&lt;/li&gt;&lt;li&gt;Part 7.2: Implementing a GAN in Keras&lt;/li&gt;&lt;li&gt;Part 7.3: Face Generation with StyleGAN and Python&lt;/li&gt;&lt;li&gt;Part 7.4: GANS for Semi-Supervised Learning in Keras&lt;/li&gt;&lt;li&gt;Part 7.5: An Overview of GAN Research&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class6.ipynb"&gt;Module 6 Assignment&lt;/a&gt; due: 03/03/2020&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_08_1_kaggle_intro.ipynb"&gt;Module 8&lt;/a&gt;&lt;br&gt;Week of 03/16/2020&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 8: Kaggle&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;Part 8.1: Introduction to Kaggle&lt;/li&gt;&lt;li&gt;Part 8.2: Building Ensembles with Scikit-Learn and Keras&lt;/li&gt;&lt;li&gt;Part 8.3: How Should you Architect Your Keras Neural Network: Hyperparameters&lt;/li&gt;&lt;li&gt;Part 8.4: Bayesian Hyperparameter Optimization for Keras&lt;/li&gt;&lt;li&gt;Part 8.5: Current Semester's Kaggle&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class7.ipynb"&gt;Module 7 Assignment&lt;/a&gt; due: 03/17/2020&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_09_1_keras_transfer.ipynb"&gt;Module 9&lt;/a&gt;&lt;br&gt;Week of 03/23/2020&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 9: Transfer Learning&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;Part 9.1: Introduction to Keras Transfer Learning&lt;/li&gt;&lt;li&gt;Part 9.2: Popular Pretrained Neural Networks for Keras. &lt;/li&gt;&lt;li&gt;Part 9.3: Transfer Learning for Computer Vision and Keras&lt;/li&gt;&lt;li&gt;Part 9.4: Transfer Learning for Languages and Keras&lt;/li&gt;&lt;li&gt;Part 9.5: Transfer Learning for Keras Feature Engineering&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class8.ipynb"&gt;Module 8 Assignment&lt;/a&gt; due: 03/24/2020&lt;/li&gt;&lt;li&gt;&lt;strong&gt;We will meet on campus this week!&lt;/strong&gt; (3rd Meeting)&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_10_1_timeseries.ipynb"&gt;Module 10&lt;/a&gt;&lt;br&gt;Week of 03/30/2020&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 10: Time Series in Keras&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;Part 10.1: Time Series Data Encoding for Deep Learning, TensorFlow and Keras&lt;/li&gt;&lt;li&gt;Part 10.2: Programming LSTM with Keras and TensorFlow&lt;/li&gt;&lt;li&gt;Part 10.3: Image Captioning with Keras and TensorFlow&lt;/li&gt;&lt;li&gt;Part 10.4: Temporal CNN in Keras and TensorFlow&lt;/li&gt;&lt;li&gt;Part 10.5: Predicting the Stock Market with Keras and TensorFlow&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class9.ipynb"&gt;Module 9 Assignment&lt;/a&gt; due: 03/31/2020&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_11_01_spacy.ipynb"&gt;Module 11&lt;/a&gt;&lt;br&gt;Week of 04/06/2020&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 11: Natural Language Processing&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;Part 11.1: Getting Started with Spacy in Python&lt;/li&gt;&lt;li&gt;Part 11.2: Word2Vec and Text Classification&lt;/li&gt;&lt;li&gt;Part 11.3: Natural Language Processing with Spacy and Keras&lt;/li&gt;&lt;li&gt;Part 11.4: What are Embedding Layers in Keras&lt;/li&gt;&lt;li&gt;Part 11.5: Learning English from Scratch with Keras and TensorFlow&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class10.ipynb"&gt;Module 10 Assignment&lt;/a&gt; due: 04/07/2020&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_12_01_ai_gym.ipynb"&gt;Module 12&lt;/a&gt;&lt;br&gt;Week of 04/13/2020&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 12: Reinforcement Learning&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;Kaggle Assignment due: 04/13/2020 (approx 4-6PM, due to Kaggle GMT timezone)&lt;/li&gt;&lt;li&gt;Part 12.1: Introduction to the OpenAI Gym&lt;/li&gt;&lt;li&gt;Part 12.2: Introduction to Q-Learning for Keras&lt;/li&gt;&lt;li&gt;Part 12.3: Keras Q-Learning in the OpenAI Gym&lt;/li&gt;&lt;li&gt;Part 12.4: Atari Games with Keras Neural Networks&lt;/li&gt;&lt;li&gt;Part 12.5: How Alpha Zero used Reinforcement Learning to Master Chess&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_13_01_flask.ipynb"&gt;Module 13&lt;/a&gt;&lt;br&gt;&lt;strong&gt;Meet on 04/20/2020&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 13: Deployment and Monitoring&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;Part 13.1: Deploying a Model to AWS&lt;/li&gt;&lt;li&gt;Part 13.2: Flask and Deep Learning Web Services&lt;/li&gt;&lt;li&gt;Part 13.3: AI at the Edge: Using Keras on a Mobile Device&lt;/li&gt;&lt;li&gt;Part 13.4: When to Retrain Your Neural Network&lt;/li&gt;&lt;li&gt;Part 13.5: Using a Keras Deep Neural Network with a Web Application&lt;/li&gt;&lt;li&gt;&lt;strong&gt;We will meet on campus this week!&lt;/strong&gt; (4th Meeting)&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="t81_558_class_14_01_automl.ipynb"&gt;Module 14&lt;/a&gt;&lt;br&gt;Week of 04/27/2020&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Module 14: Other Neural Network Techniques&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;Part 14.1: What is AutoML&lt;/li&gt;&lt;li&gt;Part 14.2: Using Denoising AutoEncoders in Keras&lt;/li&gt;&lt;li&gt;Part 14.3: Training an Intrusion Detection System with KDD99&lt;/li&gt;&lt;li&gt;Part 14.4: Anomaly Detection in Keras&lt;/li&gt;&lt;li&gt;Part 14.5: New Technology in Deep Learning&lt;/li&gt;&lt;li&gt;Final Project due 05/04/2020&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-datasets" class="anchor" aria-hidden="true" href="#datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Datasets&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://data.heatonresearch.com/data/t81-558/index.html" rel="nofollow"&gt;Datasets can be downloaded here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jeffheaton</author><guid isPermaLink="false">https://github.com/jeffheaton/t81_558_deep_learning</guid><pubDate>Tue, 04 Feb 2020 00:12:00 GMT</pubDate></item><item><title>randerson112358/Python #13 in Jupyter Notebook, This month</title><link>https://github.com/randerson112358/Python</link><description>&lt;p&gt;&lt;i&gt;:snake: Python Programs&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-python" class="anchor" aria-hidden="true" href="#python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python&lt;/h1&gt;
&lt;p&gt;This is a repository that holds my Python programs&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2cffe57e3c8276001c970391a67d67cf3a02f165/68747470733a2f2f7777772e707974686f6e2e6f72672f7374617469632f636f6d6d756e6974795f6c6f676f732f707974686f6e2d6c6f676f2d696e6b73636170652e737667"&gt;&lt;img src="https://camo.githubusercontent.com/2cffe57e3c8276001c970391a67d67cf3a02f165/68747470733a2f2f7777772e707974686f6e2e6f72672f7374617469632f636f6d6d756e6974795f6c6f676f732f707974686f6e2d6c6f676f2d696e6b73636170652e737667" width="400" data-canonical-src="https://www.python.org/static/community_logos/python-logo-inkscape.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
To see me programming in Python checkout the YouTube channel: &lt;a href="https://www.youtube.com/playlist?list=PLBhJnyA0V0uIP6tScPs01FW5WtSpJdmcv" rel="nofollow"&gt;Go To YouTube Channel&lt;/a&gt;
&lt;h1&gt;&lt;a id="user-content-relavent-books-on-amazon" class="anchor" aria-hidden="true" href="#relavent-books-on-amazon"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Relavent Books On Amazon&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/1449355730/ref=as_li_tl?ie=UTF8&amp;amp;tag=github01d-20&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;linkCode=as2&amp;amp;creativeASIN=1449355730&amp;amp;linkId=95e6eaf8c12b9fcd483dd06c1dd53e48" rel="nofollow"&gt;Learning Python, 5th Edition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/1491962291/ref=as_li_tl?ie=UTF8&amp;amp;tag=github01d-20&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;linkCode=as2&amp;amp;creativeASIN=1491962291&amp;amp;linkId=9dec6584d63a7cfcbc32af1ff9737bbf" rel="nofollow"&gt;Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/1491912057/ref=as_li_tl?ie=UTF8&amp;amp;tag=github01d-20&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;linkCode=as2&amp;amp;creativeASIN=1491912057&amp;amp;linkId=af650651a6d71fdea49cd5aa95653e1c" rel="nofollow"&gt;Python Data Science Handbook: Essential Tools for Working with Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/1449369413/ref=as_li_tl?ie=UTF8&amp;amp;tag=github01d-20&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;linkCode=as2&amp;amp;creativeASIN=1449369413&amp;amp;linkId=7b6ad9375121575c83af505f2a3ed6f3" rel="nofollow"&gt;Introduction to Machine Learning with Python: A Guide for Data Scientists&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-python-data-cleaning-programs" class="anchor" aria-hidden="true" href="#python-data-cleaning-programs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python Data Cleaning Programs&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Program Name&lt;/th&gt;
&lt;th&gt;Algorithm Name&lt;/th&gt;
&lt;th&gt;Link to Program&lt;/th&gt;
&lt;th&gt;Blog&lt;/th&gt;
&lt;th&gt;YouTube&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;concatenate_file.py&lt;/td&gt;
&lt;td&gt;Concatenate Multiple CSV files&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/concatenate_file.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://everythingcomputerscience.com/" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/channel/UCbmb5IoBtHZTpYZCDBOC1CA" rel="nofollow"&gt;YouTubeX&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;remove_empty_row.py&lt;/td&gt;
&lt;td&gt;Removes Empty Rows&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/remove_empty_row.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://everythingcomputerscience.com/" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/channel/UCbmb5IoBtHZTpYZCDBOC1CA" rel="nofollow"&gt;YouTubeX&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;replace_strings_with_numbers.py&lt;/td&gt;
&lt;td&gt;Changes Strings in CSV to Numbers&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Replace_Strings_With_Numbers/replace_strings_with_numbers.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://everythingcomputerscience.com/" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/zv_fzW2iA_U" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-web-scraping" class="anchor" aria-hidden="true" href="#web-scraping"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web Scraping&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Program Name&lt;/th&gt;
&lt;th&gt;Algorithm Name&lt;/th&gt;
&lt;th&gt;Link to Program&lt;/th&gt;
&lt;th&gt;Blog&lt;/th&gt;
&lt;th&gt;YouTube&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;scrape.py&lt;/td&gt;
&lt;td&gt;Scrape Website Links&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/scrape.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/scrape-website-using-python-90619cac7c97" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/LGZEn1OYUTk" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;News_Article.py&lt;/td&gt;
&lt;td&gt;Scrape &amp;amp; Summarize Article&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/News_Article.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://everythingcomputerscience.com/" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/YzMA2O_v5co" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-machine-learning-projects--programs" class="anchor" aria-hidden="true" href="#machine-learning-projects--programs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning Projects &amp;amp; Programs&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Project Name&lt;/th&gt;
&lt;th&gt;Program Name&lt;/th&gt;
&lt;th&gt;Algorithm Name&lt;/th&gt;
&lt;th&gt;Link to Program&lt;/th&gt;
&lt;th&gt;Blog&lt;/th&gt;
&lt;th&gt;YouTube&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Sentiment Analysis&lt;/td&gt;
&lt;td&gt;sentiment.py&lt;/td&gt;
&lt;td&gt;Sentiment Analysis&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/sentiment.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/sentiment-analysis-e2e4442bac13" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/1VHhDSOwJPw" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Simple Linear Regression Ex&lt;/td&gt;
&lt;td&gt;LinearRegression.py&lt;/td&gt;
&lt;td&gt;Linear Regression&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/LinearRegression.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/a-simple-machine-learning-python-program-bf5d156d2cda" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/z7jEJY8FbA8" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Car Classification&lt;/td&gt;
&lt;td&gt;decisionTree.py&lt;/td&gt;
&lt;td&gt;Decision Tree&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/DecisionTree/decisionTree.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/car-classification-89ad60204acf" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/U-Jm8ugN0Ps" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Golf Predictions&lt;/td&gt;
&lt;td&gt;Golf_Predictions.ipynb&lt;/td&gt;
&lt;td&gt;Decision Tree&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Golf_Predictions.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/python-decision-tree-classifier-example-d73bc3aeca6" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/bT-43kgYI3o" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Predict Boston House Price&lt;/td&gt;
&lt;td&gt;Predict_Boston_Housing_Price.ipynb&lt;/td&gt;
&lt;td&gt;Linear Regression&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Predict_Boston_Housing_Price.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/predict-boston-house-prices-using-python-linear-regression-90469e0a341" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/gOXoFDrseis" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Predict Stock Price&lt;/td&gt;
&lt;td&gt;stock.ipynb&lt;/td&gt;
&lt;td&gt;Linear Regression &amp;amp; SVR&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/stock.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/predict-stock-prices-using-python-machine-learning-53aa024da20a" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/EYnC4ACIt2g" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Classify Iris Species&lt;/td&gt;
&lt;td&gt;Logistic_Regression.ipynb&lt;/td&gt;
&lt;td&gt;Logistic Regression&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Logistic_Regression.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/python-logistic-regression-program-5e1b32f964db" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/ACdBKML9l4s" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Predict Median House Price&lt;/td&gt;
&lt;td&gt;Neural_Networks.ipynb&lt;/td&gt;
&lt;td&gt;Deep Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Neural_Networks/Neural_Networks.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/predict-house-median-prices-5f1a768dd256?postPublishedType=repub" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/vSzou5zRwNQ" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Classify Handwritten Digits&lt;/td&gt;
&lt;td&gt;MNIST_ANN.ipynb&lt;/td&gt;
&lt;td&gt;Artificial Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/MNIST_ANN.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/classify-hand-written-digits-5fdbe5d99ee7" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/kOFUQB7u5Ck" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cluster NBA Basketball Players&lt;/td&gt;
&lt;td&gt;Basketball_Data_Exploration.ipynb&lt;/td&gt;
&lt;td&gt;KMeans&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/NBA_Basketball_Exploration/Basketball_Data_Exploration.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/nba-data-analysis-exploration-9293f311e0e8" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/2Pmf6Kqak3w" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Predict FB Stock Price&lt;/td&gt;
&lt;td&gt;SVM.ipynb&lt;/td&gt;
&lt;td&gt;Support Vector Regression (SVR)&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/SVM_Stock/SVM.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/facebook-stock-prediction-bcfc676bc611" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/tMPfZV_ipOg" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Breast Cancer Detection&lt;/td&gt;
&lt;td&gt;Breast_Cancer_Detection.ipynb&lt;/td&gt;
&lt;td&gt;Random Forest Classifier &amp;amp; Gaussian Naive Bayes &amp;amp; Logistic Regression &amp;amp; Decision Tree Classifier &amp;amp; SVC&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/breast_cancer_detection/Breast_Cancer_Detection.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/breast-cancer-detection-using-machine-learning-38820fe98982" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/NSSOyhJBmWY" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Face Detection&lt;/td&gt;
&lt;td&gt;face_detection.py&lt;/td&gt;
&lt;td&gt;Open CV &amp;amp; Adaboost&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/face_detection/face_detection.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/face-detection-using-python-open-cv-d51e27266f7f" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/6klXqQMctPk" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Image Classification&lt;/td&gt;
&lt;td&gt;cnn.ipynb&lt;/td&gt;
&lt;td&gt;CNN&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Classify_Images/cnn.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/classify-images-using-convolutional-neural-networks-python-a89cecc8c679" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/mB7fdy67eFw" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Classify Handwritten Digits CNN&lt;/td&gt;
&lt;td&gt;mnist_cnn.ipynb&lt;/td&gt;
&lt;td&gt;Convolutional Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/mnist_cnn.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/classify-hand-written-digits-using-python-and-convolutional-neural-networks-26ccfc06b95c" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/V4dd2Bt9OHY" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spam Detection&lt;/td&gt;
&lt;td&gt;Email_Spam_Detection.ipynb&lt;/td&gt;
&lt;td&gt;Naive Bayes&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Email_Spam_Detection/Email_Spam_Detection.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/email-spam-detection-using-python-machine-learning-abe38c889855" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/cNLPt02RwF0" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pima-Indians Diabetes&lt;/td&gt;
&lt;td&gt;Diabetes.ipynb&lt;/td&gt;
&lt;td&gt;Artificial Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Diabetes/Diabetes.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/build-your-own-artificial-neural-network-using-python-f37d16be06bf" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=S2sZNlr-4_4&amp;amp;list=PLBhJnyA0V0uIP6tScPs01FW5WtSpJdmcv&amp;amp;index=28&amp;amp;t=0s" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Movie Recommendation Engine&lt;/td&gt;
&lt;td&gt;Movie_Recommendation.ipynb&lt;/td&gt;
&lt;td&gt;Cosine Similarity&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Movie_Recommender/Movie_Recommendation.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/build-a-movie-recommendation-engine-using-python-scikit-learn-machine-learning-e68ba297e163" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/umSM8rFtVMs" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Article Text To Speech&lt;/td&gt;
&lt;td&gt;Article_Text_To_Speech.py&lt;/td&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Article_Text_To_Speech.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/build-a-text-to-speech-program-using-python-b70de7105383" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/uPSIUjo_Fhw" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AI Smart Dr.Chat Bot&lt;/td&gt;
&lt;td&gt;smartbot.py&lt;/td&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/smartbot.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/build-your-own-ai-chat-bot-using-python-machine-learning-682ddd8acc29" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/QpMsT0WuIuI" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Neural Network Stock Prediction&lt;/td&gt;
&lt;td&gt;lstm2.py&lt;/td&gt;
&lt;td&gt;LSTM&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/LSTM_Stock/lstm2.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/stock-price-prediction-using-python-machine-learning-e82a039ac2bb" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/QIUxPv5PJOY" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-interesting-python-programs" class="anchor" aria-hidden="true" href="#interesting-python-programs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interesting Python Programs&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Project Name&lt;/th&gt;
&lt;th&gt;Program Name&lt;/th&gt;
&lt;th&gt;Link to Program&lt;/th&gt;
&lt;th&gt;Blog&lt;/th&gt;
&lt;th&gt;YouTube&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Python For Finance Simple Returns&lt;/td&gt;
&lt;td&gt;simple_returns.py&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/simple_returns.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/python-for-finance-25d2ed1ed35d" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/O-O1WclwXck" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>randerson112358</author><guid isPermaLink="false">https://github.com/randerson112358/Python</guid><pubDate>Tue, 04 Feb 2020 00:13:00 GMT</pubDate></item><item><title>jantic/DeOldify #14 in Jupyter Notebook, This month</title><link>https://github.com/jantic/DeOldify</link><description>&lt;p&gt;&lt;i&gt;A Deep Learning based project for colorizing and restoring old images (and video!)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deoldify" class="anchor" aria-hidden="true" href="#deoldify"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DeOldify&lt;/h1&gt;
&lt;p&gt;Image &lt;a href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColab.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" align="center" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt; |
Video &lt;a href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/VideoColorizerColab.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" align="center" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEW&lt;/strong&gt; For those of you who are looking for a quick and easy way to run the open source version of DeOldify, for free, try this!  I love this implementation: &lt;a href="https://deepai.org/machine-learning-model/colorizer" rel="nofollow"&gt;DeOldify Image Colorization on DeepAI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Instructions on how to use the Colabs above have been kindly provided in video tutorial form by Old Ireland in Colour's John Breslin.  It's great! Click video image below to watch.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=VaEl0faDw38" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9d812131195cc524d5fe03696fdc284208bedbde/687474703a2f2f696d672e796f75747562652e636f6d2f76692f5661456c306661447733382f302e6a7067" alt="" data-canonical-src="http://img.youtube.com/vi/VaEl0faDw38/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Get more updates on &lt;a href="https://twitter.com/citnaj" rel="nofollow"&gt;Twitter &lt;img src="resource_images/Twitter_Social_Icon_Rounded_Square_Color.svg" width="16" style="max-width:100%;"&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#about-deoldify"&gt;About DeOldify&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#example-videos"&gt;Example Videos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#example-images"&gt;Example Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#stuff-that-should-probably-be-in-a-paper"&gt;Stuff That Should Probably Be In A Paper&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#how-to-achieve-stable-video"&gt;How to Achieve Stable Video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-is-nogan"&gt;What is NoGAN?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#why-three-models"&gt;Why Three Models?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-technical-details"&gt;Technical Details&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#this-project-going-forward"&gt;Going Forward&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#getting-started-yourself"&gt;Getting Started Yourself&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#easiest-approach"&gt;Easiest Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#your-own-machine-not-as-easy"&gt;Your Own Machine&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pretrained-weights"&gt;Pretrained Weights&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-about-deoldify" class="anchor" aria-hidden="true" href="#about-deoldify"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About DeOldify&lt;/h2&gt;
&lt;p&gt;Simply put, the mission of this project is to colorize and restore old images and film footage.
We'll get into the details in a bit, but first let's see some pretty pictures and videos!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-new-and-exciting-stuff-in-deoldify" class="anchor" aria-hidden="true" href="#new-and-exciting-stuff-in-deoldify"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;New and Exciting Stuff in DeOldify&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Glitches and artifacts are almost entirely eliminated&lt;/li&gt;
&lt;li&gt;Better skin (less zombies)&lt;/li&gt;
&lt;li&gt;More highly detailed and photorealistic renders&lt;/li&gt;
&lt;li&gt;Much less "blue bias"&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Video&lt;/strong&gt; - it actually looks good!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NoGAN&lt;/strong&gt; - a new and weird but highly effective way to do GAN training for image to image.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-example-videos" class="anchor" aria-hidden="true" href="#example-videos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Videos&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;  Click images to watch&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-facebook-f8-demo" class="anchor" aria-hidden="true" href="#facebook-f8-demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Facebook F8 Demo&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=l3UXXid04Ys" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/95e149f839667ddcd87e0a1970e3870f6a61c24a/687474703a2f2f696d672e796f75747562652e636f6d2f76692f6c335558586964303459732f302e6a7067" alt="" data-canonical-src="http://img.youtube.com/vi/l3UXXid04Ys/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-silent-movie-examples" class="anchor" aria-hidden="true" href="#silent-movie-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Silent Movie Examples&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=EXn-n2iqEjI" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24d210457f7e8b57ef701788f013f2f72d2eda1c/687474703a2f2f696d672e796f75747562652e636f6d2f76692f45586e2d6e326971456a492f302e6a7067" alt="" data-canonical-src="http://img.youtube.com/vi/EXn-n2iqEjI/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-example-images" class="anchor" aria-hidden="true" href="#example-images"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Images&lt;/h2&gt;
&lt;p&gt;"Migrant Mother" by Dorothea Lange (1936)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/cf0b5cd16cd934cba884172370a78b40b28db00a/68747470733a2f2f692e696d6775722e636f6d2f427430766e6b652e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/cf0b5cd16cd934cba884172370a78b40b28db00a/68747470733a2f2f692e696d6775722e636f6d2f427430766e6b652e6a7067" alt="Migrant Mother" data-canonical-src="https://i.imgur.com/Bt0vnke.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Woman relaxing in her livingroom in Sweden (1920)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/8ae04c8fc773e163705fd8ec24d3a9271806980c/68747470733a2f2f692e696d6775722e636f6d2f31353864306f552e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/8ae04c8fc773e163705fd8ec24d3a9271806980c/68747470733a2f2f692e696d6775722e636f6d2f31353864306f552e6a7067" alt="Sweden Living Room" data-canonical-src="https://i.imgur.com/158d0oU.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"Toffs and Toughs" by Jimmy Sime (1937)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0e3d002bbc787b75359789f8ade0c43b637cded3/68747470733a2f2f692e696d6775722e636f6d2f565975617634492e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/0e3d002bbc787b75359789f8ade0c43b637cded3/68747470733a2f2f692e696d6775722e636f6d2f565975617634492e6a7067" alt="Class Divide" data-canonical-src="https://i.imgur.com/VYuav4I.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanksgiving Maskers (1911)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ba7b6ae2cc2e908346ba56f06ea54061b9b1ee6e/68747470733a2f2f692e696d6775722e636f6d2f6e3871564a35632e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/ba7b6ae2cc2e908346ba56f06ea54061b9b1ee6e/68747470733a2f2f692e696d6775722e636f6d2f6e3871564a35632e6a7067" alt="Thanksgiving Maskers" data-canonical-src="https://i.imgur.com/n8qVJ5c.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Glen Echo Madame Careta Gypsy Camp in Maryland (1925)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/83d69aafb3b306643f99566d08d805099c741e98/68747470733a2f2f692e696d6775722e636f6d2f316f59724a52492e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/83d69aafb3b306643f99566d08d805099c741e98/68747470733a2f2f692e696d6775722e636f6d2f316f59724a52492e6a7067" alt="Gypsy Camp" data-canonical-src="https://i.imgur.com/1oYrJRI.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"Mr. and Mrs. Lemuel Smith and their younger children in their farm house, Carroll County, Georgia." (1941)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/f016893e9d37cab0175d218547699364d9c30f76/68747470733a2f2f692e696d6775722e636f6d2f49326a38796e6d2e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/f016893e9d37cab0175d218547699364d9c30f76/68747470733a2f2f692e696d6775722e636f6d2f49326a38796e6d2e6a7067" alt="Georgia Farmhouse" data-canonical-src="https://i.imgur.com/I2j8ynm.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"Building the Golden Gate Bridge" (est 1937)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/3b1aca12e6009a5b8a47bcfbbc84cd533b22a1de/68747470733a2f2f692e696d6775722e636f6d2f365362466a66712e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/3b1aca12e6009a5b8a47bcfbbc84cd533b22a1de/68747470733a2f2f692e696d6775722e636f6d2f365362466a66712e6a7067" alt="Golden Gate Bridge" data-canonical-src="https://i.imgur.com/6SbFjfq.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;  What you might be wondering is while this render looks cool, are the colors accurate? The original photo certainly makes it look like the towers of the bridge could be white. We looked into this and it turns out the answer is no - the towers were already covered in red primer by this time. So that's something to keep in mind- historical accuracy remains a huge challenge!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;"Terrasse de cafÃ©, Paris" (1925)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ae76951da1b7106193d81c44d7da2a0b74d60077/68747470733a2f2f692e696d6775722e636f6d2f577072517750352e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/ae76951da1b7106193d81c44d7da2a0b74d60077/68747470733a2f2f692e696d6775722e636f6d2f577072517750352e6a7067" alt="Cafe Paris" data-canonical-src="https://i.imgur.com/WprQwP5.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Norwegian Bride (est late 1890s)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/03ab876e5b758529725e98bceea87f0e610106df/68747470733a2f2f692e696d6775722e636f6d2f4d6d7476725a6d2e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/03ab876e5b758529725e98bceea87f0e610106df/68747470733a2f2f692e696d6775722e636f6d2f4d6d7476725a6d2e6a7067" alt="Norwegian Bride" data-canonical-src="https://i.imgur.com/MmtvrZm.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ZitkÃ¡la-Å Ã¡ (Lakota: Red Bird), also known as Gertrude Simmons Bonnin (1898)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/60080246c37e01c042194b2d87f4360a25637a7b/68747470733a2f2f692e696d6775722e636f6d2f7a49474d3034332e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/60080246c37e01c042194b2d87f4360a25637a7b/68747470733a2f2f692e696d6775722e636f6d2f7a49474d3034332e6a7067" alt="Native Woman" data-canonical-src="https://i.imgur.com/zIGM043.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chinese Opium Smokers (1880)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5a05086ca8215de683081c6fb29998045fee0ddf/68747470733a2f2f692e696d6775722e636f6d2f6c5647713856712e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/5a05086ca8215de683081c6fb29998045fee0ddf/68747470733a2f2f692e696d6775722e636f6d2f6c5647713856712e6a7067" alt="Opium Real" data-canonical-src="https://i.imgur.com/lVGq8Vq.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-stuff-that-should-probably-be-in-a-paper" class="anchor" aria-hidden="true" href="#stuff-that-should-probably-be-in-a-paper"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stuff That Should Probably Be In A Paper&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-how-to-achieve-stable-video" class="anchor" aria-hidden="true" href="#how-to-achieve-stable-video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to Achieve Stable Video&lt;/h3&gt;
&lt;p&gt;NoGAN training is crucial to getting the kind of stable and colorful images seen in this iteration of DeOldify. NoGAN training combines the benefits of GAN training (wonderful colorization) while eliminating the nasty side effects (like flickering objects in video). Believe it or not, video is rendered using isolated image generation without any sort of temporal modeling tacked on. The process performs 30-60 minutes of the GAN portion of "NoGAN" training, using 1% to 3% of imagenet data once.  Then, as with still image colorization, we "DeOldify" individual frames before rebuilding the video.&lt;/p&gt;
&lt;p&gt;In addition to improved video stability, there is an interesting thing going on here worth mentioning. It turns out the models I run, even different ones and with different training structures, keep arriving at more or less the same solution.  That's even the case for the colorization of things you may think would be arbitrary and unknowable, like the color of clothing, cars, and even special effects (as seen in "Metropolis").&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ea1738479cfd9811faa49b7dc78bb59606e74cfb/68747470733a2f2f7468756d62732e6766796361742e636f6d2f48656176794c6f6e65426c6f77666973682d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/ea1738479cfd9811faa49b7dc78bb59606e74cfb/68747470733a2f2f7468756d62732e6766796361742e636f6d2f48656176794c6f6e65426c6f77666973682d73697a655f726573747269637465642e676966" alt="Metropolis Special FX" data-canonical-src="https://thumbs.gfycat.com/HeavyLoneBlowfish-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My best guess is that the models are learning some interesting rules about how to colorize based on subtle cues present in the black and white images that I certainly wouldn't expect to exist.  This result leads to nicely deterministic and consistent results, and that means you don't have track model colorization decisions because they're not arbitrary.  Additionally, they seem remarkably robust so that even in moving scenes the renders are very consistent.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/007128e9e871429b96bca83aae7f2dfa9f3d9ecc/68747470733a2f2f7468756d62732e6766796361742e636f6d2f46616d696c6961724a7562696c616e744173702d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/007128e9e871429b96bca83aae7f2dfa9f3d9ecc/68747470733a2f2f7468756d62732e6766796361742e636f6d2f46616d696c6961724a7562696c616e744173702d73697a655f726573747269637465642e676966" alt="Moving Scene Example" data-canonical-src="https://thumbs.gfycat.com/FamiliarJubilantAsp-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Other ways to stabilize video add up as well. First, generally speaking rendering at a higher resolution (higher render_factor) will increase stability of colorization decisions.  This stands to reason because the model has higher fidelity image information to work with and will have a greater chance of making the "right" decision consistently.  Closely related to this is the use of resnet101 instead of resnet34 as the backbone of the generator- objects are detected more consistently and correctly with this. This is especially important for getting good, consistent skin rendering.  It can be particularly visually jarring if you wind up with "zombie hands", for example.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2b18ba56365c70078a0672e7aaa2b402e2a25eea/68747470733a2f2f7468756d62732e6766796361742e636f6d2f54687269667479496e666572696f7249736162656c6c696e6577686561746561722d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/2b18ba56365c70078a0672e7aaa2b402e2a25eea/68747470733a2f2f7468756d62732e6766796361742e636f6d2f54687269667479496e666572696f7249736162656c6c696e6577686561746561722d73697a655f726573747269637465642e676966" alt="Zombie Hand Example" data-canonical-src="https://thumbs.gfycat.com/ThriftyInferiorIsabellinewheatear-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Additionally, gaussian noise augmentation during training appears to help but at this point the conclusions as to just how much are bit more tenuous (I just haven't formally measured this yet).  This is loosely based on work done in style transfer video, described here:  &lt;a href="https://medium.com/element-ai-research-lab/stabilizing-neural-style-transfer-for-video-62675e203e42" rel="nofollow"&gt;https://medium.com/element-ai-research-lab/stabilizing-neural-style-transfer-for-video-62675e203e42&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Special thanks go to Rani Horev for his contributions in implementing this noise augmentation.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-what-is-nogan" class="anchor" aria-hidden="true" href="#what-is-nogan"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is NoGAN?&lt;/h3&gt;
&lt;p&gt;This is a new type of GAN training that I've developed to solve some key problems in the previous DeOldify model. It provides the benefits of GAN training while spending minimal time doing direct GAN training.  Instead, most of the training time is spent pretraining the generator and critic separately with more straight-forward, fast and reliable conventional methods.  A key insight here is that those more "conventional" methods generally get you most of the results you need, and that GANs can be used to close the gap on realism. During the very short amount of actual GAN training the generator not only gets the full realistic colorization capabilities that used to take days of progressively resized GAN training, but it also doesn't accrue nearly as much of the artifacts and other ugly baggage of GANs. In fact, you can pretty much eliminate glitches and artifacts almost entirely depending on your approach. As far as I know this is a new technique. And it's incredibly effective.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Original DeOldify Model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5f92319233179b2f204b8739173abf98a69ef39a/68747470733a2f2f7468756d62732e6766796361742e636f6d2f436f6f7264696e6174656456656e657261746564486f676765742d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/5f92319233179b2f204b8739173abf98a69ef39a/68747470733a2f2f7468756d62732e6766796361742e636f6d2f436f6f7264696e6174656456656e657261746564486f676765742d73697a655f726573747269637465642e676966" alt="Before Flicker" data-canonical-src="https://thumbs.gfycat.com/CoordinatedVeneratedHogget-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NoGAN-Based DeOldify Model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/410aabdcd548bde894635617caf09eaa678a7e80/68747470733a2f2f7468756d62732e6766796361742e636f6d2f4f696c79426c61636b417263746963686172652d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/410aabdcd548bde894635617caf09eaa678a7e80/68747470733a2f2f7468756d62732e6766796361742e636f6d2f4f696c79426c61636b417263746963686172652d73697a655f726573747269637465642e676966" alt="After Flicker" data-canonical-src="https://thumbs.gfycat.com/OilyBlackArctichare-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The steps are as follows: First train the generator in a conventional way by itself with just the feature loss. Next, generate images from that, and train the critic on distinguishing between those outputs and real images as a basic binary classifier. Finally, train the generator and critic together in a GAN setting (starting right at the target size of 192px in this case).  Now for the weird part:  All the useful GAN training here only takes place within a very small window of time.  There's an inflection point where it appears the critic has transferred everything it can that is useful to the generator. Past this point, image quality oscillates between the best that you can get at the inflection point, or bad in a predictable way (orangish skin, overly red lips, etc).  There appears to be no productive training after the inflection point.  And this point lies within training on just 1% to 3% of the Imagenet Data!  That amounts to about 30-60 minutes of training at 192px.&lt;/p&gt;
&lt;p&gt;The hard part is finding this inflection point.  So far, I've accomplished this by making a whole bunch of model save checkpoints (every 0.1% of data iterated on) and then just looking for the point where images look great before they go totally bonkers with orange skin (always the first thing to go). Additionally, generator rendering starts immediately getting glitchy and inconsistent at this point, which is no good particularly for video. What I'd really like to figure out is what the tell-tale sign of the inflection point is that can be easily automated as an early stopping point.  Unfortunately, nothing definitive is jumping out at me yet.  For one, it's happening in the middle of training loss decreasing- not when it flattens out, which would seem more reasonable on the surface.&lt;/p&gt;
&lt;p&gt;Another key thing about NoGAN training is you can repeat pretraining the critic on generated images after the initial GAN training, then repeat the GAN training itself in the same fashion.  This is how I was able to get extra colorful results with the "artistic" model.  But this does come at a cost currently- the output of the generator becomes increasingly inconsistent and you have to experiment with render resolution (render_factor) to get the best result.  But the renders are still glitch free and way more consistent than I was ever able to achieve with the original DeOldify model. You can do about five of these repeat cycles, give or take, before you get diminishing returns, as far as I can tell.&lt;/p&gt;
&lt;p&gt;Keep in mind- I haven't been entirely rigorous in figuring out what all is going on in NoGAN- I'll save that for a paper. That means there's a good chance I'm wrong about something.  But I think it's definitely worth putting out there now because I'm finding it very useful- it's solving basically much of my remaining problems I had in DeOldify.&lt;/p&gt;
&lt;p&gt;This builds upon a technique developed in collaboration with Jeremy Howard and Sylvain Gugger for Fast.AI's Lesson 7 in version 3 of Practical Deep Learning for Coders Part I. The particular lesson notebook can be found here: &lt;a href="https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres-gan.ipynb"&gt;https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres-gan.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-why-three-models" class="anchor" aria-hidden="true" href="#why-three-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why Three Models?&lt;/h2&gt;
&lt;p&gt;There are now three models to choose from in DeOldify. Each of these has key strengths and weaknesses, and so have different use cases.  Video is for video of course.  But stable and artistic are both for images, and sometimes one will do images better than the other.&lt;/p&gt;
&lt;p&gt;More details:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Artistic&lt;/strong&gt; - This model achieves the highest quality results in image coloration, in terms of interesting details and vibrance. The most notable drawback however is that it's a bit of a pain to fiddle around with to get the best results (you have to adjust the rendering resolution or render_factor to achieve this).  Additionally, the model does not do as well as stable in a few key common scenarios- nature scenes and portraits.  The model uses a resnet34 backbone on a UNet with an emphasis on depth of layers on the decoder side.  This model was trained with 5 critic pretrain/GAN cycle repeats via NoGAN, in addition to the initial generator/critic pretrain/GAN NoGAN training, at 192px.  This adds up to a total of 32% of Imagenet data trained once (12.5 hours of direct GAN training).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stable&lt;/strong&gt; - This model achieves the best results with landscapes and portraits. Notably, it produces less "zombies"- where faces or limbs stay gray rather than being colored in properly.  It generally has less weird miscolorations than artistic, but it's also less colorful in general.  This model uses a resnet101 backbone on a UNet with an emphasis on width of layers on the decoder side.  This model was trained with 3 critic pretrain/GAN cycle repeats via NoGAN, in addition to the initial generator/critic pretrain/GAN NoGAN training, at 192px.  This adds up to a total of 7% of Imagenet data trained once (3 hours of direct GAN training).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Video&lt;/strong&gt; - This model is optimized for smooth, consistent and flicker-free video.  This would definitely be the least colorful of the three models, but it's honestly not too far off from "stable". The model is the same as "stable" in terms of architecture, but differs in training.  It's trained for a mere 2.2% of Imagenet data once at 192px, using only the initial generator/critic pretrain/GAN NoGAN training (1 hour of direct GAN training).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because the training of the artistic and stable models was done before the "inflection point" of NoGAN training described in "What is NoGAN???" was discovered,  I believe this amount of training on them can be knocked down considerably. As far as I can tell, the models were stopped at "good points" that were well beyond where productive training was taking place.  I'll be looking into this in the future.&lt;/p&gt;
&lt;p&gt;Ideally, eventually these three models will be consolidated into one that has all these good desirable unified.  I think there's a path there, but it's going to require more work!  So for now, the most practical solution appears to be to maintain multiple models.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-the-technical-details" class="anchor" aria-hidden="true" href="#the-technical-details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Technical Details&lt;/h2&gt;
&lt;p&gt;This is a deep learning based model.  More specifically, what I've done is combined the following approaches:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-self-attention-generative-adversarial-network" class="anchor" aria-hidden="true" href="#self-attention-generative-adversarial-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://arxiv.org/abs/1805.08318" rel="nofollow"&gt;Self-Attention Generative Adversarial Network&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Except the generator is a &lt;strong&gt;pretrained U-Net&lt;/strong&gt;, and I've just modified it to have the spectral normalization and self-attention.  It's a pretty straightforward translation.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-two-time-scale-update-rule" class="anchor" aria-hidden="true" href="#two-time-scale-update-rule"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://arxiv.org/abs/1706.08500" rel="nofollow"&gt;Two Time-Scale Update Rule&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This is also very straightforward â€“ it's just one to one generator/critic iterations and higher critic learning rate.
This is modified to incorporate a "threshold" critic loss that makes sure that the critic is "caught up" before moving on to generator training.
This is particularly useful for the "NoGAN" method described below.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-nogan" class="anchor" aria-hidden="true" href="#nogan"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NoGAN&lt;/h3&gt;
&lt;p&gt;There's no paper here! This is a new type of GAN training that I've developed to solve some key problems in the previous DeOldify model.
The gist is that you get the benefits of GAN training while spending minimal time doing direct GAN training.
More details are in the &lt;a href="#what-is-nogan"&gt;What is NoGAN?&lt;/a&gt; section (it's a doozy).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-generator-loss" class="anchor" aria-hidden="true" href="#generator-loss"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generator Loss&lt;/h3&gt;
&lt;p&gt;Loss during NoGAN learning is two parts:  One is a basic Perceptual Loss (or Feature Loss) based on VGG16 â€“ this just biases the generator model to replicate the input image.
The second is the loss score from the critic.  For the curious â€“ Perceptual Loss isn't sufficient by itself to produce good results.
It tends to just encourage a bunch of brown/green/blue â€“ you know, cheating to the test, basically, which neural networks are really good at doing!
Key thing to realize here is that GANs essentially are learning the loss function for you â€“ which is really one big step closer to toward the ideal that we're shooting for in machine learning.
And of course you generally get much better results when you get the machine to learn something you were previously hand coding.
That's certainly the case here.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Of note:&lt;/strong&gt;  There's no longer any "Progressive Growing of GANs" type training going on here.  It's just not needed in lieu of the superior results obtained by the "NoGAN" technique described above.&lt;/p&gt;
&lt;p&gt;The beauty of this model is that it should be generally useful for all sorts of image modification, and it should do it quite well.
What you're seeing above are the results of the colorization model, but that's just one component in a pipeline that I'm developing with the exact same approach.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-this-project-going-forward" class="anchor" aria-hidden="true" href="#this-project-going-forward"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;This Project, Going Forward&lt;/h2&gt;
&lt;p&gt;So that's the gist of this project â€“ I'm looking to make old photos and film look reeeeaaally good with GANs, and more importantly, make the project &lt;em&gt;useful&lt;/em&gt;.
In the meantime though this is going to be my baby and I'll be actively updating and improving the code over the foreseeable future.
I'll try to make this as user-friendly as possible, but I'm sure there's going to be hiccups along the way.&lt;/p&gt;
&lt;p&gt;Oh and I swear I'll document the code properly...eventually.  Admittedly I'm &lt;em&gt;one of those&lt;/em&gt; people who believes in "self documenting code" (LOL).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started-yourself" class="anchor" aria-hidden="true" href="#getting-started-yourself"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started Yourself&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-easiest-approach" class="anchor" aria-hidden="true" href="#easiest-approach"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Easiest Approach&lt;/h3&gt;
&lt;p&gt;The easiest way to get started is to go straight to the Colab notebooks:&lt;/p&gt;
&lt;p&gt;Image &lt;a href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColab.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" align="center" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
| Video &lt;a href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/VideoColorizerColab.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" align="center" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Special thanks to Matt Robinson and MarÃ­a Benavente for their image Colab notebook contributions, and Robert Bell for the video Colab notebook work!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-your-own-machine-not-as-easy" class="anchor" aria-hidden="true" href="#your-own-machine-not-as-easy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Your Own Machine (not as easy)&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-hardware-and-operating-system-requirements" class="anchor" aria-hidden="true" href="#hardware-and-operating-system-requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hardware and Operating System Requirements&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;(Training Only) BEEFY Graphics card&lt;/strong&gt;.  I'd really like to have more memory than the 11 GB in my GeForce 1080TI (11GB).  You'll have a tough time with less.  The Generators and Critic are ridiculously large.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(Colorization Alone) A decent graphics card&lt;/strong&gt;. Approximately 4GB+ memory video cards should be sufficient.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linux (or maybe Windows 10)&lt;/strong&gt;  I'm using Ubuntu 16.04, but nothing about this precludes Windows 10 support as far as I know.  I just haven't tested it and am not going to make it a priority for now.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-easy-install" class="anchor" aria-hidden="true" href="#easy-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Easy Install&lt;/h4&gt;
&lt;p&gt;You should now be able to do a simple install with Anaconda. Here are the steps:&lt;/p&gt;
&lt;p&gt;Open the command line and navigate to the root folder you wish to install.  Then type the following commands&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;git clone https://github.com/jantic/DeOldify.git DeOldify&lt;/span&gt;
&lt;span class="pl-c1"&gt;cd DeOldify&lt;/span&gt;
&lt;span class="pl-c1"&gt;conda env create -f environment.yml&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then start running with these commands:&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;source activate deoldify&lt;/span&gt;
&lt;span class="pl-c1"&gt;jupyter lab&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From there you can start running the notebooks in Jupyter Lab, via the url they provide you in the console.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can also now do "conda activate deoldify" if you have the latest version of conda and in fact that's now recommended. But a lot of people don't have that yet so I'm not going to make it the default instruction here yet.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-note-on-test_images-folder" class="anchor" aria-hidden="true" href="#note-on-test_images-folder"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Note on test_images Folder&lt;/h4&gt;
&lt;p&gt;The images in the &lt;code&gt;test_images&lt;/code&gt; folder have been removed because they were using Git LFS and that costs a lot of money when GitHub actually charges for bandwidth on a popular open source project (they had a billing bug for while that was recently fixed).  The notebooks that use them (the image test ones) still point to images in that directory that I (Jason) have personally and I'd like to keep it that way because, after all, I'm by far the primary and most active developer.  But they won't work for you.  Still, those notebooks are a convenient template for making your own tests if you're so inclined.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-typical-training" class="anchor" aria-hidden="true" href="#typical-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Typical training&lt;/h4&gt;
&lt;p&gt;The notebook &lt;code&gt;ColorizeTrainingWandb&lt;/code&gt; has been created to log and monitor results through &lt;a href="https://www.wandb.com/" rel="nofollow"&gt;Weights &amp;amp; Biases&lt;/a&gt;. You can find a description of typical training by consulting &lt;a href="https://app.wandb.ai/borisd13/DeOldify/reports?view=borisd13%2FDeOldify" rel="nofollow"&gt;W&amp;amp;B Report&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-docker-for-jupyter" class="anchor" aria-hidden="true" href="#docker-for-jupyter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker for Jupyter&lt;/h3&gt;
&lt;p&gt;You can build and run the docker using the following process:&lt;/p&gt;
&lt;p&gt;Cloning&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;git clone https://github.com/jantic/DeOldify.git DeOldify&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Building Docker&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;cd DeOldify &amp;amp;&amp;amp; docker build -t deoldify_jupyter -f Dockerfile .&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running Docker&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;echo "http://$(curl ifconfig.io):8888" &amp;amp;&amp;amp; nvidia-docker run --ipc=host --env NOTEBOOK_PASSWORD="pass123" -p 8888:8888 -it deoldify_jupyter&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-docker-for-api" class="anchor" aria-hidden="true" href="#docker-for-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker for API&lt;/h3&gt;
&lt;p&gt;You can build and run the docker using the following process:&lt;/p&gt;
&lt;p&gt;Cloning&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;git clone https://github.com/jantic/DeOldify.git DeOldify&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Building Docker&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;cd DeOldify &amp;amp;&amp;amp; docker build -t deoldify_api -f Dockerfile-api .&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running Docker&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;echo "http://$(curl ifconfig.io):5000" &amp;amp;&amp;amp; nvidia-docker run --ipc=host -p 5000:5000 -d deoldify_api&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Calling the API for image processing&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;curl -X POST "http://MY_SUPER_API_IP:5000/process" -H "accept: image/png" -H "Content-Type: application/json" -d "{\"source_url\":\"http://www.afrikanheritage.com/wp-content/uploads/2015/08/slave-family-P.jpeg\", \"render_factor\":35}" --output colorized_image.png&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Calling the API for video processing&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;curl -X POST "http://MY_SUPER_API_IP:5000/process" -H "accept: application/octet-stream" -H "Content-Type: application/json" -d "{\"source_url\":\"https://v.redd.it/d1ku57kvuf421/HLSPlaylist.m3u8\", \"render_factor\":35}" --output colorized_video.mp4&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you don't have Nvidia Docker, &lt;a href="https://github.com/nvidia/nvidia-docker/wiki/Installation-(version-2.0)#installing-version-20"&gt;here&lt;/a&gt; is the installation guide.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-installation-details" class="anchor" aria-hidden="true" href="#installation-details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation Details&lt;/h3&gt;
&lt;p&gt;This project is built around the wonderful Fast.AI library.  Prereqs, in summary:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Fast.AI 1.0.51&lt;/strong&gt; (and its dependencies).  If you use any higher version you'll see grid artifacts in rendering and tensorboard will malfunction. So yeah...don't do that.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyTorch 1.0.1&lt;/strong&gt; Not the latest version of PyTorch- that will not play nicely with the version of FastAI above.  Note however that the conda install of FastAI 1.0.51 grabs the latest PyTorch, which doesn't work.  This is patched over by our own conda install but fyi.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jupyter Lab&lt;/strong&gt; &lt;code&gt;conda install -c conda-forge jupyterlab&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tensorboard&lt;/strong&gt; (i.e. install Tensorflow) and &lt;strong&gt;TensorboardX&lt;/strong&gt; (&lt;a href="https://github.com/lanpa/tensorboardX"&gt;https://github.com/lanpa/tensorboardX&lt;/a&gt;).  I guess you don't &lt;em&gt;have&lt;/em&gt; to but man, life is so much better with it.  FastAI now comes with built in support for this- you just  need to install the prereqs: &lt;code&gt;conda install -c anaconda tensorflow-gpu&lt;/code&gt; and &lt;code&gt;pip install tensorboardX&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ImageNet&lt;/strong&gt; â€“ Only if you're training, of course. It has proven to be a great dataset for my purposes.  &lt;a href="http://www.image-net.org/download-images" rel="nofollow"&gt;http://www.image-net.org/download-images&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-pretrained-weights" class="anchor" aria-hidden="true" href="#pretrained-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pretrained Weights&lt;/h2&gt;
&lt;p&gt;To start right away on your own machine with your own images or videos without training the models yourself, you'll need to download the "Completed Generator Weights" listed below and drop them in the /models/ folder.&lt;/p&gt;
&lt;p&gt;The colorization inference notebooks should be able to guide you from here. The notebooks to use are named ImageColorizerArtistic.ipynb, ImageColorizerStable.ipynb, and VideoColorizer.ipynb.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-completed-generator-weights" class="anchor" aria-hidden="true" href="#completed-generator-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Completed Generator Weights&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/zkehq1uwahhbc2o/ColorizeArtistic_gen.pth?dl=0" rel="nofollow"&gt;Artistic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/mwjep3vyqk5mkjc/ColorizeStable_gen.pth?dl=0" rel="nofollow"&gt;Stable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/336vn9y4qwyg9yz/ColorizeVideo_gen.pth?dl=0" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-completed-critic-weights" class="anchor" aria-hidden="true" href="#completed-critic-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Completed Critic Weights&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/8g5txfzt2fw8mf5/ColorizeArtistic_crit.pth?dl=0" rel="nofollow"&gt;Artistic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/7a8u20e7xdu1dtd/ColorizeStable_crit.pth?dl=0" rel="nofollow"&gt;Stable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/0401djgo1dfxdzt/ColorizeVideo_crit.pth?dl=0" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pretrain-only-generator-weights" class="anchor" aria-hidden="true" href="#pretrain-only-generator-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pretrain Only Generator Weights&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/9zexurvrve141n9/ColorizeArtistic_PretrainOnly_gen.pth?dl=0" rel="nofollow"&gt;Artistic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/mdnuo1563bb8nh4/ColorizeStable_PretrainOnly_gen.pth?dl=0" rel="nofollow"&gt;Stable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/avzixh1ujf86e8x/ColorizeVideo_PretrainOnly_gen.pth?dl=0" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pretrain-only-critic-weights" class="anchor" aria-hidden="true" href="#pretrain-only-critic-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pretrain Only Critic Weights&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/lakxe8akzjgjnmh/ColorizeArtistic_PretrainOnly_crit.pth?dl=0" rel="nofollow"&gt;Artistic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/b3wka56iyv1fvdc/ColorizeStable_PretrainOnly_crit.pth?dl=0" rel="nofollow"&gt;Stable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/j7og84cbhpa94gs/ColorizeVideo_PretrainOnly_crit.pth?dl=0" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-want-the-old-deoldify" class="anchor" aria-hidden="true" href="#want-the-old-deoldify"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Want the Old DeOldify?&lt;/h2&gt;
&lt;p&gt;We suspect some of you are going to want access to the original DeOldify model for various reasons.  We have that archived here:  &lt;a href="https://github.com/dana-kelley/DeOldify"&gt;https://github.com/dana-kelley/DeOldify&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-want-more" class="anchor" aria-hidden="true" href="#want-more"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Want More?&lt;/h2&gt;
&lt;p&gt;Follow &lt;a href="https://twitter.com/search?q=%23Deoldify" rel="nofollow"&gt;#DeOldify&lt;/a&gt; or &lt;a href="https://twitter.com/citnaj" rel="nofollow"&gt;Jason Antic&lt;/a&gt; on Twitter.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;All code in this repository is under the MIT license as specified by the LICENSE file.&lt;/p&gt;
&lt;p&gt;The model weights listed in this readme under the "Pretrained Weights" section are trained by ourselves and are released under the MIT license.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jantic</author><guid isPermaLink="false">https://github.com/jantic/DeOldify</guid><pubDate>Tue, 04 Feb 2020 00:14:00 GMT</pubDate></item><item><title>dataquestio/solutions #15 in Jupyter Notebook, This month</title><link>https://github.com/dataquestio/solutions</link><description>&lt;p&gt;&lt;i&gt;Solutions for projects.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-dataquest-project-solutions" class="anchor" aria-hidden="true" href="#dataquest-project-solutions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dataquest Project Solutions&lt;/h1&gt;
&lt;p&gt;This repository is a series of notebooks that show solutions for the &lt;a href="https://www.dataquest.io/apply" rel="nofollow"&gt;projects&lt;/a&gt; at &lt;a href="https://www.dataquest.io/" rel="nofollow"&gt;Dataquest.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Of course, there are always going to be multiple ways to solve any one problem, so these notebooks just show one possible solution.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission9Solutions.ipynb"&gt;Guided Project: Explore U.S. Births&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission103Solutions.ipynb"&gt;Guided Project: Customizing Data Visualizations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission201Solution.ipynb"&gt;Guided Project: Star Wars survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission202Solution.ipynb"&gt;Guided Project: Police killings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission205Solutions.ipynb"&gt;Guided Project: Visualizing Pixar's Roller Coaster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission207Solutions.ipynb"&gt;Guided Project: Using Jupyter Notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission209Solution.ipynb"&gt;Guided Project: Analyzing movie reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission210Solution.ipynb"&gt;Guided Project: Winning Jeopardy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission211Solution.ipynb"&gt;Guided Project: Predicting board game reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission213Solution.ipynb"&gt;Guided Project: Predicting bike rentals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission215Solutions.ipynb"&gt;Guided Project: Preparing data for SQLite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission216Solutions.ipynb"&gt;Guided Project: Creating relations in SQLite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission217Solutions.ipynb"&gt;Guided Project: Analyzing NYC High School Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission146Solutions.ipynb"&gt;Guided Project: Visualizing Earnings Based On College Majors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission218Solution.ipynb"&gt;Guided Project: Exploring Gun Deaths in the US&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission219Solution.ipynb"&gt;Guided Project: Analyzing Thanksgiving Dinner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission227Solutions.ipynb"&gt;Guided Project: Analyzing Wikipedia Pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission177Solutions.ipynb"&gt;Guided Project: Analyzing Stock Prices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission188Solution.ipynb"&gt;Guided Project: Creating A Kaggle Workflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission167Solutions.ipynb"&gt;Guided Project: Analyzing Startup Fundraising Deals from Crunchbase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission240Solutions.ipynb"&gt;Guided Project: Predicting House Sale Prices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission191Solutions.ipynb"&gt;Guided Project: Answering Business Questions using SQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission193Solutions.ipynb"&gt;Guided Project: Designing and Creating a Database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission288Solutions.ipynb"&gt;Guided Project: Investigating Fandango's Movie Rating System&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission277Solutions.Rmd"&gt;Guided Project: Forest Fires Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission327Solutions.Rmd"&gt;Guided Project: NYC Schools Perceptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission348Solutions.ipynb"&gt;Guided Project: Clean and Analyze Employee Exit Surveys&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dataquestio/solutions/blob/master/Mission449Solutions.Rmd"&gt;Guided Project: Finding the Best Markets to Advertise In&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dataquestio</author><guid isPermaLink="false">https://github.com/dataquestio/solutions</guid><pubDate>Tue, 04 Feb 2020 00:15:00 GMT</pubDate></item><item><title>pandas-profiling/pandas-profiling #16 in Jupyter Notebook, This month</title><link>https://github.com/pandas-profiling/pandas-profiling</link><description>&lt;p&gt;&lt;i&gt;Create HTML profiling reports from pandas DataFrame objects&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pandas-profiling" class="anchor" aria-hidden="true" href="#pandas-profiling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pandas Profiling&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5915a3ee29e2e8be434e69115b247b9dc04d8b09/687474703a2f2f70616e6461732d70726f66696c696e672e6769746875622e696f2f70616e6461732d70726f66696c696e672f646f63732f6173736574732f6c6f676f5f6865616465722e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/5915a3ee29e2e8be434e69115b247b9dc04d8b09/687474703a2f2f70616e6461732d70726f66696c696e672e6769746875622e696f2f70616e6461732d70726f66696c696e672f646f63732f6173736574732f6c6f676f5f6865616465722e706e67" alt="Pandas Profiling Logo Header" data-canonical-src="http://pandas-profiling.github.io/pandas-profiling/docs/assets/logo_header.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.com/pandas-profiling/pandas-profiling" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/4b87442d24844a9014bcaf73e9e16fa3ff393989/68747470733a2f2f7472617669732d63692e636f6d2f70616e6461732d70726f66696c696e672f70616e6461732d70726f66696c696e672e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/pandas-profiling/pandas-profiling.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/pandas-profiling/pandas-profiling" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/cc1a47f1baa93f73c0f917f502246e251459e9ae/68747470733a2f2f636f6465636f762e696f2f67682f70616e6461732d70726f66696c696e672f70616e6461732d70726f66696c696e672f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d674d7074423459556e46" alt="Code Coverage" data-canonical-src="https://codecov.io/gh/pandas-profiling/pandas-profiling/branch/master/graph/badge.svg?token=gMptB4YUnF" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/pandas-profiling/pandas-profiling/releases"&gt;&lt;img src="https://camo.githubusercontent.com/23536cede3911c60544ddad32e025f295e2b3d79/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f70616e6461732d70726f66696c696e672f70616e6461732d70726f66696c696e672e737667" alt="Release Version" data-canonical-src="https://img.shields.io/github/release/pandas-profiling/pandas-profiling.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/pandas-profiling/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e6e5794289f867d63c8187e3d0519584be3fea06/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f70616e6461732d70726f66696c696e67" alt="Python Version" data-canonical-src="https://img.shields.io/pypi/pyversions/pandas-profiling" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/python/black"&gt;&lt;img src="https://camo.githubusercontent.com/28a51fe3a2c05048d8ca8ecd039d6b1619037326/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667" alt="Code style: black" data-canonical-src="https://img.shields.io/badge/code%20style-black-000000.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Generates profile reports from a pandas &lt;code&gt;DataFrame&lt;/code&gt;.
The pandas &lt;code&gt;df.describe()&lt;/code&gt; function is great but a little basic for serious exploratory data analysis.
&lt;code&gt;pandas_profiling&lt;/code&gt; extends the pandas DataFrame with &lt;code&gt;df.profile_report()&lt;/code&gt; for quick data analysis.&lt;/p&gt;
&lt;p&gt;For each column the following statistics - if relevant for the column type - are presented in an interactive HTML report:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Type inference&lt;/strong&gt;: detect the &lt;a href="#types"&gt;types&lt;/a&gt; of columns in a dataframe.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Essentials&lt;/strong&gt;: type, unique values, missing values&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quantile statistics&lt;/strong&gt; like minimum value, Q1, median, Q3, maximum, range, interquartile range&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Descriptive statistics&lt;/strong&gt; like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Most frequent values&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Histogram&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Correlations&lt;/strong&gt; highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Missing values&lt;/strong&gt; matrix, count, heatmap and dendrogram of missing values&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Text analysis&lt;/strong&gt; learn about categories (Uppercase, Space), scripts (Latin, Cyrillic) and blocks (ASCII) of text data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-announcements" class="anchor" aria-hidden="true" href="#announcements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Announcements&lt;/h2&gt;
&lt;p&gt;With your help, we got approved for &lt;a href="https://github.com/sponsors/sbrugman"&gt;GitHub Sponsors&lt;/a&gt;!
It's extra exciting that GitHub &lt;strong&gt;matches your contribution&lt;/strong&gt; for the first year.
Therefore, we welcome you to support the project through GitHub!&lt;/p&gt;
&lt;p&gt;The v2.4 release includes many new features (performance, exporting, GUI and datasets) and stability improvements.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/sponsors/sbrugman"&gt;Sponsor the project on GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pandas-profiling/pandas-profiling/releases/tag/v2.4.0"&gt;Read the release notes v2.4&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;January 7, 2020&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Contents:&lt;/em&gt; &lt;strong&gt;&lt;a href="#examples"&gt;Examples&lt;/a&gt;&lt;/strong&gt; |
&lt;strong&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="#documentation"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; |
&lt;strong&gt;&lt;a href="#large-datasets"&gt;Large datasets&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="#command-line-usage"&gt;Command line usage&lt;/a&gt;&lt;/strong&gt; |
&lt;strong&gt;&lt;a href="#advanced-usage"&gt;Advanced usage&lt;/a&gt;&lt;/strong&gt; |
&lt;strong&gt;&lt;a href="#types"&gt;Types&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="#how-to-contribute"&gt;How to contribute&lt;/a&gt;&lt;/strong&gt; |
&lt;strong&gt;&lt;a href="#editor-integration"&gt;Editor Integration&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="#dependencies"&gt;Dependencies&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;p&gt;The following examples can give you an impression of what the package can do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://pandas-profiling.github.io/pandas-profiling/examples/census/census_report.html" rel="nofollow"&gt;Census Income&lt;/a&gt; (US Adult Census data relating income)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pandas-profiling.github.io/pandas-profiling/examples/meteorites/meteorites_report.html" rel="nofollow"&gt;NASA Meteorites&lt;/a&gt; (comprehensive set of meteorite landings)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pandas-profiling.github.io/pandas-profiling/examples/titanic/titanic_report.html" rel="nofollow"&gt;Titanic&lt;/a&gt; (the "Wonderwall" of datasets)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pandas-profiling.github.io/pandas-profiling/examples/nza/nza_report.html" rel="nofollow"&gt;NZA&lt;/a&gt; (open data from the Dutch Healthcare Authority)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pandas-profiling.github.io/pandas-profiling/examples/stata_auto/stata_auto_report.html" rel="nofollow"&gt;Stata Auto&lt;/a&gt; (1978 Automobile data)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pandas-profiling.github.io/pandas-profiling/examples/vektis/vektis_report.html" rel="nofollow"&gt;Vektis&lt;/a&gt; (Vektis Dutch Healthcare data)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pandas-profiling.github.io/pandas-profiling/examples/website_inaccessibility/website_inaccessibility_report.html" rel="nofollow"&gt;Website Inaccessibility&lt;/a&gt; (demonstrates the URL type)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pandas-profiling.github.io/pandas-profiling/examples/colors/colors_report.html" rel="nofollow"&gt;Colors&lt;/a&gt; (a simple colors dataset)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pandas-profiling.github.io/pandas-profiling/examples/russian_vocabulary/russian_vocabulary.html" rel="nofollow"&gt;Russian Vocabulary&lt;/a&gt; (demonstrates text analysis)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-using-pip" class="anchor" aria-hidden="true" href="#using-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using pip&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://pepy.tech/project/pandas-profiling" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/69dbdf3122f4305a3fd7f70f3504b3d123d8ffca/68747470733a2f2f706570792e746563682f62616467652f70616e6461732d70726f66696c696e67" alt="PyPi Downloads" data-canonical-src="https://pepy.tech/badge/pandas-profiling" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pepy.tech/project/pandas-profiling/month" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/fffc573c1f8f97fde5518a55fedd43da9cea1ee9/68747470733a2f2f706570792e746563682f62616467652f70616e6461732d70726f66696c696e672f6d6f6e7468" alt="PyPi Monthly Downloads" data-canonical-src="https://pepy.tech/badge/pandas-profiling/month" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/pandas-profiling/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/412ffab9bf8e373223f1ca66040f86bc5b6607da/68747470733a2f2f62616467652e667572792e696f2f70792f70616e6461732d70726f66696c696e672e737667" alt="PyPi Version" data-canonical-src="https://badge.fury.io/py/pandas-profiling.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can install using the pip package manager by running&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install pandas-profiling[notebook,html]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively, you could install directly from Github:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-using-conda" class="anchor" aria-hidden="true" href="#using-conda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using conda&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://anaconda.org/conda-forge/pandas-profiling" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3bd64befdfbfab2421f7ee9537d2820230fba16a/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f70616e6461732d70726f66696c696e672e737667" alt="Conda Downloads" data-canonical-src="https://img.shields.io/conda/dn/conda-forge/pandas-profiling.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://anaconda.org/conda-forge/pandas-profiling" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/7e40a30f7cb430e3293880d9a68d6d8c9044facd/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f70616e6461732d70726f66696c696e672e737667" alt="Conda Version" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/pandas-profiling.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can install using the conda package manager by running&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c conda-forge pandas-profiling
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-from-source" class="anchor" aria-hidden="true" href="#from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;From source&lt;/h3&gt;
&lt;p&gt;Download the source code by cloning the repository or by pressing &lt;a href="https://github.com/pandas-profiling/pandas-profiling/archive/master.zip"&gt;'Download ZIP'&lt;/a&gt; on this page.
Install by navigating to the proper directory and running&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python setup.py install
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;The documentation for &lt;code&gt;pandas_profiling&lt;/code&gt; can be found &lt;a href="https://pandas-profiling.github.io/pandas-profiling/docs/" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting started&lt;/h3&gt;
&lt;p&gt;Start by loading in your pandas DataFrame, e.g. by using&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np
&lt;span class="pl-k"&gt;import&lt;/span&gt; pandas &lt;span class="pl-k"&gt;as&lt;/span&gt; pd
&lt;span class="pl-k"&gt;from&lt;/span&gt; pandas_profiling &lt;span class="pl-k"&gt;import&lt;/span&gt; ProfileReport

df &lt;span class="pl-k"&gt;=&lt;/span&gt; pd.DataFrame(
    np.random.rand(&lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-c1"&gt;5&lt;/span&gt;),
    &lt;span class="pl-v"&gt;columns&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;a&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;b&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;c&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;d&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;e&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To generate the report, run:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;profile &lt;span class="pl-k"&gt;=&lt;/span&gt; ProfileReport(df, &lt;span class="pl-v"&gt;title&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Pandas Profiling Report&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;html&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;style&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;:{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;full_width&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;:&lt;span class="pl-c1"&gt;True&lt;/span&gt;}})&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-jupyter-notebook" class="anchor" aria-hidden="true" href="#jupyter-notebook"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Jupyter Notebook&lt;/h4&gt;
&lt;p&gt;We recommend generating reports interactively by using the Jupyter notebook.
There are two interfaces (see animations below): through widgets and through a HTML report.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/32a6de6f65af60fd71d2af68075ef51c86ee2591/687474703a2f2f70616e6461732d70726f66696c696e672e6769746875622e696f2f70616e6461732d70726f66696c696e672f646f63732f6173736574732f776964676574732e676966"&gt;&lt;img alt="Notebook Widgets" src="https://camo.githubusercontent.com/32a6de6f65af60fd71d2af68075ef51c86ee2591/687474703a2f2f70616e6461732d70726f66696c696e672e6769746875622e696f2f70616e6461732d70726f66696c696e672f646f63732f6173736574732f776964676574732e676966" width="800" data-canonical-src="http://pandas-profiling.github.io/pandas-profiling/docs/assets/widgets.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is achieved by simply displaying the report. In the Jupyter Notebook, run:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;profile&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The HTML report can be included in a Juyter notebook:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/90c46e89ac2db9a07473cbb03f9a8329ec0071f5/687474703a2f2f70616e6461732d70726f66696c696e672e6769746875622e696f2f70616e6461732d70726f66696c696e672f646f63732f6173736574732f696672616d652e676966"&gt;&lt;img alt="HTML" src="https://camo.githubusercontent.com/90c46e89ac2db9a07473cbb03f9a8329ec0071f5/687474703a2f2f70616e6461732d70726f66696c696e672e6769746875622e696f2f70616e6461732d70726f66696c696e672f646f63732f6173736574732f696672616d652e676966" width="800" data-canonical-src="http://pandas-profiling.github.io/pandas-profiling/docs/assets/iframe.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Run the following code:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;profile.to_notebook_iframe()&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-saving-the-report" class="anchor" aria-hidden="true" href="#saving-the-report"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Saving the report&lt;/h4&gt;
&lt;p&gt;If you want to generate a HTML report file, save the &lt;code&gt;ProfileReport&lt;/code&gt; to an object and use the &lt;code&gt;to_file()&lt;/code&gt; function:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;profile.to_file(&lt;span class="pl-v"&gt;output_file&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;your_report.html&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Alternatively, you can obtain the data as json:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; As a string&lt;/span&gt;
json_data &lt;span class="pl-k"&gt;=&lt;/span&gt; profile.to_json()

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; As a file&lt;/span&gt;
profile.to_file(&lt;span class="pl-v"&gt;output_file&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;your_report.json&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-large-datasets" class="anchor" aria-hidden="true" href="#large-datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Large datasets&lt;/h3&gt;
&lt;p&gt;Version 2.4 introduces minimal mode.
This is a default configuration that disables expensive computations (such as correlations and dynamic binning).
Use the following syntax:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;profile &lt;span class="pl-k"&gt;=&lt;/span&gt; ProfileReport(large_dataset, &lt;span class="pl-v"&gt;minimal&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
profile.to_file(&lt;span class="pl-v"&gt;output_file&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;output.html&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-command-line-usage" class="anchor" aria-hidden="true" href="#command-line-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Command line usage&lt;/h3&gt;
&lt;p&gt;For standard formatted CSV files that can be read immediately by pandas, you can use the &lt;code&gt;pandas_profiling&lt;/code&gt; executable. Run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pandas_profiling -h
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;for information about options and arguments.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-advanced-usage" class="anchor" aria-hidden="true" href="#advanced-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Advanced usage&lt;/h3&gt;
&lt;p&gt;A set of options is available in order to adapt the report generated.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;title&lt;/code&gt; (&lt;code&gt;str&lt;/code&gt;): Title for the report ('Pandas Profiling Report' by default).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pool_size&lt;/code&gt; (&lt;code&gt;int&lt;/code&gt;): Number of workers in thread pool. When set to zero, it is set to the number of CPUs available (0 by default).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;progress_bar&lt;/code&gt; (&lt;code&gt;bool&lt;/code&gt;): If True, &lt;code&gt;pandas-profiling&lt;/code&gt; will display a progress bar.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More settings can be found in the &lt;a href="https://github.com/pandas-profiling/pandas-profiling/blob/master/src/pandas_profiling/config_default.yaml"&gt;default configuration file&lt;/a&gt;, &lt;a href="https://github.com/pandas-profiling/pandas-profiling/blob/master/src/pandas_profiling/config_minimal.yaml"&gt;minimal configuration file&lt;/a&gt; and &lt;a href="https://github.com/pandas-profiling/pandas-profiling/blob/master/src/pandas_profiling/config_dark.yaml"&gt;dark themed configuration file&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;profile &lt;span class="pl-k"&gt;=&lt;/span&gt; df.profile_report(&lt;span class="pl-v"&gt;title&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Pandas Profiling Report&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;plot&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;histogram&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bins&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;8&lt;/span&gt;}})
profile.to_file(&lt;span class="pl-v"&gt;output_file&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;output.html&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-types" class="anchor" aria-hidden="true" href="#types"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Types&lt;/h2&gt;
&lt;p&gt;Types are a powerful abstraction for effective data analysis, that goes beyond the logical data types (integer, float etc.).
&lt;code&gt;pandas-profiling&lt;/code&gt; currently recognizes the following types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Boolean&lt;/li&gt;
&lt;li&gt;Numerical&lt;/li&gt;
&lt;li&gt;Date&lt;/li&gt;
&lt;li&gt;Categorical&lt;/li&gt;
&lt;li&gt;URL&lt;/li&gt;
&lt;li&gt;Path&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We have developed a type system for Python, tailored for data analysis: &lt;a href="https://github.com/dylan-profiler/visions"&gt;visions&lt;/a&gt;.
Selecting the right typeset drastically reduces the complexity the code of your analysis.
Future versions of &lt;code&gt;pandas-profiling&lt;/code&gt; will have extended type support through &lt;code&gt;visions&lt;/code&gt;!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-contribute" class="anchor" aria-hidden="true" href="#how-to-contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to contribute&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://stackoverflow.com/questions/tagged/pandas-profiling" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3aecee78802b7df4fce7bf2a289cb3231d50c32b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737461636b6f766572666c6f772532307461672d70616e64617325323070726f66696c696e672d79656c6c6f77" alt="Questions: Stackoverflow &amp;quot;pandas-profiling&amp;quot;" data-canonical-src="https://img.shields.io/badge/stackoverflow%20tag-pandas%20profiling-yellow" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The package is actively maintained and developed as open-source software.
If &lt;code&gt;pandas-profiling&lt;/code&gt; was helpful or interesting to you, you might want to get involved.
There are several ways of contributing and helping our thousands of users.
If you would like to be a industry partner or sponsor, please &lt;a href="mailto:pandasprofiling@gmail.com"&gt;drop us a line&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The documentation is generated using &lt;a href="https://github.com/pdoc3/pdoc"&gt;&lt;code&gt;pdoc3&lt;/code&gt;&lt;/a&gt;.
If you are contributing to this project, you can rebuild the documentation using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;make docs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or on Windows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;make.bat docs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Read more on getting involved in the &lt;a href="https://github.com/pandas-profiling/pandas-profiling/blob/master/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-editor-integration" class="anchor" aria-hidden="true" href="#editor-integration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Editor integration&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-pycharm-integration" class="anchor" aria-hidden="true" href="#pycharm-integration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyCharm integration&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install &lt;code&gt;pandas-profiling&lt;/code&gt; via the instructions above&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Locate your &lt;code&gt;pandas-profiling&lt;/code&gt; executable.&lt;/p&gt;
&lt;p&gt;On macOS / Linux / BSD:&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;$ &lt;span class="pl-s1"&gt;which pandas_profiling&lt;/span&gt;
&lt;span class="pl-c1"&gt;(example) /usr/local/bin/pandas_profiling&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On Windows:&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;$ &lt;span class="pl-s1"&gt;where pandas_profiling&lt;/span&gt;
&lt;span class="pl-c1"&gt;(example) C:\ProgramData\Anaconda3\Scripts\pandas_profiling.exe&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In Pycharm, go to &lt;em&gt;Settings&lt;/em&gt; (or &lt;em&gt;Preferences&lt;/em&gt; on macOS) &amp;gt; &lt;em&gt;Tools&lt;/em&gt; &amp;gt; &lt;em&gt;External tools&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click the &lt;em&gt;+&lt;/em&gt; icon to add a new external tool&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Insert the following values&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Name: Pandas Profiling&lt;/li&gt;
&lt;li&gt;Program: &lt;em&gt;&lt;strong&gt;The location obtained in step 2&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Arguments: "$FilePath$" "$FileDir$/$FileNameWithoutAllExtensions$_report.html"&lt;/li&gt;
&lt;li&gt;Working Directory: $ProjectFileDir$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/96214837878c30f71c00da767204601394c7c998/687474703a2f2f70616e6461732d70726f66696c696e672e6769746875622e696f2f70616e6461732d70726f66696c696e672f646f63732f6173736574732f7079636861726d2d696e746567726174696f6e2e706e67"&gt;&lt;img alt="PyCharm Integration" src="https://camo.githubusercontent.com/96214837878c30f71c00da767204601394c7c998/687474703a2f2f70616e6461732d70726f66696c696e672e6769746875622e696f2f70616e6461732d70726f66696c696e672f646f63732f6173736574732f7079636861726d2d696e746567726174696f6e2e706e67" width="400" data-canonical-src="http://pandas-profiling.github.io/pandas-profiling/docs/assets/pycharm-integration.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To use the PyCharm Integration, right click on any dataset file:
&lt;em&gt;External Tools&lt;/em&gt; &amp;gt; &lt;em&gt;Pandas Profiling&lt;/em&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-other-integrations" class="anchor" aria-hidden="true" href="#other-integrations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other integrations&lt;/h3&gt;
&lt;p&gt;Other editor integrations may be contributed via pull requests.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h2&gt;
&lt;p&gt;The profile report is written in HTML and CSS, which means pandas-profiling requires a modern browser.&lt;/p&gt;
&lt;p&gt;You need &lt;a href="https://python3statement.org/" rel="nofollow"&gt;Python 3&lt;/a&gt; to run this package. Other dependencies can be found in the requirements files:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Filename&lt;/th&gt;
&lt;th&gt;Requirements&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/pandas-profiling/pandas-profiling/blob/master/requirements.txt"&gt;requirements.txt&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Package requirements&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/pandas-profiling/pandas-profiling/blob/master/requirements-dev.txt"&gt;requirements-dev.txt&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Requirements for development&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/pandas-profiling/pandas-profiling/blob/master/requirements-test.txt"&gt;requirements-test.txt&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Requirements for testing&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/pandas-profiling/pandas-profiling/blob/master/setup.py"&gt;setup.py&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Requirements for Widgets etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>pandas-profiling</author><guid isPermaLink="false">https://github.com/pandas-profiling/pandas-profiling</guid><pubDate>Tue, 04 Feb 2020 00:16:00 GMT</pubDate></item><item><title>lmoroney/dlaicourse #17 in Jupyter Notebook, This month</title><link>https://github.com/lmoroney/dlaicourse</link><description>&lt;p&gt;&lt;i&gt;Notebooks for learning deep learning&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;This repo does not have a README.&lt;/i&gt;&lt;/p&gt;</description><author>lmoroney</author><guid isPermaLink="false">https://github.com/lmoroney/dlaicourse</guid><pubDate>Tue, 04 Feb 2020 00:17:00 GMT</pubDate></item><item><title>keplergl/kepler.gl #18 in Jupyter Notebook, This month</title><link>https://github.com/keplergl/kepler.gl</link><description>&lt;p&gt;&lt;i&gt;Kepler.gl is a powerful open source geospatial analysis tool for large-scale data sets.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="right"&gt;
  &lt;a href="https://npmjs.org/package/kepler.gl" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/39b83380bed6b131827a4084fcc946e7768f9de9/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f6b65706c65722e676c2e7376673f7374796c653d666c6174" alt="version" data-canonical-src="https://img.shields.io/npm/v/kepler.gl.svg?style=flat" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://travis-ci.com/keplergl/kepler.gl" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/1c87db0a474e59d3eff3e0c30de97b347f2b1e26/68747470733a2f2f6170692e7472617669732d63692e636f6d2f6b65706c6572676c2f6b65706c65722e676c2e7376673f6272616e63683d6d6173746572" alt="build" data-canonical-src="https://api.travis-ci.com/keplergl/kepler.gl.svg?branch=master" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://github.com/keplergl/kepler.gl"&gt;
    &lt;img src="https://camo.githubusercontent.com/978f96202ab21d01de29c206b1baf8dbdb14bf99/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b65706c6572676c2f6b65706c65722e676c2e7376673f7374796c653d666c6174" alt="stars" data-canonical-src="https://img.shields.io/github/stars/keplergl/kepler.gl.svg?style=flat" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://opensource.org/licenses/MIT" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/311762166ef25238116d3cadd22fcb6091edab98/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d626c75652e737667" alt="MIT License" data-canonical-src="https://img.shields.io/badge/License-MIT-blue.svg" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://app.fossa.com/projects/custom%2B4458%2Fgithub.com%2Fkeplergl%2Fkepler.gl?ref=badge_shield" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/bdd5a5da67d3e20bcad91210d3f2cc79122f0e48/68747470733a2f2f6170702e666f7373612e636f6d2f6170692f70726f6a656374732f637573746f6d253242343435382532466769746875622e636f6d2532466b65706c6572676c2532466b65706c65722e676c2e7376673f747970653d736869656c64" alt="Fossa" data-canonical-src="https://app.fossa.com/api/projects/custom%2B4458%2Fgithub.com%2Fkeplergl%2Fkepler.gl.svg?type=shield" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://app.netlify.com/sites/keplergl/deploys" alt="Netlify Status" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/c3970e7abf4941017d0990191a86cebdc43cba0f/68747470733a2f2f696d672e736869656c64732e696f2f656e64706f696e742e7376673f75726c3d6874747073253341253246253246646576656c6f7065722e6f7377616c646c6162732e636f6d2532466e65746c6966792d73746174757325324630633962383935632d616364302d343366642d386166372d6665393630313831623638363f7374796c653d666c6174" data-canonical-src="https://img.shields.io/endpoint.svg?url=https%3A%2F%2Fdeveloper.oswaldlabs.com%2Fnetlify-status%2F0c9b895c-acd0-43fd-8af7-fe960181b686?style=flat" style="max-width:100%;"&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;h1 align="center"&gt;&lt;a id="user-content-keplergl--website-demo-app" class="anchor" aria-hidden="true" href="#keplergl--website-demo-app"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;kepler.gl | &lt;a href="http://kepler.gl" rel="nofollow"&gt;Website&lt;/a&gt; |
&lt;a href="http://kepler.gl/#/demo" rel="nofollow"&gt;Demo App&lt;/a&gt;
&lt;/h1&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://kepler.gl" rel="nofollow"&gt;&lt;img width="120" alt="Kepler.gl" src="https://camo.githubusercontent.com/c98e8bfb69c993dfe96e6a210371bc279668e878/68747470733a2f2f6431613366347370617a7a7270342e636c6f756466726f6e742e6e65742f6b65706c65722e676c2f776562736974652f69636f6e732f6b65706c65722e676c2d6c6f676f2e706e67" data-canonical-src="https://d1a3f4spazzrp4.cloudfront.net/kepler.gl/website/icons/kepler.gl-logo.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://kepler.gl/#/demo" rel="nofollow"&gt;&lt;img width="600" alt="Kepler.gl Demo" src="https://camo.githubusercontent.com/cac4939b4bfc401673b49c6f619b4dc2212bc8db/68747470733a2f2f656e672e756265722e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f30352f696d616765342d332d373638783439332e706e67" data-canonical-src="https://eng.uber.com/wp-content/uploads/2018/05/image4-3-768x493.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.kepler.gl/" rel="nofollow"&gt;Kepler.gl&lt;/a&gt; is a data-agnostic, high-performance web-based application for visual exploration of large-scale geolocation data sets. Built on top of &lt;a href="https://www.mapbox.com" rel="nofollow"&gt;Mapbox GL&lt;/a&gt; and &lt;a href="http://uber.github.io/deck.gl/#/" rel="nofollow"&gt;deck.gl&lt;/a&gt;, kepler.gl can render millions of points representing thousands of trips and perform spatial aggregations on the fly.&lt;/p&gt;
&lt;p&gt;Kepler.gl is also a React component that uses &lt;a href="https://redux.js.org/" rel="nofollow"&gt;Redux&lt;/a&gt; to manage its state and data flow. It can be embedded into other React-Redux applications and is highly customizable. For information on how to embed kepler.gl in your app take a look at this step-by-step &lt;a href="http://vis.academy/#/kepler.gl/" rel="nofollow"&gt;tutorial&lt;/a&gt; on vis.academy.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-links" class="anchor" aria-hidden="true" href="#links"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.kepler.gl/" rel="nofollow"&gt;Website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://kepler.gl/#/demo" rel="nofollow"&gt;Demo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/keplergl/kepler.gl/tree/master/examples"&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="./docs/api-reference/get-started.md"&gt;Get Started&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="./docs/user-guides/a-introduction.md"&gt;App User Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="./docs/keplergl-jupyter/user-guide.md"&gt;Jupyter Widget User Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://vis.academy/#/kepler.gl/" rel="nofollow"&gt;Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://stackoverflow.com/questions/tagged/kepler.gl" rel="nofollow"&gt;Stack Overflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="contributing/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="./docs/api-reference/overview.md"&gt;Api Reference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/keplergl/kepler.gl/wiki/Kepler.gl-2019-Roadmap"&gt;Roadmap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-env" class="anchor" aria-hidden="true" href="#env"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Env&lt;/h2&gt;
&lt;p&gt;Use Node 8.15.0 and above, older node versions have not been tested.
For best results, use &lt;a href="https://github.com/creationix/nvm"&gt;nvm&lt;/a&gt; &lt;code&gt;nvm install&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-install-keplergl" class="anchor" aria-hidden="true" href="#install-keplergl"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install kepler.gl&lt;/h2&gt;
&lt;p&gt;Install node (&lt;code&gt;&amp;gt; 8.15.0&lt;/code&gt;), yarn, and project dependencies&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;npm install --save kepler.gl
// or
yarn add kepler.gl&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;kepler.gl is built upon &lt;a href="https://www.mapbox.com" rel="nofollow"&gt;mapbox&lt;/a&gt;. You will need a &lt;a href="https://www.mapbox.com/help/define-access-token/" rel="nofollow"&gt;Mapbox Access Token&lt;/a&gt; to use it.&lt;/p&gt;
&lt;p&gt;If you don't use a module bundler, it's also fine. Kepler.gl npm package includes precompiled production UMD builds in the (umd folder)[&lt;a href="https://unpkg.com/kepler.gl/umd" rel="nofollow"&gt;https://unpkg.com/kepler.gl/umd&lt;/a&gt;].
You can add the script tag to your html file as it follows:&lt;/p&gt;
&lt;div class="highlight highlight-text-html-basic"&gt;&lt;pre&gt;&amp;lt;&lt;span class="pl-ent"&gt;script&lt;/span&gt; &lt;span class="pl-e"&gt;src&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;https://unpkg.com/kepler.gl/umd/keplergl.min.js&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span class="pl-ent"&gt;script&lt;/span&gt;&amp;gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or if you would like, you can load a specific version&lt;/p&gt;
&lt;div class="highlight highlight-text-html-basic"&gt;&lt;pre&gt;&amp;lt;&lt;span class="pl-ent"&gt;script&lt;/span&gt; &lt;span class="pl-e"&gt;src&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;https://unpkg.com/kepler.gl@0.2.2/umd/keplergl.min.js&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span class="pl-ent"&gt;script&lt;/span&gt;&amp;gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-develop-keplergl" class="anchor" aria-hidden="true" href="#develop-keplergl"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Develop kepler.gl&lt;/h2&gt;
&lt;p&gt;Take a look at the &lt;a href="contributing/DEVELOPERS.md"&gt;development guide&lt;/a&gt; to develop kepler.gl locally.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Basic Usage&lt;/h2&gt;
&lt;p&gt;Here are the basic steps to import kepler.gl into your app. You also take a look at the examples folder. Each example in the folder can be installed and run locally.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-1-mount-reducer" class="anchor" aria-hidden="true" href="#1-mount-reducer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Mount reducer&lt;/h3&gt;
&lt;p&gt;Kepler.gl uses Redux to manage its internal state, along with &lt;a href="https://github.com/btford/react-palm"&gt;react-palm&lt;/a&gt; middleware to handle side effects.&lt;/p&gt;
&lt;p&gt;You need to add &lt;code&gt;taskMiddleware&lt;/code&gt; of &lt;code&gt;react-palm&lt;/code&gt; to your store too. We are actively working on a solution where
&lt;code&gt;react-palm&lt;/code&gt; will not be required, however it is still a very lightweight side effects management tool that is easier to test than react-thunk.&lt;/p&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; {&lt;span class="pl-smi"&gt;createStore&lt;/span&gt;, &lt;span class="pl-smi"&gt;combineReducers&lt;/span&gt;, &lt;span class="pl-smi"&gt;applyMiddleware&lt;/span&gt;, &lt;span class="pl-smi"&gt;compose&lt;/span&gt;} &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;redux&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-smi"&gt;keplerGlReducer&lt;/span&gt; &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kepler.gl/reducers&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;
&lt;span class="pl-k"&gt;import&lt;/span&gt; {&lt;span class="pl-smi"&gt;enhanceReduxMiddleware&lt;/span&gt;} &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kepler.gl/middleware&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;initialState&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; {};
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;reducers&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;combineReducers&lt;/span&gt;({
  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; &amp;lt;-- mount kepler.gl reducer in your app&lt;/span&gt;
  keplerGl&lt;span class="pl-k"&gt;:&lt;/span&gt; keplerGlReducer,

  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Your other reducers here&lt;/span&gt;
  app&lt;span class="pl-k"&gt;:&lt;/span&gt; appReducer
});

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; using createStore&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; &lt;span class="pl-c1"&gt;default&lt;/span&gt; &lt;span class="pl-smi"&gt;createStore&lt;/span&gt;(
  reducer,
  initialState,
  &lt;span class="pl-en"&gt;applyMiddleware&lt;/span&gt;(
    &lt;span class="pl-en"&gt;enhanceReduxMiddleware&lt;/span&gt;([
      &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;/*&lt;/span&gt; Add other middlewares here &lt;span class="pl-c"&gt;*/&lt;/span&gt;&lt;/span&gt;
    ])
  )
);&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or if use enhancer:&lt;/p&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; using enhancers&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;initialState&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; {};
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;middlewares&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;enhanceReduxMiddleware&lt;/span&gt;([
  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Add other middlewares here&lt;/span&gt;
]);
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;enhancers&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-en"&gt;applyMiddleware&lt;/span&gt;(&lt;span class="pl-k"&gt;...&lt;/span&gt;middlewares)];

&lt;span class="pl-k"&gt;export&lt;/span&gt; &lt;span class="pl-c1"&gt;default&lt;/span&gt; &lt;span class="pl-smi"&gt;createStore&lt;/span&gt;(reducer, initialState, &lt;span class="pl-en"&gt;compose&lt;/span&gt;(&lt;span class="pl-k"&gt;...&lt;/span&gt;enhancers));&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you mount kepler.gl reducer in another address instead of &lt;code&gt;keplerGl&lt;/code&gt;, or the kepler.gl reducer is not
mounted at root of your state, you will need to specify the path to it when you mount the component
with the &lt;code&gt;getState&lt;/code&gt; prop.&lt;/p&gt;
&lt;p&gt;Read more about &lt;a href="./docs/api-reference/reducers/overview.md"&gt;Reducers&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-2-mount-component" class="anchor" aria-hidden="true" href="#2-mount-component"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Mount Component&lt;/h3&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-smi"&gt;KeplerGl&lt;/span&gt; &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kepler.gl&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;Map&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-smi"&gt;props&lt;/span&gt; &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; (
  &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;KeplerGl
    id&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;foo&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
    width&lt;span class="pl-k"&gt;=&lt;/span&gt;{width}
    mapboxApiAccessToken&lt;span class="pl-k"&gt;=&lt;/span&gt;{token}
    height&lt;span class="pl-k"&gt;=&lt;/span&gt;{height}
  &lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
);&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-props" class="anchor" aria-hidden="true" href="#props"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Props&lt;/h4&gt;
&lt;h5&gt;&lt;a id="user-content-id-string-required" class="anchor" aria-hidden="true" href="#id-string-required"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;id&lt;/code&gt; (String, required)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;map&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The id of this KeplerGl instance. &lt;code&gt;id&lt;/code&gt; is required if you have multiple
KeplerGl instances in your app. It defines the prop name of the KeplerGl state that is
stored in the KeplerGl reducer. For example, the state of the KeplerGl component with id &lt;code&gt;foo&lt;/code&gt; is
stored in &lt;code&gt;state.keplerGl.foo&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In case you create multiple kepler.gl instances using the same id, the kepler.gl state defined by the entry will be
overridden by the latest instance and reset to a blank state.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-mapboxapiaccesstoken-string-required" class="anchor" aria-hidden="true" href="#mapboxapiaccesstoken-string-required"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;mapboxApiAccessToken&lt;/code&gt; (String, required)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;undefined&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can create a free account at &lt;a href="https://www.mapbox.com" rel="nofollow"&gt;mapbox&lt;/a&gt; and create a token at &lt;a href="https://www.mapbox.com/help/define-access-token/" rel="nofollow"&gt;www.mapbox.com/account/access-tokens&lt;/a&gt;&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-getstate-function-optional" class="anchor" aria-hidden="true" href="#getstate-function-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;getState&lt;/code&gt; (Function, optional)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;state =&amp;gt; state.keplerGl&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The path to the root keplerGl state in your reducer.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-width-number-optional" class="anchor" aria-hidden="true" href="#width-number-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;width&lt;/code&gt; (Number, optional)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;800&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Width of the KeplerGl UI.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-height-number-optional" class="anchor" aria-hidden="true" href="#height-number-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;height&lt;/code&gt; (Number, optional)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;800&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-appname-string-optional" class="anchor" aria-hidden="true" href="#appname-string-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;appName&lt;/code&gt; (String, optional)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;Kepler.Gl&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;App name displayed in side panel header&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-version-string-optional" class="anchor" aria-hidden="true" href="#version-string-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;version&lt;/code&gt; (String, optional)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;v1.0&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;version displayed in side panel header&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-onsavemap-function-optional" class="anchor" aria-hidden="true" href="#onsavemap-function-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;onSaveMap&lt;/code&gt; (Function, optional)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;undefined&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Action called when click Save Map Url in side panel header.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-onviewstatechange-function-optional" class="anchor" aria-hidden="true" href="#onviewstatechange-function-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;onViewStateChange&lt;/code&gt; (Function, optional)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;undefined&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Parameter: &lt;code&gt;viewState&lt;/code&gt; - An updated view state object containing parameters such as longitude, latitude, zoom etc&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Action triggered when map viewport is updated.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-getmapboxrefmapbox-index-function-optional" class="anchor" aria-hidden="true" href="#getmapboxrefmapbox-index-function-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;getMapboxRef(mapbox, index)&lt;/code&gt; (Function, optional)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;undefined&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Function called when &lt;code&gt;KeplerGL&lt;/code&gt; adds or removes a &lt;code&gt;MapContainer&lt;/code&gt; component having an inner Mapbox map.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;mapbox&lt;/code&gt; argument is an &lt;a href="https://uber.github.io/react-map-gl/#/Documentation/api-reference/interactive-map" rel="nofollow"&gt;&lt;code&gt;InteractiveMap&lt;/code&gt;&lt;/a&gt; when added or &lt;code&gt;null&lt;/code&gt; when removed.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;index&lt;/code&gt; argument is 0 for a single map or 1 for an additional map (since &lt;code&gt;KeplerGL&lt;/code&gt; supports an optional split map view).&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-actions-object-optional" class="anchor" aria-hidden="true" href="#actions-object-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;actions&lt;/code&gt; (Object, optional)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;{}&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Actions creators to replace default kepler.gl action creator. Only use custom action when you want to modify action payload.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-mint-boolean-optional" class="anchor" aria-hidden="true" href="#mint-boolean-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;mint&lt;/code&gt; (Boolean, optional)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;true&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Whether to load a fresh empty state when component is mounted. when parse &lt;code&gt;mint: true&lt;/code&gt; kepler.gl component will always load a fresh state when re-mount the same component, state inside this component will be destroyed once its unmounted.
By Parsing &lt;code&gt;mint: false&lt;/code&gt; kepler.gl will keep the component state in the store even when it is unmounted, and use it as initial state when re-mounted again. This is useful when mounting kepler.gl in a modal, and keep the same map when re-open.&lt;/p&gt;
&lt;p&gt;Read more about &lt;a href="./docs/api-reference/components/overview.md"&gt;Components&lt;/a&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-theme-object--string-optional" class="anchor" aria-hidden="true" href="#theme-object--string-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;theme&lt;/code&gt; (Object | String, optional)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;default: &lt;code&gt;null&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can pass theme name or object used to customize Kepler.gl style. Kepler.gl provide an &lt;code&gt;'light'&lt;/code&gt; theme besides the default 'dark' theme. When pass in a theme object Kepler.gl will use the value passed as input to override values from &lt;a href="https://github.com/keplergl/kepler.gl/blob/master/src/styles/base.js"&gt;theme&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-mapboxapiurl-string-optional" class="anchor" aria-hidden="true" href="#mapboxapiurl-string-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;mapboxApiUrl&lt;/code&gt; (String, optional)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;https://api.mapbox.com&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you are using your own mapbox tile server, you can pass in your own tile server api url.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-mapstylesreplacedefault-boolean-optional" class="anchor" aria-hidden="true" href="#mapstylesreplacedefault-boolean-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;mapStylesReplaceDefault&lt;/code&gt; (Boolean, optional)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;false&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;kepler.gl provide 4 map styles to choose from. Pass &lt;code&gt;true&lt;/code&gt; if you want to supply your own &lt;code&gt;mapStyles&lt;/code&gt;. See Below.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-mapstyles-array-optional" class="anchor" aria-hidden="true" href="#mapstyles-array-optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;mapStyles&lt;/code&gt; (Array, optional)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Default: &lt;code&gt;[]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can supply additional map styles to be displayed in &lt;a href="https://github.com/keplergl/kepler.gl/blob/master/docs/user-guides/f-map-styles/1-base-map-styles.md"&gt;map style selection panel&lt;/a&gt;. By default, additional map styles will be added to default map styles. If pass &lt;code&gt;mapStylesReplaceDefault: true&lt;/code&gt;, they will replace the default ones. kepler.gl will attempt to group layers of your style based on its &lt;code&gt;id&lt;/code&gt; naming convention and use it to allow toggle visibility of &lt;a href="https://github.com/keplergl/kepler.gl/blob/master/docs/user-guides/f-map-styles/2-map-layers.md"&gt;base map layers&lt;/a&gt;. Supply your own &lt;code&gt;layerGroups&lt;/code&gt; to override default for more accurate layer grouping.&lt;/p&gt;
&lt;p&gt;Each &lt;code&gt;mapStyles&lt;/code&gt; should has the following properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;id&lt;/code&gt; (String, required) unique string that should &lt;strong&gt;not&lt;/strong&gt; be one of these reserved &lt;code&gt;dark&lt;/code&gt; &lt;code&gt;light&lt;/code&gt; &lt;code&gt;muted&lt;/code&gt;. &lt;code&gt;muted_night&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;label&lt;/code&gt; (String, required) name to be displayed in map style selection panel&lt;/li&gt;
&lt;li&gt;&lt;code&gt;url&lt;/code&gt; (String, required) mapbox style url or a url pointing to the map style json object&lt;/li&gt;
&lt;li&gt;&lt;code&gt;icon&lt;/code&gt; (String, optional) image icon of the style, it can be a url, or an &lt;a href="https://flaviocopes.com/data-urls/#how-does-a-data-url-look" rel="nofollow"&gt;image data url&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;layerGroups&lt;/code&gt; (Array, optional)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;mapStyles&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; [
  {
    id&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;my_dark_map&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
    label&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Dark Streets 9&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
    url&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;mapbox://styles/mapbox/dark-v9&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
    icon&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;`&lt;/span&gt;&lt;span class="pl-s1"&gt;&lt;span class="pl-pse"&gt;${&lt;/span&gt;apiHost&lt;span class="pl-pse"&gt;}&lt;/span&gt;&lt;/span&gt;/styles/v1/mapbox/dark-v9/static/-122.3391,37.7922,9.19,0,0/400x300?access_token=&lt;span class="pl-s1"&gt;&lt;span class="pl-pse"&gt;${&lt;/span&gt;accessToken&lt;span class="pl-pse"&gt;}&lt;/span&gt;&lt;/span&gt;&amp;amp;logo=false&amp;amp;attribution=false&lt;span class="pl-pds"&gt;`&lt;/span&gt;&lt;/span&gt;,
    layerGroups&lt;span class="pl-k"&gt;:&lt;/span&gt; [
      {
        slug&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;label&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
        &lt;span class="pl-en"&gt;filter&lt;/span&gt;&lt;span class="pl-k"&gt;:&lt;/span&gt; ({id}) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-smi"&gt;id&lt;/span&gt;.&lt;span class="pl-c1"&gt;match&lt;/span&gt;(&lt;span class="pl-sr"&gt;&lt;span class="pl-pds"&gt;/&lt;/span&gt;(?=(label&lt;span class="pl-k"&gt;|&lt;/span&gt;place-&lt;span class="pl-k"&gt;|&lt;/span&gt;poi-))&lt;span class="pl-pds"&gt;/&lt;/span&gt;&lt;/span&gt;),
        defaultVisibility&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-c1"&gt;true&lt;/span&gt;
      },
      {
        &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; adding this will keep the 3d building option&lt;/span&gt;
        slug&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;3d building&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
        &lt;span class="pl-en"&gt;filter&lt;/span&gt;&lt;span class="pl-k"&gt;:&lt;/span&gt; () &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;false&lt;/span&gt;,
        defaultVisibility&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-c1"&gt;false&lt;/span&gt;
      }
    ]
  }
];&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-3-dispatch-custom-actions-to-keplergl-reducer" class="anchor" aria-hidden="true" href="#3-dispatch-custom-actions-to-keplergl-reducer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. Dispatch custom actions to &lt;code&gt;keplerGl&lt;/code&gt; reducer.&lt;/h3&gt;
&lt;p&gt;One advantage of using the reducer over React component state to handle keplerGl state is the flexibility
to customize its behavior. If you only have one &lt;code&gt;KeplerGl&lt;/code&gt; instance in your app or never intend to dispatch actions to KeplerGl from outside the component itself,
you donâ€™t need to worry about forwarding dispatch and can move on to the next section. But life is full of customizations, and we want to make yours as enjoyable as possible.&lt;/p&gt;
&lt;p&gt;There are multiple ways to dispatch actions to a specific &lt;code&gt;KeplerGl&lt;/code&gt; instance.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the root reducer, with reducer updaters.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each action is mapped to a reducer updater in kepler.gl. You can import the reducer updater corresponding to a specific action, and call it with the previous state and action payload to get the updated state.
e.g. &lt;code&gt;updateVisDataUpdater&lt;/code&gt; is the updater for &lt;code&gt;ActionTypes.UPDATE_VIS_DATA&lt;/code&gt; (take a look at each reducer &lt;code&gt;reducers/vis-state.js&lt;/code&gt; for action to updater mapping).
Here is an example how you can listen to an app action &lt;code&gt;QUERY_SUCCESS&lt;/code&gt; and call &lt;code&gt;updateVisDataUpdater&lt;/code&gt; to load data into Kepler.Gl.&lt;/p&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-smi"&gt;keplerGlReducer&lt;/span&gt;, {&lt;span class="pl-smi"&gt;visStateUpdaters&lt;/span&gt;} &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kepler.gl/reducers&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Root Reducer&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;reducers&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;combineReducers&lt;/span&gt;({
  keplerGl&lt;span class="pl-k"&gt;:&lt;/span&gt; keplerGlReducer,

  app&lt;span class="pl-k"&gt;:&lt;/span&gt; appReducer
});

&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;composedReducer&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; (&lt;span class="pl-smi"&gt;state&lt;/span&gt;, &lt;span class="pl-smi"&gt;action&lt;/span&gt;) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; {
  &lt;span class="pl-k"&gt;switch&lt;/span&gt; (&lt;span class="pl-smi"&gt;action&lt;/span&gt;.&lt;span class="pl-c1"&gt;type&lt;/span&gt;) {
    &lt;span class="pl-k"&gt;case&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;QUERY_SUCCESS&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;:
      &lt;span class="pl-k"&gt;return&lt;/span&gt; {
        &lt;span class="pl-k"&gt;...&lt;/span&gt;state,
        keplerGl&lt;span class="pl-k"&gt;:&lt;/span&gt; {
          &lt;span class="pl-k"&gt;...&lt;/span&gt;&lt;span class="pl-smi"&gt;state&lt;/span&gt;.&lt;span class="pl-smi"&gt;keplerGl&lt;/span&gt;,

          &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; 'map' is the id of the keplerGl instance&lt;/span&gt;
          map&lt;span class="pl-k"&gt;:&lt;/span&gt; {
            &lt;span class="pl-k"&gt;...&lt;/span&gt;&lt;span class="pl-smi"&gt;state&lt;/span&gt;.&lt;span class="pl-smi"&gt;keplerGl&lt;/span&gt;.&lt;span class="pl-smi"&gt;map&lt;/span&gt;,
            visState&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-smi"&gt;visStateUpdaters&lt;/span&gt;.&lt;span class="pl-en"&gt;updateVisDataUpdater&lt;/span&gt;(
              &lt;span class="pl-smi"&gt;state&lt;/span&gt;.&lt;span class="pl-smi"&gt;keplerGl&lt;/span&gt;.&lt;span class="pl-smi"&gt;map&lt;/span&gt;.&lt;span class="pl-smi"&gt;visState&lt;/span&gt;,
              {datasets&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-smi"&gt;action&lt;/span&gt;.&lt;span class="pl-smi"&gt;payload&lt;/span&gt;}
            )
          }
        }
      };
  }
  &lt;span class="pl-k"&gt;return&lt;/span&gt; &lt;span class="pl-en"&gt;reducers&lt;/span&gt;(state, action);
};

&lt;span class="pl-k"&gt;export&lt;/span&gt; &lt;span class="pl-c1"&gt;default&lt;/span&gt; &lt;span class="pl-smi"&gt;composedReducer&lt;/span&gt;;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Read more about &lt;a href="./docs/api-reference/advanced-usages/using-updaters.md"&gt;using updaters to modify kepler.gl state&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using redux &lt;code&gt;connect&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can add a dispatch function to your component that dispatches actions to a specific &lt;code&gt;keplerGl&lt;/code&gt; component,
using connect.&lt;/p&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; component&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-smi"&gt;KeplerGl&lt;/span&gt; &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kepler.gl&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; action and forward dispatcher&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; {&lt;span class="pl-smi"&gt;toggleFullScreen&lt;/span&gt;, &lt;span class="pl-smi"&gt;forwardTo&lt;/span&gt;} &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kepler.gl/actions&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;
&lt;span class="pl-k"&gt;import&lt;/span&gt; {&lt;span class="pl-smi"&gt;connect&lt;/span&gt;} &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;react-redux&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;MapContainer&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-smi"&gt;props&lt;/span&gt; &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; (
  &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;div&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;button onClick&lt;span class="pl-k"&gt;=&lt;/span&gt;{() &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-smi"&gt;props&lt;/span&gt;.&lt;span class="pl-en"&gt;keplerGlDispatch&lt;/span&gt;(&lt;span class="pl-en"&gt;toggleFullScreen&lt;/span&gt;())}&lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;KeplerGl
      id&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;foo&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
    &lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;&lt;span class="pl-k"&gt;/&lt;/span&gt;div&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
)

&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;mapStateToProps&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-smi"&gt;state&lt;/span&gt; &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; state
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;mapDispatchToProps&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; (&lt;span class="pl-smi"&gt;dispatch&lt;/span&gt;, &lt;span class="pl-smi"&gt;props&lt;/span&gt;) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; ({
 dispatch,
 keplerGlDispatch&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;forwardTo&lt;/span&gt;(â€˜fooâ€™, dispatch)
});

&lt;span class="pl-k"&gt;export&lt;/span&gt; &lt;span class="pl-c1"&gt;default&lt;/span&gt; &lt;span class="pl-smi"&gt;connect&lt;/span&gt;(
 mapStateToProps,
 mapDispatchToProps
)(MapContainer);&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Wrap action payload&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can also simply wrap an action into a forward action with the &lt;code&gt;wrapTo&lt;/code&gt; helper&lt;/p&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; component&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-smi"&gt;KeplerGl&lt;/span&gt; &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kepler.gl&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; action and forward dispatcher&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; {&lt;span class="pl-smi"&gt;toggleFullScreen&lt;/span&gt;, &lt;span class="pl-smi"&gt;wrapTo&lt;/span&gt;} &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kepler.gl/actions&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; create a function to wrapper action payload to 'foo'&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;wrapToMap&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;wrapTo&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;foo&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;MapContainer&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; ({dispatch}) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; (
  &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;div&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;button onClick&lt;span class="pl-k"&gt;=&lt;/span&gt;{() &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;dispatch&lt;/span&gt;(&lt;span class="pl-en"&gt;wrapToMap&lt;/span&gt;(&lt;span class="pl-en"&gt;toggleFullScreen&lt;/span&gt;())} &lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;KeplerGl
      id&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;foo&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
    &lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;&lt;span class="pl-k"&gt;/&lt;/span&gt;div&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Read more about &lt;a href="./docs/api-reference/advanced-usages/forward-actions.md"&gt;forward dispatching actions&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-4-customize-style" class="anchor" aria-hidden="true" href="#4-customize-style"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4. Customize style.&lt;/h3&gt;
&lt;p&gt;Kepler.gl implements css styling using &lt;a href="https://www.styled-components.com/" rel="nofollow"&gt;Styled-Components&lt;/a&gt;. By using said framework Kepler.gl offers the ability to customize its style/theme using the following approaches:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Passing a Theme prop&lt;/li&gt;
&lt;li&gt;Styled-Components ThemeProvider&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The available properties to customize are listed here &lt;a href="https://github.com/keplergl/kepler.gl/blob/master/src/styles/base.js"&gt;theme&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/keplergl/kepler.gl/tree/master/examples/custom-theme"&gt;Custom theme example&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-passing-a-theme-prop" class="anchor" aria-hidden="true" href="#passing-a-theme-prop"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Passing a Theme prop.&lt;/h4&gt;
&lt;p&gt;You can customize Kepler.gl theme by passing a &lt;strong&gt;theme&lt;/strong&gt; props to Kepler.gl react component as it follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;white&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;#ffffff&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;customTheme&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; {
  sidePanelBg&lt;span class="pl-k"&gt;:&lt;/span&gt; white,
  titleTextColor&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;#000000&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
  sidePanelHeaderBg&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;#f7f7F7&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
  subtextColorActive&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;#2473bd&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
};

&lt;span class="pl-k"&gt;return&lt;/span&gt; (
  &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;KeplerGl
    mapboxApiAccessToken&lt;span class="pl-k"&gt;=&lt;/span&gt;{&lt;span class="pl-c1"&gt;MAPBOX_TOKEN&lt;/span&gt;}
    id&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;map&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
    width&lt;span class="pl-k"&gt;=&lt;/span&gt;{&lt;span class="pl-c1"&gt;800&lt;/span&gt;}
    height&lt;span class="pl-k"&gt;=&lt;/span&gt;{&lt;span class="pl-c1"&gt;800&lt;/span&gt;}
    theme&lt;span class="pl-k"&gt;=&lt;/span&gt;{customTheme}
  &lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
);&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can see the customTheme object defines certain properties which will override Kepler.gl default style rules.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-styled-components-theme-provider" class="anchor" aria-hidden="true" href="#styled-components-theme-provider"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Styled-Components Theme Provider.&lt;/h4&gt;
&lt;p&gt;In order to customize Kepler.gl theme using &lt;a href="https://www.styled-components.com/docs/api#themeprovider" rel="nofollow"&gt;ThemeProvider&lt;/a&gt; you can simply wrap Kepler.gl using ThemeProvider as it follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; {&lt;span class="pl-smi"&gt;ThemeProvider&lt;/span&gt;} &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;styled-components&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;white&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;#ffffff&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;customTheme&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; {
  sidePanelBg&lt;span class="pl-k"&gt;:&lt;/span&gt; white,
  titleTextColor&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;#000000&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
  sidePanelHeaderBg&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;#f7f7F7&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
  subtextColorActive&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;#2473bd&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
};

&lt;span class="pl-k"&gt;return&lt;/span&gt; (
  &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;ThemeProvider theme&lt;span class="pl-k"&gt;=&lt;/span&gt;{customTheme}&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;KeplerGl
      mapboxApiAccessToken&lt;span class="pl-k"&gt;=&lt;/span&gt;{&lt;span class="pl-c1"&gt;MAPBOX_TOKEN&lt;/span&gt;}
      id&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;map&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
      width&lt;span class="pl-k"&gt;=&lt;/span&gt;{&lt;span class="pl-c1"&gt;800&lt;/span&gt;}
      height&lt;span class="pl-k"&gt;=&lt;/span&gt;{&lt;span class="pl-c1"&gt;800&lt;/span&gt;}
    &lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;&lt;span class="pl-k"&gt;/&lt;/span&gt;ThemeProvider&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
);&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-5-render-custom-ui-components" class="anchor" aria-hidden="true" href="#5-render-custom-ui-components"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;5. Render Custom UI components.&lt;/h3&gt;
&lt;p&gt;Everyone wants the flexibility to render custom kepler.gl components. Kepler.gl has a dependency injection system that allow you to inject
components to KeplerGl replacing existing ones. All you need to do is to create a component factory for the one you want to replace, import the original component factory
and call &lt;code&gt;injectComponents&lt;/code&gt; at the root component of your app where &lt;code&gt;KeplerGl&lt;/code&gt; is mounted.
Take a look at &lt;code&gt;examples/demo-app/src/app.js&lt;/code&gt; and see how it renders a custom side panel header in kepler.gl&lt;/p&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; {&lt;span class="pl-smi"&gt;injectComponents&lt;/span&gt;, &lt;span class="pl-smi"&gt;PanelHeaderFactory&lt;/span&gt;} &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kepler.gl/components&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; define custom header&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;CustomHeader&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; () &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;div&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;My &lt;span class="pl-smi"&gt;kepler&lt;/span&gt;.&lt;span class="pl-smi"&gt;gl&lt;/span&gt; app&lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;&lt;span class="pl-k"&gt;/&lt;/span&gt;div&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;myCustomHeaderFactory&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; () &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; CustomHeader;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Inject custom header into Kepler.gl, replacing default&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;KeplerGl&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;injectComponents&lt;/span&gt;([
  [PanelHeaderFactory, myCustomHeaderFactory]
]);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; render KeplerGl, it will render your custom header instead of the default&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;MapContainer&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; () &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; (
  &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;div&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;KeplerGl id&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;foo&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;&lt;span class="pl-k"&gt;/&lt;/span&gt;div&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
);&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Using &lt;code&gt;withState&lt;/code&gt; helper to add reducer state and actions to customized component as additional props.&lt;/p&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; {
  &lt;span class="pl-smi"&gt;withState&lt;/span&gt;,
  &lt;span class="pl-smi"&gt;injectComponents&lt;/span&gt;,
  &lt;span class="pl-smi"&gt;PanelHeaderFactory&lt;/span&gt;
} &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kepler.gl/components&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;
&lt;span class="pl-k"&gt;import&lt;/span&gt; {&lt;span class="pl-smi"&gt;visStateLens&lt;/span&gt;} &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kepler.gl/reducers&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; custom action wrap to mounted instance&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;addTodo&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-smi"&gt;text&lt;/span&gt; &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class="pl-en"&gt;wrapTo&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;map&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, {
    type&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ADD_TODO&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
    text
  });

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; define custom header&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;CustomHeader&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; ({visState, addTodo}) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; (
  &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;div onClick&lt;span class="pl-k"&gt;=&lt;/span&gt;{() &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;addTodo&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;hello&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)}&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;`&lt;/span&gt;&lt;span class="pl-s1"&gt;&lt;span class="pl-pse"&gt;${&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;span class="pl-s1"&gt;    &lt;span class="pl-c1"&gt;Object&lt;/span&gt;.&lt;span class="pl-c1"&gt;keys&lt;/span&gt;(&lt;span class="pl-smi"&gt;visState&lt;/span&gt;.&lt;span class="pl-smi"&gt;datasets&lt;/span&gt;).&lt;span class="pl-c1"&gt;length&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;span class="pl-s1"&gt;  &lt;span class="pl-pse"&gt;}&lt;/span&gt;&lt;/span&gt; dataset loaded&lt;span class="pl-pds"&gt;`&lt;/span&gt;&lt;/span&gt;}&lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;&lt;span class="pl-k"&gt;/&lt;/span&gt;div&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; now CustomHeader will receive `visState` and `addTodo` as additional props.&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;myCustomHeaderFactory&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; () &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class="pl-en"&gt;withState&lt;/span&gt;(
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; keplerGl state lenses&lt;/span&gt;
    [visStateLens],
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; customMapStateToProps&lt;/span&gt;
    headerStateToProps,
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; actions&lt;/span&gt;
    {addTodo}
  )(CustomHeader);&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Read more about &lt;a href="./docs/api-reference/advanced-usages/replace-ui-component.md"&gt;replacing UI component&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-6-how-to-add-data-to-map" class="anchor" aria-hidden="true" href="#6-how-to-add-data-to-map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;6. How to add data to map&lt;/h3&gt;
&lt;p&gt;To interact with a kepler.gl instance and add new data to it, you can dispatch the &lt;strong&gt;&lt;code&gt;addDataToMap&lt;/code&gt;&lt;/strong&gt; action from anywhere inside your app. It adds a dataset or multiple datasets to a kepler.gl instance and updates the full configuration (mapState, mapStyle, visState).&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-parameters" class="anchor" aria-hidden="true" href="#parameters"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Parameters&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;data&lt;/code&gt; &lt;strong&gt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object" rel="nofollow"&gt;Object&lt;/a&gt;&lt;/strong&gt; &lt;strong&gt;*required&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;datasets&lt;/code&gt; &lt;strong&gt;(&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array" rel="nofollow"&gt;Array&lt;/a&gt;&amp;lt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object" rel="nofollow"&gt;Object&lt;/a&gt;&amp;gt; | &lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object" rel="nofollow"&gt;Object&lt;/a&gt;)&lt;/strong&gt; &lt;strong&gt;*required&lt;/strong&gt; datasets can be a dataset or an array of datasets
Each dataset object needs to have &lt;code&gt;info&lt;/code&gt; and &lt;code&gt;data&lt;/code&gt; property.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;datasets.info&lt;/code&gt; &lt;strong&gt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object" rel="nofollow"&gt;Object&lt;/a&gt;&lt;/strong&gt; -info of a dataset
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;datasets.info.id&lt;/code&gt; &lt;strong&gt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String" rel="nofollow"&gt;string&lt;/a&gt;&lt;/strong&gt; id of this dataset. If config is defined, &lt;code&gt;id&lt;/code&gt; should matches the &lt;code&gt;dataId&lt;/code&gt; in config.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;datasets.info.label&lt;/code&gt; &lt;strong&gt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String" rel="nofollow"&gt;string&lt;/a&gt;&lt;/strong&gt; A display name of this dataset&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;datasets.data&lt;/code&gt; &lt;strong&gt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object" rel="nofollow"&gt;Object&lt;/a&gt;&lt;/strong&gt; &lt;strong&gt;*required&lt;/strong&gt; The data object, in a tabular format with 2 properties &lt;code&gt;fields&lt;/code&gt; and &lt;code&gt;rows&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;datasets.data.fields&lt;/code&gt; &lt;strong&gt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array" rel="nofollow"&gt;Array&lt;/a&gt;&amp;lt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object" rel="nofollow"&gt;Object&lt;/a&gt;&amp;gt;&lt;/strong&gt; &lt;strong&gt;*required&lt;/strong&gt; Array of fields,
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;datasets.data.fields.name&lt;/code&gt; &lt;strong&gt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String" rel="nofollow"&gt;string&lt;/a&gt;&lt;/strong&gt; &lt;strong&gt;*required&lt;/strong&gt; Name of the field,&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;datasets.data.rows&lt;/code&gt; &lt;strong&gt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array" rel="nofollow"&gt;Array&lt;/a&gt;&amp;lt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array" rel="nofollow"&gt;Array&lt;/a&gt;&amp;gt;&lt;/strong&gt; &lt;strong&gt;*required&lt;/strong&gt; Array of rows, in a tabular format with &lt;code&gt;fields&lt;/code&gt; and &lt;code&gt;rows&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;options&lt;/code&gt; &lt;strong&gt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object" rel="nofollow"&gt;Object&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;options.centerMap&lt;/code&gt; &lt;strong&gt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Boolean" rel="nofollow"&gt;boolean&lt;/a&gt;&lt;/strong&gt; &lt;code&gt;default: true&lt;/code&gt; if &lt;code&gt;centerMap&lt;/code&gt; is set to &lt;code&gt;true&lt;/code&gt; kepler.gl will place the map view within the data points boundaries&lt;/li&gt;
&lt;li&gt;&lt;code&gt;options.readOnly&lt;/code&gt; &lt;strong&gt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Boolean" rel="nofollow"&gt;boolean&lt;/a&gt;&lt;/strong&gt; &lt;code&gt;default: false&lt;/code&gt; if &lt;code&gt;readOnly&lt;/code&gt; is set to &lt;code&gt;true&lt;/code&gt;
the left setting panel will be hidden&lt;/li&gt;
&lt;li&gt;&lt;code&gt;options.keepExistingConfig&lt;/code&gt; &lt;strong&gt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Boolean" rel="nofollow"&gt;boolean&lt;/a&gt;&lt;/strong&gt; &lt;code&gt;default: false&lt;/code&gt; whether to keep exiting map config, including layers, filters and splitMaps.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;config&lt;/code&gt; &lt;strong&gt;&lt;a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object" rel="nofollow"&gt;Object&lt;/a&gt;&lt;/strong&gt; this object will contain the full kepler.gl instance configuration {mapState, mapStyle, visState}&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kepler.gl provides an easy API &lt;code&gt;KeplerGlSchema.getConfigToSave&lt;/code&gt; to generate a json blob of the current kepler instance configuration.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h4&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; app.js&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; {&lt;span class="pl-smi"&gt;addDataToMap&lt;/span&gt;} &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kepler.gl/actions&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;sampleTripData&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; {
  fields&lt;span class="pl-k"&gt;:&lt;/span&gt; [
    {name&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;tpep_pickup_datetime&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, format&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YYYY-M-D H:m:s&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, type&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;timestamp&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;},
    {name&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pickup_longitude&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, format&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, type&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;real&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;},
    {name&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pickup_latitude&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, format&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, type&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;real&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;}
  ],
  rows&lt;span class="pl-k"&gt;:&lt;/span&gt; [
    [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;2015-01-15 19:05:39 +00:00&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;73.99389648&lt;/span&gt;, &lt;span class="pl-c1"&gt;40.75011063&lt;/span&gt;],
    [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;2015-01-15 19:05:39 +00:00&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;73.97642517&lt;/span&gt;, &lt;span class="pl-c1"&gt;40.73981094&lt;/span&gt;],
    [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;2015-01-15 19:05:40 +00:00&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;73.96870422&lt;/span&gt;, &lt;span class="pl-c1"&gt;40.75424576&lt;/span&gt;]
  ]
};

&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;sampleConfig&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; {
  visState&lt;span class="pl-k"&gt;:&lt;/span&gt; {
    filters&lt;span class="pl-k"&gt;:&lt;/span&gt; [
      {
        id&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;me&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
        dataId&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;test_trip_data&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
        name&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;tpep_pickup_datetime&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
        type&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;timeRange&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
        enlarged&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-c1"&gt;true&lt;/span&gt;
      }
    ]
  }
};

&lt;span class="pl-c1"&gt;this&lt;/span&gt;.&lt;span class="pl-smi"&gt;props&lt;/span&gt;.&lt;span class="pl-en"&gt;dispatch&lt;/span&gt;(
  &lt;span class="pl-en"&gt;addDataToMap&lt;/span&gt;({
    datasets&lt;span class="pl-k"&gt;:&lt;/span&gt; {
      info&lt;span class="pl-k"&gt;:&lt;/span&gt; {
        label&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Sample Taxi Trips in New York City&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
        id&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;test_trip_data&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
      },
      data&lt;span class="pl-k"&gt;:&lt;/span&gt; sampleTripData
    },
    option&lt;span class="pl-k"&gt;:&lt;/span&gt; {
      centerMap&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-c1"&gt;true&lt;/span&gt;,
      readOnly&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-c1"&gt;false&lt;/span&gt;
    },
    config&lt;span class="pl-k"&gt;:&lt;/span&gt; sampleConfig
  })
);&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Read more about &lt;a href="./docs/api-reference/actions/actions.md#adddatatomap"&gt;addDataToMap&lt;/a&gt; and &lt;a href="./docs/api-reference/advanced-usages/saving-loading-w-schema.md"&gt;Saving and loading maps with schema manager&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>keplergl</author><guid isPermaLink="false">https://github.com/keplergl/kepler.gl</guid><pubDate>Tue, 04 Feb 2020 00:18:00 GMT</pubDate></item><item><title>rhiever/Data-Analysis-and-Machine-Learning-Projects #19 in Jupyter Notebook, This month</title><link>https://github.com/rhiever/Data-Analysis-and-Machine-Learning-Projects</link><description>&lt;p&gt;&lt;i&gt;Repository of teaching materials, code, and data for my data analysis and machine learning projects.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/352488c0cbba0e8f6da11ae0761444dd0c93489c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d322e372d626c75652e737667"&gt;&lt;img src="https://camo.githubusercontent.com/352488c0cbba0e8f6da11ae0761444dd0c93489c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d322e372d626c75652e737667" alt="Python 2.7" data-canonical-src="https://img.shields.io/badge/python-2.7-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/53aa0b9151bc545b404852175644228ee0efffe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e352d626c75652e737667"&gt;&lt;img src="https://camo.githubusercontent.com/53aa0b9151bc545b404852175644228ee0efffe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e352d626c75652e737667" alt="Python 3.5" data-canonical-src="https://img.shields.io/badge/python-3.5-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/f70ca4c3e8abab12b88528661ba3f6b0ec26952e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542532304c6963656e73652d626c75652e737667"&gt;&lt;img src="https://camo.githubusercontent.com/f70ca4c3e8abab12b88528661ba3f6b0ec26952e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542532304c6963656e73652d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/license-MIT%20License-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-randy-olsons-data-analysis-and-machine-learning-projects" class="anchor" aria-hidden="true" href="#randy-olsons-data-analysis-and-machine-learning-projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Randy Olson's data analysis and machine learning projects&lt;/h1&gt;
&lt;p&gt;Â© 2016-2018 Randal S. Olson&lt;/p&gt;
&lt;p&gt;This is a repository of teaching materials, code, and data for my data analysis and machine learning projects.&lt;/p&gt;
&lt;p&gt;Each repository will (usually) correspond to one of the blog posts on my &lt;a href="http://www.randalolson.com/blog/" rel="nofollow"&gt;web site&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Be sure to check the documentation (usually in IPython Notebook format) in the directory you're interested in for the notes on the analysis, data usage terms, etc.&lt;/p&gt;
&lt;p&gt;If you don't have the necessary software installed to run IPython Notebook, don't fret. You can use &lt;a href="http://nbviewer.ipython.org/" rel="nofollow"&gt;nbviewer&lt;/a&gt; to view a notebook on the web.&lt;/p&gt;
&lt;p&gt;For example, if you want to view the notebook in the &lt;code&gt;wheres-waldo-path-optimization&lt;/code&gt; directory, copy the &lt;a href="https://github.com/rhiever/Data-Analysis-and-Machine-Learning-Projects/blob/master/wheres-waldo-path-optimization/Where's%20Waldo%20path%20optimization.ipynb"&gt;full link&lt;/a&gt; to the notebook then paste it into &lt;a href="http://nbviewer.ipython.org/github/rhiever/Data-Analysis-and-Machine-Learning-Projects/blob/master/wheres-waldo-path-optimization/Where%27s%20Waldo%20path%20optimization.ipynb" rel="nofollow"&gt;nbviewer&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-instructional-material" class="anchor" aria-hidden="true" href="#instructional-material"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Instructional Material&lt;/h3&gt;
&lt;p&gt;All instructional material in this repository is made available under the &lt;a href="https://creativecommons.org/licenses/by/4.0/" rel="nofollow"&gt;Creative Commons Attribution license&lt;/a&gt;. The following is a human-readable summary of (and not a substitute for) the &lt;a href="https://creativecommons.org/licenses/by/4.0/legalcode" rel="nofollow"&gt;full legal text of the CC BY 4.0 license&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You are free to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Share&lt;/strong&gt;â€”copy and redistribute the material in any medium or format&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Adapt&lt;/strong&gt;â€”remix, transform, and build upon the material&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;for any purpose, even commercially.&lt;/p&gt;
&lt;p&gt;The licensor cannot revoke these freedoms as long as you follow the license terms.&lt;/p&gt;
&lt;p&gt;Under the following terms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Attribution&lt;/strong&gt;â€”You must give appropriate credit (mentioning that your work is derived from work that is Â© Randal S. Olson and, where practical, linking to &lt;a href="http://www.randalolson.com/" rel="nofollow"&gt;http://www.randalolson.com/&lt;/a&gt;), provide a &lt;a href="https://creativecommons.org/licenses/by/4.0/" rel="nofollow"&gt;link to the license&lt;/a&gt;, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;No additional restrictions&lt;/strong&gt;â€”You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Notices:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.&lt;/li&gt;
&lt;li&gt;No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-software" class="anchor" aria-hidden="true" href="#software"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Software&lt;/h3&gt;
&lt;p&gt;Except where otherwise noted, the example programs and other software provided in this repository are made available under the &lt;a href="http://opensource.org/" rel="nofollow"&gt;OSI&lt;/a&gt;-approved &lt;a href="http://opensource.org/licenses/mit-license.html" rel="nofollow"&gt;MIT license&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:&lt;/p&gt;
&lt;p&gt;The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.&lt;/p&gt;
&lt;p&gt;THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>rhiever</author><guid isPermaLink="false">https://github.com/rhiever/Data-Analysis-and-Machine-Learning-Projects</guid><pubDate>Tue, 04 Feb 2020 00:19:00 GMT</pubDate></item><item><title>udacity/deep-learning-v2-pytorch #20 in Jupyter Notebook, This month</title><link>https://github.com/udacity/deep-learning-v2-pytorch</link><description>&lt;p&gt;&lt;i&gt;Projects and exercises for the latest Deep Learning ND program https://www.udacity.com/course/deep-learning-nanodegree--nd101&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deep-learning-pytorch" class="anchor" aria-hidden="true" href="#deep-learning-pytorch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning (PyTorch)&lt;/h1&gt;
&lt;p&gt;This repository contains material related to Udacity's &lt;a href="https://www.udacity.com/course/deep-learning-nanodegree--nd101" rel="nofollow"&gt;Deep Learning Nanodegree program&lt;/a&gt;. It consists of a bunch of tutorial notebooks for various deep learning topics. In most cases, the notebooks lead you through implementing models such as convolutional networks, recurrent networks, and GANs. There are other topics covered such as weight initialization and batch normalization.&lt;/p&gt;
&lt;p&gt;There are also notebooks used as projects for the Nanodegree program. In the program itself, the projects are reviewed by real people (Udacity reviewers), but the starting code is available here, as well.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table Of Contents&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-tutorials" class="anchor" aria-hidden="true" href="#tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorials&lt;/h3&gt;
&lt;h3&gt;&lt;a id="user-content-introduction-to-neural-networks" class="anchor" aria-hidden="true" href="#introduction-to-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction to Neural Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-neural-networks"&gt;Introduction to Neural Networks&lt;/a&gt;: Learn how to implement gradient descent and apply it to predicting patterns in student admissions data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/sentiment-analysis-network"&gt;Sentiment Analysis with NumPy&lt;/a&gt;: &lt;a href="http://iamtrask.github.io/" rel="nofollow"&gt;Andrew Trask&lt;/a&gt; leads you through building a sentiment analysis model, predicting if some text is positive or negative.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-to-pytorch"&gt;Introduction to PyTorch&lt;/a&gt;: Learn how to build neural networks in PyTorch and use pre-trained networks for state-of-the-art image classifiers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-convolutional-neural-networks" class="anchor" aria-hidden="true" href="#convolutional-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Convolutional Neural Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/convolutional-neural-networks"&gt;Convolutional Neural Networks&lt;/a&gt;: Visualize the output of layers that make up a CNN. Learn how to define and train a CNN for classifying &lt;a href="https://en.wikipedia.org/wiki/MNIST_database" rel="nofollow"&gt;MNIST data&lt;/a&gt;, a handwritten digit database that is notorious in the fields of machine and deep learning. Also, define and train a CNN for classifying images in the &lt;a href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="nofollow"&gt;CIFAR10 dataset&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/transfer-learning"&gt;Transfer Learning&lt;/a&gt;. In practice, most people don't train their own networks on huge datasets; they use &lt;strong&gt;pre-trained&lt;/strong&gt; networks such as VGGnet. Here you'll use VGGnet to help classify images of flowers without training an end-to-end network from scratch.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/weight-initialization"&gt;Weight Initialization&lt;/a&gt;: Explore how initializing network weights affects performance.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/autoencoder"&gt;Autoencoders&lt;/a&gt;: Build models for image compression and de-noising, using feedforward and convolutional networks in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/style-transfer"&gt;Style Transfer&lt;/a&gt;: Extract style and content features from images, using a pre-trained network. Implement style transfer according to the paper, &lt;a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="nofollow"&gt;Image Style Transfer Using Convolutional Neural Networks&lt;/a&gt; by Gatys et. al. Define appropriate losses for iteratively creating a target, style-transferred image of your own design!&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-recurrent-neural-networks" class="anchor" aria-hidden="true" href="#recurrent-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Recurrent Neural Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/recurrent-neural-networks"&gt;Intro to Recurrent Networks (Time series &amp;amp; Character-level RNN)&lt;/a&gt;: Recurrent neural networks are able to use information about the sequence of data, such as the sequence of characters in text; learn how to implement these in PyTorch for a variety of tasks.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/word2vec-embeddings"&gt;Embeddings (Word2Vec)&lt;/a&gt;: Implement the Word2Vec model to find semantic representations of words for use in natural language processing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/sentiment-rnn"&gt;Sentiment Analysis RNN&lt;/a&gt;: Implement a recurrent neural network that can predict if the text of a moview review is positive or negative.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/attention"&gt;Attention&lt;/a&gt;: Implement attention and apply it to annotation vectors.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-generative-adversarial-networks" class="anchor" aria-hidden="true" href="#generative-adversarial-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generative Adversarial Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/gan-mnist"&gt;Generative Adversarial Network on MNIST&lt;/a&gt;: Train a simple generative adversarial network on the MNIST dataset.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/batch-norm"&gt;Batch Normalization&lt;/a&gt;: Learn how to improve training rates and network stability with batch normalizations.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/dcgan-svhn"&gt;Deep Convolutional GAN (DCGAN)&lt;/a&gt;: Implement a DCGAN to generate new images based on the Street View House Numbers (SVHN) dataset.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/cycle-gan"&gt;CycleGAN&lt;/a&gt;: Implement a CycleGAN that is designed to learn from unpaired and unlabeled data; use trained generators to transform images from summer to winter and vice versa.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-deploying-a-model-with-aws-sagemaker" class="anchor" aria-hidden="true" href="#deploying-a-model-with-aws-sagemaker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deploying a Model (with AWS SageMaker)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/sagemaker-deployment"&gt;All exercise and project notebooks&lt;/a&gt; for the lessons on model deployment can be found in the linked, Github repo. Learn to deploy pre-trained models using AWS SageMaker.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-projects" class="anchor" aria-hidden="true" href="#projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Projects&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-bikesharing"&gt;Predicting Bike-Sharing Patterns&lt;/a&gt;: Implement a neural network in NumPy to predict bike rentals.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-dog-classification"&gt;Dog Breed Classifier&lt;/a&gt;: Build a convolutional neural network with PyTorch to classify any image (even an image of a face) as a specific dog breed.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-tv-script-generation"&gt;TV Script Generation&lt;/a&gt;: Train a recurrent neural network to generate scripts in the style of dialogue from Seinfeld.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-face-generation"&gt;Face Generation&lt;/a&gt;: Use a DCGAN on the CelebA dataset to generate images of new and realistic human faces.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-elective-material" class="anchor" aria-hidden="true" href="#elective-material"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Elective Material&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/tensorflow/intro-to-tensorflow"&gt;Intro to TensorFlow&lt;/a&gt;: Starting building neural networks with TensorFlow.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/keras"&gt;Keras&lt;/a&gt;: Learn to build neural networks and convolutional neural networks with Keras.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-configure-and-manage-your-environment-with-anaconda" class="anchor" aria-hidden="true" href="#configure-and-manage-your-environment-with-anaconda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configure and Manage Your Environment with Anaconda&lt;/h2&gt;
&lt;p&gt;Per the Anaconda &lt;a href="http://conda.pydata.org/docs" rel="nofollow"&gt;docs&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Conda is an open source package management system and environment management system
for installing multiple versions of software packages and their dependencies and
switching easily between them. It works on Linux, OS X and Windows, and was created
for Python programs but can package and distribute any software.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overview&lt;/h2&gt;
&lt;p&gt;Using Anaconda consists of the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install &lt;a href="http://conda.pydata.org/miniconda.html" rel="nofollow"&gt;&lt;code&gt;miniconda&lt;/code&gt;&lt;/a&gt; on your computer, by selecting the latest Python version for your operating system. If you already have &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;miniconda&lt;/code&gt; installed, you should be able to skip this step and move on to step 2.&lt;/li&gt;
&lt;li&gt;Create and activate * a new &lt;code&gt;conda&lt;/code&gt; &lt;a href="http://conda.pydata.org/docs/using/envs.html" rel="nofollow"&gt;environment&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;* Each time you wish to work on any exercises, activate your &lt;code&gt;conda&lt;/code&gt; environment!&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-1-installation" class="anchor" aria-hidden="true" href="#1-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Installation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Download&lt;/strong&gt; the latest version of &lt;code&gt;miniconda&lt;/code&gt; that matches your system.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Linux&lt;/th&gt;
&lt;th&gt;Mac&lt;/th&gt;
&lt;th&gt;Windows&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;64-bit&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh" rel="nofollow"&gt;64-bit (bash installer)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-MacOSX-x86_64.sh" rel="nofollow"&gt;64-bit (bash installer)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-Windows-x86_64.exe" rel="nofollow"&gt;64-bit (exe installer)&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;32-bit&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86.sh" rel="nofollow"&gt;32-bit (bash installer)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-Windows-x86.exe" rel="nofollow"&gt;32-bit (exe installer)&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Install&lt;/strong&gt; &lt;a href="http://conda.pydata.org/miniconda.html" rel="nofollow"&gt;miniconda&lt;/a&gt; on your machine. Detailed instructions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Linux:&lt;/strong&gt; &lt;a href="http://conda.pydata.org/docs/install/quick.html#linux-miniconda-install" rel="nofollow"&gt;http://conda.pydata.org/docs/install/quick.html#linux-miniconda-install&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mac:&lt;/strong&gt; &lt;a href="http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install" rel="nofollow"&gt;http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Windows:&lt;/strong&gt; &lt;a href="http://conda.pydata.org/docs/install/quick.html#windows-miniconda-install" rel="nofollow"&gt;http://conda.pydata.org/docs/install/quick.html#windows-miniconda-install&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-2-create-and-activate-the-environment" class="anchor" aria-hidden="true" href="#2-create-and-activate-the-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Create and Activate the Environment&lt;/h2&gt;
&lt;p&gt;For Windows users, these following commands need to be executed from the &lt;strong&gt;Anaconda prompt&lt;/strong&gt; as opposed to a Windows terminal window. For Mac, a normal terminal window will work.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-git-and-version-control" class="anchor" aria-hidden="true" href="#git-and-version-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Git and version control&lt;/h4&gt;
&lt;p&gt;These instructions also assume you have &lt;code&gt;git&lt;/code&gt; installed for working with Github from a terminal window, but if you do not, you can download that first with the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you'd like to learn more about version control and using &lt;code&gt;git&lt;/code&gt; from the command line, take a look at our &lt;a href="https://www.udacity.com/course/version-control-with-git--ud123" rel="nofollow"&gt;free course: Version Control with Git&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Now, we're ready to create our local environment!&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Clone the repository, and navigate to the downloaded folder. This may take a minute or two to clone due to the included image data.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/udacity/deep-learning-v2-pytorch.git
cd deep-learning-v2-pytorch
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;
&lt;p&gt;Create (and activate) a new environment, named &lt;code&gt;deep-learning&lt;/code&gt; with Python 3.6. If prompted to proceed with the install &lt;code&gt;(Proceed [y]/n)&lt;/code&gt; type y.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt; or &lt;strong&gt;Mac&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;conda create -n deep-learning python=3.6
source activate deep-learning
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;conda create --name deep-learning python=3.6
activate deep-learning
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point your command line should look something like: &lt;code&gt;(deep-learning) &amp;lt;User&amp;gt;:deep-learning-v2-pytorch &amp;lt;user&amp;gt;$&lt;/code&gt;. The &lt;code&gt;(deep-learning)&lt;/code&gt; indicates that your environment has been activated, and you can proceed with further package installations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install PyTorch and torchvision; this should install the latest version of PyTorch.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt; or &lt;strong&gt;Mac&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;conda install pytorch torchvision -c pytorch 
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;conda install pytorch -c pytorch
pip install torchvision
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install a few required pip packages, which are specified in the requirements text file (including OpenCV).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="7"&gt;
&lt;li&gt;That's it!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now most of the &lt;code&gt;deep-learning&lt;/code&gt; libraries are available to you. Very occasionally, you will see a repository with an addition requirements file, which exists should you want to use TensorFlow and Keras, for example. In this case, you're encouraged to install another library to your existing environment, or create a new environment for a specific project.&lt;/p&gt;
&lt;p&gt;Now, assuming your &lt;code&gt;deep-learning&lt;/code&gt; environment is still activated, you can navigate to the main repo and start looking at the notebooks:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd
cd deep-learning-v2-pytorch
jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To exit the environment when you have completed your work session, simply close the terminal window.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>udacity</author><guid isPermaLink="false">https://github.com/udacity/deep-learning-v2-pytorch</guid><pubDate>Tue, 04 Feb 2020 00:20:00 GMT</pubDate></item><item><title>mml-book/mml-book.github.io #21 in Jupyter Notebook, This month</title><link>https://github.com/mml-book/mml-book.github.io</link><description>&lt;p&gt;&lt;i&gt;Companion webpage to the book "Mathematics For Machine Learning"&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-mml-bookgithubio" class="anchor" aria-hidden="true" href="#mml-bookgithubio"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;mml-book.github.io&lt;/h1&gt;
&lt;p&gt;Companion webpage to the book "Mathematics For Machine Learning"&lt;/p&gt;
&lt;p&gt;&lt;a href="https://mml-book.com" rel="nofollow"&gt;https://mml-book.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Copyright 2020 by Marc Peter Deisenroth, A Aldo Faisal, and Cheng Soon Ong. To be published by Cambridge University Press.&lt;/p&gt;
&lt;p&gt;We are in the process of writing a book on Mathematics for Machine Learning that motivates people to learn mathematical concepts. The book is not intended to cover advanced machine learning techniques because there are already plenty of books doing this. Instead, we aim to provide the necessary mathematical skills to read those other books.&lt;/p&gt;
&lt;p&gt;We split the book into two parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mathematical foundations&lt;/li&gt;
&lt;li&gt;Example machine learning algorithms that use the mathematical foundations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We aim to keep this book reasonably short, so we cannot cover everything. We will also provide exercises for part 1 and jupyter notebooks for part 2 of the book.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>mml-book</author><guid isPermaLink="false">https://github.com/mml-book/mml-book.github.io</guid><pubDate>Tue, 04 Feb 2020 00:21:00 GMT</pubDate></item><item><title>fengdu78/Data-Science-Notes #22 in Jupyter Notebook, This month</title><link>https://github.com/fengdu78/Data-Science-Notes</link><description>&lt;p&gt;&lt;i&gt;æ•°æ®ç§‘å­¦çš„ç¬”è®°ä»¥åŠèµ„æ–™æœé›†&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-data-science-notes" class="anchor" aria-hidden="true" href="#data-science-notes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data-Science-Notes&lt;/h1&gt;
&lt;p&gt;æ•°æ®ç§‘å­¦çš„ç¬”è®°ä»¥åŠèµ„æ–™æœé›†ï¼Œç›®å‰å°šåœ¨æ›´æ–°ï¼Œéƒ¨åˆ†å†…å®¹æ¥æºäºŽgithubæœé›†ã€‚&lt;/p&gt;
&lt;p&gt;&lt;a href="0.math"&gt;0.math&lt;/a&gt; ï¼ˆæ•°å­¦åŸºç¡€ï¼‰&lt;/p&gt;
&lt;p&gt;&lt;a href="1.python-basic"&gt;1.python-basic&lt;/a&gt; ï¼ˆpythonåŸºç¡€ï¼‰&lt;/p&gt;
&lt;p&gt;&lt;a href="2.numpy"&gt;2.numpy&lt;/a&gt;ï¼ˆnumpyåŸºç¡€ï¼‰&lt;/p&gt;
&lt;p&gt;&lt;a href="3.pandas"&gt;3.pandas&lt;/a&gt;ï¼ˆpandasåŸºç¡€ï¼‰&lt;/p&gt;
&lt;p&gt;&lt;a href="4.scipy"&gt;4.scipy&lt;/a&gt;ï¼ˆscipyåŸºç¡€ï¼‰&lt;/p&gt;
&lt;p&gt;&lt;a href="5.data-visualization"&gt;5.data-visualization&lt;/a&gt;ï¼ˆæ•°æ®å¯è§†åŒ–åŸºç¡€ï¼ŒåŒ…å«matplotlibå’Œseabornï¼‰&lt;/p&gt;
&lt;p&gt;&lt;a href="6.scikit-learn"&gt;6.scikit-learn&lt;/a&gt;ï¼ˆscikit-learnåŸºç¡€ï¼‰&lt;/p&gt;
&lt;p&gt;&lt;a href="7.machine-learning"&gt;7.machine-learning&lt;/a&gt;ï¼ˆæœºå™¨å­¦ä¹ åŸºç¡€ï¼‰&lt;/p&gt;
&lt;p&gt;&lt;a href="8.deep-learning"&gt;8.deep-learning&lt;/a&gt;ï¼ˆæ·±åº¦å­¦ä¹ åŸºç¡€ï¼‰&lt;/p&gt;
&lt;p&gt;&lt;a href="9.feature-engineering"&gt;9.feature-engineering&lt;/a&gt;ï¼ˆç‰¹å¾å·¥ç¨‹åŸºç¡€ï¼‰&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-å‚è€ƒ" class="anchor" aria-hidden="true" href="#å‚è€ƒ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å‚è€ƒ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹æŽèˆª&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/data-science-ipython-notebooks"&gt;https://github.com/donnemartin/data-science-ipython-notebooks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apachecn/feature-engineering-for-ml-zh"&gt;https://github.com/apachecn/feature-engineering-for-ml-zh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/pumpkin-book"&gt;https://github.com/datawhalechina/pumpkin-book&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Doraemonzzz/Learning-from-data"&gt;https://github.com/Doraemonzzz/Learning-from-data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wzyonggege/statistical-learning-method"&gt;https://github.com/wzyonggege/statistical-learning-method&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/WenDesi/lihang_book_algorithm"&gt;https://github.com/WenDesi/lihang_book_algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/course/ml" rel="nofollow"&gt;https://www.coursera.org/course/ml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mooc.guokr.com/note/12/" rel="nofollow"&gt;https://mooc.guokr.com/note/12/&lt;/a&gt; &lt;a href="https://mooc.guokr.com/user/2133483357/" rel="nofollow"&gt;å°å°äºº_V&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ã€Špythonç§‘å­¦è®¡ç®—ã€‹&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-å…³äºŽä½œè€…" class="anchor" aria-hidden="true" href="#å…³äºŽä½œè€…"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å…³äºŽä½œè€…&lt;/h2&gt;
&lt;p&gt;å¾®ä¿¡å…¬ä¼—å·ï¼šæœºå™¨å­¦ä¹ åˆå­¦è€… &lt;a target="_blank" rel="noopener noreferrer" href="images/gongzhong.jpg"&gt;&lt;img src="images/gongzhong.jpg" alt="gongzhong" style="max-width:100%;"&gt;&lt;/a&gt;
çŸ¥è¯†æ˜Ÿçƒï¼šé»„åšçš„æœºå™¨å­¦ä¹ åœˆå­&lt;a target="_blank" rel="noopener noreferrer" href="images/zhishixingqiu1.jpg"&gt;&lt;img src="images/zhishixingqiu1.jpg" alt="xingqiu" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.zhihu.com/people/fengdu78/activities" rel="nofollow"&gt;æˆ‘çš„çŸ¥ä¹Ž&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ³¨æ„ï¼šgithubä¸‹è½½å¤ªæ…¢çš„è¯ï¼Œå…³æ³¨æˆ‘çš„å…¬ä¼—å·ï¼šâ€œæœºå™¨å­¦ä¹ åˆå­¦è€…â€ï¼Œå›žå¤â€œå­¦ä¹ è·¯çº¿â€å³å¯ä¸‹è½½æœ¬ä»“åº“çš„é•œåƒæ–‡ä»¶ï¼Œæ•´ä¸ªä»“åº“åŽ‹ç¼©æˆä¸€ä¸ªisoã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;å¦‚æžœéœ€è¦å¼•ç”¨è¿™ä¸ªRepo:&lt;/p&gt;
&lt;p&gt;æ ¼å¼ï¼š &lt;code&gt;fengdu78, Data-Science-Notes, (2019), GitHub repository, https://github.com/fengdu78/Data-Science-Notes&lt;/code&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fengdu78</author><guid isPermaLink="false">https://github.com/fengdu78/Data-Science-Notes</guid><pubDate>Tue, 04 Feb 2020 00:22:00 GMT</pubDate></item><item><title>awslabs/amazon-sagemaker-examples #23 in Jupyter Notebook, This month</title><link>https://github.com/awslabs/amazon-sagemaker-examples</link><description>&lt;p&gt;&lt;i&gt;Example notebooks that show how to apply machine learning, deep learning and reinforcement learning in Amazon SageMaker&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-amazon-sagemaker-examples" class="anchor" aria-hidden="true" href="#amazon-sagemaker-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Amazon SageMaker Examples&lt;/h1&gt;
&lt;p&gt;This repository contains example notebooks that show how to apply machine learning and deep learning in &lt;a href="https://aws.amazon.com/sagemaker" rel="nofollow"&gt;Amazon SageMaker&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-introduction-to-ground-truth-labeling-jobs" class="anchor" aria-hidden="true" href="#introduction-to-ground-truth-labeling-jobs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction to Ground Truth Labeling Jobs&lt;/h3&gt;
&lt;p&gt;These examples provide quick walkthroughs to get you up and running with the labeling job workflow for Amazon SageMaker Ground Truth.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="ground_truth_labeling_jobs/from_unlabeled_data_to_deployed_machine_learning_model_ground_truth_demo_image_classification"&gt;From Unlabeled Data to a Deployed Machine Learning Model: A SageMaker Ground Truth Demonstration for Image Classification&lt;/a&gt; is an end-to-end example that starts with an unlabeled dataset, labels it using the Ground Truth API, analyzes the results, trains an image classification neural net using the annotated dataset, and finally uses the trained model to perform batch and online inference.&lt;/li&gt;
&lt;li&gt;&lt;a href="ground_truth_labeling_jobs/ground_truth_object_detection_tutorial"&gt;Ground Truth Object Detection Tutorial&lt;/a&gt; is a similar end-to-end example but for an object detection task.&lt;/li&gt;
&lt;li&gt;&lt;a href="ground_truth_labeling_jobs/data_analysis_of_ground_truth_image_classification_output"&gt;Basic Data Analysis of an Image Classification Output Manifest&lt;/a&gt; presents charts to visualize the number of annotations for each class, differentiating between human annotations and automatic labels (if your job used auto-labeling). It also displays sample images in each class, and creates a pdf which concisely displays the full results.&lt;/li&gt;
&lt;li&gt;&lt;a href="ground_truth_labeling_jobs/object_detection_augmented_manifest_training"&gt;Training a Machine Learning Model Using an Output Manifest&lt;/a&gt; introduces the concept of an "augmented manifest" and demonstrates that the output file of a labeling job can be immediately used as the input file to train a SageMaker machine learning model.&lt;/li&gt;
&lt;li&gt;&lt;a href="ground_truth_labeling_jobs/annotation_consolidation"&gt;Annotation Consolidation&lt;/a&gt; demonstrates Amazon SageMaker Ground Truth annotation consolidation techniques for image classification for a completed labeling job.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-introduction-to-applying-machine-learning" class="anchor" aria-hidden="true" href="#introduction-to-applying-machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction to Applying Machine Learning&lt;/h3&gt;
&lt;p&gt;These examples provide a gentle introduction to machine learning concepts as they are applied in practical use cases across a variety of sectors.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="introduction_to_applying_machine_learning/xgboost_direct_marketing"&gt;Targeted Direct Marketing&lt;/a&gt; predicts potential customers that are most likely to convert based on customer and aggregate level metrics, using Amazon SageMaker's implementation of &lt;a href="https://github.com/dmlc/xgboost"&gt;XGBoost&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_applying_machine_learning/xgboost_customer_churn"&gt;Predicting Customer Churn&lt;/a&gt; uses customer interaction and service usage data to find those most likely to churn, and then walks through the cost/benefit trade-offs of providing retention incentives.  This uses Amazon SageMaker's implementation of &lt;a href="https://github.com/dmlc/xgboost"&gt;XGBoost&lt;/a&gt; to create a highly predictive model.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_applying_machine_learning/linear_time_series_forecast"&gt;Time-series Forecasting&lt;/a&gt; generates a forecast for topline product demand using Amazon SageMaker's Linear Learner algorithm.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_applying_machine_learning/breast_cancer_prediction"&gt;Cancer Prediction&lt;/a&gt; predicts Breast Cancer based on features derived from images, using SageMaker's Linear Learner.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_applying_machine_learning/ensemble_modeling"&gt;Ensembling&lt;/a&gt; predicts income using two Amazon SageMaker models to show the advantages in ensembling.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_applying_machine_learning/video_game_sales"&gt;Video Game Sales&lt;/a&gt; develops a binary prediction model for the success of video games based on review scores.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_applying_machine_learning/gluon_recommender_system"&gt;MXNet Gluon Recommender System&lt;/a&gt; uses neural network embeddings for non-linear matrix factorization to predict user movie ratings on Amazon digital reviews.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_applying_machine_learning/fair_linear_learner"&gt;Fair Linear Learner&lt;/a&gt; is an example of an effective way to create fair linear models with respect to sensitive features.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_applying_machine_learning/US-census_population_segmentation_PCA_Kmeans"&gt;Population Segmentation of US Census Data using PCA and Kmeans&lt;/a&gt; analyzes US census data and reduces dimensionality using PCA then clusters US counties using KMeans to identify segments of similar counties.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_applying_machine_learning/object2vec_document_embedding"&gt;Document Embedding using Object2Vec&lt;/a&gt; is an example to embed a large collection of documents in a common low-dimensional space, so that the semantic distances between these documents are preserved.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sagemaker-automatic-model-tuning" class="anchor" aria-hidden="true" href="#sagemaker-automatic-model-tuning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SageMaker Automatic Model Tuning&lt;/h3&gt;
&lt;p&gt;These examples introduce SageMaker's hyperparameter tuning functionality which helps deliver the best possible predictions by running a large number of training jobs to determine which hyperparameter values are the most impactful.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="hyperparameter_tuning/xgboost_direct_marketing"&gt;XGBoost Tuning&lt;/a&gt; shows how to use SageMaker hyperparameter tuning to improve your model fits for the &lt;a href="introduction_to_applying_machine_learning/xgboost_direct_marketing"&gt;Targeted Direct Marketing&lt;/a&gt; task.&lt;/li&gt;
&lt;li&gt;&lt;a href="hyperparameter_tuning/tensorflow_mnist"&gt;TensorFlow Tuning&lt;/a&gt; shows how to use SageMaker hyperparameter tuning with the pre-built TensorFlow container and MNIST dataset.&lt;/li&gt;
&lt;li&gt;&lt;a href="hyperparameter_tuning/mxnet_mnist"&gt;MXNet Tuning&lt;/a&gt; shows how to use SageMaker hyperparameter tuning with the pre-built MXNet container and MNIST dataset.&lt;/li&gt;
&lt;li&gt;&lt;a href="hyperparameter_tuning/keras_bring_your_own"&gt;Keras BYO Tuning&lt;/a&gt; shows how to use SageMaker hyperparameter tuning with a custom container running a Keras convolutional network on CIFAR-10 data.&lt;/li&gt;
&lt;li&gt;&lt;a href="hyperparameter_tuning/r_bring_your_own"&gt;R BYO Tuning&lt;/a&gt; shows how to use SageMaker hyperparameter tuning with the custom container from the &lt;a href="advanced_functionality/r_bring_your_own"&gt;Bring Your Own R Algorithm&lt;/a&gt; example.&lt;/li&gt;
&lt;li&gt;&lt;a href="hyperparameter_tuning/analyze_results"&gt;Analyzing Results&lt;/a&gt; is a shared notebook that can be used after each of the above notebooks to provide analysis on how training jobs with different hyperparameters performed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-introduction-to-amazon-algorithms" class="anchor" aria-hidden="true" href="#introduction-to-amazon-algorithms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction to Amazon Algorithms&lt;/h3&gt;
&lt;p&gt;These examples provide quick walkthroughs to get you up and running with Amazon SageMaker's custom developed algorithms.  Most of these algorithms can train on distributed hardware, scale incredibly well, and are faster and cheaper than popular alternatives.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/1P_kmeans_highlevel"&gt;k-means&lt;/a&gt; is our introductory example for Amazon SageMaker.  It walks through the process of clustering MNIST images of handwritten digits using Amazon SageMaker k-means.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/factorization_machines_mnist"&gt;Factorization Machines&lt;/a&gt; showcases Amazon SageMaker's implementation of the algorithm to predict whether a handwritten digit from the MNIST dataset is a 0 or not using a binary classifier.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/lda_topic_modeling"&gt;Latent Dirichlet Allocation (LDA)&lt;/a&gt; introduces topic modeling using Amazon SageMaker Latent Dirichlet Allocation (LDA) on a synthetic dataset.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/linear_learner_mnist"&gt;Linear Learner&lt;/a&gt; predicts whether a handwritten digit from the MNIST dataset is a 0 or not using a binary classifier from Amazon SageMaker Linear Learner.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/ntm_synthetic"&gt;Neural Topic Model (NTM)&lt;/a&gt; uses Amazon SageMaker Neural Topic Model (NTM) to uncover topics in documents from a synthetic data source, where topic distributions are known.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/pca_mnist"&gt;Principal Components Analysis (PCA)&lt;/a&gt; uses Amazon SageMaker PCA to calculate eigendigits from MNIST.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/seq2seq_translation_en-de"&gt;Seq2Seq&lt;/a&gt; uses the Amazon SageMaker Seq2Seq algorithm that's built on top of &lt;a href="https://github.com/awslabs/sockeye"&gt;Sockeye&lt;/a&gt;, which is a sequence-to-sequence framework for Neural Machine Translation based on MXNet.  Seq2Seq implements state-of-the-art encoder-decoder architectures which can also be used for tasks like Abstractive Summarization in addition to Machine Translation.  This notebook shows translation from English to German text.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/imageclassification_caltech"&gt;Image Classification&lt;/a&gt; includes full training and transfer learning examples of Amazon SageMaker's Image Classification algorithm.  This uses a ResNet deep convolutional neural network to classify images from the caltech dataset.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/xgboost_abalone"&gt;XGBoost for regression&lt;/a&gt; predicts the age of abalone (&lt;a href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html" rel="nofollow"&gt;Abalone dataset&lt;/a&gt;) using regression from Amazon SageMaker's implementation of &lt;a href="https://github.com/dmlc/xgboost"&gt;XGBoost&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/xgboost_mnist"&gt;XGBoost for multi-class classification&lt;/a&gt; uses Amazon SageMaker's implementation of &lt;a href="https://github.com/dmlc/xgboost"&gt;XGBoost&lt;/a&gt; to classify handwritten digits from the MNIST dataset as one of the ten digits using a multi-class classifier. Both single machine and distributed use-cases are presented.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/deepar_synthetic"&gt;DeepAR for time series forecasting&lt;/a&gt; illustrates how to use the Amazon SageMaker DeepAR algorithm for time series forecasting on a synthetically generated data set.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/blazingtext_word2vec_text8"&gt;BlazingText Word2Vec&lt;/a&gt; generates Word2Vec embeddings from a cleaned text dump of Wikipedia articles using SageMaker's fast and scalable BlazingText implementation.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/object_detection_pascalvoc_coco"&gt;Object Detection&lt;/a&gt; illustrates how to train an object detector using the Amazon SageMaker Object Detection algorithm with different input formats (RecordIO and image).  It uses the Pascal VOC dataset. A third notebook is provided to demonstrate the use of incremental training.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/object_detection_birds"&gt;Object detection for bird images&lt;/a&gt; demonstrates how to use the Amazon SageMaker Object Detection algorithm with a public dataset of Bird images.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/object2vec_movie_recommendation"&gt;Object2Vec for movie recommendation&lt;/a&gt; demonstrates how Object2Vec can be used to model data consisting of pairs of singleton tokens using movie recommendation as a running example.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/object2vec_multilabel_genre_classification"&gt;Object2Vec for multi-label classification&lt;/a&gt; shows how ObjectToVec algorithm can train on data consisting of pairs of sequences and singleton tokens using the setting of genre prediction of movies based on their plot descriptions.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/object2vec_sentence_similarity"&gt;Object2Vec for sentence similarity&lt;/a&gt; explains how to train Object2Vec using sequence pairs as input using sentence similarity analysis as the application.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/ipinsights_login"&gt;IP Insights for suspicious logins&lt;/a&gt; shows how to train IP Insights on a login events for a web server to identify suspicious login attempts.&lt;/li&gt;
&lt;li&gt;&lt;a href="introduction_to_amazon_algorithms/semantic_segmentation_pascalvoc"&gt;Semantic Segmentation&lt;/a&gt; shows how to train a semantic segmentation algorithm using the Amazon SageMaker Semantic Segmentation algorithm. It also demonstrates how to host the model and produce segmentaion masks and probability of segmentation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-amazon-sagemaker-rl" class="anchor" aria-hidden="true" href="#amazon-sagemaker-rl"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Amazon SageMaker RL&lt;/h3&gt;
&lt;p&gt;The following provide examples demonstrating different capabilities of Amazon SageMaker RL.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="reinforcement_learning/rl_cartpole_coach"&gt;Cartpole using Coach&lt;/a&gt; demonstrates the simplest usecase of Amazon SageMaker RL using Intel's RL Coach.&lt;/li&gt;
&lt;li&gt;&lt;a href="reinforcement_learning/rl_deepracer_robomaker_coach_gazebo"&gt;AWS DeepRacer&lt;/a&gt; demonstrates AWS DeepRacer trainig using RL Coach in the Gazebo environment.&lt;/li&gt;
&lt;li&gt;&lt;a href="reinforcement_learning/rl_hvac_coach_energyplus"&gt;HVAC using EnergyPlus&lt;/a&gt; demonstrates the training of HVAC systems using the EnergyPlus environment.&lt;/li&gt;
&lt;li&gt;&lt;a href="reinforcement_learning/rl_knapsack_coach_custom"&gt;Knapsack Problem&lt;/a&gt; demonstrates how to solve the knapsack problem using a custom environment.&lt;/li&gt;
&lt;li&gt;&lt;a href="reinforcement_learning/rl_mountain_car_coach_gymEnv"&gt;Mountain Car&lt;/a&gt; Mountain car is a classic RL problem. This notebook explains how to solve this using the OpenAI Gym environment.&lt;/li&gt;
&lt;li&gt;&lt;a href="reinforcement_learning/rl_network_compression_ray_custom"&gt;Distributed Neural Network Compression&lt;/a&gt; This notebook explains how to compress ResNets using RL, using a custom environment and the RLLib toolkit.&lt;/li&gt;
&lt;li&gt;&lt;a href="reinforcement_learning/rl_objecttracker_robomaker_coach_gazebo"&gt;Turtlebot Tracker&lt;/a&gt; This notebook demonstrates object tracking using AWS Robomaker and RL Coach in the Gazebo environment.&lt;/li&gt;
&lt;li&gt;&lt;a href="reinforcement_learning/rl_portfolio_management_coach_customEnv"&gt;Portfolio Management&lt;/a&gt; This notebook uses a custom Gym environment to manage multiple financial investments.&lt;/li&gt;
&lt;li&gt;&lt;a href="reinforcement_learning/rl_predictive_autoscaling_coach_customEnv"&gt;Autoscaling&lt;/a&gt; demonstrates how to adjust load depending on demand. This uses RL Coach and a custom environment.&lt;/li&gt;
&lt;li&gt;&lt;a href="reinforcement_learning/rl_roboschool_ray"&gt;Roboschool&lt;/a&gt; is an open source physics simulator that is commonly used to train RL policies for robotic systems. This notebook demonstrates training a few agents using it.&lt;/li&gt;
&lt;li&gt;&lt;a href="reinforcement_learning/rl_roboschool_stable_baselines"&gt;Stable Baselines&lt;/a&gt; In this notebook example, we will make the HalfCheetah agent learn to walk using the stable-baselines, which are a set of improved implementations of Reinforcement Learning (RL) algorithms based on OpenAI Baselines.&lt;/li&gt;
&lt;li&gt;&lt;a href="reinforcement_learning/rl_traveling_salesman_vehicle_routing_coach"&gt;Travelling Salesman&lt;/a&gt; is a classic NP hard problem, which this notebook solves with AWS SageMaker RL.&lt;/li&gt;
&lt;li&gt;&lt;a href="reinforcement_learning/rl_tic_tac_toe_coach_customEnv"&gt;Tic-tac-toe&lt;/a&gt; is a simple implementation of a custom Gym environment to train and deploy an RL agent in Coach that then plays tic-tac-toe interactively in a Jupyter Notebook.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-scientific-details-of-algorithms" class="anchor" aria-hidden="true" href="#scientific-details-of-algorithms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Scientific Details of Algorithms&lt;/h3&gt;
&lt;p&gt;These examples provide more thorough mathematical treatment on a select group of algorithms.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="scientific_details_of_algorithms/streaming_median"&gt;Streaming Median&lt;/a&gt; sequentially introduces concepts used in streaming algorithms, which many SageMaker algorithms rely on to deliver speed and scalability.&lt;/li&gt;
&lt;li&gt;&lt;a href="scientific_details_of_algorithms/lda_topic_modeling"&gt;Latent Dirichlet Allocation (LDA)&lt;/a&gt; dives into Amazon SageMaker's spectral decomposition approach to LDA.&lt;/li&gt;
&lt;li&gt;&lt;a href="scientific_details_of_algorithms/linear_learner_class_weights_loss_functions"&gt;Linear Learner features&lt;/a&gt; shows how to use the class weights and loss functions features of the SageMaker Linear Learner algorithm to improve performance on a credit card fraud prediction task&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-amazon-sagemaker-debugger" class="anchor" aria-hidden="true" href="#amazon-sagemaker-debugger"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Amazon SageMaker Debugger&lt;/h3&gt;
&lt;p&gt;These examples provide and introduction to SageMaker Debugger which allows debugging and monitoring capabilities for training of machine learning and deep learning algorithms. Note that although these notebooks focus on a specific framework, the same approach works with all the frameworks that Amazon SageMaker Debugger supports. The notebooks below are listed in the order in which we recommend you review them.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="sagemaker-debugger/tensorflow_builtin_rule/"&gt;Using a built-in rule with TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-debugger/tensorflow_keras_custom_rule/"&gt;Using a custom rule with TensorFlow Keras&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-debugger/mnist_tensor_analysis/"&gt;Interactive tensor analysis in notebook with MXNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-debugger/mnist_tensor_plot/"&gt;Visualizing Debugging Tensors of MXNet training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-debugger/mxnet_realtime_analysis/"&gt;Real-time analysis in notebook with MXNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-debugger/xgboost_builtin_rules/"&gt;Using a built in rule with XGBoost&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-debugger/xgboost_realtime_analysis/"&gt;Real-time analysis in notebook with XGBoost&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-debugger/mxnet_spot_training/"&gt;Using SageMaker Debugger with Managed Spot Training and MXNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-debugger/tensorflow_action_on_rule/"&gt;Reacting to CloudWatch Events from Rules to take an action based on status with TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-debugger/pytorch_custom_container/"&gt;Using SageMaker Debugger with a custom PyTorch container&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-advanced-amazon-sagemaker-functionality" class="anchor" aria-hidden="true" href="#advanced-amazon-sagemaker-functionality"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Advanced Amazon SageMaker Functionality&lt;/h3&gt;
&lt;p&gt;These examples that showcase unique functionality available in Amazon SageMaker.  They cover a broad range of topics and will utilize a variety of methods, but aim to provide the user with sufficient insight or inspiration to develop within Amazon SageMaker.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="advanced_functionality/data_distribution_types"&gt;Data Distribution Types&lt;/a&gt; showcases the difference between two methods for sending data from S3 to Amazon SageMaker Training instances.  This has particular implication for scalability and accuracy of distributed training.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/handling_kms_encrypted_data"&gt;Encrypting Your Data&lt;/a&gt; shows how to use Server Side KMS encrypted data with Amazon SageMaker training. The IAM role used for S3 access needs to have permissions to encrypt and decrypt data with the KMS key.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/parquet_to_recordio_protobuf"&gt;Using Parquet Data&lt;/a&gt; shows how to bring &lt;a href="https://parquet.apache.org/" rel="nofollow"&gt;Parquet&lt;/a&gt; data sitting in S3 into an Amazon SageMaker Notebook and convert it into the recordIO-protobuf format that many SageMaker algorithms consume.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/working_with_redshift_data"&gt;Connecting to Redshift&lt;/a&gt; demonstrates how to copy data from Redshift to S3 and vice-versa without leaving Amazon SageMaker Notebooks.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/xgboost_bring_your_own_model"&gt;Bring Your Own XGBoost Model&lt;/a&gt; shows how to use Amazon SageMaker Algorithms containers to bring a pre-trained model to a realtime hosted endpoint without ever needing to think about REST APIs.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/kmeans_bring_your_own_model"&gt;Bring Your Own k-means Model&lt;/a&gt; shows how to take a model that's been fit elsewhere and use Amazon SageMaker Algorithms containers to host it.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/r_bring_your_own"&gt;Bring Your Own R Algorithm&lt;/a&gt; shows how to bring your own algorithm container to Amazon SageMaker using the R language.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/install_r_kernel"&gt;Installing the R Kernel&lt;/a&gt; shows how to install the R kernel into an Amazon SageMaker Notebook Instance.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/scikit_bring_your_own"&gt;Bring Your Own scikit Algorithm&lt;/a&gt; provides a detailed walkthrough on how to package a scikit learn algorithm for training and production-ready hosting.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/mxnet_mnist_byom"&gt;Bring Your Own MXNet Model&lt;/a&gt; shows how to bring a model trained anywhere using MXNet into Amazon SageMaker.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/tensorflow_iris_byom"&gt;Bring Your Own TensorFlow Model&lt;/a&gt; shows how to bring a model trained anywhere using TensorFlow into Amazon SageMaker.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/inference_pipeline_sparkml_xgboost_abalone"&gt;Inference Pipeline with SparkML and XGBoost&lt;/a&gt; shows how to deploy an Inference Pipeline with SparkML for data pre-processing and XGBoost for training on the Abalone dataset. The pre-processing code is written once and used between training and inference.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/inference_pipeline_sparkml_blazingtext_dbpedia"&gt;Inference Pipeline with SparkML and BlazingText&lt;/a&gt; shows how to deploy an Inference Pipeline with SparkML for data pre-processing and BlazingText for training on the DBPedia dataset. The pre-processing code is written once and used between training and inference.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/search"&gt;Experiment Management Capabilities with Search&lt;/a&gt; shows how to organize Training Jobs into projects, and track relationships between Models, Endpoints, and Training Jobs.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/multi_model_bring_your_own"&gt;Host Multiple Models with Your Own Algorithm&lt;/a&gt; shows how to deploy multiple models to a realtime hosted endpoint with your own custom algorithm.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/multi_model_xgboost_home_value"&gt;Host Multiple Models with XGBoost&lt;/a&gt; shows how to deploy multiple models to a realtime hosted endpoint using a multi-model enabled XGBoost container.&lt;/li&gt;
&lt;li&gt;&lt;a href="advanced_functionality/multi_model_sklearn_home_value"&gt;Host Multiple Models with SKLearn&lt;/a&gt; shows how to deploy multiple models to a realtime hosted endpoint using a multi-model enabled SKLearn container.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-amazon-sagemaker-neo-compilation-jobs" class="anchor" aria-hidden="true" href="#amazon-sagemaker-neo-compilation-jobs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Amazon SageMaker Neo Compilation Jobs&lt;/h3&gt;
&lt;p&gt;These examples provide you an introduction to how to use Neo to optimizes deep learning model&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="sagemaker_neo_compilation_jobs/imageclassification_caltech"&gt;Image Classification&lt;/a&gt; Adapts form &lt;a href="introduction_to_amazon_algorithms/imageclassification_caltech"&gt;image classification&lt;/a&gt; including Neo API and comparsion between the baseline&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker_neo_compilation_jobs/mxnet_mnist"&gt;MNIST with MXNet&lt;/a&gt; Adapts form &lt;a href="sagemaker-python-sdk/mxnet_mnist"&gt;mxnet mnist&lt;/a&gt; including Neo API and comparsion between the baseline&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker_neo_compilation_jobs/pytorch_torchvision"&gt;Deploying pre-trained PyTorch vision models&lt;/a&gt; shows how to use Amazon SageMaker Neo to compile and optimize pre-trained PyTorch models from TorchVision.&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker_neo_compilation_jobs/tensorflow_distributed_mnist"&gt;Distributed TensorFlow&lt;/a&gt; Adapts form &lt;a href="sagemaker-python-sdk/tensorflow_distributed_mnist"&gt;tensorflow mnist&lt;/a&gt; including Neo API and comparsion between the baseline&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker_neo_compilation_jobs/xgboost_customer_churn"&gt;Predicting Customer Churn&lt;/a&gt; Adapts form &lt;a href="introduction_to_applying_machine_learning/xgboost_customer_churn"&gt;xgboost customer churn&lt;/a&gt; including Neo API and comparsion between the baseline&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-amazon-sagemaker-procesing" class="anchor" aria-hidden="true" href="#amazon-sagemaker-procesing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Amazon SageMaker Procesing&lt;/h3&gt;
&lt;p&gt;These examples show you how to use SageMaker Processing jobs to run data processing workloads.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="sagemaker_processing/scikit_learn_data_processing_and_model_evaluation"&gt;Scikit-Learn Data Processing and Model Evaluation&lt;/a&gt; shows how to use SageMaker Processing and the Scikit-Learn container to run data preprocessing and model evaluation workloads.&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker_processing/feature_transformation_with_sagemaker_processing"&gt;Feature transformation with Amazon SageMaker Processing and SparkML&lt;/a&gt; shows how to use SageMaker Processing to run data processing workloads using SparkML prior to training.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-amazon-sagemaker-pre-built-framework-containers-and-the-python-sdk" class="anchor" aria-hidden="true" href="#amazon-sagemaker-pre-built-framework-containers-and-the-python-sdk"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Amazon SageMaker Pre-Built Framework Containers and the Python SDK&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-pre-built-deep-learning-framework-containers" class="anchor" aria-hidden="true" href="#pre-built-deep-learning-framework-containers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-Built Deep Learning Framework Containers&lt;/h4&gt;
&lt;p&gt;These examples show you to write idiomatic TensorFlow or MXNet and then train or host in pre-built containers using SageMaker Python SDK.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/chainer_cifar10"&gt;Chainer CIFAR-10&lt;/a&gt; trains a VGG image classification network on CIFAR-10 using Chainer (both single machine and multi-machine versions are included)&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/chainer_mnist"&gt;Chainer MNIST&lt;/a&gt; trains a basic neural network on MNIST using Chainer (shows how to use local mode)&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/chainer_sentiment_analysis"&gt;Chainer sentiment analysis&lt;/a&gt; trains a LSTM network with embeddings to predict text sentiment using Chainer&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/scikit_learn_iris"&gt;IRIS with Scikit-learn&lt;/a&gt; trains a Scikit-learn classifier on IRIS data&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/mxnet_gluon_cifar10"&gt;CIFAR-10 with MXNet Gluon&lt;/a&gt; trains a ResNet-34  image classification model using MXNet Gluon&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/mxnet_gluon_mnist"&gt;MNIST with MXNet Gluon&lt;/a&gt; trains a basic neural network on the MNIST handwritten digit dataset using MXNet Gluon&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/mxnet_mnist"&gt;MNIST with MXNet&lt;/a&gt; trains a basic neural network on the MNIST handwritten digit data using MXNet's symbolic syntax&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/mxnet_gluon_sentiment"&gt;Sentiment Analysis with MXNet Gluon&lt;/a&gt; trains a text classifier using embeddings with MXNet Gluon&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/tensorflow_abalone_age_predictor_using_layers"&gt;TensorFlow Neural Networks with Layers&lt;/a&gt; trains a basic neural network on the abalone dataset using TensorFlow layers&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/tensorflow_abalone_age_predictor_using_keras"&gt;TensorFlow Networks with Keras&lt;/a&gt; trains a basic neural network on the abalone dataset using TensorFlow and Keras&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/tensorflow_iris_dnn_classifier_using_estimators"&gt;Introduction to Estimators in TensorFlow&lt;/a&gt; trains a DNN classifier estimator on the Iris dataset using TensorFlow&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/tensorflow_resnet_cifar10_with_tensorboard"&gt;TensorFlow and TensorBoard&lt;/a&gt; trains a ResNet image classification model on CIFAR-10 using TensorFlow and showcases how to track results using TensorBoard&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/tensorflow_distributed_mnist"&gt;Distributed TensorFlow&lt;/a&gt; trains a simple convolutional neural network on MNIST using TensorFlow&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-pre-built-machine-learning-framework-containers" class="anchor" aria-hidden="true" href="#pre-built-machine-learning-framework-containers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-Built Machine Learning Framework Containers&lt;/h4&gt;
&lt;p&gt;These examples show you how to build Machine Learning models with frameworks like Apache Spark or Scikit-learn using SageMaker Python SDK.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/sparkml_serving_emr_mleap_abalone"&gt;Inference with SparkML Serving&lt;/a&gt; shows how to build an ML model with Apache Spark using Amazon EMR on Abalone dataset and deploy in SageMaker with SageMaker SparkML Serving.&lt;/li&gt;
&lt;li&gt;&lt;a href="sagemaker-python-sdk/scikit_learn_inference_pipeline"&gt;Pipeline Inference with Scikit-learn and LinearLearner&lt;/a&gt; builds a ML pipeline using Scikit-learn preprocessing and LinearLearner algorithm in single endpoint&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-using-amazon-sagemaker-with-apache-spark" class="anchor" aria-hidden="true" href="#using-amazon-sagemaker-with-apache-spark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using Amazon SageMaker with Apache Spark&lt;/h3&gt;
&lt;p&gt;These examples show how to use Amazon SageMaker for model training, hosting, and inference through Apache Spark using &lt;a href="https://github.com/aws/sagemaker-spark"&gt;SageMaker Spark&lt;/a&gt;. SageMaker Spark allows you to interleave Spark Pipeline stages with Pipeline stages that interact with Amazon SageMaker.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="sagemaker-spark/pyspark_mnist"&gt;MNIST with SageMaker PySpark&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-aws-marketplace" class="anchor" aria-hidden="true" href="#aws-marketplace"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;AWS Marketplace&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-create-algorithmsmodel-packages-for-listing-in-aws-marketplace-for-machine-learning" class="anchor" aria-hidden="true" href="#create-algorithmsmodel-packages-for-listing-in-aws-marketplace-for-machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Create algorithms/model packages for listing in AWS Marketplace for machine learning.&lt;/h4&gt;
&lt;p&gt;This example shows you how to package a model-package/algorithm for listing in AWS Marketplace for machine learning.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="aws_marketplace/creating_marketplace_products"&gt;Creating Algorithm and Model Package - Listing on AWS Marketplace&lt;/a&gt; provides a detailed walkthrough on how to package a scikit learn algorithm to create SageMaker Algorithm and SageMaker Model Package entities that can be used with the enhanced SageMaker Train/Transform/Hosting/Tuning APIs and listed on AWS Marketplace.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-use-algorithms-and-model-packages-from-aws-marketplace-for-machine-learning" class="anchor" aria-hidden="true" href="#use-algorithms-and-model-packages-from-aws-marketplace-for-machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Use algorithms and model packages from AWS Marketplace for machine learning.&lt;/h4&gt;
&lt;p&gt;These examples show you how to use model-packages and algorithms from AWS Marketplace for machine learning.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="aws_marketplace/using_algorithms"&gt;Using Algorithms&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="aws_marketplace/using_algorithms/amazon_demo_product"&gt;Using Algorithm From AWS Marketplace&lt;/a&gt; provides a detailed walkthrough on how to use Algorithm with the enhanced SageMaker Train/Transform/Hosting/Tuning APIs by choosing a canonical product listed on AWS Marketplace.&lt;/li&gt;
&lt;li&gt;&lt;a href="aws_marketplace/using_algorithms/automl"&gt;Using AutoML algorithm&lt;/a&gt; provides a detailed walkthrough on how to use AutoML algorithm from AWS Marketplace.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="aws_marketplace/using_model_packages"&gt;Using Model Packages&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="aws_marketplace/using_model_packages/amazon_demo_product"&gt;Using Model Packages From AWS Marketplace&lt;/a&gt; provides a detailed walkthrough on how to use Model Package entities with the enhanced SageMaker Transform/Hosting APIs by choosing a canonical product listed on AWS Marketplace.&lt;/li&gt;
&lt;li&gt;&lt;a href="aws_marketplace/using_model_packages/auto_insurance"&gt;Using models for extracting vehicle metadata&lt;/a&gt; provides a detailed walkthrough on how to use pre-trained models from AWS Marketplace for extracting metadata for a sample use-case of auto-insurance claim processing.&lt;/li&gt;
&lt;li&gt;&lt;a href="aws_marketplace/using_model_packages/improving_industrial_workplace_safety"&gt;Using models for identifying non-compliance at a workplace&lt;/a&gt; provides a detailed walkthrough on how to use pre-trained models from AWS Marketplace for extracting metadata for a sample use-case of generating summary reports for identifying non-compliance at a construction/industrial workplace.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="aws_marketplace/using_data"&gt;Using Data&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="aws_marketplace/using_data/using_data_from_aws_data_exchange_to_predict_product_popularity"&gt;Using data and algorithm from AWS Marketplace for training a model&lt;/a&gt; provides a detailed walkthrough on how to use data from AWS Marketplace for training a model that predicts popularity of a bath product.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-under-development" class="anchor" aria-hidden="true" href="#under-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Under Development&lt;/h3&gt;
&lt;p&gt;These Amazon SageMaker examples fully illustrate a concept, but may require some additional configuration on the users part to complete.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-faq" class="anchor" aria-hidden="true" href="#faq"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FAQ&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;What do I need in order to get started?&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The quickest setup to run example notebooks includes:
&lt;ul&gt;
&lt;li&gt;An &lt;a href="http://docs.aws.amazon.com/sagemaker/latest/dg/gs-account.html" rel="nofollow"&gt;AWS account&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Proper &lt;a href="http://docs.aws.amazon.com/sagemaker/latest/dg/authentication-and-access-control.html" rel="nofollow"&gt;IAM User and Role&lt;/a&gt; setup&lt;/li&gt;
&lt;li&gt;An &lt;a href="http://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html" rel="nofollow"&gt;Amazon SageMaker Notebook Instance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;An &lt;a href="http://docs.aws.amazon.com/sagemaker/latest/dg/gs-config-permissions.html" rel="nofollow"&gt;S3 bucket&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Will these examples work outside of Amazon SageMaker Notebook Instances?&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Although most examples utilize key Amazon SageMaker functionality like distributed, managed training or real-time hosted endpoints, these notebooks can be run outside of Amazon SageMaker Notebook Instances with minimal modification (updating IAM role definition and installing the necessary libraries).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;How do I contribute my own example notebook?&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Although we're extremely excited to receive contributions from the community, we're still working on the best mechanism to take in examples from external sources.  Please bear with us in the short-term if pull requests take longer than expected or are closed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>awslabs</author><guid isPermaLink="false">https://github.com/awslabs/amazon-sagemaker-examples</guid><pubDate>Tue, 04 Feb 2020 00:23:00 GMT</pubDate></item><item><title>nicolas-gervais/predicting-car-price-from-scraped-data #24 in Jupyter Notebook, This month</title><link>https://github.com/nicolas-gervais/predicting-car-price-from-scraped-data</link><description>&lt;p&gt;&lt;i&gt;Picture and specifications scraper&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/4c036e10723d461671b7a413581be3f0daa8f3cd/68747470733a2f2f7777772e676c6f62656e657773776972652e636f6d2f6e6577732d72656c656173652f6c6f676f2f3439313738312f302f3439313738312e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/4c036e10723d461671b7a413581be3f0daa8f3cd/68747470733a2f2f7777772e676c6f62656e657773776972652e636f6d2f6e6577732d72656c656173652f6c6f676f2f3439313738312f302f3439313738312e706e67" align="right" data-canonical-src="https://www.globenewswire.com/news-release/logo/491781/0/491781.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-welcome-to-the-car-connection-dataset-tm" class="anchor" aria-hidden="true" href="#welcome-to-the-car-connection-dataset-tm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Welcome to &lt;em&gt;The Car Connection Dataset&lt;/em&gt; &lt;g-emoji class="g-emoji" alias="tm" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2122.png"&gt;â„¢ï¸&lt;/g-emoji&gt;&lt;/h1&gt;
&lt;p&gt;School Project&lt;/p&gt;
&lt;p&gt;I scraped 32,000+ cars with 150 specifications from thecarconnection.com and ran multiple analyses with Pytorch, Scikit-Learn, and Tensorflow. Those incluse PCA, fully-connected (dense) neural networks, decision trees, random forests, svm, etc.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The specs scraper is &lt;a href="https://github.com/nicolas-gervais/predicting-car-price-from-scraped-data/blob/master/scraping"&gt;here&lt;/a&gt;, but deprecated(it will only scrape 2,000 cars)&lt;/li&gt;
&lt;li&gt;The &lt;a href="https://github.com/nicolas-gervais/predicting-car-price-from-scraped-data/tree/master/picture-scraper"&gt;picture scraper repo&lt;/a&gt; is here.&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>nicolas-gervais</author><guid isPermaLink="false">https://github.com/nicolas-gervais/predicting-car-price-from-scraped-data</guid><pubDate>Tue, 04 Feb 2020 00:24:00 GMT</pubDate></item><item><title>JWarmenhoven/ISLR-python #25 in Jupyter Notebook, This month</title><link>https://github.com/JWarmenhoven/ISLR-python</link><description>&lt;p&gt;&lt;i&gt;An Introduction to Statistical Learning (James, Witten, Hastie, Tibshirani, 2013): Python code&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-islr-python" class="anchor" aria-hidden="true" href="#islr-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ISLR-python&lt;/h1&gt;
&lt;p&gt;This repository contains Python code for a selection of tables, figures and LAB sections from the book &lt;a href="http://www-bcf.usc.edu/%7Egareth/ISL/index.html" rel="nofollow"&gt;'An Introduction to Statistical Learning with Applications in R'&lt;/a&gt; by James, Witten, Hastie, Tibshirani (2013).&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
&lt;p&gt;For &lt;strong&gt;Bayesian data analysis&lt;/strong&gt;, take a look at &lt;a href="https://github.com/JWarmenhoven/DBDA-python"&gt;this repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2018-01-15&lt;/strong&gt;:&lt;br&gt;
Minor updates to the repository due to changes/deprecations in several packages. The notebooks have been tested with &lt;a href="http://nbviewer.jupyter.org/github/JWarmenhoven/ISLR-python/blob/master/Notebooks/Python%20module%20versions.ipynb" rel="nofollow"&gt;these package versions&lt;/a&gt;. Thanks @lincolnfrias and @telescopeuser.&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2016-08-30&lt;/strong&gt;:&lt;br&gt;
Chapter 6: I included Ridge/Lasso regression code using the new &lt;a href="https://github.com/civisanalytics/python-glmnet"&gt;python-glmnet&lt;/a&gt; library. This is a python wrapper for the Fortran library used in the &lt;em&gt;R&lt;/em&gt; package &lt;em&gt;glmnet&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="Notebooks/ISL%20Cover%202.jpg"&gt;&lt;img src="Notebooks/ISL%20Cover%202.jpg" height="20%" width="20%" style="max-width:100%;"&gt;&lt;/a&gt; &lt;/p&gt;&lt;p&gt;
&lt;a href="http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Chapter%203.ipynb" rel="nofollow"&gt;Chapter 3 - Linear Regression&lt;/a&gt;&lt;br&gt;
&lt;a href="http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Chapter%204.ipynb" rel="nofollow"&gt;Chapter 4 - Classification&lt;/a&gt;&lt;br&gt;
&lt;a href="http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Chapter%205.ipynb" rel="nofollow"&gt;Chapter 5 - Resampling Methods&lt;/a&gt;&lt;br&gt;
&lt;a href="http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Chapter%206.ipynb" rel="nofollow"&gt;Chapter 6 - Linear Model Selection and Regularization&lt;/a&gt;&lt;br&gt;
&lt;a href="http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Chapter%207.ipynb" rel="nofollow"&gt;Chapter 7 - Moving Beyond Linearity&lt;/a&gt;&lt;br&gt;
&lt;a href="http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Chapter%208.ipynb" rel="nofollow"&gt;Chapter 8 - Tree-Based Methods&lt;/a&gt;&lt;br&gt;
&lt;a href="http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Chapter%209.ipynb" rel="nofollow"&gt;Chapter 9 - Support Vector Machines&lt;/a&gt;&lt;br&gt;
&lt;a href="http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Chapter%2010.ipynb" rel="nofollow"&gt;Chapter 10 - Unsupervised Learning&lt;/a&gt;&lt;/p&gt;&lt;p&gt;
&lt;a href="http://nbviewer.jupyter.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Simulate.expected.misclassification.rate.ipynb" rel="nofollow"&gt;Extra: Misclassification rate simulation - SVM and Logistic Regression&lt;/a&gt;&lt;/p&gt;&lt;p&gt;
This great book gives a thorough introduction to the field of Statistical/Machine Learning. The book is available for download (see link below), but I think this is one of those books that is definitely worth buying. The book contains sections with applications in R based on public datasets available for download or which are part of the &lt;a href="https://cran.r-project.org/web/packages/ISLR/index.html" rel="nofollow"&gt;R-package ISLR&lt;/a&gt;. Furthermore, there is a Stanford University online course based on this book and taught by the authors (See &lt;a href="https://lagunita.stanford.edu/courses/" rel="nofollow"&gt;course catalogue&lt;/a&gt; for current schedule).&lt;/p&gt;&lt;p&gt;
Since Python is my language of choice for data analysis, I decided to try and do some of the calculations and plots in Jupyter Notebooks using:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pandas&lt;/li&gt;
&lt;li&gt;numpy&lt;/li&gt;
&lt;li&gt;scipy&lt;/li&gt;
&lt;li&gt;scikit-learn&lt;/li&gt;
&lt;li&gt;python-glmnet&lt;/li&gt;
&lt;li&gt;statsmodels&lt;/li&gt;
&lt;li&gt;patsy&lt;/li&gt;
&lt;li&gt;matplotlib&lt;/li&gt;
&lt;li&gt;seaborn&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It was a good way to learn more about Machine Learning in Python by creating these notebooks. I created some of the figures/tables of the chapters and worked through some LAB sections. At certain points I realize that it may look like I tried too hard to make the output identical to the tables and R-plots in the book. But I did this to explore some details of the libraries mentioned above (mostly matplotlib and seaborn). Note that this repository is &lt;strong&gt;not a standalone tutorial&lt;/strong&gt; and that you probably should have a copy of the book to follow along. Suggestions for improvement and help with unsolved issues are welcome!
See Hastie et al. (2009) for an advanced treatment of these topics.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-references" class="anchor" aria-hidden="true" href="#references"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;References:&lt;/h4&gt;
&lt;p&gt;James, G., Witten, D., Hastie, T., Tibshirani, R. (2013). &lt;i&gt;An Introduction to Statistical Learning with Applications in  R&lt;/i&gt;,  Springer Science+Business Media, New York.
&lt;a href="http://www-bcf.usc.edu/~gareth/ISL/index.html" rel="nofollow"&gt;http://www-bcf.usc.edu/~gareth/ISL/index.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hastie, T., Tibshirani, R., Friedman, J. (2009). &lt;i&gt;Elements of Statistical Learning&lt;/i&gt;, Second Edition, Springer Science+Business Media, New York.
&lt;a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/" rel="nofollow"&gt;http://statweb.stanford.edu/~tibs/ElemStatLearn/&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>JWarmenhoven</author><guid isPermaLink="false">https://github.com/JWarmenhoven/ISLR-python</guid><pubDate>Tue, 04 Feb 2020 00:25:00 GMT</pubDate></item></channel></rss>