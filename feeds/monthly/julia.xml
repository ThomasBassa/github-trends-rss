<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Julia, This month</title><link>https://github.com/trending/julia?since=monthly</link><description>The top repositories on GitHub for julia, measured monthly</description><pubDate>Thu, 07 Nov 2019 01:06:52 GMT</pubDate><lastBuildDate>Thu, 07 Nov 2019 01:06:52 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>FluxML/Flux.jl #1 in Julia, This month</title><link>https://github.com/FluxML/Flux.jl</link><description>&lt;p&gt;&lt;i&gt;Relax! Flux is the ML library that doesn't make you tensor&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/FluxML/fluxml.github.io/master/logo.png"&gt;&lt;img width="400px" src="https://raw.githubusercontent.com/FluxML/fluxml.github.io/master/logo.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/FluxML/Flux.jl" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8b10e4a0832de887b8a542480f6a864b9d2ecfc0/68747470733a2f2f7472617669732d63692e6f72672f466c75784d4c2f466c75782e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/FluxML/Flux.jl.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://fluxml.github.io/Flux.jl/stable/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f7b92a177c912c1cc007fc9b40f17ff3ee3bb414/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://slackinvite.julialang.org/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24d16c31ff9f7628be0e050b793afd8b2458029c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230736c61636b2d79656c6c6f772e737667" alt="" data-canonical-src="https://img.shields.io/badge/chat-on%20slack-yellow.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://doi.org/10.21105/joss.00602" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/33eb230ee6fb9c214eb02ee3f227e6d81e540911/68747470733a2f2f6a6f73732e7468656f6a2e6f72672f7061706572732f31302e32313130352f6a6f73732e30303630322f7374617475732e737667" alt="DOI" data-canonical-src="https://joss.theoj.org/papers/10.21105/joss.00602/status.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Flux is an elegant approach to machine learning. It's a 100% pure-Julia stack, and provides lightweight abstractions on top of Julia's native GPU and AD support. Flux makes the easy things easy while remaining fully hackable.&lt;/p&gt;
&lt;div class="highlight highlight-source-julia"&gt;&lt;pre&gt;julia&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; Pkg&lt;span class="pl-k"&gt;.&lt;/span&gt;&lt;span class="pl-c1"&gt;add&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Flux&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See the &lt;a href="https://fluxml.github.io/Flux.jl/" rel="nofollow"&gt;documentation&lt;/a&gt; or the &lt;a href="https://github.com/FluxML/model-zoo/"&gt;model zoo&lt;/a&gt; for examples.&lt;/p&gt;
&lt;p&gt;If you use Flux in research, please cite the following paper:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{innes:2018,
  author    = {Mike Innes},
  title     = {Flux: Elegant Machine Learning with Julia},
  journal   = {Journal of Open Source Software},
  year      = {2018},
  doi       = {10.21105/joss.00602},
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;p&gt;Flux has powerful high-level features, and common architectures can be defined in a few lines.&lt;/p&gt;
&lt;div class="highlight highlight-source-julia"&gt;&lt;pre&gt;model &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;Chain&lt;/span&gt;(
  &lt;span class="pl-c1"&gt;Dense&lt;/span&gt;(&lt;span class="pl-c1"&gt;768&lt;/span&gt;, &lt;span class="pl-c1"&gt;128&lt;/span&gt;, σ),
  &lt;span class="pl-c1"&gt;LSTM&lt;/span&gt;(&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-c1"&gt;256&lt;/span&gt;),
  &lt;span class="pl-c1"&gt;LSTM&lt;/span&gt;(&lt;span class="pl-c1"&gt;256&lt;/span&gt;, &lt;span class="pl-c1"&gt;128&lt;/span&gt;),
  &lt;span class="pl-c1"&gt;Dense&lt;/span&gt;(&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-c1"&gt;10&lt;/span&gt;),
  softmax)

&lt;span class="pl-en"&gt;loss&lt;/span&gt;(x, y) &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;crossentropy&lt;/span&gt;(&lt;span class="pl-c1"&gt;model&lt;/span&gt;(x), y)

Flux&lt;span class="pl-k"&gt;.&lt;/span&gt;&lt;span class="pl-c1"&gt;train!&lt;/span&gt;(loss, &lt;span class="pl-c1"&gt;params&lt;/span&gt;(model), data, &lt;span class="pl-c1"&gt;ADAM&lt;/span&gt;(&lt;span class="pl-k"&gt;...&lt;/span&gt;))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Yet you can easily strip away the layers, and directly write the mathematics for your problem. Flux will seamlessly take gradients of any Julia code, so your model looks just like the paper.&lt;/p&gt;
&lt;div class="highlight highlight-source-julia"&gt;&lt;pre&gt;W &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;param&lt;/span&gt;(&lt;span class="pl-c1"&gt;randn&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;10&lt;/span&gt;))
b &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;param&lt;/span&gt;(&lt;span class="pl-c1"&gt;randn&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;))

&lt;span class="pl-en"&gt;y&lt;/span&gt;(x) &lt;span class="pl-k"&gt;=&lt;/span&gt; σ.(W &lt;span class="pl-k"&gt;*&lt;/span&gt; x &lt;span class="pl-k"&gt;.+&lt;/span&gt; b)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If that's &lt;em&gt;still&lt;/em&gt; not enough, you can go as deep as you want, even writing your own CUDA kernels with &lt;a href="https://github.com/JuliaGPU/CUDAnative.jl"&gt;CUDAnative&lt;/a&gt;! All this can be freely mixed-and-matched in a single model or script, and it all runs interactively via Jupyter or Juno.&lt;/p&gt;
&lt;div class="highlight highlight-source-julia"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;function&lt;/span&gt; &lt;span class="pl-en"&gt;gpu_add&lt;/span&gt;(a, b, c)
  i &lt;span class="pl-k"&gt;=&lt;/span&gt; (&lt;span class="pl-c1"&gt;blockIdx&lt;/span&gt;()&lt;span class="pl-k"&gt;.&lt;/span&gt;x&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;) &lt;span class="pl-k"&gt;*&lt;/span&gt; &lt;span class="pl-c1"&gt;blockDim&lt;/span&gt;()&lt;span class="pl-k"&gt;.&lt;/span&gt;x &lt;span class="pl-k"&gt;+&lt;/span&gt; &lt;span class="pl-c1"&gt;threadIdx&lt;/span&gt;()&lt;span class="pl-k"&gt;.&lt;/span&gt;x
  c[i] &lt;span class="pl-k"&gt;=&lt;/span&gt; a[i] &lt;span class="pl-k"&gt;+&lt;/span&gt; b[i]
  &lt;span class="pl-k"&gt;return&lt;/span&gt; &lt;span class="pl-c1"&gt;nothing&lt;/span&gt;
&lt;span class="pl-k"&gt;end&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Unusual architectures are no problem in Flux, as you can use all the loops, control flow and even macros that you're used to. Here's a Tree RNN in 4 lines.&lt;/p&gt;
&lt;div class="highlight highlight-source-julia"&gt;&lt;pre&gt;&lt;span class="pl-en"&gt;tree&lt;/span&gt;() &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;rand&lt;/span&gt;() &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.5&lt;/span&gt; ? &lt;span class="pl-c1"&gt;rand&lt;/span&gt;(&lt;span class="pl-c1"&gt;10&lt;/span&gt;) : (&lt;span class="pl-c1"&gt;tree&lt;/span&gt;(), &lt;span class="pl-c1"&gt;tree&lt;/span&gt;()) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; dummy data&lt;/span&gt;

shrink &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;Dense&lt;/span&gt;(&lt;span class="pl-c1"&gt;20&lt;/span&gt;, &lt;span class="pl-c1"&gt;10&lt;/span&gt;)
&lt;span class="pl-en"&gt;combine&lt;/span&gt;(a, b) &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;shrink&lt;/span&gt;([a; b])

&lt;span class="pl-en"&gt;model&lt;/span&gt;(x) &lt;span class="pl-k"&gt;=&lt;/span&gt; x
&lt;span class="pl-en"&gt;model&lt;/span&gt;(x&lt;span class="pl-k"&gt;::&lt;/span&gt;&lt;span class="pl-c1"&gt;Tuple&lt;/span&gt;) &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;combine&lt;/span&gt;(&lt;span class="pl-c1"&gt;model&lt;/span&gt;(x[&lt;span class="pl-c1"&gt;1&lt;/span&gt;]), &lt;span class="pl-c1"&gt;model&lt;/span&gt;(x[&lt;span class="pl-c1"&gt;2&lt;/span&gt;]))

&lt;span class="pl-c1"&gt;model&lt;/span&gt;(&lt;span class="pl-c1"&gt;tree&lt;/span&gt;()) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Sample output&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Despite this flexibility, Julia's advanced compiler lets us do some powerful optimisations. For example, this definition of &lt;code&gt;sigmoid&lt;/code&gt; automatically gets fused into a &lt;em&gt;single&lt;/em&gt; GPU kernel – so it's really fast.&lt;/p&gt;
&lt;div class="highlight highlight-source-julia"&gt;&lt;pre&gt;&lt;span class="pl-en"&gt;sigmoid&lt;/span&gt;(xs) &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1&lt;/span&gt; &lt;span class="pl-k"&gt;./&lt;/span&gt; (&lt;span class="pl-c1"&gt;1&lt;/span&gt; &lt;span class="pl-k"&gt;.+&lt;/span&gt; &lt;span class="pl-c1"&gt;exp&lt;/span&gt;.(&lt;span class="pl-k"&gt;.-&lt;/span&gt;xs))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Similarly, Flux is the first dynamic framework to support &lt;a href="https://fluxml.github.io/experiments/" rel="nofollow"&gt;compiling to the browser&lt;/a&gt; and model import via &lt;a href="https://github.com/FluxML/ONNX.jl/"&gt;formats like ONNX&lt;/a&gt;, both of which are thinly-veiled compiler problems.&lt;/p&gt;
&lt;p&gt;For more on our philosophy on machine learning, check out our article &lt;a href="https://julialang.org/blog/2017/12/ml&amp;amp;pl" rel="nofollow"&gt;On Machine Learning &amp;amp; Programming Languages&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing--help" class="anchor" aria-hidden="true" href="#contributing--help"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing &amp;amp; Help&lt;/h2&gt;
&lt;p&gt;For general questions and help, check out Julia's &lt;a href="https://discourse.julialang.org/c/domain/ML" rel="nofollow"&gt;community forum&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Flux development is carried out via our &lt;a href="https://github.com/FluxML/Flux.jl/issues"&gt;GitHub issues&lt;/a&gt;, so feel free to open feature requests or PRs here.&lt;/p&gt;
&lt;p&gt;For more informal discussions we'd love to have you on the &lt;a href="https://slackinvite.julialang.org/" rel="nofollow"&gt;Julia slack&lt;/a&gt;, where we hang out on the #machine-learning channel.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-related-packages" class="anchor" aria-hidden="true" href="#related-packages"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Related Packages&lt;/h2&gt;
&lt;p&gt;Check out &lt;a href="https://github.com/FluxML/Metalhead.jl"&gt;Metalhead.jl&lt;/a&gt; for common computer vision datasets and trained models.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/JuliaML/MLDatasets.jl"&gt;MLDatasets.jl&lt;/a&gt; provides further common datasets.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>FluxML</author><guid isPermaLink="false">https://github.com/FluxML/Flux.jl</guid><pubDate>Thu, 07 Nov 2019 00:01:00 GMT</pubDate></item></channel></rss>