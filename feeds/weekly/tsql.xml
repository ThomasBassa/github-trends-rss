<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: TSQL, This week</title><link>https://github.com/trending/tsql?since=weekly</link><description>The top repositories on GitHub for tsql, measured weekly</description><pubDate>Tue, 12 Nov 2019 01:08:27 GMT</pubDate><lastBuildDate>Tue, 12 Nov 2019 01:08:27 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>BrentOzarULTD/SQL-Server-First-Responder-Kit #1 in TSQL, This week</title><link>https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit</link><description>&lt;p&gt;&lt;i&gt;sp_Blitz, sp_BlitzCache, sp_BlitzFirst, sp_BlitzIndex, and other SQL Server scripts for health checks and performance tuning.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-sql-server-first-responder-kit" class="anchor" aria-hidden="true" href="#sql-server-first-responder-kit"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SQL Server First Responder Kit&lt;/h1&gt;
&lt;p&gt;&lt;a name="user-content-header1"&gt;&lt;/a&gt;
&lt;a href="https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit/blob/master/LICENSE.md"&gt;&lt;img src="https://camo.githubusercontent.com/890acbdcb87868b382af9a4b1fac507b9659d9bf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667" alt="licence badge" data-canonical-src="https://img.shields.io/badge/license-MIT-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit/stargazers"&gt;&lt;img src="https://camo.githubusercontent.com/48e714d6a304efa786cf7baba39dfd1a6f48d8b0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4272656e744f7a6172554c54442f53514c2d5365727665722d46697273742d526573706f6e6465722d4b69742e737667" alt="stars badge" data-canonical-src="https://img.shields.io/github/stars/BrentOzarULTD/SQL-Server-First-Responder-Kit.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit/network"&gt;&lt;img src="https://camo.githubusercontent.com/0f6baf2b4e78d3b941025d29e8280c7e07090aaa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f4272656e744f7a6172554c54442f53514c2d5365727665722d46697273742d526573706f6e6465722d4b69742e737667" alt="forks badge" data-canonical-src="https://img.shields.io/github/forks/BrentOzarULTD/SQL-Server-First-Responder-Kit.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit/issues"&gt;&lt;img src="https://camo.githubusercontent.com/421930857408b0140d5439cdbc023ecfa444f834/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4272656e744f7a6172554c54442f53514c2d5365727665722d46697273742d526573706f6e6465722d4b69742e737667" alt="issues badge" data-canonical-src="https://img.shields.io/github/issues/BrentOzarULTD/SQL-Server-First-Responder-Kit.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Navigation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#how-to-get-support"&gt;How to Get Support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Common Scripts:
&lt;ul&gt;
&lt;li&gt;&lt;a href="#sp_blitz-overall-health-check"&gt;sp_Blitz: Overall Health Check&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#advanced-sp_blitz-parameters"&gt;Advanced sp_Blitz Parameters&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#writing-sp_blitz-output-to-a-table"&gt;Writing sp_Blitz Output to a Table&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#skipping-checks-or-databases"&gt;Skipping Checks or Databases&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#sp_blitzcache-find-the-most-resource-intensive-queries"&gt;sp_BlitzCache: Find the Most Resource-Intensive Queries&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#advanced-sp_blitzcache-parameters"&gt;Advanced sp_BlitzCache Parameters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#sp_blitzfirst-real-time-performance-advice"&gt;sp_BlitzFirst: Real-Time Performance Advice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sp_blitzindex-tune-your-indexes"&gt;sp_BlitzIndex: Tune Your Indexes&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#advanced-sp_blitzindex-parameters"&gt;Advanced sp_BlitzIndex Parameters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Performance Tuning:
&lt;ul&gt;
&lt;li&gt;&lt;a href="#sp_blitzinmemoryoltp-hekaton-analysis"&gt;sp_BlitzInMemoryOLTP: Hekaton Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sp_blitzlock-deadlock-analysis"&gt;sp_BlitzLock: Deadlock Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sp_blitzquerystore-query-store-sale"&gt;sp_BlitzQueryStore: Like BlitzCache, for Query Store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sp_blitzwho-what-queries-are-running-now"&gt;sp_BlitzWho: What Queries are Running Now&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Backups and Restores:
&lt;ul&gt;
&lt;li&gt;&lt;a href="#sp_blitzbackups-how-much-data-could-you-lose"&gt;sp_BlitzBackups: How Much Data Could You Lose&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sp_allnightlog-back-up-faster-to-lose-less-data"&gt;sp_AllNightLog: Back Up Faster to Lose Less Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sp_databaserestore-easier-multi-file-restores"&gt;sp_DatabaseRestore: Easier Multi-File Restores&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#parameters-common-to-many-of-the-stored-procedures"&gt;Parameters Common to Many of the Stored Procedures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;License MIT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You're a DBA, sysadmin, or developer who manages Microsoft SQL Servers. It's your fault if they're down or slow. These tools help you understand what's going on in your server.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When you want an overall health check, run &lt;a href="#sp_blitz-overall-health-check"&gt;sp_Blitz&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;To learn which queries have been using the most resources, run &lt;a href="#sp_blitzcache-find-the-most-resource-intensive-queries"&gt;sp_BlitzCache&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;To analyze which indexes are missing or slowing you down, run &lt;a href="#sp_blitzindex-tune-your-indexes"&gt;sp_BlitzIndex&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;To find out why the server is slow right now, run &lt;a href="#sp_blitzfirst-real-time-performance-advice"&gt;sp_BlitzFirst&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To install, &lt;a href="https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit/releases"&gt;download the latest release ZIP&lt;/a&gt;, then run the SQL files in the master database. (You can use other databases if you prefer.)&lt;/p&gt;
&lt;p&gt;The First Responder Kit runs on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SQL Server 2008, 2008R2, 2012, 2014, 2016, 2017 on Windows - yes, fully supported&lt;/li&gt;
&lt;li&gt;SQL Server 2017 on Linux - yes, fully supported except sp_AllNightLog and sp_DatabaseRestore, which require xp_cmdshell, which Microsoft doesn't provide on Linux&lt;/li&gt;
&lt;li&gt;SQL Server 2000, 2005 - not supported by Microsoft anymore, so we don't either&lt;/li&gt;
&lt;li&gt;Amazon RDS SQL Server - fully supported&lt;/li&gt;
&lt;li&gt;Azure SQL DB - It's a dice roll. Microsoft changes DMV contents in here without warning, so no guarantees.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-get-support" class="anchor" aria-hidden="true" href="#how-to-get-support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to Get Support&lt;/h2&gt;
&lt;p&gt;Everyone here is expected to abide by the &lt;a href="CONTRIBUTING.md#the-contributor-covenant-code-of-conduct"&gt;Contributor Covenant Code of Conduct&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When you have questions about how the tools work, talk with the community in the &lt;a href="https://sqlcommunity.slack.com/messages/firstresponderkit/" rel="nofollow"&gt;#FirstResponderKit Slack channel&lt;/a&gt;. If you need a free invite, hit &lt;a href="http://SQLslack.com/" rel="nofollow"&gt;SQLslack.com&lt;/a&gt;. Be patient - it's staffed with volunteers who have day jobs, heh.&lt;/p&gt;
&lt;p&gt;When you find a bug or want something changed, &lt;a href="CONTRIBUTING.md"&gt;read the contributing.md file&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When you have a question about what the scripts found, first make sure you read the "More Details" URL for any warning you find. We put a lot of work into documentation, and we wouldn't want someone to yell at you to go read the fine manual. After that, when you've still got questions about how something works in SQL Server, post a question at &lt;a href="http://dba.stackexchange.com" rel="nofollow"&gt;DBA.StackExchange.com&lt;/a&gt; and the community (that includes us!) will help. Include exact errors and any applicable screenshots, your SQL Server version number (including the build #), and the version of the tool you're working with.&lt;/p&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sp_blitz-overall-health-check" class="anchor" aria-hidden="true" href="#sp_blitz-overall-health-check"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;sp_Blitz: Overall Health Check&lt;/h2&gt;
&lt;p&gt;Run sp_Blitz daily or weekly for an overall health check. Just run it from SQL Server Management Studio, and you'll get a prioritized list of issues on your server right now:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/d7617f402a424f7f3a0997662263db708c2e7830/687474703a2f2f752e6272656e746f7a61722e636f6d2f6769746875622d696d616765732f73705f426c69747a2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/d7617f402a424f7f3a0997662263db708c2e7830/687474703a2f2f752e6272656e746f7a61722e636f6d2f6769746875622d696d616765732f73705f426c69747a2e706e67" alt="sp_Blitz" data-canonical-src="http://u.brentozar.com/github-images/sp_Blitz.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Output columns include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Priority - 1 is the most urgent, stuff that could get you fired. The warnings get progressively less urgent.&lt;/li&gt;
&lt;li&gt;FindingsGroup, Findings - describe the problem sp_Blitz found on the server.&lt;/li&gt;
&lt;li&gt;DatabaseName - the database having the problem. If it's null, it's a server-wide problem.&lt;/li&gt;
&lt;li&gt;URL - copy/paste this into a browser for more information.&lt;/li&gt;
&lt;li&gt;Details - not just bland text, but dynamically generated stuff with more info.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Commonly used parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@CheckUserDatabaseObjects = 0 - by default, we check inside user databases for things like triggers or heaps. Turn this off (0) to make checks go faster, or ignore stuff you can't fix if you're managing third party databases. If a server has 50+ databases, @CheckUserDatabaseObjects is automatically turned off unless...&lt;/li&gt;
&lt;li&gt;@BringThePain = 1 - required if you want to run @CheckUserDatabaseObjects = 1 with over 50 databases. It's gonna be slow.&lt;/li&gt;
&lt;li&gt;@CheckServerInfo = 1 - includes additional rows at priority 250 with server configuration details like service accounts.&lt;/li&gt;
&lt;li&gt;@IgnorePrioritiesAbove = 50 - if you want a daily bulletin of the most important warnings, set @IgnorePrioritiesAbove = 50 to only get the urgent stuff.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-advanced-sp_blitz-parameters" class="anchor" aria-hidden="true" href="#advanced-sp_blitz-parameters"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Advanced sp_Blitz Parameters&lt;/h3&gt;
&lt;p&gt;In addition to the &lt;a href="#parameters-common-to-many-of-the-stored-procedures"&gt;parameters common to many of the stored procedures&lt;/a&gt;, here are the ones specific to sp_Blitz:&lt;/p&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-writing-sp_blitz-output-to-a-table" class="anchor" aria-hidden="true" href="#writing-sp_blitz-output-to-a-table"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Writing sp_Blitz Output to a Table&lt;/h4&gt;
&lt;div class="highlight highlight-source-sql"&gt;&lt;pre&gt;sp_Blitz @OutputDatabaseName &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;DBAtools&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, @OutputSchemaName &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;dbo&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, @OutputTableName &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;BlitzResults&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Checks for the existence of a table DBAtools.dbo.BlitzResults, creates it if necessary, then adds the output of sp_Blitz into this table. This table is designed to support multiple outputs from multiple servers, so you can track your server's configuration history over time.&lt;/p&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-skipping-checks-or-databases" class="anchor" aria-hidden="true" href="#skipping-checks-or-databases"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Skipping Checks or Databases&lt;/h4&gt;
&lt;div class="highlight highlight-source-sql"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;CREATE&lt;/span&gt; &lt;span class="pl-k"&gt;TABLE&lt;/span&gt; &lt;span class="pl-en"&gt;dbo&lt;/span&gt;.BlitzChecksToSkip (
ServerName NVARCHAR(&lt;span class="pl-c1"&gt;128&lt;/span&gt;),
DatabaseName NVARCHAR(&lt;span class="pl-c1"&gt;128&lt;/span&gt;),
CheckID &lt;span class="pl-k"&gt;INT&lt;/span&gt;
);
GO
&lt;span class="pl-k"&gt;INSERT INTO&lt;/span&gt; &lt;span class="pl-c1"&gt;dbo&lt;/span&gt;.&lt;span class="pl-c1"&gt;BlitzChecksToSkip&lt;/span&gt; (ServerName, DatabaseName, CheckID)
&lt;span class="pl-k"&gt;VALUES&lt;/span&gt; (&lt;span class="pl-k"&gt;NULL&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;SalesDB&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;50&lt;/span&gt;)
sp_Blitz @SkipChecksDatabase &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;DBAtools&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, @SkipChecksSchema &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;dbo&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, @SkipChecksTable &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;BlitzChecksToSkip&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Checks for the existence of a table named Fred - just kidding, named DBAtools.dbo.BlitzChecksToSkip. The table needs at least the columns shown above (ServerName, DatabaseName, and CheckID). For each row:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the DatabaseName is populated but CheckID is null, then all checks will be skipped for that database&lt;/li&gt;
&lt;li&gt;If both DatabaseName and CheckID are populated, then that check will be skipped for that database&lt;/li&gt;
&lt;li&gt;If CheckID is populated but DatabaseName is null, then that check will be skipped for all databases&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sp_blitzcache-find-the-most-resource-intensive-queries" class="anchor" aria-hidden="true" href="#sp_blitzcache-find-the-most-resource-intensive-queries"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;sp_BlitzCache: Find the Most Resource-Intensive Queries&lt;/h2&gt;
&lt;p&gt;sp_BlitzCache looks at your plan cache where SQL Server keeps track of which queries have run recently, and how much impact they've had on the server.&lt;/p&gt;
&lt;p&gt;By default, it includes two result sets:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first result set shows your 10 most resource-intensive queries.&lt;/li&gt;
&lt;li&gt;The second result set explains the contents of the Warnings column - but it only shows the warnings that were produced in the first result set. (It's kinda like the most relevant glossary of execution plan terms.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Output columns include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Database - the database context where the query ran. Keep in mind that if you fully qualify your object names, the same query might be run from multiple databases.&lt;/li&gt;
&lt;li&gt;Cost - the Estimated Subtree Cost of the query, what Kendra Little calls "Query Bucks."&lt;/li&gt;
&lt;li&gt;Query Text - don't copy/paste from here - it's only a quick reference. A better source for the query will show up later on.&lt;/li&gt;
&lt;li&gt;Warnings - problems we found.&lt;/li&gt;
&lt;li&gt;Created At - when the plan showed up in the cache.&lt;/li&gt;
&lt;li&gt;Last Execution - maybe the query only runs at night.&lt;/li&gt;
&lt;li&gt;Query Plan - click on this, and the graphical plan pops up.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-common-sp_blitzcache-parameters" class="anchor" aria-hidden="true" href="#common-sp_blitzcache-parameters"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Common sp_BlitzCache Parameters&lt;/h3&gt;
&lt;p&gt;The @SortOrder parameter lets you pick which top 10 queries you want to examine:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;reads - logical reads&lt;/li&gt;
&lt;li&gt;CPU - from total_worker_time in sys.dm_exec_query_stats&lt;/li&gt;
&lt;li&gt;executions - how many times the query ran since the CreationDate&lt;/li&gt;
&lt;li&gt;xpm - executions per minute, derived from the CreationDate and LastExecution&lt;/li&gt;
&lt;li&gt;recent compilations - if you're looking for things that are recompiling a lot&lt;/li&gt;
&lt;li&gt;memory grant - if you're troubleshooting a RESOURCE_SEMAPHORE issue and want to find queries getting a lot of memory&lt;/li&gt;
&lt;li&gt;writes - if you wanna find those pesky ETL processes&lt;/li&gt;
&lt;li&gt;You can also use average or avg for a lot of the sorts, like @SortOrder = 'avg reads'&lt;/li&gt;
&lt;li&gt;all - sorts by all the different sort order options, and returns a single result set of hot messes. This is a little tricky because:
&lt;ul&gt;
&lt;li&gt;We find the @Top N queries by CPU, then by reads, then writes, duration, executions, memory grant, spills, etc.&lt;/li&gt;
&lt;li&gt;As we work through each pattern, we exclude the results from the prior patterns. So for example, we get the top 10 by CPU, and then when we go to get the top 10 by reads, we exclude queries that were already found in the top 10 by CPU. As a result, the top 10 by reads may not really be the top 10 by reads - because some of those might have been in the top 10 by CPU.&lt;/li&gt;
&lt;li&gt;To make things even a little more confusing, in the Pattern column of the output, we only specify the first pattern that matched, not all of the patterns that matched. It would be cool if at some point in the future, we turned this into a comma-delimited list of patterns that a query matched, and then we'd be able to get down to a tighter list of top queries. For now, though, this is kinda unscientific.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;query hash - filters for only queries that have multiple cached plans (even though they may all still be the same plan, just different copies stored.) If you use @SortOrder = 'query hash', you can specify a second sort order with a comma, like 'query hash, reads' in order to find only queries with multiple plans, sorted by the ones doing the most reads. The default second sort is CPU.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Other common parameters include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@Top = 10 - by default, you get 10 plans, but you can ask for more. Just know that the more you get, the slower it goes.&lt;/li&gt;
&lt;li&gt;@ExportToExcel = 1 - turn this on, and it doesn't return XML fields that would hinder you from copy/pasting the data into Excel.&lt;/li&gt;
&lt;li&gt;@ExpertMode = 1 - turn this on, and you get more columns with more data. Doesn't take longer to run though.&lt;/li&gt;
&lt;li&gt;@IgnoreSystemDBs = 0 - if you want to show queries in master/model/msdb. By default we hide these.&lt;/li&gt;
&lt;li&gt;@MinimumExecutionCount = 0 - in servers like data warehouses where lots of queries only run a few times, you can set a floor number for examination.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-advanced-sp_blitzcache-parameters" class="anchor" aria-hidden="true" href="#advanced-sp_blitzcache-parameters"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Advanced sp_BlitzCache Parameters&lt;/h3&gt;
&lt;p&gt;In addition to the &lt;a href="#parameters-common-to-many-of-the-stored-procedures"&gt;parameters common to many of the stored procedures&lt;/a&gt;, here are the ones specific to sp_BlitzCache:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OnlyQueryHashes - if you want to examine specific query plans, you can pass in a comma-separated list of them in a string.&lt;/li&gt;
&lt;li&gt;IgnoreQueryHashes - if you know some queries suck and you don't want to see them, you can pass in a comma-separated list of them.&lt;/li&gt;
&lt;li&gt;OnlySqlHandles, @IgnoreSqlHandles - just like the above two params&lt;/li&gt;
&lt;li&gt;@DatabaseName - if you only want to analyze plans in a single database. However, keep in mind that this is only the database context. A single query that runs in Database1 can join across objects in Database2 and Database3, but we can only know that it ran in Database1.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sp_blitzfirst-real-time-performance-advice" class="anchor" aria-hidden="true" href="#sp_blitzfirst-real-time-performance-advice"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;sp_BlitzFirst: Real-Time Performance Advice&lt;/h2&gt;
&lt;p&gt;When performance emergencies strike, this should be the first stored proc in the kit you run.&lt;/p&gt;
&lt;p&gt;It takes a sample from a bunch of DMVs (wait stats, Perfmon counters, plan cache), waits 5 seconds, and then takes another sample. It examines the differences between the samples, and then gives you a prioritized list of things that might be causing performance issues right now. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data or log file growing (or heaven forbid, shrinking)&lt;/li&gt;
&lt;li&gt;Backup or restore running&lt;/li&gt;
&lt;li&gt;DBCC operation happening&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If no problems are found, it'll tell you that too. That's one of our favorite features because you can have your help desk team run sp_BlitzFirst and read the output to you over the phone. If no problems are found, you can keep right on drinking at the bar. (Ha! Just kidding, you'll still have to close out your tab, but at least you'll feel better about finishing that drink rather than trying to sober up.)&lt;/p&gt;
&lt;p&gt;Common sp_BlitzFirst parameters include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@Seconds = 5 by default. You can specify longer samples if you want to track stats during a load test or demo, for example.&lt;/li&gt;
&lt;li&gt;@ShowSleepingSPIDs = 0 by default. When set to 1, shows long-running sleeping queries that might be blocking others.&lt;/li&gt;
&lt;li&gt;@ExpertMode = 0 by default. When set to 1, it calls sp_BlitzWho when it starts (to show you what queries are running right now), plus outputs additional result sets for wait stats, Perfmon counters, and file stats during the sample, then finishes with one final execution of sp_BlitzWho to show you what was running at the end of the sample.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-logging-sp_blitzfirst-to-tables" class="anchor" aria-hidden="true" href="#logging-sp_blitzfirst-to-tables"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Logging sp_BlitzFirst to Tables&lt;/h3&gt;
&lt;p&gt;You can log sp_BlitzFirst performance data to tables and then analyze the results with the Power BI dashboard. To do it, schedule an Agent job to run sp_BlitzFirst every 15 minutes with these parameters populated:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@OutputDatabaseName = typically 'DBAtools'&lt;/li&gt;
&lt;li&gt;@OutputSchemaName = 'dbo'&lt;/li&gt;
&lt;li&gt;@OutputTableName = 'BlitzFirst' - the quick diagnosis result set goes here&lt;/li&gt;
&lt;li&gt;@OutputTableNameFileStats = 'BlitzFirst_FileStats'&lt;/li&gt;
&lt;li&gt;@OutputTableNamePerfmonStats = 'BlitzFirst_PerfmonStats'&lt;/li&gt;
&lt;li&gt;@OutputTableNameWaitStats = 'BlitzFirst_WaitStats'&lt;/li&gt;
&lt;li&gt;@OutputTableNameBlitzCache = 'BlitzCache'&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of the above OutputTableName parameters are optional: if you don't want to collect all of the stats, you don't have to. Keep in mind that the sp_BlitzCache results will get large, fast, because each execution plan is megabytes in size.&lt;/p&gt;
&lt;p&gt;Then fire up the &lt;a href="https://www.brentozar.com/first-aid/first-responder-kit-power-bi-dashboard/" rel="nofollow"&gt;First Responder Kit Power BI dashboard.&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-logging-performance-tuning-activities" class="anchor" aria-hidden="true" href="#logging-performance-tuning-activities"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Logging Performance Tuning Activities&lt;/h3&gt;
&lt;p&gt;On the Power BI Dashboard, you can show lines for your own activities like tuning queries, adding indexes, or changing configuration settings. To do it, run sp_BlitzFirst with these parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@OutputDatabaseName = typically 'DBAtools'&lt;/li&gt;
&lt;li&gt;@OutputSchemaName = 'dbo'&lt;/li&gt;
&lt;li&gt;@OutputTableName = 'BlitzFirst' - the quick diagnosis result set goes here&lt;/li&gt;
&lt;li&gt;@LogMessage = 'Whatever you wanna show in the Power BI dashboard'&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Optionally, you can also pass in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@LogMessagePriority = 1&lt;/li&gt;
&lt;li&gt;@LogMessageFindingsGroup = 'Logged Message'&lt;/li&gt;
&lt;li&gt;@LogMessageFinding = 'Logged from sp_BlitzFirst' - you could use other values here to track other data sources like DDL triggers, Agent jobs, ETL jobs&lt;/li&gt;
&lt;li&gt;@LogMessageURL = '&lt;a href="https://OurHelpDeskSystem/ticket/?12345" rel="nofollow"&gt;https://OurHelpDeskSystem/ticket/?12345&lt;/a&gt;' - or maybe a Github issue, or Pagerduty alert&lt;/li&gt;
&lt;li&gt;@LogMessageCheckDate = '2017/10/31 11:00' - in case you need to log a message for a prior date/time, like if you forgot to log the message earlier&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sp_blitzindex-tune-your-indexes" class="anchor" aria-hidden="true" href="#sp_blitzindex-tune-your-indexes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;sp_BlitzIndex: Tune Your Indexes&lt;/h2&gt;
&lt;p&gt;SQL Server tracks your indexes: how big they are, how often they change, whether they're used to make queries go faster, and which indexes you should consider adding. The results columns are fairly self-explanatory.&lt;/p&gt;
&lt;p&gt;By default, sp_BlitzIndex analyzes the indexes of the database you're in (your current context.)&lt;/p&gt;
&lt;p&gt;Common parameters include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@DatabaseName - if you want to analyze a specific database&lt;/li&gt;
&lt;li&gt;@SchemaName, @TableName - if you pass in these, sp_BlitzIndex does a deeper-dive analysis of just one table. You get several result sets back describing more information about the table's current indexes, foreign key relationships, missing indexes, and fields in the table.&lt;/li&gt;
&lt;li&gt;@GetAllDatabases = 1 - slower, but lets you analyze all the databases at once, up to 50. If you want more than 50 databases, you also have to pass in @BringThePain = 1.&lt;/li&gt;
&lt;li&gt;@ThresholdMB = 250 - by default, we only analyze objects over 250MB because you're busy.&lt;/li&gt;
&lt;li&gt;@Mode = 0 (default) - get different data with 0=Diagnose, 1=Summarize, 2=Index Usage Detail, 3=Missing Index Detail, 4=Diagnose Details.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-advanced-sp_blitzindex-parameters" class="anchor" aria-hidden="true" href="#advanced-sp_blitzindex-parameters"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Advanced sp_BlitzIndex Parameters&lt;/h3&gt;
&lt;p&gt;In addition to the &lt;a href="#parameters-common-to-many-of-the-stored-procedures"&gt;parameters common to many of the stored procedures&lt;/a&gt;, here are the ones specific to sp_BlitzIndex:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@SkipPartitions = 1 - add this if you want to analyze large partitioned tables. We skip these by default for performance reasons.&lt;/li&gt;
&lt;li&gt;@SkipStatistics = 0 - right now, by default, we skip statistics analysis because we've had some performance issues on this.&lt;/li&gt;
&lt;li&gt;@Filter = 0 (default) - 1=No low-usage warnings for objects with 0 reads. 2=Only warn for objects &amp;gt;= 500MB&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sp_blitzinmemoryoltp-hekaton-analysis" class="anchor" aria-hidden="true" href="#sp_blitzinmemoryoltp-hekaton-analysis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;sp_BlitzInMemoryOLTP: Hekaton Analysis&lt;/h2&gt;
&lt;p&gt;Examines your usage of In-Memory OLTP tables. Parameters you can use:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@instanceLevelOnly BIT: This flag determines whether or not to simply report on the server-level environment (if applicable, i.e. there is no server-level environment for Azure SQL Database). With this parameter, memory-optimized databases are ignored. If you specify @instanceLevelOnly and a database name, the database name is ignored.&lt;/li&gt;
&lt;li&gt;@dbName NVARCHAR(4000) = N'ALL' - If you don't specify a database name, then sp_BlitzInMemoryOLTP reports on all memory-optimized databases within the instance that it executes in, or in the case of Azure SQL Database, the database that you provisioned. This is because the default for the @dbName parameter is N'ALL'.&lt;/li&gt;
&lt;li&gt;@tableName NVARCHAR(4000) = NULL&lt;/li&gt;
&lt;li&gt;@debug BIT&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To interpret the output of this stored procedure, read &lt;a href="http://nedotter.com/archive/2018/06/new-kid-on-the-block-sp_blitzinmemoryoltp/" rel="nofollow"&gt;Ned Otter's sp_BlitzInMemoryOLTP documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sp_blitzlock-deadlock-analysis" class="anchor" aria-hidden="true" href="#sp_blitzlock-deadlock-analysis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;sp_BlitzLock: Deadlock Analysis&lt;/h2&gt;
&lt;p&gt;Checks either the System Health session or a specific Extended Event session that captures deadlocks and parses out all the XML for you.&lt;/p&gt;
&lt;p&gt;Parameters you can use:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@Top: Use if you want to limit the number of deadlocks to return. This is ordered by event date ascending.&lt;/li&gt;
&lt;li&gt;@DatabaseName: If you want to filter to a specific database&lt;/li&gt;
&lt;li&gt;@StartDate: The date you want to start searching on.&lt;/li&gt;
&lt;li&gt;@EndDate: The date you want to stop searching on.&lt;/li&gt;
&lt;li&gt;@ObjectName: If you want to filter to a specific table. The object name has to be fully qualified 'Database.Schema.Table'&lt;/li&gt;
&lt;li&gt;@StoredProcName: If you want to search for a single stored proc.&lt;/li&gt;
&lt;li&gt;@AppName: If you want to filter to a specific application.&lt;/li&gt;
&lt;li&gt;@HostName: If you want to filter to a specific host.&lt;/li&gt;
&lt;li&gt;@LoginName: If you want to filter to a specific login.&lt;/li&gt;
&lt;li&gt;@EventSessionPath: If you want to point this at an XE session rather than the system health session.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sp_blitzquerystore-query-store-sale" class="anchor" aria-hidden="true" href="#sp_blitzquerystore-query-store-sale"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;sp_BlitzQueryStore: Query Store Sale&lt;/h2&gt;
&lt;p&gt;Analyzes data in Query Store schema (2016+ only) in many similar ways to what sp_BlitzCache does for the plan cache.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@Help: Right now this just prints the license if set to 1. I'm going to add better documentation here as the script matures.&lt;/li&gt;
&lt;li&gt;@DatabaseName: This one is required. Query Store is per database, so you have to point it at one to examine.&lt;/li&gt;
&lt;li&gt;@Top: How many plans from each "worst" you want to get. We look at your maxes for CPU, reads, duration, writes, memory, rows, executions, and additionally tempdb and log bytes for 2017. So it's the number of plans from each of those to gather.&lt;/li&gt;
&lt;li&gt;@StartDate: Fairly obvious, when you want to start looking at queries from. If NULL, we'll only go back seven days.&lt;/li&gt;
&lt;li&gt;@EndDate: When you want to stop looking at queries from. If you leave it NULL, we'll look ahead seven days.&lt;/li&gt;
&lt;li&gt;@MinimumExecutionCount: The minimum number of times a query has to have been executed (not just compiled) to be analyzed.&lt;/li&gt;
&lt;li&gt;@DurationFilter: The minimum number of seconds a query has to have been executed for to be analyzed.&lt;/li&gt;
&lt;li&gt;@StoredProcName: If you want to look at a single stored procedure.&lt;/li&gt;
&lt;li&gt;@Failed: If you want to look at failed queries, for some reason. I dunno, MS made such a big deal out of being able to look at these, I figured I'd add it.&lt;/li&gt;
&lt;li&gt;@PlanIdFilter: If you want to filter by a particular plan id. Remember that a query may have many different plans.&lt;/li&gt;
&lt;li&gt;@QueryIdFilter: If you want to filter by a particular query id. If you want to look at one specific plan for a query.&lt;/li&gt;
&lt;li&gt;@ExportToExcel: Leaves XML out of the input and tidies up query text so you can easily paste it into Excel.&lt;/li&gt;
&lt;li&gt;@HideSummary: Pulls the rolled up warnings and information out of the results.&lt;/li&gt;
&lt;li&gt;@SkipXML: Skips XML analysis.&lt;/li&gt;
&lt;li&gt;@Debug: Prints dynamic SQL and selects data from all temp tables if set to 1.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sp_blitzwho-what-queries-are-running-now" class="anchor" aria-hidden="true" href="#sp_blitzwho-what-queries-are-running-now"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;sp_BlitzWho: What Queries are Running Now&lt;/h2&gt;
&lt;p&gt;This is like sp_who, except it goes into way, way, way more details.&lt;/p&gt;
&lt;p&gt;It's designed for query tuners, so it includes things like memory grants, degrees of parallelism, and execution plans.&lt;/p&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sp_blitzbackups-how-much-data-could-you-lose" class="anchor" aria-hidden="true" href="#sp_blitzbackups-how-much-data-could-you-lose"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;sp_BlitzBackups: How Much Data Could You Lose&lt;/h2&gt;
&lt;p&gt;Checks your backups and reports estimated RPO and RTO based on historical data in msdb, or a centralized location for [msdb].dbo.backupset.&lt;/p&gt;
&lt;p&gt;Parameters include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;@HoursBack -- How many hours into backup history you want to go. Should be a negative number (we're going back in time, after all). But if you enter a positive number, we'll make it negative for you. You're welcome.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;@MSDBName -- if you need to prefix dbo.backupset with an alternate database name.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;@AGName -- If you have more than 1 AG on the server, and you don't know the listener name, specify the name of the AG you want to use the listener for, to push backup data. This may get used during analysis in a future release for filtering.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;@RestoreSpeedFullMBps --[FIXFIX] Brent can word this better than I can&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;@RestoreSpeedDiffMBps -- Nothing yet&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;@RestoreSpeedLogMBps -- Nothing yet&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;@PushBackupHistoryToListener -- Turn this to 1 to skip analysis and use sp_BlitzBackups to push backup data from msdb to a centralized location (more the mechanics of this to follow)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;@WriteBackupsToListenerName -- This is the name of the AG listener, and &lt;strong&gt;MUST&lt;/strong&gt; have a linked server configured pointing to it. Yes, that means you need to create a linked server that points to the AG Listener, with the appropriate permissions to write data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;@WriteBackupsToDatabaseName -- This can't be 'msdb' if you're going to use the backup data pushing mechanism. We can't write to your actual msdb tables.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;@WriteBackupsLastHours -- How many hours in the past you want to move data for. Should be a negative number (we're going back in time, after all). But if you enter a positive number, we'll make it negative for you. You're welcome.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An example run of sp_BlitzBackups to push data looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;EXEC sp_BlitzBackups    @PushBackupHistoryToListener = 1, -- Turn it on!
                        @WriteBackupsToListenerName = 'AG_LISTENER_NAME', -- Name of AG Listener and Linked Server 
                        @WriteBackupsToDatabaseName = 'FAKE_MSDB_NAME',  -- Fake MSDB name you want to push to. Remember, can't be real MSDB.
                        @WriteBackupsLastHours = -24 -- Hours back in time you want to go
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In an effort to not clog your servers up, we've taken some care in batching things as we move data. Inspired by &lt;a href="http://michaeljswart.com/2014/09/take-care-when-scripting-batches/" rel="nofollow"&gt;Michael J. Swart's Take Care When Scripting Batches&lt;/a&gt;, we only move data in 10 minute intervals.&lt;/p&gt;
&lt;p&gt;The reason behind that is, if you have 500 databases, and you're taking log backups every minute, you can have a lot of data to move. A 5000 row batch should move pretty quickly.&lt;/p&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sp_allnightlog-back-up-faster-to-lose-less-data" class="anchor" aria-hidden="true" href="#sp_allnightlog-back-up-faster-to-lose-less-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;sp_AllNightLog: Back Up Faster to Lose Less Data&lt;/h2&gt;
&lt;p&gt;You manage a SQL Server instance with hundreds or thousands of mission-critical databases. You want to back them all up as quickly as possible, and one maintenance plan job isn't going to cut it.&lt;/p&gt;
&lt;p&gt;Let's scale out our backup jobs by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Creating a table with a list of databases and their desired Recovery Point Objective (RPO, aka data loss) - done with sp_AllNightLog_Setup&lt;/li&gt;
&lt;li&gt;Set up several Agent jobs to back up databases as necessary - also done with sp_AllNightLog_Setup&lt;/li&gt;
&lt;li&gt;Inside each of those Agent jobs, they call sp_AllNightLog @Backup = 1, which loops through the table to find databases that need to be backed up, then call &lt;a href="https://ola.hallengren.com/" rel="nofollow"&gt;Ola Hallengren's DatabaseBackup stored procedure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Keeping that database list up to date as new databases are added - done by a job calling sp_AllNightLog @PollForNewDatabases = 1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information about how this works, see &lt;a href="https://www.BrentOzar.com/sp_AllNightLog" rel="nofollow"&gt;sp_AllNightLog documentation.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Known issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The msdbCentral database name is hard-coded.&lt;/li&gt;
&lt;li&gt;sp_AllNightLog depends on Ola Hallengren's DatabaseBackup, which must be installed separately. (We're not checking for it right now.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sp_databaserestore-easier-multi-file-restores" class="anchor" aria-hidden="true" href="#sp_databaserestore-easier-multi-file-restores"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;sp_DatabaseRestore: Easier Multi-File Restores&lt;/h2&gt;
&lt;p&gt;If you use &lt;a href="http://ola.hallengren.com" rel="nofollow"&gt;Ola Hallengren's backup scripts&lt;/a&gt;, DatabaseRestore.sql helps you rapidly restore a database to the most recent point in time.&lt;/p&gt;
&lt;p&gt;Parameters include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@Database - the database's name, like LogShipMe&lt;/li&gt;
&lt;li&gt;@RestoreDatabaseName&lt;/li&gt;
&lt;li&gt;@BackupPathFull - typically a UNC path like '\FILESERVER\BACKUPS\SQL2016PROD1A\LogShipMe\FULL' that points to where the full backups are stored. Note that if the path doesn't exist, we don't create it, and the query might take 30+ seconds if you specify an invalid server name.&lt;/li&gt;
&lt;li&gt;@BackupPathDiff, @BackupPathLog - as with the Full, this should be set to the exact path where the differentials and logs are stored. We don't append anything to these parameters.&lt;/li&gt;
&lt;li&gt;@MoveFiles, @MoveDataDrive, @MoveLogDrive - if you want to restore to somewhere other than your default database locations.&lt;/li&gt;
&lt;li&gt;@RunCheckDB - default 0. When set to 1, we run Ola Hallengren's DatabaseIntegrityCheck stored procedure on this database, and log the results to table. We use that stored proc's default parameters, nothing fancy.&lt;/li&gt;
&lt;li&gt;@TestRestore - default 0. When set to 1, we delete the database after the restore completes. Used for just testing your restores. Especially useful in combination with @RunCheckDB = 1 because we'll delete the database after running checkdb, but know that we delete the database even if it fails checkdb tests.&lt;/li&gt;
&lt;li&gt;@RestoreDiff - default 0. When set to 1, we restore the ncessary full, differential, and log backups (instead of just full and log) to get to the most recent point in time.&lt;/li&gt;
&lt;li&gt;@ContinueLogs - default 0. When set to 1, we don't restore a full or differential backup - we only restore the transaction log backups. Good for continuous log restores with tools like sp_AllNightLog.&lt;/li&gt;
&lt;li&gt;@RunRecovery - default 0. When set to 1, we run RESTORE WITH RECOVERY, putting the database into writable mode, and no additional log backups can be restored.&lt;/li&gt;
&lt;li&gt;@ExistingDBAction - if the database already exists when we try to restore it, 1 sets the database to single user mode, 2 kills the connections, and 3 kills the connections and then drops the database.&lt;/li&gt;
&lt;li&gt;@Debug - default 0. When 1, we print out messages of what we're doing in the messages tab of SSMS.&lt;/li&gt;
&lt;li&gt;@StopAt NVARCHAR(14) - pass in a date time to stop your restores at a time like '20170508201501'. This doesn't use the StopAt parameter for the restore command - it simply stops restoring logs that would have this date/time's contents in it. (For example, if you're taking backups every 15 minutes on the hour, and you pass in 9:05 AM as part of the restore time, the restores would stop at your last log backup that doesn't include 9:05AM's data - but it won't restore right up to 9:05 AM.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For information about how this works, see &lt;a href="https://BrentOzar.com/go/gce" rel="nofollow"&gt;Tara Kizer's white paper on Log Shipping 2.0 with Google Compute Engine.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-parameters-common-to-many-of-the-stored-procedures" class="anchor" aria-hidden="true" href="#parameters-common-to-many-of-the-stored-procedures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Parameters Common to Many of the Stored Procedures&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;@Help = 1 - returns a result set or prints messages explaining the stored procedure's input and output. Make sure to check the Messages tab in SSMS to read it.&lt;/li&gt;
&lt;li&gt;@ExpertMode = 1 - turns on more details useful for digging deeper into results.&lt;/li&gt;
&lt;li&gt;@OutputDatabaseName, @OutputSchemaName, @OutputTableName - pass all three of these in, and the stored proc's output will be written to a table. We'll create the table if it doesn't already exist.&lt;/li&gt;
&lt;li&gt;@OutputServerName - not functional yet. To track (or help!) implementation status: &lt;a href="https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit/issues/293"&gt;https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit/issues/293&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a href="LICENSE.md"&gt;The SQL Server First Responder Kit uses the MIT License.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="#header1"&gt;&lt;em&gt;Back to top&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>BrentOzarULTD</author><guid isPermaLink="false">https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit</guid><pubDate>Tue, 12 Nov 2019 00:01:00 GMT</pubDate></item><item><title>confluentinc/examples #2 in TSQL, This week</title><link>https://github.com/confluentinc/examples</link><description>&lt;p&gt;&lt;i&gt;Apache Kafka and Confluent Platform examples and demos&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/confluent-logo-300-2.png"&gt;&lt;img src="images/confluent-logo-300-2.png" alt="image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#demos"&gt;Demos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#build-your-own"&gt;Build Your Own&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#prerequisites"&gt;Prerequisities&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-demos" class="anchor" aria-hidden="true" href="#demos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Demos&lt;/h1&gt;
&lt;p&gt;This is a curated list of demos that showcase Apache Kafka® event stream processing on the Confluent Platform, an event stream processing platform that enables you to process, organize, and manage massive amounts of streaming data across cloud, on-prem, and serverless deployments.&lt;/p&gt;
&lt;p align="center"&gt;
&lt;a href="http://www.youtube.com/watch?feature=player_embedded&amp;amp;v=muQBd6gry0U" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8e17faff18bb34cc8d875916226fc1be5e400bea/687474703a2f2f696d672e796f75747562652e636f6d2f76692f6d755142643667727930552f302e6a7067" width="360" height="270" border="10" data-canonical-src="http://img.youtube.com/vi/muQBd6gry0U/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-where-to-start" class="anchor" aria-hidden="true" href="#where-to-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Where to start&lt;/h2&gt;
&lt;p&gt;The best demo to start with is &lt;a href="https://github.com/confluentinc/cp-demo"&gt;cp-demo&lt;/a&gt; which spins up a Kafka event streaming application using KSQL for stream processing, with many security features enabled, in an end-to-end streaming ETL pipeline with a source connector pulling from live IRC channels and a sink connector connecting to Elasticsearch and Kibana for visualizations.
&lt;code&gt;cp-demo&lt;/code&gt; also comes with a playbook and is a great configuration reference for Confluent Platform.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-full-demo-list" class="anchor" aria-hidden="true" href="#full-demo-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Full demo list&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#confluent-cloud"&gt;Confluent Cloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#stream-processing"&gt;Stream Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data-pipelines"&gt;Data Pipelines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#confluent-platform"&gt;Confluent Platform&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-confluent-cloud" class="anchor" aria-hidden="true" href="#confluent-cloud"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Confluent Cloud&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Demo&lt;/th&gt;
&lt;th&gt;Local&lt;/th&gt;
&lt;th&gt;Docker&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="ccloud/beginner-cloud/README.md"&gt;Beginner Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Fully scripted demo that shows how to interact with your Confluent Cloud cluster and set ACLs using the CLI &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="clients/cloud/images/confluent-cloud.jpeg"&gt;&lt;img src="clients/cloud/images/confluent-cloud.jpeg" width="400" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="clients/cloud/README.md"&gt;Clients to Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="clients/cloud/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Client applications in different programming languages connecting to &lt;a href="https://www.confluent.io/confluent-cloud/" rel="nofollow"&gt;Confluent Cloud&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="clients/cloud/images/clients-all.png"&gt;&lt;img src="clients/cloud/images/clients-all.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/gcp-pipeline/README.adoc"&gt;GCP pipeline&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/gcp-pipeline/README.adoc"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Work with &lt;a href="https://www.confluent.io/confluent-cloud/" rel="nofollow"&gt;Confluent Cloud&lt;/a&gt; to build cool pipelines into Google Cloud Platform (GCP) &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/confluentinc/demo-scene/blob/master/gcp-pipeline/images/env-data-arch-01.png"&gt;&lt;img src="https://github.com/confluentinc/demo-scene/raw/master/gcp-pipeline/images/env-data-arch-01.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="kinesis-cloud/README.md"&gt;Kinesis to Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="kinesis-cloud/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;AWS Kinesis -&amp;gt; Confluent Cloud -&amp;gt; Google Cloud Storage pipeline &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="kinesis-cloud/images/topology.jpg"&gt;&lt;img src="kinesis-cloud/images/topology.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="ccloud/README.md"&gt;On-Prem Kafka to Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="ccloud/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="ccloud/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;This more advanced demo showcases an on-prem Kafka cluster and &lt;a href="https://www.confluent.io/confluent-cloud/" rel="nofollow"&gt;Confluent Cloud&lt;/a&gt; cluster, and data copied between them with Confluent Replicator &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="ccloud/docs/images/schema-registry-local.jpg"&gt;&lt;img src="ccloud/docs/images/schema-registry-local.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-stream-processing" class="anchor" aria-hidden="true" href="#stream-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stream Processing&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Demo&lt;/th&gt;
&lt;th&gt;Local&lt;/th&gt;
&lt;th&gt;Docker&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="clickstream/README.md"&gt;Clickstream&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="clickstream/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.confluent.io/current/ksql/docs/tutorials/clickstream-docker.html#ksql-clickstream-docker" rel="nofollow"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Automated version of the &lt;a href="https://docs.confluent.io/current/ksql/docs/tutorials/clickstream-docker.html#ksql-clickstream-docker" rel="nofollow"&gt;KSQL clickstream demo&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/28e9212ca11ed82e4015367f81b89bec3e61f107/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f67726166616e612d737563636573732e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/28e9212ca11ed82e4015367f81b89bec3e61f107/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f67726166616e612d737563636573732e706e67" width="450" data-canonical-src="https://docs.confluent.io/current/_images/grafana-success.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://kafka-tutorials.confluent.io" rel="nofollow"&gt;Kafka Tutorials&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://kafka-tutorials.confluent.io" rel="nofollow"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://kafka-tutorials.confluent.io" rel="nofollow"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Collection of common event streaming use cases, with each tutorial featuring an example scenario and several complete code solutions &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a8588b0e07ad402e01e0e1f355a840c3717fb7cd/68747470733a2f2f63646e2e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f4b61666b612d5475746f7269616c732d333530783139352e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/a8588b0e07ad402e01e0e1f355a840c3717fb7cd/68747470733a2f2f63646e2e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f4b61666b612d5475746f7269616c732d333530783139352e6a7067" width="350" data-canonical-src="https://cdn.confluent.io/wp-content/uploads/Kafka-Tutorials-350x195.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/ksql-udf-advanced-example/README.md"&gt;KSQL UDF&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/ksql-udf-advanced-example/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Advanced &lt;a href="https://www.confluent.io/blog/build-udf-udaf-ksql-5-0" rel="nofollow"&gt;KSQL User-Defined Function (UDF)&lt;/a&gt; use case for connected cars &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fcb649b2d1a60911f393cc63738cdcb5c0710d73/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f4b53514c2d312d333530783139352e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/fcb649b2d1a60911f393cc63738cdcb5c0710d73/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f4b53514c2d312d333530783139352e706e67" width="350" data-canonical-src="https://www.confluent.io/wp-content/uploads/KSQL-1-350x195.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/ksql-workshop/"&gt;KSQL workshop&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/ksql-workshop/"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;showcases Kafka event stream processing using KSQL and can run self-guided as a KSQL workshop &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/confluentinc/demo-scene/blob/master/ksql-workshop/images/ksql_workshop_01.png"&gt;&lt;img src="https://github.com/confluentinc/demo-scene/raw/master/ksql-workshop/images/ksql_workshop_01.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="microservices-orders/README.md"&gt;Microservices ecosystem&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="microservices-orders/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/kafka-streams-examples/tree/5.2.2-post/src/main/java/io/confluent/examples/streams/microservices"&gt;Microservices orders Demo Application&lt;/a&gt; integrated into the Confluent Platform &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="microservices-orders/docs/images/microservices-demo.jpg"&gt;&lt;img src="microservices-orders/docs/images/microservices-demo.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="music/README.md"&gt;Music demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="music/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="music/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;KSQL version of the &lt;a href="https://docs.confluent.io/current/streams/kafka-streams-examples/docs/index.html" rel="nofollow"&gt;Kafka Streams Demo Application&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="music/images/ksql-music-demo-overview.jpg"&gt;&lt;img src="music/images/ksql-music-demo-overview.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-data-pipelines" class="anchor" aria-hidden="true" href="#data-pipelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Pipelines&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Demo&lt;/th&gt;
&lt;th&gt;Local&lt;/th&gt;
&lt;th&gt;Docker&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/no-more-silos/demo_no-more-silos.adoc"&gt;CDC with MySQL&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/no-more-silos/demo_no-more-silos.adoc"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Self-paced steps to set up a change data capture (CDC) pipeline &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b9dbae7351f1813eb87dac08d7726b9554b891a2/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6b61666b615f636f6e6e6563742d312e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/b9dbae7351f1813eb87dac08d7726b9554b891a2/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6b61666b615f636f6e6e6563742d312e706e67" width="450" data-canonical-src="https://www.confluent.io/wp-content/uploads/kafka_connect-1.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="postgres-debezium-ksql-elasticsearch/README.md"&gt;CDC with Postgres&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="postgres-debezium-ksql-elasticsearch/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Enrich event stream data with CDC data from Postgres and then stream into Elasticsearch &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="postgres-debezium-ksql-elasticsearch/images/ksql-debezium-es.png"&gt;&lt;img src="postgres-debezium-ksql-elasticsearch/images/ksql-debezium-es.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="connect-streams-pipeline/README.md"&gt;Connect and Kafka Streams&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="connect-streams-pipeline/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Demonstrate various ways, with and without Kafka Connect, to get data into Kafka topics and then loaded for use by the Kafka Streams API &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="connect-streams-pipeline/images/blog_connect_streams_diag.jpg"&gt;&lt;img src="connect-streams-pipeline/images/blog_connect_streams_diag.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/mqtt-connect-connector-demo/README.md"&gt;MQTT&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/mqtt-connect-connector-demo/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Internet of Things (IoT) integration example using Apache Kafka + Kafka Connect + MQTT Connector + Sensor Data &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/80c360e482a98ae2311869d0cedc5ef984821eee/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6477675f4d5154542e737667"&gt;&lt;img src="https://camo.githubusercontent.com/80c360e482a98ae2311869d0cedc5ef984821eee/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6477675f4d5154542e737667" width="450" data-canonical-src="https://www.confluent.io/wp-content/uploads/dwg_MQTT.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="mysql-debezium/README.md"&gt;MySQL and Debezium&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="mysql-debezium/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/tree/master/build-a-streaming-pipeline"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;End-to-end streaming ETL with KSQL for stream processing using the &lt;a href="http://debezium.io/docs/connectors/mysql/" rel="nofollow"&gt;Debezium Connector for MySQL&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="mysql-debezium/images/ksql-debezium-es.png"&gt;&lt;img src="mysql-debezium/images/ksql-debezium-es.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/tree/master/syslog"&gt;Syslog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Real-time syslog processing with Apache Kafka and KSQL: filtering logs, event-driven alerting, and enriching events &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6436ef9d9bca4eaa9d300c713fee0e4be6db8ee6/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6b73716c5f7379736c6f6730312d31303234783235382e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/6436ef9d9bca4eaa9d300c713fee0e4be6db8ee6/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6b73716c5f7379736c6f6730312d31303234783235382e706e67" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-confluent-platform" class="anchor" aria-hidden="true" href="#confluent-platform"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Confluent Platform&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Demo&lt;/th&gt;
&lt;th&gt;Local&lt;/th&gt;
&lt;th&gt;Docker&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="clients/README.md"&gt;Avro&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="clients/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Client applications using Avro and Confluent Schema Registry &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/92ad363b0e5811b5935c9dc81c37845d9273a0b7/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6477675f536368656d615265675f686f776974776f726b732e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/92ad363b0e5811b5935c9dc81c37845d9273a0b7/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6477675f536368656d615265675f686f776974776f726b732e706e67" width="420" data-canonical-src="https://www.confluent.io/wp-content/uploads/dwg_SchemaReg_howitworks.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="wikipedia/README.md"&gt;CP Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="wikipedia/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/cp-demo"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.confluent.io/current/tutorials/cp-demo/docs/index.html" rel="nofollow"&gt;Confluent Platform demo&lt;/a&gt; with a playbook for Kafka event streaming ETL deployments &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/confluentinc/cp-demo/blob/5.3.0-post/docs/images/drawing.png"&gt;&lt;img src="https://github.com/confluentinc/cp-demo/raw/5.3.0-post/docs/images/drawing.png" width="420" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="kubernetes/README.md"&gt;Kubernetes&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="kubernetes/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Demonstrations of Confluent Platform deployments using the  &lt;a href="https://docs.confluent.io/current/installation/operator/index.html" rel="nofollow"&gt;Confluent Operator&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="kubernetes/gke-base/docs/images/operator.png"&gt;&lt;img src="kubernetes/gke-base/docs/images/operator.png" width="420" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="multi-datacenter/README.md"&gt;Multi Datacenter&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="multi-datacenter/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Active-active multi-datacenter design with two instances of Confluent Replicator copying data bidirectionally between the datacenters &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/c0090d428178db34693591175b730b27450002ad/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f6d64632d6c6576656c2d312e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/c0090d428178db34693591175b730b27450002ad/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f6d64632d6c6576656c2d312e706e67" width="420" data-canonical-src="https://docs.confluent.io/current/_images/mdc-level-1.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="cp-quickstart/README.md"&gt;Quickstart&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="cp-quickstart/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.confluent.io/current/quickstart/ce-docker-quickstart.html#ce-docker-quickstart" rel="nofollow"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Automated version of the &lt;a href="https://docs.confluent.io/current/quickstart.html" rel="nofollow"&gt;Confluent Platform Quickstart&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/494b6bf1a80993311d29232f17064ab180ebe677/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f636f6e666c75656e74506c6174666f726d2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/494b6bf1a80993311d29232f17064ab180ebe677/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f636f6e666c75656e74506c6174666f726d2e706e67" width="420" data-canonical-src="https://docs.confluent.io/current/_images/confluentPlatform.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="security/rbac/README.md"&gt;Role-Based Access Control&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Role-based Access Control (RBAC) provides granular privileges for users and service accounts &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/33dd1276d7e43660810d10a9d0997502fe22a623/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f726261632d6f766572766965772e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/33dd1276d7e43660810d10a9d0997502fe22a623/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f726261632d6f766572766965772e706e67" width="450" data-canonical-src="https://docs.confluent.io/current/_images/rbac-overview.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="security/secret-protection/README.adoc"&gt;Secret Protection&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Secret Protection feature encrypts secrets in configuration files &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/90888c033d0e611f7b73c5df261a109ead6858a1/68747470733a2f2f63646e2e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f5365637265745f50726f74656374696f6e5f466561747572652e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/90888c033d0e611f7b73c5df261a109ead6858a1/68747470733a2f2f63646e2e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f5365637265745f50726f74656374696f6e5f466561747572652e6a7067" width="400" data-canonical-src="https://cdn.confluent.io/wp-content/uploads/Secret_Protection_Feature.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="replicator-security/README.md"&gt;Replicator Security&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="replicator-security/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Demos of various security configurations supported by Confluent Replicator and examples of how to implement them &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/replicator-security.png"&gt;&lt;img src="images/replicator-security.png" width="300" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-build-your-own" class="anchor" aria-hidden="true" href="#build-your-own"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Build Your Own&lt;/h1&gt;
&lt;p&gt;As a next step, you may want to build your own custom demo or test environment.
We have several resources that launch just the services in Confluent Platform with no pre-configured connectors, data sources, topics, schemas, etc.
Using these as a foundation, you can then add any connectors or applications.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="cp-all-in-one/README.md"&gt;cp-all-in-one&lt;/a&gt;: This Docker Compose file launches all services in Confluent Platform, and runs them in containers in your local host.&lt;/li&gt;
&lt;li&gt;&lt;a href="cp-all-in-one-cloud/README.md"&gt;cp-all-in-one-cloud&lt;/a&gt;: Use this with your pre-configured Confluent Cloud instance. This Docker Compose file launches all services in Confluent Platform (except for the Kafka brokers), runs them in containers in your local host, and automatically configures them to connect to Confluent Cloud.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.confluent.io/current/cli/index.html" rel="nofollow"&gt;Confluent CLI&lt;/a&gt;: For local, non-Docker installs of Confluent Platform. Using this CLI, you can launch all services in Confluent Platform with just one command &lt;code&gt;confluent local start&lt;/code&gt;, and they will all run on your local host.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.confluent.io/blog/easy-ways-generate-test-data-kafka" rel="nofollow"&gt;Generate test data&lt;/a&gt;: "Hello, World!" for launching Confluent Platform, plus different ways to generate more interesting test data for your topics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additional documentation: &lt;a href="https://docs.confluent.io/current/getting-started.html" rel="nofollow"&gt;Getting Started&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prerequisites&lt;/h1&gt;
&lt;p&gt;For local installs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download &lt;a href="https://www.confluent.io/download/" rel="nofollow"&gt;Confluent Platform 5.3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Env var &lt;code&gt;CONFLUENT_HOME=/path/to/confluentplatform&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Env var &lt;code&gt;PATH&lt;/code&gt; includes &lt;code&gt;$CONFLUENT_HOME/bin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Each demo has its own set of prerequisites as well, documented individually in each demo&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For Docker: demos have been validated with&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.docker.com/install/" rel="nofollow"&gt;Docker&lt;/a&gt; version 17.06.1-ce&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.docker.com/compose/install/" rel="nofollow"&gt;Docker Compose&lt;/a&gt; version 1.14.0 with Docker Compose file format 2.1&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>confluentinc</author><guid isPermaLink="false">https://github.com/confluentinc/examples</guid><pubDate>Tue, 12 Nov 2019 00:02:00 GMT</pubDate></item><item><title>MicrosoftLearning/DP-200-Implementing-an-Azure-Data-Solution #3 in TSQL, This week</title><link>https://github.com/MicrosoftLearning/DP-200-Implementing-an-Azure-Data-Solution</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-dp-200-implementing-an-azure-data-solution" class="anchor" aria-hidden="true" href="#dp-200-implementing-an-azure-data-solution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DP-200-Implementing-an-Azure-Data-Solution&lt;/h1&gt;
&lt;p&gt;During this course, the first and the last lab of the course are group exercises that involve discussion to help provide context for the labs that the students will take. The last lab provides the opportunity for the students to reflect on what they have achieved and what they have overcome to achieve the delivery of requirements from the case study in the labs. The rest of the labs are hands on implementing Azure data platform capabilities to meet AdventureWorks business requirements.&lt;/p&gt;
&lt;p&gt;The following is a summary of the lab objectives for each module:&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-1---azure-for-the-data-engineer" class="anchor" aria-hidden="true" href="#lab-1---azure-for-the-data-engineer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 1 - Azure for the Data Engineer&lt;/h2&gt;
&lt;p&gt;The students will take the information gained in the lessons and from the case study to scope out the deliverables for a digital transformation project within AdventureWorks. They will first identify how the evolving use of data has presented new opportunities for the organization. The students will also explore which Azure Data Platform services can be used to address the business needs and define the tasks that will be performed by the data engineer. Finally, students will finalize the data engineering deliverables for AdventureWorks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-2---working-with-data-storage" class="anchor" aria-hidden="true" href="#lab-2---working-with-data-storage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 2 - Working with Data Storage&lt;/h2&gt;
&lt;p&gt;In this lab, the students will be able to determine the appropriate storage type to implement against a given set of business and technical requirements. They will be able to create Azure storage accounts and Data Lake Storage account and explain the difference between Data Lake Storage version 1 and version 2. They will also be able to demonstrate how to perform data loads into the data storage of choice.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-3---enabling-team-based-data-science-with-azure-databricks" class="anchor" aria-hidden="true" href="#lab-3---enabling-team-based-data-science-with-azure-databricks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 3 - Enabling Team Based Data Science with Azure Databricks&lt;/h2&gt;
&lt;p&gt;By the end of this lab the student will be able to explain why Azure Databricks can be used to help in Data Science projects. The students will provision and Azure Databricks instance and will then create a workspace that will be used to perform a simple data preparation task from a Data Lake Store Gen II store. Finally, the student will perform a walk-through of performing transformations using Azure Databricks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-4---building-globally-distributed-databases-with-cosmos-db" class="anchor" aria-hidden="true" href="#lab-4---building-globally-distributed-databases-with-cosmos-db"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 4 - Building Globally Distributed Databases with Cosmos DB&lt;/h2&gt;
&lt;p&gt;The students will be able to describe and demonstrate the capabilities that Azure Cosmos DB can bring to an organization. They will be able to create a Cosmos DB instance and show how to upload and query data through a portal and through a .Net application. They will then be able to demonstrate how to enable global scale of the Cosmos DB database.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-5---working-with-relational-data-stores-in-the-cloud" class="anchor" aria-hidden="true" href="#lab-5---working-with-relational-data-stores-in-the-cloud"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 5 - Working with Relational Data Stores in the Cloud&lt;/h2&gt;
&lt;p&gt;The students will be able to provision an Azure SQL Database and Azure SQL Data Warehouse and be able to issue queries against one of the instances that are created. They will be also be able to integrate SQL Data Warehouse with a number of other Data platform technologies and use PolyBase to load data from one data source into Azure SQL Data Warehouse.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-6---performing-real-time-analytics-with-stream-analytics" class="anchor" aria-hidden="true" href="#lab-6---performing-real-time-analytics-with-stream-analytics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 6 - Performing Real-Time Analytics with Stream Analytics&lt;/h2&gt;
&lt;p&gt;The students will be able to describe what data streams are and how event processing works and choose an appropriate data stream ingestion technology for the AdventureWorks case study. They will provision the chosen ingestion technology and integrate this with Stream Analytics to create a solution that works with streaming data.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-7---orchestrating-data-movement-with-azure-data-factory" class="anchor" aria-hidden="true" href="#lab-7---orchestrating-data-movement-with-azure-data-factory"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 7 - Orchestrating Data Movement with Azure Data Factory&lt;/h2&gt;
&lt;p&gt;In this module, students will learn how Azure Data factory can be used to orchestrate the data movement from a wide range of data platform technologies. They will be able to explain the capabilities of the technology and be able to set up an end to end data pipeline that ingests data from SQL Database and load the data into SQL Data Warehouse. The student will also demonstrate how to call a compute resource.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-8---securing-azure-data-platforms" class="anchor" aria-hidden="true" href="#lab-8---securing-azure-data-platforms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 8 - Securing Azure Data Platforms&lt;/h2&gt;
&lt;p&gt;The students will be able to describe and document the different approaches to security that can be taken to provide defence in depth. This will involve the student documenting the security that has been set up so far in the course. It will also enable the students to identify any gaps in security that may exists for AdventureWorks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-9---monitoring-and-troubleshooting-data-storage-and-processing" class="anchor" aria-hidden="true" href="#lab-9---monitoring-and-troubleshooting-data-storage-and-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 9 - Monitoring and Troubleshooting Data Storage and Processing&lt;/h2&gt;
&lt;p&gt;The students will be able to define a broad monitoring solution that can help them monitor issues that can occur in their data estate. The student will then experience common data storage issues and data processing issue that can occur in cloud data solution. Finally they will implement a disaster recovery approach for a Data Platform technology.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>MicrosoftLearning</author><guid isPermaLink="false">https://github.com/MicrosoftLearning/DP-200-Implementing-an-Azure-Data-Solution</guid><pubDate>Tue, 12 Nov 2019 00:03:00 GMT</pubDate></item><item><title>nobodyiam/apollo-build-scripts #4 in TSQL, This week</title><link>https://github.com/nobodyiam/apollo-build-scripts</link><description>&lt;p&gt;&lt;i&gt;Apollo Build Scripts&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#%E4%B8%80%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"&gt;一、准备工作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#%E4%BA%8C%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4"&gt;二、安装步骤&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#%E4%B8%89%E5%90%AF%E5%8A%A8apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83"&gt;三、启动Apollo配置中心&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#%E5%9B%9B%E4%BD%BF%E7%94%A8apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83"&gt;四、使用Apollo配置中心&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了让大家更快的上手了解Apollo配置中心，我们这里准备了一个Quick Start，能够在几分钟内在本地环境部署、启动Apollo配置中心。&lt;/p&gt;
&lt;p&gt;考虑到Docker的便捷性，我们还提供了Quick Start的Docker版本，如果你对Docker比较熟悉的话，可以参考&lt;a href="https://github.com/ctripcorp/apollo/wiki/Apollo-Quick-Start-Docker%E9%83%A8%E7%BD%B2"&gt;Apollo Quick Start Docker部署&lt;/a&gt;通过Docker快速部署Apollo。&lt;/p&gt;
&lt;p&gt;不过这里需要注意的是，Quick Start只针对本地测试使用，如果要部署到生产环境，还请另行参考&lt;a href="https://github.com/ctripcorp/apollo/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97"&gt;分布式部署指南&lt;/a&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注：Quick Start需要有bash环境，Windows用户请安装&lt;a href="https://git-for-windows.github.io/" rel="nofollow"&gt;Git Bash&lt;/a&gt;，或者也可以直接通过IDE环境启动，详见&lt;a href="https://github.com/ctripcorp/apollo/wiki/Apollo%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97"&gt;Apollo开发指南&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;&lt;a id="user-content-一准备工作" class="anchor" aria-hidden="true" href="#一准备工作"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;一、准备工作&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-11-java" class="anchor" aria-hidden="true" href="#11-java"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.1 Java&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Apollo服务端：1.8+&lt;/li&gt;
&lt;li&gt;Apollo客户端：1.7+&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于Quick Start会在本地同时启动服务端和客户端，所以需要在本地安装Java 1.8+。&lt;/p&gt;
&lt;p&gt;在配置好后，可以通过如下命令检查：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;java -version&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;样例输出：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;java version &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;1.8.0_74&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
Java(TM) SE Runtime Environment (build 1.8.0_74-b02)
Java HotSpot(TM) 64-Bit Server VM (build 25.74-b02, mixed mode)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Windows用户请确保JAVA_HOME环境变量已经设置。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-12-mysql" class="anchor" aria-hidden="true" href="#12-mysql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.2 MySQL&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;版本要求：5.6.5+&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Apollo的表结构对&lt;code&gt;timestamp&lt;/code&gt;使用了多个default声明，所以需要5.6.5以上版本。&lt;/p&gt;
&lt;p&gt;连接上MySQL后，可以通过如下命令检查：&lt;/p&gt;
&lt;div class="highlight highlight-source-sql"&gt;&lt;pre&gt;SHOW VARIABLES &lt;span class="pl-k"&gt;WHERE&lt;/span&gt; Variable_name &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;version&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;&lt;/pre&gt;&lt;/div&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Variable_name&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;version&lt;/td&gt;
&lt;td&gt;5.7.11&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-13-下载quick-start安装包" class="anchor" aria-hidden="true" href="#13-下载quick-start安装包"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.3 下载Quick Start安装包&lt;/h2&gt;
&lt;p&gt;我们准备好了一个Quick Start安装包，大家只需要下载到本地，就可以直接使用，免去了编译、打包过程。&lt;/p&gt;
&lt;p&gt;安装包共50M，如果访问github网速不给力的话，可以从百度网盘下载。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从Github下载
&lt;ul&gt;
&lt;li&gt;checkout或下载&lt;a href="https://github.com/nobodyiam/apollo-build-scripts"&gt;apollo-build-scripts项目&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;由于Quick Start项目比较大，所以放在了另外的repository，请注意项目地址&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/nobodyiam/apollo-build-scripts"&gt;https://github.com/nobodyiam/apollo-build-scripts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;从百度网盘下载
&lt;ul&gt;
&lt;li&gt;通过&lt;a href="https://pan.baidu.com/s/1mhVf9va#list/path=/sharelink1426331153-165614845139829/apollo-quick-start&amp;amp;parentPath=/sharelink1426331153-165614845139829" rel="nofollow"&gt;网盘链接&lt;/a&gt;下载&lt;/li&gt;
&lt;li&gt;下载到本地后，在本地解压apollo-quick-start.zip&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;为啥安装包要58M这么大？
&lt;ul&gt;
&lt;li&gt;因为这是一个可以自启动的jar包，里面包含了所有依赖jar包以及一个内置的tomcat容器&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-131-手动打包quick-start安装包" class="anchor" aria-hidden="true" href="#131-手动打包quick-start安装包"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.3.1 手动打包Quick Start安装包&lt;/h3&gt;
&lt;p&gt;Quick Start只针对本地测试使用，所以一般用户不需要自己下载源码打包，只需要下载已经打好的包即可。不过也有部分用户希望在修改代码后重新打包，那么可以参考如下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;修改apollo-configservice, apollo-adminservice和apollo-portal的pom.xml，注释掉spring-boot-maven-plugin和maven-assembly-plugin&lt;/li&gt;
&lt;li&gt;在根目录下执行&lt;code&gt;mvn clean package -pl apollo-assembly -am -DskipTests=true&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;复制apollo-assembly/target下的jar包，rename为apollo-all-in-one.jar&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;&lt;a id="user-content-二安装步骤" class="anchor" aria-hidden="true" href="#二安装步骤"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;二、安装步骤&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-21-创建数据库" class="anchor" aria-hidden="true" href="#21-创建数据库"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2.1 创建数据库&lt;/h2&gt;
&lt;p&gt;Apollo服务端共需要两个数据库：&lt;code&gt;ApolloPortalDB&lt;/code&gt;和&lt;code&gt;ApolloConfigDB&lt;/code&gt;，我们把数据库、表的创建和样例数据都分别准备了sql文件，只需要导入数据库即可。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：如果你本地已经创建过Apollo数据库，请注意备份数据。我们准备的sql文件会清空Apollo相关的表。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-211-创建apolloportaldb" class="anchor" aria-hidden="true" href="#211-创建apolloportaldb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2.1.1 创建ApolloPortalDB&lt;/h3&gt;
&lt;p&gt;通过各种MySQL客户端导入&lt;a href="https://github.com/nobodyiam/apollo-build-scripts/blob/master/sql/apolloportaldb.sql"&gt;sql/apolloportaldb.sql&lt;/a&gt;即可。&lt;/p&gt;
&lt;p&gt;下面以MySQL原生客户端为例：&lt;/p&gt;
&lt;div class="highlight highlight-source-sql"&gt;&lt;pre&gt;source &lt;span class="pl-k"&gt;/&lt;/span&gt;your_local_path&lt;span class="pl-k"&gt;/&lt;/span&gt;sql&lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-c1"&gt;apolloportaldb&lt;/span&gt;.&lt;span class="pl-c1"&gt;sql&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;导入成功后，可以通过执行以下sql语句来验证：&lt;/p&gt;
&lt;div class="highlight highlight-source-sql"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;select&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;`&lt;/span&gt;Id&lt;span class="pl-pds"&gt;`&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;`&lt;/span&gt;AppId&lt;span class="pl-pds"&gt;`&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;`&lt;/span&gt;Name&lt;span class="pl-pds"&gt;`&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-c1"&gt;ApolloPortalDB&lt;/span&gt;.&lt;span class="pl-c1"&gt;App&lt;/span&gt;;&lt;/pre&gt;&lt;/div&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Id&lt;/th&gt;
&lt;th&gt;AppId&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;SampleApp&lt;/td&gt;
&lt;td&gt;Sample App&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-212-创建apolloconfigdb" class="anchor" aria-hidden="true" href="#212-创建apolloconfigdb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2.1.2 创建ApolloConfigDB&lt;/h3&gt;
&lt;p&gt;通过各种MySQL客户端导入&lt;a href="https://github.com/nobodyiam/apollo-build-scripts/blob/master/sql/apolloconfigdb.sql"&gt;sql/apolloconfigdb.sql&lt;/a&gt;即可。&lt;/p&gt;
&lt;p&gt;下面以MySQL原生客户端为例：&lt;/p&gt;
&lt;div class="highlight highlight-source-sql"&gt;&lt;pre&gt;source &lt;span class="pl-k"&gt;/&lt;/span&gt;your_local_path&lt;span class="pl-k"&gt;/&lt;/span&gt;sql&lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-c1"&gt;apolloconfigdb&lt;/span&gt;.&lt;span class="pl-c1"&gt;sql&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;导入成功后，可以通过执行以下sql语句来验证：&lt;/p&gt;
&lt;div class="highlight highlight-source-sql"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;select&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;`&lt;/span&gt;NamespaceId&lt;span class="pl-pds"&gt;`&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;`&lt;/span&gt;Key&lt;span class="pl-pds"&gt;`&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;`&lt;/span&gt;Value&lt;span class="pl-pds"&gt;`&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;`&lt;/span&gt;Comment&lt;span class="pl-pds"&gt;`&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-c1"&gt;ApolloConfigDB&lt;/span&gt;.&lt;span class="pl-c1"&gt;Item&lt;/span&gt;;&lt;/pre&gt;&lt;/div&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;NamespaceId&lt;/th&gt;
&lt;th&gt;Key&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;th&gt;Comment&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;timeout&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;sample timeout配置&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-22-配置数据库连接信息" class="anchor" aria-hidden="true" href="#22-配置数据库连接信息"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2.2 配置数据库连接信息&lt;/h2&gt;
&lt;p&gt;Apollo服务端需要知道如何连接到你前面创建的数据库，所以需要编辑&lt;a href="https://github.com/nobodyiam/apollo-build-scripts/blob/master/demo.sh"&gt;demo.sh&lt;/a&gt;，修改ApolloPortalDB和ApolloConfigDB相关的数据库连接串信息。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：填入的用户需要具备对ApolloPortalDB和ApolloConfigDB数据的读写权限。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;apollo config db info&lt;/span&gt;
apollo_config_db_url=jdbc:mysql://localhost:3306/ApolloConfigDB&lt;span class="pl-k"&gt;?&lt;/span&gt;characterEncoding=utf8
apollo_config_db_username=用户名
apollo_config_db_password=密码（如果没有密码，留空即可）

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; apollo portal db info&lt;/span&gt;
apollo_portal_db_url=jdbc:mysql://localhost:3306/ApolloPortalDB&lt;span class="pl-k"&gt;?&lt;/span&gt;characterEncoding=utf8
apollo_portal_db_username=用户名
apollo_portal_db_password=密码（如果没有密码，留空即可）&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：不要修改demo.sh的其它部分&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;&lt;a id="user-content-三启动apollo配置中心" class="anchor" aria-hidden="true" href="#三启动apollo配置中心"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;三、启动Apollo配置中心&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-31-确保端口未被占用" class="anchor" aria-hidden="true" href="#31-确保端口未被占用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3.1 确保端口未被占用&lt;/h2&gt;
&lt;p&gt;Quick Start脚本会在本地启动3个服务，分别使用8070, 8080, 8090端口，请确保这3个端口当前没有被使用。&lt;/p&gt;
&lt;p&gt;例如，在Linux/Mac下，可以通过如下命令检查：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;lsof -i:8080&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-32-执行启动脚本" class="anchor" aria-hidden="true" href="#32-执行启动脚本"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3.2 执行启动脚本&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;./demo.sh start&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;当看到如下输出后，就说明启动成功了！&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;==== starting service ====
Service logging file is ./service/apollo-service.log
Started [10768]
Waiting &lt;span class="pl-k"&gt;for&lt;/span&gt; config service startup.......
Config service started. You may visit http://localhost:8080 &lt;span class="pl-k"&gt;for&lt;/span&gt; service status now&lt;span class="pl-k"&gt;!&lt;/span&gt;
Waiting &lt;span class="pl-k"&gt;for&lt;/span&gt; admin service startup....
Admin service started
==== starting portal ====
Portal logging file is ./portal/apollo-portal.log
Started [10846]
Waiting &lt;span class="pl-k"&gt;for&lt;/span&gt; portal startup......
Portal started. You can visit http://localhost:8070 now&lt;span class="pl-k"&gt;!&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-33-异常排查" class="anchor" aria-hidden="true" href="#33-异常排查"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3.3 异常排查&lt;/h2&gt;
&lt;p&gt;如果启动遇到了异常，可以分别查看service和portal目录下的log文件排查问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注：在启动apollo-configservice的过程中会在日志中输出eureka注册失败的信息，如&lt;code&gt;com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused&lt;/code&gt;。需要注意的是，这个是预期的情况，因为apollo-configservice需要向Meta Server（它自己）注册服务，但是因为在启动过程中，自己还没起来，所以会报这个错。后面会进行重试的动作，所以等自己服务起来后就会注册正常了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-34-注意" class="anchor" aria-hidden="true" href="#34-注意"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3.4 注意&lt;/h2&gt;
&lt;p&gt;Quick Start只是用来帮助大家快速体验Apollo项目，具体实际使用时请参考：&lt;a href="https://github.com/ctripcorp/apollo/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97"&gt;分布式部署指南&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;另外需要注意的是Quick Start不支持增加环境，只有通过分布式部署才可以新增环境，同样请参考：&lt;a href="https://github.com/ctripcorp/apollo/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97"&gt;分布式部署指南&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-四使用apollo配置中心" class="anchor" aria-hidden="true" href="#四使用apollo配置中心"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;四、使用Apollo配置中心&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-41-使用样例项目" class="anchor" aria-hidden="true" href="#41-使用样例项目"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4.1 使用样例项目&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-411-查看样例配置" class="anchor" aria-hidden="true" href="#411-查看样例配置"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4.1.1 查看样例配置&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;打开&lt;a href="http://localhost:8070" rel="nofollow"&gt;http://localhost:8070&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Quick Start集成了&lt;a href="https://github.com/ctripcorp/apollo/wiki/Portal-%E5%AE%9E%E7%8E%B0%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%E5%8A%9F%E8%83%BD#%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%E4%B8%80%E4%BD%BF%E7%94%A8apollo%E6%8F%90%E4%BE%9B%E7%9A%84spring-security%E7%AE%80%E5%8D%95%E8%AE%A4%E8%AF%81"&gt;Spring Security简单认证&lt;/a&gt;，更多信息可以参考&lt;a href="https://github.com/ctripcorp/apollo/wiki/Portal-%E5%AE%9E%E7%8E%B0%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%E5%8A%9F%E8%83%BD"&gt;Portal 实现用户登录功能&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/nobodyiam/apollo-build-scripts/raw/master/images/apollo-login.png"&gt;&lt;img src="https://github.com/nobodyiam/apollo-build-scripts/raw/master/images/apollo-login.png" alt="登录" width="640px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;输入用户名apollo，密码admin后登录&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/nobodyiam/apollo-build-scripts/blob/master/images/apollo-sample-home.png"&gt;&lt;img src="https://github.com/nobodyiam/apollo-build-scripts/raw/master/images/apollo-sample-home.png" alt="首页" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;点击SampleApp进入配置界面，可以看到当前有一个配置timeout=100
&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/nobodyiam/apollo-build-scripts/blob/master/images/sample-app-config.png"&gt;&lt;img src="https://github.com/nobodyiam/apollo-build-scripts/raw/master/images/sample-app-config.png" alt="配置界面" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;如果提示&lt;code&gt;系统出错，请重试或联系系统负责人&lt;/code&gt;，请稍后几秒钟重试一下，因为通过Eureka注册的服务有一个刷新的延时。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-412-运行客户端程序" class="anchor" aria-hidden="true" href="#412-运行客户端程序"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4.1.2 运行客户端程序&lt;/h3&gt;
&lt;p&gt;我们准备了一个简单的&lt;a href="https://github.com/ctripcorp/apollo/blob/master/apollo-demo/src/main/java/com/ctrip/framework/apollo/demo/api/SimpleApolloConfigDemo.java"&gt;Demo客户端&lt;/a&gt;来演示从Apollo配置中心获取配置。&lt;/p&gt;
&lt;p&gt;程序很简单，就是用户输入一个key的名字，程序会输出这个key对应的值。&lt;/p&gt;
&lt;p&gt;如果没找到这个key，则输出undefined。&lt;/p&gt;
&lt;p&gt;同时，客户端还会监听配置变化事件，一旦有变化就会输出变化的配置信息。&lt;/p&gt;
&lt;p&gt;运行&lt;code&gt;./demo.sh client&lt;/code&gt;启动Demo客户端，忽略前面的调试信息，可以看到如下提示：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;Apollo Config Demo. Please input key to get the value. Input quit to exit.
&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;输入&lt;code&gt;timeout&lt;/code&gt;，会看到如下信息：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; timeout
&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; [SimpleApolloConfigDemo] Loading key &lt;span class="pl-c1"&gt;:&lt;/span&gt; timeout with value: 100&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;如果运行客户端遇到问题，可以通过修改&lt;code&gt;client/log4j2.xml&lt;/code&gt;中的level为DEBUG来查看更详细日志信息&lt;/p&gt;
&lt;div class="highlight highlight-text-xml"&gt;&lt;pre&gt;&amp;lt;&lt;span class="pl-ent"&gt;logger&lt;/span&gt; &lt;span class="pl-e"&gt;name&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;com.ctrip.framework.apollo&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-e"&gt;additivity&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;false&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-e"&gt;level&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;trace&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&amp;gt;
    &amp;lt;&lt;span class="pl-ent"&gt;AppenderRef&lt;/span&gt; &lt;span class="pl-e"&gt;ref&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Async&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-e"&gt;level&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;DEBUG&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;/&amp;gt;
&amp;lt;/&lt;span class="pl-ent"&gt;logger&lt;/span&gt;&amp;gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-413-修改配置并发布" class="anchor" aria-hidden="true" href="#413-修改配置并发布"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4.1.3 修改配置并发布&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在配置界面点击timeout这一项的编辑按钮
&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/nobodyiam/apollo-build-scripts/blob/master/images/sample-app-modify-config.png"&gt;&lt;img src="https://github.com/nobodyiam/apollo-build-scripts/raw/master/images/sample-app-modify-config.png" alt="编辑配置" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在弹出框中把值改成200并提交
&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/nobodyiam/apollo-build-scripts/blob/master/images/sample-app-submit-config.png"&gt;&lt;img src="https://github.com/nobodyiam/apollo-build-scripts/raw/master/images/sample-app-submit-config.png" alt="配置修改" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;点击发布按钮，并填写发布信息
&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/nobodyiam/apollo-build-scripts/blob/master/images/sample-app-release-config.png"&gt;&lt;img src="https://github.com/nobodyiam/apollo-build-scripts/raw/master/images/sample-app-release-config.png" alt="发布" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/nobodyiam/apollo-build-scripts/blob/master/images/sample-app-release-detail.png"&gt;&lt;img src="https://github.com/nobodyiam/apollo-build-scripts/raw/master/images/sample-app-release-detail.png" alt="发布信息" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-414-客户端查看修改后的值" class="anchor" aria-hidden="true" href="#414-客户端查看修改后的值"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4.1.4 客户端查看修改后的值&lt;/h3&gt;
&lt;p&gt;如果客户端一直在运行的话，在配置发布后就会监听到配置变化，并输出修改的配置信息：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;[SimpleApolloConfigDemo] Changes &lt;span class="pl-k"&gt;for&lt;/span&gt; namespace application
[SimpleApolloConfigDemo] Change - key: timeout, oldValue: 100, newValue: 200, changeType: MODIFIED&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;再次输入&lt;code&gt;timeout&lt;/code&gt;查看对应的值，会看到如下信息：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; timeout
&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; [SimpleApolloConfigDemo] Loading key &lt;span class="pl-c1"&gt;:&lt;/span&gt; timeout with value: 200&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-42-使用新的项目" class="anchor" aria-hidden="true" href="#42-使用新的项目"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4.2 使用新的项目&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-421-应用接入apollo" class="anchor" aria-hidden="true" href="#421-应用接入apollo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4.2.1 应用接入Apollo&lt;/h3&gt;
&lt;p&gt;这部分可以参考&lt;a href="https://github.com/ctripcorp/apollo/wiki/Java%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97"&gt;Java应用接入指南&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-422-运行客户端程序" class="anchor" aria-hidden="true" href="#422-运行客户端程序"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4.2.2 运行客户端程序&lt;/h3&gt;
&lt;p&gt;由于使用了新的项目，所以客户端需要修改appId信息。&lt;/p&gt;
&lt;p&gt;编辑&lt;code&gt;client/META-INF/app.properties&lt;/code&gt;，修改app.id为你新创建的app id。&lt;/p&gt;
&lt;div class="highlight highlight-source-ini"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;app.id&lt;/span&gt;=你的appId&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;运行&lt;code&gt;./demo.sh client&lt;/code&gt;启动Demo客户端即可。&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>nobodyiam</author><guid isPermaLink="false">https://github.com/nobodyiam/apollo-build-scripts</guid><pubDate>Tue, 12 Nov 2019 00:04:00 GMT</pubDate></item><item><title>celalceken/DatabaseManagementSystems #5 in TSQL, This week</title><link>https://github.com/celalceken/DatabaseManagementSystems</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h3&gt;&lt;a id="user-content-notlar-sürekli-güncellenmektedir" class="anchor" aria-hidden="true" href="#notlar-sürekli-güncellenmektedir"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notlar sürekli güncellenmektedir...&lt;/h3&gt;
&lt;p&gt;Bilgi çağının yaşandığı günümüzde veri yönetimi, organizasyonların en temel etkinliklerinden biridir. Doğru, ilgili ve zamanında elde edilebilen bilgi, karar verme süreçlerinde çok etkilidir ve kuruluşların yaşamını sürdürebilmesi açısından son derece önemlidir. Burada yer alan içerikler, verilerin saklanması ve etkin olarak erişilmesi amacıyla kullanılan Veritabanı Yönetim Sistemlerinin tasarlanması ve yönetilmesi konularında beceriler kazandırmayı hedeflemektedir.&lt;/p&gt;
&lt;p&gt;Notlar içerisinde yer alan konular; Veritabanı Sistemleri, Veri Modelleri, Varlık Bağıntı Modeli, Genişletilmiş Varlık Bağıntı Modeli, İlişkisel Veritabanı Modeli,  İlişkisel Cebir, Yapısal Sorgulama Dili (SQL), İleri SQL, Normalizasyon ve Başarım İyileştirme, SQL Programlama, Veritabanı Güvenliği, Diğer Veritabanı Modelleri.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>celalceken</author><guid isPermaLink="false">https://github.com/celalceken/DatabaseManagementSystems</guid><pubDate>Tue, 12 Nov 2019 00:05:00 GMT</pubDate></item></channel></rss>