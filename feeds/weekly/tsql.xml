<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: TSQL, This week</title><link>https://github.com/trending/tsql?since=weekly</link><description>The top repositories on GitHub for tsql, measured weekly</description><pubDate>Tue, 21 Jan 2020 01:04:19 GMT</pubDate><lastBuildDate>Tue, 21 Jan 2020 01:04:19 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>confluentinc/examples #1 in TSQL, This week</title><link>https://github.com/confluentinc/examples</link><description>&lt;p&gt;&lt;i&gt;Apache Kafka and Confluent Platform examples and demos&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/confluent-logo-300-2.png"&gt;&lt;img src="images/confluent-logo-300-2.png" alt="image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#demos"&gt;Demos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#build-your-own"&gt;Build Your Own&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#prerequisites"&gt;Prerequisities&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-demos" class="anchor" aria-hidden="true" href="#demos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Demos&lt;/h1&gt;
&lt;p&gt;This is a curated list of demos that showcase Apache KafkaÂ® event stream processing on the Confluent Platform, an event stream processing platform that enables you to process, organize, and manage massive amounts of streaming data across cloud, on-prem, and serverless deployments.&lt;/p&gt;
&lt;p align="center"&gt;
&lt;a href="http://www.youtube.com/watch?v=muQBd6gry0U" rel="nofollow"&gt;&lt;img src="images/examples-video-thumbnail.jpg" width="360" height="270" border="10" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-where-to-start" class="anchor" aria-hidden="true" href="#where-to-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Where to start&lt;/h2&gt;
&lt;p&gt;The best demo to start with is &lt;a href="https://github.com/confluentinc/cp-demo"&gt;cp-demo&lt;/a&gt; which spins up a Kafka event streaming application using KSQL for stream processing, with many security features enabled, in an end-to-end streaming ETL pipeline with a source connector pulling from live IRC channels and a sink connector connecting to Elasticsearch and Kibana for visualizations.
&lt;code&gt;cp-demo&lt;/code&gt; also comes with a playbook and is a great configuration reference for Confluent Platform.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-full-demo-list" class="anchor" aria-hidden="true" href="#full-demo-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Full demo list&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#confluent-cloud"&gt;Confluent Cloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#stream-processing"&gt;Stream Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data-pipelines"&gt;Data Pipelines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#confluent-platform"&gt;Confluent Platform&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-confluent-cloud" class="anchor" aria-hidden="true" href="#confluent-cloud"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Confluent Cloud&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Demo&lt;/th&gt;
&lt;th&gt;Local&lt;/th&gt;
&lt;th&gt;Docker&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="ccloud/beginner-cloud/README.md"&gt;Beginner Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Fully scripted demo that shows how to interact with your Confluent Cloud cluster and set ACLs using the CLI &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="clients/cloud/images/confluent-cloud.jpeg"&gt;&lt;img src="clients/cloud/images/confluent-cloud.jpeg" width="400" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="clients/cloud/README.md"&gt;Clients to Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="clients/cloud/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Client applications in different programming languages connecting to &lt;a href="https://www.confluent.io/confluent-cloud/?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Cloud&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="clients/cloud/images/clients-all.png"&gt;&lt;img src="clients/cloud/images/clients-all.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/gcp-pipeline/README.adoc"&gt;GCP pipeline&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/gcp-pipeline/README.adoc"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Work with &lt;a href="https://www.confluent.io/confluent-cloud/?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Cloud&lt;/a&gt; to build cool pipelines into Google Cloud Platform (GCP) &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/confluentinc/demo-scene/blob/master/gcp-pipeline/images/env-data-arch-01.png"&gt;&lt;img src="https://github.com/confluentinc/demo-scene/raw/master/gcp-pipeline/images/env-data-arch-01.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="kinesis-cloud/README.md"&gt;Kinesis to Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="kinesis-cloud/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;AWS Kinesis -&amp;gt; Confluent Cloud -&amp;gt; Google Cloud Storage pipeline &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="kinesis-cloud/images/topology.jpg"&gt;&lt;img src="kinesis-cloud/images/topology.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="ccloud/README.md"&gt;On-Prem Kafka to Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="ccloud/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="ccloud/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;This more advanced demo showcases an on-prem Kafka cluster and &lt;a href="https://www.confluent.io/confluent-cloud/?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Cloud&lt;/a&gt; cluster, and data copied between them with Confluent Replicator &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="ccloud/docs/images/schema-registry-local.jpg"&gt;&lt;img src="ccloud/docs/images/schema-registry-local.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="kubernetes/replicator-gke-cc/README.md"&gt;GKE to Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="kubernetes/replicator-gke-cc/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Uses Google Kubernetes Engine, &lt;a href="https://www.confluent.io/confluent-cloud/?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Cloud&lt;/a&gt;, and &lt;a href="https://www.confluent.io/confluent-replicator/?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Replicator&lt;/a&gt; to explore a multicloud deployment &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="kubernetes/replicator-gke-cc/docs/images/operator-demo-phase-2.png"&gt;&lt;img src="kubernetes/replicator-gke-cc/docs/images/operator-demo-phase-2.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-stream-processing" class="anchor" aria-hidden="true" href="#stream-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stream Processing&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Demo&lt;/th&gt;
&lt;th&gt;Local&lt;/th&gt;
&lt;th&gt;Docker&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="clickstream/README.md"&gt;Clickstream&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="clickstream/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.confluent.io/current/ksql/docs/tutorials/clickstream-docker.html#ksql-clickstream-docker?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Automated version of the &lt;a href="https://docs.confluent.io/current/ksql/docs/tutorials/clickstream-docker.html#ksql-clickstream-docker?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;KSQL clickstream demo&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/28e9212ca11ed82e4015367f81b89bec3e61f107/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f67726166616e612d737563636573732e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/28e9212ca11ed82e4015367f81b89bec3e61f107/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f67726166616e612d737563636573732e706e67" width="450" data-canonical-src="https://docs.confluent.io/current/_images/grafana-success.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://kafka-tutorials.confluent.io?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Kafka Tutorials&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://kafka-tutorials.confluent.io?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://kafka-tutorials.confluent.io?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Collection of common event streaming use cases, with each tutorial featuring an example scenario and several complete code solutions &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a8588b0e07ad402e01e0e1f355a840c3717fb7cd/68747470733a2f2f63646e2e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f4b61666b612d5475746f7269616c732d333530783139352e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/a8588b0e07ad402e01e0e1f355a840c3717fb7cd/68747470733a2f2f63646e2e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f4b61666b612d5475746f7269616c732d333530783139352e6a7067" width="350" data-canonical-src="https://cdn.confluent.io/wp-content/uploads/Kafka-Tutorials-350x195.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/ksql-udf-advanced-example/README.md?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top"&gt;KSQL UDF&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/ksql-udf-advanced-example/README.md?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Advanced &lt;a href="https://www.confluent.io/blog/build-udf-udaf-ksql-5-0?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;KSQL User-Defined Function (UDF)&lt;/a&gt; use case for connected cars &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fcb649b2d1a60911f393cc63738cdcb5c0710d73/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f4b53514c2d312d333530783139352e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/fcb649b2d1a60911f393cc63738cdcb5c0710d73/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f4b53514c2d312d333530783139352e706e67" width="350" data-canonical-src="https://www.confluent.io/wp-content/uploads/KSQL-1-350x195.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/ksql-workshop/"&gt;KSQL workshop&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/ksql-workshop/"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;showcases Kafka event stream processing using KSQL and can run self-guided as a KSQL workshop &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/confluentinc/demo-scene/blob/master/ksql-workshop/images/ksql_workshop_01.png"&gt;&lt;img src="https://github.com/confluentinc/demo-scene/raw/master/ksql-workshop/images/ksql_workshop_01.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="microservices-orders/README.md"&gt;Microservices ecosystem&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="microservices-orders/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/kafka-streams-examples/tree/5.2.2-post/src/main/java/io/confluent/examples/streams/microservices"&gt;Microservices orders Demo Application&lt;/a&gt; integrated into the Confluent Platform &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="microservices-orders/docs/images/microservices-demo.jpg"&gt;&lt;img src="microservices-orders/docs/images/microservices-demo.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="music/README.md"&gt;Music demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="music/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="music/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;KSQL version of the &lt;a href="https://docs.confluent.io/current/streams/kafka-streams-examples/docs/index.html?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Kafka Streams Demo Application&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="music/images/ksql-music-demo-overview.jpg"&gt;&lt;img src="music/images/ksql-music-demo-overview.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-data-pipelines" class="anchor" aria-hidden="true" href="#data-pipelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Pipelines&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Demo&lt;/th&gt;
&lt;th&gt;Local&lt;/th&gt;
&lt;th&gt;Docker&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/no-more-silos/demo_no-more-silos.adoc"&gt;CDC with MySQL&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/no-more-silos/demo_no-more-silos.adoc"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Self-paced steps to set up a change data capture (CDC) pipeline &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b9dbae7351f1813eb87dac08d7726b9554b891a2/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6b61666b615f636f6e6e6563742d312e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/b9dbae7351f1813eb87dac08d7726b9554b891a2/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6b61666b615f636f6e6e6563742d312e706e67" width="450" data-canonical-src="https://www.confluent.io/wp-content/uploads/kafka_connect-1.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="postgres-debezium-ksql-elasticsearch/README.md"&gt;CDC with Postgres&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="postgres-debezium-ksql-elasticsearch/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Enrich event stream data with CDC data from Postgres and then stream into Elasticsearch &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="postgres-debezium-ksql-elasticsearch/images/ksql-debezium-es.png"&gt;&lt;img src="postgres-debezium-ksql-elasticsearch/images/ksql-debezium-es.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="connect-streams-pipeline/README.md"&gt;Connect and Kafka Streams&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="connect-streams-pipeline/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Demonstrate various ways, with and without Kafka Connect, to get data into Kafka topics and then loaded for use by the Kafka Streams API &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="connect-streams-pipeline/images/blog_connect_streams_diag.jpg"&gt;&lt;img src="connect-streams-pipeline/images/blog_connect_streams_diag.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/mqtt-connect-connector-demo/README.md"&gt;MQTT&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/mqtt-connect-connector-demo/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Internet of Things (IoT) integration example using Apache Kafka + Kafka Connect + MQTT Connector + Sensor Data &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/80c360e482a98ae2311869d0cedc5ef984821eee/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6477675f4d5154542e737667"&gt;&lt;img src="https://camo.githubusercontent.com/80c360e482a98ae2311869d0cedc5ef984821eee/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6477675f4d5154542e737667" width="450" data-canonical-src="https://www.confluent.io/wp-content/uploads/dwg_MQTT.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="mysql-debezium/README.md"&gt;MySQL and Debezium&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="mysql-debezium/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/tree/master/build-a-streaming-pipeline"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;End-to-end streaming ETL with KSQL for stream processing using the &lt;a href="http://debezium.io/docs/connectors/mysql/" rel="nofollow"&gt;Debezium Connector for MySQL&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="mysql-debezium/images/ksql-debezium-es.png"&gt;&lt;img src="mysql-debezium/images/ksql-debezium-es.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/tree/master/syslog"&gt;Syslog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Real-time syslog processing with Apache Kafka and KSQL: filtering logs, event-driven alerting, and enriching events &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6436ef9d9bca4eaa9d300c713fee0e4be6db8ee6/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6b73716c5f7379736c6f6730312d31303234783235382e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/6436ef9d9bca4eaa9d300c713fee0e4be6db8ee6/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6b73716c5f7379736c6f6730312d31303234783235382e706e67" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-confluent-platform" class="anchor" aria-hidden="true" href="#confluent-platform"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Confluent Platform&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Demo&lt;/th&gt;
&lt;th&gt;Local&lt;/th&gt;
&lt;th&gt;Docker&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="clients/README.md"&gt;Avro&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="clients/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Client applications using Avro and Confluent Schema Registry &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/92ad363b0e5811b5935c9dc81c37845d9273a0b7/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6477675f536368656d615265675f686f776974776f726b732e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/92ad363b0e5811b5935c9dc81c37845d9273a0b7/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6477675f536368656d615265675f686f776974776f726b732e706e67" width="420" data-canonical-src="https://www.confluent.io/wp-content/uploads/dwg_SchemaReg_howitworks.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="wikipedia/README.md"&gt;CP Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="wikipedia/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/cp-demo"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.confluent.io/current/tutorials/cp-demo/docs/index.html?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Platform demo&lt;/a&gt; with a playbook for Kafka event streaming ETL deployments &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/confluentinc/cp-demo/blob/5.4.0-post/docs/images/drawing.png"&gt;&lt;img src="https://github.com/confluentinc/cp-demo/raw/5.4.0-post/docs/images/drawing.png" width="420" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="kubernetes/README.md"&gt;Kubernetes&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="kubernetes/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Demonstrations of Confluent Platform deployments using the  &lt;a href="https://docs.confluent.io/current/installation/operator/index.html?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Operator&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="kubernetes/gke-base/docs/images/operator.png"&gt;&lt;img src="kubernetes/gke-base/docs/images/operator.png" width="420" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="multi-datacenter/README.md"&gt;Multi Datacenter&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="multi-datacenter/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Active-active multi-datacenter design with two instances of Confluent Replicator copying data bidirectionally between the datacenters &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/c0090d428178db34693591175b730b27450002ad/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f6d64632d6c6576656c2d312e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/c0090d428178db34693591175b730b27450002ad/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f6d64632d6c6576656c2d312e706e67" width="420" data-canonical-src="https://docs.confluent.io/current/_images/mdc-level-1.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="multiregion/README.md"&gt;Multi Region Replication&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="multiregion/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Multi-region replication with follower fetching, observers, and replica placement&lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="multiregion/images/multi-region-topic-replicas-v2.png"&gt;&lt;img src="multiregion/images/multi-region-topic-replicas-v2.png" width="420" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="cp-quickstart/README.md"&gt;Quickstart&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="cp-quickstart/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.confluent.io/current/quickstart/ce-docker-quickstart.html#ce-docker-quickstart?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Automated version of the &lt;a href="https://docs.confluent.io/current/quickstart.html?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Platform Quickstart&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/494b6bf1a80993311d29232f17064ab180ebe677/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f636f6e666c75656e74506c6174666f726d2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/494b6bf1a80993311d29232f17064ab180ebe677/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f636f6e666c75656e74506c6174666f726d2e706e67" width="420" data-canonical-src="https://docs.confluent.io/current/_images/confluentPlatform.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="security/rbac/README.md"&gt;Role-Based Access Control&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Role-based Access Control (RBAC) provides granular privileges for users and service accounts &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/33dd1276d7e43660810d10a9d0997502fe22a623/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f726261632d6f766572766965772e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/33dd1276d7e43660810d10a9d0997502fe22a623/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f726261632d6f766572766965772e706e67" width="450" data-canonical-src="https://docs.confluent.io/current/_images/rbac-overview.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="security/secret-protection/README.adoc"&gt;Secret Protection&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Secret Protection feature encrypts secrets in configuration files &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/90888c033d0e611f7b73c5df261a109ead6858a1/68747470733a2f2f63646e2e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f5365637265745f50726f74656374696f6e5f466561747572652e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/90888c033d0e611f7b73c5df261a109ead6858a1/68747470733a2f2f63646e2e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f5365637265745f50726f74656374696f6e5f466561747572652e6a7067" width="400" data-canonical-src="https://cdn.confluent.io/wp-content/uploads/Secret_Protection_Feature.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="replicator-security/README.md"&gt;Replicator Security&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="replicator-security/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Demos of various security configurations supported by Confluent Replicator and examples of how to implement them &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/replicator-security.png"&gt;&lt;img src="images/replicator-security.png" width="300" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-build-your-own" class="anchor" aria-hidden="true" href="#build-your-own"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Build Your Own&lt;/h1&gt;
&lt;p&gt;As a next step, you may want to build your own custom demo or test environment.
We have several resources that launch just the services in Confluent Platform with no pre-configured connectors, data sources, topics, schemas, etc.
Using these as a foundation, you can then add any connectors or applications.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="cp-all-in-one/README.md"&gt;cp-all-in-one&lt;/a&gt;: This Docker Compose file launches all services in Confluent Platform, and runs them in containers in your local host.&lt;/li&gt;
&lt;li&gt;&lt;a href="cp-all-in-one-community/README.md"&gt;cp-all-in-one-community&lt;/a&gt;: This Docker Compose file launches only the community services in Confluent Platform, and runs them in containers in your local host.&lt;/li&gt;
&lt;li&gt;&lt;a href="cp-all-in-one-cloud/README.md"&gt;cp-all-in-one-cloud&lt;/a&gt;: Use this with your pre-configured Confluent Cloud instance. This Docker Compose file launches all services in Confluent Platform (except for the Kafka brokers), runs them in containers in your local host, and automatically configures them to connect to Confluent Cloud.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.confluent.io/current/cli/index.html?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent CLI&lt;/a&gt;: For local, non-Docker installs of Confluent Platform. Using this CLI, you can launch all services in Confluent Platform with just one command &lt;code&gt;confluent local start&lt;/code&gt;, and they will all run on your local host.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.confluent.io/blog/easy-ways-generate-test-data-kafka?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Generate test data&lt;/a&gt;: "Hello, World!" for launching Confluent Platform, plus different ways to generate more interesting test data for your topics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additional documentation: &lt;a href="https://docs.confluent.io/current/getting-started.html?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Getting Started&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prerequisites&lt;/h1&gt;
&lt;p&gt;For local installs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download &lt;a href="https://www.confluent.io/download/?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Platform 5.4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Env var &lt;code&gt;CONFLUENT_HOME=/path/to/confluentplatform&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Env var &lt;code&gt;PATH&lt;/code&gt; includes &lt;code&gt;$CONFLUENT_HOME/bin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Each demo has its own set of prerequisites as well, documented individually in each demo&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For Docker: demos have been validated with&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.docker.com/install/" rel="nofollow"&gt;Docker&lt;/a&gt; version 17.06.1-ce&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.docker.com/compose/install/" rel="nofollow"&gt;Docker Compose&lt;/a&gt; version 1.14.0 with Docker Compose file format 2.1&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>confluentinc</author><guid isPermaLink="false">https://github.com/confluentinc/examples</guid><pubDate>Tue, 21 Jan 2020 00:01:00 GMT</pubDate></item><item><title>MicrosoftLearning/DP-200-Implementing-an-Azure-Data-Solution #2 in TSQL, This week</title><link>https://github.com/MicrosoftLearning/DP-200-Implementing-an-Azure-Data-Solution</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-dp-200-implementing-an-azure-data-solution" class="anchor" aria-hidden="true" href="#dp-200-implementing-an-azure-data-solution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DP-200-Implementing-an-Azure-Data-Solution&lt;/h1&gt;
&lt;p&gt;During this course, the first and the last lab of the course are group exercises that involve discussion to help provide context for the labs that the students will take. The last lab provides the opportunity for the students to reflect on what they have achieved and what they have overcome to achieve the delivery of requirements from the case study in the labs. The rest of the labs are hands on implementing Azure data platform capabilities to meet AdventureWorks business requirements.&lt;/p&gt;
&lt;p&gt;The following is a summary of the lab objectives for each module:&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-1---azure-for-the-data-engineer" class="anchor" aria-hidden="true" href="#lab-1---azure-for-the-data-engineer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 1 - Azure for the Data Engineer&lt;/h2&gt;
&lt;p&gt;The students will take the information gained in the lessons and from the case study to scope out the deliverables for a digital transformation project within AdventureWorks. They will first identify how the evolving use of data has presented new opportunities for the organization. The students will also explore which Azure Data Platform services can be used to address the business needs and define the tasks that will be performed by the data engineer. Finally, students will finalize the data engineering deliverables for AdventureWorks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-2---working-with-data-storage" class="anchor" aria-hidden="true" href="#lab-2---working-with-data-storage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 2 - Working with Data Storage&lt;/h2&gt;
&lt;p&gt;In this lab, the students will be able to determine the appropriate storage type to implement against a given set of business and technical requirements. They will be able to create Azure storage accounts and Data Lake Storage account and explain the difference between Data Lake Storage version 1 and version 2. They will also be able to demonstrate how to perform data loads into the data storage of choice.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-3---enabling-team-based-data-science-with-azure-databricks" class="anchor" aria-hidden="true" href="#lab-3---enabling-team-based-data-science-with-azure-databricks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 3 - Enabling Team Based Data Science with Azure Databricks&lt;/h2&gt;
&lt;p&gt;By the end of this lab the student will be able to explain why Azure Databricks can be used to help in Data Science projects. The students will provision and Azure Databricks instance and will then create a workspace that will be used to perform a simple data preparation task from a Data Lake Store Gen II store. Finally, the student will perform a walk-through of performing transformations using Azure Databricks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-4---building-globally-distributed-databases-with-cosmos-db" class="anchor" aria-hidden="true" href="#lab-4---building-globally-distributed-databases-with-cosmos-db"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 4 - Building Globally Distributed Databases with Cosmos DB&lt;/h2&gt;
&lt;p&gt;The students will be able to describe and demonstrate the capabilities that Azure Cosmos DB can bring to an organization. They will be able to create a Cosmos DB instance and show how to upload and query data through a portal and through a .Net application. They will then be able to demonstrate how to enable global scale of the Cosmos DB database.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-5---working-with-relational-data-stores-in-the-cloud" class="anchor" aria-hidden="true" href="#lab-5---working-with-relational-data-stores-in-the-cloud"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 5 - Working with Relational Data Stores in the Cloud&lt;/h2&gt;
&lt;p&gt;The students will be able to provision an Azure SQL Database and Azure Synapse Analytics to be able to issue queries against one of the instances that are created. They will be also be able to integrate Azure Synapse Analytics with a number of other Data platform technologies and use PolyBase to load data from one data source into a data warehouse.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-6---performing-real-time-analytics-with-stream-analytics" class="anchor" aria-hidden="true" href="#lab-6---performing-real-time-analytics-with-stream-analytics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 6 - Performing Real-Time Analytics with Stream Analytics&lt;/h2&gt;
&lt;p&gt;The students will be able to describe what data streams are and how event processing works and choose an appropriate data stream ingestion technology for the AdventureWorks case study. They will provision the chosen ingestion technology and integrate this with Stream Analytics to create a solution that works with streaming data.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-7---orchestrating-data-movement-with-azure-data-factory" class="anchor" aria-hidden="true" href="#lab-7---orchestrating-data-movement-with-azure-data-factory"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 7 - Orchestrating Data Movement with Azure Data Factory&lt;/h2&gt;
&lt;p&gt;In this module, students will learn how Azure Data factory can be used to orchestrate the data movement from a wide range of data platform technologies. They will be able to explain the capabilities of the technology and be able to set up an end to end data pipeline that ingests data from SQL Database and load the data into SQL Data Warehouse. The student will also demonstrate how to call a compute resource.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-8---securing-azure-data-platforms" class="anchor" aria-hidden="true" href="#lab-8---securing-azure-data-platforms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 8 - Securing Azure Data Platforms&lt;/h2&gt;
&lt;p&gt;The students will be able to describe and document the different approaches to security that can be taken to provide defence in depth. This will involve the student documenting the security that has been set up so far in the course. It will also enable the students to identify any gaps in security that may exists for AdventureWorks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lab-9---monitoring-and-troubleshooting-data-storage-and-processing" class="anchor" aria-hidden="true" href="#lab-9---monitoring-and-troubleshooting-data-storage-and-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lab 9 - Monitoring and Troubleshooting Data Storage and Processing&lt;/h2&gt;
&lt;p&gt;The students will be able to define a broad monitoring solution that can help them monitor issues that can occur in their data estate. The student will then experience common data storage issues and data processing issue that can occur in cloud data solution. Finally they will implement a disaster recovery approach for a Data Platform technology.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>MicrosoftLearning</author><guid isPermaLink="false">https://github.com/MicrosoftLearning/DP-200-Implementing-an-Azure-Data-Solution</guid><pubDate>Tue, 21 Jan 2020 00:02:00 GMT</pubDate></item></channel></rss>