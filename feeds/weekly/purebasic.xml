<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: PureBasic, This week</title><link>https://github.com/trending/purebasic?since=weekly</link><description>The top repositories on GitHub for purebasic, measured weekly</description><pubDate>Sun, 26 Jan 2020 01:04:16 GMT</pubDate><lastBuildDate>Sun, 26 Jan 2020 01:04:16 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>onnx/onnx #1 in PureBasic, This week</title><link>https://github.com/onnx/onnx</link><description>&lt;p&gt;&lt;i&gt;Open Neural Network Exchange&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="docs/ONNX_logo_main.png"&gt;&lt;img width="40%" src="docs/ONNX_logo_main.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/onnx/onnx" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e6e12941cb55f0430a4d7c60590734c91f69589e/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f6f6e6e782f6f6e6e782f6d61737465722e7376673f6c6162656c3d4c696e7578" alt="Build Status" data-canonical-src="https://img.shields.io/travis/onnx/onnx/master.svg?label=Linux" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/onnx/onnx" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8710432deddb06e827785f0c07fee20cc1871afa/68747470733a2f2f696d672e736869656c64732e696f2f6170707665796f722f63692f6f6e6e782f6f6e6e782f6d61737465722e7376673f6c6162656c3d57696e646f7773" alt="Build status" data-canonical-src="https://img.shields.io/appveyor/ci/onnx/onnx/master.svg?label=Windows" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://powerci.osuosl.org/job/onnx-ppc64le-nightly-build/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d40af210c464362a41ccdf2d84fca198e1dbf841/68747470733a2f2f696d672e736869656c64732e696f2f6a656e6b696e732f732f687474702f706f77657263692e6f73756f736c2e6f72672f6f6e6e782d70706336346c652d6e696768746c792d6275696c642e7376673f6c6162656c3d4c696e757825323070706336346c65" alt="Build Status" data-canonical-src="https://img.shields.io/jenkins/s/http/powerci.osuosl.org/onnx-ppc64le-nightly-build.svg?label=Linux%20ppc64le" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://onnx.ai" rel="nofollow"&gt;Open Neural Network Exchange (ONNX)&lt;/a&gt; is an open ecosystem that empowers AI developers
to choose the right tools as their project evolves. ONNX provides an open source format for AI models, both deep learning and traditional ML. It defines an extensible computation graph model, as well as definitions of built-in operators and standard
data types. Currently we focus on the capabilities needed for inferencing (scoring).&lt;/p&gt;
&lt;p&gt;ONNX is &lt;a href="http://onnx.ai/supported-tools" rel="nofollow"&gt;widely supported&lt;/a&gt; and can be found in many frameworks, tools, and hardware. Enabling interoperability between different frameworks and streamlining the path from research to production helps increase the speed of innovation in the AI community. We invite the community to join us and further evolve ONNX.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-use-onnx" class="anchor" aria-hidden="true" href="#use-onnx"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Use ONNX&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/onnx/tutorials"&gt;Tutorials for creating ONNX models&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/onnx/models"&gt;Pre-trained ONNX models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-learn-about-the-onnx-spec" class="anchor" aria-hidden="true" href="#learn-about-the-onnx-spec"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn about the ONNX spec&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/Overview.md"&gt;Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/IR.md"&gt;ONNX intermediate representation spec&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/Versioning.md"&gt;Versioning principles of the spec&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/Operators.md"&gt;Operators documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/PythonAPIOverview.md"&gt;Python API Overview&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-programming-utilities-for-working-with-onnx-graphs" class="anchor" aria-hidden="true" href="#programming-utilities-for-working-with-onnx-graphs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Programming utilities for working with ONNX Graphs&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/ShapeInference.md"&gt;Shape and Type Inference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/Optimizer.md"&gt;Graph Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/VersionConverter.md"&gt;Opset Version Conversion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-contribute" class="anchor" aria-hidden="true" href="#contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribute&lt;/h1&gt;
&lt;p&gt;ONNX is a &lt;a href="community"&gt;community project&lt;/a&gt;. We encourage you to join the effort and contribute feedback, ideas, and code. You can participate in the &lt;a href="community/sigs.md"&gt;SIGs&lt;/a&gt; and &lt;a href="community/working-groups.md"&gt;Working Groups&lt;/a&gt; to shape the future of ONNX.&lt;/p&gt;
&lt;p&gt;Check out our &lt;a href="https://github.com/onnx/onnx/blob/master/docs/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; to get started.&lt;/p&gt;
&lt;p&gt;If you think some operator should be added to ONNX specification, please read
&lt;a href="docs/AddNewOp.md"&gt;this document&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-discuss" class="anchor" aria-hidden="true" href="#discuss"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Discuss&lt;/h1&gt;
&lt;p&gt;We encourage you to open &lt;a href="https://github.com/onnx/onnx/issues"&gt;Issues&lt;/a&gt;, or use Gitter for more real-time discussion:
&lt;a href="https://gitter.im/onnx/Lobby?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" alt="Join the chat at https://gitter.im/onnx/Lobby" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-follow-us" class="anchor" aria-hidden="true" href="#follow-us"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Follow Us&lt;/h1&gt;
&lt;p&gt;Stay up to date with the latest ONNX news. [&lt;a href="https://www.facebook.com/onnxai/" rel="nofollow"&gt;Facebook&lt;/a&gt;] [&lt;a href="https://twitter.com/onnxai" rel="nofollow"&gt;Twitter&lt;/a&gt;]&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-binaries" class="anchor" aria-hidden="true" href="#binaries"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Binaries&lt;/h2&gt;
&lt;p&gt;A binary build of ONNX is available from &lt;a href="https://conda.io" rel="nofollow"&gt;Conda&lt;/a&gt;, in &lt;a href="https://conda-forge.org/" rel="nofollow"&gt;conda-forge&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c conda-forge onnx
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-source" class="anchor" aria-hidden="true" href="#source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-linux-and-macos" class="anchor" aria-hidden="true" href="#linux-and-macos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linux and MacOS&lt;/h3&gt;
&lt;p&gt;You will need an install of protobuf and numpy to build ONNX.  One easy
way to get these dependencies is via
&lt;a href="https://www.anaconda.com/download/" rel="nofollow"&gt;Anaconda&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Use conda-forge protobuf, as default doesn't come with protoc
conda install -c conda-forge protobuf numpy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can then install ONNX from PyPi (Note: Set environment variable &lt;code&gt;ONNX_ML=1&lt;/code&gt; for onnx-ml):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install onnx
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also build and install ONNX locally from source code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/onnx/onnx.git
cd onnx
git submodule update --init --recursive
python setup.py install
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: When installing in a non-Anaconda environment, make sure to install the Protobuf compiler before running the pip installation of onnx. For example, on Ubuntu:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install protobuf-compiler libprotoc-dev
pip install onnx
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-windows" class="anchor" aria-hidden="true" href="#windows"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Windows&lt;/h3&gt;
&lt;p&gt;When building on Windows it is highly recommended that you also build protobuf locally as a static library. The version distributed with conda-forge is a DLL and this is a conflict as ONNX expects it to be a static lib.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-instructions-to-build-protobuf-and-onnx-on-windows" class="anchor" aria-hidden="true" href="#instructions-to-build-protobuf-and-onnx-on-windows"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Instructions to build protobuf and ONNX on windows&lt;/h4&gt;
&lt;p&gt;Step 1 : Build protobuf locally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/protocolbuffers/protobuf.git
cd protobuf
git checkout 3.9.x
cd cmake
# Explicitly set -Dprotobuf_MSVC_STATIC_RUNTIME=OFF to make sure protobuf does not statically link to runtime library
cmake -G "Visual Studio 15 2017 Win64" -Dprotobuf_MSVC_STATIC_RUNTIME=OFF -Dprotobuf_BUILD_TESTS=OFF -Dprotobuf_BUILD_EXAMPLES=OFF -DCMAKE_INSTALL_PREFIX=&amp;lt;protobuf_install_dir&amp;gt;
msbuild protobuf.sln /m /p:Configuration=Release
msbuild INSTALL.vcxproj /p:Configuration=Release
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Step 2: Build ONNX&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Get ONNX
git clone https://github.com/onnx/onnx.git
cd onnx
git submodule update --init --recursive

# Set environment variables to find protobuf and turn off static linking of ONNX to runtime library.
# Even better option is to add it to user\system PATH so this step can be performed only once.
# For more details check https://docs.microsoft.com/en-us/cpp/build/reference/md-mt-ld-use-run-time-library?view=vs-2017
set PATH=&amp;lt;protobuf_install_dir&amp;gt;\bin;%PATH%
set USE_MSVC_STATIC_RUNTIME=0

# Optional : Set environment variable `ONNX_ML=1` for onnx-ml

# Build ONNX
python setup.py install
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you do not want to build protobuf and instead want to use protobuf from conda forge then follow these instructions.
However please note : This method is just added as a convenience for users and there is very limited support from ONNX team when using this method.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-instructions-to-build-onnx-on-windows-in-anaconda-environment" class="anchor" aria-hidden="true" href="#instructions-to-build-onnx-on-windows-in-anaconda-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Instructions to build ONNX on windows in anaconda environment&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# Use conda-forge protobuf
conda install -c conda-forge protobuf=3.9.2 numpy

# Get ONNX
git clone https://github.com/onnx/onnx.git
cd onnx
git submodule update --init --recursive

# Set environment variable for ONNX to use protobuf shared lib
set CMAKE_ARGS="-DONNX_USE_PROTOBUF_SHARED_LIBS=ON"

# Build ONNX
# Optional : Set environment variable `ONNX_ML=1` for onnx-ml

python setup.py install
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-verify-installation" class="anchor" aria-hidden="true" href="#verify-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Verify Installation&lt;/h2&gt;
&lt;p&gt;After installation, run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python -c "import onnx"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to verify it works.  Note that this command does not work from
a source checkout directory; in this case you'll see:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ModuleNotFoundError: No module named 'onnx.onnx_cpp2py_export'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Change into another directory to fix this error.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-testing" class="anchor" aria-hidden="true" href="#testing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Testing&lt;/h1&gt;
&lt;p&gt;ONNX uses &lt;a href="https://docs.pytest.org" rel="nofollow"&gt;pytest&lt;/a&gt; as test driver. In order to run tests, first you need to install pytest:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install pytest nbval
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After installing pytest, do&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pytest
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to run tests.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-development" class="anchor" aria-hidden="true" href="#development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development&lt;/h1&gt;
&lt;p&gt;Check out &lt;a href="https://github.com/onnx/onnx/blob/master/docs/CONTRIBUTING.md"&gt;contributor guide&lt;/a&gt; for instructions.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h1&gt;
&lt;p&gt;&lt;a href="LICENSE"&gt;MIT License&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-code-of-conduct" class="anchor" aria-hidden="true" href="#code-of-conduct"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code of Conduct&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://onnx.ai/codeofconduct.html" rel="nofollow"&gt;ONNX Open Source Code of Conduct&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>onnx</author><guid isPermaLink="false">https://github.com/onnx/onnx</guid><pubDate>Sun, 26 Jan 2020 00:01:00 GMT</pubDate></item></channel></rss>