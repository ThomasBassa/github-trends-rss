<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Jupyter Notebook, This week</title><link>https://github.com/trending/jupyter-notebook?since=weekly</link><description>The top repositories on GitHub for jupyter-notebook, measured weekly</description><pubDate>Thu, 21 Nov 2019 01:03:46 GMT</pubDate><lastBuildDate>Thu, 21 Nov 2019 01:03:46 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>dragen1860/TensorFlow-2.x-Tutorials #1 in Jupyter Notebook, This week</title><link>https://github.com/dragen1860/TensorFlow-2.x-Tutorials</link><description>&lt;p&gt;&lt;i&gt;TensorFlow 2.x version's  Tutorials and Examples, including CNN, RNN, GAN, Auto-Encoders, FasterRCNN, GPT, BERT examples, etc. TF 2.0版入门实例代码，实战教程。&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-20-tutorials" class="anchor" aria-hidden="true" href="#tensorflow-20-tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow 2.0 Tutorials&lt;/h1&gt;
&lt;p&gt;Our repo. is the &lt;strong&gt;Winner&lt;/strong&gt; of &lt;a href="https://devpost.com/software/tensorflow-2-0-tutorials" rel="nofollow"&gt;⚡#PoweredByTF 2.0 Challenge!&lt;/a&gt;.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="res/tensorflow-2.0.gif"&gt;&lt;img src="res/tensorflow-2.0.gif" width="250" align="middle" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Timeline:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Oct. 1, 2019: TensorFlow 2.0 Stable!&lt;/li&gt;
&lt;li&gt;Aug. 24, 2019: &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf" rel="nofollow"&gt;TensorFlow 2.0 rc0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jun. 8, 2019: &lt;a href="https://twitter.com/fchollet/status/1134583289384120320" rel="nofollow"&gt;TensorFlow 2.0 Beta&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Mar. 7, 2019: &lt;a href="https://www.tensorflow.org/alpha" rel="nofollow"&gt;Tensorflow 2.0 Alpha&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jan. 11, 2019: &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf" rel="nofollow"&gt;TensorFlow r2.0 preview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Aug. 14, 2018: &lt;a href="https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/bgug1G6a89A" rel="nofollow"&gt;TensorFlow 2.0 is coming&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h1&gt;
&lt;p&gt;make sure you are using python 3.x.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU install&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;pip install tensorflow &lt;span class="pl-k"&gt;-&lt;/span&gt;U&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;GPU install&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Install &lt;code&gt;CUDA 10.0&lt;/code&gt;(or after) and &lt;code&gt;cudnn&lt;/code&gt; by yourself. and set &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; up.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;pip install tensorflow&lt;span class="pl-k"&gt;-&lt;/span&gt;gpu  &lt;span class="pl-k"&gt;-&lt;/span&gt;U&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Test installation:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;In [&lt;span class="pl-c1"&gt;2&lt;/span&gt;]: &lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow  &lt;span class="pl-k"&gt;as&lt;/span&gt; tf

In [&lt;span class="pl-c1"&gt;3&lt;/span&gt;]: tf.&lt;span class="pl-c1"&gt;__version__&lt;/span&gt;
Out[&lt;span class="pl-c1"&gt;3&lt;/span&gt;]: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;2.0.0&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
In [&lt;span class="pl-c1"&gt;4&lt;/span&gt;]: tf.test.is_gpu_available()
&lt;span class="pl-c1"&gt;...&lt;/span&gt;
totalMemory: &lt;span class="pl-c1"&gt;3.&lt;/span&gt;&lt;span class="pl-ii"&gt;95GiB&lt;/span&gt; freeMemory: &lt;span class="pl-c1"&gt;3.&lt;/span&gt;&lt;span class="pl-ii"&gt;00GiB&lt;/span&gt;
&lt;span class="pl-c1"&gt;...&lt;/span&gt;
Out[&lt;span class="pl-c1"&gt;4&lt;/span&gt;]: &lt;span class="pl-c1"&gt;True&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-配套tf2视频教程" class="anchor" aria-hidden="true" href="#配套tf2视频教程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;配套TF2视频教程&lt;/h1&gt;
&lt;p align="center"&gt;
  &lt;a href="https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1209092816&amp;amp;_trace_c_p_k2_=dca16f8fd11a4525bac8c89f779b2cfa" rel="nofollow"&gt;
    &lt;img src="res/cover.png" width="400" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1209092816&amp;amp;_trace_c_p_k2_=dca16f8fd11a4525bac8c89f779b2cfa" rel="nofollow"&gt;
    &lt;img src="res/TF_QR_163.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
&lt;/p&gt; 
&lt;p&gt;TensorFlow 2.0的视频教程链接：&lt;a href="https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1209092816&amp;amp;_trace_c_p_k2_=dca16f8fd11a4525bac8c89f779b2cfa" rel="nofollow"&gt;深度学习与TensorFlow 2实战&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-acknowledgement" class="anchor" aria-hidden="true" href="#acknowledgement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgement&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;爱可可-爱生活 友情推荐 &lt;a target="_blank" rel="noopener noreferrer" href="res/weibo.jpg"&gt;&lt;img src="res/weibo.jpg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-includes" class="anchor" aria-hidden="true" href="#includes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Includes&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;TensorFlow 2.0 Overview&lt;/li&gt;
&lt;li&gt;TensorFlow 2.0 Basic Usage&lt;/li&gt;
&lt;li&gt;Linear Regression&lt;/li&gt;
&lt;li&gt;MNIST, FashionMNIST&lt;/li&gt;
&lt;li&gt;CIFAR10&lt;/li&gt;
&lt;li&gt;Fully Connected Layer&lt;/li&gt;
&lt;li&gt;VGG16&lt;/li&gt;
&lt;li&gt;Inception Network&lt;/li&gt;
&lt;li&gt;ResNet18&lt;/li&gt;
&lt;li&gt;Naive RNN&lt;/li&gt;
&lt;li&gt;LSTM&lt;/li&gt;
&lt;li&gt;ColorBot&lt;/li&gt;
&lt;li&gt;Auto-Encoders&lt;/li&gt;
&lt;li&gt;Variational Auto-Encoders&lt;/li&gt;
&lt;li&gt;DCGAN&lt;/li&gt;
&lt;li&gt;CycleGAN&lt;/li&gt;
&lt;li&gt;WGAN&lt;/li&gt;
&lt;li&gt;Pixel2Pixel&lt;/li&gt;
&lt;li&gt;Faster RCNN&lt;/li&gt;
&lt;li&gt;A2C&lt;/li&gt;
&lt;li&gt;GPT&lt;/li&gt;
&lt;li&gt;BERT&lt;/li&gt;
&lt;li&gt;GCN&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Feel free to submit a &lt;strong&gt;PR&lt;/strong&gt; request to make this repo. more complete!&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-refered-repos" class="anchor" aria-hidden="true" href="#refered-repos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Refered Repos.&lt;/h1&gt;
&lt;p&gt;Our work is not built from scratch. Great appreciation to these open works！&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/madalinabuzau/tensorflow-eager-tutorials"&gt;https://github.com/madalinabuzau/tensorflow-eager-tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/herbiebradley/CycleGAN-Tensorflow"&gt;https://github.com/herbiebradley/CycleGAN-Tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/pix2pix/pix2pix_eager.ipynb"&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/pix2pix/pix2pix_eager.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/moono/tf-eager-on-GAN"&gt;https://github.com/moono/tf-eager-on-GAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Viredery/tf-eager-fasterrcnn"&gt;https://github.com/Viredery/tf-eager-fasterrcnn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/github/gitignore/blob/master/Python.gitignore"&gt;https://github.com/github/gitignore/blob/master/Python.gitignore&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dragen1860</author><guid isPermaLink="false">https://github.com/dragen1860/TensorFlow-2.x-Tutorials</guid><pubDate>Thu, 21 Nov 2019 00:01:00 GMT</pubDate></item><item><title>fengdu78/lihang-code #2 in Jupyter Notebook, This week</title><link>https://github.com/fengdu78/lihang-code</link><description>&lt;p&gt;&lt;i&gt;《统计学习方法》的代码实现&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="readme.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;strong&gt;代码目录&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;第1章 统计学习方法概论&lt;/p&gt;
&lt;p&gt;第2章 感知机&lt;/p&gt;
&lt;p&gt;第3章 k近邻法&lt;/p&gt;
&lt;p&gt;第4章 朴素贝叶斯&lt;/p&gt;
&lt;p&gt;第5章 决策树&lt;/p&gt;
&lt;p&gt;第6章 逻辑斯谛回归&lt;/p&gt;
&lt;p&gt;第7章 支持向量机&lt;/p&gt;
&lt;p&gt;第8章 提升方法&lt;/p&gt;
&lt;p&gt;第9章 EM算法及其推广&lt;/p&gt;
&lt;p&gt;第10章 隐马尔可夫模型&lt;/p&gt;
&lt;p&gt;第11章 条件随机场&lt;/p&gt;
&lt;p&gt;第12章 监督学习方法总结&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;参考：
&lt;a href="https://github.com/wzyonggege/statistical-learning-method"&gt;https://github.com/wzyonggege/statistical-learning-method&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/WenDesi/lihang_book_algorithm"&gt;https://github.com/WenDesi/lihang_book_algorithm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/tudaodiaozhale" rel="nofollow"&gt;https://blog.csdn.net/tudaodiaozhale&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;代码整理和修改：机器学习初学者&lt;/p&gt;
&lt;p&gt;微信公众号：机器学习初学者 &lt;a target="_blank" rel="noopener noreferrer" href="images/gongzhong.jpg"&gt;&lt;img src="images/gongzhong.jpg" alt="gongzhong" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;知识星球：黄博的机器学习圈子&lt;a target="_blank" rel="noopener noreferrer" href="images/zhishixingqiu1.jpg"&gt;&lt;img src="images/zhishixingqiu1.jpg" alt="xingqiu" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.zhihu.com/people/fengdu78" rel="nofollow"&gt;知乎&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fengdu78</author><guid isPermaLink="false">https://github.com/fengdu78/lihang-code</guid><pubDate>Thu, 21 Nov 2019 00:02:00 GMT</pubDate></item><item><title>jackfrued/Python-100-Days #3 in Jupyter Notebook, This week</title><link>https://github.com/jackfrued/Python-100-Days</link><description>&lt;p&gt;&lt;i&gt;Python - 100天从新手到大师&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-python---100天从新手到大师" class="anchor" aria-hidden="true" href="#python---100天从新手到大师"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python - 100天从新手到大师&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;作者：骆昊&lt;/p&gt;
&lt;p&gt;最近有很多想学习Python的小伙伴陆陆续续加入我们的交流群，目前我们的交流群人数已经超过一万人。我们的目标是打造一个优质的Python交流社区，一方面为想学习Python的初学者扫平入门过程中的重重障碍；另一方为新入行的开发者提供问道的途径，帮助他们迅速成长为优秀的职业人；此外，有经验的开发者可以利用这个平台把自己的工作经验无偿分享或有偿提供出来，让大家都能够得到职业技能以及综合素质的全面提升。之前的公开课和线下技术交流活动因为工作的关系荒废了一段时间了，但是各位小伙伴仍然活跃在交流群并一如既往的支持我们，在此向大家表示感谢。近期开始持续更新前15天和最后10天的内容，前15天是写给初学者的，我希望把上手的难度进一步降低，例子程序更加简单清晰；最后10天是Python项目实战和面试相关的东西，我希望内容更详实和完整，尤其是第100天的面试题部分；创作不易，感谢大家的打赏支持，这些钱不会用于购买咖啡而是通过腾讯公益平台捐赠给需要帮助的人（&lt;a href="./%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97.md"&gt;点击&lt;/a&gt;了解捐赠情况）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-qq-group.png"&gt;&lt;img src="./res/python-qq-group.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-python应用领域和就业形势分析" class="anchor" aria-hidden="true" href="#python应用领域和就业形势分析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python应用领域和就业形势分析&lt;/h3&gt;
&lt;p&gt;简单的说，Python是一个“优雅”、“明确”、“简单”的编程语言。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;学习曲线低，非专业人士也能上手&lt;/li&gt;
&lt;li&gt;开源系统，拥有强大的生态圈&lt;/li&gt;
&lt;li&gt;解释型语言，完美的平台可移植性&lt;/li&gt;
&lt;li&gt;支持面向对象和函数式编程&lt;/li&gt;
&lt;li&gt;能够通过调用C/C++代码扩展功能&lt;/li&gt;
&lt;li&gt;代码规范程度高，可读性强&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目前几个比较流行的领域，Python都有用武之地。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;云基础设施 - Python / Java / Go&lt;/li&gt;
&lt;li&gt;DevOps - Python / Shell / Ruby / Go&lt;/li&gt;
&lt;li&gt;网络爬虫 - Python / PHP / C++&lt;/li&gt;
&lt;li&gt;数据分析挖掘 - Python / R / Scala / Matlab&lt;/li&gt;
&lt;li&gt;机器学习 - Python / R / Java / Lisp&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作为一名Python开发者，主要的就业领域包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python服务器后台开发 / 游戏服务器开发 / 数据接口开发工程师&lt;/li&gt;
&lt;li&gt;Python自动化运维工程师&lt;/li&gt;
&lt;li&gt;Python数据分析 / 数据可视化 / 大数据工程师&lt;/li&gt;
&lt;li&gt;Python爬虫工程师&lt;/li&gt;
&lt;li&gt;Python聊天机器人开发 / 图像识别和视觉算法 / 深度学习工程师&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图显示了主要城市Python招聘需求量及薪资待遇排行榜（截止到2018年5月）。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-top-10.png"&gt;&lt;img src="./res/python-top-10.png" alt="Python招聘需求及薪资待遇Top 10" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-bj-salary.png"&gt;&lt;img src="./res/python-bj-salary.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-salary-chengdu.png"&gt;&lt;img src="./res/python-salary-chengdu.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;给初学者的几个建议：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make English as your working language.&lt;/li&gt;
&lt;li&gt;Practice makes perfect.&lt;/li&gt;
&lt;li&gt;All experience comes from mistakes.&lt;/li&gt;
&lt;li&gt;Don't be one of the leeches.&lt;/li&gt;
&lt;li&gt;Either stand out or kicked out.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day0115---python语言基础" class="anchor" aria-hidden="true" href="#day0115---python语言基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day01~15 - &lt;a href="./Day01-15"&gt;Python语言基础&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day01---初识python" class="anchor" aria-hidden="true" href="#day01---初识python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day01 - &lt;a href="./Day01-15/01.%E5%88%9D%E8%AF%86Python.md"&gt;初识Python&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Python简介 - Python的历史 / Python的优缺点 / Python的应用领域&lt;/li&gt;
&lt;li&gt;搭建编程环境 - Windows环境 / Linux环境 / MacOS环境&lt;/li&gt;
&lt;li&gt;从终端运行Python程序 - Hello, world / print函数 / 运行程序&lt;/li&gt;
&lt;li&gt;使用IDLE - 交互式环境(REPL) / 编写多行代码 / 运行程序 / 退出IDLE&lt;/li&gt;
&lt;li&gt;注释 - 注释的作用 / 单行注释 / 多行注释&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day02---语言元素" class="anchor" aria-hidden="true" href="#day02---语言元素"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day02 - &lt;a href="./Day01-15/02.%E8%AF%AD%E8%A8%80%E5%85%83%E7%B4%A0.md"&gt;语言元素&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;程序和进制 - 指令和程序 / 冯诺依曼机 / 二进制和十进制 / 八进制和十六进制&lt;/li&gt;
&lt;li&gt;变量和类型 - 变量的命名 / 变量的使用 / input函数 / 检查变量类型 / 类型转换&lt;/li&gt;
&lt;li&gt;数字和字符串 - 整数 / 浮点数 / 复数 / 字符串 / 字符串基本操作 / 字符编码&lt;/li&gt;
&lt;li&gt;运算符 - 数学运算符 / 赋值运算符 / 比较运算符 / 逻辑运算符 / 身份运算符 / 运算符的优先级&lt;/li&gt;
&lt;li&gt;应用案例 - 华氏温度转换成摄氏温度 / 输入圆的半径计算周长和面积 / 输入年份判断是否是闰年&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day03---分支结构" class="anchor" aria-hidden="true" href="#day03---分支结构"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day03 - &lt;a href="./Day01-15/03.%E5%88%86%E6%94%AF%E7%BB%93%E6%9E%84.md"&gt;分支结构&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;分支结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图&lt;/li&gt;
&lt;li&gt;if语句 - 简单的if / if-else结构 / if-elif-else结构 / 嵌套的if&lt;/li&gt;
&lt;li&gt;应用案例 - 用户身份验证 / 英制单位与公制单位互换 / 掷骰子决定做什么 / 百分制成绩转等级制 / 分段函数求值 / 输入三条边的长度如果能构成三角形就计算周长和面积&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day04---循环结构" class="anchor" aria-hidden="true" href="#day04---循环结构"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day04 - &lt;a href="./Day01-15/04.%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84.md"&gt;循环结构&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;循环结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图&lt;/li&gt;
&lt;li&gt;while循环 - 基本结构 / break语句 / continue语句&lt;/li&gt;
&lt;li&gt;for循环 - 基本结构 / range类型 / 循环中的分支结构 / 嵌套的循环 / 提前结束程序&lt;/li&gt;
&lt;li&gt;应用案例 - 1~100求和 / 判断素数 / 猜数字游戏 / 打印九九表 / 打印三角形图案 / 猴子吃桃 / 百钱百鸡&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day05---构造程序逻辑" class="anchor" aria-hidden="true" href="#day05---构造程序逻辑"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day05 - &lt;a href="./Day01-15/05.%E6%9E%84%E9%80%A0%E7%A8%8B%E5%BA%8F%E9%80%BB%E8%BE%91.md"&gt;构造程序逻辑&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;经典案例：水仙花数 / 百钱百鸡 / Craps赌博游戏&lt;/li&gt;
&lt;li&gt;练习题目：斐波那契数列 / 完美数 / 素数&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day06---函数和模块的使用" class="anchor" aria-hidden="true" href="#day06---函数和模块的使用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day06 - &lt;a href="./Day01-15/06.%E5%87%BD%E6%95%B0%E5%92%8C%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8.md"&gt;函数和模块的使用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;函数的作用 - 代码的坏味道 / 用函数封装功能模块&lt;/li&gt;
&lt;li&gt;定义函数 - def语句 / 函数名 / 参数列表 / return语句 / 调用自定义函数&lt;/li&gt;
&lt;li&gt;调用函数 - Python内置函数 /  导入模块和函数&lt;/li&gt;
&lt;li&gt;函数的参数 - 默认参数 / 可变参数 / 关键字参数 / 命名关键字参数&lt;/li&gt;
&lt;li&gt;函数的返回值 - 没有返回值  / 返回单个值 / 返回多个值&lt;/li&gt;
&lt;li&gt;作用域问题 - 局部作用域 / 嵌套作用域 / 全局作用域 / 内置作用域 / 和作用域相关的关键字&lt;/li&gt;
&lt;li&gt;用模块管理函数 - 模块的概念 / 用自定义模块管理函数 / 命名冲突的时候会怎样（同一个模块和不同的模块）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day07---字符串和常用数据结构" class="anchor" aria-hidden="true" href="#day07---字符串和常用数据结构"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day07 - &lt;a href="./Day01-15/07.%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.md"&gt;字符串和常用数据结构&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;字符串的使用 - 计算长度 / 下标运算 / 切片 / 常用方法&lt;/li&gt;
&lt;li&gt;列表基本用法 - 定义列表 / 用下表访问元素 / 下标越界 / 添加元素 / 删除元素 / 修改元素 / 切片 / 循环遍历&lt;/li&gt;
&lt;li&gt;列表常用操作 - 连接 / 复制(复制元素和复制数组) / 长度 / 排序 / 倒转 / 查找&lt;/li&gt;
&lt;li&gt;生成列表 - 使用range创建数字列表 / 生成表达式 / 生成器&lt;/li&gt;
&lt;li&gt;元组的使用 - 定义元组 / 使用元组中的值 / 修改元组变量 / 元组和列表转换&lt;/li&gt;
&lt;li&gt;集合基本用法 - 集合和列表的区别 /  创建集合 / 添加元素 / 删除元素 /  清空&lt;/li&gt;
&lt;li&gt;集合常用操作 - 交集 / 并集 / 差集 / 对称差 / 子集 / 超集&lt;/li&gt;
&lt;li&gt;字典的基本用法 - 字典的特点 / 创建字典 / 添加元素 / 删除元素 / 取值 / 清空&lt;/li&gt;
&lt;li&gt;字典常用操作 - keys()方法 / values()方法 / items()方法 / setdefault()方法&lt;/li&gt;
&lt;li&gt;基础练习 - 跑马灯效果 / 列表找最大元素 / 统计考试成绩的平均分 / Fibonacci数列 / 杨辉三角&lt;/li&gt;
&lt;li&gt;综合案例 - 双色球选号 / 井字棋&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day08---面向对象编程基础" class="anchor" aria-hidden="true" href="#day08---面向对象编程基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day08 - &lt;a href="./Day01-15/08.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80.md"&gt;面向对象编程基础&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;类和对象 - 什么是类 / 什么是对象 / 面向对象其他相关概念&lt;/li&gt;
&lt;li&gt;定义类 - 基本结构 / 属性和方法 / 构造器 / 析构器 / __str__方法&lt;/li&gt;
&lt;li&gt;使用对象 - 创建对象 / 给对象发消息&lt;/li&gt;
&lt;li&gt;面向对象的四大支柱 - 抽象 / 封装 / 继承 / 多态&lt;/li&gt;
&lt;li&gt;基础练习 - 定义学生类 / 定义时钟类 / 定义图形类 / 定义汽车类&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day09---面向对象进阶" class="anchor" aria-hidden="true" href="#day09---面向对象进阶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day09 - &lt;a href="./Day01-15/09.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%BF%9B%E9%98%B6.md"&gt;面向对象进阶&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;属性 - 类属性 / 实例属性 / 属性访问器 / 属性修改器 / 属性删除器 / 使用__slots__&lt;/li&gt;
&lt;li&gt;类中的方法 - 实例方法 / 类方法 / 静态方法&lt;/li&gt;
&lt;li&gt;运算符重载 - __add__ / __sub__ / __or__ /__getitem__ / __setitem__ / __len__ / __repr__ / __gt__ / __lt__ / __le__ / __ge__ / __eq__ / __ne__ / __contains__&lt;/li&gt;
&lt;li&gt;类(的对象)之间的关系 - 关联 / 继承 / 依赖&lt;/li&gt;
&lt;li&gt;继承和多态 - 什么是继承 / 继承的语法 / 调用父类方法 / 方法重写 / 类型判定 / 多重继承 / 菱形继承(钻石继承)和C3算法&lt;/li&gt;
&lt;li&gt;综合案例 - 工资结算系统 / 图书自动折扣系统 / 自定义分数类&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day10---图形用户界面和游戏开发" class="anchor" aria-hidden="true" href="#day10---图形用户界面和游戏开发"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day10 - &lt;a href="./Day01-15/10.%E5%9B%BE%E5%BD%A2%E7%94%A8%E6%88%B7%E7%95%8C%E9%9D%A2%E5%92%8C%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91.md"&gt;图形用户界面和游戏开发&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;使用tkinter开发GUI程序&lt;/li&gt;
&lt;li&gt;使用pygame三方库开发游戏应用&lt;/li&gt;
&lt;li&gt;“大球吃小球”游戏&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day11---文件和异常" class="anchor" aria-hidden="true" href="#day11---文件和异常"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day11 - &lt;a href="./Day01-15/11.%E6%96%87%E4%BB%B6%E5%92%8C%E5%BC%82%E5%B8%B8.md"&gt;文件和异常&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;读文件 - 读取整个文件 / 逐行读取 / 文件路径&lt;/li&gt;
&lt;li&gt;写文件 - 覆盖写入 / 追加写入 / 文本文件 / 二进制文件&lt;/li&gt;
&lt;li&gt;异常处理 - 异常机制的重要性 / try-except代码块 / else代码块 / finally代码块 / 内置异常类型 / 异常栈 / raise语句&lt;/li&gt;
&lt;li&gt;数据持久化 - CSV文件概述 / csv模块的应用 / JSON数据格式 / json模块的应用&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day12---字符串和正则表达式" class="anchor" aria-hidden="true" href="#day12---字符串和正则表达式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day12 - &lt;a href="./Day01-15/12.%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F.md"&gt;字符串和正则表达式&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;字符串高级操作 - 转义字符 / 原始字符串 / 多行字符串 / in和 not in运算符 / is开头的方法 / join和split方法 / strip相关方法 / pyperclip模块 / 不变字符串和可变字符串 / StringIO的使用&lt;/li&gt;
&lt;li&gt;正则表达式入门 - 正则表达式的作用 / 元字符 / 转义 / 量词 / 分组 / 零宽断言 /贪婪匹配与惰性匹配懒惰 / 使用re模块实现正则表达式操作（匹配、搜索、替换、捕获）&lt;/li&gt;
&lt;li&gt;使用正则表达式 - re模块 / compile函数 / group和groups方法 / match方法 / search方法 / findall和finditer方法 / sub和subn方法 / split方法&lt;/li&gt;
&lt;li&gt;应用案例 - 使用正则表达式验证输入的字符串&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day13---进程和线程" class="anchor" aria-hidden="true" href="#day13---进程和线程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day13 - &lt;a href="./Day01-15/13.%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B.md"&gt;进程和线程&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;进程和线程的概念 - 什么是进程 / 什么是线程 / 多线程的应用场景&lt;/li&gt;
&lt;li&gt;使用进程 - fork函数 / multiprocessing模块 / 进程池 / 进程间通信&lt;/li&gt;
&lt;li&gt;使用线程 - thread模块 / threading模块 / Thread类 / Lock类 / Condition类 / 线程池&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day14---网络编程入门和网络应用开发" class="anchor" aria-hidden="true" href="#day14---网络编程入门和网络应用开发"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day14 - &lt;a href="./Day01-15/14.%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91.md"&gt;网络编程入门和网络应用开发&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;计算机网络基础 - 计算机网络发展史 / “TCP-IP”模型 / IP地址 / 端口 / 协议 / 其他相关概念&lt;/li&gt;
&lt;li&gt;网络应用模式 - “客户端-服务器”模式 / “浏览器-服务器”模式&lt;/li&gt;
&lt;li&gt;基于HTTP协议访问网络资源 - 网络API概述 / 访问URL / requests模块 / 解析JSON格式数据&lt;/li&gt;
&lt;li&gt;Python网络编程 - 套接字的概念 / socket模块 /  socket函数 / 创建TCP服务器 / 创建TCP客户端 / 创建UDP服务器 / 创建UDP客户端 / SocketServer模块&lt;/li&gt;
&lt;li&gt;电子邮件 - SMTP协议 / POP3协议 / IMAP协议 / smtplib模块 / poplib模块 / imaplib模块&lt;/li&gt;
&lt;li&gt;短信服务 - 调用短信服务网关&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day15---图像和文档处理" class="anchor" aria-hidden="true" href="#day15---图像和文档处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day15 - &lt;a href="./Day01-15/15.%E5%9B%BE%E5%83%8F%E5%92%8C%E5%8A%9E%E5%85%AC%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86.md"&gt;图像和文档处理&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;用Pillow处理图片 - 图片读写 / 图片合成 / 几何变换 / 色彩转换 / 滤镜效果&lt;/li&gt;
&lt;li&gt;读写Word文档 - 文本内容的处理 / 段落 / 页眉和页脚 / 样式的处理&lt;/li&gt;
&lt;li&gt;读写Excel文件 - xlrd模块 / xlwt模块&lt;/li&gt;
&lt;li&gt;生成PDF文件 - pypdf2模块 / reportlab模块&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day16day20---python语言进阶-" class="anchor" aria-hidden="true" href="#day16day20---python语言进阶-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day16~Day20 - &lt;a href="./Day16-20/16-20.Python%E8%AF%AD%E8%A8%80%E8%BF%9B%E9%98%B6.md"&gt;Python语言进阶 &lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;常用数据结构&lt;/li&gt;
&lt;li&gt;函数的高级用法 - “一等公民” / 高阶函数 / Lambda函数 / 作用域和闭包 / 装饰器&lt;/li&gt;
&lt;li&gt;面向对象高级知识 - “三大支柱” / 类与类之间的关系 / 垃圾回收 / 魔术属性和方法 / 混入 / 元类 / 面向对象设计原则 / GoF设计模式&lt;/li&gt;
&lt;li&gt;迭代器和生成器 - 相关魔术方法 / 创建生成器的两种方式 /&lt;/li&gt;
&lt;li&gt;并发和异步编程 - 多线程 / 多进程 / 异步IO / async和await&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day2130---web前端入门" class="anchor" aria-hidden="true" href="#day2130---web前端入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day21~30 - &lt;a href="./Day21-30/21-30.Web%E5%89%8D%E7%AB%AF%E6%A6%82%E8%BF%B0.md"&gt;Web前端入门&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用HTML标签承载页面内容&lt;/li&gt;
&lt;li&gt;用CSS渲染页面&lt;/li&gt;
&lt;li&gt;用JavaScript处理交互式行为&lt;/li&gt;
&lt;li&gt;jQuery入门和提高&lt;/li&gt;
&lt;li&gt;Vue.js入门&lt;/li&gt;
&lt;li&gt;Element的使用&lt;/li&gt;
&lt;li&gt;Bootstrap的使用&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day3135---玩转linux操作系统" class="anchor" aria-hidden="true" href="#day3135---玩转linux操作系统"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day31~35 - &lt;a href="./Day31-35/31-35.%E7%8E%A9%E8%BD%ACLinux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.md"&gt;玩转Linux操作系统&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;操作系统发展史和Linux概述&lt;/li&gt;
&lt;li&gt;Linux基础命令&lt;/li&gt;
&lt;li&gt;Linux中的实用程序&lt;/li&gt;
&lt;li&gt;Linux的文件系统&lt;/li&gt;
&lt;li&gt;Vim编辑器的应用&lt;/li&gt;
&lt;li&gt;环境变量和Shell编程&lt;/li&gt;
&lt;li&gt;软件的安装和服务的配置&lt;/li&gt;
&lt;li&gt;网络访问和管理&lt;/li&gt;
&lt;li&gt;其他相关内容&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day3640---数据库基础和进阶" class="anchor" aria-hidden="true" href="#day3640---数据库基础和进阶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day36~40 - &lt;a href="./Day36-40"&gt;数据库基础和进阶&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="./Day36-40/36-38.%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93MySQL.md"&gt;关系型数据库MySQL&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;关系型数据库概述&lt;/li&gt;
&lt;li&gt;MySQL的安装和使用&lt;/li&gt;
&lt;li&gt;SQL的使用
&lt;ul&gt;
&lt;li&gt;DDL - 数据定义语言 - create / drop / alter&lt;/li&gt;
&lt;li&gt;DML - 数据操作语言 - insert / delete / update / select&lt;/li&gt;
&lt;li&gt;DCL - 数据控制语言 - grant / revoke&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;相关知识
&lt;ul&gt;
&lt;li&gt;范式理论 - 设计二维表的指导思想&lt;/li&gt;
&lt;li&gt;数据完整性&lt;/li&gt;
&lt;li&gt;数据一致性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在Python中操作MySQL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="./Day36-40/39-40.NoSQL%E5%85%A5%E9%97%A8.md"&gt;NoSQL入门&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;NoSQL概述&lt;/li&gt;
&lt;li&gt;Redis概述&lt;/li&gt;
&lt;li&gt;Mongo概述&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day4155---实战django" class="anchor" aria-hidden="true" href="#day4155---实战django"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day41~55 - &lt;a href="./Day41-55"&gt;实战Django&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day41---快速上手" class="anchor" aria-hidden="true" href="#day41---快速上手"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day41 - &lt;a href="./Day41-55/41.%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B.md"&gt;快速上手&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Web应用工作原理和HTTP协议&lt;/li&gt;
&lt;li&gt;Django框架概述&lt;/li&gt;
&lt;li&gt;5分钟快速上手&lt;/li&gt;
&lt;li&gt;使用视图模板&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day42---深入模型" class="anchor" aria-hidden="true" href="#day42---深入模型"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day42 - &lt;a href="./Day41-55/42.%E6%B7%B1%E5%85%A5%E6%A8%A1%E5%9E%8B.md"&gt;深入模型&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;关系型数据库配置&lt;/li&gt;
&lt;li&gt;管理后台的使用&lt;/li&gt;
&lt;li&gt;使用ORM完成对模型的CRUD操作&lt;/li&gt;
&lt;li&gt;Django模型最佳实践&lt;/li&gt;
&lt;li&gt;模型定义参考&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day43---静态资源和ajax请求" class="anchor" aria-hidden="true" href="#day43---静态资源和ajax请求"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day43 - &lt;a href="./Day41-55/43.%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E5%92%8CAjax%E8%AF%B7%E6%B1%82.md"&gt;静态资源和Ajax请求&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;加载静态资源&lt;/li&gt;
&lt;li&gt;用Ajax请求获取数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day44---表单的应用" class="anchor" aria-hidden="true" href="#day44---表单的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day44 - &lt;a href="./Day41-55/44.%E8%A1%A8%E5%8D%95%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;表单的应用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;表单和表单控件&lt;/li&gt;
&lt;li&gt;跨站请求伪造和CSRF令牌&lt;/li&gt;
&lt;li&gt;Form和ModelForm&lt;/li&gt;
&lt;li&gt;表单验证&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day45---cookie和session" class="anchor" aria-hidden="true" href="#day45---cookie和session"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day45 - &lt;a href="./Day41-55/45.Cookie%E5%92%8CSession.md"&gt;Cookie和Session&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;实现用户跟踪&lt;/li&gt;
&lt;li&gt;cookie和session的关系&lt;/li&gt;
&lt;li&gt;Django框架对session的支持&lt;/li&gt;
&lt;li&gt;视图函数中的cookie读写操作&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day46---报表和日志" class="anchor" aria-hidden="true" href="#day46---报表和日志"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day46 - &lt;a href="./Day41-55/46.%E6%8A%A5%E8%A1%A8%E5%92%8C%E6%97%A5%E5%BF%97.md"&gt;报表和日志&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;通过HttpResponse修改响应头&lt;/li&gt;
&lt;li&gt;使用StreamingHttpResponse处理大文件&lt;/li&gt;
&lt;li&gt;使用xlwt生成Excel报表&lt;/li&gt;
&lt;li&gt;使用reportlab生成PDF报表&lt;/li&gt;
&lt;li&gt;使用ECharts生成前端图表&lt;/li&gt;
&lt;li&gt;配置日志和Django-Debug-Toolbar&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day47---中间件的应用" class="anchor" aria-hidden="true" href="#day47---中间件的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day47 - &lt;a href="./Day41-55/47.%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;中间件的应用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;什么是中间件&lt;/li&gt;
&lt;li&gt;Django框架内置的中间件&lt;/li&gt;
&lt;li&gt;自定义中间件及其应用场景&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day48---前后端分离开发入门" class="anchor" aria-hidden="true" href="#day48---前后端分离开发入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day48 - &lt;a href="./Day41-55/48.%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%BC%80%E5%8F%91%E5%85%A5%E9%97%A8.md"&gt;前后端分离开发入门&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;返回JSON格式的数据&lt;/li&gt;
&lt;li&gt;用Vue.js渲染页面&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day49---restful架构和drf入门" class="anchor" aria-hidden="true" href="#day49---restful架构和drf入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day49 - &lt;a href="./Day41-55/49.RESTful%E6%9E%B6%E6%9E%84%E5%92%8CDRF%E5%85%A5%E9%97%A8.md"&gt;RESTful架构和DRF入门&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day50---restful架构和drf进阶" class="anchor" aria-hidden="true" href="#day50---restful架构和drf进阶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day50 - &lt;a href="./Day41-55/50.RESTful%E6%9E%B6%E6%9E%84%E5%92%8CDRF%E8%BF%9B%E9%98%B6.md"&gt;RESTful架构和DRF进阶&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day51---使用缓存" class="anchor" aria-hidden="true" href="#day51---使用缓存"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day51 - &lt;a href="./Day41-55/51.%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98.md"&gt;使用缓存&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;网站优化第一定律&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在Django项目中使用Redis提供缓存服务&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在视图函数中读写缓存&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用装饰器实现页面缓存&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为数据接口提供缓存服务&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day52---文件上传和富文本编辑" class="anchor" aria-hidden="true" href="#day52---文件上传和富文本编辑"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day52 - &lt;a href="./Day41-55/52.%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%92%8C%E5%AF%8C%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8.md"&gt;文件上传和富文本编辑&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;文件上传表单控件和图片文件预览&lt;/li&gt;
&lt;li&gt;服务器端如何处理上传的文件&lt;/li&gt;
&lt;li&gt;富文本编辑器概述&lt;/li&gt;
&lt;li&gt;wangEditor的使用&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day53---短信和邮件" class="anchor" aria-hidden="true" href="#day53---短信和邮件"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day53 - &lt;a href="./Day41-55/53.%E7%9F%AD%E4%BF%A1%E5%92%8C%E9%82%AE%E4%BB%B6.md"&gt;短信和邮件&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;常用短信网关平台介绍&lt;/li&gt;
&lt;li&gt;使用螺丝帽发送短信&lt;/li&gt;
&lt;li&gt;Django框架对邮件服务的支持&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day54---异步任务和定时任务" class="anchor" aria-hidden="true" href="#day54---异步任务和定时任务"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day54 - &lt;a href="./Day41-55/54.%E5%BC%82%E6%AD%A5%E4%BB%BB%E5%8A%A1%E5%92%8C%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1.md"&gt;异步任务和定时任务&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;网站优化第二定律&lt;/li&gt;
&lt;li&gt;配置消息队列服务&lt;/li&gt;
&lt;li&gt;在项目中使用celery实现任务异步化&lt;/li&gt;
&lt;li&gt;在项目中使用celery实现定时任务&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day55---单元测试和项目上线" class="anchor" aria-hidden="true" href="#day55---单元测试和项目上线"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day55 - &lt;a href="./Day41-55/55.%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E5%92%8C%E9%A1%B9%E7%9B%AE%E4%B8%8A%E7%BA%BF.md"&gt;单元测试和项目上线&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Python中的单元测试&lt;/li&gt;
&lt;li&gt;Django框架对单元测试的支持&lt;/li&gt;
&lt;li&gt;使用版本控制系统&lt;/li&gt;
&lt;li&gt;配置和使用uWSGI&lt;/li&gt;
&lt;li&gt;动静分离和Nginx配置&lt;/li&gt;
&lt;li&gt;配置HTTPS&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day5660---实战flask" class="anchor" aria-hidden="true" href="#day5660---实战flask"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day56~60 - &lt;a href="./Day56-65"&gt;实战Flask&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day56---flask入门" class="anchor" aria-hidden="true" href="#day56---flask入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day56 - &lt;a href="./Day56-60/56.Flask%E5%85%A5%E9%97%A8.md"&gt;Flask入门&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day57---模板的使用" class="anchor" aria-hidden="true" href="#day57---模板的使用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day57 - &lt;a href="./Day56-60/57.%E6%A8%A1%E6%9D%BF%E7%9A%84%E4%BD%BF%E7%94%A8.md"&gt;模板的使用&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day58---表单的处理" class="anchor" aria-hidden="true" href="#day58---表单的处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day58 - &lt;a href="./Day56-60/58.%E8%A1%A8%E5%8D%95%E7%9A%84%E5%A4%84%E7%90%86.md"&gt;表单的处理&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day59---数据库操作" class="anchor" aria-hidden="true" href="#day59---数据库操作"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day59 - &lt;a href="./Day56-60/59.%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C.md"&gt;数据库操作&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day60---项目实战" class="anchor" aria-hidden="true" href="#day60---项目实战"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day60 - &lt;a href="./Day56-60/60.%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.md"&gt;项目实战&lt;/a&gt;&lt;/h4&gt;
&lt;h3&gt;&lt;a id="user-content-day6165---实战tornado" class="anchor" aria-hidden="true" href="#day6165---实战tornado"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day61~65 - &lt;a href="./Day61-65"&gt;实战Tornado&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day61---预备知识" class="anchor" aria-hidden="true" href="#day61---预备知识"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day61 - &lt;a href="./Day61-65/61.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86.md"&gt;预备知识&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;并发编程&lt;/li&gt;
&lt;li&gt;I/O模式和事件驱动&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day62---tornado入门" class="anchor" aria-hidden="true" href="#day62---tornado入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day62 - &lt;a href="./Day61-65/62.Tornado%E5%85%A5%E9%97%A8.md"&gt;Tornado入门&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Tornado概述&lt;/li&gt;
&lt;li&gt;5分钟上手Tornado&lt;/li&gt;
&lt;li&gt;路由解析&lt;/li&gt;
&lt;li&gt;请求处理器&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day63---异步化" class="anchor" aria-hidden="true" href="#day63---异步化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day63 - &lt;a href="./Day61-65/63.%E5%BC%82%E6%AD%A5%E5%8C%96.md"&gt;异步化&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;aiomysql和aioredis的使用&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day64---websocket的应用" class="anchor" aria-hidden="true" href="#day64---websocket的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day64 - &lt;a href="./Day61-65/64.WebSocket%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;WebSocket的应用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;WebSocket简介&lt;/li&gt;
&lt;li&gt;WebSocket服务器端编程&lt;/li&gt;
&lt;li&gt;WebSocket客户端编程&lt;/li&gt;
&lt;li&gt;项目：Web聊天室&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day65---项目实战" class="anchor" aria-hidden="true" href="#day65---项目实战"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day65 - &lt;a href="./Day61-65/65.%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.md"&gt;项目实战&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;前后端分离开发和接口文档的撰写&lt;/li&gt;
&lt;li&gt;使用Vue.js实现前端渲染&lt;/li&gt;
&lt;li&gt;使用ECharts实现报表功能&lt;/li&gt;
&lt;li&gt;使用WebSocket实现推送服务&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day6675---爬虫开发" class="anchor" aria-hidden="true" href="#day6675---爬虫开发"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day66~75 - &lt;a href="./Day66-75"&gt;爬虫开发&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day66---网络爬虫和相关工具" class="anchor" aria-hidden="true" href="#day66---网络爬虫和相关工具"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day66 - &lt;a href="./Day66-75/66.%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%92%8C%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7.md"&gt;网络爬虫和相关工具&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;网络爬虫的概念及其应用领域&lt;/li&gt;
&lt;li&gt;网络爬虫的合法性探讨&lt;/li&gt;
&lt;li&gt;开发网络爬虫的相关工具&lt;/li&gt;
&lt;li&gt;一个爬虫程序的构成&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day67---数据采集和解析" class="anchor" aria-hidden="true" href="#day67---数据采集和解析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day67 - &lt;a href="./Day66-75/67.%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%92%8C%E8%A7%A3%E6%9E%90.md"&gt;数据采集和解析&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;数据采集的标准和三方库&lt;/li&gt;
&lt;li&gt;页面解析的三种方式：正则表达式解析 / XPath解析 / CSS选择器解析&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day68---存储数据" class="anchor" aria-hidden="true" href="#day68---存储数据"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day68 - &lt;a href="./Day66-75/68.%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE.md"&gt;存储数据&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;如何存储海量数据&lt;/li&gt;
&lt;li&gt;实现数据的缓存&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day69---并发下载" class="anchor" aria-hidden="true" href="#day69---并发下载"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day69 - &lt;a href="./Day66-75/69.%E5%B9%B6%E5%8F%91%E4%B8%8B%E8%BD%BD.md"&gt;并发下载&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;多线程和多进程&lt;/li&gt;
&lt;li&gt;异步I/O和协程&lt;/li&gt;
&lt;li&gt;async和await关键字的使用&lt;/li&gt;
&lt;li&gt;三方库aiohttp的应用&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day70---解析动态内容" class="anchor" aria-hidden="true" href="#day70---解析动态内容"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day70 - &lt;a href="./Day66-75/70.%E8%A7%A3%E6%9E%90%E5%8A%A8%E6%80%81%E5%86%85%E5%AE%B9.md"&gt;解析动态内容&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;JavaScript逆向工程&lt;/li&gt;
&lt;li&gt;使用Selenium获取动态内容&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day71---表单交互和验证码处理" class="anchor" aria-hidden="true" href="#day71---表单交互和验证码处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day71 - &lt;a href="./Day66-75/71.%E8%A1%A8%E5%8D%95%E4%BA%A4%E4%BA%92%E5%92%8C%E9%AA%8C%E8%AF%81%E7%A0%81%E5%A4%84%E7%90%86.md"&gt;表单交互和验证码处理&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;自动提交表单&lt;/li&gt;
&lt;li&gt;Cookie池的应用&lt;/li&gt;
&lt;li&gt;验证码处理&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day72---scrapy入门" class="anchor" aria-hidden="true" href="#day72---scrapy入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day72 - &lt;a href="./Day66-75/72.Scrapy%E5%85%A5%E9%97%A8.md"&gt;Scrapy入门&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Scrapy爬虫框架概述&lt;/li&gt;
&lt;li&gt;安装和使用Scrapy&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day73---scrapy高级应用" class="anchor" aria-hidden="true" href="#day73---scrapy高级应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day73 - &lt;a href="./Day66-75/73.Scrapy%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8.md"&gt;Scrapy高级应用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Spider的用法&lt;/li&gt;
&lt;li&gt;中间件的应用：下载中间件 / 蜘蛛中间件&lt;/li&gt;
&lt;li&gt;Scrapy对接Selenium抓取动态内容&lt;/li&gt;
&lt;li&gt;Scrapy部署到Docker&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day74---scrapy分布式实现" class="anchor" aria-hidden="true" href="#day74---scrapy分布式实现"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day74 - &lt;a href="./Day66-75/74.Scrapy%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E7%8E%B0.md"&gt;Scrapy分布式实现&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;分布式爬虫的原理&lt;/li&gt;
&lt;li&gt;Scrapy分布式实现&lt;/li&gt;
&lt;li&gt;使用Scrapyd实现分布式部署&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day75---爬虫项目实战" class="anchor" aria-hidden="true" href="#day75---爬虫项目实战"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day75 - &lt;a href="./Day66-75/75.%E7%88%AC%E8%99%AB%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.md"&gt;爬虫项目实战&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;爬取招聘网站数据&lt;/li&gt;
&lt;li&gt;爬取房地产行业数据&lt;/li&gt;
&lt;li&gt;爬取二手车交易平台数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day7690---数据处理和机器学习" class="anchor" aria-hidden="true" href="#day7690---数据处理和机器学习"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day76~90 - &lt;a href="./Day76-90"&gt;数据处理和机器学习&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day76---机器学习基础" class="anchor" aria-hidden="true" href="#day76---机器学习基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day76 - &lt;a href="./Day76-90/76.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md"&gt;机器学习基础&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day77---pandas的应用" class="anchor" aria-hidden="true" href="#day77---pandas的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day77 - &lt;a href="./Day76-90/77.Pandas%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;Pandas的应用&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day78---numpy和scipy的应用" class="anchor" aria-hidden="true" href="#day78---numpy和scipy的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day78 - &lt;a href="./Day76-90/78.NumPy%E5%92%8CSciPy%E7%9A%84%E5%BA%94%E7%94%A8"&gt;NumPy和SciPy的应用&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day79---matplotlib和数据可视化" class="anchor" aria-hidden="true" href="#day79---matplotlib和数据可视化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day79 - &lt;a href="./Day76-90/79.Matplotlib%E5%92%8C%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96"&gt;Matplotlib和数据可视化&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day80---k最近邻knn分类" class="anchor" aria-hidden="true" href="#day80---k最近邻knn分类"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day80 - &lt;a href="./Day76-90/80.k%E6%9C%80%E8%BF%91%E9%82%BB%E5%88%86%E7%B1%BB.md"&gt;k最近邻(KNN)分类&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day81---决策树" class="anchor" aria-hidden="true" href="#day81---决策树"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day81 - &lt;a href="./Day76-90/81.%E5%86%B3%E7%AD%96%E6%A0%91.md"&gt;决策树&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day82---贝叶斯分类" class="anchor" aria-hidden="true" href="#day82---贝叶斯分类"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day82 - &lt;a href="./Day76-90/82.%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB.md"&gt;贝叶斯分类&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day83---支持向量机svm" class="anchor" aria-hidden="true" href="#day83---支持向量机svm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day83 - &lt;a href="./Day76-90/83.%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.md"&gt;支持向量机(SVM)&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day84---k-均值聚类" class="anchor" aria-hidden="true" href="#day84---k-均值聚类"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day84 - &lt;a href="./Day76-90/84.K-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB.md"&gt;K-均值聚类&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day85---回归分析" class="anchor" aria-hidden="true" href="#day85---回归分析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day85 - &lt;a href="./Day76-90/85.%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90.md"&gt;回归分析&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day86---大数据分析入门" class="anchor" aria-hidden="true" href="#day86---大数据分析入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day86 - &lt;a href="./Day76-90/86.%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%85%A5%E9%97%A8.md"&gt;大数据分析入门&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day87---大数据分析进阶" class="anchor" aria-hidden="true" href="#day87---大数据分析进阶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day87 - &lt;a href="./Day76-90/87.%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%BF%9B%E9%98%B6.md"&gt;大数据分析进阶&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day88---tensorflow入门" class="anchor" aria-hidden="true" href="#day88---tensorflow入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day88 - &lt;a href="./Day76-90/88.Tensorflow%E5%85%A5%E9%97%A8.md"&gt;Tensorflow入门&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day89---tensorflow实战" class="anchor" aria-hidden="true" href="#day89---tensorflow实战"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day89 - &lt;a href="./Day76-90/89.Tensorflow%E5%AE%9E%E6%88%98.md"&gt;Tensorflow实战&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day90---推荐系统" class="anchor" aria-hidden="true" href="#day90---推荐系统"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day90 - &lt;a href="./Day76-90/90.%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.md"&gt;推荐系统&lt;/a&gt;&lt;/h4&gt;
&lt;h3&gt;&lt;a id="user-content-day91100---团队项目开发" class="anchor" aria-hidden="true" href="#day91100---团队项目开发"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day91~100 - &lt;a href="./Day91-100"&gt;团队项目开发&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-第91天团队项目开发的问题和解决方案" class="anchor" aria-hidden="true" href="#第91天团队项目开发的问题和解决方案"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第91天：&lt;a href="./Day91-100/91.%E5%9B%A2%E9%98%9F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md"&gt;团队项目开发的问题和解决方案&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;软件过程模型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;经典过程模型（瀑布模型）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可行性分析（研究做还是不做），输出《可行性分析报告》。&lt;/li&gt;
&lt;li&gt;需求分析（研究做什么），输出《需求规格说明书》和产品界面原型图。&lt;/li&gt;
&lt;li&gt;概要设计和详细设计，输出概念模型图、物理模型图、类图、时序图等。&lt;/li&gt;
&lt;li&gt;编码 / 测试。&lt;/li&gt;
&lt;li&gt;上线 / 维护。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;敏捷开发（Scrum）- 产品所有者、Scrum Master、研发人员 - Sprint&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;产品的Backlog（用户故事、产品原型）。&lt;/li&gt;
&lt;li&gt;计划会议（评估和预算）。&lt;/li&gt;
&lt;li&gt;日常开发（站立会议、番茄工作法、结对编程、测试先行、代码重构……）。&lt;/li&gt;
&lt;li&gt;修复bug（问题描述、重现步骤、测试人员、被指派人）。&lt;/li&gt;
&lt;li&gt;评审会议（Showcase）。&lt;/li&gt;
&lt;li&gt;回顾会议（当前周期做得好和不好的地方）。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;补充：敏捷软件开发宣言&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;个体和互动&lt;/strong&gt; 高于 流程和工具&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;工作的软件&lt;/strong&gt; 高于 详尽的文档&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;客户合作&lt;/strong&gt; 高于 合同谈判&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;响应变化&lt;/strong&gt; 高于 遵循计划&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/agile-scrum-sprint-cycle.png"&gt;&lt;img src="./res/agile-scrum-sprint-cycle.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;角色：产品所有者（决定做什么，能对需求拍板的人）、团队负责人（解决各种问题，专注如何更好的工作，屏蔽外部对开发团队的影响）、开发团队（项目执行人员，具体指开发人员和测试人员）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;准备工作：商业案例和资金、合同、憧憬、初始产品需求、初始发布计划、入股、组建团队。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;敏捷团队通常人数为8-10人。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;工作量估算：将开发任务量化，包括原型、Logo设计、UI设计、前端开发等，尽量把每个工作分解到最小任务量，最小任务量标准为工作时间不能超过两天，然后估算总体项目时间。把每个任务都贴在白板上面，白板上分三部分：to do（待完成）、in progress（进行中）和done（已完成）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;项目团队组建&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;团队的构成和角色&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;说明：谢谢付祥英女士绘制了下面这张精美的公司组织架构图。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/company_architecture.png"&gt;&lt;img src="./res/company_architecture.png" alt="company_architecture" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;编程规范和代码审查（flake8、pylint）&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/pylint.png"&gt;&lt;img src="./res/pylint.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Python中的一些“惯例”（请参考&lt;a href="Python%E6%83%AF%E4%BE%8B.md"&gt;《Python惯例-如何编写Pythonic的代码》&lt;/a&gt;）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;影响代码可读性的原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;代码注释太少或者没有注释&lt;/li&gt;
&lt;li&gt;代码破坏了语言的最佳实践&lt;/li&gt;
&lt;li&gt;反模式编程（意大利面代码、复制-黏贴编程、自负编程、……）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;团队开发工具介绍&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;版本控制：Git、Mercury&lt;/li&gt;
&lt;li&gt;缺陷管理：&lt;a href="https://about.gitlab.com/" rel="nofollow"&gt;Gitlab&lt;/a&gt;、&lt;a href="http://www.redmine.org.cn/" rel="nofollow"&gt;Redmine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;敏捷闭环工具：&lt;a href="https://www.zentao.net/" rel="nofollow"&gt;禅道&lt;/a&gt;、&lt;a href="https://www.atlassian.com/software/jira/features" rel="nofollow"&gt;JIRA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;持续集成：&lt;a href="https://jenkins.io/" rel="nofollow"&gt;Jenkins&lt;/a&gt;、&lt;a href="https://travis-ci.org/" rel="nofollow"&gt;Travis-CI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;请参考&lt;a href="Day91-100/%E5%9B%A2%E9%98%9F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91.md"&gt;《团队项目开发》&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-项目选题和理解业务" class="anchor" aria-hidden="true" href="#项目选题和理解业务"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目选题和理解业务&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;选题范围设定&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CMS（用户端）：新闻聚合网站、问答/分享社区、影评/书评网站等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MIS（用户端+管理端）：KMS、KPI考核系统、HRS、CRM系统、供应链系统、仓储管理系统等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;App后台（管理端+数据接口）：二手交易类、报刊杂志类、小众电商类、新闻资讯类、旅游类、社交类、阅读类等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;其他类型：自身行业背景和工作经验、业务容易理解和把控。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;需求理解、模块划分和任务分配&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需求理解：头脑风暴和竞品分析。&lt;/li&gt;
&lt;li&gt;模块划分：画思维导图（XMind），每个模块是一个枝节点，每个具体的功能是一个叶节点（用动词表述），需要确保每个叶节点无法再生出新节点，确定每个叶子节点的重要性、优先级和工作量。&lt;/li&gt;
&lt;li&gt;任务分配：由项目负责人根据上面的指标为每个团队成员分配任务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/requirements_by_xmind.png"&gt;&lt;img src="./res/requirements_by_xmind.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;制定项目进度表（每日更新）&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;th&gt;人员&lt;/th&gt;
&lt;th&gt;状态&lt;/th&gt;
&lt;th&gt;完成&lt;/th&gt;
&lt;th&gt;工时&lt;/th&gt;
&lt;th&gt;计划开始&lt;/th&gt;
&lt;th&gt;实际开始&lt;/th&gt;
&lt;th&gt;计划结束&lt;/th&gt;
&lt;th&gt;实际结束&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;评论&lt;/td&gt;
&lt;td&gt;添加评论&lt;/td&gt;
&lt;td&gt;王大锤&lt;/td&gt;
&lt;td&gt;正在进行&lt;/td&gt;
&lt;td&gt;50%&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;删除评论&lt;/td&gt;
&lt;td&gt;王大锤&lt;/td&gt;
&lt;td&gt;等待&lt;/td&gt;
&lt;td&gt;0%&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;查看评论&lt;/td&gt;
&lt;td&gt;白元芳&lt;/td&gt;
&lt;td&gt;正在进行&lt;/td&gt;
&lt;td&gt;20%&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;需要进行代码审查&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;评论投票&lt;/td&gt;
&lt;td&gt;白元芳&lt;/td&gt;
&lt;td&gt;等待&lt;/td&gt;
&lt;td&gt;0%&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2018/8/8&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/8&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OOAD和数据库设计&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;UML（统一建模语言）的类图&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/uml-class-diagram.png"&gt;&lt;img src="./res/uml-class-diagram.png" alt="uml" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过模型创建表（正向工程）&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python manage.py makemigrations app
python manage.py migrate&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用PowerDesigner绘制物理模型图。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/power-designer-pdm.png"&gt;&lt;img src="./res/power-designer-pdm.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过数据表创建模型（反向工程）&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python manage.py inspectdb &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; app/models.py&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-第92天使用docker部署应用" class="anchor" aria-hidden="true" href="#第92天使用docker部署应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第92天：&lt;a href="./Day91-100/92.%E4%BD%BF%E7%94%A8Docker%E9%83%A8%E7%BD%B2%E5%BA%94%E7%94%A8.md"&gt;使用Docker部署应用&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Docker简介&lt;/li&gt;
&lt;li&gt;安装Docker&lt;/li&gt;
&lt;li&gt;使用Docker创建容器（Nginx、MySQL、Redis、Gitlab、Jenkins）&lt;/li&gt;
&lt;li&gt;构建Docker镜像（Dockerfile的编写和相关指令）&lt;/li&gt;
&lt;li&gt;容器编排（Docker-compose）&lt;/li&gt;
&lt;li&gt;集群管理&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-第93天mysql性能优化" class="anchor" aria-hidden="true" href="#第93天mysql性能优化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第93天：&lt;a href="./Day91-100/93.MySQL%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.md"&gt;MySQL性能优化&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第94天网络api接口设计" class="anchor" aria-hidden="true" href="#第94天网络api接口设计"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第94天：&lt;a href="./Day91-100/94.%E7%BD%91%E7%BB%9CAPI%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1.md"&gt;网络API接口设计&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第95天使用django开发商业项目day91-10095使用django开发商业项目md" class="anchor" aria-hidden="true" href="#第95天使用django开发商业项目day91-10095使用django开发商业项目md"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第95天：[使用Django开发商业项目](./Day91-100/95.使用Django开发商业项	目.md)&lt;/h4&gt;
&lt;h5&gt;&lt;a id="user-content-项目开发中的公共问题" class="anchor" aria-hidden="true" href="#项目开发中的公共问题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目开发中的公共问题&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;数据库的配置（多数据库、主从复制、数据库路由）&lt;/li&gt;
&lt;li&gt;缓存的配置（分区缓存、键设置、超时设置、主从复制、故障恢复（哨兵））&lt;/li&gt;
&lt;li&gt;日志的配置&lt;/li&gt;
&lt;li&gt;分析和调试（Django-Debug-ToolBar）&lt;/li&gt;
&lt;li&gt;好用的Python模块（日期计算、图像处理、数据加密、三方API）&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-rest-api设计" class="anchor" aria-hidden="true" href="#rest-api设计"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;REST API设计&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;RESTful架构
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.ruanyifeng.com/blog/2011/09/restful.html" rel="nofollow"&gt;理解RESTful架构&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ruanyifeng.com/blog/2014/05/restful_api.html" rel="nofollow"&gt;RESTful API设计指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html" rel="nofollow"&gt;RESTful API最佳实践&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;API接口文档的撰写
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://rap2.taobao.org/" rel="nofollow"&gt;RAP2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://yapi.demo.qunar.com/" rel="nofollow"&gt;YAPI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.django-rest-framework.org/" rel="nofollow"&gt;django-REST-framework&lt;/a&gt;的应用&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-项目中的重点难点剖析" class="anchor" aria-hidden="true" href="#项目中的重点难点剖析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目中的重点难点剖析&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;使用缓存缓解数据库压力 - Redis&lt;/li&gt;
&lt;li&gt;使用消息队列做解耦合和削峰 - Celery + RabbitMQ&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-第96天软件测试和自动化测试" class="anchor" aria-hidden="true" href="#第96天软件测试和自动化测试"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第96天：&lt;a href="Day91-100/96.%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E5%92%8C%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95.md"&gt;软件测试和自动化测试&lt;/a&gt;&lt;/h4&gt;
&lt;h5&gt;&lt;a id="user-content-单元测试" class="anchor" aria-hidden="true" href="#单元测试"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;单元测试&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;测试的种类&lt;/li&gt;
&lt;li&gt;编写单元测试（unittest、pytest、nose2、tox、ddt、……）&lt;/li&gt;
&lt;li&gt;测试覆盖率（coverage）&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-项目部署" class="anchor" aria-hidden="true" href="#项目部署"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目部署&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;部署前的准备工作
&lt;ul&gt;
&lt;li&gt;关键设置（SECRET_KEY / DEBUG / ALLOWED_HOSTS / 缓存 / 数据库）&lt;/li&gt;
&lt;li&gt;HTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECURE&lt;/li&gt;
&lt;li&gt;日志相关配置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Linux常用命令回顾&lt;/li&gt;
&lt;li&gt;Linux常用服务的安装和配置&lt;/li&gt;
&lt;li&gt;uWSGI/Gunicorn和Nginx的使用
&lt;ul&gt;
&lt;li&gt;Gunicorn和uWSGI的比较
&lt;ul&gt;
&lt;li&gt;对于不需要大量定制化的简单应用程序，Gunicorn是一个不错的选择，uWSGI的学习曲线比Gunicorn要陡峭得多，Gunicorn的默认参数就已经能够适应大多数应用程序。&lt;/li&gt;
&lt;li&gt;uWSGI支持异构部署。&lt;/li&gt;
&lt;li&gt;由于Nginx本身支持uWSGI，在线上一般都将Nginx和uWSGI捆绑在一起部署，而且uWSGI属于功能齐全且高度定制的WSGI中间件。&lt;/li&gt;
&lt;li&gt;在性能上，Gunicorn和uWSGI其实表现相当。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;使用虚拟化技术（Docker）部署测试环境和生产环境&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-性能测试" class="anchor" aria-hidden="true" href="#性能测试"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;性能测试&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;AB的使用&lt;/li&gt;
&lt;li&gt;SQLslap的使用&lt;/li&gt;
&lt;li&gt;sysbench的使用&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-自动化测试" class="anchor" aria-hidden="true" href="#自动化测试"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;自动化测试&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;使用Shell和Python进行自动化测试&lt;/li&gt;
&lt;li&gt;使用Selenium实现自动化测试
&lt;ul&gt;
&lt;li&gt;Selenium IDE&lt;/li&gt;
&lt;li&gt;Selenium WebDriver&lt;/li&gt;
&lt;li&gt;Selenium Remote Control&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;测试工具Robot Framework介绍&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-第97天电商网站技术要点剖析" class="anchor" aria-hidden="true" href="#第97天电商网站技术要点剖析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第97天：&lt;a href="./Day91-100/97.%E7%94%B5%E5%95%86%E7%BD%91%E7%AB%99%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9%E5%89%96%E6%9E%90.md"&gt;电商网站技术要点剖析&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第98天项目部署上线和性能调优" class="anchor" aria-hidden="true" href="#第98天项目部署上线和性能调优"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第98天：&lt;a href="./Day91-100/98.%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E4%B8%8A%E7%BA%BF%E5%92%8C%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98.md"&gt;项目部署上线和性能调优&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;MySQL数据库调优&lt;/li&gt;
&lt;li&gt;Web服务器性能优化
&lt;ul&gt;
&lt;li&gt;Nginx负载均衡配置&lt;/li&gt;
&lt;li&gt;Keepalived实现高可用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;代码性能调优
&lt;ul&gt;
&lt;li&gt;多线程&lt;/li&gt;
&lt;li&gt;异步化&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;静态资源访问优化
&lt;ul&gt;
&lt;li&gt;云存储&lt;/li&gt;
&lt;li&gt;CDN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-第99天面试中的公共问题" class="anchor" aria-hidden="true" href="#第99天面试中的公共问题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第99天：&lt;a href="./Day91-100/99.%E9%9D%A2%E8%AF%95%E4%B8%AD%E7%9A%84%E5%85%AC%E5%85%B1%E9%97%AE%E9%A2%98.md"&gt;面试中的公共问题&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第100天python面试题集" class="anchor" aria-hidden="true" href="#第100天python面试题集"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第100天：&lt;a href="./Day91-100/100.Python%E9%9D%A2%E8%AF%95%E9%A2%98%E9%9B%86.md"&gt;Python面试题集&lt;/a&gt;&lt;/h4&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jackfrued</author><guid isPermaLink="false">https://github.com/jackfrued/Python-100-Days</guid><pubDate>Thu, 21 Nov 2019 00:03:00 GMT</pubDate></item><item><title>lexfridman/mit-deep-learning #4 in Jupyter Notebook, This week</title><link>https://github.com/lexfridman/mit-deep-learning</link><description>&lt;p&gt;&lt;i&gt;Tutorials, assignments, and competitions for MIT Deep Learning related courses.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-mit-deep-learning" class="anchor" aria-hidden="true" href="#mit-deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MIT Deep Learning&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://deeplearning.mit.edu/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/42d3d635cdb0e88dee786c6edc1f41e0902faa2b/68747470733a2f2f646565706c6561726e696e672e6d69742e6564752f66696c65732f696d616765732f6d69745f646565705f6c6561726e696e672e706e67" data-canonical-src="https://deeplearning.mit.edu/files/images/mit_deep_learning.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repository is a collection of tutorials for &lt;a href="https://deeplearning.mit.edu/" rel="nofollow"&gt;MIT Deep Learning&lt;/a&gt; courses. More added as courses progress.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tutorial-deep-learning-basics" class="anchor" aria-hidden="true" href="#tutorial-deep-learning-basics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorial: Deep Learning Basics&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb"&gt;&lt;img src="https://camo.githubusercontent.com/0d2d7920619e3df257f1c677431968ff491a5e80/68747470733a2f2f692e696d6775722e636f6d2f6a3446714275522e676966" data-canonical-src="https://i.imgur.com/j4FqBuR.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tutorial accompanies the &lt;a href="https://www.youtube.com/watch?list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf&amp;amp;v=O5xeyoRL95U" rel="nofollow"&gt;lecture on Deep Learning Basics&lt;/a&gt;. It presents several concepts in deep learning, demonstrating the first two (feed forward and convolutional neural networks) and providing pointers to tutorials on the others. This is a good place to start.&lt;/p&gt;
&lt;p&gt;Links: [ &lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb"&gt;Jupyter Notebook&lt;/a&gt; ]
[ &lt;a href="https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb" rel="nofollow"&gt;Google Colab&lt;/a&gt; ]
[ &lt;a href="https://medium.com/tensorflow/mit-deep-learning-basics-introduction-and-overview-with-tensorflow-355bcd26baf0" rel="nofollow"&gt;Blog Post&lt;/a&gt; ]
[ &lt;a href="https://www.youtube.com/watch?list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf&amp;amp;v=O5xeyoRL95U" rel="nofollow"&gt;Lecture Video&lt;/a&gt; ]&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tutorial-driving-scene-segmentation" class="anchor" aria-hidden="true" href="#tutorial-driving-scene-segmentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorial: Driving Scene Segmentation&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_driving_scene_segmentation/tutorial_driving_scene_segmentation.ipynb"&gt;&lt;img src="images/thumb_driving_scene_segmentation.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tutorial demostrates semantic segmentation with a state-of-the-art model (DeepLab) on a sample video from the MIT Driving Scene Segmentation Dataset.&lt;/p&gt;
&lt;p&gt;Links: [ &lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_driving_scene_segmentation/tutorial_driving_scene_segmentation.ipynb"&gt;Jupyter Notebook&lt;/a&gt; ]
[ &lt;a href="https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_driving_scene_segmentation/tutorial_driving_scene_segmentation.ipynb" rel="nofollow"&gt;Google Colab&lt;/a&gt; ]&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tutorial-generative-adversarial-networks-gans" class="anchor" aria-hidden="true" href="#tutorial-generative-adversarial-networks-gans"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorial: Generative Adversarial Networks (GANs)&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_gans/tutorial_gans.ipynb"&gt;&lt;img src="images/thumb_mushroom_biggan.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tutorial explores generative adversarial networks (GANs) starting with BigGAN, the state-of-the-art conditional GAN.&lt;/p&gt;
&lt;p&gt;Links: [ &lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_gans/tutorial_gans.ipynb"&gt;Jupyter Notebook&lt;/a&gt; ]
[ &lt;a href="https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_gans/tutorial_gans.ipynb" rel="nofollow"&gt;Google Colab&lt;/a&gt; ]&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-deeptraffic-deep-reinforcement-learning-competition" class="anchor" aria-hidden="true" href="#deeptraffic-deep-reinforcement-learning-competition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DeepTraffic Deep Reinforcement Learning Competition&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://selfdrivingcars.mit.edu/deeptraffic" rel="nofollow"&gt;&lt;img src="images/thumb_deeptraffic.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;DeepTraffic is a deep reinforcement learning competition. The goal is to create a neural network that drives a vehicle (or multiple vehicles) as fast as possible through dense highway traffic.&lt;/p&gt;
&lt;p&gt;Links: [ &lt;a href="https://github.com/lexfridman/deeptraffic"&gt;GitHub&lt;/a&gt; ] [ &lt;a href="https://selfdrivingcars.mit.edu/deeptraffic" rel="nofollow"&gt;Website&lt;/a&gt; ] [ &lt;a href="https://arxiv.org/abs/1801.02805" rel="nofollow"&gt;Paper&lt;/a&gt; ]&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-team" class="anchor" aria-hidden="true" href="#team"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Team&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://lexfridman.com" rel="nofollow"&gt;Lex Fridman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~liding/" rel="nofollow"&gt;Li Ding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~jterwill/" rel="nofollow"&gt;Jack Terwilliger&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~glazermi/" rel="nofollow"&gt;Michael Glazer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~patsekin/" rel="nofollow"&gt;Aleksandr Patsekin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~aishni/" rel="nofollow"&gt;Aishni Parab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~aladawy/" rel="nofollow"&gt;Dina AlAdawy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~henris/" rel="nofollow"&gt;Henri Schmidt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>lexfridman</author><guid isPermaLink="false">https://github.com/lexfridman/mit-deep-learning</guid><pubDate>Thu, 21 Nov 2019 00:04:00 GMT</pubDate></item><item><title>tensorflow/tpu #5 in Jupyter Notebook, This week</title><link>https://github.com/tensorflow/tpu</link><description>&lt;p&gt;&lt;i&gt;Reference models and tools for Cloud TPUs.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-cloud-tpus" class="anchor" aria-hidden="true" href="#cloud-tpus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cloud TPUs&lt;/h1&gt;
&lt;p&gt;This repository is a collection of reference models and tools used with
&lt;a href="https://cloud.google.com/tpu/" rel="nofollow"&gt;Cloud TPUs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The fastest way to get started training a model on a Cloud TPU is by following
the tutorial. Click the button below to launch the tutorial using Google Cloud
Shell.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://console.cloud.google.com/cloudshell/open?git_repo=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftpu&amp;amp;page=shell&amp;amp;tutorial=tools%2Fctpu%2Ftutorial.md" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/acf32864fdae185325f992b48fb2132badef1e9a/687474703a2f2f677374617469632e636f6d2f636c6f75647373682f696d616765732f6f70656e2d62746e2e737667" alt="Open in Cloud Shell" data-canonical-src="http://gstatic.com/cloudssh/images/open-btn.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; This repository is a public mirror, pull requests will not be accepted.
Please file an issue if you have a feature or bug request.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-running-models" class="anchor" aria-hidden="true" href="#running-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running Models&lt;/h2&gt;
&lt;p&gt;To run models in the &lt;code&gt;models&lt;/code&gt; subdirectory, you may need to add the top-level
&lt;code&gt;/models&lt;/code&gt; folder to the Python path with the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export PYTHONPATH="$PYTHONPATH:/path/to/models"
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>tensorflow</author><guid isPermaLink="false">https://github.com/tensorflow/tpu</guid><pubDate>Thu, 21 Nov 2019 00:05:00 GMT</pubDate></item><item><title>google-research/google-research #6 in Jupyter Notebook, This week</title><link>https://github.com/google-research/google-research</link><description>&lt;p&gt;&lt;i&gt;Google AI Research&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-google-ai-research" class="anchor" aria-hidden="true" href="#google-ai-research"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Google AI Research&lt;/h1&gt;
&lt;p&gt;This repository contains code released by
&lt;a href="https://ai.google/research" rel="nofollow"&gt;Google AI Research&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Because the repo is large, we recommend you clone the repo without its history.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone git@github.com:google-research/google-research.git --depth=1
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Disclaimer: This is not an official Google product.&lt;/em&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>google-research</author><guid isPermaLink="false">https://github.com/google-research/google-research</guid><pubDate>Thu, 21 Nov 2019 00:06:00 GMT</pubDate></item><item><title>practicalAI/practicalAI #7 in Jupyter Notebook, This week</title><link>https://github.com/practicalAI/practicalAI</link><description>&lt;p&gt;&lt;i&gt;📚 A practical approach to machine learning. &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;div align="center"&gt;
&lt;a href="https://practicalai.me" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/369fcfdcd241a0324ffaee51715926a56c049302/68747470733a2f2f70726163746963616c61692e6d652f7374617469632f696d672f70726163746963616c41492f6c6f676f2e706e67" width="200" data-canonical-src="https://practicalai.me/static/img/practicalAI/logo.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;p&gt;A &lt;i&gt;&lt;b&gt;practical&lt;/b&gt;&lt;/i&gt; approach to machine learning.&lt;/p&gt;
&lt;a href="https://github.com/practicalAI/practicalAI"&gt;
&lt;img src="https://camo.githubusercontent.com/c1b6c20adc52e06a1c58218665169097a63bd549/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70726163746963616c41492f70726163746963616c41492e7376673f7374796c653d736f6369616c266c6162656c3d53746172" data-canonical-src="https://img.shields.io/github/stars/practicalAI/practicalAI.svg?style=social&amp;amp;label=Star" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://www.linkedin.com/company/practicalai-me" rel="nofollow"&gt;
&lt;img src="https://camo.githubusercontent.com/19c0cf9ba93aa446aa855a0203c46ee39841cba9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7374796c652d2d3565626130302e7376673f6c6162656c3d4c696e6b6564496e266c6f676f3d6c696e6b6564696e267374796c653d736f6369616c" data-canonical-src="https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&amp;amp;logo=linkedin&amp;amp;style=social" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://twitter.com/GokuMohandas" rel="nofollow"&gt;
&lt;img src="https://camo.githubusercontent.com/fd3346389d2255e7c7aa4395d6afb74e7a1df552/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f476f6b754d6f68616e6461732e7376673f6c6162656c3d466f6c6c6f77267374796c653d736f6369616c" data-canonical-src="https://img.shields.io/twitter/follow/GokuMohandas.svg?label=Follow&amp;amp;style=social" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;p&gt;&lt;sub&gt;Created by
&lt;a href="https://goku.me" rel="nofollow"&gt;Goku Mohandas&lt;/a&gt; and
&lt;a href="https://github.com/GokuMohandas/practicalAI/graphs/contributors"&gt;
contributors
&lt;/a&gt;
&lt;/sub&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-notebooks" class="anchor" aria-hidden="true" href="#notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notebooks&lt;/h2&gt;
&lt;ul&gt;
    &lt;li&gt;
        &lt;g-emoji class="g-emoji" alias="earth_americas" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f30e.png"&gt;🌎&lt;/g-emoji&gt; → &lt;a href="https://practicalai.me" rel="nofollow"&gt;https://practicalai.me&lt;/a&gt;
    &lt;/li&gt;
    &lt;li&gt;
        All of these notebooks are in &lt;a href="https://tensorflow.org" rel="nofollow"&gt;TensorFlow 2.0 + Keras&lt;/a&gt; but you can find old PyTorch notebooks in the &lt;a href="https://github.com/practicalAI/practicalAI/tree/4ad626098aca25db5628fe67895e738d5a5c2c2a"&gt;v0.1&lt;/a&gt; release.
    &lt;/li&gt;
    &lt;li&gt;
        If you prefer Jupyter Notebooks or want to add/fix content, check out the &lt;a href="https://github.com/practicalAI/practicalAI/tree/master/notebooks"&gt;notebooks&lt;/a&gt; directory.
    &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="2"&gt;
        &lt;h4 align="center"&gt;&lt;a id="user-content-basic-ml" class="anchor" aria-hidden="true" href="#basic-ml"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Basic ML&lt;/h4&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center"&gt;&lt;b&gt;Basics&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Machine Learning&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Tools&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Deep Learning&lt;/b&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="4"&gt;
        &lt;ul&gt;
            &lt;li&gt;Learn Python basics with notebooks.&lt;/li&gt;
            &lt;li&gt;Use data science libraries like &lt;a href="https://www.numpy.org/" rel="nofollow"&gt;NumPy&lt;/a&gt; and &lt;a href="https://pandas.pydata.org/" rel="nofollow"&gt;Pandas&lt;/a&gt;.&lt;/li&gt;
            &lt;li&gt;Implement basic ML models in &lt;a href="https://www.tensorflow.org/overview/" rel="nofollow"&gt;TensorFlow 2.0 + Keras&lt;/a&gt;.&lt;/li&gt;
            &lt;li&gt;Create deep learning models for improved performance.&lt;/li&gt;
        &lt;/ul&gt;
        &lt;/td&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/00_Notebooks.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="notebook" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png"&gt;📓&lt;/g-emoji&gt; Notebooks&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="chart_with_upwards_trend" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4c8.png"&gt;📈&lt;/g-emoji&gt; Linear Regression&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="mag_right" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f50e.png"&gt;🔎&lt;/g-emoji&gt; Data &amp;amp; Models&lt;/td&gt;
        &lt;td&gt;️&lt;g-emoji class="g-emoji" alias="framed_picture" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5bc.png"&gt;🖼&lt;/g-emoji&gt; Convolutional Neural Networks&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/01_Python.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="snake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f40d.png"&gt;🐍&lt;/g-emoji&gt; Python&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="bar_chart" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ca.png"&gt;📊&lt;/g-emoji&gt; Logistic Regression&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="hammer_and_wrench" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6e0.png"&gt;🛠&lt;/g-emoji&gt; Utilities&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="crown" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f451.png"&gt;👑&lt;/g-emoji&gt; Embeddings&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/02_NumPy.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="1234" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f522.png"&gt;🔢&lt;/g-emoji&gt; NumPy&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;️&lt;g-emoji class="g-emoji" alias="control_knobs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f39b.png"&gt;🎛&lt;/g-emoji&gt; Multilayer Perceptrons&lt;/td&gt;
        &lt;td&gt;️&lt;g-emoji class="g-emoji" alias="scissors" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2702.png"&gt;✂️&lt;/g-emoji&gt; Preprocessing&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="green_book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d7.png"&gt;📗&lt;/g-emoji&gt; Recurrent Neural Networks&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/03_Pandas.ipynb" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="panda_face" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f43c.png"&gt;🐼&lt;/g-emoji&gt; Pandas&lt;/a&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="2"&gt;&lt;h4 align="center"&gt;&lt;a id="user-content-production-ml" class="anchor" aria-hidden="true" href="#production-ml"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Production ML&lt;/h4&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center"&gt;&lt;b&gt;Local&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Applications&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Scale&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Miscellaneous&lt;/b&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="3"&gt;
        &lt;ul&gt;
            &lt;li&gt;Setup your local environment for ML.&lt;/li&gt;
            &lt;li&gt;Wrap your ML in RESTful APIs using &lt;a href="http://flask.pocoo.org/" rel="nofollow"&gt;Flask&lt;/a&gt; to create applications.&lt;/li&gt;
            &lt;li&gt;Standardize and scale your ML applications with &lt;a href="https://www.docker.com/" rel="nofollow"&gt;Docker&lt;/a&gt; and &lt;a href="https://kubernetes.io/" rel="nofollow"&gt;Kubernetes&lt;/a&gt;.&lt;/li&gt;
            &lt;li&gt;Deploy simple and scalable ML workflows using &lt;a href="https://www.kubeflow.org/" rel="nofollow"&gt;Kubeflow&lt;/a&gt;.&lt;/li&gt;
        &lt;/ul&gt;
        &lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="computer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png"&gt;💻&lt;/g-emoji&gt; Local Setup&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="evergreen_tree" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f332.png"&gt;🌲&lt;/g-emoji&gt; Logging&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="whale" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f433.png"&gt;🐳&lt;/g-emoji&gt; Docker&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="handshake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f91d.png"&gt;🤝&lt;/g-emoji&gt; Distributed Training&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="snake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f40d.png"&gt;🐍&lt;/g-emoji&gt; ML Scripts&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="funeral_urn" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26b1.png"&gt;⚱️&lt;/g-emoji&gt; Flask Applications&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="ship" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a2.png"&gt;🚢&lt;/g-emoji&gt; Kubernetes&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="battery" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f50b.png"&gt;🔋&lt;/g-emoji&gt; Databases&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="white_check_mark" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png"&gt;✅&lt;/g-emoji&gt; Unit Tests&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="ocean" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f30a.png"&gt;🌊&lt;/g-emoji&gt; Kubeflow&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="closed_lock_with_key" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f510.png"&gt;🔐&lt;/g-emoji&gt; Authentication&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="2"&gt;&lt;h4 align="center"&gt;&lt;a id="user-content-advanced-ml" class="anchor" aria-hidden="true" href="#advanced-ml"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Advanced ML&lt;/h4&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center"&gt;&lt;b&gt;General&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Sequential&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Popular&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Miscellaneous&lt;/b&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="3"&gt;
        &lt;ul&gt;
            &lt;li&gt;Dive into architectural and interpretable advancements in neural networks.&lt;/li&gt;
            &lt;li&gt;Implement state-of-the-art NLP techniques.&lt;/li&gt;
            &lt;li&gt;Learn about popular deep learning algorithms used for generation, time-series, etc.&lt;/li&gt;
        &lt;/ul&gt;
        &lt;/td&gt;
        &lt;td&gt;🧐 Attention&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="bee" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f41d.png"&gt;🐝&lt;/g-emoji&gt; Transformers&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="performing_arts" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3ad.png"&gt;🎭&lt;/g-emoji&gt; Generative Adversarial Networks&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png"&gt;🔮&lt;/g-emoji&gt; Autoencoders&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="racing_car" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3ce.png"&gt;🏎️&lt;/g-emoji&gt; Highway Networks&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="japanese_ogre" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f479.png"&gt;👹&lt;/g-emoji&gt; BERT, GPT2, XLNet&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="8ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3b1.png"&gt;🎱&lt;/g-emoji&gt; Bayesian Deep Learning&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="spider" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f577.png"&gt;🕷️&lt;/g-emoji&gt; Graph Neural Networks&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="droplet" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a7.png"&gt;💧&lt;/g-emoji&gt; Residual Networks&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="clock9" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f558.png"&gt;🕘&lt;/g-emoji&gt; Temporal CNNs&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="cherries" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f352.png"&gt;🍒&lt;/g-emoji&gt; Reinforcement Learning&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="2"&gt;&lt;h4 align="center"&gt;&lt;a id="user-content-topics" class="anchor" aria-hidden="true" href="#topics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Topics&lt;/h4&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center"&gt;&lt;b&gt;Computer Vision&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Natural Language&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Unsupervised Learning&lt;/b&gt;&lt;/td&gt;
        &lt;td align="center"&gt;&lt;b&gt;Miscellaneous&lt;/b&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
        &lt;td colspan="1" rowspan="4"&gt;
        &lt;ul&gt;
            &lt;li&gt;Learn how to use deep learning for computer vision tasks.&lt;/li&gt;
            &lt;li&gt;Implement techniques for natural language tasks.&lt;/li&gt;
            &lt;li&gt;Derive insights from unlabeled data using unsupervised learning.&lt;/li&gt;
        &lt;/ul&gt;
        &lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="camera_flash" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f8.png"&gt;📸&lt;/g-emoji&gt; Image Recognition&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png"&gt;📖&lt;/g-emoji&gt; Text classification&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="dango" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f361.png"&gt;🍡&lt;/g-emoji&gt; Clustering&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="alarm_clock" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/23f0.png"&gt;⏰&lt;/g-emoji&gt; Time-series Analysis&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="framed_picture" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5bc.png"&gt;🖼️&lt;/g-emoji&gt; Image Segmentation&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="speech_balloon" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ac.png"&gt;💬&lt;/g-emoji&gt; Named Entity Recognition&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="houses" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3d8.png"&gt;🏘️&lt;/g-emoji&gt; Topic Modeling&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="shopping_cart" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6d2.png"&gt;🛒&lt;/g-emoji&gt; Recommendation Systems&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="art" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3a8.png"&gt;🎨&lt;/g-emoji&gt; Image Generation&lt;/td&gt;
        &lt;td&gt;🧠 Knowledge Graphs&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="dart" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png"&gt;🎯&lt;/g-emoji&gt; One-shot Learning&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;g-emoji class="g-emoji" alias="card_file_box" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5c3.png"&gt;🗃️&lt;/g-emoji&gt; Interpretability&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-updates" class="anchor" aria-hidden="true" href="#updates"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Updates&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://practicalai.me/#newsletter" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="mailbox_with_mail" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ec.png"&gt;📬&lt;/g-emoji&gt; Newsletter&lt;/a&gt; - Subscribe to get updates on new content&lt;/p&gt;
&lt;div&gt;
&lt;a href="https://twitter.com/practicalai_me" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6729390835283dc393cb7f500d840be48cdac6c6/68747470733a2f2f70726163746963616c61692e6d652f7374617469632f696d672f6d656469612f74772e706e67" width="30" data-canonical-src="https://practicalai.me/static/img/media/tw.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.youtube.com/channel/UCgW4K2UDK21kHIzxpjNos7Q" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/786df4e8cd9d5421583bf063cdcf9e3d06d14de5/68747470733a2f2f70726163746963616c61692e6d652f7374617469632f696d672f6d656469612f7974622e706e67" width="30" data-canonical-src="https://practicalai.me/static/img/media/ytb.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/practicalAI/practicalAI"&gt;&lt;img src="https://camo.githubusercontent.com/082d52273e2945cb5126868e9cc44d4c91ffe912/68747470733a2f2f70726163746963616c61692e6d652f7374617469632f696d672f6d656469612f677468622e706e67" width="30" data-canonical-src="https://practicalai.me/static/img/media/gthb.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.linkedin.com/company/practicalai-me" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/045b09864f16b18059d20d17bfaf906b26ca3aae/68747470733a2f2f70726163746963616c61692e6d652f7374617469632f696d672f6d656469612f6c6e6b646e2e706e67" width="30" data-canonical-src="https://practicalai.me/static/img/media/lnkdn.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>practicalAI</author><guid isPermaLink="false">https://github.com/practicalAI/practicalAI</guid><pubDate>Thu, 21 Nov 2019 00:07:00 GMT</pubDate></item><item><title>czy36mengfei/tensorflow2_tutorials_chinese #8 in Jupyter Notebook, This week</title><link>https://github.com/czy36mengfei/tensorflow2_tutorials_chinese</link><description>&lt;p&gt;&lt;i&gt;tensorflow2中文教程，持续更新(当前版本:tensorflow2.0)，tag: tensorflow 2.0 tutorials&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow2_tutorials_chinese" class="anchor" aria-hidden="true" href="#tensorflow2_tutorials_chinese"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;tensorflow2_tutorials_chinese&lt;/h1&gt;
&lt;p&gt;tensorflow2中文教程，持续更新（不定期更新）&lt;/p&gt;
&lt;p&gt;tensorflow 2.0 正式版已上线， 后面将持续根据TensorFlow2的相关教程和学习资料。&lt;/p&gt;
&lt;p&gt;最新tensorflow教程和相关资源，请关注微信公众号：DoitNLP，
后面我会在DoitNLP上，持续更新深度学习、NLP、Tensorflow的相关教程和前沿资讯，它将成为我们一起学习tensorflow的大本营。&lt;/p&gt;
&lt;p&gt;当前tensorflow版本：tensorflow2.0&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最全Tensorflow 2.0 教程持续更新：&lt;/strong&gt;
&lt;a href="https://zhuanlan.zhihu.com/p/59507137" rel="nofollow"&gt;https://zhuanlan.zhihu.com/p/59507137&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本教程主要由tensorflow2.0官方教程的个人学习复现笔记整理而来，并借鉴了一些keras构造神经网络的方法，中文讲解，方便喜欢阅读中文教程的朋友，tensorflow官方教程：&lt;a href="https://www.tensorflow.org" rel="nofollow"&gt;https://www.tensorflow.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58825020" rel="nofollow"&gt;TensorFlow 2.0 教程- Keras 快速入门&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58825710" rel="nofollow"&gt;TensorFlow 2.0 教程-keras 函数api&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58826227" rel="nofollow"&gt;TensorFlow 2.0 教程-使用keras训练模型&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59481536" rel="nofollow"&gt;TensorFlow 2.0 教程-用keras构建自己的网络层&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59481985" rel="nofollow"&gt;TensorFlow 2.0 教程-keras模型保存和序列化&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59482373" rel="nofollow"&gt;TensorFlow 2.0 教程-eager模式&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59482589" rel="nofollow"&gt;TensorFlow 2.0 教程-Variables&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59482934" rel="nofollow"&gt;TensorFlow 2.0 教程--AutoGraph&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;TensorFlow 2.0 深度学习实践&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59506238" rel="nofollow"&gt;TensorFlow2.0 教程-图像分类&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59506402" rel="nofollow"&gt;TensorFlow2.0 教程-文本分类&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59506543" rel="nofollow"&gt;TensorFlow2.0 教程-过拟合和欠拟合&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60232704" rel="nofollow"&gt;TensorFlow2.0教程-结构化数据分类&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60238056" rel="nofollow"&gt;TensorFlow2.0教程-回归&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60485936" rel="nofollow"&gt;TensorFlow2.0教程-保持和读取模型&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;TensorFlow 2.0 基础网络结构&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60899040" rel="nofollow"&gt;TensorFlow2教程-基础MLP网络&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60900318" rel="nofollow"&gt;TensorFlow2教程-MLP及深度学习常见技巧&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60900649" rel="nofollow"&gt;TensorFlow2教程-基础CNN网络&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60900902" rel="nofollow"&gt;TensorFlow2教程-CNN变体网络&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60901179" rel="nofollow"&gt;TensorFlow2教程-文本卷积&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60966714" rel="nofollow"&gt;TensorFlow2教程-LSTM和GRU&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61077346" rel="nofollow"&gt;TensorFlow2教程-自编码器&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61080045" rel="nofollow"&gt;TensorFlow2教程-卷积自编码器&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61224215" rel="nofollow"&gt;TensorFlow2教程-词嵌入&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61280722" rel="nofollow"&gt;TensorFlow2教程-DCGAN&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61400276" rel="nofollow"&gt;TensorFlow2教程-使用Estimator构建Boosted trees&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;TensorFlow 2.0 安装&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61472293" rel="nofollow"&gt;TensorFlow2教程-Ubuntu安装TensorFlow 2.0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62036280" rel="nofollow"&gt;TensorFlow2教程-Windows安装tensorflow2.0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;完整tensorflow2.0教程代码请看&lt;a href="https://github.com/czy36mengfei/tensorflow2_tutorials_chinese"&gt;tensorflow2.0：中文教程tensorflow2_tutorials_chinese(欢迎star)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;更多TensorFlow 2.0 入门教程请持续关注专栏：&lt;a href="https://zhuanlan.zhihu.com/c_1091021863043624960" rel="nofollow"&gt;Tensorflow2教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;深度学习入门书籍和资源推荐：&lt;a href="https://zhuanlan.zhihu.com/p/65371424" rel="nofollow"&gt;https://zhuanlan.zhihu.com/p/65371424&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>czy36mengfei</author><guid isPermaLink="false">https://github.com/czy36mengfei/tensorflow2_tutorials_chinese</guid><pubDate>Thu, 21 Nov 2019 00:08:00 GMT</pubDate></item><item><title>Pierian-Data/Complete-Python-3-Bootcamp #9 in Jupyter Notebook, This week</title><link>https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</link><description>&lt;p&gt;&lt;i&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-complete-python-3-bootcamp" class="anchor" aria-hidden="true" href="#complete-python-3-bootcamp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Complete-Python-3-Bootcamp&lt;/h1&gt;
&lt;p&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/p&gt;
&lt;p&gt;Get it now for 95% off with the link:
&lt;a href="https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB" rel="nofollow"&gt;https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Pierian-Data</author><guid isPermaLink="false">https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</guid><pubDate>Thu, 21 Nov 2019 00:09:00 GMT</pubDate></item><item><title>fastai/fastai #10 in Jupyter Notebook, This week</title><link>https://github.com/fastai/fastai</link><description>&lt;p&gt;&lt;i&gt;The fastai deep learning library, plus lessons and tutorials&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://dev.azure.com/fastdotai/fastai/_build/latest?definitionId=1" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a1b1234cce0c844f75224d1df07b4f236f78aee7/68747470733a2f2f6465762e617a7572652e636f6d2f66617374646f7461692f6661737461692f5f617069732f6275696c642f7374617475732f6661737461692e666173746169" alt="Build Status" data-canonical-src="https://dev.azure.com/fastdotai/fastai/_apis/build/status/fastai.fastai" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.python.org/pypi/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/26f7b20369ea7a096cfb30bdf0d14bc6ceda0275/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6661737461692e737667" alt="pypi fastai version" data-canonical-src="https://img.shields.io/pypi/v/fastai.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://anaconda.org/fastai/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2c20a6e61cb1c612b644253db1e3c1f7972d7f0e/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f762f6661737461692f6661737461692e737667" alt="Conda fastai version" data-canonical-src="https://img.shields.io/conda/v/fastai/fastai.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://anaconda.org/fastai/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/39f258e6563b60eef6a88589cd194d3a85033747/68747470733a2f2f616e61636f6e64612e6f72672f6661737461692f6661737461692f6261646765732f706c6174666f726d732e737667" alt="Anaconda-Server Badge" data-canonical-src="https://anaconda.org/fastai/fastai/badges/platforms.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.python.org/pypi/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6dc643192dbbbd8edda826d1be289ba06ef2b57f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6661737461692e737667" alt="fastai python compatibility" data-canonical-src="https://img.shields.io/pypi/pyversions/fastai.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.python.org/pypi/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f600abfa75b593d49643c1710ed42865373f9d75/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f6661737461692e737667" alt="fastai license" data-canonical-src="https://img.shields.io/pypi/l/fastai.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-fastai" class="anchor" aria-hidden="true" href="#fastai"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;fastai&lt;/h1&gt;
&lt;p&gt;The fastai library simplifies training fast and accurate neural nets using modern best practices. See the &lt;a href="https://docs.fast.ai" rel="nofollow"&gt;fastai website&lt;/a&gt; to get started. The library is based on research into deep learning best practices undertaken at &lt;a href="http://www.fast.ai" rel="nofollow"&gt;fast.ai&lt;/a&gt;, and includes "out of the box" support for &lt;a href="https://docs.fast.ai/vision.html#vision" rel="nofollow"&gt;&lt;code&gt;vision&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://docs.fast.ai/text.html#text" rel="nofollow"&gt;&lt;code&gt;text&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://docs.fast.ai/tabular.html#tabular" rel="nofollow"&gt;&lt;code&gt;tabular&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://docs.fast.ai/collab.html#collab" rel="nofollow"&gt;&lt;code&gt;collab&lt;/code&gt;&lt;/a&gt; (collaborative filtering) models. For brief examples, see the &lt;a href="https://github.com/fastai/fastai/tree/master/examples"&gt;examples&lt;/a&gt; folder; detailed examples are provided in the full &lt;a href="https://docs.fast.ai/" rel="nofollow"&gt;documentation&lt;/a&gt;. For instance, here's how to train an MNIST model using &lt;a href="https://arxiv.org/abs/1512.03385" rel="nofollow"&gt;resnet18&lt;/a&gt; (from the &lt;a href="https://github.com/fastai/fastai/blob/master/examples/vision.ipynb"&gt;vision example&lt;/a&gt;):&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; fastai.vision &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;
path &lt;span class="pl-k"&gt;=&lt;/span&gt; untar_data(&lt;span class="pl-c1"&gt;MNIST_PATH&lt;/span&gt;)
data &lt;span class="pl-k"&gt;=&lt;/span&gt; image_data_from_folder(path)
learn &lt;span class="pl-k"&gt;=&lt;/span&gt; cnn_learner(data, models.resnet18, &lt;span class="pl-v"&gt;metrics&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;accuracy)
learn.fit(&lt;span class="pl-c1"&gt;1&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-note-for-coursefastai-students" class="anchor" aria-hidden="true" href="#note-for-coursefastai-students"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Note for &lt;a href="http://course.fast.ai" rel="nofollow"&gt;course.fast.ai&lt;/a&gt; students&lt;/h2&gt;
&lt;p&gt;This document is written for &lt;code&gt;fastai v1&lt;/code&gt;, which we use for the current version the &lt;a href="http://course.fast.ai" rel="nofollow"&gt;course.fast.ai&lt;/a&gt; deep learning courses. If you're following along with a course at &lt;a href="http://course18.fast.ai" rel="nofollow"&gt;course18.fast.ai&lt;/a&gt; (i.e. the machine learning course, which isn't updated for v1) you need to use &lt;code&gt;fastai 0.7&lt;/code&gt;;  please follow the installation instructions &lt;a href="https://forums.fast.ai/t/fastai-v0-install-issues-thread/24652" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt; &lt;em&gt;fastai v1 currently supports Linux only, and requires &lt;strong&gt;PyTorch v1&lt;/strong&gt; and &lt;strong&gt;Python 3.6&lt;/strong&gt; or later. Windows support is at an experimental stage: it should work fine but it's much slower and less well tested. Since Macs don't currently have good Nvidia GPU support, we do not currently prioritize Mac development.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;fastai-1.x&lt;/code&gt; can be installed with either &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;pip&lt;/code&gt; package managers and also from source. At the moment you can't just run &lt;em&gt;install&lt;/em&gt;, since you first need to get the correct &lt;code&gt;pytorch&lt;/code&gt; version installed - thus to get &lt;code&gt;fastai-1.x&lt;/code&gt; installed choose one of the installation recipes below using your favorite python package manager. Note that &lt;strong&gt;PyTorch v1&lt;/strong&gt; and &lt;strong&gt;Python 3.6&lt;/strong&gt; are the minimal version requirements.&lt;/p&gt;
&lt;p&gt;It's highly recommended you install &lt;code&gt;fastai&lt;/code&gt; and its dependencies in a virtual environment (&lt;a href="https://conda.io/docs/user-guide/tasks/manage-environments.html" rel="nofollow"&gt;&lt;code&gt;conda&lt;/code&gt;&lt;/a&gt; or others), so that you don't interfere with system-wide python packages. It's not that you must, but if you experience problems with any dependency packages, please consider using a fresh virtual environment just for &lt;code&gt;fastai&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Starting with pytorch-1.x you no longer need to install a special pytorch-cpu version. Instead use the normal pytorch and it works with and without GPU. But &lt;a href="https://docs.fast.ai/install.html#cpu-build" rel="nofollow"&gt;you can install the cpu build too&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you experience installation problems, please read about &lt;a href="https://github.com/fastai/fastai/blob/master/README.md#installation-issues"&gt;installation issues&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are planning on using &lt;code&gt;fastai&lt;/code&gt; in the jupyter notebook environment, make sure to also install the corresponding &lt;a href="https://docs.fast.ai/install.html#jupyter-notebook-dependencies" rel="nofollow"&gt;packages&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;More advanced installation issues, such as installing only partial dependencies are covered in a dedicated &lt;a href="https://docs.fast.ai/install.html" rel="nofollow"&gt;installation doc&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-conda-install" class="anchor" aria-hidden="true" href="#conda-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Conda Install&lt;/h3&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install -c pytorch -c fastai fastai&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will install the &lt;code&gt;pytorch&lt;/code&gt; build with the latest &lt;code&gt;cudatoolkit&lt;/code&gt; version. If you need a higher or lower &lt;code&gt;CUDA XX&lt;/code&gt; build (e.g. CUDA 9.0), following the instructions &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;here&lt;/a&gt;, to install the desired &lt;code&gt;pytorch&lt;/code&gt; build.&lt;/p&gt;
&lt;p&gt;Note that JPEG decoding can be a bottleneck, particularly if you have a fast GPU. You can optionally install an optimized JPEG decoder as follows (Linux):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda uninstall --force jpeg libtiff -y
conda install -c conda-forge libjpeg-turbo pillow==6.0.0
CC=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;cc -mavx2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; pip install --no-cache-dir -U --force-reinstall --no-binary :all: --compile pillow-simd&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you only care about faster JPEG decompression, it can be &lt;code&gt;pillow&lt;/code&gt; or &lt;code&gt;pillow-simd&lt;/code&gt; in the last command above, the latter speeds up other image processing operations. For the full story see &lt;a href="https://docs.fast.ai/performance.html#faster-image-processing" rel="nofollow"&gt;Pillow-SIMD&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-pypi-install" class="anchor" aria-hidden="true" href="#pypi-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyPI Install&lt;/h3&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install fastai&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By default pip will install the latest &lt;code&gt;pytorch&lt;/code&gt; with the latest &lt;code&gt;cudatoolkit&lt;/code&gt;. If your hardware doesn't support the latest &lt;code&gt;cudatoolkit&lt;/code&gt;, follow the instructions &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;here&lt;/a&gt;, to install a &lt;code&gt;pytorch&lt;/code&gt; build that fits your hardware.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-bug-fix-install" class="anchor" aria-hidden="true" href="#bug-fix-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bug Fix Install&lt;/h3&gt;
&lt;p&gt;If a bug fix was made in git and you can't wait till a new release is made, you can install the bleeding edge version of &lt;code&gt;fastai&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install git+https://github.com/fastai/fastai.git
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-developer-install" class="anchor" aria-hidden="true" href="#developer-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Developer Install&lt;/h3&gt;
&lt;p&gt;The following instructions will result in a &lt;a href="https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs" rel="nofollow"&gt;pip editable install&lt;/a&gt;, so that you can &lt;code&gt;git pull&lt;/code&gt; at any time and your environment will automatically get the updates:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/fastai/fastai
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; fastai
tools/run-after-git-clone
pip install -e &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;.[dev]&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, you can test that the build works by starting the jupyter notebook:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;jupyter notebook&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and executing an example notebook. For example load &lt;code&gt;examples/tabular.ipynb&lt;/code&gt; and run it.&lt;/p&gt;
&lt;p&gt;Please refer to &lt;a href="https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; and &lt;a href="https://docs.fast.ai/dev/develop.html" rel="nofollow"&gt;Notes For Developers&lt;/a&gt; for more details on how to contribute to the &lt;code&gt;fastai&lt;/code&gt; project.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-building-from-source" class="anchor" aria-hidden="true" href="#building-from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building From Source&lt;/h3&gt;
&lt;p&gt;If for any reason you can't use the prepackaged packages and have to build from source, this section is for you.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To build &lt;code&gt;pytorch&lt;/code&gt; from source follow the &lt;a href="https://github.com/pytorch/pytorch#from-source"&gt;complete instructions&lt;/a&gt;. Remember to first install CUDA, CuDNN, and other required libraries as suggested - everything will be very slow without those libraries built into &lt;code&gt;pytorch&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next, you will also need to build &lt;code&gt;torchvision&lt;/code&gt; from source:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/pytorch/vision
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; vision
python setup.py install&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When both &lt;code&gt;pytorch&lt;/code&gt; and &lt;code&gt;torchvision&lt;/code&gt; are installed, first test that you can load each of these libraries:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;import torch
import torchvision&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to validate that they were installed correctly&lt;/p&gt;
&lt;p&gt;Finally, proceed with &lt;code&gt;fastai&lt;/code&gt; installation as normal, either through prepackaged pip or conda builds or installing from source ("the developer install") as explained in the sections above.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-installation-issues" class="anchor" aria-hidden="true" href="#installation-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation Issues&lt;/h2&gt;
&lt;p&gt;If the installation process fails, first make sure &lt;a href="https://github.com/fastai/fastai/blob/master/README.md#is-my-system-supported"&gt;your system is supported&lt;/a&gt;. And if the problem is still not addressed, please refer to the &lt;a href="https://docs.fast.ai/troubleshoot.html" rel="nofollow"&gt;troubleshooting document&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you encounter installation problems with conda, make sure you have the latest &lt;code&gt;conda&lt;/code&gt; client (&lt;code&gt;conda install&lt;/code&gt; will do an update too):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install conda&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-is-my-system-supported" class="anchor" aria-hidden="true" href="#is-my-system-supported"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Is My System Supported?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Python: You need to have python 3.6 or higher&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CPU or GPU&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pytorch&lt;/code&gt; binary package comes with its own CUDA, CuDNN, NCCL, MKL, and other libraries so you don't have to install system-wide NVIDIA's CUDA and related libraries if you don't need them for something else. If you have them installed already it doesn't matter which NVIDIA's CUDA version library you have installed system-wide. Your system could have CUDA 9.0 libraries, and you can still use &lt;code&gt;pytorch&lt;/code&gt; build with CUDA 10.0 libraries without any problem, since the &lt;code&gt;pytorch&lt;/code&gt; binary package is self-contained.&lt;/p&gt;
&lt;p&gt;The only requirement is that you have installed and configured the NVIDIA driver correctly. Usually you can test that by running &lt;code&gt;nvidia-smi&lt;/code&gt;. While it's possible that this application is not available on your system, it's very likely that if it doesn't work, then you don't have your NVIDIA drivers configured properly. And remember that a reboot is always required after installing NVIDIA drivers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Operating System:&lt;/p&gt;
&lt;p&gt;Since fastai-1.0 relies on pytorch-1.0, you need to be able to install pytorch-1.0 first.&lt;/p&gt;
&lt;p&gt;As of this moment pytorch.org's 1.0 version supports:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Platform&lt;/th&gt;
&lt;th&gt;GPU&lt;/th&gt;
&lt;th&gt;CPU&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;linux&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mac&lt;/td&gt;
&lt;td&gt;source&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;windows&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Legend: &lt;code&gt;binary&lt;/code&gt; = can be installed directly, &lt;code&gt;source&lt;/code&gt; = needs to be built from source.&lt;/p&gt;
&lt;p&gt;If there is no &lt;code&gt;pytorch&lt;/code&gt; preview conda or pip package available for your system, you may still be able to &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;build it from source&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How do you know which pytorch cuda version build to choose?&lt;/p&gt;
&lt;p&gt;It depends on the version of the installed NVIDIA driver. Here are the requirements for CUDA versions supported by pre-built &lt;code&gt;pytorch&lt;/code&gt; releases:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;CUDA Toolkit&lt;/th&gt;
&lt;th&gt;NVIDIA (Linux x86_64)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CUDA 10.0&lt;/td&gt;
&lt;td&gt;&amp;gt;= 410.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CUDA 9.0&lt;/td&gt;
&lt;td&gt;&amp;gt;= 384.81&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CUDA 8.0&lt;/td&gt;
&lt;td&gt;&amp;gt;= 367.48&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So if your NVIDIA driver is less than 384, then you can only use CUDA 8.0. Of course, you can upgrade your drivers to more recent ones if your card supports it.&lt;/p&gt;
&lt;p&gt;You can find a complete table with all variations &lt;a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you use NVIDIA driver 410+, you most likely want to install the &lt;code&gt;cudatoolkit=10.0&lt;/code&gt; pytorch variant, via:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install -c pytorch pytorch cudatoolkit=10.0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or if you need a lower version, use one of:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install -c pytorch pytorch cudatoolkit=8.0
conda install -c pytorch pytorch cudatoolkit=9.0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For other options refer to the complete list of &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;the available pytorch variants&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-updates" class="anchor" aria-hidden="true" href="#updates"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Updates&lt;/h2&gt;
&lt;p&gt;In order to update your environment, simply install &lt;code&gt;fastai&lt;/code&gt; in exactly the same way you did the initial installation.&lt;/p&gt;
&lt;p&gt;Top level files &lt;code&gt;environment.yml&lt;/code&gt; and &lt;code&gt;environment-cpu.yml&lt;/code&gt; belong to the old fastai (0.7). &lt;code&gt;conda env update&lt;/code&gt; is no longer the way to update your &lt;code&gt;fastai-1.x&lt;/code&gt; environment. These files remain because the fastai course-v2 video instructions rely on this setup. Eventually, once fastai course-v3 p1 and p2 will be completed, they will probably be moved to where they belong - under &lt;code&gt;old/&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-guidelines" class="anchor" aria-hidden="true" href="#contribution-guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution guidelines&lt;/h2&gt;
&lt;p&gt;If you want to contribute to &lt;code&gt;fastai&lt;/code&gt;, be sure to review the &lt;a href="https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt;. This project adheres to fastai's &lt;a href="https://github.com/fastai/fastai/blob/master/CODE-OF-CONDUCT.md"&gt;code of conduct&lt;/a&gt;. By participating, you are expected to uphold this code.&lt;/p&gt;
&lt;p&gt;We use GitHub issues for tracking requests and bugs, so please see &lt;a href="https://forums.fast.ai/" rel="nofollow"&gt;fastai forum&lt;/a&gt; for general questions and discussion.&lt;/p&gt;
&lt;p&gt;The fastai project strives to abide by generally accepted best practices in open-source software development:&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-history" class="anchor" aria-hidden="true" href="#history"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;History&lt;/h2&gt;
&lt;p&gt;A detailed history of changes can be found &lt;a href="https://github.com/fastai/fastai/blob/master/CHANGES.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-copyright" class="anchor" aria-hidden="true" href="#copyright"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Copyright&lt;/h2&gt;
&lt;p&gt;Copyright 2017 onwards, fast.ai, Inc. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this project's files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fastai</author><guid isPermaLink="false">https://github.com/fastai/fastai</guid><pubDate>Thu, 21 Nov 2019 00:10:00 GMT</pubDate></item><item><title>zergtant/pytorch-handbook #11 in Jupyter Notebook, This week</title><link>https://github.com/zergtant/pytorch-handbook</link><description>&lt;p&gt;&lt;i&gt;pytorch handbook是一本开源的书籍，目标是帮助那些希望和使用PyTorch进行深度学习开发和研究的朋友快速入门，其中包含的Pytorch教程全部通过测试保证可以成功运行&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pytorch-中文手册pytorch-handbook" class="anchor" aria-hidden="true" href="#pytorch-中文手册pytorch-handbook"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyTorch 中文手册（pytorch handbook）&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/pytorch/pytorch/master/docs/source/_static/img/pytorch-logo-dark.png"&gt;&lt;img src="https://raw.githubusercontent.com/pytorch/pytorch/master/docs/source/_static/img/pytorch-logo-dark.png" alt="pytorch" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-书籍介绍" class="anchor" aria-hidden="true" href="#书籍介绍"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;书籍介绍&lt;/h2&gt;
&lt;p&gt;这是一本开源的书籍，目标是帮助那些希望和使用PyTorch进行深度学习开发和研究的朋友快速入门。&lt;/p&gt;
&lt;p&gt;由于本人水平有限，在写此教程的时候参考了一些网上的资料，在这里对他们表示敬意，我会在每个引用中附上原文地址，方便大家参考。&lt;/p&gt;
&lt;p&gt;深度学习的技术在飞速的发展，同时PyTorch也在不断更新，且本人会逐步完善相关内容。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-版本说明" class="anchor" aria-hidden="true" href="#版本说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;版本说明&lt;/h2&gt;
&lt;p&gt;由于PyTorch版本更迭，教程的版本会与PyTorch版本，保持一致。&lt;/p&gt;
&lt;p&gt;2019.10.10 PyTorch已经发布1.3的稳定版。&lt;/p&gt;
&lt;p&gt;已经全部测试完毕 代码可完全兼容1.3&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-qq-3群" class="anchor" aria-hidden="true" href="#qq-3群"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;QQ 3群&lt;/h2&gt;
&lt;p&gt;群号：773681699&lt;/p&gt;
&lt;p&gt;扫描二维码&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="Pytorch-Handbook-3.png"&gt;&lt;img src="Pytorch-Handbook-3.png" alt="QR" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="//shang.qq.com/wpa/qunwpa?idkey=ee402d5f0e7732b2171e643d729177ce55ac404eafda5edd9b740d73fabe6a96" rel="nofollow"&gt;点击链接加入群聊 『PyTorch Handbook 交流3群』&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;1群(985896536)已满，2群(681980831)已满&lt;/p&gt;
&lt;p&gt;不要再加了&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-说明" class="anchor" aria-hidden="true" href="#说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;说明&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;修改错别字请直接提issue或PR&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PR时请注意版本&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有问题也请直接提issue&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;感谢&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-目录" class="anchor" aria-hidden="true" href="#目录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目录&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-第一章pytorch-入门" class="anchor" aria-hidden="true" href="#第一章pytorch-入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第一章：PyTorch 入门&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="chapter1/1.1-pytorch-introduction.md"&gt;PyTorch 简介&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter1/1.2-pytorch-installation.md"&gt;PyTorch 环境搭建&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter1/1.3-deep-learning-with-pytorch-60-minute-blitz.md"&gt;PyTorch 深度学习：60分钟快速入门（官方）&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="chapter1/1_tensor_tutorial.ipynb"&gt;张量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter1/2_autograd_tutorial.ipynb"&gt;Autograd：自动求导&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter1/3_neural_networks_tutorial.ipynb"&gt;神经网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter1/4_cifar10_tutorial.ipynb"&gt;训练一个分类器&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter1/5_data_parallel_tutorial.ipynb"&gt;选读：数据并行处理（多GPU）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter1/1.4-pytorch-resource.md"&gt;相关资源介绍&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-第二章-基础" class="anchor" aria-hidden="true" href="#第二章-基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第二章 基础&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-第一节-pytorch-基础" class="anchor" aria-hidden="true" href="#第一节-pytorch-基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第一节 PyTorch 基础&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="chapter2/2.1.1.pytorch-basics-tensor.ipynb"&gt;张量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter2/2.1.2-pytorch-basics-autograd.ipynb"&gt;自动求导&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter2/2.1.3-pytorch-basics-nerual-network.ipynb"&gt;神经网络包nn和优化器optm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter2/2.1.4-pytorch-basics-data-loader.ipynb"&gt;数据的加载和预处理&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-第二节-深度学习基础及数学原理" class="anchor" aria-hidden="true" href="#第二节-深度学习基础及数学原理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第二节 深度学习基础及数学原理&lt;/h4&gt;
&lt;p&gt;&lt;a href="chapter2/2.2-deep-learning-basic-mathematics.ipynb"&gt;深度学习基础及数学原理&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-第三节-神经网络简介" class="anchor" aria-hidden="true" href="#第三节-神经网络简介"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第三节 神经网络简介&lt;/h4&gt;
&lt;p&gt;&lt;a href="chapter2/2.3-deep-learning-neural-network-introduction.ipynb"&gt;神经网络简介&lt;/a&gt;  注：本章在本地使用微软的Edge打开会崩溃，请使Chrome Firefox打开查看&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-第四节-卷积神经网络" class="anchor" aria-hidden="true" href="#第四节-卷积神经网络"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第四节 卷积神经网络&lt;/h4&gt;
&lt;p&gt;&lt;a href="chapter2/2.4-cnn.ipynb"&gt;卷积神经网络&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-第五节-循环神经网络" class="anchor" aria-hidden="true" href="#第五节-循环神经网络"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第五节 循环神经网络&lt;/h4&gt;
&lt;p&gt;&lt;a href="chapter2/2.5-rnn.ipynb"&gt;循环神经网络&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-第三章-实践" class="anchor" aria-hidden="true" href="#第三章-实践"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第三章 实践&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-第一节-logistic回归二元分类" class="anchor" aria-hidden="true" href="#第一节-logistic回归二元分类"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第一节 logistic回归二元分类&lt;/h4&gt;
&lt;p&gt;&lt;a href="chapter3/3.1-logistic-regression.ipynb"&gt;logistic回归二元分类&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-第二节-cnnmnist数据集手写数字识别" class="anchor" aria-hidden="true" href="#第二节-cnnmnist数据集手写数字识别"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第二节 CNN:MNIST数据集手写数字识别&lt;/h4&gt;
&lt;p&gt;&lt;a href="chapter3/3.2-mnist.ipynb"&gt;CNN:MNIST数据集手写数字识别&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-第三节-rnn实例通过sin预测cos" class="anchor" aria-hidden="true" href="#第三节-rnn实例通过sin预测cos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第三节 RNN实例：通过Sin预测Cos&lt;/h4&gt;
&lt;p&gt;&lt;a href="chapter3/3.3-rnn.ipynb"&gt;RNN实例：通过Sin预测Cos&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-第四章-提高" class="anchor" aria-hidden="true" href="#第四章-提高"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第四章 提高&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-第一节-fine-tuning" class="anchor" aria-hidden="true" href="#第一节-fine-tuning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第一节 Fine-tuning&lt;/h4&gt;
&lt;p&gt;&lt;a href="chapter4/4.1-fine-tuning.ipynb"&gt;Fine-tuning&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-第二节-可视化" class="anchor" aria-hidden="true" href="#第二节-可视化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第二节 可视化&lt;/h4&gt;
&lt;p&gt;&lt;a href="chapter4/4.2.1-visdom.ipynb"&gt;visdom&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="chapter4/4.2.2-tensorboardx.ipynb"&gt;tensorboardx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="chapter4/4.2.3-cnn-visualizing.ipynb"&gt;可视化理解卷积神经网络&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-第三节-fastai" class="anchor" aria-hidden="true" href="#第三节-fastai"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第三节 Fast.ai&lt;/h4&gt;
&lt;p&gt;&lt;a href="chapter4/4.3-fastai.ipynb"&gt;Fast.ai&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-第四节-训练的一些技巧" class="anchor" aria-hidden="true" href="#第四节-训练的一些技巧"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第四节 训练的一些技巧&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第五节-多gpu并行训练" class="anchor" aria-hidden="true" href="#第五节-多gpu并行训练"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第五节 多GPU并行训练&lt;/h4&gt;
&lt;p&gt;&lt;a href="chapter4/4.5-multiply-gpu-parallel-training.ipynb"&gt;多GPU并行计算&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-第五章-应用" class="anchor" aria-hidden="true" href="#第五章-应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第五章 应用&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-第一节-kaggle介绍" class="anchor" aria-hidden="true" href="#第一节-kaggle介绍"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第一节 Kaggle介绍&lt;/h4&gt;
&lt;p&gt;&lt;a href="chapter5/5.1-kaggle.md"&gt;Kaggle介绍&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-第二节-结构化数据" class="anchor" aria-hidden="true" href="#第二节-结构化数据"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第二节 结构化数据&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第三节-计算机视觉" class="anchor" aria-hidden="true" href="#第三节-计算机视觉"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第三节 计算机视觉&lt;/h4&gt;
&lt;p&gt;&lt;a href="chapter5/5.3-Fashion-MNIST.ipynb"&gt;Fashion MNIST 图像分类&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-第四节-自然语言处理" class="anchor" aria-hidden="true" href="#第四节-自然语言处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第四节 自然语言处理&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第五节-协同过滤" class="anchor" aria-hidden="true" href="#第五节-协同过滤"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第五节 协同过滤&lt;/h4&gt;
&lt;h3&gt;&lt;a id="user-content-第六章-资源" class="anchor" aria-hidden="true" href="#第六章-资源"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第六章 资源&lt;/h3&gt;
&lt;h3&gt;&lt;a id="user-content-第七章-附录" class="anchor" aria-hidden="true" href="#第七章-附录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第七章 附录&lt;/h3&gt;
&lt;p&gt;transforms的常用操作总结&lt;/p&gt;
&lt;p&gt;pytorch的损失函数总结&lt;/p&gt;
&lt;p&gt;pytorch的优化器总结&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/60543937b5e790e3bca35357ccc1313f4b5f52b3/68747470733a2f2f692e6372656174697665636f6d6d6f6e732e6f72672f6c2f62792d6e632d73612f332e302f38387833312e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/60543937b5e790e3bca35357ccc1313f4b5f52b3/68747470733a2f2f692e6372656174697665636f6d6d6f6e732e6f72672f6c2f62792d6e632d73612f332e302f38387833312e706e67" alt="" data-canonical-src="https://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn" rel="nofollow"&gt;本作品采用知识共享署名-非商业性使用-相同方式共享 3.0  中国大陆许可协议进行许可&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>zergtant</author><guid isPermaLink="false">https://github.com/zergtant/pytorch-handbook</guid><pubDate>Thu, 21 Nov 2019 00:11:00 GMT</pubDate></item><item><title>slundberg/shap #12 in Jupyter Notebook, This week</title><link>https://github.com/slundberg/shap</link><description>&lt;p&gt;&lt;i&gt;A unified approach to explain the output of any machine learning model.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/shap_diagram.png"&gt;&lt;img src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/shap_diagram.png" width="400" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/slundberg/shap" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/19de279a6f67f8eea3f52ccecc779c3e1aff55e7/68747470733a2f2f7472617669732d63692e6f72672f736c756e64626572672f736861702e7376673f6272616e63683d6d6173746572" data-canonical-src="https://travis-ci.org/slundberg/shap.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://mybinder.org/v2/gh/slundberg/shap/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/483bae47a175c24dfbfc57390edd8b6982ac5fb3/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge_logo.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SHAP (SHapley Additive exPlanations)&lt;/strong&gt; is a unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods [1-7] and representing the only possible consistent and locally accurate additive feature attribution method based on expectations (see our &lt;a href="#citations"&gt;papers&lt;/a&gt; for details and citations).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-install" class="anchor" aria-hidden="true" href="#install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install&lt;/h2&gt;
&lt;p&gt;SHAP can be installed from either &lt;a href="https://pypi.org/project/shap" rel="nofollow"&gt;PyPI&lt;/a&gt; or &lt;a href="https://anaconda.org/conda-forge/shap" rel="nofollow"&gt;conda-forge&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;pip install shap
&lt;i&gt;or&lt;/i&gt;
conda install -c conda-forge shap
&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-tree-ensemble-example-with-treeexplainer-xgboostlightgbmcatboostscikit-learnpyspark-models" class="anchor" aria-hidden="true" href="#tree-ensemble-example-with-treeexplainer-xgboostlightgbmcatboostscikit-learnpyspark-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tree ensemble example with TreeExplainer (XGBoost/LightGBM/CatBoost/scikit-learn/pyspark models)&lt;/h2&gt;
&lt;p&gt;While SHAP values can explain the output of any machine learning model, we have developed a high-speed exact algorithm for tree ensemble methods (&lt;a href="https://arxiv.org/abs/1802.03888" rel="nofollow"&gt;Tree SHAP arXiv paper&lt;/a&gt;). Fast C++ implementations are supported for &lt;em&gt;XGBoost&lt;/em&gt;, &lt;em&gt;LightGBM&lt;/em&gt;, &lt;em&gt;CatBoost&lt;/em&gt;, &lt;em&gt;scikit-learn&lt;/em&gt; and &lt;em&gt;pyspark&lt;/em&gt; tree models:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; xgboost
&lt;span class="pl-k"&gt;import&lt;/span&gt; shap

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; load JS visualization code to notebook&lt;/span&gt;
shap.initjs()

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; train XGBoost model&lt;/span&gt;
X,y &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.datasets.boston()
model &lt;span class="pl-k"&gt;=&lt;/span&gt; xgboost.train({&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;learning_rate&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;0.01&lt;/span&gt;}, xgboost.DMatrix(X, &lt;span class="pl-v"&gt;label&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;y), &lt;span class="pl-c1"&gt;100&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; explain the model's predictions using SHAP values&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)&lt;/span&gt;
explainer &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.TreeExplainer(model)
shap_values &lt;span class="pl-k"&gt;=&lt;/span&gt; explainer.shap_values(X)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)&lt;/span&gt;
shap.force_plot(explainer.expected_value, shap_values[&lt;span class="pl-c1"&gt;0&lt;/span&gt;,:], X.iloc[&lt;span class="pl-c1"&gt;0&lt;/span&gt;,:])&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_instance.png"&gt;&lt;img width="811" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_instance.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;The above explanation shows features each contributing to push the model output from the base value (the average model output over the training dataset we passed) to the model output. Features pushing the prediction higher are shown in red, those pushing the prediction lower are in blue (these force plots are introduced in our &lt;a href="https://www.nature.com/articles/s41551-018-0304-0" rel="nofollow"&gt;Nature BME paper&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;If we take many explanations such as the one shown above, rotate them 90 degrees, and then stack them horizontally, we can see explanations for an entire dataset (in the notebook this plot is interactive):&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; visualize the training set predictions&lt;/span&gt;
shap.force_plot(explainer.expected_value, shap_values, X)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_dataset.png"&gt;&lt;img width="811" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_dataset.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;To understand how a single feature effects the output of the model we can plot the SHAP value of that feature vs. the value of the feature for all the examples in a dataset. Since SHAP values represent a feature's responsibility for a change in the model output, the plot below represents the change in predicted house price as RM (the average number of rooms per house in an area) changes. Vertical dispersion at a single value of RM represents interaction effects with other features. To help reveal these interactions &lt;code&gt;dependence_plot&lt;/code&gt; automatically selects another feature for coloring. In this case coloring by RAD (index of accessibility to radial highways) highlights that the average number of rooms per house has less impact on home price for areas with a high RAD value.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; create a SHAP dependence plot to show the effect of a single feature across the whole dataset&lt;/span&gt;
shap.dependence_plot(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;RM&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, shap_values, X)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_dependence_plot.png"&gt;&lt;img width="544" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_dependence_plot.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;To get an overview of which features are most important for a model we can plot the SHAP values of every feature for every sample. The plot below sorts features by the sum of SHAP value magnitudes over all samples, and uses SHAP values to show the distribution of the impacts each feature has on the model output. The color represents the feature value (red high, blue low). This reveals for example that a high LSTAT (% lower status of the population) lowers the predicted home price.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; summarize the effects of all the features&lt;/span&gt;
shap.summary_plot(shap_values, X)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_summary_plot.png"&gt;&lt;img width="483" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_summary_plot.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;We can also just take the mean absolute value of the SHAP values for each feature to get a standard bar plot (produces stacked bars for multi-class outputs):&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;shap.summary_plot(shap_values, X, &lt;span class="pl-v"&gt;plot_type&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;bar&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_summary_plot_bar.png"&gt;&lt;img width="470" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_summary_plot_bar.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-deep-learning-example-with-deepexplainer-tensorflowkeras-models" class="anchor" aria-hidden="true" href="#deep-learning-example-with-deepexplainer-tensorflowkeras-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep learning example with DeepExplainer (TensorFlow/Keras models)&lt;/h2&gt;
&lt;p&gt;Deep SHAP is a high-speed approximation algorithm for SHAP values in deep learning models that builds on a connection with &lt;a href="https://arxiv.org/abs/1704.02685" rel="nofollow"&gt;DeepLIFT&lt;/a&gt; described in the SHAP NIPS paper. The implementation here differs from the original DeepLIFT by using a distribution of background samples instead of a single reference value, and using Shapley equations to linearize components such as max, softmax, products, divisions, etc. Note that some of these enhancements have also been since integrated into DeepLIFT. TensorFlow models and Keras models using the TensorFlow backend are supported (there is also preliminary support for PyTorch):&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; ...include code from https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py&lt;/span&gt;

&lt;span class="pl-k"&gt;import&lt;/span&gt; shap
&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; select a set of background examples to take an expectation over&lt;/span&gt;
background &lt;span class="pl-k"&gt;=&lt;/span&gt; x_train[np.random.choice(x_train.shape[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], &lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;replace&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;False&lt;/span&gt;)]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; explain predictions of the model on four images&lt;/span&gt;
e &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.DeepExplainer(model, background)
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; ...or pass tensors directly&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)&lt;/span&gt;
shap_values &lt;span class="pl-k"&gt;=&lt;/span&gt; e.shap_values(x_test[&lt;span class="pl-c1"&gt;1&lt;/span&gt;:&lt;span class="pl-c1"&gt;5&lt;/span&gt;])

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; plot the feature attributions&lt;/span&gt;
shap.image_plot(shap_values, &lt;span class="pl-k"&gt;-&lt;/span&gt;x_test[&lt;span class="pl-c1"&gt;1&lt;/span&gt;:&lt;span class="pl-c1"&gt;5&lt;/span&gt;])&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/mnist_image_plot.png"&gt;&lt;img width="820" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/mnist_image_plot.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;The plot above explains ten outputs (digits 0-9) for four different images. Red pixels increase the model's output while blue pixels decrease the output. The input images are shown on the left, and as nearly transparent grayscale backings behind each of the explanations. The sum of the SHAP values equals the difference between the expected model output (averaged over the background dataset) and the current model output. Note that for the 'zero' image the blank middle is important, while for the 'four' image the lack of a connection on top makes it a four instead of a nine.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-deep-learning-example-with-gradientexplainer-tensorflowkeraspytorch-models" class="anchor" aria-hidden="true" href="#deep-learning-example-with-gradientexplainer-tensorflowkeraspytorch-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep learning example with GradientExplainer (TensorFlow/Keras/PyTorch models)&lt;/h2&gt;
&lt;p&gt;Expected gradients combines ideas from &lt;a href="https://arxiv.org/abs/1703.01365" rel="nofollow"&gt;Integrated Gradients&lt;/a&gt;, SHAP, and &lt;a href="https://arxiv.org/abs/1706.03825" rel="nofollow"&gt;SmoothGrad&lt;/a&gt; into a single expected value equation. This allows an entire dataset to be used as the background distribution (as opposed to a single reference value) and allows local smoothing. If we approximate the model with a linear function between each background data sample and the current input to be explained, and we assume the input features are independent then expected gradients will compute approximate SHAP values. In the example below we have explained how the 7th intermediate layer of the VGG16 ImageNet model impacts the output probabilities.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; keras.applications.vgg16 &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-c1"&gt;VGG16&lt;/span&gt;
&lt;span class="pl-k"&gt;from&lt;/span&gt; keras.applications.vgg16 &lt;span class="pl-k"&gt;import&lt;/span&gt; preprocess_input
&lt;span class="pl-k"&gt;import&lt;/span&gt; keras.backend &lt;span class="pl-k"&gt;as&lt;/span&gt; K
&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np
&lt;span class="pl-k"&gt;import&lt;/span&gt; json
&lt;span class="pl-k"&gt;import&lt;/span&gt; shap

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; load pre-trained model and choose two images to explain&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; VGG16(&lt;span class="pl-v"&gt;weights&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;imagenet&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;include_top&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
X,y &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.datasets.imagenet50()
to_explain &lt;span class="pl-k"&gt;=&lt;/span&gt; X[[&lt;span class="pl-c1"&gt;39&lt;/span&gt;,&lt;span class="pl-c1"&gt;41&lt;/span&gt;]]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; load the ImageNet class names&lt;/span&gt;
url &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
fname &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.datasets.cache(url)
&lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-c1"&gt;open&lt;/span&gt;(fname) &lt;span class="pl-k"&gt;as&lt;/span&gt; f:
    class_names &lt;span class="pl-k"&gt;=&lt;/span&gt; json.load(f)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; explain how the input to the 7th layer of the model explains the top two classes&lt;/span&gt;
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;map2layer&lt;/span&gt;(&lt;span class="pl-smi"&gt;x&lt;/span&gt;, &lt;span class="pl-smi"&gt;layer&lt;/span&gt;):
    feed_dict &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;dict&lt;/span&gt;(&lt;span class="pl-c1"&gt;zip&lt;/span&gt;([model.layers[&lt;span class="pl-c1"&gt;0&lt;/span&gt;].input], [preprocess_input(x.copy())]))
    &lt;span class="pl-k"&gt;return&lt;/span&gt; K.get_session().run(model.layers[layer].input, feed_dict)
e &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.GradientExplainer(
    (model.layers[&lt;span class="pl-c1"&gt;7&lt;/span&gt;].input, model.layers[&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;].output),
    map2layer(X, &lt;span class="pl-c1"&gt;7&lt;/span&gt;),
    &lt;span class="pl-v"&gt;local_smoothing&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0&lt;/span&gt; &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; std dev of smoothing noise&lt;/span&gt;
)
shap_values,indexes &lt;span class="pl-k"&gt;=&lt;/span&gt; e.shap_values(map2layer(to_explain, &lt;span class="pl-c1"&gt;7&lt;/span&gt;), &lt;span class="pl-v"&gt;ranked_outputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; get the names for the classes&lt;/span&gt;
index_names &lt;span class="pl-k"&gt;=&lt;/span&gt; np.vectorize(&lt;span class="pl-k"&gt;lambda&lt;/span&gt; &lt;span class="pl-smi"&gt;x&lt;/span&gt;: class_names[&lt;span class="pl-c1"&gt;str&lt;/span&gt;(x)][&lt;span class="pl-c1"&gt;1&lt;/span&gt;])(indexes)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; plot the explanations&lt;/span&gt;
shap.image_plot(shap_values, to_explain, index_names)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/gradient_imagenet_plot.png"&gt;&lt;img width="500" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/gradient_imagenet_plot.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Predictions for two input images are explained in the plot above. Red pixels represent positive SHAP values that increase the probability of the class, while blue pixels represent negative SHAP values the reduce the probability of the class. By using &lt;code&gt;ranked_outputs=2&lt;/code&gt; we explain only the two most likely classes for each input (this spares us from explaining all 1,000 classes).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-model-agnostic-example-with-kernelexplainer-explains-any-function" class="anchor" aria-hidden="true" href="#model-agnostic-example-with-kernelexplainer-explains-any-function"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model agnostic example with KernelExplainer (explains any function)&lt;/h2&gt;
&lt;p&gt;Kernel SHAP uses a specially-weighted local linear regression to estimate SHAP values for any model. Below is a simple example for explaining a multi-class SVM on the classic iris dataset.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; sklearn
&lt;span class="pl-k"&gt;import&lt;/span&gt; shap
&lt;span class="pl-k"&gt;from&lt;/span&gt; sklearn.model_selection &lt;span class="pl-k"&gt;import&lt;/span&gt; train_test_split

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; print the JS visualization code to the notebook&lt;/span&gt;
shap.initjs()

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; train a SVM classifier&lt;/span&gt;
X_train,X_test,Y_train,Y_test &lt;span class="pl-k"&gt;=&lt;/span&gt; train_test_split(&lt;span class="pl-k"&gt;*&lt;/span&gt;shap.datasets.iris(), &lt;span class="pl-v"&gt;test_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0.2&lt;/span&gt;, &lt;span class="pl-v"&gt;random_state&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
svm &lt;span class="pl-k"&gt;=&lt;/span&gt; sklearn.svm.SVC(&lt;span class="pl-v"&gt;kernel&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;rbf&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;probability&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
svm.fit(X_train, Y_train)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; use Kernel SHAP to explain test set predictions&lt;/span&gt;
explainer &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.KernelExplainer(svm.predict_proba, X_train, &lt;span class="pl-v"&gt;link&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;logit&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
shap_values &lt;span class="pl-k"&gt;=&lt;/span&gt; explainer.shap_values(X_test, &lt;span class="pl-v"&gt;nsamples&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; plot the SHAP values for the Setosa output of the first instance&lt;/span&gt;
shap.force_plot(explainer.expected_value[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], shap_values[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;0&lt;/span&gt;,:], X_test.iloc[&lt;span class="pl-c1"&gt;0&lt;/span&gt;,:], &lt;span class="pl-v"&gt;link&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;logit&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/iris_instance.png"&gt;&lt;img width="810" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/iris_instance.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;The above explanation shows four features each contributing to push the model output from the base value (the average model output over the training dataset we passed) towards zero. If there were any features pushing the class label higher they would be shown in red.&lt;/p&gt;
&lt;p&gt;If we take many explanations such as the one shown above, rotate them 90 degrees, and then stack them horizontally, we can see explanations for an entire dataset. This is exactly what we do below for all the examples in the iris test set:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; plot the SHAP values for the Setosa output of all instances&lt;/span&gt;
shap.force_plot(explainer.expected_value[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], shap_values[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], X_test, &lt;span class="pl-v"&gt;link&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;logit&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/iris_dataset.png"&gt;&lt;img width="813" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/iris_dataset.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-shap-interaction-values" class="anchor" aria-hidden="true" href="#shap-interaction-values"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SHAP Interaction Values&lt;/h2&gt;
&lt;p&gt;SHAP interaction values are a generalization of SHAP values to higher order interactions. Fast exact computation of pairwise interactions are implemented for tree models with &lt;code&gt;shap.TreeExplainer(model).shap_interaction_values(X)&lt;/code&gt;. This returns a matrix for every prediction, where the main effects are on the diagonal and the interaction effects are off-diagonal. These values often reveal interesting hidden relationships, such as how the increased risk of death peaks for men at age 60 (see the NHANES notebook for details):&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/nhanes_age_sex_interaction.png"&gt;&lt;img width="483" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/nhanes_age_sex_interaction.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sample-notebooks" class="anchor" aria-hidden="true" href="#sample-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sample notebooks&lt;/h2&gt;
&lt;p&gt;The notebooks below demonstrate different use cases for SHAP. Look inside the notebooks directory of the repository if you want to try playing with the original notebooks yourself.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-treeexplainer" class="anchor" aria-hidden="true" href="#treeexplainer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TreeExplainer&lt;/h3&gt;
&lt;p&gt;An implementation of Tree SHAP, a fast and exact algorithm to compute SHAP values for trees and ensembles of trees.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/NHANES%20I%20Survival%20Model.html" rel="nofollow"&gt;&lt;strong&gt;NHANES survival model with XGBoost and SHAP interaction values&lt;/strong&gt;&lt;/a&gt; - Using mortality data from 20 years of followup this notebook demonstrates how to use XGBoost and &lt;code&gt;shap&lt;/code&gt; to uncover complex risk factor relationships.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/tree_explainer/Census%20income%20classification%20with%20LightGBM.html" rel="nofollow"&gt;&lt;strong&gt;Census income classification with LightGBM&lt;/strong&gt;&lt;/a&gt; - Using the standard adult census income dataset, this notebook trains a gradient boosting tree model with LightGBM and then explains predictions using &lt;code&gt;shap&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/League%20of%20Legends%20Win%20Prediction%20with%20XGBoost.html" rel="nofollow"&gt;&lt;strong&gt;League of Legends Win Prediction with XGBoost&lt;/strong&gt;&lt;/a&gt; - Using a Kaggle dataset of 180,000 ranked matches from League of Legends we train and explain a gradient boosting tree model with XGBoost to predict if a player will win their match.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-deepexplainer" class="anchor" aria-hidden="true" href="#deepexplainer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DeepExplainer&lt;/h3&gt;
&lt;p&gt;An implementation of Deep SHAP, a faster (but only approximate) algorithm to compute SHAP values for deep learning models that is based on connections between SHAP and the DeepLIFT algorithm.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/deep_explainer/Front%20Page%20DeepExplainer%20MNIST%20Example.html" rel="nofollow"&gt;&lt;strong&gt;MNIST Digit classification with Keras&lt;/strong&gt;&lt;/a&gt; - Using the MNIST handwriting recognition dataset, this notebook trains a neural network with Keras and then explains predictions using &lt;code&gt;shap&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/deep_explainer/Keras%20LSTM%20for%20IMDB%20Sentiment%20Classification.html" rel="nofollow"&gt;&lt;strong&gt;Keras LSTM for IMDB Sentiment Classification&lt;/strong&gt;&lt;/a&gt; - This notebook trains an LSTM with Keras on the IMDB text sentiment analysis dataset and then explains predictions using &lt;code&gt;shap&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-gradientexplainer" class="anchor" aria-hidden="true" href="#gradientexplainer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GradientExplainer&lt;/h3&gt;
&lt;p&gt;An implementation of expected gradients to approximate SHAP values for deep learning models. It is based on connections between SHAP and the Integrated Gradients algorithm. GradientExplainer is slower than DeepExplainer and makes different approximation assumptions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/gradient_explainer/Explain%20an%20Intermediate%20Layer%20of%20VGG16%20on%20ImageNet.html" rel="nofollow"&gt;&lt;strong&gt;Explain an Intermediate Layer of VGG16 on ImageNet&lt;/strong&gt;&lt;/a&gt; - This notebook demonstrates how to explain the output of a pre-trained VGG16 ImageNet model using an internal convolutional layer.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-linearexplainer" class="anchor" aria-hidden="true" href="#linearexplainer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LinearExplainer&lt;/h3&gt;
&lt;p&gt;For a linear model with independent features we can analytically compute the exact SHAP values. We can also account for feature correlation if we are willing to estimate the feature covaraince matrix. LinearExplainer supports both of these options.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/linear_explainer/Sentiment%20Analysis%20with%20Logistic%20Regression.html" rel="nofollow"&gt;&lt;strong&gt;Sentiment Analysis with Logistic Regression&lt;/strong&gt;&lt;/a&gt; - This notebook demonstrates how to explain a linear logistic regression sentiment analysis model.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-kernelexplainer" class="anchor" aria-hidden="true" href="#kernelexplainer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;KernelExplainer&lt;/h3&gt;
&lt;p&gt;An implementation of Kernel SHAP, a model agnostic method to estimate SHAP values for any model. Because it makes not assumptions about the model type, KernelExplainer is slower than the other model type specific algorithms.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/Census%20income%20classification%20with%20scikit-learn.html" rel="nofollow"&gt;&lt;strong&gt;Census income classification with scikit-learn&lt;/strong&gt;&lt;/a&gt; - Using the standard adult census income dataset, this notebook trains a k-nearest neighbors classifier using scikit-learn and then explains predictions using &lt;code&gt;shap&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/ImageNet%20VGG16%20Model%20with%20Keras.html" rel="nofollow"&gt;&lt;strong&gt;ImageNet VGG16 Model with Keras&lt;/strong&gt;&lt;/a&gt; - Explain the classic VGG16 convolutional nerual network's predictions for an image. This works by applying the model agnostic Kernel SHAP method to a super-pixel segmented image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/Iris%20classification%20with%20scikit-learn.html" rel="nofollow"&gt;&lt;strong&gt;Iris classification&lt;/strong&gt;&lt;/a&gt; - A basic demonstration using the popular iris species dataset. It explains predictions from six different models in scikit-learn using &lt;code&gt;shap&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-documentation-notebooks" class="anchor" aria-hidden="true" href="#documentation-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation notebooks&lt;/h2&gt;
&lt;p&gt;These notebooks comprehensively demonstrate how to use specific functions and objects.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/plots/decision_plot.html" rel="nofollow"&gt;&lt;code&gt;shap.decision_plot&lt;/code&gt; and &lt;code&gt;shap.multioutput_decision_plot&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/plots/dependence_plot.html" rel="nofollow"&gt;&lt;code&gt;shap.dependence_plot&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-methods-unified-by-shap" class="anchor" aria-hidden="true" href="#methods-unified-by-shap"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Methods Unified by SHAP&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;LIME:&lt;/em&gt; Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. "Why should i trust you?: Explaining the predictions of any classifier." Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Shapley sampling values:&lt;/em&gt; Strumbelj, Erik, and Igor Kononenko. "Explaining prediction models and individual predictions with feature contributions." Knowledge and information systems 41.3 (2014): 647-665.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;DeepLIFT:&lt;/em&gt; Shrikumar, Avanti, Peyton Greenside, and Anshul Kundaje. "Learning important features through propagating activation differences." arXiv preprint arXiv:1704.02685 (2017).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;QII:&lt;/em&gt; Datta, Anupam, Shayak Sen, and Yair Zick. "Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems." Security and Privacy (SP), 2016 IEEE Symposium on. IEEE, 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Layer-wise relevance propagation:&lt;/em&gt; Bach, Sebastian, et al. "On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation." PloS one 10.7 (2015): e0130140.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Shapley regression values:&lt;/em&gt; Lipovetsky, Stan, and Michael Conklin. "Analysis of regression in game theory approach." Applied Stochastic Models in Business and Industry 17.4 (2001): 319-330.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Tree interpreter:&lt;/em&gt; Saabas, Ando. Interpreting random forests. &lt;a href="http://blog.datadive.net/interpreting-random-forests/" rel="nofollow"&gt;http://blog.datadive.net/interpreting-random-forests/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-citations" class="anchor" aria-hidden="true" href="#citations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citations&lt;/h2&gt;
&lt;p&gt;The algorithms and visualizations used in this package came primarily out of research in &lt;a href="https://suinlee.cs.washington.edu" rel="nofollow"&gt;Su-In Lee's lab&lt;/a&gt; at the University of Washington. If you use SHAP in your research we would appreciate a citation to the appropriate paper(s):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For general use of SHAP you can read/cite our &lt;a href="http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions" rel="nofollow"&gt;NeurIPS paper&lt;/a&gt; (&lt;a href="https://raw.githubusercontent.com/slundberg/shap/master/docs/references/shap_nips.bib" rel="nofollow"&gt;bibtex&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;For TreeExplainer you can (for now) read/cite our &lt;a href="https://arxiv.org/abs/1905.04610" rel="nofollow"&gt;arXiv paper&lt;/a&gt; (&lt;a href="https://raw.githubusercontent.com/slundberg/shap/master/docs/references/treeshap_arxiv.bib" rel="nofollow"&gt;bibtex&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;For &lt;code&gt;force_plot&lt;/code&gt; visualizations and medical applications you can read/cite our &lt;a href="https://www.nature.com/articles/s41551-018-0304-0" rel="nofollow"&gt;Nature Biomedical Engineering paper&lt;/a&gt; (&lt;a href="https://raw.githubusercontent.com/slundberg/shap/master/docs/references/nature_bme.bib" rel="nofollow"&gt;bibtex&lt;/a&gt;; &lt;a href="https://rdcu.be/baVbR" rel="nofollow"&gt;free access&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/db8c6ffa9af4cf6d17c411a9f7ad56cc1b508c35/68747470733a2f2f7777772e66616365626f6f6b2e636f6d2f74723f69643d3138393134373039313835353939312665763d5061676556696577266e6f7363726970743d31"&gt;&lt;img height="1" width="1" src="https://camo.githubusercontent.com/db8c6ffa9af4cf6d17c411a9f7ad56cc1b508c35/68747470733a2f2f7777772e66616365626f6f6b2e636f6d2f74723f69643d3138393134373039313835353939312665763d5061676556696577266e6f7363726970743d31" data-canonical-src="https://www.facebook.com/tr?id=189147091855991&amp;amp;ev=PageView&amp;amp;noscript=1" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>slundberg</author><guid isPermaLink="false">https://github.com/slundberg/shap</guid><pubDate>Thu, 21 Nov 2019 00:12:00 GMT</pubDate></item><item><title>onnx/models #13 in Jupyter Notebook, This week</title><link>https://github.com/onnx/models</link><description>&lt;p&gt;&lt;i&gt;A collection of pre-trained, state-of-the-art models in the ONNX format &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-onnx-model-zoo" class="anchor" aria-hidden="true" href="#onnx-model-zoo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ONNX Model Zoo&lt;/h1&gt;
&lt;p&gt;Open Neural Network Exchange (ONNX) is an open standard format for representing machine learning models. ONNX is supported by a community of partners who have implemented it in many frameworks and tools.&lt;/p&gt;
&lt;p&gt;The ONNX Model Zoo is a collection of pre-trained, state-of-the-art models in the &lt;a href="http://onnx.ai" rel="nofollow"&gt;ONNX&lt;/a&gt; format contributed by community members like you. Accompanying each model are &lt;a href="http://jupyter.org" rel="nofollow"&gt;Jupyter notebooks&lt;/a&gt; for model training and running inference with the trained model. The notebooks are written in Python and include links to the training dataset as well as references to the original paper that describes the model architecture.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-models" class="anchor" aria-hidden="true" href="#models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Models&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-read-the-usage-section-below-for-more-details-on-the-file-formats-in-the-onnx-model-zoo-onnx-pb-npz-and-starter-python-code-for-validating-your-onnx-model-using-test-data" class="anchor" aria-hidden="true" href="#read-the-usage-section-below-for-more-details-on-the-file-formats-in-the-onnx-model-zoo-onnx-pb-npz-and-starter-python-code-for-validating-your-onnx-model-using-test-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Read the &lt;a href="#usage-"&gt;Usage&lt;/a&gt; section below for more details on the file formats in the ONNX Model Zoo (.onnx, .pb, .npz) and starter Python code for validating your ONNX model using test data.&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-vision" class="anchor" aria-hidden="true" href="#vision"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Vision&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#image_classification"&gt;Image Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#object_detection"&gt;Object Detection &amp;amp; Image Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#body_analysis"&gt;Body, Face &amp;amp; Gesture Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#image_manipulation"&gt;Image Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-language" class="anchor" aria-hidden="true" href="#language"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Language&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#machine_comprehension"&gt;Machine Comprehension&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#machine_translation"&gt;Machine Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#language"&gt;Language Modelling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-other" class="anchor" aria-hidden="true" href="#other"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#visual_qna"&gt;Visual Question Answering &amp;amp; Dialog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#speech"&gt;Speech &amp;amp; Audio Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#others"&gt;Other interesting models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-image-classification-" class="anchor" aria-hidden="true" href="#image-classification-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image Classification &lt;a name="user-content-image_classification"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-image_classification"&gt;
&lt;p&gt;This collection of models take images as input, then classifies the major objects in the images into 1000 object categories such as keyboard, mouse, pencil, and many animals.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/mobilenet"&gt;MobileNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1801.04381" rel="nofollow"&gt;Sandler et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Light-weight deep neural network best suited for mobile and embedded vision applications. &lt;br&gt;Top-5 error from paper - ~10%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/resnet"&gt;ResNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1512.03385" rel="nofollow"&gt;He et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A CNN model (up to 152 layers). Uses shortcut connections to achieve higher accuracy when classifying images. &lt;br&gt; Top-5 error from paper - ~3.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/squeezenet"&gt;SqueezeNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1602.07360" rel="nofollow"&gt;Iandola et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A light-weight CNN model providing AlexNet level accuracy with 50x fewer parameters. &lt;br&gt;Top-5 error from paper - ~20%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/vgg"&gt;VGG&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1409.1556" rel="nofollow"&gt;Simonyan et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN model(up to 19 layers). Similar to AlexNet but uses multiple smaller kernel-sized filters that provides more accuracy when classifying images. &lt;br&gt;Top-5 error from paper - ~8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/alexnet"&gt;AlexNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="nofollow"&gt;Krizhevsky et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A Deep CNN model (up to 8 layers) where the input is an image and the output is a vector of 1000 numbers. &lt;br&gt; Top-5 error from paper - ~15%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/inception_and_googlenet/googlenet"&gt;GoogleNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1409.4842.pdf" rel="nofollow"&gt;Szegedy et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN model(up to 22 layers). Comparatively smaller and faster than VGG and more accurate in detailing than AlexNet. &lt;br&gt; Top-5 error from paper - ~6.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/caffenet"&gt;CaffeNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://ucb-icsi-vision-group.github.io/caffe-paper/caffe.pdf" rel="nofollow"&gt;Krizhevsky et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN variation of AlexNet for Image Classification in Caffe where the max pooling precedes the local response normalization (LRN) so that the LRN takes less compute and memory.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/rcnn_ilsvrc13"&gt;RCNN_ILSVRC13&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1311.2524" rel="nofollow"&gt;Girshick et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Pure Caffe implementation of R-CNN for image classification. This model uses localization of regions to classify and extract features from images.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/densenet-121"&gt;DenseNet-121&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1608.06993" rel="nofollow"&gt;Huang et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Model that has every layer connected to every other layer and passes on its own feature providing strong gradient flow and more diversified features.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/inception_and_googlenet/inception_v1"&gt;Inception_V1&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1409.4842" rel="nofollow"&gt;Szegedy et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;This model is same as GoogLeNet, implemented through Caffe2 that has improved utilization of the computing resources inside the network and helps with the vanishing gradient problem. &lt;br&gt; Top-5 error from paper - ~6.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/inception_and_googlenet/inception_v2"&gt;Inception_V2&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1512.00567" rel="nofollow"&gt;Szegedy et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN model for Image Classification as an adaptation to Inception v1 with batch normalization. This model has reduced computational cost and improved image resolution compared to Inception v1. &lt;br&gt; Top-5 error from paper ~4.82%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/shufflenet"&gt;ShuffleNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1707.01083" rel="nofollow"&gt;Zhang et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Extremely computation efficient CNN model that is designed specifically for mobile devices. This model greatly reduces the computational cost and provides a ~13x speedup over AlexNet on ARM-based mobile devices. Compared to MobileNet, ShuffleNet achieves superior performance by a significant margin due to it's efficient structure. &lt;br&gt; Top-1 error from paper - ~7.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/zfnet-512"&gt;ZFNet-512&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1311.2901" rel="nofollow"&gt;Zeiler et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN model (up to 8 layers) that increased the number of features that the network is capable of detecting that helps to pick image features at a finer level of resolution. &lt;br&gt; Top-5 error from paper - ~14.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h4&gt;&lt;a id="user-content-domain-based-image-classification-" class="anchor" aria-hidden="true" href="#domain-based-image-classification-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-image_classification"&gt;Domain-based Image Classification &lt;/a&gt;&lt;a name="user-content-domain_based_image"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;a name="user-content-domain_based_image"&gt;
&lt;p&gt;This subset of models classify images for specific domains and datasets.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/mnist"&gt;MNIST-Handwritten Digit Recognition&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Microsoft/CNTK/blob/master/Tutorials/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.ipynb"&gt;Convolutional Neural Network with MNIST&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN model for handwritten digit identification&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-object-detection--image-segmentation-" class="anchor" aria-hidden="true" href="#object-detection--image-segmentation-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-domain_based_image"&gt;Object Detection &amp;amp; Image Segmentation &lt;/a&gt;&lt;a name="user-content-object_detection"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-object_detection"&gt;
&lt;p&gt;Object detection models detect the presence of multiple objects in an image and segment out areas of the image where the objects are detected. Semantic segmentation models partition an input image by labeling each pixel into a set of pre-defined categories.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/tiny_yolov2"&gt;Tiny YOLOv2&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1612.08242.pdf" rel="nofollow"&gt;Redmon et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A real-time CNN for object detection that detects 20 different classes. A smaller version of the more complex full YOLOv2 network.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/ssd"&gt;SSD&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1512.02325" rel="nofollow"&gt;Liu et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Single Stage Detector: real-time CNN for object detection that detects 80 different classes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/faster-rcnn"&gt;Faster-RCNN&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1506.01497" rel="nofollow"&gt;Ren et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Increases efficiency from R-CNN by connecting a RPN with a CNN to create a single, unified network for object detection that detects 80 different classes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/mask-rcnn"&gt;Mask-RCNN&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1703.06870" rel="nofollow"&gt;He et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A real-time neural network for object instance segmentation that detects 80 different classes. Extends Faster R-CNN as each of the 300 elected ROIs go through 3 parallel branches of the network: label prediction, bounding box prediction and mask prediction.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;YOLO v2&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1612.08242" rel="nofollow"&gt;Redmon et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A CNN model for real-time object detection system that can detect over 9000 object categories. It uses a single network evaluation, enabling it to be more than 1000x faster than R-CNN and 100x faster than Faster R-CNN. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/yolov3"&gt;YOLO v3&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1804.02767.pdf" rel="nofollow"&gt;Redmon et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A deep CNN model for real-time object detection that detects 80 different classes. A little bigger than YOLOv2 but still very fast. As accurate as SSD but 3 times faster.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/tiny_yolov3"&gt;Tiny YOLOv3&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1804.02767.pdf" rel="nofollow"&gt;Redmon et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A smaller version of YOLOv3 model.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/duc"&gt;DUC&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1702.08502" rel="nofollow"&gt;Wang et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN based pixel-wise semantic segmentation model with &amp;gt;80% &lt;a href="/models/semantic_segmentation/DUC/README.md/#metric"&gt;mIOU&lt;/a&gt; (mean Intersection Over Union). Trained on cityscapes dataset, which can be effectively implemented in self driving vehicle systems.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FCN&lt;/td&gt;
&lt;td&gt;&lt;a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf" rel="nofollow"&gt;Long et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN based segmentation model trained end-to-end, pixel-to-pixel that produces efficient inference and learning. Built off of AlexNet, VGG net, GoogLeNet classification methods. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-body-face--gesture-analysis-" class="anchor" aria-hidden="true" href="#body-face--gesture-analysis-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-object_detection"&gt;Body, Face &amp;amp; Gesture Analysis &lt;/a&gt;&lt;a name="user-content-body_analysis"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-body_analysis"&gt;
&lt;p&gt;Face detection models identify and/or recognize human faces and emotions in given images. Body and Gesture Analysis models identify gender and age in given image.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/body_analysis/arcface"&gt;ArcFace&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1801.07698" rel="nofollow"&gt;Deng et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A CNN based model for face recognition which learns discriminative features of faces and produces embeddings for input face images.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CNN Cascade&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Li_A_Convolutional_Neural_2015_CVPR_paper.pdf" rel="nofollow"&gt;Li et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;The model operates at multiple resolutions, quickly rejecting the background regions in the fast low resolution stages in an image and carefully evaluates a small number of challenging candidates in the last high resolution stage. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/body_analysis/emotion_ferplus"&gt;Emotion FerPlus&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1608.01041" rel="nofollow"&gt;Barsoum et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN for emotion recognition trained on images of faces.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Age and Gender Classification using Convolutional Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.openu.ac.il/home/hassner/projects/cnn_agegender/CNN_AgeGenderEstimation.pdf" rel="nofollow"&gt;Levi et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;This model accurately classifies gender and age even the amount of learning data is limited.&lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-image-manipulation-" class="anchor" aria-hidden="true" href="#image-manipulation-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-body_analysis"&gt;Image Manipulation &lt;/a&gt;&lt;a name="user-content-image_manipulation"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-image_manipulation"&gt;
&lt;p&gt;Image manipulation models use neural networks to transform input images to modified output images. Some popular models in this category involve style transfer or enhancing images by increasing resolution.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Unpaired Image to Image Translation using Cycle consistent Adversarial Network&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1703.10593" rel="nofollow"&gt;Zhu et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;The model uses learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/super_resolution/sub_pixel_cnn_2016"&gt;Super Resolution with sub-pixel CNN&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1609.05158" rel="nofollow"&gt;Shi et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A deep CNN that uses sub-pixel convolution layers to upscale the input image.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/style_transfer/fast_neural_style"&gt;Fast Neural Style Transfer&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1603.08155" rel="nofollow"&gt;Johnson et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;This method uses a loss network pretrained for image classification to define perceptual loss functions that measure perceptual differences in content and style between images. The loss network remains fixed during the training process.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-speech--audio-processing-" class="anchor" aria-hidden="true" href="#speech--audio-processing-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-image_manipulation"&gt;Speech &amp;amp; Audio Processing &lt;/a&gt;&lt;a name="user-content-speech"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-speech"&gt;
&lt;p&gt;This class of models uses audio data to train models that can identify voice, generate music, or even read text out loud.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Speech recognition with deep recurrent neural networks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.cs.toronto.edu/~fritz/absps/RNN13.pdf" rel="nofollow"&gt;Graves et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A RNN model for sequential data for speech recognition. Labels problems where the input-output alignment is unknown&lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Deep voice: Real time neural text to speech&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1702.07825" rel="nofollow"&gt;Arik et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A DNN model that performs end-to-end neural speech synthesis. Requires fewer parameters and it is faster than other systems. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Sound Generative models&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1609.03499" rel="nofollow"&gt;WaveNet: A Generative Model for Raw Audio &lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A CNN model that generates raw audio waveforms. Has predictive distribution for each audio sample. Generates realistic music fragments. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-machine-comprehension-" class="anchor" aria-hidden="true" href="#machine-comprehension-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-speech"&gt;Machine Comprehension &lt;/a&gt;&lt;a name="user-content-machine_comprehension"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-machine_comprehension"&gt;
&lt;p&gt;This subset of natural language processing models that answer questions about a given context paragraph.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="text/machine_comprehension/bidirectional_attention_flow"&gt;Bidirectional Attention Flow&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1611.01603" rel="nofollow"&gt;Seo et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A model that answers a query about a given context paragraph.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="text/machine_comprehension/bert-squad"&gt;BERT-Squad&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1810.04805.pdf" rel="nofollow"&gt;Devlin et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;This model answers questions based on the context of the given input paragraph.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="text/machine_comprehension/gpt-2"&gt;GPT-2&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="nofollow"&gt;Radford et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A large transformer-based language model that given a sequence of words within some text, predicts the next word.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-machine-translation-" class="anchor" aria-hidden="true" href="#machine-translation-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-machine_comprehension"&gt;Machine Translation &lt;/a&gt;&lt;a name="user-content-machine_translation"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-machine_translation"&gt;
&lt;p&gt;This class of natural language processing models learns how to translate input text to another language.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Neural Machine Translation by jointly learning to align and translate&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1409.0473" rel="nofollow"&gt;Bahdanau et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Aims to build a single neural network that can be jointly tuned to maximize the translation performance. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Google's Neural Machine Translation System&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1609.08144" rel="nofollow"&gt;Wu et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;This model helps to improve issues faced by the Neural Machine Translation (NMT) systems like parallelism that helps accelerate the final translation speed.&lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-language-modelling-" class="anchor" aria-hidden="true" href="#language-modelling-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-machine_translation"&gt;Language Modelling &lt;/a&gt;&lt;a name="user-content-language"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-language"&gt;
&lt;p&gt;This subset of natural language processing models learns representations of language from large corpuses of text.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Deep Neural Network Language Models&lt;/td&gt;
&lt;td&gt;&lt;a href="https://pdfs.semanticscholar.org/a177/45f1d7045636577bcd5d513620df5860e9e5.pdf" rel="nofollow"&gt;Arisoy et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A DNN acoustic model. Used in many natural language technologies. Represents a probability distribution over all possible word strings in a language. &lt;br&gt; &lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-visual-question-answering--dialog-" class="anchor" aria-hidden="true" href="#visual-question-answering--dialog-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-language"&gt;Visual Question Answering &amp;amp; Dialog &lt;/a&gt;&lt;a name="user-content-visual_qna"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-visual_qna"&gt;
&lt;p&gt;This subset of natural language processing models uses input images to answer questions about those images.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;VQA: Visual Question Answering&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1505.00468v6.pdf" rel="nofollow"&gt;Agrawal et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A model that takes an image and a free-form, open-ended natural language question about the image and outputs a natural-language answer. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Yin and Yang: Balancing and Answering Binary Visual Questions&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1511.05099.pdf" rel="nofollow"&gt;Zhang et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Addresses VQA by converting the question to a tuple that concisely summarizes the visual concept to be detected in the image. Next, if the concept can be found in the image, it provides a “yes” or “no” answer. Its performance matches the traditional VQA approach on unbalanced dataset, and outperforms it on the balanced dataset. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Making the V in VQA Matter&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1612.00837.pdf" rel="nofollow"&gt;Goyal et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Balances the VQA dataset by collecting complementary images such that every question is associated with a pair of similar images that result in two different answers to the question, providing a unique interpretable model that provides a counter-example based explanation.  &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Visual Dialog&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1611.08669" rel="nofollow"&gt;Das et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;An AI agent that holds a meaningful dialog with humans in natural, conversational language about visual content. Curates a large-scale Visual Dialog dataset (VisDial). &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-other-interesting-models-" class="anchor" aria-hidden="true" href="#other-interesting-models-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-visual_qna"&gt;Other interesting models &lt;/a&gt;&lt;a name="user-content-others"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-others"&gt;
&lt;/a&gt;&lt;p&gt;&lt;a name="user-content-others"&gt;There are many interesting deep learning models that do not fit into the categories described above. The ONNX team would like to highly encourage users and researchers to &lt;/a&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt; their models to the growing model zoo.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Text to Image&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1605.05396" rel="nofollow"&gt;Generative Adversarial Text to image Synthesis &lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Effectively bridges the advances in text and image modeling, translating visual concepts from characters to pixels. Generates plausible images of birds and flowers from detailed text descriptions. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Time Series Forecasting&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1703.07015.pdf" rel="nofollow"&gt;Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks &lt;/a&gt;&lt;/td&gt;
&lt;td&gt;The model extracts short-term local dependency patterns among variables and to discover long-term patterns for time series trends. It helps to predict solar plant energy output, electricity consumption, and traffic jam situations. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Recommender systems&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.cs.toronto.edu/~mvolkovs/nips2017_deepcf.pdf" rel="nofollow"&gt;DropoutNet: Addressing Cold Start in Recommender Systems&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A collaborative filtering method that makes predictions about an individual’s preference based on preference information from other users.&lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Collaborative filtering&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1708.05031.pdf" rel="nofollow"&gt;Neural Collaborative Filtering&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A DNN model based on the interaction between user and item features using matrix factorization. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Autoencoders&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1506.01057" rel="nofollow"&gt;A Hierarchical Neural Autoencoder for Paragraphs and Documents&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;An LSTM (long-short term memory) auto-encoder to preserve and reconstruct multi-sentence paragraphs.&lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-usage-" class="anchor" aria-hidden="true" href="#usage-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage &lt;a name="user-content-usage-"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;a name="user-content-usage-"&gt;
&lt;p&gt;Every ONNX backend should support running the models out of the box. After downloading and extracting the tarball of each model, you will find:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A protobuf file &lt;code&gt;model.onnx&lt;/code&gt; that represents the serialized ONNX model.&lt;/li&gt;
&lt;li&gt;Test data (in the form of serialized protobuf TensorProto files or serialized NumPy archives).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The test data files can be used to validate ONNX models from the Model Zoo. We have provided the following interface examples for you to get started. Please replace &lt;code&gt;onnx_backend&lt;/code&gt; in your code with the appropriate framework of your choice that provides ONNX inferencing support, and likewise replace &lt;code&gt;backend.run_model&lt;/code&gt; with the framework's model evaluation logic.&lt;/p&gt;
&lt;p&gt;There are two different formats for the test data files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Serialized protobuf TensorProtos (.pb), stored in folders with the naming convention &lt;code&gt;test_data_set_*&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np
&lt;span class="pl-k"&gt;import&lt;/span&gt; onnx
&lt;span class="pl-k"&gt;import&lt;/span&gt; os
&lt;span class="pl-k"&gt;import&lt;/span&gt; glob
&lt;span class="pl-k"&gt;import&lt;/span&gt; onnx_backend &lt;span class="pl-k"&gt;as&lt;/span&gt; backend

&lt;span class="pl-k"&gt;from&lt;/span&gt; onnx &lt;span class="pl-k"&gt;import&lt;/span&gt; numpy_helper

model &lt;span class="pl-k"&gt;=&lt;/span&gt; onnx.load(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;model.onnx&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
test_data_dir &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;test_data_set_0&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load inputs&lt;/span&gt;
inputs &lt;span class="pl-k"&gt;=&lt;/span&gt; []
inputs_num &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;len&lt;/span&gt;(glob.glob(os.path.join(test_data_dir, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;input_*.pb&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)))
&lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(inputs_num):
    input_file &lt;span class="pl-k"&gt;=&lt;/span&gt; os.path.join(test_data_dir, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;input_&lt;span class="pl-c1"&gt;{}&lt;/span&gt;.pb&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.format(i))
    tensor &lt;span class="pl-k"&gt;=&lt;/span&gt; onnx.TensorProto()
    &lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-c1"&gt;open&lt;/span&gt;(input_file, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;rb&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-k"&gt;as&lt;/span&gt; f:
        tensor.ParseFromString(f.read())
    inputs.append(numpy_helper.to_array(tensor))

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load reference outputs&lt;/span&gt;
ref_outputs &lt;span class="pl-k"&gt;=&lt;/span&gt; []
ref_outputs_num &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;len&lt;/span&gt;(glob.glob(os.path.join(test_data_dir, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;output_*.pb&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)))
&lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(ref_outputs_num):
    output_file &lt;span class="pl-k"&gt;=&lt;/span&gt; os.path.join(test_data_dir, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;output_&lt;span class="pl-c1"&gt;{}&lt;/span&gt;.pb&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.format(i))
    tensor &lt;span class="pl-k"&gt;=&lt;/span&gt; onnx.TensorProto()
    &lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-c1"&gt;open&lt;/span&gt;(output_file, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;rb&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-k"&gt;as&lt;/span&gt; f:
        tensor.ParseFromString(f.read())
    ref_outputs.append(numpy_helper.to_array(tensor))

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Run the model on the backend&lt;/span&gt;
outputs &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;list&lt;/span&gt;(backend.run_model(model, inputs))

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Compare the results with reference outputs.&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; ref_o, o &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;zip&lt;/span&gt;(ref_outputs, outputs):
    np.testing.assert_almost_equal(ref_o, o)&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Serialized Numpy archives, stored in files with the naming convention &lt;code&gt;test_data_*.npz&lt;/code&gt;. Each file contains one set of test inputs and outputs.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np
&lt;span class="pl-k"&gt;import&lt;/span&gt; onnx
&lt;span class="pl-k"&gt;import&lt;/span&gt; onnx_backend &lt;span class="pl-k"&gt;as&lt;/span&gt; backend

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load the model and sample inputs and outputs&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; onnx.load(model_pb_path)
sample &lt;span class="pl-k"&gt;=&lt;/span&gt; np.load(npz_path, &lt;span class="pl-v"&gt;encoding&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bytes&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
inputs &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;list&lt;/span&gt;(sample[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;inputs&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])
outputs &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;list&lt;/span&gt;(sample[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;outputs&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Run the model with an onnx backend and verify the results&lt;/span&gt;
np.testing.assert_almost_equal(outputs, backend.run_model(model, inputs))&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-model-visualization" class="anchor" aria-hidden="true" href="#model-visualization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model Visualization&lt;/h2&gt;
&lt;/a&gt;&lt;p&gt;&lt;a name="user-content-usage-"&gt;You can see visualizations of each model's network architecture by using &lt;/a&gt;&lt;a href="https://lutzroeder.github.io/Netron" rel="nofollow"&gt;Netron&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributions" class="anchor" aria-hidden="true" href="#contributions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributions&lt;/h2&gt;
&lt;p&gt;Do you want to contribute a model? To get started, pick any model presented above with the &lt;a href="contribute.md"&gt;contribute&lt;/a&gt; link under the Description column. The links point to a page containing guidelines for making a contribution.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h1&gt;
&lt;p&gt;&lt;a href="LICENSE"&gt;MIT License&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>onnx</author><guid isPermaLink="false">https://github.com/onnx/models</guid><pubDate>Thu, 21 Nov 2019 00:13:00 GMT</pubDate></item><item><title>fastai/course-nlp #14 in Jupyter Notebook, This week</title><link>https://github.com/fastai/course-nlp</link><description>&lt;p&gt;&lt;i&gt;A Code-First Introduction to NLP course&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-a-code-first-intro-to-natural-language-processing" class="anchor" aria-hidden="true" href="#a-code-first-intro-to-natural-language-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A Code-First Intro to Natural Language Processing&lt;/h1&gt;
&lt;p&gt;You can find out about the course in &lt;a href="https://www.fast.ai/2019/07/08/fastai-nlp/" rel="nofollow"&gt;this blog post&lt;/a&gt; and all &lt;a href="https://www.youtube.com/playlist?list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9" rel="nofollow"&gt;lecture videos are available here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This course was originally taught in the &lt;a href="https://www.usfca.edu/arts-sciences/graduate-programs/analytics" rel="nofollow"&gt;University of San Francisco's Masters of Science in Data Science&lt;/a&gt; program, summer 2019.  The course is taught in Python with Jupyter Notebooks, using libraries such as sklearn, nltk, pytorch, and fastai.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h2&gt;
&lt;p&gt;The following topics will be covered:&lt;/p&gt;
&lt;p&gt;1. What is NLP?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A changing field&lt;/li&gt;
&lt;li&gt;Resources&lt;/li&gt;
&lt;li&gt;Tools&lt;/li&gt;
&lt;li&gt;Python libraries&lt;/li&gt;
&lt;li&gt;Example applications&lt;/li&gt;
&lt;li&gt;Ethics issues&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2. Topic Modeling with NMF and SVD&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stop words, stemming, &amp;amp; lemmatization&lt;/li&gt;
&lt;li&gt;Term-document matrix&lt;/li&gt;
&lt;li&gt;Topic Frequency-Inverse Document Frequency (TF-IDF)&lt;/li&gt;
&lt;li&gt;Singular Value Decomposition (SVD)&lt;/li&gt;
&lt;li&gt;Non-negative Matrix Factorization (NMF)&lt;/li&gt;
&lt;li&gt;Truncated SVD, Randomized SVD&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3. Sentiment classification with Naive Bayes, Logistic regression, and ngrams&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sparse matrix storage&lt;/li&gt;
&lt;li&gt;Counters&lt;/li&gt;
&lt;li&gt;the fastai library&lt;/li&gt;
&lt;li&gt;Naive Bayes&lt;/li&gt;
&lt;li&gt;Logistic regression&lt;/li&gt;
&lt;li&gt;Ngrams&lt;/li&gt;
&lt;li&gt;Logistic regression with Naive Bayes features, with trigrams&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;4. Regex (and re-visiting tokenization)&lt;/p&gt;
&lt;p&gt;5. Language modeling &amp;amp; sentiment classification with deep learning&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Language model&lt;/li&gt;
&lt;li&gt;Transfer learning&lt;/li&gt;
&lt;li&gt;Sentiment classification&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;6. Translation with RNNs&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Review Embeddings&lt;/li&gt;
&lt;li&gt;Bleu metric&lt;/li&gt;
&lt;li&gt;Teacher Forcing&lt;/li&gt;
&lt;li&gt;Bidirectional&lt;/li&gt;
&lt;li&gt;Attention&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;7. Translation with the Transformer architecture&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transformer Model&lt;/li&gt;
&lt;li&gt;Multi-head attention&lt;/li&gt;
&lt;li&gt;Masking&lt;/li&gt;
&lt;li&gt;Label smoothing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;8. Bias &amp;amp; ethics in NLP&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bias in word embeddings&lt;/li&gt;
&lt;li&gt;types of bias&lt;/li&gt;
&lt;li&gt;attention economy&lt;/li&gt;
&lt;li&gt;drowning in fraudulent/fake info&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-why-is-this-course-taught-in-a-weird-order" class="anchor" aria-hidden="true" href="#why-is-this-course-taught-in-a-weird-order"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why is this course taught in a weird order?&lt;/h2&gt;
&lt;p&gt;This course is structured with a &lt;em&gt;top-down&lt;/em&gt; teaching method, which is different from how most math courses operate.  Typically, in a &lt;em&gt;bottom-up&lt;/em&gt; approach, you first learn all the separate components you will be using, and then you gradually build them up into more complex structures.  The problems with this are that students often lose motivation, don't have a sense of the "big picture", and don't know what they'll need.&lt;/p&gt;
&lt;p&gt;Harvard Professor David Perkins has a book, &lt;a href="https://www.amazon.com/Making-Learning-Whole-Principles-Transform/dp/0470633719" rel="nofollow"&gt;Making Learning Whole&lt;/a&gt; in which he uses baseball as an analogy.  We don't require kids to memorize all the rules of baseball and understand all the technical details before we let them play the game.  Rather, they start playing with a just general sense of it, and then gradually learn more rules/details as time goes on.&lt;/p&gt;
&lt;p&gt;If you took the fast.ai deep learning course, that is what we used.  You can hear more about my teaching philosophy &lt;a href="http://www.fast.ai/2016/10/08/teaching-philosophy/" rel="nofollow"&gt;in this blog post&lt;/a&gt; or &lt;a href="https://vimeo.com/214233053" rel="nofollow"&gt;this talk I gave at the San Francisco Machine Learning meetup&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All that to say, don't worry if you don't understand everything at first!  You're not supposed to.  We will start using some "black boxes" and then we'll dig into the lower level details later.&lt;/p&gt;
&lt;p&gt;To start, focus on what things DO, not what they ARE.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fastai</author><guid isPermaLink="false">https://github.com/fastai/course-nlp</guid><pubDate>Thu, 21 Nov 2019 00:14:00 GMT</pubDate></item><item><title>justmarkham/scikit-learn-videos #15 in Jupyter Notebook, This week</title><link>https://github.com/justmarkham/scikit-learn-videos</link><description>&lt;p&gt;&lt;i&gt;Jupyter notebooks from the scikit-learn video series&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-introduction-to-machine-learning-with-scikit-learn" class="anchor" aria-hidden="true" href="#introduction-to-machine-learning-with-scikit-learn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction to machine learning with scikit-learn&lt;/h1&gt;
&lt;p&gt;This video series will teach you how to solve machine learning problems using Python's popular scikit-learn library. There are &lt;strong&gt;10 video tutorials&lt;/strong&gt; totaling 4.5 hours, each with a corresponding &lt;strong&gt;Jupyter notebook&lt;/strong&gt;. The notebook contains everything you see in the video: code, output, images, and comments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The notebooks in this repository have been updated to use Python 3.6 and scikit-learn 0.19.1. The original notebooks (shown in the video) used Python 2.7 and scikit-learn 0.16, and can be downloaded from the &lt;a href="https://github.com/justmarkham/scikit-learn-videos/tree/archive"&gt;archive branch&lt;/a&gt;. You can read about how I updated the code in this &lt;a href="https://www.dataschool.io/how-to-update-your-scikit-learn-code-for-2018/" rel="nofollow"&gt;blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can &lt;a href="https://www.youtube.com/playlist?list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A" rel="nofollow"&gt;watch the entire series&lt;/a&gt; on YouTube, and &lt;a href="http://nbviewer.jupyter.org/github/justmarkham/scikit-learn-videos/tree/master/" rel="nofollow"&gt;view all of the notebooks&lt;/a&gt; using nbviewer.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=elojMnjn4kk&amp;amp;list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&amp;amp;index=1" title="Watch the first tutorial video" rel="nofollow"&gt;&lt;img src="images/youtube.png" alt="Watch the first tutorial video" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Once you complete this video series, I recommend enrolling in my online course, &lt;a href="http://www.dataschool.io/learn/" rel="nofollow"&gt;Machine Learning with Text in Python&lt;/a&gt;, to gain a deeper understanding of scikit-learn and Natural Language Processing.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;What is machine learning, and how does it work? (&lt;a href="https://www.youtube.com/watch?v=elojMnjn4kk&amp;amp;list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&amp;amp;index=1" rel="nofollow"&gt;video&lt;/a&gt;, &lt;a href="01_machine_learning_intro.ipynb"&gt;notebook&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is machine learning?&lt;/li&gt;
&lt;li&gt;What are the two main categories of machine learning?&lt;/li&gt;
&lt;li&gt;What are some examples of machine learning?&lt;/li&gt;
&lt;li&gt;How does machine learning "work"?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Setting up Python for machine learning: scikit-learn and Jupyter Notebook (&lt;a href="https://www.youtube.com/watch?v=IsXXlYVBt1M&amp;amp;list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&amp;amp;index=2" rel="nofollow"&gt;video&lt;/a&gt;, &lt;a href="02_machine_learning_setup.ipynb"&gt;notebook&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What are the benefits and drawbacks of scikit-learn?&lt;/li&gt;
&lt;li&gt;How do I install scikit-learn?&lt;/li&gt;
&lt;li&gt;How do I use the Jupyter Notebook?&lt;/li&gt;
&lt;li&gt;What are some good resources for learning Python?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Getting started in scikit-learn with the famous iris dataset (&lt;a href="https://www.youtube.com/watch?v=hd1W4CyPX58&amp;amp;list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&amp;amp;index=3" rel="nofollow"&gt;video&lt;/a&gt;, &lt;a href="03_getting_started_with_iris.ipynb"&gt;notebook&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is the famous iris dataset, and how does it relate to machine learning?&lt;/li&gt;
&lt;li&gt;How do we load the iris dataset into scikit-learn?&lt;/li&gt;
&lt;li&gt;How do we describe a dataset using machine learning terminology?&lt;/li&gt;
&lt;li&gt;What are scikit-learn's four key requirements for working with data?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Training a machine learning model with scikit-learn (&lt;a href="https://www.youtube.com/watch?v=RlQuVL6-qe8&amp;amp;list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&amp;amp;index=4" rel="nofollow"&gt;video&lt;/a&gt;, &lt;a href="04_model_training.ipynb"&gt;notebook&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is the K-nearest neighbors classification model?&lt;/li&gt;
&lt;li&gt;What are the four steps for model training and prediction in scikit-learn?&lt;/li&gt;
&lt;li&gt;How can I apply this pattern to other machine learning models?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Comparing machine learning models in scikit-learn (&lt;a href="https://www.youtube.com/watch?v=0pP4EwWJgIU&amp;amp;list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&amp;amp;index=5" rel="nofollow"&gt;video&lt;/a&gt;, &lt;a href="05_model_evaluation.ipynb"&gt;notebook&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How do I choose which model to use for my supervised learning task?&lt;/li&gt;
&lt;li&gt;How do I choose the best tuning parameters for that model?&lt;/li&gt;
&lt;li&gt;How do I estimate the likely performance of my model on out-of-sample data?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Data science pipeline: pandas, seaborn, scikit-learn (&lt;a href="https://www.youtube.com/watch?v=3ZWuPVWq7p4&amp;amp;list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&amp;amp;index=6" rel="nofollow"&gt;video&lt;/a&gt;, &lt;a href="06_linear_regression.ipynb"&gt;notebook&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How do I use the pandas library to read data into Python?&lt;/li&gt;
&lt;li&gt;How do I use the seaborn library to visualize data?&lt;/li&gt;
&lt;li&gt;What is linear regression, and how does it work?&lt;/li&gt;
&lt;li&gt;How do I train and interpret a linear regression model in scikit-learn?&lt;/li&gt;
&lt;li&gt;What are some evaluation metrics for regression problems?&lt;/li&gt;
&lt;li&gt;How do I choose which features to include in my model?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cross-validation for parameter tuning, model selection, and feature selection (&lt;a href="https://www.youtube.com/watch?v=6dbrR-WymjI&amp;amp;list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&amp;amp;index=7" rel="nofollow"&gt;video&lt;/a&gt;, &lt;a href="07_cross_validation.ipynb"&gt;notebook&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is the drawback of using the train/test split procedure for model evaluation?&lt;/li&gt;
&lt;li&gt;How does K-fold cross-validation overcome this limitation?&lt;/li&gt;
&lt;li&gt;How can cross-validation be used for selecting tuning parameters, choosing between models, and selecting features?&lt;/li&gt;
&lt;li&gt;What are some possible improvements to cross-validation?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Efficiently searching for optimal tuning parameters (&lt;a href="https://www.youtube.com/watch?v=Gol_qOgRqfA&amp;amp;list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&amp;amp;index=8" rel="nofollow"&gt;video&lt;/a&gt;, &lt;a href="08_grid_search.ipynb"&gt;notebook&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How can K-fold cross-validation be used to search for an optimal tuning parameter?&lt;/li&gt;
&lt;li&gt;How can this process be made more efficient?&lt;/li&gt;
&lt;li&gt;How do you search for multiple tuning parameters at once?&lt;/li&gt;
&lt;li&gt;What do you do with those tuning parameters before making real predictions?&lt;/li&gt;
&lt;li&gt;How can the computational expense of this process be reduced?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Evaluating a classification model (&lt;a href="https://www.youtube.com/watch?v=85dtiMz9tSo&amp;amp;list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&amp;amp;index=9" rel="nofollow"&gt;video&lt;/a&gt;, &lt;a href="09_classification_metrics.ipynb"&gt;notebook&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is the purpose of model evaluation, and what are some common evaluation procedures?&lt;/li&gt;
&lt;li&gt;What is the usage of classification accuracy, and what are its limitations?&lt;/li&gt;
&lt;li&gt;How does a confusion matrix describe the performance of a classifier?&lt;/li&gt;
&lt;li&gt;What metrics can be computed from a confusion matrix?&lt;/li&gt;
&lt;li&gt;How can you adjust classifier performance by changing the classification threshold?&lt;/li&gt;
&lt;li&gt;What is the purpose of an ROC curve?&lt;/li&gt;
&lt;li&gt;How does Area Under the Curve (AUC) differ from classification accuracy?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Encoding categorical features (&lt;a href="https://www.youtube.com/watch?v=irHhDMbw3xo&amp;amp;list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&amp;amp;index=10" rel="nofollow"&gt;video&lt;/a&gt;, &lt;a href="10_categorical_features.ipynb"&gt;notebook&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Why should you use a Pipeline?&lt;/li&gt;
&lt;li&gt;How do you encode categorical features with OneHotEncoder?&lt;/li&gt;
&lt;li&gt;How do you apply OneHotEncoder to selected columns with ColumnTransformer?&lt;/li&gt;
&lt;li&gt;How do you build and cross-validate a Pipeline?&lt;/li&gt;
&lt;li&gt;How do you make predictions on new data using a Pipeline?&lt;/li&gt;
&lt;li&gt;Why should you use scikit-learn (rather than pandas) for preprocessing?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-bonus-video" class="anchor" aria-hidden="true" href="#bonus-video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bonus Video&lt;/h2&gt;
&lt;p&gt;At the PyCon 2016 conference, I taught a &lt;strong&gt;3-hour tutorial&lt;/strong&gt; that builds upon this video series and focuses on &lt;strong&gt;text-based data&lt;/strong&gt;. You can watch the &lt;a href="https://www.youtube.com/watch?v=ZiKMIuYidY0&amp;amp;list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&amp;amp;index=10" rel="nofollow"&gt;tutorial video&lt;/a&gt; on YouTube.&lt;/p&gt;
&lt;p&gt;Here are the topics I covered:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Model building in scikit-learn (refresher)&lt;/li&gt;
&lt;li&gt;Representing text as numerical data&lt;/li&gt;
&lt;li&gt;Reading a text-based dataset into pandas&lt;/li&gt;
&lt;li&gt;Vectorizing our dataset&lt;/li&gt;
&lt;li&gt;Building and evaluating a model&lt;/li&gt;
&lt;li&gt;Comparing models&lt;/li&gt;
&lt;li&gt;Examining a model for further insight&lt;/li&gt;
&lt;li&gt;Practicing this workflow on another dataset&lt;/li&gt;
&lt;li&gt;Tuning the vectorizer (discussion)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Visit this &lt;a href="https://github.com/justmarkham/pycon-2016-tutorial"&gt;GitHub repository&lt;/a&gt; to access the tutorial notebooks and many other recommended resources.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>justmarkham</author><guid isPermaLink="false">https://github.com/justmarkham/scikit-learn-videos</guid><pubDate>Thu, 21 Nov 2019 00:15:00 GMT</pubDate></item><item><title>dennybritz/reinforcement-learning #16 in Jupyter Notebook, This week</title><link>https://github.com/dennybritz/reinforcement-learning</link><description>&lt;p&gt;&lt;i&gt;Implementation of Reinforcement Learning Algorithms. Python, OpenAI Gym, Tensorflow. Exercises and Solutions to accompany Sutton's Book and David Silver's course.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h3&gt;&lt;a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overview&lt;/h3&gt;
&lt;p&gt;This repository provides code, exercises and solutions for popular Reinforcement Learning algorithms. These are meant to serve as a learning tool to complement the theoretical materials from&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://incompleteideas.net/book/RLbook2018.pdf" rel="nofollow"&gt;Reinforcement Learning: An Introduction (2nd Edition)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" rel="nofollow"&gt;David Silver's Reinforcement Learning Course&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each folder in corresponds to one or more chapters of the above textbook and/or course. In addition to exercises and solution, each folder also contains a list of learning goals, a brief concept summary, and links to the relevant readings.&lt;/p&gt;
&lt;p&gt;All code is written in Python 3 and uses RL environments from &lt;a href="https://gym.openai.com/" rel="nofollow"&gt;OpenAI Gym&lt;/a&gt;. Advanced techniques use &lt;a href="https://www.tensorflow.org/" rel="nofollow"&gt;Tensorflow&lt;/a&gt; for neural network implementations.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="Introduction/"&gt;Introduction to RL problems &amp;amp; OpenAI Gym&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="MDP/"&gt;MDPs and Bellman Equations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="DP/"&gt;Dynamic Programming: Model-Based RL, Policy Iteration and Value Iteration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="MC/"&gt;Monte Carlo Model-Free Prediction &amp;amp; Control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="TD/"&gt;Temporal Difference Model-Free Prediction &amp;amp; Control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="FA/"&gt;Function Approximation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="DQN/"&gt;Deep Q Learning&lt;/a&gt; (WIP)&lt;/li&gt;
&lt;li&gt;&lt;a href="PolicyGradient/"&gt;Policy Gradient Methods&lt;/a&gt; (WIP)&lt;/li&gt;
&lt;li&gt;Learning and Planning (WIP)&lt;/li&gt;
&lt;li&gt;Exploration and Exploitation (WIP)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-list-of-implemented-algorithms" class="anchor" aria-hidden="true" href="#list-of-implemented-algorithms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;List of Implemented Algorithms&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="DP/Policy%20Evaluation%20Solution.ipynb"&gt;Dynamic Programming Policy Evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="DP/Policy%20Iteration%20Solution.ipynb"&gt;Dynamic Programming Policy Iteration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="DP/Value%20Iteration%20Solution.ipynb"&gt;Dynamic Programming Value Iteration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="MC/MC%20Prediction%20Solution.ipynb"&gt;Monte Carlo Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="MC/MC%20Control%20with%20Epsilon-Greedy%20Policies%20Solution.ipynb"&gt;Monte Carlo Control with Epsilon-Greedy Policies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="MC/Off-Policy%20MC%20Control%20with%20Weighted%20Importance%20Sampling%20Solution.ipynb"&gt;Monte Carlo Off-Policy Control with Importance Sampling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="TD/SARSA%20Solution.ipynb"&gt;SARSA (On Policy TD Learning)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="TD/Q-Learning%20Solution.ipynb"&gt;Q-Learning (Off Policy TD Learning)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="FA/Q-Learning%20with%20Value%20Function%20Approximation%20Solution.ipynb"&gt;Q-Learning with Linear Function Approximation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="DQN/Deep%20Q%20Learning%20Solution.ipynb"&gt;Deep Q-Learning for Atari Games&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="DQN/Double%20DQN%20Solution.ipynb"&gt;Double Deep-Q Learning for Atari Games&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep Q-Learning with Prioritized Experience Replay (WIP)&lt;/li&gt;
&lt;li&gt;&lt;a href="PolicyGradient/CliffWalk%20REINFORCE%20with%20Baseline%20Solution.ipynb"&gt;Policy Gradient: REINFORCE with Baseline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="PolicyGradient/CliffWalk%20Actor%20Critic%20Solution.ipynb"&gt;Policy Gradient: Actor Critic with Baseline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="PolicyGradient/Continuous%20MountainCar%20Actor%20Critic%20Solution.ipynb"&gt;Policy Gradient: Actor Critic with Baseline for Continuous Action Spaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deterministic Policy Gradients for Continuous Action Spaces (WIP)&lt;/li&gt;
&lt;li&gt;Deep Deterministic Policy Gradients (DDPG) (WIP)&lt;/li&gt;
&lt;li&gt;&lt;a href="PolicyGradient/a3c"&gt;Asynchronous Advantage Actor Critic (A3C)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h3&gt;
&lt;p&gt;Textbooks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://incompleteideas.net/book/RLbook2018.pdf" rel="nofollow"&gt;Reinforcement Learning: An Introduction (2nd Edition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Classes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" rel="nofollow"&gt;David Silver's Reinforcement Learning Course (UCL, 2015)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://rll.berkeley.edu/deeprlcourse/" rel="nofollow"&gt;CS294 - Deep Reinforcement Learning (Berkeley, Fall 2015)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.udacity.com/course/reinforcement-learning--ud600" rel="nofollow"&gt;CS 8803 - Reinforcement Learning (Georgia Tech)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cs.uwaterloo.ca/~ppoupart/teaching/cs885-spring18/" rel="nofollow"&gt;CS885 - Reinforcement Learning (UWaterloo), Spring 2018&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://rail.eecs.berkeley.edu/deeprlcourse/" rel="nofollow"&gt;CS294-112 - Deep Reinforcement Learning (UC Berkeley)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Talks/Tutorials:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://videolectures.net/deeplearning2016_pineau_reinforcement_learning/" rel="nofollow"&gt;Introduction to Reinforcement Learning (Joelle Pineau @ Deep Learning Summer School 2016)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://videolectures.net/deeplearning2016_abbeel_deep_reinforcement/" rel="nofollow"&gt;Deep Reinforcement Learning (Pieter Abbeel @ Deep Learning Summer School 2016)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://techtalks.tv/talks/deep-reinforcement-learning/62360/" rel="nofollow"&gt;Deep Reinforcement Learning ICML 2016 Tutorial (David Silver)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ggqnxyjaKe4" rel="nofollow"&gt;Tutorial: Introduction to Reinforcement Learning with Function Approximation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLjKEIQlKCTZYN3CYBlj8r58SbNorobqcp" rel="nofollow"&gt;John Schulman - Deep Reinforcement Learning (4 Lectures)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf" rel="nofollow"&gt;Deep Reinforcement Learning Slides @ NIPS 2016&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://spinningup.openai.com/en/latest/user/introduction.html" rel="nofollow"&gt;OpenAI Spinning Up&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs" rel="nofollow"&gt;Advanced Deep Learning &amp;amp; Reinforcement Learning (UCL 2018, DeepMind)&lt;/a&gt;
-&lt;a href="https://sites.google.com/view/deep-rl-bootcamp/lectures" rel="nofollow"&gt;Deep RL Bootcamp&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Other Projects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/carpedm20/deep-rl-tensorflow"&gt;carpedm20/deep-rl-tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/matthiasplappert/keras-rl"&gt;matthiasplappert/keras-rl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Selected Papers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.readcube.com/articles/10.1038/nature14236" rel="nofollow"&gt;Human-Level Control through Deep Reinforcement Learning (2015-02)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1509.06461" rel="nofollow"&gt;Deep Reinforcement Learning with Double Q-learning (2015-09)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1509.02971" rel="nofollow"&gt;Continuous control with deep reinforcement learning (2015-09)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1511.05952" rel="nofollow"&gt;Prioritized Experience Replay (2015-11)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1511.06581" rel="nofollow"&gt;Dueling Network Architectures for Deep Reinforcement Learning (2015-11)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1602.01783" rel="nofollow"&gt;Asynchronous Methods for Deep Reinforcement Learning (2016-02)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1603.01121" rel="nofollow"&gt;Deep Reinforcement Learning from Self-Play in Imperfect-Information Games (2016-03)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf" rel="nofollow"&gt;Mastering the game of Go with deep neural networks and tree search&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dennybritz</author><guid isPermaLink="false">https://github.com/dennybritz/reinforcement-learning</guid><pubDate>Thu, 21 Nov 2019 00:16:00 GMT</pubDate></item><item><title>wesm/pydata-book #17 in Jupyter Notebook, This week</title><link>https://github.com/wesm/pydata-book</link><description>&lt;p&gt;&lt;i&gt;Materials and IPython notebooks for "Python for Data Analysis" by Wes McKinney, published by O'Reilly Media&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-python-for-data-analysis-2nd-edition" class="anchor" aria-hidden="true" href="#python-for-data-analysis-2nd-edition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python for Data Analysis, 2nd Edition&lt;/h1&gt;
&lt;p&gt;Materials and IPython notebooks for "Python for Data Analysis" by Wes McKinney,
published by O'Reilly Media&lt;/p&gt;
&lt;p&gt;&lt;a href="http://amzn.to/2vvBijB" rel="nofollow"&gt;Buy the book on Amazon&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://notebooks.azure.com/import/gh/wesm/pydata-book" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2c33d8af3d101ffcd6ea73a8d02290b8d829ac52/68747470733a2f2f6e6f7465626f6f6b732e617a7572652e636f6d2f6c61756e63682e706e67" data-canonical-src="https://notebooks.azure.com/launch.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Follow Wes on Twitter: &lt;a href="https://twitter.com/wesmckinn" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e5ee948ef48fbfa31f868c9dbd301bbd5cf38097/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f7765736d636b696e6e2e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f77" alt="Twitter Follow" data-canonical-src="https://img.shields.io/twitter/follow/wesmckinn.svg?style=social&amp;amp;label=Follow" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-1st-edition-readers" class="anchor" aria-hidden="true" href="#1st-edition-readers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1st Edition Readers&lt;/h1&gt;
&lt;p&gt;If you are reading the &lt;a href="http://amzn.to/2vvBijB" rel="nofollow"&gt;1st Edition&lt;/a&gt; (published in 2012), please find the
reorganized book materials on the &lt;a href="https://github.com/wesm/pydata-book/tree/1st-edition"&gt;&lt;code&gt;1st-edition&lt;/code&gt; branch&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-translations" class="anchor" aria-hidden="true" href="#translations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Translations&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/BrambleXu/pydata-notebook"&gt;Chinese&lt;/a&gt; by Xu Liang&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-ipython-notebooks" class="anchor" aria-hidden="true" href="#ipython-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;IPython Notebooks:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch02.ipynb" rel="nofollow"&gt;Chapter 2: Python Language Basics, IPython, and Jupyter Notebooks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch03.ipynb" rel="nofollow"&gt;Chapter 3: Built-in Data Structures, Functions, and Files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch04.ipynb" rel="nofollow"&gt;Chapter 4: NumPy Basics: Arrays and Vectorized Computation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch05.ipynb" rel="nofollow"&gt;Chapter 5: Getting Started with pandas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch06.ipynb" rel="nofollow"&gt;Chapter 6: Data Loading, Storage, and File Formats&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch07.ipynb" rel="nofollow"&gt;Chapter 7: Data Cleaning and Preparation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch08.ipynb" rel="nofollow"&gt;Chapter 8: Data Wrangling: Join, Combine, and Reshape&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch09.ipynb" rel="nofollow"&gt;Chapter 9: Plotting and Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch10.ipynb" rel="nofollow"&gt;Chapter 10: Data Aggregation and Group Operations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch11.ipynb" rel="nofollow"&gt;Chapter 11: Time Series&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch12.ipynb" rel="nofollow"&gt;Chapter 12: Advanced pandas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch13.ipynb" rel="nofollow"&gt;Chapter 13: Introduction to Modeling Libraries in Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch14.ipynb" rel="nofollow"&gt;Chapter 14: Data Analysis Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/appa.ipynb" rel="nofollow"&gt;Appendix A: Advanced NumPy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-code" class="anchor" aria-hidden="true" href="#code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code&lt;/h3&gt;
&lt;p&gt;The code in this repository, including all code samples in the notebooks listed
above, is released under the &lt;a href="LICENSE-CODE"&gt;MIT license&lt;/a&gt;. Read more at the
&lt;a href="https://opensource.org/licenses/MIT" rel="nofollow"&gt;Open Source Initiative&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>wesm</author><guid isPermaLink="false">https://github.com/wesm/pydata-book</guid><pubDate>Thu, 21 Nov 2019 00:17:00 GMT</pubDate></item><item><title>asdf2014/algorithm #18 in Jupyter Notebook, This week</title><link>https://github.com/asdf2014/algorithm</link><description>&lt;p&gt;&lt;i&gt;Leetcode 组队刷题&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://yuzhouwan.com/" rel="nofollow"&gt;&lt;img align="right" width="30%" height="30%" src="https://user-images.githubusercontent.com/8108788/58363706-18c4d080-7edb-11e9-947a-cf7233c8e2cc.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://yuzhouwan.com/posts/666/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c2921f8f521b893afe36c1cff03afb8b4f7b3e93/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6e7472696275746f72732f61736466323031342f616c676f726974686d" alt="" data-canonical-src="https://img.shields.io/github/contributors/asdf2014/algorithm" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://yuzhouwan.com/posts/666/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/85c803638dc104b566428b15f199c53756071fb8/68747470733a2f2f79757a686f7577616e2e636f6d2f696d616765732f636f6d706c657465642e737667" alt="" data-canonical-src="https://yuzhouwan.com/images/completed.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://yuzhouwan.com/posts/666/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f97df299e0857b09c28fa0b787f231894acce0fe/68747470733a2f2f79757a686f7577616e2e636f6d2f696d616765732f636f76657265642e737667" alt="" data-canonical-src="https://yuzhouwan.com/images/covered.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://yuzhouwan.com/posts/666/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/376f9d08d99c58a42de9659c62b9634a84954e76/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c616e6775616765732f636f756e742f61736466323031342f616c676f726974686d" alt="" data-canonical-src="https://img.shields.io/github/languages/count/asdf2014/algorithm" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://yuzhouwan.com/posts/666/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2f27abc5d701a4fd33bc8f4a384f150f3d7e0675/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c616e6775616765732f746f702f61736466323031342f616c676f726974686d" alt="" data-canonical-src="https://img.shields.io/github/languages/top/asdf2014/algorithm" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/asdf2014/algorithm/alerts/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/21fc0c73757bbef04c11faf2452262a1ac638db4/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f672f61736466323031342f616c676f726974686d2e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138" alt="" data-canonical-src="https://img.shields.io/lgtm/alerts/g/asdf2014/algorithm.svg?logo=lgtm&amp;amp;logoWidth=18" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/asdf2014/algorithm/context:python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/968c5c5e74cff8d332a39cff354f4b673cd2723f/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f61736466323031342f616c676f726974686d2e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138" alt="" data-canonical-src="https://img.shields.io/lgtm/grade/python/g/asdf2014/algorithm.svg?logo=lgtm&amp;amp;logoWidth=18" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://goreportcard.com/report/github.com/asdf2014/algorithm" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6ecec2168d7f25c1b288b212281ec9bf9b21c559/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6769746875622e636f6d2f61736466323031342f616c676f726974686d" alt="" data-canonical-src="https://goreportcard.com/badge/github.com/asdf2014/algorithm" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://yuzhouwan.com/posts/666/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d0f418155e341136dd4ec9c26c95f52a646fa118/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f61736466323031342f616c676f726974686d3f63616368655365636f6e64733d33363030" alt="" data-canonical-src="https://img.shields.io/github/commit-activity/m/asdf2014/algorithm?cacheSeconds=3600" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://yuzhouwan.com/posts/666/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d147e1f9130facf4bf2316229fc722488335e457/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f61736466323031342f616c676f726974686d" alt="" data-canonical-src="https://img.shields.io/github/license/asdf2014/algorithm" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/yuzhouwan/community?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/831e6077d7a3de6acfaaa517a0ca4ea370867103/68747470733a2f2f6261646765732e6769747465722e696d2f79757a686f7577616e2f636f6d6d756e6974792e737667" alt="" data-canonical-src="https://badges.gitter.im/yuzhouwan/community.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://shang.qq.com/wpa/qunwpa?idkey=bfbcf1453371a0810fd6be235ace47147f6fb9d262fb768b497c861f50af0af4" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2e4310a9ba08bec0d8f4184661a8e7e5749f94de/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f515125323047726f75702d353336363735332d626c75652e7376673f7374796c653d736f6369616c266c6f676f3d74656e63656e742d7171" alt="" data-canonical-src="https://img.shields.io/badge/QQ%20Group-5366753-blue.svg?style=social&amp;amp;logo=tencent-qq" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;中文 | &lt;a href="https://github.com/asdf2014/algorithm/blob/master/README-en.md"&gt;English&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-leetcode-组队刷题" class="anchor" aria-hidden="true" href="#leetcode-组队刷题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Leetcode 组队刷题&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-介绍" class="anchor" aria-hidden="true" href="#介绍"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;介绍&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-代码仓库" class="anchor" aria-hidden="true" href="#代码仓库"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;代码仓库&lt;/h3&gt;
&lt;p&gt;　代码仓库的坐标：&lt;strong&gt;&lt;a href="https://github.com/asdf2014/algorithm"&gt;asdf2014 / algorithm&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-报名途径" class="anchor" aria-hidden="true" href="#报名途径"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;报名途径&lt;/h3&gt;
&lt;p&gt;　只需要在《&lt;a href="https://yuzhouwan.com/posts/666/" rel="nofollow"&gt;Algorithm&lt;/a&gt;》文末留言，即可随时参与&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-参与方式" class="anchor" aria-hidden="true" href="#参与方式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;参与方式&lt;/h3&gt;
&lt;p&gt;　每位参与的小伙伴，都会获得代码仓库的 Collaborator 权限，可以自由地提交代码（不限制语种）。在 &lt;code&gt;/Codes/${User}&lt;/code&gt; 目录下，每人都将拥有一个自己的代码库。留下 Github 名称后，将很快会收到邀请函，大家可以在 &lt;a href="https://github.com/asdf2014/algorithm/invitations"&gt;asdf2014 - algorithm - invitations&lt;/a&gt; 链接中认领（当然，也欢迎直接通过提交 MR 参与进来）&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 一键完成您的第一次代码提交&lt;/span&gt;
bash -c &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;curl -L https://raw.githubusercontent.com/asdf2014/algorithm/master/first_commit.sh&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-刷题频率" class="anchor" aria-hidden="true" href="#刷题频率"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;刷题频率&lt;/h3&gt;
&lt;p&gt;　考虑到可能大家的闲暇时间并不多，我们暂定刷题频率为“一周一题”&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-选题策略" class="anchor" aria-hidden="true" href="#选题策略"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;选题策略&lt;/h3&gt;
&lt;p&gt;　分为两个阶段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;前 100 题都是经典中的经典，所以我们第一阶段先将这些题目吃透&lt;/li&gt;
&lt;li&gt;第二阶段，通过程序进行&lt;a href="https://nbviewer.jupyter.org/github/asdf2014/algorithm/blob/master/Leetcode%20Picker/leetcode_picker.ipynb" rel="nofollow"&gt;&lt;strong&gt;随机选定&lt;/strong&gt;&lt;/a&gt;，历史题库可以点击&lt;a href="https://yuzhouwan.com/posts/666/#%E6%A3%80%E7%B4%A2" rel="nofollow"&gt;链接&lt;/a&gt;看到&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-排行榜" class="anchor" aria-hidden="true" href="#排行榜"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;排行榜&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-完成题目最多的小伙伴" class="anchor" aria-hidden="true" href="#完成题目最多的小伙伴"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;完成题目最多的小伙伴&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;User&lt;/th&gt;
&lt;th align="center"&gt;Completed&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/zsdostar"&gt;zsdostar&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;27&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/lxycg"&gt;lxycg&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;23&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/gmywq392"&gt;gmywq392&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;21&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/asdf2014"&gt;asdf2014&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;19&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/mggger"&gt;mggger&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/GinRyan"&gt;GinRyan&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/yore"&gt;yore&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/fengxuanmo"&gt;fengxuanmo&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/gracekoo"&gt;gracekoo&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/BoCai"&gt;BoCai&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-最活跃的小伙伴" class="anchor" aria-hidden="true" href="#最活跃的小伙伴"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;最活跃的小伙伴&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;User&lt;/th&gt;
&lt;th align="center"&gt;Latest Active Date&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/lxycg"&gt;lxycg&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;2019-11-20 14:34:51&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/asdf2014"&gt;asdf2014&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;2019-11-16 16:17:01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/beingStrong"&gt;beingStrong&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;2019-11-15 23:00:50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/BlitheLou"&gt;BlitheLou&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;2019-11-12 22:01:41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/BoCai"&gt;BoCai&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;2019-11-12 18:59:52&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/GinRyan"&gt;GinRyan&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;2019-11-11 04:52:45&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/zsdostar"&gt;zsdostar&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;2019-11-05 16:30:48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/gracekoo"&gt;gracekoo&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;2019-11-03 23:08:06&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/P_fzr"&gt;P_fzr&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;2019-10-23 19:04:39&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/asdf2014/algorithm/tree/master/Codes/gmywq392"&gt;gmywq392&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;2019-10-05 18:13:46&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;排行榜的更新会在提交后自动执行。我们每月做一次汇总，每月最佳可以永久记录在项目中。&lt;/p&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-q--a" class="anchor" aria-hidden="true" href="#q--a"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Q &amp;amp; A&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-初衷" class="anchor" aria-hidden="true" href="#初衷"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;初衷&lt;/h3&gt;
&lt;p&gt;　说实话 这纯属公益项目，只是召集大家一起刷题，一起交流。对我而言，顶多就是锻炼一下我的运营能力。
想过最坏的情况，就是到最后就剩我一个人默默地刷题、往里面提代码 &lt;g-emoji class="g-emoji" alias="sweat_smile" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f605.png"&gt;😅&lt;/g-emoji&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;更多内容，详见《&lt;a href="https://yuzhouwan.com/posts/666/" rel="nofollow"&gt;Algorithm&lt;/a&gt;》&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>asdf2014</author><guid isPermaLink="false">https://github.com/asdf2014/algorithm</guid><pubDate>Thu, 21 Nov 2019 00:18:00 GMT</pubDate></item><item><title>yandexdataschool/nlp_course #19 in Jupyter Notebook, This week</title><link>https://github.com/yandexdataschool/nlp_course</link><description>&lt;p&gt;&lt;i&gt;YSDA course in Natural Language Processing&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-ysda-natural-language-processing-course-" class="anchor" aria-hidden="true" href="#ysda-natural-language-processing-course-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;YSDA Natural Language Processing course &lt;a href="https://mybinder.org/v2/gh/yandexdataschool/nlp_course/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/483bae47a175c24dfbfc57390edd8b6982ac5fb3/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge_logo.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;This is the 2019 version. For previous year' course materials, go to &lt;a href="https://github.com/yandexdataschool/nlp_course/tree/master"&gt;this branch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lecture and seminar materials for each week are in ./week* folders&lt;/li&gt;
&lt;li&gt;YSDA homework deadlines will be listed in Anytask (&lt;a href="https://github.com/yandexdataschool/nlp_course/wiki/Homeworks-and-grading"&gt;read more&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Any technical issues, ideas, bugs in course materials, contribution ideas - add an &lt;a href="https://github.com/yandexdataschool/nlp_course/issues"&gt;issue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Installing libraries and troubleshooting: &lt;a href="https://github.com/yandexdataschool/nlp_course/issues/1"&gt;this thread&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-syllabus" class="anchor" aria-hidden="true" href="#syllabus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Syllabus&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="./week01_embeddings"&gt;&lt;strong&gt;week01&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;Embeddings&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lecture: Word embeddings. Distributional semantics, LSA, Word2Vec, GloVe. Why and when we need them.&lt;/li&gt;
&lt;li&gt;Seminar: Playing with word and sentence embeddings.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="./week02_classification"&gt;&lt;strong&gt;week02&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;Text classification&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lecture: Text classification. Classical approaches for text representation: BOW, TF-IDF. Neural approaches: embeddings, convolutions, RNNs&lt;/li&gt;
&lt;li&gt;Seminar: Salary prediction with convolutional neural networks; explaining network predictions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="./week03_lm"&gt;&lt;strong&gt;week03&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;Language Models&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lecture: Language models: N-gram and neural approaches; visualizing trained models&lt;/li&gt;
&lt;li&gt;Seminar: Generating ArXiv papers with language models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="./week04_seq2seq"&gt;&lt;strong&gt;week04&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;Seq2seq/Attention&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lecture: Seq2seq: encoder-decoder framework. Attention: Bahdanau model. Self-attention, Transformer. Analysis of attention heads in Transformer.&lt;/li&gt;
&lt;li&gt;Seminar: Machine translation of hotel and hostel descriptions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="./week05_em"&gt;&lt;strong&gt;week05&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;Expectation-Maximization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lecture: Expectation-Maximization and Hidden Markov Models&lt;/li&gt;
&lt;li&gt;Seminar: Implementing expectation maximization&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="./week06_mt"&gt;&lt;strong&gt;week06&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;Machine Translation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lecture: Word Alignment Models, Noisy Channel, Machine Translation.&lt;/li&gt;
&lt;li&gt;Seminar: Introduction to word alignment assignment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-contributors--course-staff" class="anchor" aria-hidden="true" href="#contributors--course-staff"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributors &amp;amp; course staff&lt;/h1&gt;
&lt;p&gt;Course materials and teaching performed by&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://lena-voita.github.io" rel="nofollow"&gt;Elena Voita&lt;/a&gt; - course admin, lectures, seminars, homeworks&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kovarsky"&gt;Boris Kovarsky&lt;/a&gt; - lectures, seminars, homeworks&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/drt7"&gt;David Talbot&lt;/a&gt; - lectures, seminars, homeworks&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/esgv"&gt;Sergey Gubanov&lt;/a&gt; - lectures, seminars, homeworks&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/justheuristic"&gt;Just Heuristic&lt;/a&gt; - lectures, seminars, homeworks&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>yandexdataschool</author><guid isPermaLink="false">https://github.com/yandexdataschool/nlp_course</guid><pubDate>Thu, 21 Nov 2019 00:19:00 GMT</pubDate></item><item><title>Azure/MachineLearningNotebooks #20 in Jupyter Notebook, This week</title><link>https://github.com/Azure/MachineLearningNotebooks</link><description>&lt;p&gt;&lt;i&gt;Python notebooks with ML and deep learning examples with Azure Machine Learning | Microsoft&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-azure-machine-learning-service-example-notebooks" class="anchor" aria-hidden="true" href="#azure-machine-learning-service-example-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Azure Machine Learning service example notebooks&lt;/h1&gt;
&lt;p&gt;This repository contains example notebooks demonstrating the &lt;a href="https://azure.microsoft.com/en-us/services/machine-learning-service/" rel="nofollow"&gt;Azure Machine Learning&lt;/a&gt; Python SDK which allows you to build, train, deploy and manage machine learning solutions using Azure.  The AML SDK allows you the choice of using local or cloud compute resources, while managing and maintaining the complete data science workflow from the cloud.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/MicrosoftDocs/azure-docs/master/articles/machine-learning/service/media/concept-azure-machine-learning-architecture/workflow.png"&gt;&lt;img src="https://raw.githubusercontent.com/MicrosoftDocs/azure-docs/master/articles/machine-learning/service/media/concept-azure-machine-learning-architecture/workflow.png" alt="Azure ML Workflow" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-quick-installation" class="anchor" aria-hidden="true" href="#quick-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick installation&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install azureml-sdk&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Read more detailed instructions on &lt;a href="./NBSETUP.md"&gt;how to set up your environment&lt;/a&gt; using Azure Notebook service, your own Jupyter notebook server, or Docker.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-navigate-and-use-the-example-notebooks" class="anchor" aria-hidden="true" href="#how-to-navigate-and-use-the-example-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to navigate and use the example notebooks?&lt;/h2&gt;
&lt;p&gt;If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, you should always run the &lt;a href="./configuration.ipynb"&gt;Configuration&lt;/a&gt; notebook first when setting up a notebook library on a new machine or in a new environment. It configures your notebook library to connect to an Azure Machine Learning workspace, and sets up your workspace and compute to be used by many of the other examples.
This &lt;a href=".index.md"&gt;index&lt;/a&gt; should assist in navigating the Azure Machine Learning notebook samples and encourage efficient retrieval of topics and content.&lt;/p&gt;
&lt;p&gt;If you want to...&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;...try out and explore Azure ML, start with image classification tutorials: &lt;a href="./tutorials/img-classification-part1-training.ipynb"&gt;Part 1 (Training)&lt;/a&gt; and &lt;a href="./tutorials/img-classification-part2-deploy.ipynb"&gt;Part 2 (Deployment)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;...learn about experimentation and tracking run history, first &lt;a href="./how-to-use-azureml/training/train-within-notebook/train-within-notebook.ipynb"&gt;train within Notebook&lt;/a&gt;, then try &lt;a href="./how-to-use-azureml/training/train-on-remote-vm/train-on-remote-vm.ipynb"&gt;training on remote VM&lt;/a&gt; and &lt;a href="./how-to-use-azureml/training/logging-api/logging-api.ipynb"&gt;using logging APIs&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;...train deep learning models at scale, first learn about &lt;a href="./how-to-use-azureml/training/train-on-amlcompute/train-on-amlcompute.ipynb"&gt;Machine Learning Compute&lt;/a&gt;, and then try &lt;a href="./how-to-use-azureml/training-with-deep-learning/train-hyperparameter-tune-deploy-with-pytorch/train-hyperparameter-tune-deploy-with-pytorch.ipynb"&gt;distributed hyperparameter tuning&lt;/a&gt; and &lt;a href="./how-to-use-azureml/training-with-deep-learning/distributed-pytorch-with-horovod/distributed-pytorch-with-horovod.ipynb"&gt;distributed training&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;...deploy models as a realtime scoring service, first learn the basics by &lt;a href="./how-to-use-azureml/training/train-within-notebook/train-within-notebook.ipynb"&gt;training within Notebook and deploying to Azure Container Instance&lt;/a&gt;, then learn how to &lt;a href="./how-to-use-azureml/deployment/register-model-create-image-deploy-service/register-model-create-image-deploy-service.ipynb"&gt;register and manage models, and create Docker images&lt;/a&gt;, and &lt;a href="./how-to-use-azureml/deployment/production-deploy-to-aks/production-deploy-to-aks.ipynb"&gt;production deploy models on Azure Kubernetes Cluster&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;...deploy models as a batch scoring service, first &lt;a href="./how-to-use-azureml/training/train-within-notebook/train-within-notebook.ipynb"&gt;train a model within Notebook&lt;/a&gt;, learn how to &lt;a href="./how-to-use-azureml/deployment/register-model-create-image-deploy-service/register-model-create-image-deploy-service.ipynb"&gt;register and manage models&lt;/a&gt;, then &lt;a href="./how-to-use-azureml/training/train-on-amlcompute/train-on-amlcompute.ipynb"&gt;create Machine Learning Compute for scoring compute&lt;/a&gt;, and &lt;a href="https://aka.ms/pl-batch-scoring" rel="nofollow"&gt;use Machine Learning Pipelines to deploy your model&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;...monitor your deployed models, learn about using &lt;a href="./how-to-use-azureml/deployment/enable-app-insights-in-production-service/enable-app-insights-in-production-service.ipynb"&gt;App Insights&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-tutorials" class="anchor" aria-hidden="true" href="#tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorials&lt;/h2&gt;
&lt;p&gt;The &lt;a href="./tutorials"&gt;Tutorials&lt;/a&gt; folder contains notebooks for the tutorials described in the &lt;a href="https://aka.ms/aml-docs" rel="nofollow"&gt;Azure Machine Learning documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-use-azure-ml" class="anchor" aria-hidden="true" href="#how-to-use-azure-ml"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to use Azure ML&lt;/h2&gt;
&lt;p&gt;The &lt;a href="./how-to-use-azureml"&gt;How to use Azure ML&lt;/a&gt; folder contains specific examples demonstrating the features of the Azure Machine Learning SDK&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="./how-to-use-azureml/training"&gt;Training&lt;/a&gt; - Examples of how to build models using Azure ML's logging and execution capabilities on local and remote compute targets&lt;/li&gt;
&lt;li&gt;&lt;a href="./how-to-use-azureml/training-with-deep-learning"&gt;Training with Deep Learning&lt;/a&gt; - Examples demonstrating how to build deep learning models using estimators and parameter sweeps&lt;/li&gt;
&lt;li&gt;&lt;a href="./how-to-use-azureml/manage-azureml-service"&gt;Manage Azure ML Service&lt;/a&gt; - Examples how to perform tasks, such as authenticate against Azure ML service in different ways.&lt;/li&gt;
&lt;li&gt;&lt;a href="./how-to-use-azureml/automated-machine-learning"&gt;Automated Machine Learning&lt;/a&gt; - Examples using Automated Machine Learning to automatically generate optimal machine learning pipelines and models&lt;/li&gt;
&lt;li&gt;&lt;a href="./how-to-use-azureml/machine-learning-pipelines"&gt;Machine Learning Pipelines&lt;/a&gt; - Examples showing how to create and use reusable pipelines for training and batch scoring&lt;/li&gt;
&lt;li&gt;&lt;a href="./how-to-use-azureml/deployment"&gt;Deployment&lt;/a&gt; - Examples showing how to deploy and manage machine learning models and solutions&lt;/li&gt;
&lt;li&gt;&lt;a href="./how-to-use-azureml/azure-databricks"&gt;Azure Databricks&lt;/a&gt; - Examples showing how to use Azure ML with Azure Databricks&lt;/li&gt;
&lt;li&gt;&lt;a href="./how-to-use-azureml/monitor-models"&gt;Monitor Models&lt;/a&gt; - Examples showing how to enable model monitoring services such as DataDrift&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Quickstarts, end-to-end tutorials, and how-tos on the &lt;a href="https://docs.microsoft.com/en-us/azure/machine-learning/service/" rel="nofollow"&gt;official documentation site for Azure Machine Learning service&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py" rel="nofollow"&gt;Python SDK reference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Azure ML Data Prep SDK &lt;a href="https://aka.ms/data-prep-sdk" rel="nofollow"&gt;overview&lt;/a&gt;, &lt;a href="https://aka.ms/aml-data-prep-apiref" rel="nofollow"&gt;Python SDK reference&lt;/a&gt;, and &lt;a href="https://aka.ms/aml-data-prep-notebooks" rel="nofollow"&gt;tutorials and how-tos&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-community-repository" class="anchor" aria-hidden="true" href="#community-repository"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community Repository&lt;/h2&gt;
&lt;p&gt;Visit this &lt;a href="https://github.com/microsoft/MLOps/tree/master/examples"&gt;community repository&lt;/a&gt; to find useful end-to-end sample notebooks. Also, please follow these &lt;a href="https://github.com/microsoft/MLOps/blob/master/contributing.md"&gt;contribution guidelines&lt;/a&gt; when contributing to this repository.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-projects-using-azure-machine-learning" class="anchor" aria-hidden="true" href="#projects-using-azure-machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Projects using Azure Machine Learning&lt;/h2&gt;
&lt;p&gt;Visit following repos to see projects contributed by Azure ML users:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Azure/AMLSamples"&gt;AMLSamples&lt;/a&gt; Number of end-to-end examples, including face recognition, predictive maintenance, customer churn and sentiment analysis.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/microsoft/nlp"&gt;Learn about Natural Language Processing best practices using Azure Machine Learning service&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Microsoft/AzureML-BERT"&gt;Pre-Train BERT models using Azure Machine Learning service&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/amynic/azureml-sdk-fashion"&gt;Fashion MNIST with Azure ML SDK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/katiehouse3/microsoft-azure-ml-notebooks"&gt;UMass Amherst Student Samples&lt;/a&gt; - A number of end-to-end machine learning notebooks, including machine translation, image classification, and customer churn, created by students in the 696DS course at UMass Amherst.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-datatelemetry" class="anchor" aria-hidden="true" href="#datatelemetry"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data/Telemetry&lt;/h2&gt;
&lt;p&gt;This repository collects usage data and sends it to Mircosoft to help improve our products and services. Read Microsoft's &lt;a href="https://privacy.microsoft.com/en-US/privacystatement" rel="nofollow"&gt;privacy statement to learn more&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To opt out of tracking, please go to the raw markdown or .ipynb files and remove the following line of code:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/README.png)&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This URL will be slightly different depending on the file.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/c46ad7e1ce8c1c4ffaf085f08619fe9c1b16eb50/68747470733a2f2f506978656c53657276657232303139303432333131343233382e617a75726577656273697465732e6e65742f6170692f696d7072657373696f6e732f4d616368696e654c6561726e696e674e6f7465626f6f6b732f524541444d452e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/c46ad7e1ce8c1c4ffaf085f08619fe9c1b16eb50/68747470733a2f2f506978656c53657276657232303139303432333131343233382e617a75726577656273697465732e6e65742f6170692f696d7072657373696f6e732f4d616368696e654c6561726e696e674e6f7465626f6f6b732f524541444d452e706e67" alt="Impressions" data-canonical-src="https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/README.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Azure</author><guid isPermaLink="false">https://github.com/Azure/MachineLearningNotebooks</guid><pubDate>Thu, 21 Nov 2019 00:20:00 GMT</pubDate></item><item><title>NVIDIA/tacotron2 #21 in Jupyter Notebook, This week</title><link>https://github.com/NVIDIA/tacotron2</link><description>&lt;p&gt;&lt;i&gt;Tacotron 2 - PyTorch implementation with faster-than-realtime inference&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tacotron-2-without-wavenet" class="anchor" aria-hidden="true" href="#tacotron-2-without-wavenet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tacotron 2 (without wavenet)&lt;/h1&gt;
&lt;p&gt;PyTorch implementation of &lt;a href="https://arxiv.org/pdf/1712.05884.pdf" rel="nofollow"&gt;Natural TTS Synthesis By Conditioning
Wavenet On Mel Spectrogram Predictions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This implementation includes &lt;strong&gt;distributed&lt;/strong&gt; and &lt;strong&gt;automatic mixed precision&lt;/strong&gt; support
and uses the &lt;a href="https://keithito.com/LJ-Speech-Dataset/" rel="nofollow"&gt;LJSpeech dataset&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Distributed and Automatic Mixed Precision support relies on NVIDIA's &lt;a href="https://github.com/nvidia/apex"&gt;Apex&lt;/a&gt; and &lt;a href="https://github.com/NVIDIA/apex/tree/master/apex/amp"&gt;AMP&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Visit our &lt;a href="https://nv-adlr.github.io/WaveGlow" rel="nofollow"&gt;website&lt;/a&gt; for audio samples using our published &lt;a href="https://drive.google.com/file/d/1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA/view?usp=sharing" rel="nofollow"&gt;Tacotron 2&lt;/a&gt; and
&lt;a href="https://drive.google.com/file/d/1WsibBTsuRg_SF2Z6L6NFRTT-NjEy1oTx/view?usp=sharing" rel="nofollow"&gt;WaveGlow&lt;/a&gt; models.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="tensorboard.png"&gt;&lt;img src="tensorboard.png" alt="Alignment, Predicted Mel Spectrogram, Target Mel Spectrogram" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pre-requisites" class="anchor" aria-hidden="true" href="#pre-requisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-requisites&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;NVIDIA GPU + CUDA cuDNN&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Download and extract the &lt;a href="https://keithito.com/LJ-Speech-Dataset/" rel="nofollow"&gt;LJ Speech dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Clone this repo: &lt;code&gt;git clone https://github.com/NVIDIA/tacotron2.git&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;CD into this repo: &lt;code&gt;cd tacotron2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Initialize submodule: &lt;code&gt;git submodule init; git submodule update&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Update .wav paths: &lt;code&gt;sed -i -- 's,DUMMY,ljs_dataset_folder/wavs,g' filelists/*.txt&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Alternatively, set &lt;code&gt;load_mel_from_disk=True&lt;/code&gt; in &lt;code&gt;hparams.py&lt;/code&gt; and update mel-spectrogram paths&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Install &lt;a href="https://github.com/pytorch/pytorch#installation"&gt;PyTorch 1.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install &lt;a href="https://github.com/nvidia/apex"&gt;Apex&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install python requirements or build docker image
&lt;ul&gt;
&lt;li&gt;Install python requirements: &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-training" class="anchor" aria-hidden="true" href="#training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;python train.py --output_directory=outdir --log_directory=logdir&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;(OPTIONAL) &lt;code&gt;tensorboard --logdir=outdir/logdir&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-training-using-a-pre-trained-model" class="anchor" aria-hidden="true" href="#training-using-a-pre-trained-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training using a pre-trained model&lt;/h2&gt;
&lt;p&gt;Training using a pre-trained model can lead to faster convergence&lt;br&gt;
By default, the dataset dependent text embedding layers are &lt;a href="https://github.com/NVIDIA/tacotron2/blob/master/hparams.py#L22"&gt;ignored&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Download our published &lt;a href="https://drive.google.com/file/d/1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA/view?usp=sharing" rel="nofollow"&gt;Tacotron 2&lt;/a&gt; model&lt;/li&gt;
&lt;li&gt;&lt;code&gt;python train.py --output_directory=outdir --log_directory=logdir -c tacotron2_statedict.pt --warm_start&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-multi-gpu-distributed-and-automatic-mixed-precision-training" class="anchor" aria-hidden="true" href="#multi-gpu-distributed-and-automatic-mixed-precision-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Multi-GPU (distributed) and Automatic Mixed Precision Training&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;python -m multiproc train.py --output_directory=outdir --log_directory=logdir --hparams=distributed_run=True,fp16_run=True&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-inference-demo" class="anchor" aria-hidden="true" href="#inference-demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Inference demo&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Download our published &lt;a href="https://drive.google.com/file/d/1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA/view?usp=sharing" rel="nofollow"&gt;Tacotron 2&lt;/a&gt; model&lt;/li&gt;
&lt;li&gt;Download our published &lt;a href="https://drive.google.com/file/d/1WsibBTsuRg_SF2Z6L6NFRTT-NjEy1oTx/view?usp=sharing" rel="nofollow"&gt;WaveGlow&lt;/a&gt; model&lt;/li&gt;
&lt;li&gt;&lt;code&gt;jupyter notebook --ip=127.0.0.1 --port=31337&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Load inference.ipynb&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;N.b.  When performing Mel-Spectrogram to Audio synthesis, make sure Tacotron 2
and the Mel decoder were trained on the same mel-spectrogram representation.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-related-repos" class="anchor" aria-hidden="true" href="#related-repos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Related repos&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/NVIDIA/WaveGlow"&gt;WaveGlow&lt;/a&gt; Faster than real time Flow-based
Generative Network for Speech Synthesis&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/NVIDIA/nv-wavenet/"&gt;nv-wavenet&lt;/a&gt; Faster than real time
WaveNet.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;This implementation uses code from the following repos: &lt;a href="https://github.com/keithito/tacotron/"&gt;Keith
Ito&lt;/a&gt;, &lt;a href="https://github.com/pseeth/pytorch-stft"&gt;Prem
Seetharaman&lt;/a&gt; as described in our code.&lt;/p&gt;
&lt;p&gt;We are inspired by &lt;a href="https://github.com/r9y9/tacotron_pytorch"&gt;Ryuchi Yamamoto's&lt;/a&gt;
Tacotron PyTorch implementation.&lt;/p&gt;
&lt;p&gt;We are thankful to the Tacotron 2 paper authors, specially Jonathan Shen, Yuxuan
Wang and Zongheng Yang.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>NVIDIA</author><guid isPermaLink="false">https://github.com/NVIDIA/tacotron2</guid><pubDate>Thu, 21 Nov 2019 00:21:00 GMT</pubDate></item><item><title>YunYang1994/TensorFlow2.0-Examples #22 in Jupyter Notebook, This week</title><link>https://github.com/YunYang1994/TensorFlow2.0-Examples</link><description>&lt;p&gt;&lt;i&gt;🙄 difficult algorithm, simple code.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2 align="center"&gt;&lt;a id="user-content-tensorflow20-examples" class="anchor" aria-hidden="true" href="#tensorflow20-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;🎉TensorFlow2.0-Examples🎉!&lt;/code&gt;&lt;/h2&gt;
&lt;p align="center"&gt;"&lt;i&gt;Talk is cheap, show me the code.&lt;/i&gt;" 
  ----- Linus Torvalds&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master"&gt;
    &lt;img src="https://camo.githubusercontent.com/588410b32491be114a084c302282529d4759412a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4272616e63682d6d61737465722d677265656e2e7376673f6c6f6e6743616368653d74727565" alt="Branch" data-canonical-src="https://img.shields.io/badge/Branch-master-green.svg?longCache=true" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/stargazers"&gt;
    &lt;img src="https://camo.githubusercontent.com/9a6823f33eb16c4b8050789afcd2e248d043f8e7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59756e59616e67313939342f54656e736f72466c6f77322e302d4578616d706c65732e7376673f6c6162656c3d5374617273267374796c653d736f6369616c" alt="Stars" data-canonical-src="https://img.shields.io/github/stars/YunYang1994/TensorFlow2.0-Examples.svg?label=Stars&amp;amp;style=social" style="max-width:100%;"&gt;
  &lt;/a&gt;
    &lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/network/members"&gt;
    &lt;img src="https://camo.githubusercontent.com/0abf80c6579aab48b8fa89e521d75254b1ac1c58/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f59756e59616e67313939342f54656e736f72466c6f77322e302d4578616d706c65732e7376673f6c6162656c3d466f726b73267374796c653d736f6369616c" alt="Forks" data-canonical-src="https://img.shields.io/github/forks/YunYang1994/TensorFlow2.0-Examples.svg?label=Forks&amp;amp;style=social" style="max-width:100%;"&gt;
  &lt;/a&gt;
  
   &lt;a href="https://github.com/sindresorhus/awesome"&gt;
   &lt;img src="https://camo.githubusercontent.com/13c4e50d88df7178ae1882a203ed57b641674f94/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667" alt="Awesome" data-canonical-src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" style="max-width:100%;"&gt;
  &lt;/a&gt;
  
   &lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/blob/master/LICENSE"&gt;
   &lt;img src="https://camo.githubusercontent.com/72b8fa08522b87c996b58d36be5132a346d434c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6173686170652f6170697374617475732e7376673f6d61784167653d32353932303030" alt="Awesome" data-canonical-src="https://img.shields.io/github/license/mashape/apistatus.svg?maxAge=2592000" style="max-width:100%;"&gt;
&lt;/a&gt;&lt;/p&gt;&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/blob/master/LICENSE"&gt;
&lt;/a&gt;&lt;div align="center"&gt;&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/blob/master/LICENSE"&gt;
  &lt;sub&gt;Created by
  &lt;/sub&gt;&lt;/a&gt;&lt;a href="https://github.com/YunYang1994"&gt;YunYang1994&lt;/a&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;p&gt;This tutorial was designed for easily diving into TensorFlow2.0.  it includes both notebooks and source codes with explanation. &lt;strong&gt;It will be continuously updated !&lt;/strong&gt; &lt;g-emoji class="g-emoji" alias="snake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f40d.png"&gt;🐍&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="snake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f40d.png"&gt;🐍&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="snake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f40d.png"&gt;🐍&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="snake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f40d.png"&gt;🐍&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="snake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f40d.png"&gt;🐍&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="snake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f40d.png"&gt;🐍&lt;/g-emoji&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-1---introduction" class="anchor" aria-hidden="true" href="#1---introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1 - Introduction&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hello World&lt;/strong&gt; (&lt;a href="https://nbviewer.jupyter.org/github/YunYang1994/tensorflow2.0-examples/blob/master/1-Introduction/helloworld.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;) (&lt;a href="1-Introduction/helloworld.py"&gt;code&lt;/a&gt;). Very simple example to learn how to print "hello world" using TensorFlow.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Variable&lt;/strong&gt; (&lt;a href="https://nbviewer.jupyter.org/github/YunYang1994/tensorflow2.0-examples/blob/master/1-Introduction/variable.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;) (&lt;a href="1-Introduction/variable.py"&gt;code&lt;/a&gt;). Learn to use variable in tensorflow.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Basical operation&lt;/strong&gt; (&lt;a href="https://nbviewer.jupyter.org/github/YunYang1994/tensorflow2.0-examples/blob/master/1-Introduction/basic_operations.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;) (&lt;a href="1-Introduction/basic_operations.py"&gt;code&lt;/a&gt;). A simple example that covers TensorFlow basic operations.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Activation&lt;/strong&gt; (&lt;a href="https://nbviewer.jupyter.org/github/YunYang1994/tensorflow2.0-examples/blob/master/1-Introduction/activation.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;) (&lt;a href="1-Introduction/activation.py"&gt;code&lt;/a&gt;). Start to know some activation functions in tensorflow.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GradientTape&lt;/strong&gt; (&lt;a href="https://nbviewer.jupyter.org/github/YunYang1994/tensorflow2.0-examples/blob/master/1-Introduction/GradientTape.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;) (&lt;a href="1-Introduction/GradientTape.py"&gt;code&lt;/a&gt;). Introduce a key technique for automatic differentiation&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-2---basical-models" class="anchor" aria-hidden="true" href="#2---basical-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2 - Basical Models&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Linear Regression&lt;/strong&gt; (&lt;a href="https://nbviewer.jupyter.org/github/YunYang1994/tensorflow2.0-examples/blob/master/2-Basical_Models/Linear_Regression.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;) (&lt;a href="2-Basical_Models/Linear_Regression.py"&gt;code&lt;/a&gt;). Implement a Linear Regression with TensorFlow.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Logistic Regression&lt;/strong&gt; (&lt;a href="https://nbviewer.jupyter.org/github/YunYang1994/tensorflow2.0-examples/blob/master/2-Basical_Models/Logistic_Regression.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;) (&lt;a href="2-Basical_Models/Logistic_Regression.py"&gt;code&lt;/a&gt;). Implement a Logistic Regression with TensorFlow.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multilayer Perceptron Layer&lt;/strong&gt; (&lt;a href="https://nbviewer.jupyter.org/github/YunYang1994/tensorflow2.0-examples/blob/master/2-Basical_Models/Multilayer_Perceptron.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;) (&lt;a href="2-Basical_Models/Multilayer_Perceptron.py"&gt;code&lt;/a&gt;). Implement Multi-Layer Perceptron Model with TensorFlow.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CNN&lt;/strong&gt; (&lt;a href="https://tensorflow.google.cn/tutorials/quickstart/advanced" rel="nofollow"&gt;notebook&lt;/a&gt;) (&lt;a href="2-Basical_Models/CNN.py"&gt;code&lt;/a&gt;). Implement CNN Model with TensorFlow.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-3---neural-network-architecture" class="anchor" aria-hidden="true" href="#3---neural-network-architecture"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3 - Neural Network Architecture&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;VGG16&lt;/strong&gt; (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/3-Neural_Network_Architecture"&gt;notebook&lt;/a&gt;) (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/3-Neural_Network_Architecture/vgg16.py"&gt;code&lt;/a&gt;)(&lt;a href="https://arxiv.org/pdf/1409.1556.pdf" rel="nofollow"&gt;paper&lt;/a&gt;). VGG16: Very Deep Convolutional Networks for Large-Scale Image Recognition.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Resnet&lt;/strong&gt; (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/3-Neural_Network_Architecture"&gt;notebook&lt;/a&gt;) (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/3-Neural_Network_Architecture/resnet.py"&gt;code&lt;/a&gt;)(&lt;a href="https://arxiv.org/pdf/1512.03385.pdf" rel="nofollow"&gt;paper&lt;/a&gt;). Resnet: Deep Residual Learning for Image Recognition. &lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AutoEncoder&lt;/strong&gt; (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/3-Neural_Network_Architecture"&gt;notebook&lt;/a&gt;) (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/3-Neural_Network_Architecture/autoencoder.py"&gt;code&lt;/a&gt;)(&lt;a href="http://www.cs.toronto.edu/~hinton/science.pdf" rel="nofollow"&gt;paper&lt;/a&gt;). AutoEncoder: Reducing the Dimensionality of Data with Neural Networks.&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/30433053/68206851-b08d2580-0008-11ea-8b51-061e0cbead62.gif"&gt;&lt;img width="65%" src="https://user-images.githubusercontent.com/30433053/68206851-b08d2580-0008-11ea-8b51-061e0cbead62.gif" style="max-width:100%;"&gt;&lt;/a&gt;
    
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FPN&lt;/strong&gt; (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/3-Neural_Network_Architecture"&gt;notebook&lt;/a&gt;) (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/3-Neural_Network_Architecture/fpn.py"&gt;code&lt;/a&gt;)(&lt;a href="https://arxiv.org/abs/1612.03144" rel="nofollow"&gt;paper&lt;/a&gt;). FPN: Feature Pyramid Networks for Object Detection.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-4---object-detection" class="anchor" aria-hidden="true" href="#4---object-detection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4 - Object Detection&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;RPN&lt;/strong&gt; (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/RPN"&gt;notebook&lt;/a&gt;) (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/RPN/rpn.py"&gt;code&lt;/a&gt;)(&lt;a href="https://arxiv.org/pdf/1703.06283.pdf" rel="nofollow"&gt;paper&lt;/a&gt;). RPN:  a Region Proposal Network &lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/30433053/67913231-4e2ac400-fbc7-11e9-9995-94ed6f7181d4.png"&gt;&lt;img width="70%" src="https://user-images.githubusercontent.com/30433053/67913231-4e2ac400-fbc7-11e9-9995-94ed6f7181d4.png" style="max-width:100%;"&gt;&lt;/a&gt;
    
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MTCNN&lt;/strong&gt; (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/MTCNN"&gt;notebook&lt;/a&gt;) (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/MTCNN/mtcnn.py"&gt;code&lt;/a&gt;)(&lt;a href="https://arxiv.org/abs/1604.02878" rel="nofollow"&gt;paper&lt;/a&gt;). MTCNN: Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks. &lt;em&gt;(Face detection and Alignment)&lt;/em&gt; &lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/30433053/68547531-7e6f2f80-041d-11ea-8cfb-0c5a22af0921.jpg"&gt;&lt;img width="40%" src="https://user-images.githubusercontent.com/30433053/68547531-7e6f2f80-041d-11ea-8cfb-0c5a22af0921.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
    
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;YOLOv3&lt;/strong&gt; (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/YOLOV3"&gt;notebook&lt;/a&gt;) (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/YOLOV3/core/yolov3.py"&gt;code&lt;/a&gt;)(&lt;a href="https://arxiv.org/pdf/1804.02767.pdf" rel="nofollow"&gt;paper&lt;/a&gt;). YOLOv3: An Incremental Improvement.&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/30433053/67914531-656bb080-fbcb-11e9-9775-302a25faf747.png"&gt;&lt;img width="65%" src="https://user-images.githubusercontent.com/30433053/67914531-656bb080-fbcb-11e9-9775-302a25faf747.png" style="max-width:100%;"&gt;&lt;/a&gt;
    
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SSD&lt;/strong&gt; (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/SSD"&gt;notebook&lt;/a&gt;) (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/SSD/ssd.py"&gt;code&lt;/a&gt;)(&lt;a href="http://arxiv.org/abs/1512.02325" rel="nofollow"&gt;paper&lt;/a&gt;). SSD: Single Shot MultiBox Detector.&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt; 【TO DO】&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/30433053/68290134-5f416c80-00c2-11ea-8cbc-d6010ced4efd.png"&gt;&lt;img width="56%" src="https://user-images.githubusercontent.com/30433053/68290134-5f416c80-00c2-11ea-8cbc-d6010ced4efd.png" style="max-width:100%;"&gt;&lt;/a&gt;
    
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Faster R-CNN&lt;/strong&gt; (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/Faster-RCNN"&gt;notebook&lt;/a&gt;) (&lt;a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/Faster-RCNN/frcnn.py"&gt;code&lt;/a&gt;)(&lt;a href="http://arxiv.org/abs/1506.01497" rel="nofollow"&gt;paper&lt;/a&gt;). Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks.&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt; 【TO DO】&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/30433053/68546623-54187480-0413-11ea-9396-0a698c5a2580.png"&gt;&lt;img width="65%" src="https://user-images.githubusercontent.com/30433053/68546623-54187480-0413-11ea-9396-0a698c5a2580.png" style="max-width:100%;"&gt;&lt;/a&gt;
    
&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-5---image-segmentation" class="anchor" aria-hidden="true" href="#5---image-segmentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;5 - Image Segmentation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FCN&lt;/strong&gt; (&lt;a href="5-Image_Segmentation/FCN"&gt;notebook&lt;/a&gt;) (&lt;a href="5-Image_Segmentation/FCN/fcn8s.py"&gt;code&lt;/a&gt;)(&lt;a href="https://arxiv.org/abs/1411.4038" rel="nofollow"&gt;paper&lt;/a&gt;). FCN: Fully Convolutional Networks for Semantic Segmentation. &lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/30433053/67917411-e62eaa80-fbd3-11e9-9fe1-95550cf559d7.png"&gt;&lt;img width="60%" src="https://user-images.githubusercontent.com/30433053/67917411-e62eaa80-fbd3-11e9-9fe1-95550cf559d7.png" style="max-width:100%;"&gt;&lt;/a&gt;
    
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Unet&lt;/strong&gt; (&lt;a href="5-Image_Segmentation/Unet"&gt;notebook&lt;/a&gt;) (&lt;a href="5-Image_Segmentation/Unet/train.py"&gt;code&lt;/a&gt;)(&lt;a href="https://arxiv.org/abs/1505.04597" rel="nofollow"&gt;paper&lt;/a&gt;). U-Net: Convolutional Networks for Biomedical Image Segmentation. &lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/30433053/67922238-2ba7a380-fbe5-11e9-96a0-55c6827bd024.png"&gt;&lt;img width="50%" src="https://user-images.githubusercontent.com/30433053/67922238-2ba7a380-fbe5-11e9-96a0-55c6827bd024.png" style="max-width:100%;"&gt;&lt;/a&gt;
    
&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-6---generative-adversarial-networks" class="anchor" aria-hidden="true" href="#6---generative-adversarial-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;6 - Generative Adversarial Networks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DCGAN&lt;/strong&gt; (&lt;a href="https://nbviewer.jupyter.org/github/YunYang1994/tensorflow2.0-examples/blob/master/6-Generative_Adversarial_Networks/dcgan.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;) (&lt;a href="6-Generative_Adversarial_Networks/dcgan.py"&gt;code&lt;/a&gt;)(&lt;a href="https://arxiv.org/pdf/1511.06434.pdf" rel="nofollow"&gt;paper&lt;/a&gt;).  Deep Convolutional Generative Adversarial Network.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pix2Pix&lt;/strong&gt; (&lt;a href="https://nbviewer.jupyter.org/github/YunYang1994/tensorflow2.0-examples/blob/master/6-Generative_Adversarial_Networks/Pix2Pix.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;) (&lt;a href="6-Generative_Adversarial_Networks/Pix2Pix.py"&gt;code&lt;/a&gt;)(&lt;a href="https://arxiv.org/pdf/1611.07004.pdf" rel="nofollow"&gt;paper&lt;/a&gt;).  Image-to-Image Translation with Conditional Adversarial Networks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-7---reinforcement-learning" class="anchor" aria-hidden="true" href="#7---reinforcement-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;7 - Reinforcement Learning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DQN&lt;/strong&gt; (&lt;a href="6-Reinforcement_Learning/YOLOV2.ipynb"&gt;notebook&lt;/a&gt;) (&lt;a href="6-Reinforcement_Learning/YOLOV2.py"&gt;code&lt;/a&gt;). deep Q-network (DQN).&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>YunYang1994</author><guid isPermaLink="false">https://github.com/YunYang1994/TensorFlow2.0-Examples</guid><pubDate>Thu, 21 Nov 2019 00:22:00 GMT</pubDate></item><item><title>NVIDIA-AI-IOT/jetbot #23 in Jupyter Notebook, This week</title><link>https://github.com/NVIDIA-AI-IOT/jetbot</link><description>&lt;p&gt;&lt;i&gt;An educational AI robot based on NVIDIA Jetson Nano.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-jetbot" class="anchor" aria-hidden="true" href="#jetbot"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;JetBot&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Interested in making projects like this with Jetson Nano?  Check out the &lt;a href="https://info.nvidia.com/ai-for-makers-learn-with-jetbot-reg-page.html?nvid=nv-int-84114" rel="nofollow"&gt;webinar&lt;/a&gt; we released on 5/16/2019!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="../..//wiki/images/jetson-jetbot-illustration_1600x1260.png"&gt;&lt;img src="../..//wiki/images/jetson-jetbot-illustration_1600x1260.png" height="256" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;JetBot is an open-source robot based on NVIDIA Jetson Nano that is&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Affordable&lt;/strong&gt; - Less than $150 add-on to Jetson Nano&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Educational&lt;/strong&gt; - Tutorials from basic motion to AI based collision avoidance&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fun!&lt;/strong&gt; - Interactively programmed from your web browser&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Building and using JetBot gives the hands on experience needed to create entirely new AI projects.&lt;/p&gt;
&lt;p&gt;To get started, read the &lt;a href="https://github.com/NVIDIA-AI-IOT/jetbot/wiki"&gt;JetBot Wiki&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/igrigorik/ga-beacon"&gt;&lt;img src="https://camo.githubusercontent.com/48228270fe5e7df2a81064448b94b395450e67a2/68747470733a2f2f67612d626561636f6e2e61707073706f742e636f6d2f55412d3133353931393531302d312f6a6574626f742f524541444d453f706978656c" alt="Analytics" data-canonical-src="https://ga-beacon.appspot.com/UA-135919510-1/jetbot/README?pixel" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>NVIDIA-AI-IOT</author><guid isPermaLink="false">https://github.com/NVIDIA-AI-IOT/jetbot</guid><pubDate>Thu, 21 Nov 2019 00:23:00 GMT</pubDate></item><item><title>ljpzzz/machinelearning #24 in Jupyter Notebook, This week</title><link>https://github.com/ljpzzz/machinelearning</link><description>&lt;p&gt;&lt;i&gt;My blogs and code for machine learning. http://cnblogs.com/pinard&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="readme.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-刘建平pinard的博客配套代码" class="anchor" aria-hidden="true" href="#刘建平pinard的博客配套代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;刘建平Pinard的博客配套代码&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://www.cnblogs.com/pinard" rel="nofollow"&gt;http://www.cnblogs.com/pinard&lt;/a&gt; 刘建平Pinard&lt;/p&gt;
&lt;p&gt;之前不少朋友反应我博客中的代码都是连续的片段，不好学习，因此这里把文章和代码做一个整理。
代码有部分来源于网络，已加上相关方版权信息。部分为自己原创，已加上我的版权信息。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-目录" class="anchor" aria-hidden="true" href="#目录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="#2"&gt;机器学习基础与回归算法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="#3"&gt;机器学习分类算法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="#4"&gt;机器学习聚类算法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="#5"&gt;机器学习降维算法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="#6"&gt;机器学习集成学习算法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="#7"&gt;数学统计学&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="#8"&gt;机器学习关联算法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="#9"&gt;机器学习推荐算法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="#10"&gt;深度学习算法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="#11"&gt;自然语言处理算法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="#1"&gt;强化学习算法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="#12"&gt;特征工程与算法落地&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-注意" class="anchor" aria-hidden="true" href="#注意"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;注意&lt;/h2&gt;
&lt;p&gt;2016-2017年写的博客使用的python版本是2.7， 2018年因为TensorFlow对Python3的一些要求，所以写博客使用的Python版本是3.6。少部分2016，2017年的博客代码无法找到，重新用Python3.6跑过上传，因此可能会出现和博客中代码稍有不一致的地方，主要涉及到print的语法和range的用法，若遇到问题，稍微修改即可跑通。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-赞助我" class="anchor" aria-hidden="true" href="#赞助我"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#13"&gt;赞助我&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="user-content-1"&gt;&lt;a id="user-content-强化学习文章与代码" class="anchor" aria-hidden="true" href="#强化学习文章与代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;强化学习文章与代码：:&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;文章&lt;/th&gt;
&lt;th&gt;代码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9385570.html" rel="nofollow"&gt;强化学习（一）模型基础&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/introduction.py"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9426283.html" rel="nofollow"&gt;强化学习（二）马尔科夫决策过程(MDP)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9463815.html" rel="nofollow"&gt;强化学习（三）用动态规划（DP）求解&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9492980.html" rel="nofollow"&gt;强化学习（四）用蒙特卡罗法（MC）求解&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9529828.html" rel="nofollow"&gt;强化学习（五）用时序差分法（TD）求解&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9614290.html" rel="nofollow"&gt;强化学习（六）时序差分在线控制算法SARSA&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/sarsa_windy_world.py"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9669263.html" rel="nofollow"&gt;强化学习（七）时序差分离线控制算法Q-Learning&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/q_learning_windy_world.py"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9714655.html" rel="nofollow"&gt;强化学习（八）价值函数的近似表示与Deep Q-Learning&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/dqn.py"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9756075.html" rel="nofollow"&gt;强化学习（九）Deep Q-Learning进阶之Nature DQN&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/nature_dqn.py"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9778063.html" rel="nofollow"&gt;强化学习（十）Double DQN (DDQN)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/ddqn.py"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9797695.html" rel="nofollow"&gt;强化学习(十一) Prioritized Replay DQN&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/ddqn_prioritised_replay.py"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9923859.html" rel="nofollow"&gt;强化学习(十二) Dueling DQN&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/duel_dqn.py"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/10137696.html" rel="nofollow"&gt;强化学习(十三) 策略梯度(Policy Gradient)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/policy_gradient.py"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/10272023.html" rel="nofollow"&gt;强化学习(十四) Actor-Critic&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/actor_critic.py"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/10334127.html" rel="nofollow"&gt;强化学习(十五) A3C&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/a3c.py"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/10345762.html" rel="nofollow"&gt;强化学习(十六) 深度确定性策略梯度(DDPG)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/ddpg.py"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/10384424.html" rel="nofollow"&gt;强化学习(十七) 基于模型的强化学习与Dyna算法框架&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/10470571.html" rel="nofollow"&gt;强化学习(十八) 基于模拟的搜索与蒙特卡罗树搜索(MCTS)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/10609228.html" rel="nofollow"&gt;强化学习(十九) AlphaGo Zero强化学习原理&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="user-content-2"&gt;&lt;a id="user-content-机器学习基础与回归算法文章与代码" class="anchor" aria-hidden="true" href="#机器学习基础与回归算法文章与代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习基础与回归算法文章与代码：&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;文章&lt;/th&gt;
&lt;th&gt;代码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/5970503.html" rel="nofollow"&gt;梯度下降（Gradient Descent）小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/5976811.html" rel="nofollow"&gt;最小二乘法小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/5992719.html" rel="nofollow"&gt;交叉验证(Cross Validation)原理小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/5993450.html" rel="nofollow"&gt;精确率与召回率，RoC曲线与PR曲线&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6004041.html" rel="nofollow"&gt;线性回归原理小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6007200.html" rel="nofollow"&gt;机器学习研究与开发平台的选择&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6013484.html" rel="nofollow"&gt;scikit-learn 和pandas 基于windows单机机器学习环境的搭建&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6016029.html" rel="nofollow"&gt;用scikit-learn和pandas学习线性回归&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/linear-regression.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6018889.html" rel="nofollow"&gt;Lasso回归算法： 坐标轴下降法与最小角回归法小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6023000.html" rel="nofollow"&gt;用scikit-learn和pandas学习Ridge回归&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/ridge_regression_1.ipynb"&gt;代码1&lt;/a&gt; &lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/ridge_regression.ipynb"&gt;代码2&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6026343.html" rel="nofollow"&gt;scikit-learn 线性回归算法库小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9314198.html" rel="nofollow"&gt;异常点检测算法小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="user-content-3"&gt;&lt;a id="user-content-机器学习分类算法文章与代码" class="anchor" aria-hidden="true" href="#机器学习分类算法文章与代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习分类算法文章与代码：&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;文章&lt;/th&gt;
&lt;th&gt;代码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6029432.html" rel="nofollow"&gt;逻辑回归原理小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6035872.html" rel="nofollow"&gt;scikit-learn 逻辑回归类库使用小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6042320.html" rel="nofollow"&gt;感知机原理小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6050306.html" rel="nofollow"&gt;决策树算法原理(上)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6053344.html" rel="nofollow"&gt;决策树算法原理(下)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6056319.html" rel="nofollow"&gt;scikit-learn决策树算法类库使用小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/decision_tree_classifier.ipynb"&gt;代码1&lt;/a&gt; &lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/decision_tree_classifier_1.ipynb"&gt;代码2&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6061661.html" rel="nofollow"&gt;K近邻法(KNN)原理小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6065607.html" rel="nofollow"&gt;scikit-learn K近邻法类库使用小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/knn_classifier.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6069267.html" rel="nofollow"&gt;朴素贝叶斯算法原理小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6074222.html" rel="nofollow"&gt;scikit-learn 朴素贝叶斯类库使用小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/native_bayes.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6093948.html" rel="nofollow"&gt;最大熵模型原理小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6097604.html" rel="nofollow"&gt;支持向量机原理(一) 线性支持向量机&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6100722.html" rel="nofollow"&gt;支持向量机原理(二) 线性支持向量机的软间隔最大化模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6103615.html" rel="nofollow"&gt;支持向量机原理(三)线性不可分支持向量机与核函数&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6111471.html" rel="nofollow"&gt;支持向量机原理(四)SMO算法原理&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6113120.html" rel="nofollow"&gt;支持向量机原理(五)线性支持回归&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6117515.html" rel="nofollow"&gt;scikit-learn 支持向量机算法库使用小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6126077.html" rel="nofollow"&gt;支持向量机高斯核调参小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/svm_classifier.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="user-content-7"&gt;&lt;a id="user-content-数学统计学文章与代码" class="anchor" aria-hidden="true" href="#数学统计学文章与代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数学统计学文章与代码：&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;文章&lt;/th&gt;
&lt;th&gt;代码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6047802.html" rel="nofollow"&gt;机器学习算法的随机数据生成&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/mathematics/random_data_generation.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6625739.html" rel="nofollow"&gt;MCMC(一)蒙特卡罗方法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6632399.html" rel="nofollow"&gt;MCMC(二)马尔科夫链&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/mathematics/mcmc_2.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6638955.html" rel="nofollow"&gt;MCMC(三)MCMC采样和M-H采样&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/mathematics/mcmc_3_4.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6645766.html" rel="nofollow"&gt;MCMC(四)Gibbs采样&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/mathematics/mcmc_3_4.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/10750718.html" rel="nofollow"&gt;机器学习中的矩阵向量求导(一) 求导定义与求导布局&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/10773942.html" rel="nofollow"&gt;机器学习中的矩阵向量求导(二) 矩阵向量求导之定义法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/10791506.html" rel="nofollow"&gt;机器学习中的矩阵向量求导(三) 矩阵向量求导之微分法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/10825264.html" rel="nofollow"&gt;机器学习中的矩阵向量求导(四) 矩阵向量求导链式法则&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/10930902.html" rel="nofollow"&gt;机器学习中的矩阵向量求导(五) 矩阵对矩阵的求导&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="user-content-6"&gt;&lt;a id="user-content-机器学习集成学习文章与代码" class="anchor" aria-hidden="true" href="#机器学习集成学习文章与代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习集成学习文章与代码：&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;文章&lt;/th&gt;
&lt;th&gt;代码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6131423.html" rel="nofollow"&gt;集成学习原理小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6133937.html" rel="nofollow"&gt;集成学习之Adaboost算法原理小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6136914.html" rel="nofollow"&gt;scikit-learn Adaboost类库使用小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/ensemble-learning/adaboost-classifier.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6140514.html" rel="nofollow"&gt;梯度提升树(GBDT)原理小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6143927.html" rel="nofollow"&gt;scikit-learn 梯度提升树(GBDT)调参小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/ensemble-learning/gbdt_classifier.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6156009.html" rel="nofollow"&gt;Bagging与随机森林算法原理小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6160412.html" rel="nofollow"&gt;scikit-learn随机森林调参小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/ensemble-learning/random_forest_classifier.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/10979808.html" rel="nofollow"&gt;XGBoost算法原理小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/11114748.html" rel="nofollow"&gt;XGBoost类库使用小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/ensemble-learning/xgboost-example.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="user-content-4"&gt;&lt;a id="user-content-机器学习聚类算法文章与代码" class="anchor" aria-hidden="true" href="#机器学习聚类算法文章与代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习聚类算法文章与代码：&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;文章&lt;/th&gt;
&lt;th&gt;代码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6164214.html" rel="nofollow"&gt;K-Means聚类算法原理&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6169370.html" rel="nofollow"&gt;用scikit-learn学习K-Means聚类&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/kmeans_cluster.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6179132.html" rel="nofollow"&gt;BIRCH聚类算法原理&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6200579.html" rel="nofollow"&gt;用scikit-learn学习BIRCH聚类&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/birch_cluster.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6208966.html" rel="nofollow"&gt;DBSCAN密度聚类算法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6217852.html" rel="nofollow"&gt;用scikit-learn学习DBSCAN聚类&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/dbscan_cluster.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6221564.html" rel="nofollow"&gt;谱聚类（spectral clustering）原理总结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6235920.html" rel="nofollow"&gt;用scikit-learn学习谱聚类&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/spectral_cluster.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="user-content-5"&gt;&lt;a id="user-content-机器学习降维算法文章与代码" class="anchor" aria-hidden="true" href="#机器学习降维算法文章与代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习降维算法文章与代码：&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;文章&lt;/th&gt;
&lt;th&gt;代码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6239403.html" rel="nofollow"&gt;主成分分析（PCA）原理总结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6243025.html" rel="nofollow"&gt;用scikit-learn学习主成分分析(PCA)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/pca.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6244265.html" rel="nofollow"&gt;线性判别分析LDA原理总结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6249328.html" rel="nofollow"&gt;用scikit-learn进行LDA降维&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/lda.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6251584.html" rel="nofollow"&gt;奇异值分解(SVD)原理与在降维中的应用&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6266408.html" rel="nofollow"&gt;局部线性嵌入(LLE)原理总结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6273377.html" rel="nofollow"&gt;用scikit-learn研究局部线性嵌入(LLE)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/lle.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="user-content-8"&gt;&lt;a id="user-content-机器学习关联算法文章与代码" class="anchor" aria-hidden="true" href="#机器学习关联算法文章与代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习关联算法文章与代码：&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;文章&lt;/th&gt;
&lt;th&gt;代码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6288716.html" rel="nofollow"&gt;典型关联分析(CCA)原理总结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6293298.html" rel="nofollow"&gt;Apriori算法原理总结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6307064.html" rel="nofollow"&gt;FP Tree算法原理总结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6323182.html" rel="nofollow"&gt;PrefixSpan算法原理总结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6340162.html" rel="nofollow"&gt;用Spark学习FP Tree算法和PrefixSpan算法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/fp_tree_prefixspan.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6039099.html" rel="nofollow"&gt;日志和告警数据挖掘经验谈&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="user-content-9"&gt;&lt;a id="user-content-机器学习推荐算法文章与代码" class="anchor" aria-hidden="true" href="#机器学习推荐算法文章与代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习推荐算法文章与代码：&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;文章&lt;/th&gt;
&lt;th&gt;代码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6349233.html" rel="nofollow"&gt;协同过滤推荐算法总结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6351319.html" rel="nofollow"&gt;矩阵分解在协同过滤推荐算法中的应用&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6362647.html" rel="nofollow"&gt;SimRank协同过滤推荐算法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6364932.html" rel="nofollow"&gt;用Spark学习矩阵分解推荐算法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/matrix_factorization.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6370127.html" rel="nofollow"&gt;分解机(Factorization Machines)推荐算法原理&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9128682.html" rel="nofollow"&gt;贝叶斯个性化排序(BPR)算法小结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9163481.html" rel="nofollow"&gt;用tensorflow学习贝叶斯个性化排序(BPR)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/bpr.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="user-content-10"&gt;&lt;a id="user-content-深度学习算法文章与代码" class="anchor" aria-hidden="true" href="#深度学习算法文章与代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;深度学习算法文章与代码：&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;文章&lt;/th&gt;
&lt;th&gt;代码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6418668.html" rel="nofollow"&gt;深度神经网络（DNN）模型与前向传播算法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6422831.html" rel="nofollow"&gt;深度神经网络（DNN）反向传播算法(BP)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6437495.html" rel="nofollow"&gt;深度神经网络（DNN）损失函数和激活函数的选择&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6472666.html" rel="nofollow"&gt;深度神经网络（DNN）的正则化&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6483207.html" rel="nofollow"&gt;卷积神经网络(CNN)模型结构&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6489633.html" rel="nofollow"&gt;卷积神经网络(CNN)前向传播算法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6494810.html" rel="nofollow"&gt;卷积神经网络(CNN)反向传播算法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6509630.html" rel="nofollow"&gt;循环神经网络(RNN)模型与前向反向传播算法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6519110.html" rel="nofollow"&gt;LSTM模型与前向反向传播算法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6530523.html" rel="nofollow"&gt;受限玻尔兹曼机（RBM）原理总结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="user-content-11"&gt;&lt;a id="user-content-自然语言处理文章与代码" class="anchor" aria-hidden="true" href="#自然语言处理文章与代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;自然语言处理文章与代码：&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;文章&lt;/th&gt;
&lt;th&gt;代码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6677078.html" rel="nofollow"&gt;文本挖掘的分词原理&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6688348.html" rel="nofollow"&gt;文本挖掘预处理之向量化与Hash Trick&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/hash_trick.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6693230.html" rel="nofollow"&gt;文本挖掘预处理之TF-IDF&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/tf-idf.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6744056.html" rel="nofollow"&gt;中文文本挖掘预处理流程总结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/chinese_digging.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6756534.html" rel="nofollow"&gt;英文文本挖掘预处理流程总结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/english_digging.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6805861.html" rel="nofollow"&gt;文本主题模型之潜在语义索引(LSI)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6812011.html" rel="nofollow"&gt;文本主题模型之非负矩阵分解(NMF)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/nmf.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6831308.html" rel="nofollow"&gt;文本主题模型之LDA(一) LDA基础&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6867828.html" rel="nofollow"&gt;文本主题模型之LDA(二) LDA求解之Gibbs采样算法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6873703.html" rel="nofollow"&gt;文本主题模型之LDA(三) LDA求解之变分推断EM算法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6908150.html" rel="nofollow"&gt;用scikit-learn学习LDA主题模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/lda.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6912636.html" rel="nofollow"&gt;EM算法原理总结&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6945257.html" rel="nofollow"&gt;隐马尔科夫模型HMM（一）HMM模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6955871.html" rel="nofollow"&gt;隐马尔科夫模型HMM（二）前向后向算法评估观察序列概率&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6972299.html" rel="nofollow"&gt;隐马尔科夫模型HMM（三）鲍姆-韦尔奇算法求解HMM参数&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/6991852.html" rel="nofollow"&gt;隐马尔科夫模型HMM（四）维特比算法解码隐藏状态序列&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/7001397.html" rel="nofollow"&gt;用hmmlearn学习隐马尔科夫模型HMM&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/hmm.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/7048333.html" rel="nofollow"&gt;条件随机场CRF(一)从随机场到线性链条件随机场&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/7055072.html" rel="nofollow"&gt;条件随机场CRF(二) 前向后向算法评估标记序列概率&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/7068574.html" rel="nofollow"&gt;条件随机场CRF(三) 模型学习与维特比算法解码&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/7160330.html" rel="nofollow"&gt;word2vec原理(一) CBOW与Skip-Gram模型基础&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/7243513.html" rel="nofollow"&gt;word2vec原理(二) 基于Hierarchical Softmax的模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/7249903.html" rel="nofollow"&gt;word2vec原理(三) 基于Negative Sampling的模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/7278324.html" rel="nofollow"&gt;用gensim学习word2vec&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/natural-language-processing/word2vec.ipynb"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="user-content-12"&gt;&lt;a id="user-content-特征工程与算法落地文章与代码" class="anchor" aria-hidden="true" href="#特征工程与算法落地文章与代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;特征工程与算法落地文章与代码：&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;文章&lt;/th&gt;
&lt;th&gt;代码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9032759.html" rel="nofollow"&gt;特征工程之特征选择&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9061549.html" rel="nofollow"&gt;特征工程之特征表达&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9093890.html" rel="nofollow"&gt;特征工程之特征预处理&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9220199.html" rel="nofollow"&gt;用PMML实现机器学习模型的跨平台上线&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/model-in-product/sklearn-jpmml"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.cnblogs.com/pinard/p/9251296.html" rel="nofollow"&gt;tensorflow机器学习模型的跨平台上线&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ljpzzz/machinelearning/blob/master/model-in-product/tensorflow-java"&gt;代码&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="user-content-13"&gt;&lt;a id="user-content-赞助我-1" class="anchor" aria-hidden="true" href="#赞助我-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;赞助我&lt;/h3&gt;
&lt;p&gt;你的支持是我写作的动力(1.微信/2.支付宝)：&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./assert/invoice.bmp"&gt;&lt;img src="./assert/invoice.bmp" alt="微信赞助" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./assert/invoice_ali.bmp"&gt;&lt;img src="./assert/invoice_ali.bmp" alt="支付宝赞助" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;License MIT.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ljpzzz</author><guid isPermaLink="false">https://github.com/ljpzzz/machinelearning</guid><pubDate>Thu, 21 Nov 2019 00:24:00 GMT</pubDate></item><item><title>Azure/Azure-Sentinel #25 in Jupyter Notebook, This week</title><link>https://github.com/Azure/Azure-Sentinel</link><description>&lt;p&gt;&lt;i&gt;Cloud-native SIEM for intelligent security analytics for your entire enterprise.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-azure-sentinel" class="anchor" aria-hidden="true" href="#azure-sentinel"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Azure Sentinel&lt;/h1&gt;
&lt;p&gt;Welcome to the Azure Sentinel repository! This repository contains out of the box detections, exploration queries, hunting queries, dashboards and playbooks to help you get ramped up with Azure Sentinel and provide you security content to secure your environment and hunt for threats. You can also submit any &lt;a href="https://github.com/Azure/Azure-Sentinel/issues"&gt;issues&lt;/a&gt; or feature requests as you onboard to Azure Sentinel. For questions and feedback, please contact &lt;a href="AzureSentinel@microsoft.com"&gt;AzureSentinel@microsoft.com&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://help.github.com/en#dotcom"&gt;Getting started with GitHub&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://go.microsoft.com/fwlink/?linkid=2073774&amp;amp;clcid=0x409" rel="nofollow"&gt;Azure Sentinel documentation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://techcommunity.microsoft.com/t5/Azure-Sentinel/bd-p/AzureSentinel" rel="nofollow"&gt;Azure Sentinel Techcommunity&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h1&gt;
&lt;p&gt;This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit &lt;a href="https://cla.microsoft.com" rel="nofollow"&gt;https://cla.microsoft.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When you submit a pull request, a CLA-bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt;
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/" rel="nofollow"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;.
For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/" rel="nofollow"&gt;Code of Conduct FAQ&lt;/a&gt; or
contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Azure</author><guid isPermaLink="false">https://github.com/Azure/Azure-Sentinel</guid><pubDate>Thu, 21 Nov 2019 00:25:00 GMT</pubDate></item></channel></rss>