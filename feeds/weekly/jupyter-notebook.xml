<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Jupyter Notebook, This week</title><link>https://github.com/trending/jupyter-notebook?since=weekly</link><description>The top repositories on GitHub for jupyter-notebook, measured weekly</description><pubDate>Wed, 05 Feb 2020 01:08:32 GMT</pubDate><lastBuildDate>Wed, 05 Feb 2020 01:08:32 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>google-research/google-research #1 in Jupyter Notebook, This week</title><link>https://github.com/google-research/google-research</link><description>&lt;p&gt;&lt;i&gt;Google AI Research&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-google-ai-research" class="anchor" aria-hidden="true" href="#google-ai-research"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Google AI Research&lt;/h1&gt;
&lt;p&gt;This repository contains code released by
&lt;a href="https://ai.google/research" rel="nofollow"&gt;Google AI Research&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Because the repo is large, we recommend you clone the repo without its history.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone git@github.com:google-research/google-research.git --depth=1
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Disclaimer: This is not an official Google product.&lt;/em&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>google-research</author><guid isPermaLink="false">https://github.com/google-research/google-research</guid><pubDate>Wed, 05 Feb 2020 00:01:00 GMT</pubDate></item><item><title>mml-book/mml-book.github.io #2 in Jupyter Notebook, This week</title><link>https://github.com/mml-book/mml-book.github.io</link><description>&lt;p&gt;&lt;i&gt;Companion webpage to the book "Mathematics For Machine Learning"&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-mml-bookgithubio" class="anchor" aria-hidden="true" href="#mml-bookgithubio"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;mml-book.github.io&lt;/h1&gt;
&lt;p&gt;Companion webpage to the book "Mathematics For Machine Learning"&lt;/p&gt;
&lt;p&gt;&lt;a href="https://mml-book.com" rel="nofollow"&gt;https://mml-book.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Copyright 2020 by Marc Peter Deisenroth, A Aldo Faisal, and Cheng Soon Ong. To be published by Cambridge University Press.&lt;/p&gt;
&lt;p&gt;We are in the process of writing a book on Mathematics for Machine Learning that motivates people to learn mathematical concepts. The book is not intended to cover advanced machine learning techniques because there are already plenty of books doing this. Instead, we aim to provide the necessary mathematical skills to read those other books.&lt;/p&gt;
&lt;p&gt;We split the book into two parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mathematical foundations&lt;/li&gt;
&lt;li&gt;Example machine learning algorithms that use the mathematical foundations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We aim to keep this book reasonably short, so we cannot cover everything. We will also provide exercises for part 1 and jupyter notebooks for part 2 of the book.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>mml-book</author><guid isPermaLink="false">https://github.com/mml-book/mml-book.github.io</guid><pubDate>Wed, 05 Feb 2020 00:02:00 GMT</pubDate></item><item><title>CoreyMSchafer/code_snippets #3 in Jupyter Notebook, This week</title><link>https://github.com/CoreyMSchafer/code_snippets</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-code_snippets" class="anchor" aria-hidden="true" href="#code_snippets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;code_snippets&lt;/h1&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>CoreyMSchafer</author><guid isPermaLink="false">https://github.com/CoreyMSchafer/code_snippets</guid><pubDate>Wed, 05 Feb 2020 00:03:00 GMT</pubDate></item><item><title>jakevdp/PythonDataScienceHandbook #4 in Jupyter Notebook, This week</title><link>https://github.com/jakevdp/PythonDataScienceHandbook</link><description>&lt;p&gt;&lt;i&gt;Python Data Science Handbook: full text in Jupyter Notebooks&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-python-data-science-handbook" class="anchor" aria-hidden="true" href="#python-data-science-handbook"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python Data Science Handbook&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://mybinder.org/v2/gh/jakevdp/PythonDataScienceHandbook/master?filepath=notebooks%2FIndex.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repository contains the entire &lt;a href="http://shop.oreilly.com/product/0636920034919.do" rel="nofollow"&gt;Python Data Science Handbook&lt;/a&gt;, in the form of (free!) Jupyter notebooks.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="notebooks/figures/PDSH-cover.png"&gt;&lt;img src="notebooks/figures/PDSH-cover.png" alt="cover image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-use-this-book" class="anchor" aria-hidden="true" href="#how-to-use-this-book"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to Use this Book&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Read the book in its entirety online at &lt;a href="https://jakevdp.github.io/PythonDataScienceHandbook/" rel="nofollow"&gt;https://jakevdp.github.io/PythonDataScienceHandbook/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the code using the Jupyter notebooks available in this repository's &lt;a href="notebooks"&gt;notebooks&lt;/a&gt; directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Launch executable versions of these notebooks using &lt;a href="http://colab.research.google.com" rel="nofollow"&gt;Google Colab&lt;/a&gt;: &lt;a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Launch a live notebook server with these notebooks using &lt;a href="https://beta.mybinder.org/" rel="nofollow"&gt;binder&lt;/a&gt;: &lt;a href="https://mybinder.org/v2/gh/jakevdp/PythonDataScienceHandbook/master?filepath=notebooks%2FIndex.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Buy the printed book through &lt;a href="http://shop.oreilly.com/product/0636920034919.do" rel="nofollow"&gt;O'Reilly Media&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-about" class="anchor" aria-hidden="true" href="#about"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About&lt;/h2&gt;
&lt;p&gt;The book was written and tested with Python 3.5, though other Python versions (including Python 2.7) should work in nearly all cases.&lt;/p&gt;
&lt;p&gt;The book introduces the core libraries essential for working with data in Python: particularly &lt;a href="http://ipython.org" rel="nofollow"&gt;IPython&lt;/a&gt;, &lt;a href="http://numpy.org" rel="nofollow"&gt;NumPy&lt;/a&gt;, &lt;a href="http://pandas.pydata.org" rel="nofollow"&gt;Pandas&lt;/a&gt;, &lt;a href="http://matplotlib.org" rel="nofollow"&gt;Matplotlib&lt;/a&gt;, &lt;a href="http://scikit-learn.org" rel="nofollow"&gt;Scikit-Learn&lt;/a&gt;, and related packages.
Familiarity with Python as a language is assumed; if you need a quick introduction to the language itself, see the free companion project,
&lt;a href="https://github.com/jakevdp/WhirlwindTourOfPython"&gt;A Whirlwind Tour of Python&lt;/a&gt;: it's a fast-paced introduction to the Python language aimed at researchers and scientists.&lt;/p&gt;
&lt;p&gt;See &lt;a href="http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;Index.ipynb&lt;/a&gt; for an index of the notebooks available to accompany the text.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-software" class="anchor" aria-hidden="true" href="#software"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Software&lt;/h2&gt;
&lt;p&gt;The code in the book was tested with Python 3.5, though most (but not all) will also work correctly with Python 2.7 and other older Python versions.&lt;/p&gt;
&lt;p&gt;The packages I used to run the code in the book are listed in &lt;a href="requirements.txt"&gt;requirements.txt&lt;/a&gt; (Note that some of these exact version numbers may not be available on your platform: you may have to tweak them for your own use).
To install the requirements using &lt;a href="http://conda.pydata.org" rel="nofollow"&gt;conda&lt;/a&gt;, run the following at the command-line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda install --file requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To create a stand-alone environment named &lt;code&gt;PDSH&lt;/code&gt; with Python 3.5 and all the required package versions, run the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda create -n PDSH python=3.5 --file requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can read more about using conda environments in the &lt;a href="http://conda.pydata.org/docs/using/envs.html" rel="nofollow"&gt;Managing Environments&lt;/a&gt; section of the conda documentation.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-code" class="anchor" aria-hidden="true" href="#code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code&lt;/h3&gt;
&lt;p&gt;The code in this repository, including all code samples in the notebooks listed above, is released under the &lt;a href="LICENSE-CODE"&gt;MIT license&lt;/a&gt;. Read more at the &lt;a href="https://opensource.org/licenses/MIT" rel="nofollow"&gt;Open Source Initiative&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-text" class="anchor" aria-hidden="true" href="#text"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Text&lt;/h3&gt;
&lt;p&gt;The text content of the book is released under the &lt;a href="LICENSE-TEXT"&gt;CC-BY-NC-ND license&lt;/a&gt;. Read more at &lt;a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode" rel="nofollow"&gt;Creative Commons&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jakevdp</author><guid isPermaLink="false">https://github.com/jakevdp/PythonDataScienceHandbook</guid><pubDate>Wed, 05 Feb 2020 00:04:00 GMT</pubDate></item><item><title>udacity/deep-learning-v2-pytorch #5 in Jupyter Notebook, This week</title><link>https://github.com/udacity/deep-learning-v2-pytorch</link><description>&lt;p&gt;&lt;i&gt;Projects and exercises for the latest Deep Learning ND program https://www.udacity.com/course/deep-learning-nanodegree--nd101&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deep-learning-pytorch" class="anchor" aria-hidden="true" href="#deep-learning-pytorch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning (PyTorch)&lt;/h1&gt;
&lt;p&gt;This repository contains material related to Udacity's &lt;a href="https://www.udacity.com/course/deep-learning-nanodegree--nd101" rel="nofollow"&gt;Deep Learning Nanodegree program&lt;/a&gt;. It consists of a bunch of tutorial notebooks for various deep learning topics. In most cases, the notebooks lead you through implementing models such as convolutional networks, recurrent networks, and GANs. There are other topics covered such as weight initialization and batch normalization.&lt;/p&gt;
&lt;p&gt;There are also notebooks used as projects for the Nanodegree program. In the program itself, the projects are reviewed by real people (Udacity reviewers), but the starting code is available here, as well.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table Of Contents&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-tutorials" class="anchor" aria-hidden="true" href="#tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorials&lt;/h3&gt;
&lt;h3&gt;&lt;a id="user-content-introduction-to-neural-networks" class="anchor" aria-hidden="true" href="#introduction-to-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction to Neural Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-neural-networks"&gt;Introduction to Neural Networks&lt;/a&gt;: Learn how to implement gradient descent and apply it to predicting patterns in student admissions data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/sentiment-analysis-network"&gt;Sentiment Analysis with NumPy&lt;/a&gt;: &lt;a href="http://iamtrask.github.io/" rel="nofollow"&gt;Andrew Trask&lt;/a&gt; leads you through building a sentiment analysis model, predicting if some text is positive or negative.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-to-pytorch"&gt;Introduction to PyTorch&lt;/a&gt;: Learn how to build neural networks in PyTorch and use pre-trained networks for state-of-the-art image classifiers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-convolutional-neural-networks" class="anchor" aria-hidden="true" href="#convolutional-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Convolutional Neural Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/convolutional-neural-networks"&gt;Convolutional Neural Networks&lt;/a&gt;: Visualize the output of layers that make up a CNN. Learn how to define and train a CNN for classifying &lt;a href="https://en.wikipedia.org/wiki/MNIST_database" rel="nofollow"&gt;MNIST data&lt;/a&gt;, a handwritten digit database that is notorious in the fields of machine and deep learning. Also, define and train a CNN for classifying images in the &lt;a href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="nofollow"&gt;CIFAR10 dataset&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/transfer-learning"&gt;Transfer Learning&lt;/a&gt;. In practice, most people don't train their own networks on huge datasets; they use &lt;strong&gt;pre-trained&lt;/strong&gt; networks such as VGGnet. Here you'll use VGGnet to help classify images of flowers without training an end-to-end network from scratch.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/weight-initialization"&gt;Weight Initialization&lt;/a&gt;: Explore how initializing network weights affects performance.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/autoencoder"&gt;Autoencoders&lt;/a&gt;: Build models for image compression and de-noising, using feedforward and convolutional networks in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/style-transfer"&gt;Style Transfer&lt;/a&gt;: Extract style and content features from images, using a pre-trained network. Implement style transfer according to the paper, &lt;a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="nofollow"&gt;Image Style Transfer Using Convolutional Neural Networks&lt;/a&gt; by Gatys et. al. Define appropriate losses for iteratively creating a target, style-transferred image of your own design!&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-recurrent-neural-networks" class="anchor" aria-hidden="true" href="#recurrent-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Recurrent Neural Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/recurrent-neural-networks"&gt;Intro to Recurrent Networks (Time series &amp;amp; Character-level RNN)&lt;/a&gt;: Recurrent neural networks are able to use information about the sequence of data, such as the sequence of characters in text; learn how to implement these in PyTorch for a variety of tasks.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/word2vec-embeddings"&gt;Embeddings (Word2Vec)&lt;/a&gt;: Implement the Word2Vec model to find semantic representations of words for use in natural language processing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/sentiment-rnn"&gt;Sentiment Analysis RNN&lt;/a&gt;: Implement a recurrent neural network that can predict if the text of a moview review is positive or negative.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/attention"&gt;Attention&lt;/a&gt;: Implement attention and apply it to annotation vectors.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-generative-adversarial-networks" class="anchor" aria-hidden="true" href="#generative-adversarial-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generative Adversarial Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/gan-mnist"&gt;Generative Adversarial Network on MNIST&lt;/a&gt;: Train a simple generative adversarial network on the MNIST dataset.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/batch-norm"&gt;Batch Normalization&lt;/a&gt;: Learn how to improve training rates and network stability with batch normalizations.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/dcgan-svhn"&gt;Deep Convolutional GAN (DCGAN)&lt;/a&gt;: Implement a DCGAN to generate new images based on the Street View House Numbers (SVHN) dataset.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/cycle-gan"&gt;CycleGAN&lt;/a&gt;: Implement a CycleGAN that is designed to learn from unpaired and unlabeled data; use trained generators to transform images from summer to winter and vice versa.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-deploying-a-model-with-aws-sagemaker" class="anchor" aria-hidden="true" href="#deploying-a-model-with-aws-sagemaker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deploying a Model (with AWS SageMaker)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/sagemaker-deployment"&gt;All exercise and project notebooks&lt;/a&gt; for the lessons on model deployment can be found in the linked, Github repo. Learn to deploy pre-trained models using AWS SageMaker.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-projects" class="anchor" aria-hidden="true" href="#projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Projects&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-bikesharing"&gt;Predicting Bike-Sharing Patterns&lt;/a&gt;: Implement a neural network in NumPy to predict bike rentals.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-dog-classification"&gt;Dog Breed Classifier&lt;/a&gt;: Build a convolutional neural network with PyTorch to classify any image (even an image of a face) as a specific dog breed.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-tv-script-generation"&gt;TV Script Generation&lt;/a&gt;: Train a recurrent neural network to generate scripts in the style of dialogue from Seinfeld.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-face-generation"&gt;Face Generation&lt;/a&gt;: Use a DCGAN on the CelebA dataset to generate images of new and realistic human faces.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-elective-material" class="anchor" aria-hidden="true" href="#elective-material"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Elective Material&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/tensorflow/intro-to-tensorflow"&gt;Intro to TensorFlow&lt;/a&gt;: Starting building neural networks with TensorFlow.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/keras"&gt;Keras&lt;/a&gt;: Learn to build neural networks and convolutional neural networks with Keras.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-configure-and-manage-your-environment-with-anaconda" class="anchor" aria-hidden="true" href="#configure-and-manage-your-environment-with-anaconda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configure and Manage Your Environment with Anaconda&lt;/h2&gt;
&lt;p&gt;Per the Anaconda &lt;a href="http://conda.pydata.org/docs" rel="nofollow"&gt;docs&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Conda is an open source package management system and environment management system
for installing multiple versions of software packages and their dependencies and
switching easily between them. It works on Linux, OS X and Windows, and was created
for Python programs but can package and distribute any software.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overview&lt;/h2&gt;
&lt;p&gt;Using Anaconda consists of the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install &lt;a href="http://conda.pydata.org/miniconda.html" rel="nofollow"&gt;&lt;code&gt;miniconda&lt;/code&gt;&lt;/a&gt; on your computer, by selecting the latest Python version for your operating system. If you already have &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;miniconda&lt;/code&gt; installed, you should be able to skip this step and move on to step 2.&lt;/li&gt;
&lt;li&gt;Create and activate * a new &lt;code&gt;conda&lt;/code&gt; &lt;a href="http://conda.pydata.org/docs/using/envs.html" rel="nofollow"&gt;environment&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;* Each time you wish to work on any exercises, activate your &lt;code&gt;conda&lt;/code&gt; environment!&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-1-installation" class="anchor" aria-hidden="true" href="#1-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Installation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Download&lt;/strong&gt; the latest version of &lt;code&gt;miniconda&lt;/code&gt; that matches your system.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Linux&lt;/th&gt;
&lt;th&gt;Mac&lt;/th&gt;
&lt;th&gt;Windows&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;64-bit&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh" rel="nofollow"&gt;64-bit (bash installer)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-MacOSX-x86_64.sh" rel="nofollow"&gt;64-bit (bash installer)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-Windows-x86_64.exe" rel="nofollow"&gt;64-bit (exe installer)&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;32-bit&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86.sh" rel="nofollow"&gt;32-bit (bash installer)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-Windows-x86.exe" rel="nofollow"&gt;32-bit (exe installer)&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Install&lt;/strong&gt; &lt;a href="http://conda.pydata.org/miniconda.html" rel="nofollow"&gt;miniconda&lt;/a&gt; on your machine. Detailed instructions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Linux:&lt;/strong&gt; &lt;a href="http://conda.pydata.org/docs/install/quick.html#linux-miniconda-install" rel="nofollow"&gt;http://conda.pydata.org/docs/install/quick.html#linux-miniconda-install&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mac:&lt;/strong&gt; &lt;a href="http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install" rel="nofollow"&gt;http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Windows:&lt;/strong&gt; &lt;a href="http://conda.pydata.org/docs/install/quick.html#windows-miniconda-install" rel="nofollow"&gt;http://conda.pydata.org/docs/install/quick.html#windows-miniconda-install&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-2-create-and-activate-the-environment" class="anchor" aria-hidden="true" href="#2-create-and-activate-the-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Create and Activate the Environment&lt;/h2&gt;
&lt;p&gt;For Windows users, these following commands need to be executed from the &lt;strong&gt;Anaconda prompt&lt;/strong&gt; as opposed to a Windows terminal window. For Mac, a normal terminal window will work.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-git-and-version-control" class="anchor" aria-hidden="true" href="#git-and-version-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Git and version control&lt;/h4&gt;
&lt;p&gt;These instructions also assume you have &lt;code&gt;git&lt;/code&gt; installed for working with Github from a terminal window, but if you do not, you can download that first with the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you'd like to learn more about version control and using &lt;code&gt;git&lt;/code&gt; from the command line, take a look at our &lt;a href="https://www.udacity.com/course/version-control-with-git--ud123" rel="nofollow"&gt;free course: Version Control with Git&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Now, we're ready to create our local environment!&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Clone the repository, and navigate to the downloaded folder. This may take a minute or two to clone due to the included image data.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/udacity/deep-learning-v2-pytorch.git
cd deep-learning-v2-pytorch
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;
&lt;p&gt;Create (and activate) a new environment, named &lt;code&gt;deep-learning&lt;/code&gt; with Python 3.6. If prompted to proceed with the install &lt;code&gt;(Proceed [y]/n)&lt;/code&gt; type y.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt; or &lt;strong&gt;Mac&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;conda create -n deep-learning python=3.6
source activate deep-learning
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;conda create --name deep-learning python=3.6
activate deep-learning
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point your command line should look something like: &lt;code&gt;(deep-learning) &amp;lt;User&amp;gt;:deep-learning-v2-pytorch &amp;lt;user&amp;gt;$&lt;/code&gt;. The &lt;code&gt;(deep-learning)&lt;/code&gt; indicates that your environment has been activated, and you can proceed with further package installations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install PyTorch and torchvision; this should install the latest version of PyTorch.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt; or &lt;strong&gt;Mac&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;conda install pytorch torchvision -c pytorch 
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;conda install pytorch -c pytorch
pip install torchvision
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install a few required pip packages, which are specified in the requirements text file (including OpenCV).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="7"&gt;
&lt;li&gt;That's it!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now most of the &lt;code&gt;deep-learning&lt;/code&gt; libraries are available to you. Very occasionally, you will see a repository with an addition requirements file, which exists should you want to use TensorFlow and Keras, for example. In this case, you're encouraged to install another library to your existing environment, or create a new environment for a specific project.&lt;/p&gt;
&lt;p&gt;Now, assuming your &lt;code&gt;deep-learning&lt;/code&gt; environment is still activated, you can navigate to the main repo and start looking at the notebooks:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd
cd deep-learning-v2-pytorch
jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To exit the environment when you have completed your work session, simply close the terminal window.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>udacity</author><guid isPermaLink="false">https://github.com/udacity/deep-learning-v2-pytorch</guid><pubDate>Wed, 05 Feb 2020 00:05:00 GMT</pubDate></item><item><title>fastai/fastai2 #6 in Jupyter Notebook, This week</title><link>https://github.com/fastai/fastai2</link><description>&lt;p&gt;&lt;i&gt;Temporary home for fastai v2 while it's being developed&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;
&lt;h1&gt;&lt;a id="user-content-welcome-to-fastai-v2" class="anchor" aria-hidden="true" href="#welcome-to-fastai-v2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Welcome to fastai v2&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;NB: This is still in early development. Use v1 unless you want to contribute to the next version of fastai&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing&lt;/h2&gt;
&lt;p&gt;You can get all the necessary dependencies by simply installing fastai v1: &lt;code&gt;conda install -c fastai -c pytorch fastai&lt;/code&gt;. Or alternatively you can automatically install the dependencies into a new environment:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/fastai/fastai2
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; fastai2
conda env create -f environment.yml
&lt;span class="pl-c1"&gt;source&lt;/span&gt; activate fastai2&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, you can install fastai v2 with pip: &lt;code&gt;pip install fastai2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Or you can use an editable install (which is probably the best approach at the moment, since fastai v2 is under heavy development):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/fastai/fastai2
cd fastai2
pip install -e .[dev]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should also use an editable install of &lt;a href="https://github.com/fastai/fastcore"&gt;&lt;code&gt;fastcore&lt;/code&gt;&lt;/a&gt; to go with it.&lt;/p&gt;
&lt;p&gt;To use &lt;code&gt;fastai2.medical.imaging&lt;/code&gt; you'll also need to:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install pyarrow
pip install pydicom kornia opencv-python scikit-image&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-tests" class="anchor" aria-hidden="true" href="#tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tests&lt;/h2&gt;
&lt;p&gt;To run the tests in parallel, launch:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;nbdev_test_nbs&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;make &lt;span class="pl-c1"&gt;test&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;After you clone this repository, please run &lt;code&gt;nbdev_install_git_hooks&lt;/code&gt; in your terminal. This sets up git hooks, which clean up the notebooks to remove the extraneous stuff stored in the notebooks (e.g. which cells you ran) which causes unnecessary merge conflicts.&lt;/p&gt;
&lt;p&gt;Before submitting a PR, check that the local library and notebooks match. The script &lt;code&gt;nbdev_diff_nbs&lt;/code&gt; can let you know if there is a difference between the local library and the notebooks.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you made a change to the notebooks in one of the exported cells, you can export it to the library with &lt;code&gt;nbdev_build_lib&lt;/code&gt; or &lt;code&gt;make fastai2&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If you made a change to the library, you can export it back to the notebooks with &lt;code&gt;nbdev_update_lib&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fastai</author><guid isPermaLink="false">https://github.com/fastai/fastai2</guid><pubDate>Wed, 05 Feb 2020 00:06:00 GMT</pubDate></item><item><title>fastai/course-v3 #7 in Jupyter Notebook, This week</title><link>https://github.com/fastai/course-v3</link><description>&lt;p&gt;&lt;i&gt;The 3rd edition of course.fast.ai&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-course-v3" class="anchor" aria-hidden="true" href="#course-v3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;course-v3&lt;/h1&gt;
&lt;p&gt;The 3rd edition of &lt;a href="https://course.fast.ai" rel="nofollow"&gt;course.fast.ai&lt;/a&gt;. See the &lt;code&gt;nbs&lt;/code&gt; folder for the notebooks.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fastai</author><guid isPermaLink="false">https://github.com/fastai/course-v3</guid><pubDate>Wed, 05 Feb 2020 00:07:00 GMT</pubDate></item><item><title>aamini/introtodeeplearning #8 in Jupyter Notebook, This week</title><link>https://github.com/aamini/introtodeeplearning</link><description>&lt;p&gt;&lt;i&gt;Lab Materials for MIT 6.S191: Introduction to Deep Learning&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="http://introtodeeplearning.com" rel="nofollow"&gt;&lt;img src="assets/banner.png" alt="banner" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repository contains all of the code and software labs for &lt;a href="http://introtodeeplearning.com" rel="nofollow"&gt;MIT 6.S191: Introduction to Deep Learning&lt;/a&gt;! All lecture slides and videos are available on the course website.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-opening-the-labs-in-google-colaboratory" class="anchor" aria-hidden="true" href="#opening-the-labs-in-google-colaboratory"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Opening the labs in Google Colaboratory:&lt;/h2&gt;
&lt;p&gt;The 2020 6.S191 labs will be run in Google's Colaboratory, a Jupyter notebook environment that runs entirely in the cloud, you don't need to download anything. To run these labs, you must have a Google account.&lt;/p&gt;
&lt;p&gt;On this Github repo, navigate to the lab folder you want to run (&lt;code&gt;lab1&lt;/code&gt;, &lt;code&gt;lab2&lt;/code&gt;, &lt;code&gt;lab3&lt;/code&gt;) and open the appropriate python notebook (*.ipynb). Click the "Run in Colab" link on the top of the lab. That's it!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-running-the-labs" class="anchor" aria-hidden="true" href="#running-the-labs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running the labs&lt;/h2&gt;
&lt;p&gt;Now, to run the labs, open the Jupyter notebook on Colab. Navigate to the "Runtime" tab --&amp;gt; "Change runtime type". In the pop-up window, under "Runtime type" select "Python 3", and under "Hardware accelerator" select "GPU". Go through the notebooks and fill in the &lt;code&gt;#TODO&lt;/code&gt; cells to get the code to compile for yourself!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-mit-deep-learning-package" class="anchor" aria-hidden="true" href="#mit-deep-learning-package"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MIT Deep Learning package&lt;/h3&gt;
&lt;p&gt;You might notice that inside the labs we install the &lt;code&gt;mitdeeplearning&lt;/code&gt; python package from the Python Package repository:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pip install mitdeeplearning&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This package contains convienence functions that we use throughout the course and can be imported like any other Python package.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import mitdeeplearning as mdl&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We do this for you in each of the labs, but the package is also open source under the same license so you can also use it outside the class.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lecture-videos" class="anchor" aria-hidden="true" href="#lecture-videos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lecture Videos&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=5v1JnYv_yWs&amp;amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;amp;index=1" rel="nofollow"&gt;&lt;img src="assets/video_play.png" width="500" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All lecture videos are available publicly online and linked above! Use and/or modification of lecture slides outside of 6.S191 must reference:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; MIT 6.S191: Introduction to Deep Learning&lt;/p&gt;
&lt;p&gt;&lt;a href="http://introtodeeplearning.com" rel="nofollow"&gt;http://introtodeeplearning.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;All code in this repository is copyright 2020 &lt;a href="http://introtodeeplearning.com" rel="nofollow"&gt;MIT 6.S191 Introduction to Deep Learning&lt;/a&gt;. All Rights Reserved.&lt;/p&gt;
&lt;p&gt;Licensed under the MIT License. You may not use this file except in compliance with the License. Use and/or modification of this code outside of 6.S191 must reference:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; MIT 6.S191: Introduction to Deep Learning&lt;/p&gt;
&lt;p&gt;&lt;a href="http://introtodeeplearning.com" rel="nofollow"&gt;http://introtodeeplearning.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>aamini</author><guid isPermaLink="false">https://github.com/aamini/introtodeeplearning</guid><pubDate>Wed, 05 Feb 2020 00:08:00 GMT</pubDate></item><item><title>giswqs/earthengine-py-notebooks #9 in Jupyter Notebook, This week</title><link>https://github.com/giswqs/earthengine-py-notebooks</link><description>&lt;p&gt;&lt;i&gt;A collection of 300+ Jupyter Python notebook examples for using Google Earth Engine with interactive mapping&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-earthengine-py-notebooks" class="anchor" aria-hidden="true" href="#earthengine-py-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;earthengine-py-notebooks&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://opensource.org/licenses/MIT" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3ccf4c50a1576b0dd30b286717451fa56b783512/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/License-MIT-yellow.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A collection of &lt;strong&gt;300+&lt;/strong&gt; Jupyter Python notebook examples for using Google Earth Engine with interactive mapping&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contact:&lt;/strong&gt; Qiusheng Wu (&lt;a href="https://wetlands.io" rel="nofollow"&gt;https://wetlands.io&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-1-description" class="anchor" aria-hidden="true" href="#1-description"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Description&lt;/h2&gt;
&lt;p&gt;This repository is a collection of &lt;strong&gt;300+&lt;/strong&gt; Jupyter Python notebook examples. I developed these examples by converting my other repo &lt;a href="https://github.com/giswqs/qgis-earthengine-examples"&gt;qgis-earthengine-examples&lt;/a&gt; from Python scripts to Jupyter notebooks. Now you can display Earth Engine data layers interactively in Jupyter notebooks without having to install &lt;a href="https://www.qgis.org/" rel="nofollow"&gt;QGIS&lt;/a&gt;. Three Python packages are being used in these examples, including the &lt;a href="https://developers.google.com/earth-engine/python_install" rel="nofollow"&gt;Earth Engine Python API&lt;/a&gt;, &lt;a href="https://github.com/python-visualization/folium"&gt;folium&lt;/a&gt;, and &lt;a href="https://github.com/giswqs/geehydro"&gt;geehydro&lt;/a&gt;. The &lt;strong&gt;geehydro&lt;/strong&gt; Python package builds on the folium package and implements several methods for displaying Earth Engine data layers, such as &lt;code&gt;Map.addLayer()&lt;/code&gt;, &lt;code&gt;Map.setCenter()&lt;/code&gt;, &lt;code&gt;Map.centerObject()&lt;/code&gt;, and &lt;code&gt;Map.setOptions()&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-2-usage" class="anchor" aria-hidden="true" href="#2-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Usage&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Explore this repository and open any available Jupyter notebook in your browser (e.g., &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Template/template.ipynb"&gt;template.ipynb&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; When the selected Jupyter notebook is open, click the &lt;a href="https://nbviewer.jupyter.org/github/giswqs/earthengine-py-notebooks/blob/master/Template/template.ipynb" rel="nofollow"&gt;Notebook Viewer&lt;/a&gt; link to view the interactive map.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; If you would like to execute cells in the notebook interactively, you will need to &lt;a href="https://earthengine.google.com/signup/" rel="nofollow"&gt;Sign up&lt;/a&gt; for a &lt;a href="https://earthengine.google.com/" rel="nofollow"&gt;Google Earth Engine&lt;/a&gt; account. Then you can click either &lt;a href="https://colab.research.google.com/github/giswqs/earthengine-py-notebooks/blob/master/Template/template.ipynb" rel="nofollow"&gt;Run in Google Colab&lt;/a&gt; or &lt;a href="https://mybinder.org/v2/gh/giswqs/earthengine-py-notebooks/master?filepath=Template/template.ipynb" rel="nofollow"&gt;Run in binder&lt;/a&gt; to execute code interactively. This will allow you to add your own Earth Engine Python script.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-3-demo" class="anchor" aria-hidden="true" href="#3-demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. Demo&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b6f17f06134c1375ab827952a40a97b9cbeaa3f2/68747470733a2f2f692e696d6775722e636f6d2f746e4a434d7a4a2e676966"&gt;&lt;img src="https://camo.githubusercontent.com/b6f17f06134c1375ab827952a40a97b9cbeaa3f2/68747470733a2f2f692e696d6775722e636f6d2f746e4a434d7a4a2e676966" alt="ee-py-notebooks" data-canonical-src="https://i.imgur.com/tnJCMzJ.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-4-examples" class="anchor" aria-hidden="true" href="#4-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4. Examples&lt;/h2&gt;
&lt;p&gt;The Table of Contents below mimics the structure of the Google Earth Engine &lt;a href="https://developers.google.com/earth-engine" rel="nofollow"&gt;API Documentation&lt;/a&gt;. I strongly encourage you to check out the API Documentation if you need an in-depth explanation of each Python example. Please note that the list below does not include all the Python examples contained in this repository. You are welcome to explore the repository and find more examples to suit your needs.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-get-started" class="anchor" aria-hidden="true" href="#get-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/GetStarted"&gt;Get Started&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/GetStarted/01_hello_world.ipynb"&gt;Hello world!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/GetStarted/02_adding_data_to_qgis.ipynb"&gt;Adding data to Map&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/GetStarted/03_finding_images.ipynb"&gt;Finding images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/GetStarted/04_band_math.ipynb"&gt;Band math&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/GetStarted/05_map_function.ipynb"&gt;Mapping (what to do instead of a for-loop)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/GetStarted/06_reducing.ipynb"&gt;Reducing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/GetStarted/07_image_statistics.ipynb"&gt;Image statistics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/GetStarted/08_masking.ipynb"&gt;Masking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/GetStarted/09_a_complete_example.ipynb"&gt;A complete example&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-machine-learning" class="anchor" aria-hidden="true" href="#machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/MachineLearning"&gt;Machine Learning&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Supervised Classification Algorithms
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/MachineLearning/cart_classifier.ipynb"&gt;Classification and Regression Trees (CART)&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/MachineLearning/svm_classifier.ipynb"&gt;Support Vector Machine (SVM)&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/MachineLearning/confusion_matrix.ipynb"&gt;Confusion Matrix&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Unsupervised Classification Algorithms
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/MachineLearning/clustering.ipynb"&gt;KMeans Clustering&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-image" class="anchor" aria-hidden="true" href="#image"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image"&gt;Image&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/image_overview.ipynb"&gt;Image Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/image_vis.ipynb"&gt;Image Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/image_metadata.ipynb"&gt;Image information and metadata&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/band_math.ipynb"&gt;Mathematical operations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/conditional_operations.ipynb"&gt;Relational, conditional and Boolean operations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/convolutions.ipynb"&gt;Convolutions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/morphological_operations.ipynb"&gt;Morphological Operations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/gradients.ipynb"&gt;Gradients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/edge_detection.ipynb"&gt;Edge detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/spectral_unmixing.ipynb"&gt;Spectral transformations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/texture.ipynb"&gt;Texture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/object_based.ipynb"&gt;Object-based methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/cumulative_cost_mapping.ipynb"&gt;Cumulative Cost Mapping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/image_displacement.ipynb"&gt;Registering Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Miscellaneous
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/band_stats.ipynb"&gt;Band statistics (min, max, mean, std)&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/image_stats_by_band.ipynb"&gt;Image statistics by band&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Image/extract_value_to_points.ipynb"&gt;Extract value to points&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/rename_bands.ipynb"&gt;Rename bands&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/clipping.ipynb"&gt;Clipping&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/find_image_by_path_row.ipynb"&gt;Find image by path and row&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/get_image_resolution.ipynb"&gt;Get image resolution&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/get_image_extent.ipynb"&gt;Get image extent&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/set_image_properties.ipynb"&gt;Set image properties&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/select_bands.ipynb"&gt;Select bands&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/convert_bands_to_image_collection.ipynb"&gt;Convert bands to ImageCollection&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/reclassify.ipynb"&gt;Reclassify&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/composite_bands.ipynb"&gt;Composite bands&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/image_smoothing.ipynb"&gt;Image smoothing&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/download.ipynb"&gt;Download image&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/cell_statistics.ipynb"&gt;Cell statistics&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/image_patch_area.ipynb"&gt;Image patch area&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/get_image_id.ipynb"&gt;Get image id&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Image/get_band_name_and_type.ipynb"&gt;Get band name and type&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/ImageCollection/filtering_by_calendar_range.ipynb"&gt;Filtering by calendar range&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-imagecollection" class="anchor" aria-hidden="true" href="#imagecollection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/ImageCollection"&gt;ImageCollection&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/ImageCollection/overview.ipynb"&gt;ImageCollection Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/ImageCollection/metadata.ipynb"&gt;ImageCollection Information and Metadata&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/ImageCollection/filtering_collection.ipynb"&gt;Filtering an ImageCollection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/ImageCollection/map_function.ipynb"&gt;Mapping over an ImageCollection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/ImageCollection/reducing_collection.ipynb"&gt;Reducing an ImageCollection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/ImageCollection/mosaicking.ipynb"&gt;Compositing and Mosaicking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Miscellaneous
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/ImageCollection/get_image_centroid.ipynb"&gt;Get image centroid&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/ImageCollection/convert_imagecollection_to_image.ipynb"&gt;Convert ImageCollection to Image&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/ImageCollection/sort_by_cloud_and_date.ipynb"&gt;Sort by cloud and date&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/ImageCollection/filtering_by_metadata.ipynb"&gt;Filtering by metadata&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/ImageCollection/filtering_by_band_names.ipynb"&gt;Filtering by band names&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/ImageCollection/select_image_by_index.ipynb"&gt;Select image by index&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/ImageCollection/creating_monthly_imagery.ipynb"&gt;Creating monthly imagery&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-geometry-feature-featurecollection" class="anchor" aria-hidden="true" href="#geometry-feature-featurecollection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection"&gt;Geometry, Feature, FeatureCollection&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/FeatureCollection/creating_feature.ipynb"&gt;Geometry Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/visualizing_geometries.ipynb"&gt;Geodesic vs. Planar Geometries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/visualizing_geometries.ipynb"&gt;Geometry Visualization and Information&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/FeatureCollection/geometric_operations.ipynb"&gt;Geometric Operations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/FeatureCollection/creating_feature.ipynb"&gt;Feature Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/FeatureCollection/from_polygons.ipynb"&gt;FeatureCollection Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/visualizing_feature_collection.ipynb"&gt;Feature and FeatureCollection Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/FeatureCollection/metadata_aggregation.ipynb"&gt;FeatureCollection Information and Metadata&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/FeatureCollection/filtering_feature_collection.ipynb"&gt;Filtering a FeatureCollection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/FeatureCollection/map_function.ipynb"&gt;Mapping over a FeatureCollection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/FeatureCollection/reducing_feature_collection.ipynb"&gt;Reducing a FeatureCollection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/FeatureCollection/idw_interpolation.ipynb"&gt;Vector to Raster Interpolation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Miscellaneous
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/FeatureCollection/add_new_attribute.ipynb"&gt;Add new attribute&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/add_area_column.ipynb"&gt;Add area column&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/add_random_value_column.ipynb"&gt;Add random value column&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/column_statistics.ipynb"&gt;Single column statistics&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/column_statistics_multiple.ipynb"&gt;Multiple column statistics&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/simplify_polygons.ipynb"&gt;Simplify polygons&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/column_statistics_by_group.ipynb"&gt;Column statistics by group&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/select_by_location.ipynb"&gt;Select by location&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/select_by_attributes.ipynb"&gt;Select by attributes&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/select_by_strings.ipynb"&gt;Select by strings&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/vector_symbology.ipynb"&gt;Vector symbology&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/merge_feature_collections.ipynb"&gt;Merge FeatureCollection&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/search_by_buffer_distance.ipynb"&gt;Search by buffer distance&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/select_columns.ipynb"&gt;Select columns&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/minimum_bounding_geometry.ipynb"&gt;Mimimum bounding geometry&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/FeatureCollection/clipping.ipynb"&gt;Clipping polygons&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-reducer" class="anchor" aria-hidden="true" href="#reducer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Reducer"&gt;Reducer&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Reducer/min_max_reducer.ipynb"&gt;Reducer Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Reducer/median_reducer.ipynb"&gt;ImageCollection Reductions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Reducer/image_reductions.ipynb"&gt;Image Reductions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Reducer/stats_of_an_image_region.ipynb"&gt;Statistics of an Image Region&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Reducer/stats_of_image_regions.ipynb"&gt;Statistics of Image Regions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Reducer/stats_of_image_neighborhoods.ipynb"&gt;Statistics of Image Neighborhoods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Reducer/stats_of_columns.ipynb"&gt;Statistics of FeatureCollection Columns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Reducer/convert_raster_to_vector.ipynb"&gt;Raster to Vector Conversion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Reducer/convert_vector_to_raster.ipynb"&gt;Vector to Raster Conversion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Grouped Reductions and Zonal Statistics
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Reducer/stats_by_group.ipynb"&gt;Statistics by group&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Reducer/zonal_statistics.ipynb"&gt;Zonal Statistics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Reducer/weighted_reductions.ipynb"&gt;Weighted Reductions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Reducer/linear_regression.ipynb"&gt;Linear Regression&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-join" class="anchor" aria-hidden="true" href="#join"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Join"&gt;Join&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Join/simple_joins.ipynb"&gt;Simple Joins&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Join/inverted_joins.ipynb"&gt;Inverted Joins&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Join/inner_joins.ipynb"&gt;Inner Joins&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Join/save_all_joins.ipynb"&gt;Save-All Joins&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Join/save_best_joins.ipynb"&gt;Save-Best Joins&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Join/spatial_joins.ipynb"&gt;Spatial Joins&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-array" class="anchor" aria-hidden="true" href="#array"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Array"&gt;Array&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Array/array_images.ipynb"&gt;Arrays and Array Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Array/array_transformations.ipynb"&gt;Array Transformations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Array/eigen_analysis.ipynb"&gt;Eigen Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Array/array_sorting.ipynb"&gt;Array Sorting and Reducing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-specialized-algorithms" class="anchor" aria-hidden="true" href="#specialized-algorithms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Algorithms"&gt;Specialized Algorithms&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Landsat Algorithms
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Algorithms/landsat_radiance.ipynb"&gt;Radiance&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Algorithms/landsat_surface_reflectance.ipynb"&gt;Surface Reflectance&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Algorithms/landsat_cloud_score.ipynb"&gt;Simple cloud score&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Algorithms/landsat_simple_composite.ipynb"&gt;Simple composite&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Algorithms/sentinel-1_filtering.ipynb"&gt;Sentinel-1 Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Resampling and Reducing Resolution
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Algorithms/resampling.ipynb"&gt;Resampling&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Algorithms/reduce_resolution.ipynb"&gt;Reducing Resolution&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Algorithms/ntl_linear_fit.ipynb"&gt;Linear fit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Pattern recognition
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Algorithms/center_pivot_irrigation_detector.ipynb"&gt;Center-pivot Irrigation Detector&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-asset-management" class="anchor" aria-hidden="true" href="#asset-management"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/AssetManagement"&gt;Asset Management&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/AssetManagement/export_raster.ipynb"&gt;Exporting Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/AssetManagement/export_ImageCollection.ipynb"&gt;Exporting ImageCollection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/AssetManagement/export_vector.ipynb"&gt;Exporting Vector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/AssetManagement/export_FeatureCollection.ipynb"&gt;Exporting FeatureCollection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/AssetManagement/export_csv.ipynb"&gt;Exporting CSV&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/AssetManagement/export_table.ipynb"&gt;Exporting Table&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/AssetManagement/export_TimeSeries.ipynb"&gt;Exporting TimeSeries&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-how-earth-engine-works" class="anchor" aria-hidden="true" href="#how-earth-engine-works"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/HowEarthEngineWorks"&gt;How Earth Engine Works&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/HowEarthEngineWorks/ClientVsServer.ipynb"&gt;Client vs. Server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/HowEarthEngineWorks/DeferredExecution.ipynb"&gt;Deferred Execution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/HowEarthEngineWorks/Projections.ipynb"&gt;Projections&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-filter" class="anchor" aria-hidden="true" href="#filter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Filter"&gt;Filter&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Filter/filter_eq.ipynb"&gt;Filter to metadata equal to the given value&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Filter/filter_neq.ipynb"&gt;Filter to metadata not equal to the given value&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Filter/filter_in_list.ipynb"&gt;Filter on metadata contained in a list&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Filter/filter_string_contains.ipynb"&gt;Filter on metadata that cotains a certain string&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Filter/filter_string_starts_with.ipynb"&gt;Filter on metadata that starts with a certain string&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Filter/filter_string_ends_with.ipynb"&gt;Filter on metadata that ends with a certain string&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Filter/filter_range_contains.ipynb"&gt;Filter on metadata that falls within a specified range&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-visualization" class="anchor" aria-hidden="true" href="#visualization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Visualization"&gt;Visualization&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/image_rgb_composite.ipynb"&gt;RGB composite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/image_color_palettes.ipynb"&gt;Color palettes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/image_color_ramp.ipynb"&gt;Color ramp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/hillshade.ipynb"&gt;Hillshade&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/image_stretch.ipynb"&gt;Image stretch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/image_thumbanil.ipynb"&gt;Image thumbnail&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/rendering_categorical_maps.ipynb"&gt;Rendering categorical maps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/styled_layer_descriptors.ipynb"&gt;Styled layer descriptors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/terrain_visualization.ipynb"&gt;Terrain visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/visualizing_feature_collection.ipynb"&gt;Visualizing FeatureCollection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/visualizing_geometries.ipynb"&gt;Visualizing Geometry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/nlcd_land_cover.ipynb"&gt;NLCD Land Cover&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Visualization/us_counties.ipynb"&gt;US Counties&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Miscellaneous
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Visualization/ndvi_symbology.ipynb"&gt;NDVI symbology&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Visualization/ndvi_symbology.ipynb"&gt;NDWI symbology&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Visualization/landsat_symbology.ipynb"&gt;Landsat symbology&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Visualization/nwi_wetlands_symbology.ipynb"&gt;NWI wetlands symbology&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Visualization/color_by_attribute.ipynb"&gt;Color by attribute&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Visualization/random_color_visualizer.ipynb"&gt;Random color visualizer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-datasets" class="anchor" aria-hidden="true" href="#datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets"&gt;Datasets&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Terrain"&gt;Terrain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Water"&gt;Water&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors"&gt;Vector datasets catalog&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/international_boundary.ipynb"&gt;Large Scale International Boundary Polygons (LSIB)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/us_census_counties.ipynb"&gt;TIGER: US 2018 Census Counties&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/us_census_states.ipynb"&gt;TIGER: US 2018 Census States&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/us_census_roads.ipynb"&gt;TIGER: US 2016 Census Roads&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/us_census_blocks.ipynb"&gt;TIGER: US 2010 Census Blocks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/us_census_tracts.ipynb"&gt;TIGER: US Census 2010 Census Tracts + Demographic Profile 1 aggregate statistics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/us_census_zip_code.ipynb"&gt;TIGER: US Census 2010 5-digit ZIP Code Tabulation Areas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/global_land_ice_measurements.ipynb"&gt;GLIMS: Global Land Ice Measurements from Space&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/usgs_watershed_boundary.ipynb"&gt;USGS Watershed Boundary Datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/us_epa_ecoregions.ipynb"&gt;USA EPA Ecoregions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/resolve_ecoregions.ipynb"&gt;RESOLVE Ecoregions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/world_database_on_protected_areas.ipynb"&gt;World Database on Protected Areas (WDPA)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/global_power_plant_database.ipynb"&gt;WRI Global Power Plant Database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Datasets/Vectors/landsat_wrs2_grid.ipynb"&gt;Landsat WRS-2 grid&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-tutorials" class="anchor" aria-hidden="true" href="#tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Tutorials"&gt;Tutorials&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Tutorials/GlobalSurfaceWater"&gt;Global Surface Water&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-genas-examples" class="anchor" aria-hidden="true" href="#genas-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/tree/master/Gena"&gt;Gena's Examples&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Gena/map_add_features.ipynb"&gt;Map.addLayer()&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Gena/map_center_object.ipynb"&gt;Map.centerObject()&lt;/a&gt; | &lt;a href="https://github.com/giswqs/earthengine-py-notebooks/blob/master/Gena/map_set_center.ipynb"&gt;Map.setCenter()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>giswqs</author><guid isPermaLink="false">https://github.com/giswqs/earthengine-py-notebooks</guid><pubDate>Wed, 05 Feb 2020 00:09:00 GMT</pubDate></item><item><title>dennybritz/reinforcement-learning #10 in Jupyter Notebook, This week</title><link>https://github.com/dennybritz/reinforcement-learning</link><description>&lt;p&gt;&lt;i&gt;Implementation of Reinforcement Learning Algorithms. Python, OpenAI Gym, Tensorflow. Exercises and Solutions to accompany Sutton's Book and David Silver's course.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h3&gt;&lt;a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overview&lt;/h3&gt;
&lt;p&gt;This repository provides code, exercises and solutions for popular Reinforcement Learning algorithms. These are meant to serve as a learning tool to complement the theoretical materials from&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://incompleteideas.net/book/RLbook2018.pdf" rel="nofollow"&gt;Reinforcement Learning: An Introduction (2nd Edition)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" rel="nofollow"&gt;David Silver's Reinforcement Learning Course&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each folder in corresponds to one or more chapters of the above textbook and/or course. In addition to exercises and solution, each folder also contains a list of learning goals, a brief concept summary, and links to the relevant readings.&lt;/p&gt;
&lt;p&gt;All code is written in Python 3 and uses RL environments from &lt;a href="https://gym.openai.com/" rel="nofollow"&gt;OpenAI Gym&lt;/a&gt;. Advanced techniques use &lt;a href="https://www.tensorflow.org/" rel="nofollow"&gt;Tensorflow&lt;/a&gt; for neural network implementations.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="Introduction/"&gt;Introduction to RL problems &amp;amp; OpenAI Gym&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="MDP/"&gt;MDPs and Bellman Equations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="DP/"&gt;Dynamic Programming: Model-Based RL, Policy Iteration and Value Iteration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="MC/"&gt;Monte Carlo Model-Free Prediction &amp;amp; Control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="TD/"&gt;Temporal Difference Model-Free Prediction &amp;amp; Control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="FA/"&gt;Function Approximation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="DQN/"&gt;Deep Q Learning&lt;/a&gt; (WIP)&lt;/li&gt;
&lt;li&gt;&lt;a href="PolicyGradient/"&gt;Policy Gradient Methods&lt;/a&gt; (WIP)&lt;/li&gt;
&lt;li&gt;Learning and Planning (WIP)&lt;/li&gt;
&lt;li&gt;Exploration and Exploitation (WIP)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-list-of-implemented-algorithms" class="anchor" aria-hidden="true" href="#list-of-implemented-algorithms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;List of Implemented Algorithms&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="DP/Policy%20Evaluation%20Solution.ipynb"&gt;Dynamic Programming Policy Evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="DP/Policy%20Iteration%20Solution.ipynb"&gt;Dynamic Programming Policy Iteration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="DP/Value%20Iteration%20Solution.ipynb"&gt;Dynamic Programming Value Iteration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="MC/MC%20Prediction%20Solution.ipynb"&gt;Monte Carlo Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="MC/MC%20Control%20with%20Epsilon-Greedy%20Policies%20Solution.ipynb"&gt;Monte Carlo Control with Epsilon-Greedy Policies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="MC/Off-Policy%20MC%20Control%20with%20Weighted%20Importance%20Sampling%20Solution.ipynb"&gt;Monte Carlo Off-Policy Control with Importance Sampling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="TD/SARSA%20Solution.ipynb"&gt;SARSA (On Policy TD Learning)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="TD/Q-Learning%20Solution.ipynb"&gt;Q-Learning (Off Policy TD Learning)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="FA/Q-Learning%20with%20Value%20Function%20Approximation%20Solution.ipynb"&gt;Q-Learning with Linear Function Approximation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="DQN/Deep%20Q%20Learning%20Solution.ipynb"&gt;Deep Q-Learning for Atari Games&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="DQN/Double%20DQN%20Solution.ipynb"&gt;Double Deep-Q Learning for Atari Games&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep Q-Learning with Prioritized Experience Replay (WIP)&lt;/li&gt;
&lt;li&gt;&lt;a href="PolicyGradient/CliffWalk%20REINFORCE%20with%20Baseline%20Solution.ipynb"&gt;Policy Gradient: REINFORCE with Baseline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="PolicyGradient/CliffWalk%20Actor%20Critic%20Solution.ipynb"&gt;Policy Gradient: Actor Critic with Baseline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="PolicyGradient/Continuous%20MountainCar%20Actor%20Critic%20Solution.ipynb"&gt;Policy Gradient: Actor Critic with Baseline for Continuous Action Spaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deterministic Policy Gradients for Continuous Action Spaces (WIP)&lt;/li&gt;
&lt;li&gt;Deep Deterministic Policy Gradients (DDPG) (WIP)&lt;/li&gt;
&lt;li&gt;&lt;a href="PolicyGradient/a3c"&gt;Asynchronous Advantage Actor Critic (A3C)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h3&gt;
&lt;p&gt;Textbooks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://incompleteideas.net/book/RLbook2018.pdf" rel="nofollow"&gt;Reinforcement Learning: An Introduction (2nd Edition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Classes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" rel="nofollow"&gt;David Silver's Reinforcement Learning Course (UCL, 2015)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://rll.berkeley.edu/deeprlcourse/" rel="nofollow"&gt;CS294 - Deep Reinforcement Learning (Berkeley, Fall 2015)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.udacity.com/course/reinforcement-learning--ud600" rel="nofollow"&gt;CS 8803 - Reinforcement Learning (Georgia Tech)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cs.uwaterloo.ca/~ppoupart/teaching/cs885-spring18/" rel="nofollow"&gt;CS885 - Reinforcement Learning (UWaterloo), Spring 2018&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://rail.eecs.berkeley.edu/deeprlcourse/" rel="nofollow"&gt;CS294-112 - Deep Reinforcement Learning (UC Berkeley)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Talks/Tutorials:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://videolectures.net/deeplearning2016_pineau_reinforcement_learning/" rel="nofollow"&gt;Introduction to Reinforcement Learning (Joelle Pineau @ Deep Learning Summer School 2016)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://videolectures.net/deeplearning2016_abbeel_deep_reinforcement/" rel="nofollow"&gt;Deep Reinforcement Learning (Pieter Abbeel @ Deep Learning Summer School 2016)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://techtalks.tv/talks/deep-reinforcement-learning/62360/" rel="nofollow"&gt;Deep Reinforcement Learning ICML 2016 Tutorial (David Silver)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ggqnxyjaKe4" rel="nofollow"&gt;Tutorial: Introduction to Reinforcement Learning with Function Approximation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLjKEIQlKCTZYN3CYBlj8r58SbNorobqcp" rel="nofollow"&gt;John Schulman - Deep Reinforcement Learning (4 Lectures)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf" rel="nofollow"&gt;Deep Reinforcement Learning Slides @ NIPS 2016&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://spinningup.openai.com/en/latest/user/introduction.html" rel="nofollow"&gt;OpenAI Spinning Up&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs" rel="nofollow"&gt;Advanced Deep Learning &amp;amp; Reinforcement Learning (UCL 2018, DeepMind)&lt;/a&gt;
-&lt;a href="https://sites.google.com/view/deep-rl-bootcamp/lectures" rel="nofollow"&gt;Deep RL Bootcamp&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Other Projects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/carpedm20/deep-rl-tensorflow"&gt;carpedm20/deep-rl-tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/matthiasplappert/keras-rl"&gt;matthiasplappert/keras-rl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Selected Papers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.readcube.com/articles/10.1038/nature14236" rel="nofollow"&gt;Human-Level Control through Deep Reinforcement Learning (2015-02)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1509.06461" rel="nofollow"&gt;Deep Reinforcement Learning with Double Q-learning (2015-09)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1509.02971" rel="nofollow"&gt;Continuous control with deep reinforcement learning (2015-09)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1511.05952" rel="nofollow"&gt;Prioritized Experience Replay (2015-11)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1511.06581" rel="nofollow"&gt;Dueling Network Architectures for Deep Reinforcement Learning (2015-11)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1602.01783" rel="nofollow"&gt;Asynchronous Methods for Deep Reinforcement Learning (2016-02)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1603.01121" rel="nofollow"&gt;Deep Reinforcement Learning from Self-Play in Imperfect-Information Games (2016-03)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf" rel="nofollow"&gt;Mastering the game of Go with deep neural networks and tree search&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dennybritz</author><guid isPermaLink="false">https://github.com/dennybritz/reinforcement-learning</guid><pubDate>Wed, 05 Feb 2020 00:10:00 GMT</pubDate></item><item><title>selfteaching/the-craft-of-selfteaching #11 in Jupyter Notebook, This week</title><link>https://github.com/selfteaching/the-craft-of-selfteaching</link><description>&lt;p&gt;&lt;i&gt;One has no future if one couldn't teach themself.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-the-craft-of-selfteaching" class="anchor" aria-hidden="true" href="#the-craft-of-selfteaching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;the-craft-of-selfteaching&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;One has no future if one couldn't teach themself&lt;a href="#fn1" name="user-content-fn1b"&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;&lt;a id="user-content-" class="anchor" aria-hidden="true" href="#"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;a href="https://github.com/virushuo"&gt;@virushuo&lt;/a&gt;&lt;strong&gt;&lt;/strong&gt;&lt;a href="https://github.com/hongqn"&gt;@hongqn&lt;/a&gt;) &lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; pseudo-code of selfteaching in Python&lt;/span&gt;

&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;teach_yourself&lt;/span&gt;(&lt;span class="pl-smi"&gt;anything&lt;/span&gt;):
    &lt;span class="pl-k"&gt;while&lt;/span&gt; &lt;span class="pl-k"&gt;not&lt;/span&gt; create():
        learn()
        practice()
    &lt;span class="pl-k"&gt;return&lt;/span&gt; teach_yourself(another)

teach_yourself(coding)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; &lt;a href="T-appendix.jupyter-installation-and-setup.ipynb"&gt;T-appendix.jupyter-installation-and-setup&lt;/a&gt;  &lt;a href="https://github.com/jupyterlab/jupyterlab"&gt;Jupyterlab&lt;/a&gt; &lt;/p&gt;
&lt;p&gt; &lt;a href="02.proof-of-work.ipynb"&gt; Pull Request &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2019  3  23  Markdown &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://github.com/selfteaching/the-craft-of-selfteaching/tree/master/markdown"&gt;https://github.com/selfteaching/the-craft-of-selfteaching/tree/master/markdown&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-" class="anchor" aria-hidden="true" href="#"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="01.preface.ipynb"&gt;01.preface&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="02.proof-of-work.ipynb"&gt;02.proof-of-work&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.A.better.teachyourself.ipynb"&gt;Part.1.A.better.teachyourself&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.B.why.start.from.learning.coding.ipynb"&gt;Part.1.B.why.start.from.learning.coding&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.C.must.learn.sth.only.by.reading.ipynb"&gt;Part.1.C.must.learn.sth.only.by.reading&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.D.preparation.for.reading.ipynb"&gt;Part.1.D.preparation.for.reading&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.1.entrance.ipynb"&gt;Part.1.E.1.entrance&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.2.values-and-their-operators.ipynb"&gt;Part.1.E.2.values-and-their-operators&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.3.controlflow.ipynb"&gt;Part.1.E.3.controlflow&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.4.functions.ipynb"&gt;Part.1.E.4.functions&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.5.strings.ipynb"&gt;Part.1.E.5.strings&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.6.containers.ipynb"&gt;Part.1.E.6.containers&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.7.files.ipynb"&gt;Part.1.E.7.files&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.F.deal-with-forward-references.ipynb"&gt;Part.1.F.deal-with-forward-references&lt;strong&gt;  &lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.G.The-Python-Tutorial-local.ipynb"&gt;Part.1.G.The-Python-Tutorial-local&lt;strong&gt;The Python Tutorial&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.A.clumsy-and-patience.ipynb"&gt;Part.2.A.clumsy-and-patience&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.B.deliberate-practicing.ipynb"&gt;Part.2.B.deliberate-practicing&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.C.why-start-from-writing-functions.ipynb"&gt;Part.2.C.why-start-from-writing-functions&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.1-args.ipynb"&gt;Part.2.D.1-args&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.2-aargs.ipynb"&gt;Part.2.D.2-aargs&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.3-lambda.ipynb"&gt;Part.2.D.3-lambda&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.4-recursion.ipynb"&gt;Part.2.D.4-recursion&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.5-docstrings.ipynb"&gt;Part.2.D.5-docstrings&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.6-modules.ipynb"&gt;Part.2.D.6-modules&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.7-tdd.ipynb"&gt;Part.2.D.7-tdd&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.8-main.ipynb"&gt;Part.2.D.8-main&lt;strong&gt; Python &lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.E.deliberate-thinking.ipynb"&gt;Part.2.E.deliberate-thinking&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.A.conquering-difficulties.ipynb"&gt;Part.3.A.conquering-difficulties&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.B.1.classes-1.ipynb"&gt;Part.3.B.1.classes-1&lt;strong&gt;  &lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.B.2.classes-2.ipynb"&gt;Part.3.B.2.classes-2&lt;strong&gt;  Python &lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.B.3.decorator-iterator-generator.ipynb"&gt;Part.3.B.3.decorator-iterator-generator&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.B.4.regex.ipynb"&gt;Part.3.B.4.regex&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.B.5.bnf-ebnf-pebnf.ipynb"&gt;Part.3.B.5.bnf-ebnf-pebnf&lt;strong&gt;BNF  EBNF&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.C.breaking-good-and-bad.ipynb"&gt;Part.3.C.breaking-good-and-bad&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.D.indispensable-illusion.ipynb"&gt;Part.3.D.indispensable-illusion&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.E.to-be-thorough.ipynb"&gt;Part.3.E.to-be-thorough&lt;strong&gt;  &lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.F.social-selfteaching.ipynb"&gt;Part.3.F.social-selfteaching&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.G.the-golden-age-and-google.ipynb"&gt;Part.3.G.the-golden-age-and-google&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.H.prevent-focus-drifting.ipynb"&gt;Part.3.H.prevent-focus-drifting&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Q.good-communication.ipynb"&gt;Q.good-communiation&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="R.finale.ipynb"&gt;R.finale&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="S.whats-next.ipynb"&gt;S.whats-next&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="T-appendix.editor.vscode.ipynb"&gt;T-appendix.editor.vscode&lt;strong&gt;Visual Studio Code &lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="T-appendix.git-introduction.ipynb"&gt;T-appendix.git-introduction&lt;strong&gt;Git &lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="T-appendix.jupyter-installation-and-setup.ipynb"&gt;T-appendix.jupyter-installation-and-setup&lt;strong&gt;Jupyterlab &lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="T-appendix.symbols.ipynb"&gt;T-appendix.symbols&lt;strong&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" rel="nofollow"&gt;CC-BY-NC-ND license&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/CC-BY-NC-ND.png?raw=true"&gt;&lt;img src="images/CC-BY-NC-ND.png?raw=true" alt="CC-BY-NC-ND" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name="user-content-fn1"&gt;[1]&lt;/a&gt;&lt;a href="https://en.oxforddictionaries.com/usage/themselves-or-themself" rel="nofollow"&gt;'Themselves' or 'themself'? -- Oxford Dictionary&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="#fn1b"&gt;Back to Content&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>selfteaching</author><guid isPermaLink="false">https://github.com/selfteaching/the-craft-of-selfteaching</guid><pubDate>Wed, 05 Feb 2020 00:11:00 GMT</pubDate></item><item><title>Pierian-Data/Complete-Python-3-Bootcamp #12 in Jupyter Notebook, This week</title><link>https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</link><description>&lt;p&gt;&lt;i&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-complete-python-3-bootcamp" class="anchor" aria-hidden="true" href="#complete-python-3-bootcamp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Complete-Python-3-Bootcamp&lt;/h1&gt;
&lt;p&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/p&gt;
&lt;p&gt;Get it now for 95% off with the link:
&lt;a href="https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB" rel="nofollow"&gt;https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Pierian-Data</author><guid isPermaLink="false">https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</guid><pubDate>Wed, 05 Feb 2020 00:12:00 GMT</pubDate></item><item><title>lmoroney/dlaicourse #13 in Jupyter Notebook, This week</title><link>https://github.com/lmoroney/dlaicourse</link><description>&lt;p&gt;&lt;i&gt;Notebooks for learning deep learning&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;This repo does not have a README.&lt;/i&gt;&lt;/p&gt;</description><author>lmoroney</author><guid isPermaLink="false">https://github.com/lmoroney/dlaicourse</guid><pubDate>Wed, 05 Feb 2020 00:13:00 GMT</pubDate></item><item><title>guipsamora/pandas_exercises #14 in Jupyter Notebook, This week</title><link>https://github.com/guipsamora/pandas_exercises</link><description>&lt;p&gt;&lt;i&gt;Practice your pandas skills!&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pandas-exercises" class="anchor" aria-hidden="true" href="#pandas-exercises"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pandas Exercises&lt;/h1&gt;
&lt;p&gt;Fed up with a ton of tutorials but no easy way to find exercises I decided to create a repo just with exercises to practice pandas.
Don't get me wrong, tutorials are great resources, but to learn is to do. So unless you practice you won't learn.&lt;/p&gt;
&lt;p&gt;There will be three different types of files:&lt;br&gt;
1. Exercise instructions&lt;br&gt;
2. Solutions without code&lt;br&gt;
3. Solutions with code and comments&lt;/p&gt;
&lt;p&gt;My suggestion is that you learn a topic in a tutorial, video or documentation and then do the first exercises.
Learn one more topic and do more exercises. If you are stuck, don't go directly to the solution with code files. Check the solutions only and try to get the correct answer.&lt;/p&gt;
&lt;p&gt;Suggestions and collaborations are more than welcome.&lt;g-emoji class="g-emoji" alias="slightly_smiling_face" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f642.png"&gt;&lt;/g-emoji&gt; Please open an issue or make a PR indicating the exercise and your problem/solution.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-lessons" class="anchor" aria-hidden="true" href="#lessons"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lessons&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="#getting-and-knowing"&gt;Getting and knowing&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#merge"&gt;Merge&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#time-series"&gt;Time Series&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="#filtering-and-sorting"&gt;Filtering and Sorting&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#stats"&gt;Stats&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#deleting"&gt;Deleting&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="#grouping"&gt;Grouping&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#visualization"&gt;Visualization&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Indexing&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="#apply"&gt;Apply&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#creating-series-and-dataframes"&gt;Creating Series and DataFrames&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Exporting&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-getting-and-knowing" class="anchor" aria-hidden="true" href="#getting-and-knowing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data"&gt;Getting and knowing&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data/Chipotle"&gt;Chipotle&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data/Occupation"&gt;Occupation&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data/World%20Food%20Facts"&gt;World Food Facts&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-filtering-and-sorting" class="anchor" aria-hidden="true" href="#filtering-and-sorting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting"&gt;Filtering and Sorting&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting/Chipotle"&gt;Chipotle&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting/Euro12"&gt;Euro12&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting/Fictional%20Army"&gt;Fictional Army&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-grouping" class="anchor" aria-hidden="true" href="#grouping"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping"&gt;Grouping&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping/Alcohol_Consumption"&gt;Alcohol Consumption&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping/Occupation"&gt;Occupation&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping/Regiment"&gt;Regiment&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-apply" class="anchor" aria-hidden="true" href="#apply"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/04_Apply"&gt;Apply&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/04_Apply/Students_Alcohol_Consumption"&gt;Students Alcohol Consumption&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/04_Apply/US_Crime_Rates"&gt;US_Crime_Rates&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-merge" class="anchor" aria-hidden="true" href="#merge"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge"&gt;Merge&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge/Auto_MPG"&gt;Auto_MPG&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge/Fictitous%20Names"&gt;Fictitious Names&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge/Housing%20Market"&gt;House Market&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-stats" class="anchor" aria-hidden="true" href="#stats"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/06_Stats"&gt;Stats&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/06_Stats/US_Baby_Names"&gt;US_Baby_Names&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/06_Stats/Wind_Stats"&gt;Wind_Stats&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-visualization" class="anchor" aria-hidden="true" href="#visualization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization"&gt;Visualization&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Chipotle"&gt;Chipotle&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Titanic_Desaster"&gt;Titanic Disaster&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Scores"&gt;Scores&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Online_Retail"&gt;Online Retail&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Tips"&gt;Tips&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-creating-series-and-dataframes" class="anchor" aria-hidden="true" href="#creating-series-and-dataframes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/08_Creating_Series_and_DataFrames"&gt;Creating Series and DataFrames&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/08_Creating_Series_and_DataFrames/Pokemon"&gt;Pokemon&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-time-series" class="anchor" aria-hidden="true" href="#time-series"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series"&gt;Time Series&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series/Apple_Stock"&gt;Apple_Stock&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series/Getting_Financial_Data"&gt;Getting_Financial_Data&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series/Getting_Financial_Data"&gt;Investor_Flow_of_Funds_US&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-deleting" class="anchor" aria-hidden="true" href="#deleting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/10_Deleting"&gt;Deleting&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/10_Deleting/Iris"&gt;Iris&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/10_Deleting/Wine"&gt;Wine&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-video-solutions" class="anchor" aria-hidden="true" href="#video-solutions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Video Solutions&lt;/h1&gt;
&lt;p&gt;Video tutorials of data scientists working through the above exercises:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=pu3IpU937xs&amp;amp;list=PLgJhDSE2ZLxaY_DigHeiIDC1cD09rXgJv" rel="nofollow"&gt;Data Talks - Pandas Learning By Doing&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>guipsamora</author><guid isPermaLink="false">https://github.com/guipsamora/pandas_exercises</guid><pubDate>Wed, 05 Feb 2020 00:14:00 GMT</pubDate></item><item><title>wesm/pydata-book #15 in Jupyter Notebook, This week</title><link>https://github.com/wesm/pydata-book</link><description>&lt;p&gt;&lt;i&gt;Materials and IPython notebooks for "Python for Data Analysis" by Wes McKinney, published by O'Reilly Media&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-python-for-data-analysis-2nd-edition" class="anchor" aria-hidden="true" href="#python-for-data-analysis-2nd-edition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python for Data Analysis, 2nd Edition&lt;/h1&gt;
&lt;p&gt;Materials and IPython notebooks for "Python for Data Analysis" by Wes McKinney,
published by O'Reilly Media&lt;/p&gt;
&lt;p&gt;&lt;a href="http://amzn.to/2vvBijB" rel="nofollow"&gt;Buy the book on Amazon&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://notebooks.azure.com/import/gh/wesm/pydata-book" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2c33d8af3d101ffcd6ea73a8d02290b8d829ac52/68747470733a2f2f6e6f7465626f6f6b732e617a7572652e636f6d2f6c61756e63682e706e67" data-canonical-src="https://notebooks.azure.com/launch.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Follow Wes on Twitter: &lt;a href="https://twitter.com/wesmckinn" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e5ee948ef48fbfa31f868c9dbd301bbd5cf38097/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f7765736d636b696e6e2e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f77" alt="Twitter Follow" data-canonical-src="https://img.shields.io/twitter/follow/wesmckinn.svg?style=social&amp;amp;label=Follow" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-1st-edition-readers" class="anchor" aria-hidden="true" href="#1st-edition-readers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1st Edition Readers&lt;/h1&gt;
&lt;p&gt;If you are reading the &lt;a href="http://amzn.to/2vvBijB" rel="nofollow"&gt;1st Edition&lt;/a&gt; (published in 2012), please find the
reorganized book materials on the &lt;a href="https://github.com/wesm/pydata-book/tree/1st-edition"&gt;&lt;code&gt;1st-edition&lt;/code&gt; branch&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-translations" class="anchor" aria-hidden="true" href="#translations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Translations&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/BrambleXu/pydata-notebook"&gt;Chinese&lt;/a&gt; by Xu Liang&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-ipython-notebooks" class="anchor" aria-hidden="true" href="#ipython-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;IPython Notebooks:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch02.ipynb" rel="nofollow"&gt;Chapter 2: Python Language Basics, IPython, and Jupyter Notebooks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch03.ipynb" rel="nofollow"&gt;Chapter 3: Built-in Data Structures, Functions, and Files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch04.ipynb" rel="nofollow"&gt;Chapter 4: NumPy Basics: Arrays and Vectorized Computation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch05.ipynb" rel="nofollow"&gt;Chapter 5: Getting Started with pandas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch06.ipynb" rel="nofollow"&gt;Chapter 6: Data Loading, Storage, and File Formats&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch07.ipynb" rel="nofollow"&gt;Chapter 7: Data Cleaning and Preparation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch08.ipynb" rel="nofollow"&gt;Chapter 8: Data Wrangling: Join, Combine, and Reshape&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch09.ipynb" rel="nofollow"&gt;Chapter 9: Plotting and Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch10.ipynb" rel="nofollow"&gt;Chapter 10: Data Aggregation and Group Operations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch11.ipynb" rel="nofollow"&gt;Chapter 11: Time Series&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch12.ipynb" rel="nofollow"&gt;Chapter 12: Advanced pandas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch13.ipynb" rel="nofollow"&gt;Chapter 13: Introduction to Modeling Libraries in Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch14.ipynb" rel="nofollow"&gt;Chapter 14: Data Analysis Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/appa.ipynb" rel="nofollow"&gt;Appendix A: Advanced NumPy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-code" class="anchor" aria-hidden="true" href="#code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code&lt;/h3&gt;
&lt;p&gt;The code in this repository, including all code samples in the notebooks listed
above, is released under the &lt;a href="LICENSE-CODE"&gt;MIT license&lt;/a&gt;. Read more at the
&lt;a href="https://opensource.org/licenses/MIT" rel="nofollow"&gt;Open Source Initiative&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>wesm</author><guid isPermaLink="false">https://github.com/wesm/pydata-book</guid><pubDate>Wed, 05 Feb 2020 00:15:00 GMT</pubDate></item><item><title>tensorflow/probability #16 in Jupyter Notebook, This week</title><link>https://github.com/tensorflow/probability</link><description>&lt;p&gt;&lt;i&gt;Probabilistic reasoning and statistical analysis in TensorFlow&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-probability" class="anchor" aria-hidden="true" href="#tensorflow-probability"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow Probability&lt;/h1&gt;
&lt;p&gt;TensorFlow Probability is a library for probabilistic reasoning and statistical
analysis in TensorFlow. As part of the TensorFlow ecosystem, TensorFlow
Probability provides integration of probabilistic methods with deep networks,
gradient-based inference via automatic differentiation, and scalability to
large datasets and models via hardware acceleration (e.g., GPUs) and distributed
computation.&lt;/p&gt;
&lt;p&gt;Our probabilistic machine learning tools are structured as follows.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Layer 0: TensorFlow.&lt;/strong&gt; Numerical operations. In particular, the LinearOperator
class enables matrix-free implementations that can exploit special structure
(diagonal, low-rank, etc.) for efficient computation. It is built and maintained
by the TensorFlow Probability team and is now part of
&lt;a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/ops/linalg"&gt;&lt;code&gt;tf.linalg&lt;/code&gt;&lt;/a&gt;
in core TF.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Layer 1: Statistical Building Blocks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Distributions (&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/distributions"&gt;&lt;code&gt;tfp.distributions&lt;/code&gt;&lt;/a&gt;):
A large collection of probability
distributions and related statistics with batch and
&lt;a href="https://docs.scipy.org/doc/numpy-1.14.0/user/basics.broadcasting.html" rel="nofollow"&gt;broadcasting&lt;/a&gt;
semantics. See the
&lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/TensorFlow_Distributions_Tutorial.ipynb"&gt;Distributions Tutorial&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Bijectors (&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/bijectors"&gt;&lt;code&gt;tfp.bijectors&lt;/code&gt;&lt;/a&gt;):
Reversible and composable transformations of random variables. Bijectors
provide a rich class of transformed distributions, from classical examples
like the
&lt;a href="https://en.wikipedia.org/wiki/Log-normal_distribution" rel="nofollow"&gt;log-normal distribution&lt;/a&gt;
to sophisticated deep learning models such as
&lt;a href="https://arxiv.org/abs/1705.07057" rel="nofollow"&gt;masked autoregressive flows&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Layer 2: Model Building&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Joint Distributions (e.g., &lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/distributions/joint_distribution_sequential.py"&gt;&lt;code&gt;tfp.distributions.JointDistributionSequential&lt;/code&gt;&lt;/a&gt;):
Joint distributions over one or more possibly-interdependent distributions.
For an introduction to modeling with TFP's &lt;code&gt;JointDistribution&lt;/code&gt;s, check out
&lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Modeling_with_JointDistribution.ipynb"&gt;this colab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Probabilistic Layers (&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/layers"&gt;&lt;code&gt;tfp.layers&lt;/code&gt;&lt;/a&gt;):
Neural network layers with uncertainty over the functions they represent,
extending TensorFlow Layers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Layer 3: Probabilistic Inference&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Markov chain Monte Carlo (&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/mcmc"&gt;&lt;code&gt;tfp.mcmc&lt;/code&gt;&lt;/a&gt;):
Algorithms for approximating integrals via sampling. Includes
&lt;a href="https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo" rel="nofollow"&gt;Hamiltonian Monte Carlo&lt;/a&gt;,
random-walk Metropolis-Hastings, and the ability to build custom transition
kernels.&lt;/li&gt;
&lt;li&gt;Variational Inference (&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/vi"&gt;&lt;code&gt;tfp.vi&lt;/code&gt;&lt;/a&gt;):
Algorithms for approximating integrals via optimization.&lt;/li&gt;
&lt;li&gt;Optimizers (&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/optimizer"&gt;&lt;code&gt;tfp.optimizer&lt;/code&gt;&lt;/a&gt;):
Stochastic optimization methods, extending TensorFlow Optimizers. Includes
&lt;a href="http://www.icml-2011.org/papers/398_icmlpaper.pdf" rel="nofollow"&gt;Stochastic Gradient Langevin Dynamics&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Monte Carlo (&lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/python/monte_carlo"&gt;&lt;code&gt;tfp.monte_carlo&lt;/code&gt;&lt;/a&gt;):
Tools for computing Monte Carlo expectations.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TensorFlow Probability is under active development. Interfaces may change at any
time.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;p&gt;See &lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/examples/"&gt;&lt;code&gt;tensorflow_probability/examples/&lt;/code&gt;&lt;/a&gt;
for end-to-end examples. It includes tutorial notebooks such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Linear_Mixed_Effects_Models.ipynb"&gt;Linear Mixed Effects Models&lt;/a&gt;.
A hierarchical linear model for sharing statistical strength across examples.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Eight_Schools.ipynb"&gt;Eight Schools&lt;/a&gt;.
A hierarchical normal model for exchangeable treatment effects.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/HLM_TFP_R_Stan.ipynb"&gt;Hierarchical Linear Models&lt;/a&gt;.
Hierarchical linear models compared among TensorFlow Probability, R, and Stan.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Bayesian_Gaussian_Mixture_Model.ipynb"&gt;Bayesian Gaussian Mixture Models&lt;/a&gt;.
Clustering with a probabilistic generative model.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_PCA.ipynb"&gt;Probabilistic Principal Components Analysis&lt;/a&gt;.
Dimensionality reduction with latent variables.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Gaussian_Copula.ipynb"&gt;Gaussian Copulas&lt;/a&gt;.
Probability distributions for capturing dependence across random variables.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/TensorFlow_Distributions_Tutorial.ipynb"&gt;TensorFlow Distributions: A Gentle Introduction&lt;/a&gt;.
Introduction to TensorFlow Distributions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Understanding_TensorFlow_Distributions_Shapes.ipynb"&gt;Understanding TensorFlow Distributions Shapes&lt;/a&gt;.
How to distinguish between samples, batches, and events for arbitrarily shaped
probabilistic computations.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/TensorFlow_Probability_Case_Study_Covariance_Estimation.ipynb"&gt;TensorFlow Probability Case Study: Covariance Estimation&lt;/a&gt;.
A user's case study in applying TensorFlow Probability to estimate covariances.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It also includes example scripts such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/examples/vae.py"&gt;Variational Autoencoders&lt;/a&gt;.
Representation learning with a latent code and variational inference.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/examples/vq_vae.py"&gt;Vector-Quantized Autoencoder&lt;/a&gt;.
Discrete representation learning with vector quantization.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/examples/disentangled_vae.py"&gt;Disentangled Sequential Variational Autoencoder&lt;/a&gt;
Disentangled representation learning over sequences with variational inference.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/examples/grammar_vae.py"&gt;Grammar Variational Autoencoder&lt;/a&gt;.
Representation learning over productions in a context-free grammar.&lt;/li&gt;
&lt;li&gt;Latent Dirichlet Allocation
(&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/examples/latent_dirichlet_allocation_distributions.py"&gt;Distributions version&lt;/a&gt;,
Mixed membership modeling for capturing topics in a document.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/examples/deep_exponential_family.py"&gt;Deep Exponential Family&lt;/a&gt;.
A deep, sparse generative model for discovering a hierarchy of topics.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/examples/bayesian_neural_network.py"&gt;Bayesian Neural Networks&lt;/a&gt;.
Neural networks with uncertainty over their weights.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/examples/logistic_regression.py"&gt;Bayesian Logistic Regression&lt;/a&gt;.
Bayesian inference for binary classification.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-stable-builds" class="anchor" aria-hidden="true" href="#stable-builds"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stable Builds&lt;/h3&gt;
&lt;p&gt;To install the latest version, run the following:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Notes:&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; - We recommend that users move towards using TensorFlow 2.x as soon as&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;   possible. Until the TF2 stable package is released (due in Sep. 2019),&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;   the best way to use TFP with TF2 is to use nightlyTFP and TF2 packages:&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;     - Nightly TFP: [tfp-nightly](http://pypi.python.org/pypi/tfp-nightly)&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;     - Nightly TF2: [tf-nightly-2.0-preview](http://pypi.python.org/pypi/tf-nightly-2.0-preview)&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;   Once the TF2 stable release comes out, TFP will issue its 0.8.0 release,&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;   which will be tested and stable against TF 2.0.0.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; - You need the latest version of `pip` in order to get the latest version of&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;   `tf-nightly-2.0-preview`.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; - For GPU TF, use `tf-nightly-2.0-preview-gpu`.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; - The `--upgrade` flag ensures you'll get the latest version.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; - The `--user` flag ensures the packages are installed to your user directory&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;   rather than the system directory.&lt;/span&gt;
python -m pip install pip --upgrade --user
python -m pip install tf-nightly-2.0-preview tfp-nightly --upgrade --user
TFVERSION=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;python -c &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;import tensorflow; print(tensorflow.__version__)&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; If you have an older pip, you might get this older version of&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; tf-nightly-2.0-preview, so check to be sure.&lt;/span&gt;
[[ &lt;span class="pl-smi"&gt;$TFVERSION&lt;/span&gt; &lt;span class="pl-k"&gt;==&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;2.0.0-dev20190731&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; ]] &lt;span class="pl-k"&gt;&amp;amp;&amp;amp;&lt;/span&gt;
  &lt;span class="pl-c1"&gt;echo&lt;/span&gt; &lt;span class="pl-k"&gt;&amp;gt;&amp;amp;2&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Failed to install the most recent TF. Found: &lt;span class="pl-smi"&gt;${TFVERSION}&lt;/span&gt;.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;TensorFlow Probability depends on a recent stable release of
&lt;a href="https://www.tensorflow.org/install" rel="nofollow"&gt;TensorFlow&lt;/a&gt; (pip package &lt;code&gt;tensorflow&lt;/code&gt;). See
the &lt;a href="https://github.com/tensorflow/probability/releases"&gt;TFP release notes&lt;/a&gt; for
details about dependencies between TensorFlow and TensorFlow Probability.&lt;/p&gt;
&lt;p&gt;Note: Since TensorFlow is &lt;em&gt;not&lt;/em&gt; included as a dependency of the TensorFlow
Probability package (in &lt;code&gt;setup.py&lt;/code&gt;), you must explicitly install the TensorFlow
package (&lt;code&gt;tensorflow&lt;/code&gt; or &lt;code&gt;tensorflow-gpu&lt;/code&gt;). This allows us to maintain one
package instead of separate packages for CPU and GPU-enabled TensorFlow.&lt;/p&gt;
&lt;p&gt;To force a Python 3-specific install, replace &lt;code&gt;pip&lt;/code&gt; with &lt;code&gt;pip3&lt;/code&gt; in the above
commands. For additional installation help, guidance installing prerequisites,
and (optionally) setting up virtual environments, see the &lt;a href="https://www.tensorflow.org/install" rel="nofollow"&gt;TensorFlow
installation guide&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-nightly-builds" class="anchor" aria-hidden="true" href="#nightly-builds"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Nightly Builds&lt;/h3&gt;
&lt;p&gt;There are also nightly builds of TensorFlow Probability under the pip package
&lt;code&gt;tfp-nightly&lt;/code&gt;, which depends on one of &lt;code&gt;tf-nightly&lt;/code&gt;, &lt;code&gt;tf-nightly-gpu&lt;/code&gt;,
&lt;code&gt;tf-nightly-2.0-preview&lt;/code&gt; or &lt;code&gt;tf-nightly-gpu-2.0-preview&lt;/code&gt;. Nightly builds include
newer features, but may be less stable than the versioned releases. Docs are
periodically refreshed &lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/g3doc/api_docs/python/tfp.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-installing-from-source" class="anchor" aria-hidden="true" href="#installing-from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing from Source&lt;/h3&gt;
&lt;p&gt;You can also install from source. This requires the &lt;a href="https://bazel.build/" rel="nofollow"&gt;Bazel&lt;/a&gt; build system.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; sudo apt-get install bazel git python-pip  # Ubuntu; others, see above links.&lt;/span&gt;
git clone https://github.com/tensorflow/probability.git
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; probability
bazel build --copt=-O3 --copt=-march=native :pip_pkg
PKGDIR=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;mktemp -d&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;
./bazel-bin/pip_pkg &lt;span class="pl-smi"&gt;$PKGDIR&lt;/span&gt;
pip install --user --upgrade &lt;span class="pl-smi"&gt;$PKGDIR&lt;/span&gt;/&lt;span class="pl-k"&gt;*&lt;/span&gt;.whl&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-community" class="anchor" aria-hidden="true" href="#community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community&lt;/h2&gt;
&lt;p&gt;As part of TensorFlow, we're committed to fostering an open and welcoming
environment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://stackoverflow.com/questions/tagged/tensorflow" rel="nofollow"&gt;Stack Overflow&lt;/a&gt;: Ask
or answer technical questions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/probability/issues"&gt;GitHub&lt;/a&gt;: Report bugs or
make feature requests.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.tensorflow.org/" rel="nofollow"&gt;TensorFlow Blog&lt;/a&gt;: Stay up to date on content
from the TensorFlow team and best articles from the community.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://youtube.com/tensorflow/" rel="nofollow"&gt;Youtube Channel&lt;/a&gt;: Follow TensorFlow shows.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://groups.google.com/a/tensorflow.org/forum/#!forum/tfprobability" rel="nofollow"&gt;tfprobability@tensorflow.org&lt;/a&gt;:
Open mailing list for discussion and questions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See the &lt;a href="https://www.tensorflow.org/community/" rel="nofollow"&gt;TensorFlow Community&lt;/a&gt; page for
more details. Check out our latest publicity here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=BjUkL8DFH5Q" rel="nofollow"&gt;Coffee with a Googler: Probabilistic Machine Learning in TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/tensorflow/introducing-tensorflow-probability-dca4c304e245" rel="nofollow"&gt;Introducing TensorFlow Probability&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;We're eager to collaborate with you! See &lt;a href="CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt;
for a guide on how to contribute. This project adheres to TensorFlow's
&lt;a href="CODE_OF_CONDUCT.md"&gt;code of conduct&lt;/a&gt;. By participating, you are expected to
uphold this code.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-references" class="anchor" aria-hidden="true" href="#references"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;References&lt;/h2&gt;
&lt;p&gt;If you use TensorFlow Probability in a paper, please cite:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;TensorFlow Distributions.&lt;/em&gt; Joshua V. Dillon, Ian Langmore, Dustin Tran,
Eugene Brevdo, Srinivas Vasudevan, Dave Moore, Brian Patton, Alex Alemi, Matt
Hoffman, Rif A. Saurous.
&lt;a href="https://arxiv.org/abs/1711.10604" rel="nofollow"&gt;arXiv preprint arXiv:1711.10604, 2017&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(We're aware there's a lot more to TensorFlow Probability than Distributions, but the Distributions paper lays out our vision and is a fine thing to cite for now.)&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>tensorflow</author><guid isPermaLink="false">https://github.com/tensorflow/probability</guid><pubDate>Wed, 05 Feb 2020 00:16:00 GMT</pubDate></item><item><title>fastai/fastai #17 in Jupyter Notebook, This week</title><link>https://github.com/fastai/fastai</link><description>&lt;p&gt;&lt;i&gt;The fastai deep learning library, plus lessons and tutorials&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://dev.azure.com/fastdotai/fastai/_build/latest?definitionId=1" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a1b1234cce0c844f75224d1df07b4f236f78aee7/68747470733a2f2f6465762e617a7572652e636f6d2f66617374646f7461692f6661737461692f5f617069732f6275696c642f7374617475732f6661737461692e666173746169" alt="Build Status" data-canonical-src="https://dev.azure.com/fastdotai/fastai/_apis/build/status/fastai.fastai" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.python.org/pypi/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/26f7b20369ea7a096cfb30bdf0d14bc6ceda0275/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6661737461692e737667" alt="pypi fastai version" data-canonical-src="https://img.shields.io/pypi/v/fastai.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://anaconda.org/fastai/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2c20a6e61cb1c612b644253db1e3c1f7972d7f0e/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f762f6661737461692f6661737461692e737667" alt="Conda fastai version" data-canonical-src="https://img.shields.io/conda/v/fastai/fastai.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://anaconda.org/fastai/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/39f258e6563b60eef6a88589cd194d3a85033747/68747470733a2f2f616e61636f6e64612e6f72672f6661737461692f6661737461692f6261646765732f706c6174666f726d732e737667" alt="Anaconda-Server Badge" data-canonical-src="https://anaconda.org/fastai/fastai/badges/platforms.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.python.org/pypi/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6dc643192dbbbd8edda826d1be289ba06ef2b57f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6661737461692e737667" alt="fastai python compatibility" data-canonical-src="https://img.shields.io/pypi/pyversions/fastai.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.python.org/pypi/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f600abfa75b593d49643c1710ed42865373f9d75/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f6661737461692e737667" alt="fastai license" data-canonical-src="https://img.shields.io/pypi/l/fastai.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-fastai" class="anchor" aria-hidden="true" href="#fastai"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;fastai&lt;/h1&gt;
&lt;p&gt;The fastai library simplifies training fast and accurate neural nets using modern best practices. See the &lt;a href="https://docs.fast.ai" rel="nofollow"&gt;fastai website&lt;/a&gt; to get started. The library is based on research into deep learning best practices undertaken at &lt;a href="http://www.fast.ai" rel="nofollow"&gt;fast.ai&lt;/a&gt;, and includes "out of the box" support for &lt;a href="https://docs.fast.ai/vision.html#vision" rel="nofollow"&gt;&lt;code&gt;vision&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://docs.fast.ai/text.html#text" rel="nofollow"&gt;&lt;code&gt;text&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://docs.fast.ai/tabular.html#tabular" rel="nofollow"&gt;&lt;code&gt;tabular&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://docs.fast.ai/collab.html#collab" rel="nofollow"&gt;&lt;code&gt;collab&lt;/code&gt;&lt;/a&gt; (collaborative filtering) models. For brief examples, see the &lt;a href="https://github.com/fastai/fastai/tree/master/examples"&gt;examples&lt;/a&gt; folder; detailed examples are provided in the full &lt;a href="https://docs.fast.ai/" rel="nofollow"&gt;documentation&lt;/a&gt;. For instance, here's how to train an MNIST model using &lt;a href="https://arxiv.org/abs/1512.03385" rel="nofollow"&gt;resnet18&lt;/a&gt; (from the &lt;a href="https://github.com/fastai/fastai/blob/master/examples/vision.ipynb"&gt;vision example&lt;/a&gt;):&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; fastai.vision &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;
path &lt;span class="pl-k"&gt;=&lt;/span&gt; untar_data(&lt;span class="pl-c1"&gt;MNIST_PATH&lt;/span&gt;)
data &lt;span class="pl-k"&gt;=&lt;/span&gt; image_data_from_folder(path)
learn &lt;span class="pl-k"&gt;=&lt;/span&gt; cnn_learner(data, models.resnet18, &lt;span class="pl-v"&gt;metrics&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;accuracy)
learn.fit(&lt;span class="pl-c1"&gt;1&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-note-for-coursefastai-students" class="anchor" aria-hidden="true" href="#note-for-coursefastai-students"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Note for &lt;a href="http://course.fast.ai" rel="nofollow"&gt;course.fast.ai&lt;/a&gt; students&lt;/h2&gt;
&lt;p&gt;This document is written for &lt;code&gt;fastai v1&lt;/code&gt;, which we use for the current version the &lt;a href="http://course.fast.ai" rel="nofollow"&gt;course.fast.ai&lt;/a&gt; deep learning courses. If you're following along with a course at &lt;a href="http://course18.fast.ai" rel="nofollow"&gt;course18.fast.ai&lt;/a&gt; (i.e. the machine learning course, which isn't updated for v1) you need to use &lt;code&gt;fastai 0.7&lt;/code&gt;;  please follow the installation instructions &lt;a href="https://forums.fast.ai/t/fastai-v0-install-issues-thread/24652" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt; &lt;em&gt;fastai v1 currently supports Linux only, and requires &lt;strong&gt;PyTorch v1&lt;/strong&gt; and &lt;strong&gt;Python 3.6&lt;/strong&gt; or later. Windows support is at an experimental stage: it should work fine but it's much slower and less well tested. Since Macs don't currently have good Nvidia GPU support, we do not currently prioritize Mac development.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;fastai-1.x&lt;/code&gt; can be installed with either &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;pip&lt;/code&gt; package managers and also from source. At the moment you can't just run &lt;em&gt;install&lt;/em&gt;, since you first need to get the correct &lt;code&gt;pytorch&lt;/code&gt; version installed - thus to get &lt;code&gt;fastai-1.x&lt;/code&gt; installed choose one of the installation recipes below using your favorite python package manager. Note that &lt;strong&gt;PyTorch v1&lt;/strong&gt; and &lt;strong&gt;Python 3.6&lt;/strong&gt; are the minimal version requirements.&lt;/p&gt;
&lt;p&gt;It's highly recommended you install &lt;code&gt;fastai&lt;/code&gt; and its dependencies in a virtual environment (&lt;a href="https://conda.io/docs/user-guide/tasks/manage-environments.html" rel="nofollow"&gt;&lt;code&gt;conda&lt;/code&gt;&lt;/a&gt; or others), so that you don't interfere with system-wide python packages. It's not that you must, but if you experience problems with any dependency packages, please consider using a fresh virtual environment just for &lt;code&gt;fastai&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Starting with pytorch-1.x you no longer need to install a special pytorch-cpu version. Instead use the normal pytorch and it works with and without GPU. But &lt;a href="https://docs.fast.ai/install.html#cpu-build" rel="nofollow"&gt;you can install the cpu build too&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you experience installation problems, please read about &lt;a href="https://github.com/fastai/fastai/blob/master/README.md#installation-issues"&gt;installation issues&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are planning on using &lt;code&gt;fastai&lt;/code&gt; in the jupyter notebook environment, make sure to also install the corresponding &lt;a href="https://docs.fast.ai/install.html#jupyter-notebook-dependencies" rel="nofollow"&gt;packages&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;More advanced installation issues, such as installing only partial dependencies are covered in a dedicated &lt;a href="https://docs.fast.ai/install.html" rel="nofollow"&gt;installation doc&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-conda-install" class="anchor" aria-hidden="true" href="#conda-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Conda Install&lt;/h3&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install -c pytorch -c fastai fastai&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will install the &lt;code&gt;pytorch&lt;/code&gt; build with the latest &lt;code&gt;cudatoolkit&lt;/code&gt; version. If you need a higher or lower &lt;code&gt;CUDA XX&lt;/code&gt; build (e.g. CUDA 9.0), following the instructions &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;here&lt;/a&gt;, to install the desired &lt;code&gt;pytorch&lt;/code&gt; build.&lt;/p&gt;
&lt;p&gt;Note that JPEG decoding can be a bottleneck, particularly if you have a fast GPU. You can optionally install an optimized JPEG decoder as follows (Linux):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda uninstall --force jpeg libtiff -y
conda install -c conda-forge libjpeg-turbo pillow==6.0.0
CC=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;cc -mavx2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; pip install --no-cache-dir -U --force-reinstall --no-binary :all: --compile pillow-simd&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you only care about faster JPEG decompression, it can be &lt;code&gt;pillow&lt;/code&gt; or &lt;code&gt;pillow-simd&lt;/code&gt; in the last command above, the latter speeds up other image processing operations. For the full story see &lt;a href="https://docs.fast.ai/performance.html#faster-image-processing" rel="nofollow"&gt;Pillow-SIMD&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-pypi-install" class="anchor" aria-hidden="true" href="#pypi-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyPI Install&lt;/h3&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install fastai&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By default pip will install the latest &lt;code&gt;pytorch&lt;/code&gt; with the latest &lt;code&gt;cudatoolkit&lt;/code&gt;. If your hardware doesn't support the latest &lt;code&gt;cudatoolkit&lt;/code&gt;, follow the instructions &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;here&lt;/a&gt;, to install a &lt;code&gt;pytorch&lt;/code&gt; build that fits your hardware.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-bug-fix-install" class="anchor" aria-hidden="true" href="#bug-fix-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bug Fix Install&lt;/h3&gt;
&lt;p&gt;If a bug fix was made in git and you can't wait till a new release is made, you can install the bleeding edge version of &lt;code&gt;fastai&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install git+https://github.com/fastai/fastai.git
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-developer-install" class="anchor" aria-hidden="true" href="#developer-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Developer Install&lt;/h3&gt;
&lt;p&gt;The following instructions will result in a &lt;a href="https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs" rel="nofollow"&gt;pip editable install&lt;/a&gt;, so that you can &lt;code&gt;git pull&lt;/code&gt; at any time and your environment will automatically get the updates:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/fastai/fastai
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; fastai
tools/run-after-git-clone
pip install -e &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;.[dev]&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, you can test that the build works by starting the jupyter notebook:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;jupyter notebook&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and executing an example notebook. For example load &lt;code&gt;examples/tabular.ipynb&lt;/code&gt; and run it.&lt;/p&gt;
&lt;p&gt;Please refer to &lt;a href="https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; and &lt;a href="https://docs.fast.ai/dev/develop.html" rel="nofollow"&gt;Notes For Developers&lt;/a&gt; for more details on how to contribute to the &lt;code&gt;fastai&lt;/code&gt; project.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-building-from-source" class="anchor" aria-hidden="true" href="#building-from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building From Source&lt;/h3&gt;
&lt;p&gt;If for any reason you can't use the prepackaged packages and have to build from source, this section is for you.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To build &lt;code&gt;pytorch&lt;/code&gt; from source follow the &lt;a href="https://github.com/pytorch/pytorch#from-source"&gt;complete instructions&lt;/a&gt;. Remember to first install CUDA, CuDNN, and other required libraries as suggested - everything will be very slow without those libraries built into &lt;code&gt;pytorch&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next, you will also need to build &lt;code&gt;torchvision&lt;/code&gt; from source:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/pytorch/vision
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; vision
python setup.py install&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When both &lt;code&gt;pytorch&lt;/code&gt; and &lt;code&gt;torchvision&lt;/code&gt; are installed, first test that you can load each of these libraries:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;import torch
import torchvision&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to validate that they were installed correctly&lt;/p&gt;
&lt;p&gt;Finally, proceed with &lt;code&gt;fastai&lt;/code&gt; installation as normal, either through prepackaged pip or conda builds or installing from source ("the developer install") as explained in the sections above.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-installation-issues" class="anchor" aria-hidden="true" href="#installation-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation Issues&lt;/h2&gt;
&lt;p&gt;If the installation process fails, first make sure &lt;a href="https://github.com/fastai/fastai/blob/master/README.md#is-my-system-supported"&gt;your system is supported&lt;/a&gt;. And if the problem is still not addressed, please refer to the &lt;a href="https://docs.fast.ai/troubleshoot.html" rel="nofollow"&gt;troubleshooting document&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you encounter installation problems with conda, make sure you have the latest &lt;code&gt;conda&lt;/code&gt; client (&lt;code&gt;conda install&lt;/code&gt; will do an update too):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install conda&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-is-my-system-supported" class="anchor" aria-hidden="true" href="#is-my-system-supported"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Is My System Supported?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Python: You need to have python 3.6 or higher&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CPU or GPU&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pytorch&lt;/code&gt; binary package comes with its own CUDA, CuDNN, NCCL, MKL, and other libraries so you don't have to install system-wide NVIDIA's CUDA and related libraries if you don't need them for something else. If you have them installed already it doesn't matter which NVIDIA's CUDA version library you have installed system-wide. Your system could have CUDA 9.0 libraries, and you can still use &lt;code&gt;pytorch&lt;/code&gt; build with CUDA 10.0 libraries without any problem, since the &lt;code&gt;pytorch&lt;/code&gt; binary package is self-contained.&lt;/p&gt;
&lt;p&gt;The only requirement is that you have installed and configured the NVIDIA driver correctly. Usually you can test that by running &lt;code&gt;nvidia-smi&lt;/code&gt;. While it's possible that this application is not available on your system, it's very likely that if it doesn't work, then you don't have your NVIDIA drivers configured properly. And remember that a reboot is always required after installing NVIDIA drivers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Operating System:&lt;/p&gt;
&lt;p&gt;Since fastai-1.0 relies on pytorch-1.0, you need to be able to install pytorch-1.0 first.&lt;/p&gt;
&lt;p&gt;As of this moment pytorch.org's 1.0 version supports:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Platform&lt;/th&gt;
&lt;th&gt;GPU&lt;/th&gt;
&lt;th&gt;CPU&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;linux&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mac&lt;/td&gt;
&lt;td&gt;source&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;windows&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Legend: &lt;code&gt;binary&lt;/code&gt; = can be installed directly, &lt;code&gt;source&lt;/code&gt; = needs to be built from source.&lt;/p&gt;
&lt;p&gt;If there is no &lt;code&gt;pytorch&lt;/code&gt; preview conda or pip package available for your system, you may still be able to &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;build it from source&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How do you know which pytorch cuda version build to choose?&lt;/p&gt;
&lt;p&gt;It depends on the version of the installed NVIDIA driver. Here are the requirements for CUDA versions supported by pre-built &lt;code&gt;pytorch&lt;/code&gt; releases:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;CUDA Toolkit&lt;/th&gt;
&lt;th&gt;NVIDIA (Linux x86_64)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CUDA 10.0&lt;/td&gt;
&lt;td&gt;&amp;gt;= 410.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CUDA 9.0&lt;/td&gt;
&lt;td&gt;&amp;gt;= 384.81&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CUDA 8.0&lt;/td&gt;
&lt;td&gt;&amp;gt;= 367.48&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So if your NVIDIA driver is less than 384, then you can only use CUDA 8.0. Of course, you can upgrade your drivers to more recent ones if your card supports it.&lt;/p&gt;
&lt;p&gt;You can find a complete table with all variations &lt;a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you use NVIDIA driver 410+, you most likely want to install the &lt;code&gt;cudatoolkit=10.0&lt;/code&gt; pytorch variant, via:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install -c pytorch pytorch cudatoolkit=10.0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or if you need a lower version, use one of:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install -c pytorch pytorch cudatoolkit=8.0
conda install -c pytorch pytorch cudatoolkit=9.0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For other options refer to the complete list of &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;the available pytorch variants&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-updates" class="anchor" aria-hidden="true" href="#updates"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Updates&lt;/h2&gt;
&lt;p&gt;In order to update your environment, simply install &lt;code&gt;fastai&lt;/code&gt; in exactly the same way you did the initial installation.&lt;/p&gt;
&lt;p&gt;Top level files &lt;code&gt;environment.yml&lt;/code&gt; and &lt;code&gt;environment-cpu.yml&lt;/code&gt; belong to the old fastai (0.7). &lt;code&gt;conda env update&lt;/code&gt; is no longer the way to update your &lt;code&gt;fastai-1.x&lt;/code&gt; environment. These files remain because the fastai course-v2 video instructions rely on this setup. Eventually, once fastai course-v3 p1 and p2 will be completed, they will probably be moved to where they belong - under &lt;code&gt;old/&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-guidelines" class="anchor" aria-hidden="true" href="#contribution-guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution guidelines&lt;/h2&gt;
&lt;p&gt;If you want to contribute to &lt;code&gt;fastai&lt;/code&gt;, be sure to review the &lt;a href="https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt;. This project adheres to fastai's &lt;a href="https://github.com/fastai/fastai/blob/master/CODE-OF-CONDUCT.md"&gt;code of conduct&lt;/a&gt;. By participating, you are expected to uphold this code.&lt;/p&gt;
&lt;p&gt;We use GitHub issues for tracking requests and bugs, so please see &lt;a href="https://forums.fast.ai/" rel="nofollow"&gt;fastai forum&lt;/a&gt; for general questions and discussion.&lt;/p&gt;
&lt;p&gt;The fastai project strives to abide by generally accepted best practices in open-source software development:&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-history" class="anchor" aria-hidden="true" href="#history"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;History&lt;/h2&gt;
&lt;p&gt;A detailed history of changes can be found &lt;a href="https://github.com/fastai/fastai/blob/master/CHANGES.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-copyright" class="anchor" aria-hidden="true" href="#copyright"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Copyright&lt;/h2&gt;
&lt;p&gt;Copyright 2017 onwards, fast.ai, Inc. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this project's files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fastai</author><guid isPermaLink="false">https://github.com/fastai/fastai</guid><pubDate>Wed, 05 Feb 2020 00:17:00 GMT</pubDate></item><item><title>rlabbe/Kalman-and-Bayesian-Filters-in-Python #18 in Jupyter Notebook, This week</title><link>https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python</link><description>&lt;p&gt;&lt;i&gt;Kalman Filter book using Jupyter Notebook. Focuses on building intuition and experience, not formal proofs.  Includes Kalman filters,extended Kalman filters, unscented Kalman filters, particle filters, and more. All exercises include solutions.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-kalman-and-bayesian-filters-in-python" class="anchor" aria-hidden="true" href="#kalman-and-bayesian-filters-in-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python"&gt;Kalman and Bayesian Filters in Python&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Introductory text for Kalman and Bayesian filters. All code is written in Python, and the book itself is written using Juptyer Notebook so that you can run and modify the code in your browser. What better way to learn?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;"Kalman and Bayesian Filters in Python" looks amazing! ... your book is just what I needed&lt;/strong&gt; - Allen Downey, Professor and O'Reilly author.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thanks for all your work on publishing your introductory text on Kalman Filtering, as well as the Python Kalman Filtering libraries. Weve been using it internally to teach some key state estimation concepts to folks and its been a huge help.&lt;/strong&gt; - Sam Rodkey, SpaceX&lt;/p&gt;
&lt;p&gt;Start reading online now by clicking the binder or Azure badge below:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://beta.mybinder.org/v2/gh/rlabbe/Kalman-and-Bayesian-Filters-in-Python/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/70c5b4d050d4019f4f20b170d75679a9316ac5e5/687474703a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="http://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://notebooks.azure.com/import/gh/rlabbe/Kalman-and-Bayesian-Filters-in-Python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2c33d8af3d101ffcd6ea73a8d02290b8d829ac52/68747470733a2f2f6e6f7465626f6f6b732e617a7572652e636f6d2f6c61756e63682e706e67" data-canonical-src="https://notebooks.azure.com/launch.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/master/animations/05_dog_track.gif"&gt;&lt;img src="https://raw.githubusercontent.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/master/animations/05_dog_track.gif" alt="alt tag" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-what-are-kalman-and-bayesian-filters" class="anchor" aria-hidden="true" href="#what-are-kalman-and-bayesian-filters"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What are Kalman and Bayesian Filters?&lt;/h2&gt;
&lt;p&gt;Sensors are noisy. The world is full of data and events that we want to measure and track, but we cannot rely on sensors to give us perfect information. The GPS in my car reports altitude. Each time I pass the same point in the road it reports a slightly different altitude. My kitchen scale gives me different readings if I weigh the same object twice.&lt;/p&gt;
&lt;p&gt;In simple cases the solution is obvious. If my scale gives slightly different readings I can just take a few readings and average them. Or I can replace it with a more accurate scale. But what do we do when the sensor is very noisy, or the environment makes data collection difficult? We may be trying to track the movement of a low flying aircraft. We may want to create an autopilot for a drone, or ensure that our farm tractor seeded the entire field. I work on computer vision, and I need to track moving objects in images, and the computer vision algorithms create very noisy and unreliable results.&lt;/p&gt;
&lt;p&gt;This book teaches you how to solve these sorts of filtering problems. I use many different algorithms, but they are all based on Bayesian probability. In simple terms Bayesian probability determines what is likely to be true based on past information.&lt;/p&gt;
&lt;p&gt;If I asked you the heading of my car at this moment you would have no idea. You'd proffer a number between 1 and 360 degrees, and have a 1 in 360 chance of being right. Now suppose I told you that 2 seconds ago its heading was 243. In 2 seconds my car could not turn very far so you could make a far more accurate prediction. You are using past information to more accurately infer information about the present or future.&lt;/p&gt;
&lt;p&gt;The world is also noisy. That prediction helps you make a better estimate, but it also subject to noise. I may have just braked for a dog or swerved around a pothole. Strong winds and ice on the road are external influences on the path of my car. In control literature we call this noise though you may not think of it that way.&lt;/p&gt;
&lt;p&gt;There is more to Bayesian probability, but you have the main idea. Knowledge is uncertain, and we alter our beliefs based on the strength of the evidence. Kalman and Bayesian filters blend our noisy and limited knowledge of how a system behaves with the noisy and limited sensor readings to produce the best possible estimate of the state of the system. Our principle is to never discard information.&lt;/p&gt;
&lt;p&gt;Say we are tracking an object and a sensor reports that it suddenly changed direction. Did it really turn, or is the data noisy? It depends. If this is a jet fighter we'd be very inclined to believe the report of a sudden maneuver. If it is a freight train on a straight track we would discount it. We'd further modify our belief depending on how accurate the sensor is. Our beliefs depend on the past and on our knowledge of the system we are tracking and on the characteristics of the sensors.&lt;/p&gt;
&lt;p&gt;The Kalman filter was invented by Rudolf Emil Klmn to solve this sort of problem in a mathematically optimal way. Its first use was on the Apollo missions to the moon, and since then it has been used in an enormous variety of domains. There are Kalman filters in aircraft, on submarines, and on cruise missiles. Wall street uses them to track the market. They are used in robots, in IoT (Internet of Things) sensors, and in laboratory instruments. Chemical plants use them to control and monitor reactions. They are used to perform medical imaging and to remove noise from cardiac signals. If it involves a sensor and/or time-series data, a Kalman filter or a close relative to the Kalman filter is usually involved.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-motivation" class="anchor" aria-hidden="true" href="#motivation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motivation&lt;/h2&gt;
&lt;p&gt;The motivation for this book came out of my desire for a gentle introduction to Kalman filtering. I'm a software engineer that spent almost two decades in the avionics field, and so I have always been 'bumping elbows' with the Kalman filter, but never implemented one myself. As I moved into solving tracking problems with computer vision the need became urgent. There are classic textbooks in the field, such as Grewal and Andrew's excellent &lt;em&gt;Kalman Filtering&lt;/em&gt;. But sitting down and trying to read many of these books is a dismal experience if you do not have the required background. Typically the first few chapters fly through several years of undergraduate math, blithely referring you to textbooks on topics such as It calculus, and present an entire semester's worth of statistics in a few brief paragraphs. They are good texts for an upper undergraduate course, and an invaluable reference to researchers and professionals, but the going is truly difficult for the more casual reader. Symbology is introduced without explanation, different texts use different terms and variables for the same concept, and the books are almost devoid of examples or worked problems. I often found myself able to parse the words and comprehend the mathematics of a definition, but had no idea as to what real world phenomena they describe. "But what does that &lt;em&gt;mean?&lt;/em&gt;" was my repeated thought.&lt;/p&gt;
&lt;p&gt;However, as I began to finally understand the Kalman filter I realized the underlying concepts are quite straightforward. A few simple probability rules, some intuition about how we integrate disparate knowledge to explain events in our everyday life and the core concepts of the Kalman filter are accessible. Kalman filters have a reputation for difficulty, but shorn of much of the formal terminology the beauty of the subject and of their math became clear to me, and I fell in love with the topic.&lt;/p&gt;
&lt;p&gt;As I began to understand the math and theory more difficulties present themselves. A book or paper's author makes some statement of fact and presents a graph as proof.  Unfortunately, why the statement is true is not clear to me, nor is the method for making that plot obvious. Or maybe I wonder "is this true if R=0?"  Or the author provides pseudocode at such a high level that the implementation is not obvious. Some books offer Matlab code, but I do not have a license to that expensive package. Finally, many books end each chapter with many useful exercises. Exercises which you need to understand if you want to implement Kalman filters for yourself, but exercises with no answers. If you are using the book in a classroom, perhaps this is okay, but it is terrible for the independent reader. I loathe that an author withholds information from me, presumably to avoid 'cheating' by the student in the classroom.&lt;/p&gt;
&lt;p&gt;From my point of view none of this necessary. Certainly if you are designing a Kalman filter for a aircraft or missile you must thoroughly master of all of the mathematics and topics in a typical Kalman filter textbook. I just want to track an image on a screen, or write some code for an Arduino project. I want to know how the plots in the book are made, and chose different parameters than the author chose. I want to run simulations. I want to inject more noise in the signal and see how a filter performs. There are thousands of opportunities for using Kalman filters in everyday code, and yet this fairly straightforward topic is the provenance of rocket scientists and academics.&lt;/p&gt;
&lt;p&gt;I wrote this book to address all of those needs. This is not the book for you if you program navigation computers for Boeing or design radars for Raytheon. Go get an advanced degree at Georgia Tech, UW, or the like, because you'll need it. This book is for the hobbiest, the curious, and the working engineer that needs to filter or smooth data.&lt;/p&gt;
&lt;p&gt;This book is interactive. While you can read it online as static content, I urge you to use it as intended. It is written using Jupyter Notebook, which allows me to combine text, math, Python, and Python output in one place. Every plot, every piece of data in this book is generated from Python that is available to you right inside the notebook. Want to double the value of a parameter? Click on the Python cell, change the parameter's value, and click 'Run'. A new plot or printed output will appear in the book.&lt;/p&gt;
&lt;p&gt;This book has exercises, but it also has the answers. I trust you. If you just need an answer, go ahead and read the answer. If you want to internalize this knowledge, try to implement the exercise before you read the answer.&lt;/p&gt;
&lt;p&gt;This book has supporting libraries for computing statistics, plotting various things related to filters, and for the various filters that we cover. This does require a strong caveat; most of the code is written for didactic purposes. It is rare that I chose the most efficient solution (which often obscures the intent of the code), and in the first parts of the book I did not concern myself with numerical stability. This is important to understand - Kalman filters in aircraft are carefully designed and implemented to be numerically stable; the naive implementation is not stable in many cases. If you are serious about Kalman filters this book will not be the last book you need. My intention is to introduce you to the concepts and mathematics, and to get you to the point where the textbooks are approachable.&lt;/p&gt;
&lt;p&gt;Finally, this book is free. The cost for the books required to learn Kalman filtering is somewhat prohibitive even for a Silicon Valley engineer like myself; I cannot believe they are within the reach of someone in a depressed economy, or a financially struggling student. I have gained so much from free software like Python, and free books like those from Allen B. Downey &lt;a href="http://www.greenteapress.com/" rel="nofollow"&gt;here&lt;/a&gt;. It's time to repay that. So, the book is free, it is hosted on free servers, and it uses only free and open software such as IPython and mathjax to create the book.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-reading-online" class="anchor" aria-hidden="true" href="#reading-online"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reading Online&lt;/h2&gt;
&lt;p&gt;The book is written as a collection of Jupyter Notebooks, an interactive, browser based system that allows you to combine text, Python, and math into your browser. There are multiple ways to read these online, listed below.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-binder" class="anchor" aria-hidden="true" href="#binder"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;binder&lt;/h3&gt;
&lt;p&gt;binder serves interactive notebooks online, so you can run the code and change the code within your browser without downloading the book or installing Jupyter.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://beta.mybinder.org/v2/gh/rlabbe/Kalman-and-Bayesian-Filters-in-Python/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/70c5b4d050d4019f4f20b170d75679a9316ac5e5/687474703a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="http://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-nbviewer" class="anchor" aria-hidden="true" href="#nbviewer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;nbviewer&lt;/h3&gt;
&lt;p&gt;The website &lt;a href="http://nbviewer.org" rel="nofollow"&gt;http://nbviewer.org&lt;/a&gt; provides an Jupyter Notebook server that renders notebooks stored at github (or elsewhere). The rendering is done in real time when you load the book. You may use &lt;a href="http://nbviewer.ipython.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/table_of_contents.ipynb" rel="nofollow"&gt;&lt;em&gt;this nbviewer link&lt;/em&gt;&lt;/a&gt; to access my book via nbviewer. If you read my book today, and then I make a change tomorrow, when you go back tomorrow you will see that change. Notebooks are rendered statically - you can read them, but not modify or run the code.&lt;/p&gt;
&lt;p&gt;nbviewer seems to lag the checked in version by a few days, so you might not be reading the most recent content.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-github" class="anchor" aria-hidden="true" href="#github"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GitHub&lt;/h3&gt;
&lt;p&gt;GitHub is able to render the notebooks directly. The quickest way to view a notebook is to just click on them above. However, it renders the math incorrectly, and I cannot recommend using it if you are doing more than just dipping into the book.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pdf-version" class="anchor" aria-hidden="true" href="#pdf-version"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PDF Version&lt;/h2&gt;
&lt;p&gt;A PDF version of the book is available &lt;a href="https://drive.google.com/open?id=0By_SW19c1BfhSVFzNHc0SjduNzg" rel="nofollow"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The PDF will usually lag behind what is in github as I don't update it for every minor check in.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-downloading-and-running-the-book" class="anchor" aria-hidden="true" href="#downloading-and-running-the-book"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Downloading and Running the Book&lt;/h2&gt;
&lt;p&gt;However, this book is intended to be interactive and I recommend using it in that form. It's a little more effort to set up, but worth it. If you install IPython and some supporting libraries on your computer and then clone this book you will be able to run all of the code in the book yourself. You can perform experiments, see how filters react to different data, see how different filters react to the same data, and so on. I find this sort of immediate feedback both vital and invigorating. You do not have to wonder "what happens if". Try it and see!&lt;/p&gt;
&lt;p&gt;The book and supporting software can be downloaded from GitHub by running this command on  the command line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone --depth=1 https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python.git
pip install filterpy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Instructions for installation of the IPython ecosystem can be found in the Installation appendix, found &lt;a href="http://nbviewer.ipython.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/Appendix-A-Installation.ipynb" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once the software is installed you can navigate to the installation directory and run Juptyer notebook with the command line instruction&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will open a browser window showing the contents of the base directory. The book is organized into chapters. To read Chapter 2, click on the link for chapter 2. This will cause the browser to open that subdirectory. In each subdirectory there will be one or more IPython Notebooks (all notebooks have a .ipynb file extension). The chapter contents are in the notebook with the same name as the chapter name. There are sometimes supporting notebooks for doing things like generating animations that are displayed in the chapter. These are not intended to be read by the end user, but of course if you are curious as to how an animation is made go ahead and take a look.&lt;/p&gt;
&lt;p&gt;This is admittedly a somewhat cumbersome interface to a book; I am following in the footsteps of several other projects that are somewhat repurposing Jupyter Notebook to generate entire books. I feel the slight annoyances have a huge payoff - instead of having to download a separate code base and run it in an IDE while you try to read a book, all of the code and text is in one place. If you want to alter the code, you may do so and immediately see the effects of your change. If you find a bug, you can make a fix, and push it back to my repository so that everyone in the world benefits. And, of course, you will never encounter a problem I face all the time with traditional books - the book and the code are out of sync with each other, and you are left scratching your head as to which source to trust.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-companion-software" class="anchor" aria-hidden="true" href="#companion-software"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Companion Software&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://pypi.python.org/pypi/filterpy" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2514efa585c6a295744d54c87effb293c6ffee51/687474703a2f2f696d672e736869656c64732e696f2f707970692f762f66696c74657270792e737667" alt="Latest Version" data-canonical-src="http://img.shields.io/pypi/v/filterpy.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I wrote an open source Bayesian filtering Python library called &lt;strong&gt;FilterPy&lt;/strong&gt;. I have made the project available on PyPi, the Python Package Index.  To install from PyPi, at the command line issue the command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install filterpy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you do not have pip, you may follow the instructions here: &lt;a href="https://pip.pypa.io/en/latest/installing.html" rel="nofollow"&gt;https://pip.pypa.io/en/latest/installing.html&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All of the filters used in this book as well as others not in this book are implemented in my Python library FilterPy, available &lt;a href="https://github.com/rlabbe/filterpy"&gt;here&lt;/a&gt;. You do not need to download or install this to read the book, but you will likely want to use this library to write your own filters. It includes Kalman filters, Fading Memory filters, H infinity filters, Extended and Unscented filters, least square filters, and many more.  It also includes helper routines that simplify the designing the matrices used by some of the filters, and other code such as Kalman based smoothers.&lt;/p&gt;
&lt;p&gt;FilterPy is hosted github at (&lt;a href="https://github.com/rlabbe/filterpy"&gt;https://github.com/rlabbe/filterpy&lt;/a&gt;).  If you want the bleading edge release you will want to grab a copy from github, and follow your Python installation's instructions for adding it to the Python search path. This might expose you to some instability since you might not get a tested release, but as a benefit you will also get all of the test scripts used to test the library. You can examine these scripts to see many examples of writing and running filters while not in the Jupyter Notebook environment.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-alternative-way-of-running-the-book-in-conda-environment" class="anchor" aria-hidden="true" href="#alternative-way-of-running-the-book-in-conda-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Alternative Way of Running the Book in Conda environment&lt;/h2&gt;
&lt;p&gt;If you have conda or miniconda installed, you can create environment by&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda env update -f environment.yml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and use&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;source activate kf_bf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;source deactivate kf_bf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to activate and deactivate the environment.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-issues-or-questions" class="anchor" aria-hidden="true" href="#issues-or-questions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Issues or Questions&lt;/h2&gt;
&lt;p&gt;If you have comments, you can write an issue at GitHub so that everyone can read it along with my response. Please don't view it as a way to report bugs only. Alternatively I've created a gitter room for more informal discussion. &lt;a href="https://gitter.im/rlabbe/Kalman-and-Bayesian-Filters-in-Python?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" alt="Join the chat at https://gitter.im/rlabbe/Kalman-and-Bayesian-Filters-in-Python" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://creativecommons.org/licenses/by/4.0/" rel="nofollow"&gt;&lt;img alt="Creative Commons License" src="https://camo.githubusercontent.com/005cfe27b7c4520ac0d6b607d6a7e33f5ad4eb6e/68747470733a2f2f692e6372656174697665636f6d6d6f6e732e6f72672f6c2f62792f342e302f38387833312e706e67" data-canonical-src="https://i.creativecommons.org/l/by/4.0/88x31.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;br&gt;&lt;span&gt;Kalman and Bayesian Filters in Python&lt;/span&gt; by &lt;a href="https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python"&gt;Roger R. Labbe&lt;/a&gt; is licensed under a &lt;a href="http://creativecommons.org/licenses/by/4.0/" rel="nofollow"&gt;Creative Commons Attribution 4.0 International License&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All software in this book, software that supports this book (such as in the the code directory) or used in the generation of the book (in the pdf directory) that is contained in this repository is licensed under the following MIT license:&lt;/p&gt;
&lt;p&gt;The MIT License (MIT)&lt;/p&gt;
&lt;p&gt;Copyright (c) 2015 Roger R. Labbe Jr&lt;/p&gt;
&lt;p&gt;Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:&lt;/p&gt;
&lt;p&gt;The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.&lt;/p&gt;
&lt;p&gt;THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.TION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h2&gt;
&lt;p&gt;rlabbejr at gmail.com&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>rlabbe</author><guid isPermaLink="false">https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python</guid><pubDate>Wed, 05 Feb 2020 00:18:00 GMT</pubDate></item><item><title>elastic/examples #19 in Jupyter Notebook, This week</title><link>https://github.com/elastic/examples</link><description>&lt;p&gt;&lt;i&gt;Home for Elasticsearch examples available to everyone. It's a great way to get started.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h1&gt;
&lt;p&gt;This is a collection of examples to help you get familiar with the Elastic Stack and X-Pack. Each example folder includes a README with detailed instructions for getting up and running with the  particular example. The following information pertains to the &lt;a href="https://github.com/elastic/examples"&gt;examples&lt;/a&gt; repo as a whole.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#quick-start"&gt;Quick start&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#example-catalog"&gt;Example catalog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick start&lt;/h3&gt;
&lt;p&gt;You have a few options to get started with the examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you want to try them all, you can &lt;a href="https://github.com/elastic/examples/archive/master.zip"&gt;download the entire repo &lt;/a&gt;. Or, if you are familiar with Git, you can &lt;a href="https://github.com/elastic/examples.git"&gt;clone the repo&lt;/a&gt;. Then, simply follow the instructions in the individual README of the examples you're interested in to get started.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you are only interested in a specific example or two, you can download the contents of just those examples - follow instructions in the individual READMEs OR you can use some of the &lt;a href="http://stackoverflow.com/questions/7106012/download-a-single-folder-or-directory-from-a-github-repo" rel="nofollow"&gt;options mentioned here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h3&gt;
&lt;p&gt;See &lt;a href="https://github.com/elastic/examples/blob/master/CONTRIBUTING.md"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-example-catalog" class="anchor" aria-hidden="true" href="#example-catalog"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example catalog&lt;/h3&gt;
&lt;p&gt;Below is the list of examples available in this repo:&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-common-data-formats" class="anchor" aria-hidden="true" href="#common-data-formats"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Common Data Formats&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Common%20Data%20Formats/apache_logs"&gt;Apache Logs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Common%20Data%20Formats/nginx_logs"&gt;NGINX Logs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Common%20Data%20Formats/nginx_json_logs"&gt;NGINX JSON Logs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Common%20Data%20Formats/nginx_json_plus_logs"&gt;NGINX JSON Plus Logs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Common%20Data%20Formats/twitter"&gt;Twitter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Common%20Data%20Formats/cef"&gt;CEF&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-exploring-public-datasets" class="anchor" aria-hidden="true" href="#exploring-public-datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Exploring Public Datasets&lt;/h4&gt;
&lt;p&gt;Examples using the Elastic Stack for analyzing public dataset.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Exploring%20Public%20Datasets/donorschoose"&gt;DonorsChoose.org donations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Exploring%20Public%20Datasets/earthquakes"&gt;NCEDC earthquakes data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Exploring%20Public%20Datasets/nyc_traffic_accidents"&gt;NYC traffic accidents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Exploring%20Public%20Datasets/usfec"&gt;US FEC campaign contributions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Exploring%20Public%20Datasets/cdc_nutrition_exercise_patterns"&gt;CDC health behavior survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Exploring%20Public%20Datasets/nyc_restaurants"&gt;NYC restaurant health grades&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Exploring%20Public%20Datasets/nhl"&gt;NHL Match Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-getting-started-with-graph-exploration" class="anchor" aria-hidden="true" href="#getting-started-with-graph-exploration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started with Graph exploration&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Graph/apache_logs_security_analysis"&gt;Exploring attack vectors in Apache logs using Graph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Graph/movie_recommendations"&gt;Powering recommendation using Graph&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-alerting-on-elastic-stack" class="anchor" aria-hidden="true" href="#alerting-on-elastic-stack"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Alerting on Elastic Stack&lt;/h4&gt;
&lt;p&gt;X-Pack lets you set up watches (or rules) to detect and alert on changes in your Elasticsearch data. Below is a list of examples watches that configured to detect and alert on a few common scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/cpu_iowait_hosts"&gt;High I/O wait on CPU&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/errors_in_logs"&gt;Critical error  in logs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/filesystem_usage"&gt;High filesystem usage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/lateral_movement_in_user_comm"&gt;Lateral movement in user communication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/ml_examples"&gt;Alerting on Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/monitoring_cluster_health"&gt;Monitoring Cluster Health&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/monitoring_free_disk_space"&gt;Monitoring Free Disk Space&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/new_process_started"&gt;New process started on hosts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/port_scan"&gt;Port scan detected&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/system_fails_to_provide_data"&gt;Interrupted log flow from hosts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/twitter_trends"&gt;Trending hashtag on twitter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/unexpected_account_activity"&gt;Unexpected account activity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Alerting/watcher_dashboard"&gt;Watch history dashboard&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-machine-learning" class="anchor" aria-hidden="true" href="#machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine learning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Machine%20Learning/Getting%20Started%20Examples"&gt;Getting started tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Machine%20Learning/IT%20Operations%20Recipes"&gt;IT operations recipes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Machine%20Learning/Security%20Analytics%20Recipes"&gt;Security analytics recipes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Machine%20Learning/Business%20Metrics%20Recipes"&gt;Business metrics recipes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-search--api-examples" class="anchor" aria-hidden="true" href="#search--api-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Search &amp;amp; API Examples&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Search/recipe_search_java"&gt;Recipe Search with Java&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Search/recipe_search_php"&gt;Recipe Search with PHP&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-security-analytics" class="anchor" aria-hidden="true" href="#security-analytics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Security Analytics&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Security%20Analytics/auditd_analysis"&gt;Audit Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Security%20Analytics/cef_with_kafka"&gt;CEF with Kafka&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Security%20Analytics/dns_tunnel_detection"&gt;DNS Tunnel Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Security%20Analytics/malware_analysis"&gt;Malware Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Security%20Analytics/ssh_analysis"&gt;SSH Analysis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-miscellaneous" class="anchor" aria-hidden="true" href="#miscellaneous"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Miscellaneous&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Miscellaneous/custom_tile_maps"&gt;Custom Tile Maps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Miscellaneous/kafka_monitoring"&gt;Monitoring Kafka&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Miscellaneous/kibana_geoserver"&gt;Kibana with Geoserver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/examples/tree/master/Miscellaneous/docker"&gt;The ElasticStack on Docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>elastic</author><guid isPermaLink="false">https://github.com/elastic/examples</guid><pubDate>Wed, 05 Feb 2020 00:19:00 GMT</pubDate></item><item><title>codebasics/py #20 in Jupyter Notebook, This week</title><link>https://github.com/codebasics/py</link><description>&lt;p&gt;&lt;i&gt;Repository to store sample python programs for python learning&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-py" class="anchor" aria-hidden="true" href="#py"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;py&lt;/h1&gt;
&lt;p&gt;Repository to store sample python programs for python learning
Youtube channel &lt;a href="https://www.youtube.com/channel/UCh9nVJoWXmFb7sLApWGcLPQ" rel="nofollow"&gt;https://www.youtube.com/channel/UCh9nVJoWXmFb7sLApWGcLPQ&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>codebasics</author><guid isPermaLink="false">https://github.com/codebasics/py</guid><pubDate>Wed, 05 Feb 2020 00:20:00 GMT</pubDate></item><item><title>aimacode/aima-python #21 in Jupyter Notebook, This week</title><link>https://github.com/aimacode/aima-python</link><description>&lt;p&gt;&lt;i&gt;Python implementation of algorithms from Russell And Norvig's "Artificial Intelligence - A Modern Approach"&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;div align="center"&gt;
  &lt;a href="http://aima.cs.berkeley.edu/" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/aimacode/aima-python/master/images/aima_logo.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;
&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-aima-python--" class="anchor" aria-hidden="true" href="#aima-python--"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;aima-python&lt;/code&gt; &lt;a href="https://travis-ci.org/aimacode/aima-python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/01177a7ca5a96309e258148841f9c5c82ff80993/68747470733a2f2f7472617669732d63692e6f72672f61696d61636f64652f61696d612d707974686f6e2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/aimacode/aima-python.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="http://mybinder.org/repo/aimacode/aima-python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/70c5b4d050d4019f4f20b170d75679a9316ac5e5/687474703a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="http://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Python code for the book &lt;em&gt;&lt;a href="http://aima.cs.berkeley.edu" rel="nofollow"&gt;Artificial Intelligence: A Modern Approach&lt;/a&gt;.&lt;/em&gt; You can use this in conjunction with a course on AI, or for study on your own. We're looking for &lt;a href="https://github.com/aimacode/aima-python/blob/master/CONTRIBUTING.md"&gt;solid contributors&lt;/a&gt; to help.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-structure-of-the-project" class="anchor" aria-hidden="true" href="#structure-of-the-project"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Structure of the Project&lt;/h2&gt;
&lt;p&gt;When complete, this project will have Python implementations for all the pseudocode algorithms in the book, as well as tests and examples of use. For each major topic, such as &lt;code&gt;nlp&lt;/code&gt; (natural language processing), we provide the following  files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;nlp.py&lt;/code&gt;: Implementations of all the pseudocode algorithms, and necessary support functions/classes/data.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tests/test_nlp.py&lt;/code&gt;: A lightweight test suite, using &lt;code&gt;assert&lt;/code&gt; statements, designed for use with &lt;a href="http://pytest.org/latest/" rel="nofollow"&gt;&lt;code&gt;py.test&lt;/code&gt;&lt;/a&gt;, but also usable on their own.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nlp.ipynb&lt;/code&gt;: A Jupyter (IPython) notebook that explains and gives examples of how to use the code.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nlp_apps.ipynb&lt;/code&gt;: A Jupyter notebook that gives example applications of the code.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-python-34-and-up" class="anchor" aria-hidden="true" href="#python-34-and-up"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python 3.4 and up&lt;/h2&gt;
&lt;p&gt;This code requires Python 3.4 or later, and does not run in Python 2. You can &lt;a href="https://www.python.org/downloads" rel="nofollow"&gt;install Python&lt;/a&gt; or use a browser-based Python interpreter such as &lt;a href="https://repl.it/languages/python3" rel="nofollow"&gt;repl.it&lt;/a&gt;.
You can run the code in an IDE, or from the command line with &lt;code&gt;python -i filename.py&lt;/code&gt; where the &lt;code&gt;-i&lt;/code&gt; option puts you in an interactive loop where you can run Python functions. All notebooks are available in a &lt;a href="http://mybinder.org/repo/aimacode/aima-python" rel="nofollow"&gt;binder environment&lt;/a&gt;. Alternatively, visit &lt;a href="http://jupyter.org/" rel="nofollow"&gt;jupyter.org&lt;/a&gt; for instructions on setting up your own Jupyter notebook environment.&lt;/p&gt;
&lt;p&gt;There is a sibling &lt;a href="https://github.com/rajatjain1997/aima-docker"&gt;aima-docker&lt;/a&gt; project that shows you how to use docker containers to run more complex problems in more complex software environments.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation-guide" class="anchor" aria-hidden="true" href="#installation-guide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation Guide&lt;/h2&gt;
&lt;p&gt;To download the repository:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git clone https://github.com/aimacode/aima-python.git&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Then you need to install the basic dependencies to run the project on your system:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd aima-python
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You also need to fetch the datasets from the &lt;a href="https://github.com/aimacode/aima-data"&gt;&lt;code&gt;aima-data&lt;/code&gt;&lt;/a&gt; repository:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git submodule init
git submodule update
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wait for the datasets to download, it may take a while. Once they are downloaded, you need to install &lt;code&gt;pytest&lt;/code&gt;, so that you can run the test suite:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pip install pytest&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Then to run the tests:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py.test&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And you are good to go!&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-index-of-algorithms" class="anchor" aria-hidden="true" href="#index-of-algorithms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Index of Algorithms&lt;/h1&gt;
&lt;p&gt;Here is a table of algorithms, the figure, name of the algorithm in the book and in the repository, and the file where they are implemented in the repository. This chart was made for the third edition of the book and is being updated for the upcoming fourth edition. Empty implementations are a good place for contributors to look for an issue. The &lt;a href="https://github.com/aimacode/aima-pseudocode"&gt;aima-pseudocode&lt;/a&gt; project describes all the algorithms from the book. An asterisk next to the file name denotes the algorithm is not fully implemented. Another great place for contributors to start is by adding tests and writing on the notebooks. You can see which algorithms have tests and notebook sections below. If the algorithm you want to work on is covered, don't worry! You can still add more tests and provide some examples of use in the notebook!&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;strong&gt;Figure&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;Name (in 3&lt;sup&gt;rd&lt;/sup&gt; edition)&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;Name (in repository)&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;File&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;Tests&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;Notebook&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;Random-Vacuum-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;RandomVacuumAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;Model-Based-Vacuum-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;ModelBasedVacuumAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.1&lt;/td&gt;
&lt;td align="left"&gt;Environment&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Environment&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.1&lt;/td&gt;
&lt;td align="left"&gt;Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Agent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.3&lt;/td&gt;
&lt;td align="left"&gt;Table-Driven-Vacuum-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;TableDrivenVacuumAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.7&lt;/td&gt;
&lt;td align="left"&gt;Table-Driven-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;TableDrivenAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.8&lt;/td&gt;
&lt;td align="left"&gt;Reflex-Vacuum-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;ReflexVacuumAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.10&lt;/td&gt;
&lt;td align="left"&gt;Simple-Reflex-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;SimpleReflexAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2.12&lt;/td&gt;
&lt;td align="left"&gt;Model-Based-Reflex-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;ReflexAgentWithState&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/agents.py"&gt;&lt;code&gt;agents.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;Problem&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Problem&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;Node&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Node&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;Queue&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Queue&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/utils.py"&gt;&lt;code&gt;utils.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;No Need&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.1&lt;/td&gt;
&lt;td align="left"&gt;Simple-Problem-Solving-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;SimpleProblemSolvingAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.2&lt;/td&gt;
&lt;td align="left"&gt;Romania&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;romania&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.7&lt;/td&gt;
&lt;td align="left"&gt;Tree-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;depth/breadth_first_tree_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.7&lt;/td&gt;
&lt;td align="left"&gt;Graph-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;depth/breadth_first_graph_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.11&lt;/td&gt;
&lt;td align="left"&gt;Breadth-First-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;breadth_first_graph_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.14&lt;/td&gt;
&lt;td align="left"&gt;Uniform-Cost-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;uniform_cost_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.17&lt;/td&gt;
&lt;td align="left"&gt;Depth-Limited-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;depth_limited_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.18&lt;/td&gt;
&lt;td align="left"&gt;Iterative-Deepening-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;iterative_deepening_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.22&lt;/td&gt;
&lt;td align="left"&gt;Best-First-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;best_first_graph_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.24&lt;/td&gt;
&lt;td align="left"&gt;A*-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;astar_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.26&lt;/td&gt;
&lt;td align="left"&gt;Recursive-Best-First-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;recursive_best_first_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.2&lt;/td&gt;
&lt;td align="left"&gt;Hill-Climbing&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;hill_climbing&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.5&lt;/td&gt;
&lt;td align="left"&gt;Simulated-Annealing&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;simulated_annealing&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.8&lt;/td&gt;
&lt;td align="left"&gt;Genetic-Algorithm&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;genetic_algorithm&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.11&lt;/td&gt;
&lt;td align="left"&gt;And-Or-Graph-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;and_or_graph_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.21&lt;/td&gt;
&lt;td align="left"&gt;Online-DFS-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;online_dfs_agent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.24&lt;/td&gt;
&lt;td align="left"&gt;LRTA*-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;LRTAStarAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;5.3&lt;/td&gt;
&lt;td align="left"&gt;Minimax-Decision&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;minimax_decision&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/games.py"&gt;&lt;code&gt;games.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;5.7&lt;/td&gt;
&lt;td align="left"&gt;Alpha-Beta-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;alphabeta_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/games.py"&gt;&lt;code&gt;games.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;6&lt;/td&gt;
&lt;td align="left"&gt;CSP&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;CSP&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/csp.py"&gt;&lt;code&gt;csp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;6.3&lt;/td&gt;
&lt;td align="left"&gt;AC-3&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;AC3&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/csp.py"&gt;&lt;code&gt;csp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;6.5&lt;/td&gt;
&lt;td align="left"&gt;Backtracking-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;backtracking_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/csp.py"&gt;&lt;code&gt;csp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;6.8&lt;/td&gt;
&lt;td align="left"&gt;Min-Conflicts&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;min_conflicts&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/csp.py"&gt;&lt;code&gt;csp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;6.11&lt;/td&gt;
&lt;td align="left"&gt;Tree-CSP-Solver&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;tree_csp_solver&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/csp.py"&gt;&lt;code&gt;csp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7&lt;/td&gt;
&lt;td align="left"&gt;KB&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;KB&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.1&lt;/td&gt;
&lt;td align="left"&gt;KB-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;KB_AgentProgram&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.7&lt;/td&gt;
&lt;td align="left"&gt;Propositional Logic Sentence&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Expr&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/utils.py"&gt;&lt;code&gt;utils.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.10&lt;/td&gt;
&lt;td align="left"&gt;TT-Entails&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;tt_entails&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.12&lt;/td&gt;
&lt;td align="left"&gt;PL-Resolution&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;pl_resolution&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.14&lt;/td&gt;
&lt;td align="left"&gt;Convert to CNF&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;to_cnf&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.15&lt;/td&gt;
&lt;td align="left"&gt;PL-FC-Entails?&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;pl_fc_entails&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.17&lt;/td&gt;
&lt;td align="left"&gt;DPLL-Satisfiable?&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;dpll_satisfiable&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.18&lt;/td&gt;
&lt;td align="left"&gt;WalkSAT&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;WalkSAT&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.20&lt;/td&gt;
&lt;td align="left"&gt;Hybrid-Wumpus-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;HybridWumpusAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.22&lt;/td&gt;
&lt;td align="left"&gt;SATPlan&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;SAT_plan&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;9&lt;/td&gt;
&lt;td align="left"&gt;Subst&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;subst&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;9.1&lt;/td&gt;
&lt;td align="left"&gt;Unify&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;unify&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;9.3&lt;/td&gt;
&lt;td align="left"&gt;FOL-FC-Ask&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;fol_fc_ask&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;9.6&lt;/td&gt;
&lt;td align="left"&gt;FOL-BC-Ask&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;fol_bc_ask&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;10.1&lt;/td&gt;
&lt;td align="left"&gt;Air-Cargo-problem&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;air_cargo&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;10.2&lt;/td&gt;
&lt;td align="left"&gt;Spare-Tire-Problem&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;spare_tire&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;10.3&lt;/td&gt;
&lt;td align="left"&gt;Three-Block-Tower&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;three_block_tower&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;10.7&lt;/td&gt;
&lt;td align="left"&gt;Cake-Problem&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;have_cake_and_eat_cake_too&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;10.9&lt;/td&gt;
&lt;td align="left"&gt;Graphplan&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;GraphPlan&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;10.13&lt;/td&gt;
&lt;td align="left"&gt;Partial-Order-Planner&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;PartialOrderPlanner&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;11.1&lt;/td&gt;
&lt;td align="left"&gt;Job-Shop-Problem-With-Resources&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;job_shop_problem&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;11.5&lt;/td&gt;
&lt;td align="left"&gt;Hierarchical-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;hierarchical_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;11.8&lt;/td&gt;
&lt;td align="left"&gt;Angelic-Search&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;angelic_search&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;11.10&lt;/td&gt;
&lt;td align="left"&gt;Doubles-tennis&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;double_tennis_problem&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/planning.py"&gt;&lt;code&gt;planning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;13&lt;/td&gt;
&lt;td align="left"&gt;Discrete Probability Distribution&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;ProbDist&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;13.1&lt;/td&gt;
&lt;td align="left"&gt;DT-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;DTAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;14.9&lt;/td&gt;
&lt;td align="left"&gt;Enumeration-Ask&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;enumeration_ask&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;14.11&lt;/td&gt;
&lt;td align="left"&gt;Elimination-Ask&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;elimination_ask&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;14.13&lt;/td&gt;
&lt;td align="left"&gt;Prior-Sample&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;prior_sample&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;14.14&lt;/td&gt;
&lt;td align="left"&gt;Rejection-Sampling&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;rejection_sampling&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;14.15&lt;/td&gt;
&lt;td align="left"&gt;Likelihood-Weighting&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;likelihood_weighting&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;14.16&lt;/td&gt;
&lt;td align="left"&gt;Gibbs-Ask&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;gibbs_ask&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;15.4&lt;/td&gt;
&lt;td align="left"&gt;Forward-Backward&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;forward_backward&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;15.6&lt;/td&gt;
&lt;td align="left"&gt;Fixed-Lag-Smoothing&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;fixed_lag_smoothing&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;15.17&lt;/td&gt;
&lt;td align="left"&gt;Particle-Filtering&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;particle_filtering&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;16.9&lt;/td&gt;
&lt;td align="left"&gt;Information-Gathering-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;InformationGatheringAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;17.4&lt;/td&gt;
&lt;td align="left"&gt;Value-Iteration&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;value_iteration&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/mdp.py"&gt;&lt;code&gt;mdp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;17.7&lt;/td&gt;
&lt;td align="left"&gt;Policy-Iteration&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;policy_iteration&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/mdp.py"&gt;&lt;code&gt;mdp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;17.9&lt;/td&gt;
&lt;td align="left"&gt;POMDP-Value-Iteration&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;pomdp_value_iteration&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/mdp.py"&gt;&lt;code&gt;mdp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18.5&lt;/td&gt;
&lt;td align="left"&gt;Decision-Tree-Learning&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;DecisionTreeLearner&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/learning.py"&gt;&lt;code&gt;learning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18.8&lt;/td&gt;
&lt;td align="left"&gt;Cross-Validation&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;cross_validation&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/learning.py"&gt;&lt;code&gt;learning.py&lt;/code&gt;&lt;/a&gt;*&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18.11&lt;/td&gt;
&lt;td align="left"&gt;Decision-List-Learning&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;DecisionListLearner&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/learning.py"&gt;&lt;code&gt;learning.py&lt;/code&gt;&lt;/a&gt;*&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18.24&lt;/td&gt;
&lt;td align="left"&gt;Back-Prop-Learning&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;BackPropagationLearner&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/learning.py"&gt;&lt;code&gt;learning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18.34&lt;/td&gt;
&lt;td align="left"&gt;AdaBoost&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;AdaBoost&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/learning.py"&gt;&lt;code&gt;learning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;19.2&lt;/td&gt;
&lt;td align="left"&gt;Current-Best-Learning&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;current_best_learning&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="knowledge.py"&gt;&lt;code&gt;knowledge.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;19.3&lt;/td&gt;
&lt;td align="left"&gt;Version-Space-Learning&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;version_space_learning&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="knowledge.py"&gt;&lt;code&gt;knowledge.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;19.8&lt;/td&gt;
&lt;td align="left"&gt;Minimal-Consistent-Det&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;minimal_consistent_det&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="knowledge.py"&gt;&lt;code&gt;knowledge.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;19.12&lt;/td&gt;
&lt;td align="left"&gt;FOIL&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;FOIL_container&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="knowledge.py"&gt;&lt;code&gt;knowledge.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;21.2&lt;/td&gt;
&lt;td align="left"&gt;Passive-ADP-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;PassiveADPAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/rl.py"&gt;&lt;code&gt;rl.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;21.4&lt;/td&gt;
&lt;td align="left"&gt;Passive-TD-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;PassiveTDAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/rl.py"&gt;&lt;code&gt;rl.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;21.8&lt;/td&gt;
&lt;td align="left"&gt;Q-Learning-Agent&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;QLearningAgent&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/rl.py"&gt;&lt;code&gt;rl.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;22.1&lt;/td&gt;
&lt;td align="left"&gt;HITS&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;HITS&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/nlp.py"&gt;&lt;code&gt;nlp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;23&lt;/td&gt;
&lt;td align="left"&gt;Chart-Parse&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;Chart&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/nlp.py"&gt;&lt;code&gt;nlp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;23.5&lt;/td&gt;
&lt;td align="left"&gt;CYK-Parse&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;CYK_parse&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/nlp.py"&gt;&lt;code&gt;nlp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;25.9&lt;/td&gt;
&lt;td align="left"&gt;Monte-Carlo-Localization&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;monte_carlo_localization&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/probability.py"&gt;&lt;code&gt;probability.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Done&lt;/td&gt;
&lt;td align="left"&gt;Included&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-index-of-data-structures" class="anchor" aria-hidden="true" href="#index-of-data-structures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Index of data structures&lt;/h1&gt;
&lt;p&gt;Here is a table of the implemented data structures, the figure, name of the implementation in the repository, and the file where they are implemented.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;strong&gt;Figure&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;Name (in repository)&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;File&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3.2&lt;/td&gt;
&lt;td align="left"&gt;romania_map&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.9&lt;/td&gt;
&lt;td align="left"&gt;vacumm_world&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4.23&lt;/td&gt;
&lt;td align="left"&gt;one_dim_state_space&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;6.1&lt;/td&gt;
&lt;td align="left"&gt;australia_map&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/search.py"&gt;&lt;code&gt;search.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.13&lt;/td&gt;
&lt;td align="left"&gt;wumpus_world_inference&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7.16&lt;/td&gt;
&lt;td align="left"&gt;horn_clauses_KB&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/logic.py"&gt;&lt;code&gt;logic.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;17.1&lt;/td&gt;
&lt;td align="left"&gt;sequential_decision_environment&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/mdp.py"&gt;&lt;code&gt;mdp.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18.2&lt;/td&gt;
&lt;td align="left"&gt;waiting_decision_tree&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="../master/learning.py"&gt;&lt;code&gt;learning.py&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgements&lt;/h1&gt;
&lt;p&gt;Many thanks for contributions over the years. I got bug reports, corrected code, and other support from Darius Bacon, Phil Ruggera, Peng Shao, Amit Patil, Ted Nienstedt, Jim Martin, Ben Catanzariti, and others. Now that the project is on GitHub, you can see the &lt;a href="https://github.com/aimacode/aima-python/graphs/contributors"&gt;contributors&lt;/a&gt; who are doing a great job of actively improving the project. Many thanks to all contributors, especially &lt;a href="https://github.com/darius"&gt;@darius&lt;/a&gt;, &lt;a href="https://github.com/SnShine"&gt;@SnShine&lt;/a&gt;, &lt;a href="https://github.com/reachtarunhere"&gt;@reachtarunhere&lt;/a&gt;, &lt;a href="https://github.com/antmarakis"&gt;@antmarakis&lt;/a&gt;, &lt;a href="https://github.com/Chipe1"&gt;@Chipe1&lt;/a&gt;, &lt;a href="https://github.com/ad71"&gt;@ad71&lt;/a&gt; and &lt;a href="https://github.com/MariannaSpyrakou"&gt;@MariannaSpyrakou&lt;/a&gt;.&lt;/p&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>aimacode</author><guid isPermaLink="false">https://github.com/aimacode/aima-python</guid><pubDate>Wed, 05 Feb 2020 00:21:00 GMT</pubDate></item><item><title>dragen1860/TensorFlow-2.x-Tutorials #22 in Jupyter Notebook, This week</title><link>https://github.com/dragen1860/TensorFlow-2.x-Tutorials</link><description>&lt;p&gt;&lt;i&gt;TensorFlow 2.x version's  Tutorials and Examples, including CNN, RNN, GAN, Auto-Encoders, FasterRCNN, GPT, BERT examples, etc. TF 2.0&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-20-tutorials" class="anchor" aria-hidden="true" href="#tensorflow-20-tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow 2.0 Tutorials&lt;/h1&gt;
&lt;p&gt;Our repo. is the &lt;strong&gt;Winner&lt;/strong&gt; of &lt;a href="https://devpost.com/software/tensorflow-2-0-tutorials" rel="nofollow"&gt;#PoweredByTF 2.0 Challenge!&lt;/a&gt;.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="res/tensorflow-2.0.gif"&gt;&lt;img src="res/tensorflow-2.0.gif" width="250" align="middle" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Timeline:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Oct. 1, 2019: TensorFlow 2.0 Stable!&lt;/li&gt;
&lt;li&gt;Aug. 24, 2019: &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf" rel="nofollow"&gt;TensorFlow 2.0 rc0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jun. 8, 2019: &lt;a href="https://twitter.com/fchollet/status/1134583289384120320" rel="nofollow"&gt;TensorFlow 2.0 Beta&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Mar. 7, 2019: &lt;a href="https://www.tensorflow.org/alpha" rel="nofollow"&gt;Tensorflow 2.0 Alpha&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jan. 11, 2019: &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf" rel="nofollow"&gt;TensorFlow r2.0 preview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Aug. 14, 2018: &lt;a href="https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/bgug1G6a89A" rel="nofollow"&gt;TensorFlow 2.0 is coming&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h1&gt;
&lt;p&gt;make sure you are using python 3.x.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU install&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;pip install tensorflow &lt;span class="pl-k"&gt;-&lt;/span&gt;U&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;GPU install&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Install &lt;code&gt;CUDA 10.0&lt;/code&gt;(or after) and &lt;code&gt;cudnn&lt;/code&gt; by yourself. and set &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; up.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;pip install tensorflow&lt;span class="pl-k"&gt;-&lt;/span&gt;gpu  &lt;span class="pl-k"&gt;-&lt;/span&gt;U&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Test installation:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;In [&lt;span class="pl-c1"&gt;2&lt;/span&gt;]: &lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow  &lt;span class="pl-k"&gt;as&lt;/span&gt; tf

In [&lt;span class="pl-c1"&gt;3&lt;/span&gt;]: tf.&lt;span class="pl-c1"&gt;__version__&lt;/span&gt;
Out[&lt;span class="pl-c1"&gt;3&lt;/span&gt;]: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;2.0.0&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
In [&lt;span class="pl-c1"&gt;4&lt;/span&gt;]: tf.test.is_gpu_available()
&lt;span class="pl-c1"&gt;...&lt;/span&gt;
totalMemory: &lt;span class="pl-c1"&gt;3.&lt;/span&gt;&lt;span class="pl-ii"&gt;95GiB&lt;/span&gt; freeMemory: &lt;span class="pl-c1"&gt;3.&lt;/span&gt;&lt;span class="pl-ii"&gt;00GiB&lt;/span&gt;
&lt;span class="pl-c1"&gt;...&lt;/span&gt;
Out[&lt;span class="pl-c1"&gt;4&lt;/span&gt;]: &lt;span class="pl-c1"&gt;True&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-tf2" class="anchor" aria-hidden="true" href="#tf2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TF2&lt;/h1&gt;
&lt;p align="center"&gt;
  &lt;a href="https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1209092816&amp;amp;_trace_c_p_k2_=dca16f8fd11a4525bac8c89f779b2cfa" rel="nofollow"&gt;
    &lt;img src="res/cover.png" width="400" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1209092816&amp;amp;_trace_c_p_k2_=dca16f8fd11a4525bac8c89f779b2cfa" rel="nofollow"&gt;
    &lt;img src="res/TF_QR_163.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
&lt;/p&gt; 
&lt;p&gt;TensorFlow 2.0&lt;a href="https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1209092816&amp;amp;_trace_c_p_k2_=dca16f8fd11a4525bac8c89f779b2cfa" rel="nofollow"&gt;TensorFlow 2&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-acknowledgement" class="anchor" aria-hidden="true" href="#acknowledgement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgement&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;-  &lt;a target="_blank" rel="noopener noreferrer" href="res/weibo.jpg"&gt;&lt;img src="res/weibo.jpg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-includes" class="anchor" aria-hidden="true" href="#includes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Includes&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;TensorFlow 2.0 Overview&lt;/li&gt;
&lt;li&gt;TensorFlow 2.0 Basic Usage&lt;/li&gt;
&lt;li&gt;Linear Regression&lt;/li&gt;
&lt;li&gt;MNIST, FashionMNIST&lt;/li&gt;
&lt;li&gt;CIFAR10&lt;/li&gt;
&lt;li&gt;Fully Connected Layer&lt;/li&gt;
&lt;li&gt;VGG16&lt;/li&gt;
&lt;li&gt;Inception Network&lt;/li&gt;
&lt;li&gt;ResNet18&lt;/li&gt;
&lt;li&gt;Naive RNN&lt;/li&gt;
&lt;li&gt;LSTM&lt;/li&gt;
&lt;li&gt;ColorBot&lt;/li&gt;
&lt;li&gt;Auto-Encoders&lt;/li&gt;
&lt;li&gt;Variational Auto-Encoders&lt;/li&gt;
&lt;li&gt;DCGAN&lt;/li&gt;
&lt;li&gt;CycleGAN&lt;/li&gt;
&lt;li&gt;WGAN&lt;/li&gt;
&lt;li&gt;Pixel2Pixel&lt;/li&gt;
&lt;li&gt;Faster RCNN&lt;/li&gt;
&lt;li&gt;A2C&lt;/li&gt;
&lt;li&gt;GPT&lt;/li&gt;
&lt;li&gt;BERT&lt;/li&gt;
&lt;li&gt;GCN&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Feel free to submit a &lt;strong&gt;PR&lt;/strong&gt; request to make this repo. more complete!&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-refered-repos" class="anchor" aria-hidden="true" href="#refered-repos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Refered Repos.&lt;/h1&gt;
&lt;p&gt;Our work is not built from scratch. Great appreciation to these open works&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/madalinabuzau/tensorflow-eager-tutorials"&gt;https://github.com/madalinabuzau/tensorflow-eager-tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/herbiebradley/CycleGAN-Tensorflow"&gt;https://github.com/herbiebradley/CycleGAN-Tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/pix2pix/pix2pix_eager.ipynb"&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/pix2pix/pix2pix_eager.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/moono/tf-eager-on-GAN"&gt;https://github.com/moono/tf-eager-on-GAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Viredery/tf-eager-fasterrcnn"&gt;https://github.com/Viredery/tf-eager-fasterrcnn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/github/gitignore/blob/master/Python.gitignore"&gt;https://github.com/github/gitignore/blob/master/Python.gitignore&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dragen1860</author><guid isPermaLink="false">https://github.com/dragen1860/TensorFlow-2.x-Tutorials</guid><pubDate>Wed, 05 Feb 2020 00:22:00 GMT</pubDate></item><item><title>onnx/models #23 in Jupyter Notebook, This week</title><link>https://github.com/onnx/models</link><description>&lt;p&gt;&lt;i&gt;A collection of pre-trained, state-of-the-art models in the ONNX format &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-onnx-model-zoo" class="anchor" aria-hidden="true" href="#onnx-model-zoo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ONNX Model Zoo&lt;/h1&gt;
&lt;p&gt;Open Neural Network Exchange (ONNX) is an open standard format for representing machine learning models. ONNX is supported by a community of partners who have implemented it in many frameworks and tools.&lt;/p&gt;
&lt;p&gt;The ONNX Model Zoo is a collection of pre-trained, state-of-the-art models in the &lt;a href="http://onnx.ai" rel="nofollow"&gt;ONNX&lt;/a&gt; format contributed by community members like you. Accompanying each model are &lt;a href="http://jupyter.org" rel="nofollow"&gt;Jupyter notebooks&lt;/a&gt; for model training and running inference with the trained model. The notebooks are written in Python and include links to the training dataset as well as references to the original paper that describes the model architecture.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-models" class="anchor" aria-hidden="true" href="#models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Models&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-read-the-usage-section-below-for-more-details-on-the-file-formats-in-the-onnx-model-zoo-onnx-pb-npz-and-starter-python-code-for-validating-your-onnx-model-using-test-data" class="anchor" aria-hidden="true" href="#read-the-usage-section-below-for-more-details-on-the-file-formats-in-the-onnx-model-zoo-onnx-pb-npz-and-starter-python-code-for-validating-your-onnx-model-using-test-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Read the &lt;a href="#usage-"&gt;Usage&lt;/a&gt; section below for more details on the file formats in the ONNX Model Zoo (.onnx, .pb, .npz) and starter Python code for validating your ONNX model using test data.&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-vision" class="anchor" aria-hidden="true" href="#vision"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Vision&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#image_classification"&gt;Image Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#object_detection"&gt;Object Detection &amp;amp; Image Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#body_analysis"&gt;Body, Face &amp;amp; Gesture Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#image_manipulation"&gt;Image Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-language" class="anchor" aria-hidden="true" href="#language"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Language&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#machine_comprehension"&gt;Machine Comprehension&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#machine_translation"&gt;Machine Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#language"&gt;Language Modelling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-other" class="anchor" aria-hidden="true" href="#other"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#visual_qna"&gt;Visual Question Answering &amp;amp; Dialog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#speech"&gt;Speech &amp;amp; Audio Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#others"&gt;Other interesting models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-image-classification-" class="anchor" aria-hidden="true" href="#image-classification-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image Classification &lt;a name="user-content-image_classification"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-image_classification"&gt;
&lt;p&gt;This collection of models take images as input, then classifies the major objects in the images into 1000 object categories such as keyboard, mouse, pencil, and many animals.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/mobilenet"&gt;MobileNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1801.04381" rel="nofollow"&gt;Sandler et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Light-weight deep neural network best suited for mobile and embedded vision applications. &lt;br&gt;Top-5 error from paper - ~10%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/resnet"&gt;ResNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1512.03385" rel="nofollow"&gt;He et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A CNN model (up to 152 layers). Uses shortcut connections to achieve higher accuracy when classifying images. &lt;br&gt; Top-5 error from paper - ~3.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/squeezenet"&gt;SqueezeNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1602.07360" rel="nofollow"&gt;Iandola et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A light-weight CNN model providing AlexNet level accuracy with 50x fewer parameters. &lt;br&gt;Top-5 error from paper - ~20%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/vgg"&gt;VGG&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1409.1556" rel="nofollow"&gt;Simonyan et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN model(up to 19 layers). Similar to AlexNet but uses multiple smaller kernel-sized filters that provides more accuracy when classifying images. &lt;br&gt;Top-5 error from paper - ~8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/alexnet"&gt;AlexNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="nofollow"&gt;Krizhevsky et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A Deep CNN model (up to 8 layers) where the input is an image and the output is a vector of 1000 numbers. &lt;br&gt; Top-5 error from paper - ~15%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/inception_and_googlenet/googlenet"&gt;GoogleNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1409.4842.pdf" rel="nofollow"&gt;Szegedy et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN model(up to 22 layers). Comparatively smaller and faster than VGG and more accurate in detailing than AlexNet. &lt;br&gt; Top-5 error from paper - ~6.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/caffenet"&gt;CaffeNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://ucb-icsi-vision-group.github.io/caffe-paper/caffe.pdf" rel="nofollow"&gt;Krizhevsky et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN variation of AlexNet for Image Classification in Caffe where the max pooling precedes the local response normalization (LRN) so that the LRN takes less compute and memory.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/rcnn_ilsvrc13"&gt;RCNN_ILSVRC13&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1311.2524" rel="nofollow"&gt;Girshick et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Pure Caffe implementation of R-CNN for image classification. This model uses localization of regions to classify and extract features from images.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/densenet-121"&gt;DenseNet-121&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1608.06993" rel="nofollow"&gt;Huang et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Model that has every layer connected to every other layer and passes on its own feature providing strong gradient flow and more diversified features.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/inception_and_googlenet/inception_v1"&gt;Inception_V1&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1409.4842" rel="nofollow"&gt;Szegedy et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;This model is same as GoogLeNet, implemented through Caffe2 that has improved utilization of the computing resources inside the network and helps with the vanishing gradient problem. &lt;br&gt; Top-5 error from paper - ~6.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/inception_and_googlenet/inception_v2"&gt;Inception_V2&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1512.00567" rel="nofollow"&gt;Szegedy et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN model for Image Classification as an adaptation to Inception v1 with batch normalization. This model has reduced computational cost and improved image resolution compared to Inception v1. &lt;br&gt; Top-5 error from paper ~4.82%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/shufflenet"&gt;ShuffleNet&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1707.01083" rel="nofollow"&gt;Zhang et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Extremely computation efficient CNN model that is designed specifically for mobile devices. This model greatly reduces the computational cost and provides a ~13x speedup over AlexNet on ARM-based mobile devices. Compared to MobileNet, ShuffleNet achieves superior performance by a significant margin due to it's efficient structure. &lt;br&gt; Top-1 error from paper - ~7.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/zfnet-512"&gt;ZFNet-512&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1311.2901" rel="nofollow"&gt;Zeiler et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN model (up to 8 layers) that increased the number of features that the network is capable of detecting that helps to pick image features at a finer level of resolution. &lt;br&gt; Top-5 error from paper - ~14.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h4&gt;&lt;a id="user-content-domain-based-image-classification-" class="anchor" aria-hidden="true" href="#domain-based-image-classification-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-image_classification"&gt;Domain-based Image Classification &lt;/a&gt;&lt;a name="user-content-domain_based_image"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;a name="user-content-domain_based_image"&gt;
&lt;p&gt;This subset of models classify images for specific domains and datasets.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/classification/mnist"&gt;MNIST-Handwritten Digit Recognition&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Microsoft/CNTK/blob/master/Tutorials/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.ipynb"&gt;Convolutional Neural Network with MNIST&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN model for handwritten digit identification&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-object-detection--image-segmentation-" class="anchor" aria-hidden="true" href="#object-detection--image-segmentation-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-domain_based_image"&gt;Object Detection &amp;amp; Image Segmentation &lt;/a&gt;&lt;a name="user-content-object_detection"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-object_detection"&gt;
&lt;p&gt;Object detection models detect the presence of multiple objects in an image and segment out areas of the image where the objects are detected. Semantic segmentation models partition an input image by labeling each pixel into a set of pre-defined categories.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/tiny_yolov2"&gt;Tiny YOLOv2&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1612.08242.pdf" rel="nofollow"&gt;Redmon et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A real-time CNN for object detection that detects 20 different classes. A smaller version of the more complex full YOLOv2 network.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/ssd"&gt;SSD&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1512.02325" rel="nofollow"&gt;Liu et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Single Stage Detector: real-time CNN for object detection that detects 80 different classes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/faster-rcnn"&gt;Faster-RCNN&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1506.01497" rel="nofollow"&gt;Ren et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Increases efficiency from R-CNN by connecting a RPN with a CNN to create a single, unified network for object detection that detects 80 different classes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/mask-rcnn"&gt;Mask-RCNN&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1703.06870" rel="nofollow"&gt;He et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A real-time neural network for object instance segmentation that detects 80 different classes. Extends Faster R-CNN as each of the 300 elected ROIs go through 3 parallel branches of the network: label prediction, bounding box prediction and mask prediction.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;YOLO v2&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1612.08242" rel="nofollow"&gt;Redmon et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A CNN model for real-time object detection system that can detect over 9000 object categories. It uses a single network evaluation, enabling it to be more than 1000x faster than R-CNN and 100x faster than Faster R-CNN. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/yolov3"&gt;YOLO v3&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1804.02767.pdf" rel="nofollow"&gt;Redmon et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A deep CNN model for real-time object detection that detects 80 different classes. A little bigger than YOLOv2 but still very fast. As accurate as SSD but 3 times faster.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/tiny_yolov3"&gt;Tiny YOLOv3&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1804.02767.pdf" rel="nofollow"&gt;Redmon et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A smaller version of YOLOv3 model.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/object_detection_segmentation/duc"&gt;DUC&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1702.08502" rel="nofollow"&gt;Wang et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN based pixel-wise semantic segmentation model with &amp;gt;80% &lt;a href="/models/semantic_segmentation/DUC/README.md/#metric"&gt;mIOU&lt;/a&gt; (mean Intersection Over Union). Trained on cityscapes dataset, which can be effectively implemented in self driving vehicle systems.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FCN&lt;/td&gt;
&lt;td&gt;&lt;a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf" rel="nofollow"&gt;Long et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN based segmentation model trained end-to-end, pixel-to-pixel that produces efficient inference and learning. Built off of AlexNet, VGG net, GoogLeNet classification methods. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-body-face--gesture-analysis-" class="anchor" aria-hidden="true" href="#body-face--gesture-analysis-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-object_detection"&gt;Body, Face &amp;amp; Gesture Analysis &lt;/a&gt;&lt;a name="user-content-body_analysis"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-body_analysis"&gt;
&lt;p&gt;Face detection models identify and/or recognize human faces and emotions in given images. Body and Gesture Analysis models identify gender and age in given image.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/body_analysis/arcface"&gt;ArcFace&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1801.07698" rel="nofollow"&gt;Deng et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A CNN based model for face recognition which learns discriminative features of faces and produces embeddings for input face images.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CNN Cascade&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Li_A_Convolutional_Neural_2015_CVPR_paper.pdf" rel="nofollow"&gt;Li et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;The model operates at multiple resolutions, quickly rejecting the background regions in the fast low resolution stages in an image and carefully evaluates a small number of challenging candidates in the last high resolution stage. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/body_analysis/emotion_ferplus"&gt;Emotion FerPlus&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1608.01041" rel="nofollow"&gt;Barsoum et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep CNN for emotion recognition trained on images of faces.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Age and Gender Classification using Convolutional Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.openu.ac.il/home/hassner/projects/cnn_agegender/CNN_AgeGenderEstimation.pdf" rel="nofollow"&gt;Levi et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;This model accurately classifies gender and age even the amount of learning data is limited.&lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-image-manipulation-" class="anchor" aria-hidden="true" href="#image-manipulation-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-body_analysis"&gt;Image Manipulation &lt;/a&gt;&lt;a name="user-content-image_manipulation"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-image_manipulation"&gt;
&lt;p&gt;Image manipulation models use neural networks to transform input images to modified output images. Some popular models in this category involve style transfer or enhancing images by increasing resolution.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Unpaired Image to Image Translation using Cycle consistent Adversarial Network&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1703.10593" rel="nofollow"&gt;Zhu et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;The model uses learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/super_resolution/sub_pixel_cnn_2016"&gt;Super Resolution with sub-pixel CNN&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1609.05158" rel="nofollow"&gt;Shi et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A deep CNN that uses sub-pixel convolution layers to upscale the input image.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="vision/style_transfer/fast_neural_style"&gt;Fast Neural Style Transfer&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1603.08155" rel="nofollow"&gt;Johnson et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;This method uses a loss network pretrained for image classification to define perceptual loss functions that measure perceptual differences in content and style between images. The loss network remains fixed during the training process.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-speech--audio-processing-" class="anchor" aria-hidden="true" href="#speech--audio-processing-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-image_manipulation"&gt;Speech &amp;amp; Audio Processing &lt;/a&gt;&lt;a name="user-content-speech"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-speech"&gt;
&lt;p&gt;This class of models uses audio data to train models that can identify voice, generate music, or even read text out loud.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Speech recognition with deep recurrent neural networks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.cs.toronto.edu/~fritz/absps/RNN13.pdf" rel="nofollow"&gt;Graves et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A RNN model for sequential data for speech recognition. Labels problems where the input-output alignment is unknown&lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Deep voice: Real time neural text to speech&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1702.07825" rel="nofollow"&gt;Arik et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A DNN model that performs end-to-end neural speech synthesis. Requires fewer parameters and it is faster than other systems. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Sound Generative models&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1609.03499" rel="nofollow"&gt;WaveNet: A Generative Model for Raw Audio &lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A CNN model that generates raw audio waveforms. Has predictive distribution for each audio sample. Generates realistic music fragments. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-machine-comprehension-" class="anchor" aria-hidden="true" href="#machine-comprehension-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-speech"&gt;Machine Comprehension &lt;/a&gt;&lt;a name="user-content-machine_comprehension"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-machine_comprehension"&gt;
&lt;p&gt;This subset of natural language processing models that answer questions about a given context paragraph.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="text/machine_comprehension/bidirectional_attention_flow"&gt;Bidirectional Attention Flow&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1611.01603" rel="nofollow"&gt;Seo et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A model that answers a query about a given context paragraph.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="text/machine_comprehension/bert-squad"&gt;BERT-Squad&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1810.04805.pdf" rel="nofollow"&gt;Devlin et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;This model answers questions based on the context of the given input paragraph.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;a href="text/machine_comprehension/gpt-2"&gt;GPT-2&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="nofollow"&gt;Radford et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A large transformer-based language model that given a sequence of words within some text, predicts the next word.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-machine-translation-" class="anchor" aria-hidden="true" href="#machine-translation-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-machine_comprehension"&gt;Machine Translation &lt;/a&gt;&lt;a name="user-content-machine_translation"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-machine_translation"&gt;
&lt;p&gt;This class of natural language processing models learns how to translate input text to another language.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Neural Machine Translation by jointly learning to align and translate&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1409.0473" rel="nofollow"&gt;Bahdanau et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Aims to build a single neural network that can be jointly tuned to maximize the translation performance. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Google's Neural Machine Translation System&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1609.08144" rel="nofollow"&gt;Wu et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;This model helps to improve issues faced by the Neural Machine Translation (NMT) systems like parallelism that helps accelerate the final translation speed.&lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-language-modelling-" class="anchor" aria-hidden="true" href="#language-modelling-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-machine_translation"&gt;Language Modelling &lt;/a&gt;&lt;a name="user-content-language"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-language"&gt;
&lt;p&gt;This subset of natural language processing models learns representations of language from large corpuses of text.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Deep Neural Network Language Models&lt;/td&gt;
&lt;td&gt;&lt;a href="https://pdfs.semanticscholar.org/a177/45f1d7045636577bcd5d513620df5860e9e5.pdf" rel="nofollow"&gt;Arisoy et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A DNN acoustic model. Used in many natural language technologies. Represents a probability distribution over all possible word strings in a language. &lt;br&gt; &lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-visual-question-answering--dialog-" class="anchor" aria-hidden="true" href="#visual-question-answering--dialog-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-language"&gt;Visual Question Answering &amp;amp; Dialog &lt;/a&gt;&lt;a name="user-content-visual_qna"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-visual_qna"&gt;
&lt;p&gt;This subset of natural language processing models uses input images to answer questions about those images.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;VQA: Visual Question Answering&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1505.00468v6.pdf" rel="nofollow"&gt;Agrawal et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A model that takes an image and a free-form, open-ended natural language question about the image and outputs a natural-language answer. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Yin and Yang: Balancing and Answering Binary Visual Questions&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1511.05099.pdf" rel="nofollow"&gt;Zhang et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Addresses VQA by converting the question to a tuple that concisely summarizes the visual concept to be detected in the image. Next, if the concept can be found in the image, it provides a yes or no answer. Its performance matches the traditional VQA approach on unbalanced dataset, and outperforms it on the balanced dataset. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Making the V in VQA Matter&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1612.00837.pdf" rel="nofollow"&gt;Goyal et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Balances the VQA dataset by collecting complementary images such that every question is associated with a pair of similar images that result in two different answers to the question, providing a unique interpretable model that provides a counter-example based explanation.  &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Visual Dialog&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1611.08669" rel="nofollow"&gt;Das et al.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;An AI agent that holds a meaningful dialog with humans in natural, conversational language about visual content. Curates a large-scale Visual Dialog dataset (VisDial). &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;/a&gt;&lt;h3&gt;&lt;a id="user-content-other-interesting-models-" class="anchor" aria-hidden="true" href="#other-interesting-models-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-visual_qna"&gt;Other interesting models &lt;/a&gt;&lt;a name="user-content-others"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;a name="user-content-others"&gt;
&lt;/a&gt;&lt;p&gt;&lt;a name="user-content-others"&gt;There are many interesting deep learning models that do not fit into the categories described above. The ONNX team would like to highly encourage users and researchers to &lt;/a&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt; their models to the growing model zoo.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model Class&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Text to Image&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1605.05396" rel="nofollow"&gt;Generative Adversarial Text to image Synthesis &lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Effectively bridges the advances in text and image modeling, translating visual concepts from characters to pixels. Generates plausible images of birds and flowers from detailed text descriptions. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Time Series Forecasting&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1703.07015.pdf" rel="nofollow"&gt;Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks &lt;/a&gt;&lt;/td&gt;
&lt;td&gt;The model extracts short-term local dependency patterns among variables and to discover long-term patterns for time series trends. It helps to predict solar plant energy output, electricity consumption, and traffic jam situations. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Recommender systems&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.cs.toronto.edu/~mvolkovs/nips2017_deepcf.pdf" rel="nofollow"&gt;DropoutNet: Addressing Cold Start in Recommender Systems&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A collaborative filtering method that makes predictions about an individuals preference based on preference information from other users.&lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Collaborative filtering&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1708.05031.pdf" rel="nofollow"&gt;Neural Collaborative Filtering&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A DNN model based on the interaction between user and item features using matrix factorization. &lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Autoencoders&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1506.01057" rel="nofollow"&gt;A Hierarchical Neural Autoencoder for Paragraphs and Documents&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;An LSTM (long-short term memory) auto-encoder to preserve and reconstruct multi-sentence paragraphs.&lt;br&gt;&lt;a href="contribute.md"&gt;contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-usage-" class="anchor" aria-hidden="true" href="#usage-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage &lt;a name="user-content-usage-"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;a name="user-content-usage-"&gt;
&lt;p&gt;Every ONNX backend should support running the models out of the box. After downloading and extracting the tarball of each model, you will find:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A protobuf file &lt;code&gt;model.onnx&lt;/code&gt; that represents the serialized ONNX model.&lt;/li&gt;
&lt;li&gt;Test data (in the form of serialized protobuf TensorProto files or serialized NumPy archives).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The test data files can be used to validate ONNX models from the Model Zoo. We have provided the following interface examples for you to get started. Please replace &lt;code&gt;onnx_backend&lt;/code&gt; in your code with the appropriate framework of your choice that provides ONNX inferencing support, and likewise replace &lt;code&gt;backend.run_model&lt;/code&gt; with the framework's model evaluation logic.&lt;/p&gt;
&lt;p&gt;There are two different formats for the test data files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Serialized protobuf TensorProtos (.pb), stored in folders with the naming convention &lt;code&gt;test_data_set_*&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np
&lt;span class="pl-k"&gt;import&lt;/span&gt; onnx
&lt;span class="pl-k"&gt;import&lt;/span&gt; os
&lt;span class="pl-k"&gt;import&lt;/span&gt; glob
&lt;span class="pl-k"&gt;import&lt;/span&gt; onnx_backend &lt;span class="pl-k"&gt;as&lt;/span&gt; backend

&lt;span class="pl-k"&gt;from&lt;/span&gt; onnx &lt;span class="pl-k"&gt;import&lt;/span&gt; numpy_helper

model &lt;span class="pl-k"&gt;=&lt;/span&gt; onnx.load(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;model.onnx&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
test_data_dir &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;test_data_set_0&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load inputs&lt;/span&gt;
inputs &lt;span class="pl-k"&gt;=&lt;/span&gt; []
inputs_num &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;len&lt;/span&gt;(glob.glob(os.path.join(test_data_dir, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;input_*.pb&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)))
&lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(inputs_num):
    input_file &lt;span class="pl-k"&gt;=&lt;/span&gt; os.path.join(test_data_dir, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;input_&lt;span class="pl-c1"&gt;{}&lt;/span&gt;.pb&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.format(i))
    tensor &lt;span class="pl-k"&gt;=&lt;/span&gt; onnx.TensorProto()
    &lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-c1"&gt;open&lt;/span&gt;(input_file, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;rb&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-k"&gt;as&lt;/span&gt; f:
        tensor.ParseFromString(f.read())
    inputs.append(numpy_helper.to_array(tensor))

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load reference outputs&lt;/span&gt;
ref_outputs &lt;span class="pl-k"&gt;=&lt;/span&gt; []
ref_outputs_num &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;len&lt;/span&gt;(glob.glob(os.path.join(test_data_dir, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;output_*.pb&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)))
&lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(ref_outputs_num):
    output_file &lt;span class="pl-k"&gt;=&lt;/span&gt; os.path.join(test_data_dir, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;output_&lt;span class="pl-c1"&gt;{}&lt;/span&gt;.pb&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.format(i))
    tensor &lt;span class="pl-k"&gt;=&lt;/span&gt; onnx.TensorProto()
    &lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-c1"&gt;open&lt;/span&gt;(output_file, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;rb&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-k"&gt;as&lt;/span&gt; f:
        tensor.ParseFromString(f.read())
    ref_outputs.append(numpy_helper.to_array(tensor))

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Run the model on the backend&lt;/span&gt;
outputs &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;list&lt;/span&gt;(backend.run_model(model, inputs))

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Compare the results with reference outputs.&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; ref_o, o &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;zip&lt;/span&gt;(ref_outputs, outputs):
    np.testing.assert_almost_equal(ref_o, o)&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Serialized Numpy archives, stored in files with the naming convention &lt;code&gt;test_data_*.npz&lt;/code&gt;. Each file contains one set of test inputs and outputs.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np
&lt;span class="pl-k"&gt;import&lt;/span&gt; onnx
&lt;span class="pl-k"&gt;import&lt;/span&gt; onnx_backend &lt;span class="pl-k"&gt;as&lt;/span&gt; backend

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load the model and sample inputs and outputs&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; onnx.load(model_pb_path)
sample &lt;span class="pl-k"&gt;=&lt;/span&gt; np.load(npz_path, &lt;span class="pl-v"&gt;encoding&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bytes&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
inputs &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;list&lt;/span&gt;(sample[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;inputs&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])
outputs &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;list&lt;/span&gt;(sample[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;outputs&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Run the model with an onnx backend and verify the results&lt;/span&gt;
np.testing.assert_almost_equal(outputs, backend.run_model(model, inputs))&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-model-visualization" class="anchor" aria-hidden="true" href="#model-visualization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model Visualization&lt;/h2&gt;
&lt;/a&gt;&lt;p&gt;&lt;a name="user-content-usage-"&gt;You can see visualizations of each model's network architecture by using &lt;/a&gt;&lt;a href="https://github.com/lutzroeder/Netron"&gt;Netron&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributions" class="anchor" aria-hidden="true" href="#contributions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributions&lt;/h2&gt;
&lt;p&gt;Do you want to contribute a model? To get started, pick any model presented above with the &lt;a href="contribute.md"&gt;contribute&lt;/a&gt; link under the Description column. The links point to a page containing guidelines for making a contribution.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h1&gt;
&lt;p&gt;&lt;a href="LICENSE"&gt;MIT License&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>onnx</author><guid isPermaLink="false">https://github.com/onnx/models</guid><pubDate>Wed, 05 Feb 2020 00:23:00 GMT</pubDate></item><item><title>jackfrued/Python-100-Days #24 in Jupyter Notebook, This week</title><link>https://github.com/jackfrued/Python-100-Days</link><description>&lt;p&gt;&lt;i&gt;Python - 100&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-python---100" class="anchor" aria-hidden="true" href="#python---100"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python - 100&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;PythonPythonPython15101510Python100&lt;a href="./%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97.md"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-qq-group.png"&gt;&lt;img src="./res/python-qq-group.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-python" class="anchor" aria-hidden="true" href="#python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python&lt;/h3&gt;
&lt;p&gt;Python&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;C/C++&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Python&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; - Python / Java / Go&lt;/li&gt;
&lt;li&gt;DevOps - Python / Shell / Ruby / Go&lt;/li&gt;
&lt;li&gt; - Python / PHP / C++&lt;/li&gt;
&lt;li&gt; - Python / R / Scala / Matlab&lt;/li&gt;
&lt;li&gt; - Python / R / Java / Lisp&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Python&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python /  / &lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;Python /  / &lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;Python /  / &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Python20185&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-top-10.png"&gt;&lt;img src="./res/python-top-10.png" alt="PythonTop 10" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-bj-salary.png"&gt;&lt;img src="./res/python-bj-salary.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-salary-chengdu.png"&gt;&lt;img src="./res/python-salary-chengdu.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make English as your working language.&lt;/li&gt;
&lt;li&gt;Practice makes perfect.&lt;/li&gt;
&lt;li&gt;All experience comes from mistakes.&lt;/li&gt;
&lt;li&gt;Don't be one of the leeches.&lt;/li&gt;
&lt;li&gt;Either stand out or kicked out.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day0115---python" class="anchor" aria-hidden="true" href="#day0115---python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day01~15 - &lt;a href="./Day01-15"&gt;Python&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day01---python" class="anchor" aria-hidden="true" href="#day01---python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day01 - &lt;a href="./Day01-15/01.%E5%88%9D%E8%AF%86Python.md"&gt;Python&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Python - Python / Python / Python&lt;/li&gt;
&lt;li&gt; - Windows / Linux / MacOS&lt;/li&gt;
&lt;li&gt;Python - Hello, world / print / &lt;/li&gt;
&lt;li&gt;IDLE - (REPL) /  /  / IDLE&lt;/li&gt;
&lt;li&gt; -  /  / &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day02---" class="anchor" aria-hidden="true" href="#day02---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day02 - &lt;a href="./Day01-15/02.%E8%AF%AD%E8%A8%80%E5%85%83%E7%B4%A0.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt; -  /  /  / &lt;/li&gt;
&lt;li&gt; -  /  / input /  / &lt;/li&gt;
&lt;li&gt; -  /  /  /  /  / &lt;/li&gt;
&lt;li&gt; -  /  /  /  /  / &lt;/li&gt;
&lt;li&gt; -  /  / &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day03---" class="anchor" aria-hidden="true" href="#day03---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day03 - &lt;a href="./Day01-15/03.%E5%88%86%E6%94%AF%E7%BB%93%E6%9E%84.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt; -  /  /  / &lt;/li&gt;
&lt;li&gt;if - if / if-else / if-elif-else / if&lt;/li&gt;
&lt;li&gt; -  /  /  /  /  / &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day04---" class="anchor" aria-hidden="true" href="#day04---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day04 - &lt;a href="./Day01-15/04.%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt; -  /  /  / &lt;/li&gt;
&lt;li&gt;while -  / break / continue&lt;/li&gt;
&lt;li&gt;for -  / range /  /  / &lt;/li&gt;
&lt;li&gt; - 1~100 /  /  /  /  /  / &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day05---" class="anchor" aria-hidden="true" href="#day05---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day05 - &lt;a href="./Day01-15/05.%E6%9E%84%E9%80%A0%E7%A8%8B%E5%BA%8F%E9%80%BB%E8%BE%91.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt; /  / Craps&lt;/li&gt;
&lt;li&gt; /  / &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day06---" class="anchor" aria-hidden="true" href="#day06---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day06 - &lt;a href="./Day01-15/06.%E5%87%BD%E6%95%B0%E5%92%8C%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt; -  / &lt;/li&gt;
&lt;li&gt; - def /  /  / return / &lt;/li&gt;
&lt;li&gt; - Python /  &lt;/li&gt;
&lt;li&gt; -  /  /  / &lt;/li&gt;
&lt;li&gt; -   /  / &lt;/li&gt;
&lt;li&gt; -  /  /  /  / &lt;/li&gt;
&lt;li&gt; -  /  / &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day07---" class="anchor" aria-hidden="true" href="#day07---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day07 - &lt;a href="./Day01-15/07.%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt; -  /  /  / &lt;/li&gt;
&lt;li&gt; -  /  /  /  /  /  /  / &lt;/li&gt;
&lt;li&gt; -  / () /  /  /  / &lt;/li&gt;
&lt;li&gt; - range /  / &lt;/li&gt;
&lt;li&gt; -  /  /  / &lt;/li&gt;
&lt;li&gt; -  /   /  /  /  &lt;/li&gt;
&lt;li&gt; -  /  /  /  /  / &lt;/li&gt;
&lt;li&gt; -  /  /  /  /  / &lt;/li&gt;
&lt;li&gt; - keys() / values() / items() / setdefault()&lt;/li&gt;
&lt;li&gt; -  /  /  / Fibonacci / &lt;/li&gt;
&lt;li&gt; -  / &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day08---" class="anchor" aria-hidden="true" href="#day08---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day08 - &lt;a href="./Day01-15/08.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt; -  /  / &lt;/li&gt;
&lt;li&gt; -  /  /  /  / __str__&lt;/li&gt;
&lt;li&gt; -  / &lt;/li&gt;
&lt;li&gt; -  /  /  / &lt;/li&gt;
&lt;li&gt; -  /  /  / &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day09---" class="anchor" aria-hidden="true" href="#day09---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day09 - &lt;a href="./Day01-15/09.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%BF%9B%E9%98%B6.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt; -  /  /  /  /  / __slots__&lt;/li&gt;
&lt;li&gt; -  /  / &lt;/li&gt;
&lt;li&gt; - __add__ / __sub__ / __or__ /__getitem__ / __setitem__ / __len__ / __repr__ / __gt__ / __lt__ / __le__ / __ge__ / __eq__ / __ne__ / __contains__&lt;/li&gt;
&lt;li&gt;() -  /  / &lt;/li&gt;
&lt;li&gt; -  /  /  /  /  /  / ()C3&lt;/li&gt;
&lt;li&gt; -  /  / &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day10---" class="anchor" aria-hidden="true" href="#day10---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day10 - &lt;a href="./Day01-15/10.%E5%9B%BE%E5%BD%A2%E7%94%A8%E6%88%B7%E7%95%8C%E9%9D%A2%E5%92%8C%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;tkinterGUI&lt;/li&gt;
&lt;li&gt;pygame&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day11---" class="anchor" aria-hidden="true" href="#day11---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day11 - &lt;a href="./Day01-15/11.%E6%96%87%E4%BB%B6%E5%92%8C%E5%BC%82%E5%B8%B8.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt; -  /  / &lt;/li&gt;
&lt;li&gt; -  /  /  / &lt;/li&gt;
&lt;li&gt; -  / try-except / else / finally /  /  / raise&lt;/li&gt;
&lt;li&gt; - CSV / csv / JSON / json&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day12---" class="anchor" aria-hidden="true" href="#day12---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day12 - &lt;a href="./Day01-15/12.%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt; -  /  /  / in not in / is / joinsplit / strip / pyperclip /  / StringIO&lt;/li&gt;
&lt;li&gt; -  /  /  /  /  /  / / re&lt;/li&gt;
&lt;li&gt; - re / compile / groupgroups / match / search / findallfinditer / subsubn / split&lt;/li&gt;
&lt;li&gt; - &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day13---" class="anchor" aria-hidden="true" href="#day13---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day13 - &lt;a href="./Day01-15/13.%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt; -  /  / &lt;/li&gt;
&lt;li&gt; - fork / multiprocessing /  / &lt;/li&gt;
&lt;li&gt; - thread / threading / Thread / Lock / Condition / &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day14---" class="anchor" aria-hidden="true" href="#day14---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day14 - &lt;a href="./Day01-15/14.%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt; -  / TCP-IP / IP /  /  / &lt;/li&gt;
&lt;li&gt; - - / -&lt;/li&gt;
&lt;li&gt;HTTP - API / URL / requests / JSON&lt;/li&gt;
&lt;li&gt;Python -  / socket /  socket / TCP / TCP / UDP / UDP / SocketServer&lt;/li&gt;
&lt;li&gt; - SMTP / POP3 / IMAP / smtplib / poplib / imaplib&lt;/li&gt;
&lt;li&gt; - &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day15---" class="anchor" aria-hidden="true" href="#day15---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day15 - &lt;a href="./Day01-15/15.%E5%9B%BE%E5%83%8F%E5%92%8C%E5%8A%9E%E5%85%AC%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Pillow -  /  /  /  / &lt;/li&gt;
&lt;li&gt;Word -  /  /  / &lt;/li&gt;
&lt;li&gt;Excel - xlrd / xlwt&lt;/li&gt;
&lt;li&gt;PDF - pypdf2 / reportlab&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day16day20---python-" class="anchor" aria-hidden="true" href="#day16day20---python-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day16~Day20 - &lt;a href="./Day16-20/16-20.Python%E8%AF%AD%E8%A8%80%E8%BF%9B%E9%98%B6.md"&gt;Python &lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt; -  /  / Lambda /  / &lt;/li&gt;
&lt;li&gt; -  /  /  /  /  /  /  / GoF&lt;/li&gt;
&lt;li&gt; -  /  /&lt;/li&gt;
&lt;li&gt; -  /  / IO / asyncawait&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day2130---web" class="anchor" aria-hidden="true" href="#day2130---web"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day21~30 - &lt;a href="./Day21-30/21-30.Web%E5%89%8D%E7%AB%AF%E6%A6%82%E8%BF%B0.md"&gt;Web&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;HTML&lt;/li&gt;
&lt;li&gt;CSS&lt;/li&gt;
&lt;li&gt;JavaScript&lt;/li&gt;
&lt;li&gt;jQuery&lt;/li&gt;
&lt;li&gt;Vue.js&lt;/li&gt;
&lt;li&gt;Element&lt;/li&gt;
&lt;li&gt;Bootstrap&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day3135---linux" class="anchor" aria-hidden="true" href="#day3135---linux"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day31~35 - &lt;a href="./Day31-35/31-35.%E7%8E%A9%E8%BD%ACLinux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.md"&gt;Linux&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Linux&lt;/li&gt;
&lt;li&gt;Linux&lt;/li&gt;
&lt;li&gt;Linux&lt;/li&gt;
&lt;li&gt;Linux&lt;/li&gt;
&lt;li&gt;Vim&lt;/li&gt;
&lt;li&gt;Shell&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day3640---" class="anchor" aria-hidden="true" href="#day3640---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day36~40 - &lt;a href="./Day36-40"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="./Day36-40/36-38.%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93MySQL.md"&gt;MySQL&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;MySQL&lt;/li&gt;
&lt;li&gt;SQL
&lt;ul&gt;
&lt;li&gt;DDL -  - create / drop / alter&lt;/li&gt;
&lt;li&gt;DML -  - insert / delete / update / select&lt;/li&gt;
&lt;li&gt;DCL -  - grant / revoke&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt; - &lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PythonMySQL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="./Day36-40/39-40.NoSQL%E5%85%A5%E9%97%A8.md"&gt;NoSQL&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;NoSQL&lt;/li&gt;
&lt;li&gt;Redis&lt;/li&gt;
&lt;li&gt;Mongo&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day4155---django" class="anchor" aria-hidden="true" href="#day4155---django"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day41~55 - &lt;a href="./Day41-55"&gt;Django&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day41---" class="anchor" aria-hidden="true" href="#day41---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day41 - &lt;a href="./Day41-55/41.%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;WebHTTP&lt;/li&gt;
&lt;li&gt;Django&lt;/li&gt;
&lt;li&gt;5&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day42---" class="anchor" aria-hidden="true" href="#day42---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day42 - &lt;a href="./Day41-55/42.%E6%B7%B1%E5%85%A5%E6%A8%A1%E5%9E%8B.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;ORMCRUD&lt;/li&gt;
&lt;li&gt;Django&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day43---ajax" class="anchor" aria-hidden="true" href="#day43---ajax"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day43 - &lt;a href="./Day41-55/43.%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E5%92%8CAjax%E8%AF%B7%E6%B1%82.md"&gt;Ajax&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;Ajax&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day44---" class="anchor" aria-hidden="true" href="#day44---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day44 - &lt;a href="./Day41-55/44.%E8%A1%A8%E5%8D%95%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;CSRF&lt;/li&gt;
&lt;li&gt;FormModelForm&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day45---cookiesession" class="anchor" aria-hidden="true" href="#day45---cookiesession"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day45 - &lt;a href="./Day41-55/45.Cookie%E5%92%8CSession.md"&gt;CookieSession&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;cookiesession&lt;/li&gt;
&lt;li&gt;Djangosession&lt;/li&gt;
&lt;li&gt;cookie&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day46---" class="anchor" aria-hidden="true" href="#day46---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day46 - &lt;a href="./Day41-55/46.%E6%8A%A5%E8%A1%A8%E5%92%8C%E6%97%A5%E5%BF%97.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;HttpResponse&lt;/li&gt;
&lt;li&gt;StreamingHttpResponse&lt;/li&gt;
&lt;li&gt;xlwtExcel&lt;/li&gt;
&lt;li&gt;reportlabPDF&lt;/li&gt;
&lt;li&gt;ECharts&lt;/li&gt;
&lt;li&gt;Django-Debug-Toolbar&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day47---" class="anchor" aria-hidden="true" href="#day47---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day47 - &lt;a href="./Day41-55/47.%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;Django&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day48---" class="anchor" aria-hidden="true" href="#day48---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day48 - &lt;a href="./Day41-55/48.%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%BC%80%E5%8F%91%E5%85%A5%E9%97%A8.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;JSON&lt;/li&gt;
&lt;li&gt;Vue.js&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day49---restfuldrf" class="anchor" aria-hidden="true" href="#day49---restfuldrf"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day49 - &lt;a href="./Day41-55/49.RESTful%E6%9E%B6%E6%9E%84%E5%92%8CDRF%E5%85%A5%E9%97%A8.md"&gt;RESTfulDRF&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day50---restfuldrf" class="anchor" aria-hidden="true" href="#day50---restfuldrf"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day50 - &lt;a href="./Day41-55/50.RESTful%E6%9E%B6%E6%9E%84%E5%92%8CDRF%E8%BF%9B%E9%98%B6.md"&gt;RESTfulDRF&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day51---" class="anchor" aria-hidden="true" href="#day51---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day51 - &lt;a href="./Day41-55/51.%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DjangoRedis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day52---" class="anchor" aria-hidden="true" href="#day52---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day52 - &lt;a href="./Day41-55/52.%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%92%8C%E5%AF%8C%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;wangEditor&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day53---" class="anchor" aria-hidden="true" href="#day53---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day53 - &lt;a href="./Day41-55/53.%E7%9F%AD%E4%BF%A1%E5%92%8C%E9%82%AE%E4%BB%B6.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;Django&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day54---" class="anchor" aria-hidden="true" href="#day54---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day54 - &lt;a href="./Day41-55/54.%E5%BC%82%E6%AD%A5%E4%BB%BB%E5%8A%A1%E5%92%8C%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;celery&lt;/li&gt;
&lt;li&gt;celery&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day55---" class="anchor" aria-hidden="true" href="#day55---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day55 - &lt;a href="./Day41-55/55.%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E5%92%8C%E9%A1%B9%E7%9B%AE%E4%B8%8A%E7%BA%BF.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;Django&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;uWSGI&lt;/li&gt;
&lt;li&gt;Nginx&lt;/li&gt;
&lt;li&gt;HTTPS&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day5660---flask" class="anchor" aria-hidden="true" href="#day5660---flask"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day56~60 - &lt;a href="./Day56-65"&gt;Flask&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day56---flask" class="anchor" aria-hidden="true" href="#day56---flask"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day56 - &lt;a href="./Day56-60/56.Flask%E5%85%A5%E9%97%A8.md"&gt;Flask&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day57---" class="anchor" aria-hidden="true" href="#day57---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day57 - &lt;a href="./Day56-60/57.%E6%A8%A1%E6%9D%BF%E7%9A%84%E4%BD%BF%E7%94%A8.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day58---" class="anchor" aria-hidden="true" href="#day58---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day58 - &lt;a href="./Day56-60/58.%E8%A1%A8%E5%8D%95%E7%9A%84%E5%A4%84%E7%90%86.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day59---" class="anchor" aria-hidden="true" href="#day59---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day59 - &lt;a href="./Day56-60/59.%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day60---" class="anchor" aria-hidden="true" href="#day60---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day60 - &lt;a href="./Day56-60/60.%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h3&gt;&lt;a id="user-content-day6165---tornado" class="anchor" aria-hidden="true" href="#day6165---tornado"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day61~65 - &lt;a href="./Day61-65"&gt;Tornado&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day61---" class="anchor" aria-hidden="true" href="#day61---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day61 - &lt;a href="./Day61-65/61.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;I/O&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day62---tornado" class="anchor" aria-hidden="true" href="#day62---tornado"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day62 - &lt;a href="./Day61-65/62.Tornado%E5%85%A5%E9%97%A8.md"&gt;Tornado&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Tornado&lt;/li&gt;
&lt;li&gt;5Tornado&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day63---" class="anchor" aria-hidden="true" href="#day63---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day63 - &lt;a href="./Day61-65/63.%E5%BC%82%E6%AD%A5%E5%8C%96.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;aiomysqlaioredis&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day64---websocket" class="anchor" aria-hidden="true" href="#day64---websocket"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day64 - &lt;a href="./Day61-65/64.WebSocket%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;WebSocket&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;WebSocket&lt;/li&gt;
&lt;li&gt;WebSocket&lt;/li&gt;
&lt;li&gt;WebSocket&lt;/li&gt;
&lt;li&gt;Web&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day65---" class="anchor" aria-hidden="true" href="#day65---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day65 - &lt;a href="./Day61-65/65.%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;Vue.js&lt;/li&gt;
&lt;li&gt;ECharts&lt;/li&gt;
&lt;li&gt;WebSocket&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day6675---" class="anchor" aria-hidden="true" href="#day6675---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day66~75 - &lt;a href="./Day66-75"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day66---" class="anchor" aria-hidden="true" href="#day66---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day66 - &lt;a href="./Day66-75/66.%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%92%8C%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day67---" class="anchor" aria-hidden="true" href="#day67---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day67 - &lt;a href="./Day66-75/67.%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%92%8C%E8%A7%A3%E6%9E%90.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt; / XPath / CSS&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day68---" class="anchor" aria-hidden="true" href="#day68---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day68 - &lt;a href="./Day66-75/68.%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day69---" class="anchor" aria-hidden="true" href="#day69---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day69 - &lt;a href="./Day66-75/69.%E5%B9%B6%E5%8F%91%E4%B8%8B%E8%BD%BD.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;I/O&lt;/li&gt;
&lt;li&gt;asyncawait&lt;/li&gt;
&lt;li&gt;aiohttp&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day70---" class="anchor" aria-hidden="true" href="#day70---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day70 - &lt;a href="./Day66-75/70.%E8%A7%A3%E6%9E%90%E5%8A%A8%E6%80%81%E5%86%85%E5%AE%B9.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;JavaScript&lt;/li&gt;
&lt;li&gt;Selenium&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day71---" class="anchor" aria-hidden="true" href="#day71---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day71 - &lt;a href="./Day66-75/71.%E8%A1%A8%E5%8D%95%E4%BA%A4%E4%BA%92%E5%92%8C%E9%AA%8C%E8%AF%81%E7%A0%81%E5%A4%84%E7%90%86.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;Cookie&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day72---scrapy" class="anchor" aria-hidden="true" href="#day72---scrapy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day72 - &lt;a href="./Day66-75/72.Scrapy%E5%85%A5%E9%97%A8.md"&gt;Scrapy&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Scrapy&lt;/li&gt;
&lt;li&gt;Scrapy&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day73---scrapy" class="anchor" aria-hidden="true" href="#day73---scrapy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day73 - &lt;a href="./Day66-75/73.Scrapy%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8.md"&gt;Scrapy&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Spider&lt;/li&gt;
&lt;li&gt; / &lt;/li&gt;
&lt;li&gt;ScrapySelenium&lt;/li&gt;
&lt;li&gt;ScrapyDocker&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day74---scrapy" class="anchor" aria-hidden="true" href="#day74---scrapy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day74 - &lt;a href="./Day66-75/74.Scrapy%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E7%8E%B0.md"&gt;Scrapy&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;Scrapy&lt;/li&gt;
&lt;li&gt;Scrapyd&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day75---" class="anchor" aria-hidden="true" href="#day75---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day75 - &lt;a href="./Day66-75/75.%E7%88%AC%E8%99%AB%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day7690---" class="anchor" aria-hidden="true" href="#day7690---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day76~90 - &lt;a href="./Day76-90"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day76---" class="anchor" aria-hidden="true" href="#day76---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day76 - &lt;a href="./Day76-90/76.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day77---pandas" class="anchor" aria-hidden="true" href="#day77---pandas"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day77 - &lt;a href="./Day76-90/77.Pandas%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;Pandas&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day78---numpyscipy" class="anchor" aria-hidden="true" href="#day78---numpyscipy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day78 - &lt;a href="./Day76-90/78.NumPy%E5%92%8CSciPy%E7%9A%84%E5%BA%94%E7%94%A8"&gt;NumPySciPy&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day79---matplotlib" class="anchor" aria-hidden="true" href="#day79---matplotlib"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day79 - &lt;a href="./Day76-90/79.Matplotlib%E5%92%8C%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96"&gt;Matplotlib&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day80---kknn" class="anchor" aria-hidden="true" href="#day80---kknn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day80 - &lt;a href="./Day76-90/80.k%E6%9C%80%E8%BF%91%E9%82%BB%E5%88%86%E7%B1%BB.md"&gt;k(KNN)&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day81---" class="anchor" aria-hidden="true" href="#day81---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day81 - &lt;a href="./Day76-90/81.%E5%86%B3%E7%AD%96%E6%A0%91.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day82---" class="anchor" aria-hidden="true" href="#day82---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day82 - &lt;a href="./Day76-90/82.%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day83---svm" class="anchor" aria-hidden="true" href="#day83---svm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day83 - &lt;a href="./Day76-90/83.%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.md"&gt;(SVM)&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day84---k-" class="anchor" aria-hidden="true" href="#day84---k-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day84 - &lt;a href="./Day76-90/84.K-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB.md"&gt;K-&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day85---" class="anchor" aria-hidden="true" href="#day85---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day85 - &lt;a href="./Day76-90/85.%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day86---" class="anchor" aria-hidden="true" href="#day86---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day86 - &lt;a href="./Day76-90/86.%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%85%A5%E9%97%A8.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day87---" class="anchor" aria-hidden="true" href="#day87---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day87 - &lt;a href="./Day76-90/87.%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%BF%9B%E9%98%B6.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day88---tensorflow" class="anchor" aria-hidden="true" href="#day88---tensorflow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day88 - &lt;a href="./Day76-90/88.Tensorflow%E5%85%A5%E9%97%A8.md"&gt;Tensorflow&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day89---tensorflow" class="anchor" aria-hidden="true" href="#day89---tensorflow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day89 - &lt;a href="./Day76-90/89.Tensorflow%E5%AE%9E%E6%88%98.md"&gt;Tensorflow&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day90---" class="anchor" aria-hidden="true" href="#day90---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day90 - &lt;a href="./Day76-90/90.%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h3&gt;&lt;a id="user-content-day91100---" class="anchor" aria-hidden="true" href="#day91100---"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day91~100 - &lt;a href="./Day91-100"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-91" class="anchor" aria-hidden="true" href="#91"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;91&lt;a href="./Day91-100/91.%E5%9B%A2%E9%98%9F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;ER&lt;/li&gt;
&lt;li&gt; / &lt;/li&gt;
&lt;li&gt; / &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scrum- Scrum Master - Sprint&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Backlog&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;bug&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;Showcase&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;/strong&gt;  &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;/strong&gt;  &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;/strong&gt;  &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;/strong&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/agile-scrum-sprint-cycle.png"&gt;&lt;img src="./res/agile-scrum-sprint-cycle.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;8-10&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;LogoUIto doin progressdone&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/company_architecture.png"&gt;&lt;img src="./res/company_architecture.png" alt="company_architecture" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;flake8pylint&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/pylint.png"&gt;&lt;img src="./res/pylint.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Python&lt;a href="Python%E6%83%AF%E4%BE%8B.md"&gt;Python-Pythonic&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;-&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GitMercury&lt;/li&gt;
&lt;li&gt;&lt;a href="https://about.gitlab.com/" rel="nofollow"&gt;Gitlab&lt;/a&gt;&lt;a href="http://www.redmine.org.cn/" rel="nofollow"&gt;Redmine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zentao.net/" rel="nofollow"&gt;&lt;/a&gt;&lt;a href="https://www.atlassian.com/software/jira/features" rel="nofollow"&gt;JIRA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jenkins.io/" rel="nofollow"&gt;Jenkins&lt;/a&gt;&lt;a href="https://travis-ci.org/" rel="nofollow"&gt;Travis-CI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="Day91-100/91.%E5%9B%A2%E9%98%9F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-" class="anchor" aria-hidden="true" href="#"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CMS//&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MIS+KMSKPIHRSCRM&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;App+&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;XMind&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/requirements_by_xmind.png"&gt;&lt;img src="./res/requirements_by_xmind.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;50%&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;0%&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;20%&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;0%&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2018/8/8&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/8&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OOAD&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;UML&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/uml-class-diagram.png"&gt;&lt;img src="./res/uml-class-diagram.png" alt="uml" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python manage.py makemigrations app
python manage.py migrate&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PowerDesigner&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/power-designer-pdm.png"&gt;&lt;img src="./res/power-designer-pdm.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python manage.py inspectdb &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; app/models.py&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-92docker" class="anchor" aria-hidden="true" href="#92docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;92&lt;a href="./Day91-100/92.Docker%E5%AE%B9%E5%99%A8%E8%AF%A6%E8%A7%A3.md"&gt;Docker&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;DockerNginxMySQLRedisGitlabJenkins&lt;/li&gt;
&lt;li&gt;DockerDockerfile&lt;/li&gt;
&lt;li&gt;Docker-compose&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-93mysql" class="anchor" aria-hidden="true" href="#93mysql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;93&lt;a href="./Day91-100/93.MySQL%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.md"&gt;MySQL&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-94api" class="anchor" aria-hidden="true" href="#94api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;94&lt;a href="./Day91-100/94.%E7%BD%91%E7%BB%9CAPI%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1.md"&gt;API&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-95djangoday91-10095djangomd" class="anchor" aria-hidden="true" href="#95djangoday91-10095djangomd"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;95[Django](./Day91-100/95.Django	.md)&lt;/h4&gt;
&lt;h5&gt;&lt;a id="user-content-" class="anchor" aria-hidden="true" href="#"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;Django-Debug-ToolBar&lt;/li&gt;
&lt;li&gt;PythonAPI&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-rest-api" class="anchor" aria-hidden="true" href="#rest-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;REST API&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;RESTful
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.ruanyifeng.com/blog/2011/09/restful.html" rel="nofollow"&gt;RESTful&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ruanyifeng.com/blog/2014/05/restful_api.html" rel="nofollow"&gt;RESTful API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html" rel="nofollow"&gt;RESTful API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;API
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://rap2.taobao.org/" rel="nofollow"&gt;RAP2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://yapi.demo.qunar.com/" rel="nofollow"&gt;YAPI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.django-rest-framework.org/" rel="nofollow"&gt;django-REST-framework&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-" class="anchor" aria-hidden="true" href="#"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt; - Redis&lt;/li&gt;
&lt;li&gt; - Celery + RabbitMQ&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-96" class="anchor" aria-hidden="true" href="#96"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;96&lt;a href="Day91-100/96.%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E5%92%8C%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h5&gt;&lt;a id="user-content-" class="anchor" aria-hidden="true" href="#"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;unittestpytestnose2toxddt&lt;/li&gt;
&lt;li&gt;coverage&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-" class="anchor" aria-hidden="true" href="#"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;SECRET_KEY / DEBUG / ALLOWED_HOSTS /  / &lt;/li&gt;
&lt;li&gt;HTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECURE&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Linux&lt;/li&gt;
&lt;li&gt;Linux&lt;/li&gt;
&lt;li&gt;uWSGI/GunicornNginx
&lt;ul&gt;
&lt;li&gt;GunicornuWSGI
&lt;ul&gt;
&lt;li&gt;GunicornuWSGIGunicornGunicorn&lt;/li&gt;
&lt;li&gt;uWSGI&lt;/li&gt;
&lt;li&gt;NginxuWSGINginxuWSGIuWSGIWSGI&lt;/li&gt;
&lt;li&gt;GunicornuWSGI&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-" class="anchor" aria-hidden="true" href="#"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;AB&lt;/li&gt;
&lt;li&gt;SQLslap&lt;/li&gt;
&lt;li&gt;sysbench&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-" class="anchor" aria-hidden="true" href="#"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;ShellPython&lt;/li&gt;
&lt;li&gt;Selenium
&lt;ul&gt;
&lt;li&gt;Selenium IDE&lt;/li&gt;
&lt;li&gt;Selenium WebDriver&lt;/li&gt;
&lt;li&gt;Selenium Remote Control&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Robot Framework&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-97" class="anchor" aria-hidden="true" href="#97"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;97&lt;a href="./Day91-100/97.%E7%94%B5%E5%95%86%E7%BD%91%E7%AB%99%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9%E5%89%96%E6%9E%90.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-98" class="anchor" aria-hidden="true" href="#98"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;98&lt;a href="./Day91-100/98.%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E4%B8%8A%E7%BA%BF%E5%92%8C%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;MySQL&lt;/li&gt;
&lt;li&gt;Web
&lt;ul&gt;
&lt;li&gt;Nginx&lt;/li&gt;
&lt;li&gt;Keepalived&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;CDN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-99" class="anchor" aria-hidden="true" href="#99"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;99&lt;a href="./Day91-100/99.%E9%9D%A2%E8%AF%95%E4%B8%AD%E7%9A%84%E5%85%AC%E5%85%B1%E9%97%AE%E9%A2%98.md"&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-100python" class="anchor" aria-hidden="true" href="#100python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;100&lt;a href="./Day91-100/100.Python%E9%9D%A2%E8%AF%95%E9%A2%98%E9%9B%86.md"&gt;Python&lt;/a&gt;&lt;/h4&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jackfrued</author><guid isPermaLink="false">https://github.com/jackfrued/Python-100-Days</guid><pubDate>Wed, 05 Feb 2020 00:24:00 GMT</pubDate></item><item><title>NVIDIA-AI-IOT/jetracer #25 in Jupyter Notebook, This week</title><link>https://github.com/NVIDIA-AI-IOT/jetracer</link><description>&lt;p&gt;&lt;i&gt;An autonomous AI racecar using NVIDIA Jetson Nano&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-jetracer" class="anchor" aria-hidden="true" href="#jetracer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;JetRacer&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4212806/67442981-ce459e00-f5b7-11e9-9c8a-14ab360decb8.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/4212806/67442981-ce459e00-f5b7-11e9-9c8a-14ab360decb8.gif" height="256" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;JetRacer is an autonomous AI racecar using NVIDIA Jetson Nano.  With JetRacer you will&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Go fast - Optimize for high framerates to move at high speeds&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Have fun - Follow examples and program interactively from your web browser&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By building and experimenting with JetRacer you will create fast AI pipelines and push the boundaries of speed.&lt;/p&gt;
&lt;p&gt;To get started, follow the &lt;a href="#setup"&gt;setup&lt;/a&gt; below.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-cars" class="anchor" aria-hidden="true" href="#cars"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cars&lt;/h2&gt;
&lt;p&gt;There are two different JetRacer cars that you can build.  They differ primarily in size and speed.  Which one to pick depends on your use case&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Latrax Rally&lt;/th&gt;
&lt;th&gt;Tamiya TT02&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/25759564/67250038-b1c22e00-f41e-11e9-82d2-bbb17526310b.jpg"&gt;&lt;img src="https://user-images.githubusercontent.com/25759564/67250038-b1c22e00-f41e-11e9-82d2-bbb17526310b.jpg" width="256" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/25759564/67250039-b1c22e00-f41e-11e9-931f-98c1729550d0.jpg"&gt;&lt;img src="https://user-images.githubusercontent.com/25759564/67250039-b1c22e00-f41e-11e9-931f-98c1729550d0.jpg" width="320" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1/18th scale&lt;/td&gt;
&lt;td&gt;1/10th scale&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Moderate Speed&lt;/td&gt;
&lt;td&gt;High Speed&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;~$400 total build cost&lt;/td&gt;
&lt;td&gt;~$600 total build cost&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Compact and portable&lt;/td&gt;
&lt;td&gt;Large and easy to modify&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Soldering required&lt;/td&gt;
&lt;td&gt;No soldering required&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Base car pre-assembled&lt;/td&gt;
&lt;td&gt;Base car assembly required&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;If you have any questions, please reach out by &lt;a href="../..//issues"&gt;creating an issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;p&gt;JetRacer comes with a couple examples to get you up and running.  The examples are in the format of Jupyter Notebooks, which are interactive documents which combine text, code, and visualization.  Once you've completed the notebooks, start tweaking them to create your own racing software!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-example-1---basic-motion" class="anchor" aria-hidden="true" href="#example-1---basic-motion"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example 1 - Basic motion&lt;/h3&gt;
&lt;p&gt;In this example you'll learn to progam JetRacer programatically from your web browser.  Learn more in the &lt;a href="docs/examples.md"&gt;examples&lt;/a&gt; documentation.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4212806/60383497-68d90a80-9a26-11e9-9a18-778b7d3a3221.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/4212806/60383497-68d90a80-9a26-11e9-9a18-778b7d3a3221.gif" height="300/" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-example-2---road-following" class="anchor" aria-hidden="true" href="#example-2---road-following"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example 2 - Road following&lt;/h3&gt;
&lt;p&gt;In this example, you'll teach JetRacer how to follow a road using AI.  After training the neural network using the &lt;a href="notebooks/interactive_regression.ipynb"&gt;interactive training notebook&lt;/a&gt;, you'll optimize the model using NVIDIA TensorRT and deploy for a live demo. Learn more in the &lt;a href="docs/examples.md"&gt;examples&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4212806/60383389-bd7b8600-9a24-11e9-9f64-926e5edb52cc.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/4212806/60383389-bd7b8600-9a24-11e9-9f64-926e5edb52cc.gif" height="300/" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h2&gt;
&lt;p&gt;To get started with JetRacer, follow these steps&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Order parts from the bill of materials&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/latrax/bill_of_materials.md"&gt;Latrax version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/tamiya/bill_of_materials.md"&gt;Tamiya version&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow the hardware setup&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/latrax/hardware_setup.md"&gt;Latrax version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/tamiya/hardware_setup.md"&gt;Tamiya version&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow the &lt;a href="docs/software_setup.md"&gt;software setup&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run through the &lt;a href="docs/examples.md"&gt;examples&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-see-also" class="anchor" aria-hidden="true" href="#see-also"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;See also&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://github.com/NVIDIA-AI-IOT/jetbot"&gt;JetBot&lt;/a&gt; - An educational AI robot based on NVIDIA Jetson Nano&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://github.com/NVIDIA-AI-IOT/jetcam"&gt;JetCam&lt;/a&gt; - An easy to use Python camera interface for NVIDIA Jetson&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://github.com/NVIDIA-AI-IOT/jetcard"&gt;JetCard&lt;/a&gt; - An SD card image for web programming AI projects with NVIDIA Jetson Nano&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://github.com/NVIDIA-AI-IOT/torch2trt"&gt;torch2trt&lt;/a&gt; - An easy to use PyTorch to TensorRT converter&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>NVIDIA-AI-IOT</author><guid isPermaLink="false">https://github.com/NVIDIA-AI-IOT/jetracer</guid><pubDate>Wed, 05 Feb 2020 00:25:00 GMT</pubDate></item></channel></rss>