<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Jupyter Notebook, This week</title><link>https://github.com/trending/jupyter-notebook?since=weekly</link><description>The top repositories on GitHub for jupyter-notebook, measured weekly</description><pubDate>Sat, 04 Jan 2020 01:10:46 GMT</pubDate><lastBuildDate>Sat, 04 Jan 2020 01:10:46 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>rasbt/deeplearning-models #1 in Jupyter Notebook, This week</title><link>https://github.com/rasbt/deeplearning-models</link><description>&lt;p&gt;&lt;i&gt;A collection of various deep learning architectures, models, and tips&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/61841a3590d58efb5f368ffb4d82ef16e216fd82/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e372d626c75652e737667"&gt;&lt;img src="https://camo.githubusercontent.com/61841a3590d58efb5f368ffb4d82ef16e216fd82/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e372d626c75652e737667" alt="Python 3.7" data-canonical-src="https://img.shields.io/badge/Python-3.7-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-deep-learning-models" class="anchor" aria-hidden="true" href="#deep-learning-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning Models&lt;/h1&gt;
&lt;p&gt;A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-traditional-machine-learning" class="anchor" aria-hidden="true" href="#traditional-machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Traditional Machine Learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Perceptron&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/basic-ml/perceptron.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/basic-ml/perceptron.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/basic-ml/perceptron.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/basic-ml/perceptron.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Logistic Regression&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/basic-ml/logistic-regression.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/basic-ml/logistic-regression.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/basic-ml/logistic-regression.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/basic-ml/logistic-regression.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Softmax Regression (Multinomial Logistic Regression)&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/basic-ml/softmax-regression.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/basic-ml/softmax-regression.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/basic-ml/softmax-regression.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/basic-ml/softmax-regression.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Softmax Regression with MLxtend's plot_decision_regions on Iris&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/basic-ml/softmax-regression-mlxtend-1.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/basic-ml/softmax-regression-mlxtend-1.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-multilayer-perceptrons" class="anchor" aria-hidden="true" href="#multilayer-perceptrons"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Multilayer Perceptrons&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Multilayer Perceptron&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/mlp/mlp-basic.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/mlp/mlp-basic.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mlp/mlp-basic.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mlp/mlp-basic.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Multilayer Perceptron with Dropout&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/mlp/mlp-dropout.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/mlp/mlp-dropout.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mlp/mlp-dropout.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mlp/mlp-dropout.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Multilayer Perceptron with Batch Normalization&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/mlp/mlp-batchnorm.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/mlp/mlp-batchnorm.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mlp/mlp-batchnorm.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mlp/mlp-batchnorm.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Multilayer Perceptron with Backpropagation from Scratch&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/mlp/mlp-lowlevel.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/mlp/mlp-lowlevel.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mlp/mlp-fromscratch__sigmoid-mse.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mlp/mlp-fromscratch__sigmoid-mse.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-convolutional-neural-networks" class="anchor" aria-hidden="true" href="#convolutional-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Convolutional Neural Networks&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-basic" class="anchor" aria-hidden="true" href="#basic"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Basic&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Convolutional Neural Network&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/cnn/cnn-basic.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/cnn/cnn-basic.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-basic.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-basic.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Convolutional Neural Network with He Initialization&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-he-init.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-he-init.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-concepts" class="anchor" aria-hidden="true" href="#concepts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Concepts&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Replacing Fully-Connnected by Equivalent Convolutional Layers&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/fc-to-conv.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/fc-to-conv.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-fully-convolutional" class="anchor" aria-hidden="true" href="#fully-convolutional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fully Convolutional&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Fully Convolutional Neural Network&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-allconv.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-allconv.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-lenet" class="anchor" aria-hidden="true" href="#lenet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LeNet&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;LeNet-5 on MNIST&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-lenet5-mnist.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-lenet5-mnist.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;LeNet-5 on CIFAR-10&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-lenet5-cifar10.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-lenet5-cifar10.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;LeNet-5 on QuickDraw&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-lenet5-quickdraw.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-lenet5-quickdraw.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-alexnet" class="anchor" aria-hidden="true" href="#alexnet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;AlexNet&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;AlexNet on CIFAR-10&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-alexnet-cifar10.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-alexnet-cifar10.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-vgg" class="anchor" aria-hidden="true" href="#vgg"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;VGG&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Convolutional Neural Network VGG-16&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/cnn/cnn-vgg16.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/cnn/cnn-vgg16.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-vgg16.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-vgg16.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;VGG-16 Gender Classifier Trained on CelebA&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-vgg16-celeba.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-vgg16-celeba.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Convolutional Neural Network VGG-19&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-vgg19.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-vgg19.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-densenet" class="anchor" aria-hidden="true" href="#densenet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DenseNet&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;DenseNet-121 Digit Classifier Trained on MNIST&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-densenet121-mnist.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-densenet121-mnist.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;DenseNet-121 Image Classifier Trained on CIFAR-10&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-densenet121-cifar10.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-densenet121-cifar10.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-resnet" class="anchor" aria-hidden="true" href="#resnet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ResNet&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;ResNet and Residual Blocks&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/resnet-ex-1.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/resnet-ex-1.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;ResNet-18 Digit Classifier Trained on MNIST&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-resnet18-mnist.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet18-mnist.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;ResNet-18 Gender Classifier Trained on CelebA&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-resnet18-celeba-dataparallel.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet18-celeba-dataparallel.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;ResNet-34 Digit Classifier Trained on MNIST&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-resnet34-mnist.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet34-mnist.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;ResNet-34 Object Classifier Trained on QuickDraw&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-resnet34-quickdraw.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet34-quickdraw.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;ResNet-34 Gender Classifier Trained on CelebA&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-resnet34-celeba-dataparallel.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet34-celeba-dataparallel.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;ResNet-50 Digit Classifier Trained on MNIST&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-resnet50-mnist.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet50-mnist.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;ResNet-50 Gender Classifier Trained on CelebA&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-resnet50-celeba-dataparallel.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet50-celeba-dataparallel.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;ResNet-101 Gender Classifier Trained on CelebA&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-resnet101-celeba.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet101-celeba.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;ResNet-101 Trained on CIFAR-10&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-resnet101-cifar10.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet101-cifar10.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;ResNet-152 Gender Classifier Trained on CelebA&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-resnet152-celeba.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet152-celeba.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-network-in-network" class="anchor" aria-hidden="true" href="#network-in-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Network in Network&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Network in Network CIFAR-10 Classifier&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/nin-cifar10.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/nin-cifar10.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-normalization-layers" class="anchor" aria-hidden="true" href="#normalization-layers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Normalization Layers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;BatchNorm before and after Activation for Network-in-Network CIFAR-10 Classifier&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/nin-cifar10_batchnorm.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/nin-cifar10_batchnorm.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Filter Response Normalization for Network-in-Network CIFAR-10 Classifier&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/nin-cifar10_filter-response-norm.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/nin-cifar10_filter-response-norm.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-metric-learning" class="anchor" aria-hidden="true" href="#metric-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Metric Learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Siamese Network with Multilayer Perceptrons&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/metric/siamese-1.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/metric/siamese-1.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-autoencoders" class="anchor" aria-hidden="true" href="#autoencoders"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Autoencoders&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-fully-connected-autoencoders" class="anchor" aria-hidden="true" href="#fully-connected-autoencoders"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fully-connected Autoencoders&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Autoencoder (MNIST)&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/autoencoder/ae-basic.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/autoencoder/ae-basic.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-basic.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-basic.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Autoencoder (MNIST) + Scikit-Learn Random Forest Classifier&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/autoencoder/ae-basic-with-rf.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/autoencoder/ae-basic.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-basic-with-rf.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-basic.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-convolutional-autoencoders" class="anchor" aria-hidden="true" href="#convolutional-autoencoders"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Convolutional Autoencoders&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Convolutional Autoencoder with Deconvolutions / Transposed Convolutions&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/autoencoder/ae-deconv.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/autoencoder/ae-deconv.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-deconv.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-deconv.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Convolutional Autoencoder with Deconvolutions and Continuous Jaccard Distance&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-deconv-jaccard.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-deconv-jaccard.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Convolutional Autoencoder with Deconvolutions (without pooling operations)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-deconv-nopool.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-deconv-nopool.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Convolutional Autoencoder with Nearest-neighbor Interpolation&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/autoencoder/ae-conv-nneighbor.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/autoencoder/ae-conv-nneighbor.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-conv-nneighbor.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-conv-nneighbor.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Convolutional Autoencoder with Nearest-neighbor Interpolation -- Trained on CelebA&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-conv-nneighbor-celeba.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-conv-nneighbor-celeba.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Convolutional Autoencoder with Nearest-neighbor Interpolation -- Trained on Quickdraw&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-conv-nneighbor-quickdraw-1.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-conv-nneighbor-quickdraw-1.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-variational-autoencoders" class="anchor" aria-hidden="true" href="#variational-autoencoders"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Variational Autoencoders&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Variational Autoencoder&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-var.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-var.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Convolutional Variational Autoencoder&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-conv-var.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-conv-var.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-conditional-variational-autoencoders" class="anchor" aria-hidden="true" href="#conditional-variational-autoencoders"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Conditional Variational Autoencoders&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Conditional Variational Autoencoder (with labels in reconstruction loss)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-cvae.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-cvae.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Conditional Variational Autoencoder (without labels in reconstruction loss)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-cvae_no-out-concat.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-cvae_no-out-concat.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Convolutional Conditional Variational Autoencoder (with labels in reconstruction loss)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-cnn-cvae.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-cnn-cvae.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Convolutional Conditional Variational Autoencoder (without labels in reconstruction loss)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/autoencoder/ae-cnn-cvae_no-out-concat.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-cnn-cvae_no-out-concat.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-generative-adversarial-networks-gans" class="anchor" aria-hidden="true" href="#generative-adversarial-networks-gans"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generative Adversarial Networks (GANs)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Fully Connected GAN on MNIST&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/gan/gan.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/gan/gan.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/gan/gan.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/gan/gan.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Fully Connected Wasserstein GAN on MNIST&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/gan/wgan-1.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/gan/wgan-1.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Convolutional GAN on MNIST&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/gan/gan-conv.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/gan/gan-conv.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/gan/gan-conv.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/gan/gan-conv.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Convolutional GAN on MNIST with Label Smoothing&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/gan/gan-conv-smoothing.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/gan/gan-conv-smoothing.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/gan/gan-conv-smoothing.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/gan/gan-conv-smoothing.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Convolutional Wasserstein GAN on MNIST&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/gan/dc-wgan-1.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/gan/dc-wgan-1.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-graph-neural-networks-gnns" class="anchor" aria-hidden="true" href="#graph-neural-networks-gnns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Graph Neural Networks (GNNs)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Most Basic Graph Neural Network with Gaussian Filter on MNIST&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/gnn/gnn-basic-1.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/gnn/gnn-basic-1.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Basic Graph Neural Network with Edge Prediction on MNIST&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/gnn/gnn-basic-edge-1.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/gnn/gnn-basic-edge-1.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Basic Graph Neural Network with Spectral Graph Convolution on MNIST&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/gnn/gnn-basic-graph-spectral-1.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/gnn/gnn-basic-graph-spectral-1.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-recurrent-neural-networks-rnns" class="anchor" aria-hidden="true" href="#recurrent-neural-networks-rnns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Recurrent Neural Networks (RNNs)&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-many-to-one-sentiment-analysis--classification" class="anchor" aria-hidden="true" href="#many-to-one-sentiment-analysis--classification"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Many-to-one: Sentiment Analysis / Classification&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;A simple single-layer RNN (IMDB)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/rnn/rnn_simple_imdb.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_simple_imdb.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;A simple single-layer RNN with packed sequences to ignore padding characters (IMDB)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/rnn/rnn_simple_packed_imdb.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_simple_packed_imdb.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;RNN with LSTM cells (IMDB)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/rnn/rnn_lstm_packed_imdb.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_lstm_packed_imdb.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;RNN with LSTM cells (IMDB) and pre-trained GloVe word vectors&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/rnn/rnn_lstm_packed_imdb-glove.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_lstm_packed_imdb-glove.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;RNN with LSTM cells and Own Dataset in CSV Format (IMDB)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/rnn/rnn_lstm_packed_own_csv_imdb.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_lstm_packed_own_csv_imdb.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;RNN with GRU cells (IMDB)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/rnn/rnn_gru_packed_imdb.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_gru_packed_imdb.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Multilayer bi-directional RNN (IMDB)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/rnn/rnn_gru_packed_imdb.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_gru_packed_imdb.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Bidirectional Multi-layer RNN with LSTM with Own Dataset in CSV Format (AG News)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/rnn/rnn_bi_multilayer_lstm_own_csv_agnews.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_bi_multilayer_lstm_own_csv_agnews.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Bidirectional Multi-layer RNN with LSTM with Own Dataset in CSV Format (Yelp Review Polarity)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/rnn/rnn_bi_multilayer_lstm_own_csv_yelp-polarity.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_bi_multilayer_lstm_own_csv_yelp-polarity.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Bidirectional Multi-layer RNN with LSTM with Own Dataset in CSV Format (Amazon Review Polarity)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/rnn/rnn_bi_multilayer_lstm_own_csv_amazon-polarity.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_bi_multilayer_lstm_own_csv_amazon-polarity.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-many-to-many--sequence-to-sequence" class="anchor" aria-hidden="true" href="#many-to-many--sequence-to-sequence"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Many-to-Many / Sequence-to-Sequence&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;A simple character RNN to generate new text (Charles Dickens)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/rnn/char_rnn-charlesdickens.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/char_rnn-charlesdickens.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-ordinal-regression" class="anchor" aria-hidden="true" href="#ordinal-regression"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ordinal Regression&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ordinal Regression CNN -- CORAL w. ResNet34 on AFAD-Lite&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/ordinal/ordinal-cnn-coral-afadlite.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/ordinal/ordinal-cnn-coral-afadlite.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Ordinal Regression CNN -- Niu et al. 2016 w. ResNet34 on AFAD-Lite&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/ordinal/ordinal-cnn-niu-afadlite.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/ordinal/ordinal-cnn-niu-afadlite.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Ordinal Regression CNN -- Beckham and Pal 2016 w. ResNet34 on AFAD-Lite&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/ordinal/ordinal-cnn-beckham2016-afadlite.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/ordinal/ordinal-cnn-beckham2016-afadlite.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-tips-and-tricks" class="anchor" aria-hidden="true" href="#tips-and-tricks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tips and Tricks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Cyclical Learning Rate&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/tricks/cyclical-learning-rate.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/tricks/cyclical-learning-rate.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Annealing with Increasing the Batch Size (w. CIFAR-10 &amp;amp; AlexNet)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/tricks/cnn-alexnet-cifar10-batchincrease.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/tricks/cnn-alexnet-cifar10-batchincrease.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Gradient Clipping (w. MLP on MNIST)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/tricks/gradclipping_mlp.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/tricks/gradclipping_mlp.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-transfer-learning" class="anchor" aria-hidden="true" href="#transfer-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transfer Learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Transfer Learning Example (VGG16 pre-trained on ImageNet for Cifar-10)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;   [PyTorch: &lt;a href="pytorch_ipynb/transfer/transferlearning-vgg16-cifar10-1.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/transfer/transferlearning-vgg16-cifar10-1.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pytorch-workflows-and-mechanics" class="anchor" aria-hidden="true" href="#pytorch-workflows-and-mechanics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyTorch Workflows and Mechanics&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-custom-datasets" class="anchor" aria-hidden="true" href="#custom-datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Custom Datasets&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Custom Data Loader Example for PNG Files&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mechanics/custom-dataloader-png/custom-dataloader-example.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/custom-dataloader-png/custom-dataloader-example.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Using PyTorch Dataset Loading Utilities for Custom Datasets -- CSV files converted to HDF5&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mechanics/custom-data-loader-csv.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/custom-data-loader-csv.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Using PyTorch Dataset Loading Utilities for Custom Datasets -- Face Images from CelebA&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mechanics/custom-data-loader-celeba.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/custom-data-loader-celeba.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Using PyTorch Dataset Loading Utilities for Custom Datasets -- Drawings from Quickdraw&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mechanics/custom-data-loader-quickdraw.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/custom-data-loader-quickdraw.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Using PyTorch Dataset Loading Utilities for Custom Datasets -- Drawings from the Street View House Number (SVHN) Dataset&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mechanics/custom-data-loader-svhn.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/custom-data-loader-svhn.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Using PyTorch Dataset Loading Utilities for Custom Datasets -- Asian Face Dataset (AFAD)&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mechanics/custom-data-loader-afad.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/custom-data-loader-afad.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Using PyTorch Dataset Loading Utilities for Custom Datasets -- Dating Historical Color Images&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mechanics/custom-data-loader_dating-historical-color-images.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/custom-data-loader_dating-historical-color-images.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-training-and-preprocessing" class="anchor" aria-hidden="true" href="#training-and-preprocessing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training and Preprocessing&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Generating Validation Set Splits&lt;br&gt;
[PyTorch]: &lt;a href="pytorch_ipynb/mechanics/validation-splits.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/validation-splits.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Dataloading with Pinned Memory&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-resnet34-cifar10-pinmem.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet34-cifar10-pinmem.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Standardizing Images&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-standardized.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-standardized.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Image Transformation Examples&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mechanics/torchvision-transform-examples.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/torchvision-transform-examples.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Char-RNN with Own Text File&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/rnn/char_rnn-charlesdickens.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/char_rnn-charlesdickens.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Sentiment Classification RNN with Own CSV File&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/rnn/rnn_lstm_packed_own_csv_imdb.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_lstm_packed_own_csv_imdb.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-parallel-computing" class="anchor" aria-hidden="true" href="#parallel-computing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Parallel Computing&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Using Multiple GPUs with DataParallel -- VGG-16 Gender Classifier on CelebA&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/cnn/cnn-vgg16-celeba-data-parallel.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-vgg16-celeba-data-parallel.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-other" class="anchor" aria-hidden="true" href="#other"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Sequential API and hooks&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mechanics/mlp-sequential.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/mlp-sequential.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Weight Sharing Within a Layer&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mechanics/cnn-weight-sharing.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/cnn-weight-sharing.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Plotting Live Training Performance in Jupyter Notebooks with just Matplotlib&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mechanics/plot-jupyter-matplotlib.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/plot-jupyter-matplotlib.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-autograd" class="anchor" aria-hidden="true" href="#autograd"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Autograd&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Getting Gradients of an Intermediate Variable in PyTorch&lt;br&gt;
   [PyTorch: &lt;a href="pytorch_ipynb/mechanics/manual-gradients.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/mechanics/manual-gradients.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-tensorflow-workflows-and-mechanics" class="anchor" aria-hidden="true" href="#tensorflow-workflows-and-mechanics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow Workflows and Mechanics&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-custom-datasets-1" class="anchor" aria-hidden="true" href="#custom-datasets-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Custom Datasets&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Chunking an Image Dataset for Minibatch Training using NumPy NPZ Archives&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/mechanics/image-data-chunking-npz.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/mechanics/image-data-chunking-npz.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Storing an Image Dataset for Minibatch Training using HDF5&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/mechanics/image-data-chunking-hdf5.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/mechanics/image-data-chunking-hdf5.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Using Input Pipelines to Read Data from TFRecords Files&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/mechanics/tfrecords.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/mechanics/tfrecords.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Using Queue Runners to Feed Images Directly from Disk&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/mechanics/file-queues.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/mechanics/file-queues.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Using TensorFlow's Dataset API&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/mechanics/dataset-api.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/mechanics/dataset-api.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-training-and-preprocessing-1" class="anchor" aria-hidden="true" href="#training-and-preprocessing-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training and Preprocessing&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Saving and Loading Trained Models -- from TensorFlow Checkpoint Files and NumPy NPZ Archives&lt;br&gt;
   [TensorFlow 1: &lt;a href="tensorflow1_ipynb/mechanics/saving-and-reloading-models.ipynb"&gt;GitHub&lt;/a&gt; | &lt;a href="https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/tensorflow1_ipynb/mechanics/saving-and-reloading-models.ipynb" rel="nofollow"&gt;Nbviewer&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>rasbt</author><guid isPermaLink="false">https://github.com/rasbt/deeplearning-models</guid><pubDate>Sat, 04 Jan 2020 00:01:00 GMT</pubDate></item><item><title>chenyuntc/pytorch-book #2 in Jupyter Notebook, This week</title><link>https://github.com/chenyuntc/pytorch-book</link><description>&lt;p&gt;&lt;i&gt;PyTorch tutorials and fun projects including neural talk, neural style, poem writing, anime generation (《深度学习框架PyTorch：入门与实战》)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-english-version" class="anchor" aria-hidden="true" href="#english-version"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="README_EN.md"&gt;English Version&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;这是书籍《深度学习框架PyTorch：入门与实践》的对应代码，但是也可以作为一个独立的PyTorch入门指南和教程。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-更新说明" class="anchor" aria-hidden="true" href="#更新说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;更新说明&lt;/h2&gt;
&lt;p&gt;Working on migration to Pytorch 1.0, stay tuned!&lt;/p&gt;
&lt;p&gt;当前版本的代码是基于pytorch 1.0.1， 如果想使用旧版的 请 &lt;code&gt;git checkout v0.4&lt;/code&gt; 或者 &lt;code&gt;git checkout v0.3&lt;/code&gt;。旧版代码有更好的python2/python3 兼容，CPU/GPU兼容测试。 新版的代码未经过完整测试，已在GPU和python3 下测试通过。但是理论上在python2和CPU上不应该有太多的问题。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-内容" class="anchor" aria-hidden="true" href="#内容"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;内容&lt;/h2&gt;
&lt;p&gt;该书（教程/仓库）的内容如图所示：
&lt;a target="_blank" rel="noopener noreferrer" href="imgs/mindmap.png"&gt;&lt;img src="imgs/mindmap.png" alt="思维导图" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以看出本教程可以分为两部分：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基础部分&lt;/strong&gt;（前五章）讲解PyTorch内容，这部份介绍了PyTorch中主要的的模块，和深度学习中常用的一些工具。对于这部分内容，这里利用Jupyter Notebook作为教学工具，读者可以结合notebook修改运行，反复实验。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第二章介绍如何安装PyTorch和配置学习环境。同时提供了一个快速入门教程，基于官方的教程简化并更新内容，读者可以花费大约1到2小时的时间快速完成入门任务，而后根据需求再选择深入阅读后续相关章节的内容。&lt;/li&gt;
&lt;li&gt;第三章介绍了PyTorch中多维数组Tensor和动态图autograd/Variable的使用，并配以例子，让读者分别使用Tensor和autograd实现线性回归，比较二者的不同点。除了介绍这二者的基础使用之外，本章还对Tensor的底层设计，以及autograd的计算图原理进行比较深入分析，希望能使得读者能对这些底层知识有更全面的掌握。&lt;/li&gt;
&lt;li&gt;第四章介绍了PyTorch中神经网络模块nn的基础用法，同时讲解了神经网络中“层”，“损失函数”，“优化器”等，最后带领读者用不到50行的代码搭建出曾夺得ImageNet冠军的ResNet。&lt;/li&gt;
&lt;li&gt;第五章介绍了PyTorch中数据加载，GPU加速，持久化和可视化等相关工具。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;实战部分&lt;/strong&gt;（第六到十章）利用PyTorch实现了几个酷炫有趣的应用，对于这部分的内容，本仓库给出完整的实现代码，并提供预训练好的模型作为demo，供读者测试。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第六章是承上启下的一章，这一章的目标不是教会读者新函数，新知识，而是结合Kaggle中一个经典的比赛，实现一个深度学习中比较简单的图像二分类问题。在实现过程中，带领读者复习前五章的知识，并提出代码规范以合理的组织程序，代码，使得程序更加可读，可维护。第六章还介绍了在PyTorch中如何进行debug。&lt;/li&gt;
&lt;li&gt;第七章为读者讲解了当前最火爆的生成对抗网络（GAN），带领读者从头实现一个动漫头像生成器，能够利用GAN生成风格多变的动漫头像。&lt;/li&gt;
&lt;li&gt;第八章为读者讲解了风格迁移的相关知识，并带领读者实现风格迁移网络，将自己的照片变成高大上的名画。&lt;/li&gt;
&lt;li&gt;第九章为读者讲解了一些自然语言处理的基础知识，并讲解了CharRNN的原理。而后利用收集了几万首唐诗，训练出了一个可以自动写诗歌的小程序。这个小程序可以控制生成诗歌的&lt;strong&gt;格式&lt;/strong&gt;，&lt;strong&gt;意境&lt;/strong&gt;，还能生成&lt;strong&gt;藏头诗&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;第十章为读者介绍了图像描述任务，并以最新的AI Challenger比赛的数据为例，带领读者实现了一个可以进行简单图像描述的的小程序。&lt;/li&gt;
&lt;li&gt;第十一章（&lt;strong&gt;新增，实验性&lt;/strong&gt;） 由&lt;a href="https://github.com/Diamondfan"&gt;Diamondfan&lt;/a&gt; 编写的语音识别。完善了本项目（本项目已囊括图像，文本，语音三大领域的例子）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Notebook中的文字描述内容属于本书的初稿，有描述不通顺，错别字之处还请谅解&lt;/strong&gt;。本打算删除notebook中描述的内容，只留下代码，但为了方便读者阅读学习，最终还是决定留下。 我会抽空根据书中内容逐字校对这部分内容，但并不对此并不提供具体时间点。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-是否需要买书" class="anchor" aria-hidden="true" href="#是否需要买书"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;是否需要买书&lt;/h2&gt;
&lt;p&gt;书&lt;strong&gt;不是必要的&lt;/strong&gt;，这个仓库包含书中50%以上的文字内容，90%以上的代码，尤其是前几章入门内容，几乎是完全保留了书中的讲解内容。读者即使不买书也能正常使用本教程。&lt;/p&gt;
&lt;p&gt;&lt;del&gt;如果你觉得纸质书的优势吸引你，不妨小破费一笔，支持一下作者这大半年来的工作。同时为了尽可能的方便读者，笔者还专门开通腾讯云的服务，用以保存教程中用到的部分模型，预处理的数据和部分大文件。&lt;/del&gt;
书中的部分内容已经过时，以此仓库内容为准。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-代码说明" class="anchor" aria-hidden="true" href="#代码说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;代码说明&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;代码主要在python3下测试得到最终结果，python2暂未测试。v0.2和v0.3 分支的代码同时经过严格测试支持python2/python3&lt;/li&gt;
&lt;li&gt;实战部分代码同时在GPU和CPU环境下测试通过&lt;/li&gt;
&lt;li&gt;代码已更新兼容到PyTorch &lt;code&gt;0.4.1&lt;/code&gt;, 后续会考虑兼容 &lt;code&gt;v1.0&lt;/code&gt;，但暂无确切时间点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你想在PyTorch 0.2.0或0.3下运行,请&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git checkout v0.2 # v0.3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果有任何不当，或者有待改进的地方，欢迎读者开issue讨论，或者提交pull request。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-环境配置" class="anchor" aria-hidden="true" href="#环境配置"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;环境配置&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;安装&lt;a href="http://pytorch.org" rel="nofollow"&gt;PyTorch&lt;/a&gt;，请从官网选择指定的版本安装即可，一键安装（即使你使用anaconda，也建议使用pip）。更多的安装方式请参阅书中说明。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;克隆仓库&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;git clone https:&lt;span class="pl-k"&gt;//&lt;/span&gt;github.com&lt;span class="pl-k"&gt;/&lt;/span&gt;chenyuntc&lt;span class="pl-k"&gt;/&lt;/span&gt;PyTorch&lt;span class="pl-k"&gt;-&lt;/span&gt;book.git&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装第三方依赖包&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;cd pytorch&lt;span class="pl-k"&gt;-&lt;/span&gt;book &lt;span class="pl-ii"&gt;&amp;amp;&amp;amp;&lt;/span&gt; pip install &lt;span class="pl-k"&gt;-&lt;/span&gt;r requirements.txt&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-visdom打不开及其解决方案" class="anchor" aria-hidden="true" href="#visdom打不开及其解决方案"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Visdom打不开及其解决方案&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;新版的visdom已经解决了这个问题,只需要升级即可&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install --upgrade visdom
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;之前的&lt;a href="https://github.com/chenyuntc/pytorch-book/blob/2c8366137b691aaa8fbeeea478cc1611c09e15f5/README.md#visdom%E6%89%93%E4%B8%8D%E5%BC%80%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"&gt;解决方案&lt;/a&gt; 不再需要，已删除。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-_" class="anchor" aria-hidden="true" href="#_"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;^_^&lt;/h2&gt;
&lt;p&gt;有任何bug，解释不清楚的地方或者是困惑，欢迎开issue&lt;/p&gt;
&lt;p&gt;欢迎pull requests&lt;/p&gt;
&lt;p&gt;Happy Coding!&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0376580818bbc47cd4b2f29ab6ca684122ba6e9f/687474703a2f2f696d6731342e333630627579696d672e636f6d2f6e312f6a66732f7431333333392f33322f323436333733303139382f3231373438332f65383134386336622f35613431323737644e62643134373063312e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/0376580818bbc47cd4b2f29ab6ca684122ba6e9f/687474703a2f2f696d6731342e333630627579696d672e636f6d2f6e312f6a66732f7431333333392f33322f323436333733303139382f3231373438332f65383134386336622f35613431323737644e62643134373063312e6a7067" alt="" data-canonical-src="http://img14.360buyimg.com/n1/jfs/t13339/32/2463730198/217483/e8148c6b/5a41277dNbd1470c1.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://search.jd.com/Search?keyword=pytorch%20%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AE%9E%E8%B7%B5&amp;amp;enc=utf-8&amp;amp;wq=pytorch%20%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AE%9E%E8%B7%B5&amp;amp;pvid=8b0d91d7108845ad8cbaf596326f3eb3" rel="nofollow"&gt;京东购买链接&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://search.dangdang.com/?key=pytorch%20%C8%EB%C3%C5%D3%EB%CA%B5%BC%F9&amp;amp;act=input" rel="nofollow"&gt;当当购买链接&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>chenyuntc</author><guid isPermaLink="false">https://github.com/chenyuntc/pytorch-book</guid><pubDate>Sat, 04 Jan 2020 00:02:00 GMT</pubDate></item><item><title>lexfridman/mit-deep-learning #3 in Jupyter Notebook, This week</title><link>https://github.com/lexfridman/mit-deep-learning</link><description>&lt;p&gt;&lt;i&gt;Tutorials, assignments, and competitions for MIT Deep Learning related courses.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-mit-deep-learning" class="anchor" aria-hidden="true" href="#mit-deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MIT Deep Learning&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://deeplearning.mit.edu/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/42d3d635cdb0e88dee786c6edc1f41e0902faa2b/68747470733a2f2f646565706c6561726e696e672e6d69742e6564752f66696c65732f696d616765732f6d69745f646565705f6c6561726e696e672e706e67" data-canonical-src="https://deeplearning.mit.edu/files/images/mit_deep_learning.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repository is a collection of tutorials for &lt;a href="https://deeplearning.mit.edu/" rel="nofollow"&gt;MIT Deep Learning&lt;/a&gt; courses. More added as courses progress.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tutorial-deep-learning-basics" class="anchor" aria-hidden="true" href="#tutorial-deep-learning-basics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorial: Deep Learning Basics&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb"&gt;&lt;img src="https://camo.githubusercontent.com/0d2d7920619e3df257f1c677431968ff491a5e80/68747470733a2f2f692e696d6775722e636f6d2f6a3446714275522e676966" data-canonical-src="https://i.imgur.com/j4FqBuR.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tutorial accompanies the &lt;a href="https://www.youtube.com/watch?list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf&amp;amp;v=O5xeyoRL95U" rel="nofollow"&gt;lecture on Deep Learning Basics&lt;/a&gt;. It presents several concepts in deep learning, demonstrating the first two (feed forward and convolutional neural networks) and providing pointers to tutorials on the others. This is a good place to start.&lt;/p&gt;
&lt;p&gt;Links: [ &lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb"&gt;Jupyter Notebook&lt;/a&gt; ]
[ &lt;a href="https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb" rel="nofollow"&gt;Google Colab&lt;/a&gt; ]
[ &lt;a href="https://medium.com/tensorflow/mit-deep-learning-basics-introduction-and-overview-with-tensorflow-355bcd26baf0" rel="nofollow"&gt;Blog Post&lt;/a&gt; ]
[ &lt;a href="https://www.youtube.com/watch?list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf&amp;amp;v=O5xeyoRL95U" rel="nofollow"&gt;Lecture Video&lt;/a&gt; ]&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tutorial-driving-scene-segmentation" class="anchor" aria-hidden="true" href="#tutorial-driving-scene-segmentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorial: Driving Scene Segmentation&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_driving_scene_segmentation/tutorial_driving_scene_segmentation.ipynb"&gt;&lt;img src="images/thumb_driving_scene_segmentation.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tutorial demostrates semantic segmentation with a state-of-the-art model (DeepLab) on a sample video from the MIT Driving Scene Segmentation Dataset.&lt;/p&gt;
&lt;p&gt;Links: [ &lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_driving_scene_segmentation/tutorial_driving_scene_segmentation.ipynb"&gt;Jupyter Notebook&lt;/a&gt; ]
[ &lt;a href="https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_driving_scene_segmentation/tutorial_driving_scene_segmentation.ipynb" rel="nofollow"&gt;Google Colab&lt;/a&gt; ]&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tutorial-generative-adversarial-networks-gans" class="anchor" aria-hidden="true" href="#tutorial-generative-adversarial-networks-gans"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorial: Generative Adversarial Networks (GANs)&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_gans/tutorial_gans.ipynb"&gt;&lt;img src="images/thumb_mushroom_biggan.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tutorial explores generative adversarial networks (GANs) starting with BigGAN, the state-of-the-art conditional GAN.&lt;/p&gt;
&lt;p&gt;Links: [ &lt;a href="https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_gans/tutorial_gans.ipynb"&gt;Jupyter Notebook&lt;/a&gt; ]
[ &lt;a href="https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_gans/tutorial_gans.ipynb" rel="nofollow"&gt;Google Colab&lt;/a&gt; ]&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-deeptraffic-deep-reinforcement-learning-competition" class="anchor" aria-hidden="true" href="#deeptraffic-deep-reinforcement-learning-competition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DeepTraffic Deep Reinforcement Learning Competition&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://selfdrivingcars.mit.edu/deeptraffic" rel="nofollow"&gt;&lt;img src="images/thumb_deeptraffic.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;DeepTraffic is a deep reinforcement learning competition. The goal is to create a neural network that drives a vehicle (or multiple vehicles) as fast as possible through dense highway traffic.&lt;/p&gt;
&lt;p&gt;Links: [ &lt;a href="https://github.com/lexfridman/deeptraffic"&gt;GitHub&lt;/a&gt; ] [ &lt;a href="https://selfdrivingcars.mit.edu/deeptraffic" rel="nofollow"&gt;Website&lt;/a&gt; ] [ &lt;a href="https://arxiv.org/abs/1801.02805" rel="nofollow"&gt;Paper&lt;/a&gt; ]&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-team" class="anchor" aria-hidden="true" href="#team"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Team&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://lexfridman.com" rel="nofollow"&gt;Lex Fridman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~liding/" rel="nofollow"&gt;Li Ding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~jterwill/" rel="nofollow"&gt;Jack Terwilliger&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~glazermi/" rel="nofollow"&gt;Michael Glazer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~patsekin/" rel="nofollow"&gt;Aleksandr Patsekin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~aishni/" rel="nofollow"&gt;Aishni Parab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~aladawy/" rel="nofollow"&gt;Dina AlAdawy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mit.edu/~henris/" rel="nofollow"&gt;Henri Schmidt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>lexfridman</author><guid isPermaLink="false">https://github.com/lexfridman/mit-deep-learning</guid><pubDate>Sat, 04 Jan 2020 00:03:00 GMT</pubDate></item><item><title>ShusenTang/Dive-into-DL-PyTorch #4 in Jupyter Notebook, This week</title><link>https://github.com/ShusenTang/Dive-into-DL-PyTorch</link><description>&lt;p&gt;&lt;i&gt;本项目将《动手学深度学习》(Dive into Deep Learning)原书中的MXNet实现改为PyTorch实现。&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="docs/README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="img/cover.png"&gt;&lt;img width="500" src="img/cover.png" alt="封面" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a href="https://tangshusen.me/Dive-into-DL-PyTorch" rel="nofollow"&gt;本项目&lt;/a&gt;将&lt;a href="http://zh.d2l.ai/" rel="nofollow"&gt;《动手学深度学习》&lt;/a&gt; 原书中MXNet代码实现改为PyTorch实现。原书作者：阿斯顿·张、李沐、扎卡里 C. 立顿、亚历山大 J. 斯莫拉以及其他社区贡献者，GitHub地址：&lt;a href="https://github.com/d2l-ai/d2l-zh"&gt;https://github.com/d2l-ai/d2l-zh&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;此书的&lt;a href="https://zh.d2l.ai/" rel="nofollow"&gt;中&lt;/a&gt;&lt;a href="https://d2l.ai/" rel="nofollow"&gt;英&lt;/a&gt;版本存在一些不同，针对此书英文版的PyTorch重构可参考&lt;a href="https://github.com/dsgiitr/d2l-pytorch"&gt;这个项目&lt;/a&gt;。
There are some differences between the &lt;a href="https://zh.d2l.ai/" rel="nofollow"&gt;Chinese&lt;/a&gt; and &lt;a href="https://d2l.ai/" rel="nofollow"&gt;English&lt;/a&gt; versions of this book. For the PyTorch modifying of the English version, you can refer to &lt;a href="https://github.com/dsgiitr/d2l-pytorch"&gt;this repo&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-简介" class="anchor" aria-hidden="true" href="#简介"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;简介&lt;/h2&gt;
&lt;p&gt;本仓库主要包含code和docs两个文件夹（外加一些数据存放在data中）。其中code文件夹就是每章相关jupyter notebook代码（基于PyTorch）；docs文件夹就是markdown格式的《动手学深度学习》书中的相关内容，然后利用&lt;a href="https://docsify.js.org/#/zh-cn/" rel="nofollow"&gt;docsify&lt;/a&gt;将网页文档部署到GitHub Pages上，由于原书使用的是MXNet框架，所以docs内容可能与原书略有不同，但是整体内容是一样的。欢迎对本项目做出贡献或提出issue。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-面向人群" class="anchor" aria-hidden="true" href="#面向人群"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;面向人群&lt;/h2&gt;
&lt;p&gt;本项目面向对深度学习感兴趣，尤其是想使用PyTorch进行深度学习的童鞋。本项目并不要求你有任何深度学习或者机器学习的背景知识，你只需了解基础的数学和编程，如基础的线性代数、微分和概率，以及基础的Python编程。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-食用方法" class="anchor" aria-hidden="true" href="#食用方法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;食用方法&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-方法一" class="anchor" aria-hidden="true" href="#方法一"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;方法一&lt;/h3&gt;
&lt;p&gt;本仓库包含一些latex公式，但github的markdown原生是不支持公式显示的，而docs文件夹已经利用&lt;a href="https://docsify.js.org/#/zh-cn/" rel="nofollow"&gt;docsify&lt;/a&gt;被部署到了GitHub Pages上，所以查看文档最简便的方法就是直接访问&lt;a href="https://tangshusen.me/Dive-into-DL-PyTorch" rel="nofollow"&gt;本项目网页版&lt;/a&gt;。当然如果你还想跑一下运行相关代码的话还是得把本项目clone下来，然后运行code文件夹下相关代码。&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-方法二" class="anchor" aria-hidden="true" href="#方法二"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;方法二&lt;/h3&gt;
&lt;p&gt;你还可以在本地访问文档，先安装&lt;code&gt;docsify-cli&lt;/code&gt;工具:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;npm i docsify-cli -g&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后将本项目clone到本地:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/ShusenTang/Dive-into-DL-PyTorch.git
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; Dive-into-DL-PyTorch&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后运行一个本地服务器，这样就可以很方便的在&lt;code&gt;http://localhost:3000&lt;/code&gt;实时访问文档网页渲染效果。&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;docsify serve docs&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-目录" class="anchor" aria-hidden="true" href="#目录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=""&gt;简介&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="read_guide.md"&gt;阅读指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter01_DL-intro/deep-learning-intro.md"&gt;1. 深度学习简介&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2. 预备知识
&lt;ul&gt;
&lt;li&gt;&lt;a href="chapter02_prerequisite/2.1_install.md"&gt;2.1 环境配置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter02_prerequisite/2.2_tensor.md"&gt;2.2 数据操作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter02_prerequisite/2.3_autograd.md"&gt;2.3 自动求梯度&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;3. 深度学习基础
&lt;ul&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.1_linear-regression.md"&gt;3.1 线性回归&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.2_linear-regression-scratch.md"&gt;3.2 线性回归的从零开始实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.3_linear-regression-pytorch.md"&gt;3.3 线性回归的简洁实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.4_softmax-regression.md"&gt;3.4 softmax回归&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.5_fashion-mnist.md"&gt;3.5 图像分类数据集（Fashion-MNIST）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.6_softmax-regression-scratch.md"&gt;3.6 softmax回归的从零开始实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.7_softmax-regression-pytorch.md"&gt;3.7 softmax回归的简洁实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.8_mlp.md"&gt;3.8 多层感知机&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.9_mlp-scratch.md"&gt;3.9 多层感知机的从零开始实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.10_mlp-pytorch.md"&gt;3.10 多层感知机的简洁实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.11_underfit-overfit.md"&gt;3.11 模型选择、欠拟合和过拟合&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.12_weight-decay.md"&gt;3.12 权重衰减&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.13_dropout.md"&gt;3.13 丢弃法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.14_backprop.md"&gt;3.14 正向传播、反向传播和计算图&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.15_numerical-stability-and-init.md"&gt;3.15 数值稳定性和模型初始化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter03_DL-basics/3.16_kaggle-house-price.md"&gt;3.16 实战Kaggle比赛：房价预测&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;4. 深度学习计算
&lt;ul&gt;
&lt;li&gt;&lt;a href="chapter04_DL_computation/4.1_model-construction.md"&gt;4.1 模型构造&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter04_DL_computation/4.2_parameters.md"&gt;4.2 模型参数的访问、初始化和共享&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter04_DL_computation/4.3_deferred-init.md"&gt;4.3 模型参数的延后初始化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter04_DL_computation/4.4_custom-layer.md"&gt;4.4 自定义层&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter04_DL_computation/4.5_read-write.md"&gt;4.5 读取和存储&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter04_DL_computation/4.6_use-gpu.md"&gt;4.6 GPU计算&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;5. 卷积神经网络
&lt;ul&gt;
&lt;li&gt;&lt;a href="chapter05_CNN/5.1_conv-layer.md"&gt;5.1 二维卷积层&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter05_CNN/5.2_padding-and-strides.md"&gt;5.2 填充和步幅&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter05_CNN/5.3_channels.md"&gt;5.3 多输入通道和多输出通道&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter05_CNN/5.4_pooling.md"&gt;5.4 池化层&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter05_CNN/5.5_lenet.md"&gt;5.5 卷积神经网络（LeNet）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter05_CNN/5.6_alexnet.md"&gt;5.6 深度卷积神经网络（AlexNet）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter05_CNN/5.7_vgg.md"&gt;5.7 使用重复元素的网络（VGG）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter05_CNN/5.8_nin.md"&gt;5.8 网络中的网络（NiN）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter05_CNN/5.9_googlenet.md"&gt;5.9 含并行连结的网络（GoogLeNet）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter05_CNN/5.10_batch-norm.md"&gt;5.10 批量归一化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter05_CNN/5.11_resnet.md"&gt;5.11 残差网络（ResNet）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter05_CNN/5.12_densenet.md"&gt;5.12 稠密连接网络（DenseNet）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;6. 循环神经网络
&lt;ul&gt;
&lt;li&gt;&lt;a href="chapter06_RNN/6.1_lang-model.md"&gt;6.1 语言模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter06_RNN/6.2_rnn.md"&gt;6.2 循环神经网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter06_RNN/6.3_lang-model-dataset.md"&gt;6.3 语言模型数据集（周杰伦专辑歌词）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter06_RNN/6.4_rnn-scratch.md"&gt;6.4 循环神经网络的从零开始实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter06_RNN/6.5_rnn-pytorch.md"&gt;6.5 循环神经网络的简洁实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter06_RNN/6.6_bptt.md"&gt;6.6 通过时间反向传播&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter06_RNN/6.7_gru.md"&gt;6.7 门控循环单元（GRU）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter06_RNN/6.8_lstm.md"&gt;6.8 长短期记忆（LSTM）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter06_RNN/6.9_deep-rnn.md"&gt;6.9 深度循环神经网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter06_RNN/6.10_bi-rnn.md"&gt;6.10 双向循环神经网络&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;7. 优化算法
&lt;ul&gt;
&lt;li&gt;&lt;a href="chapter07_optimization/7.1_optimization-intro.md"&gt;7.1 优化与深度学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter07_optimization/7.2_gd-sgd.md"&gt;7.2 梯度下降和随机梯度下降&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter07_optimization/7.3_minibatch-sgd.md"&gt;7.3 小批量随机梯度下降&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter07_optimization/7.4_momentum.md"&gt;7.4 动量法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter07_optimization/7.5_adagrad.md"&gt;7.5 AdaGrad算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter07_optimization/7.6_rmsprop.md"&gt;7.6 RMSProp算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter07_optimization/7.7_adadelta.md"&gt;7.7 AdaDelta算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter07_optimization/7.8_adam.md"&gt;7.8 Adam算法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;8. 计算性能
&lt;ul&gt;
&lt;li&gt;&lt;a href="chapter08_computational-performance/8.1_hybridize.md"&gt;8.1 命令式和符号式混合编程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter08_computational-performance/8.2_async-computation.md"&gt;8.2 异步计算&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter08_computational-performance/8.3_auto-parallelism.md"&gt;8.3 自动并行计算&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter08_computational-performance/8.4_multiple-gpus.md"&gt;8.4 多GPU计算&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;9. 计算机视觉
&lt;ul&gt;
&lt;li&gt;&lt;a href="chapter09_computer-vision/9.1_image-augmentation.md"&gt;9.1 图像增广&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter09_computer-vision/9.2_fine-tuning.md"&gt;9.2 微调&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter09_computer-vision/9.3_bounding-box.md"&gt;9.3 目标检测和边界框&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter09_computer-vision/9.4_anchor.md"&gt;9.4 锚框&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter09_computer-vision/9.5_multiscale-object-detection.md"&gt;9.5 多尺度目标检测&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter09_computer-vision/9.6_object-detection-dataset.md"&gt;9.6 目标检测数据集（皮卡丘）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 9.7 单发多框检测（SSD）&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="chapter09_computer-vision/9.8_rcnn.md"&gt;9.8 区域卷积神经网络（R-CNN）系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter09_computer-vision/9.9_semantic-segmentation-and-dataset.md"&gt;9.9 语义分割和数据集&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 9.10 全卷积网络（FCN）&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="chapter09_computer-vision/9.11_neural-style.md"&gt;9.11 样式迁移&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 9.12 实战Kaggle比赛：图像分类（CIFAR-10）&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 9.13 实战Kaggle比赛：狗的品种识别（ImageNet Dogs）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;10. 自然语言处理
&lt;ul&gt;
&lt;li&gt;&lt;a href="chapter10_natural-language-processing/10.1_word2vec.md"&gt;10.1 词嵌入（word2vec）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter10_natural-language-processing/10.2_approx-training.md"&gt;10.2 近似训练&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter10_natural-language-processing/10.3_word2vec-pytorch.md"&gt;10.3 word2vec的实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter10_natural-language-processing/10.4_fasttext.md"&gt;10.4 子词嵌入（fastText）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter10_natural-language-processing/10.5_glove.md"&gt;10.5 全局向量的词嵌入（GloVe）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter10_natural-language-processing/10.6_similarity-analogy.md"&gt;10.6 求近义词和类比词&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter10_natural-language-processing/10.7_sentiment-analysis-rnn.md"&gt;10.7 文本情感分类：使用循环神经网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter10_natural-language-processing/10.8_sentiment-analysis-cnn.md"&gt;10.8 文本情感分类：使用卷积神经网络（textCNN）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter10_natural-language-processing/10.9_seq2seq.md"&gt;10.9 编码器—解码器（seq2seq）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter10_natural-language-processing/10.10_beam-search.md"&gt;10.10 束搜索&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter10_natural-language-processing/10.11_attention.md"&gt;10.11 注意力机制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chapter10_natural-language-processing/10.12_machine-translation.md"&gt;10.12 机器翻译&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;持续更新中......&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-原书地址" class="anchor" aria-hidden="true" href="#原书地址"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;原书地址&lt;/h2&gt;
&lt;p&gt;中文版：&lt;a href="https://zh.d2l.ai/" rel="nofollow"&gt;动手学深度学习&lt;/a&gt; | &lt;a href="https://github.com/d2l-ai/d2l-zh"&gt;Github仓库&lt;/a&gt;&lt;br&gt;
English Version: &lt;a href="https://d2l.ai/" rel="nofollow"&gt;Dive into Deep Learning&lt;/a&gt; | &lt;a href="https://github.com/d2l-ai/d2l-en"&gt;Github Repo&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-引用" class="anchor" aria-hidden="true" href="#引用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;引用&lt;/h2&gt;
&lt;p&gt;如果您在研究中使用了这个项目请引用原书:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@book{zhang2019dive,
    title={Dive into Deep Learning},
    author={Aston Zhang and Zachary C. Lipton and Mu Li and Alexander J. Smola},
    note={\url{http://www.d2l.ai}},
    year={2020}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ShusenTang</author><guid isPermaLink="false">https://github.com/ShusenTang/Dive-into-DL-PyTorch</guid><pubDate>Sat, 04 Jan 2020 00:04:00 GMT</pubDate></item><item><title>randerson112358/Python #5 in Jupyter Notebook, This week</title><link>https://github.com/randerson112358/Python</link><description>&lt;p&gt;&lt;i&gt;:snake: Python Programs&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-python" class="anchor" aria-hidden="true" href="#python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python&lt;/h1&gt;
&lt;p&gt;This is a repository that holds my Python programs&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2cffe57e3c8276001c970391a67d67cf3a02f165/68747470733a2f2f7777772e707974686f6e2e6f72672f7374617469632f636f6d6d756e6974795f6c6f676f732f707974686f6e2d6c6f676f2d696e6b73636170652e737667"&gt;&lt;img src="https://camo.githubusercontent.com/2cffe57e3c8276001c970391a67d67cf3a02f165/68747470733a2f2f7777772e707974686f6e2e6f72672f7374617469632f636f6d6d756e6974795f6c6f676f732f707974686f6e2d6c6f676f2d696e6b73636170652e737667" width="400" data-canonical-src="https://www.python.org/static/community_logos/python-logo-inkscape.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
To see me programming in Python checkout the YouTube channel: &lt;a href="https://www.youtube.com/playlist?list=PLBhJnyA0V0uIP6tScPs01FW5WtSpJdmcv" rel="nofollow"&gt;Go To YouTube Channel&lt;/a&gt;
&lt;h1&gt;&lt;a id="user-content-relavent-books-on-amazon" class="anchor" aria-hidden="true" href="#relavent-books-on-amazon"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Relavent Books On Amazon&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/1449355730/ref=as_li_tl?ie=UTF8&amp;amp;tag=github01d-20&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;linkCode=as2&amp;amp;creativeASIN=1449355730&amp;amp;linkId=95e6eaf8c12b9fcd483dd06c1dd53e48" rel="nofollow"&gt;Learning Python, 5th Edition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/1491962291/ref=as_li_tl?ie=UTF8&amp;amp;tag=github01d-20&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;linkCode=as2&amp;amp;creativeASIN=1491962291&amp;amp;linkId=9dec6584d63a7cfcbc32af1ff9737bbf" rel="nofollow"&gt;Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/1491912057/ref=as_li_tl?ie=UTF8&amp;amp;tag=github01d-20&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;linkCode=as2&amp;amp;creativeASIN=1491912057&amp;amp;linkId=af650651a6d71fdea49cd5aa95653e1c" rel="nofollow"&gt;Python Data Science Handbook: Essential Tools for Working with Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/1449369413/ref=as_li_tl?ie=UTF8&amp;amp;tag=github01d-20&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;linkCode=as2&amp;amp;creativeASIN=1449369413&amp;amp;linkId=7b6ad9375121575c83af505f2a3ed6f3" rel="nofollow"&gt;Introduction to Machine Learning with Python: A Guide for Data Scientists&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-python-data-cleaning-programs" class="anchor" aria-hidden="true" href="#python-data-cleaning-programs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python Data Cleaning Programs&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Program Name&lt;/th&gt;
&lt;th&gt;Algorithm Name&lt;/th&gt;
&lt;th&gt;Link to Program&lt;/th&gt;
&lt;th&gt;Blog&lt;/th&gt;
&lt;th&gt;YouTube&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;concatenate_file.py&lt;/td&gt;
&lt;td&gt;Concatenate Multiple CSV files&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/concatenate_file.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://everythingcomputerscience.com/" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/channel/UCbmb5IoBtHZTpYZCDBOC1CA" rel="nofollow"&gt;YouTubeX&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;remove_empty_row.py&lt;/td&gt;
&lt;td&gt;Removes Empty Rows&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/remove_empty_row.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://everythingcomputerscience.com/" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/channel/UCbmb5IoBtHZTpYZCDBOC1CA" rel="nofollow"&gt;YouTubeX&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;replace_strings_with_numbers.py&lt;/td&gt;
&lt;td&gt;Changes Strings in CSV to Numbers&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Replace_Strings_With_Numbers/replace_strings_with_numbers.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://everythingcomputerscience.com/" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/zv_fzW2iA_U" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-web-scraping" class="anchor" aria-hidden="true" href="#web-scraping"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web Scraping&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Program Name&lt;/th&gt;
&lt;th&gt;Algorithm Name&lt;/th&gt;
&lt;th&gt;Link to Program&lt;/th&gt;
&lt;th&gt;Blog&lt;/th&gt;
&lt;th&gt;YouTube&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;scrape.py&lt;/td&gt;
&lt;td&gt;Scrape Website Links&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/scrape.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/scrape-website-using-python-90619cac7c97" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/LGZEn1OYUTk" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;News_Article.py&lt;/td&gt;
&lt;td&gt;Scrape &amp;amp; Summarize Article&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/News_Article.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://everythingcomputerscience.com/" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/YzMA2O_v5co" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-machine-learning-projects--programs" class="anchor" aria-hidden="true" href="#machine-learning-projects--programs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning Projects &amp;amp; Programs&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Project Name&lt;/th&gt;
&lt;th&gt;Program Name&lt;/th&gt;
&lt;th&gt;Algorithm Name&lt;/th&gt;
&lt;th&gt;Link to Program&lt;/th&gt;
&lt;th&gt;Blog&lt;/th&gt;
&lt;th&gt;YouTube&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Sentiment Analysis&lt;/td&gt;
&lt;td&gt;sentiment.py&lt;/td&gt;
&lt;td&gt;Sentiment Analysis&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/sentiment.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/sentiment-analysis-e2e4442bac13" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/1VHhDSOwJPw" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Simple Linear Regression Ex&lt;/td&gt;
&lt;td&gt;LinearRegression.py&lt;/td&gt;
&lt;td&gt;Linear Regression&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/LinearRegression.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/a-simple-machine-learning-python-program-bf5d156d2cda" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/z7jEJY8FbA8" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Car Classification&lt;/td&gt;
&lt;td&gt;decisionTree.py&lt;/td&gt;
&lt;td&gt;Decision Tree&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/DecisionTree/decisionTree.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/car-classification-89ad60204acf" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/U-Jm8ugN0Ps" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Golf Predictions&lt;/td&gt;
&lt;td&gt;Golf_Predictions.ipynb&lt;/td&gt;
&lt;td&gt;Decision Tree&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Golf_Predictions.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/python-decision-tree-classifier-example-d73bc3aeca6" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/bT-43kgYI3o" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Predict Boston House Price&lt;/td&gt;
&lt;td&gt;Predict_Boston_Housing_Price.ipynb&lt;/td&gt;
&lt;td&gt;Linear Regression&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Predict_Boston_Housing_Price.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/predict-boston-house-prices-using-python-linear-regression-90469e0a341" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/gOXoFDrseis" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Predict Stock Price&lt;/td&gt;
&lt;td&gt;stock.ipynb&lt;/td&gt;
&lt;td&gt;Linear Regression &amp;amp; SVR&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/stock.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/predict-stock-prices-using-python-machine-learning-53aa024da20a" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/EYnC4ACIt2g" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Classify Iris Species&lt;/td&gt;
&lt;td&gt;Logistic_Regression.ipynb&lt;/td&gt;
&lt;td&gt;Logistic Regression&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Logistic_Regression.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/python-logistic-regression-program-5e1b32f964db" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/ACdBKML9l4s" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Predict Median House Price&lt;/td&gt;
&lt;td&gt;Neural_Networks.ipynb&lt;/td&gt;
&lt;td&gt;Deep Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Neural_Networks/Neural_Networks.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/predict-house-median-prices-5f1a768dd256?postPublishedType=repub" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/vSzou5zRwNQ" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Classify Handwritten Digits&lt;/td&gt;
&lt;td&gt;MNIST_ANN.ipynb&lt;/td&gt;
&lt;td&gt;Artificial Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/MNIST_ANN.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/classify-hand-written-digits-5fdbe5d99ee7" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/kOFUQB7u5Ck" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cluster NBA Basketball Players&lt;/td&gt;
&lt;td&gt;Basketball_Data_Exploration.ipynb&lt;/td&gt;
&lt;td&gt;KMeans&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/NBA_Basketball_Exploration/Basketball_Data_Exploration.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/nba-data-analysis-exploration-9293f311e0e8" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/2Pmf6Kqak3w" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Predict FB Stock Price&lt;/td&gt;
&lt;td&gt;SVM.ipynb&lt;/td&gt;
&lt;td&gt;Support Vector Regression (SVR)&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/SVM_Stock/SVM.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/facebook-stock-prediction-bcfc676bc611" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/tMPfZV_ipOg" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Breast Cancer Detection&lt;/td&gt;
&lt;td&gt;Breast_Cancer_Detection.ipynb&lt;/td&gt;
&lt;td&gt;Random Forest Classifier &amp;amp; Gaussian Naive Bayes &amp;amp; Logistic Regression &amp;amp; Decision Tree Classifier &amp;amp; SVC&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/breast_cancer_detection/Breast_Cancer_Detection.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/breast-cancer-detection-using-machine-learning-38820fe98982" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/NSSOyhJBmWY" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Face Detection&lt;/td&gt;
&lt;td&gt;face_detection.py&lt;/td&gt;
&lt;td&gt;Open CV &amp;amp; Adaboost&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/face_detection/face_detection.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/face-detection-using-python-open-cv-d51e27266f7f" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/6klXqQMctPk" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Image Classification&lt;/td&gt;
&lt;td&gt;cnn.ipynb&lt;/td&gt;
&lt;td&gt;CNN&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Classify_Images/cnn.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/classify-images-using-convolutional-neural-networks-python-a89cecc8c679" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/mB7fdy67eFw" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Classify Handwritten Digits CNN&lt;/td&gt;
&lt;td&gt;mnist_cnn.ipynb&lt;/td&gt;
&lt;td&gt;Convolutional Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/mnist_cnn.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/classify-hand-written-digits-using-python-and-convolutional-neural-networks-26ccfc06b95c" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/V4dd2Bt9OHY" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spam Detection&lt;/td&gt;
&lt;td&gt;Email_Spam_Detection.ipynb&lt;/td&gt;
&lt;td&gt;Naive Bayes&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Email_Spam_Detection/Email_Spam_Detection.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/email-spam-detection-using-python-machine-learning-abe38c889855" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/cNLPt02RwF0" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pima-Indians Diabetes&lt;/td&gt;
&lt;td&gt;Diabetes.ipynb&lt;/td&gt;
&lt;td&gt;Artificial Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Diabetes/Diabetes.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/build-your-own-artificial-neural-network-using-python-f37d16be06bf" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=S2sZNlr-4_4&amp;amp;list=PLBhJnyA0V0uIP6tScPs01FW5WtSpJdmcv&amp;amp;index=28&amp;amp;t=0s" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Movie Recommendation Engine&lt;/td&gt;
&lt;td&gt;Movie_Recommendation.ipynb&lt;/td&gt;
&lt;td&gt;Cosine Similarity&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Movie_Recommender/Movie_Recommendation.ipynb"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/build-a-movie-recommendation-engine-using-python-scikit-learn-machine-learning-e68ba297e163" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/umSM8rFtVMs" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Article Text To Speech&lt;/td&gt;
&lt;td&gt;Article_Text_To_Speech.py&lt;/td&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/Article_Text_To_Speech.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/build-a-text-to-speech-program-using-python-b70de7105383" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/uPSIUjo_Fhw" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AI Smart Dr.Chat Bot&lt;/td&gt;
&lt;td&gt;smartbot.py&lt;/td&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/smartbot.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/build-your-own-ai-chat-bot-using-python-machine-learning-682ddd8acc29" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/QpMsT0WuIuI" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Neural Network Stock Prediction&lt;/td&gt;
&lt;td&gt;lstm2.py&lt;/td&gt;
&lt;td&gt;LSTM&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/randerson112358/Python/blob/master/LSTM_Stock/lstm2.py"&gt;Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://medium.com/@randerson112358/stock-price-prediction-using-python-machine-learning-e82a039ac2bb" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://youtu.be/QIUxPv5PJOY" rel="nofollow"&gt;YouTube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>randerson112358</author><guid isPermaLink="false">https://github.com/randerson112358/Python</guid><pubDate>Sat, 04 Jan 2020 00:05:00 GMT</pubDate></item><item><title>wesm/pydata-book #6 in Jupyter Notebook, This week</title><link>https://github.com/wesm/pydata-book</link><description>&lt;p&gt;&lt;i&gt;Materials and IPython notebooks for "Python for Data Analysis" by Wes McKinney, published by O'Reilly Media&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-python-for-data-analysis-2nd-edition" class="anchor" aria-hidden="true" href="#python-for-data-analysis-2nd-edition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python for Data Analysis, 2nd Edition&lt;/h1&gt;
&lt;p&gt;Materials and IPython notebooks for "Python for Data Analysis" by Wes McKinney,
published by O'Reilly Media&lt;/p&gt;
&lt;p&gt;&lt;a href="http://amzn.to/2vvBijB" rel="nofollow"&gt;Buy the book on Amazon&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://notebooks.azure.com/import/gh/wesm/pydata-book" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2c33d8af3d101ffcd6ea73a8d02290b8d829ac52/68747470733a2f2f6e6f7465626f6f6b732e617a7572652e636f6d2f6c61756e63682e706e67" data-canonical-src="https://notebooks.azure.com/launch.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Follow Wes on Twitter: &lt;a href="https://twitter.com/wesmckinn" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e5ee948ef48fbfa31f868c9dbd301bbd5cf38097/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f7765736d636b696e6e2e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f77" alt="Twitter Follow" data-canonical-src="https://img.shields.io/twitter/follow/wesmckinn.svg?style=social&amp;amp;label=Follow" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-1st-edition-readers" class="anchor" aria-hidden="true" href="#1st-edition-readers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1st Edition Readers&lt;/h1&gt;
&lt;p&gt;If you are reading the &lt;a href="http://amzn.to/2vvBijB" rel="nofollow"&gt;1st Edition&lt;/a&gt; (published in 2012), please find the
reorganized book materials on the &lt;a href="https://github.com/wesm/pydata-book/tree/1st-edition"&gt;&lt;code&gt;1st-edition&lt;/code&gt; branch&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-translations" class="anchor" aria-hidden="true" href="#translations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Translations&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/BrambleXu/pydata-notebook"&gt;Chinese&lt;/a&gt; by Xu Liang&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-ipython-notebooks" class="anchor" aria-hidden="true" href="#ipython-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;IPython Notebooks:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch02.ipynb" rel="nofollow"&gt;Chapter 2: Python Language Basics, IPython, and Jupyter Notebooks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch03.ipynb" rel="nofollow"&gt;Chapter 3: Built-in Data Structures, Functions, and Files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch04.ipynb" rel="nofollow"&gt;Chapter 4: NumPy Basics: Arrays and Vectorized Computation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch05.ipynb" rel="nofollow"&gt;Chapter 5: Getting Started with pandas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch06.ipynb" rel="nofollow"&gt;Chapter 6: Data Loading, Storage, and File Formats&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch07.ipynb" rel="nofollow"&gt;Chapter 7: Data Cleaning and Preparation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch08.ipynb" rel="nofollow"&gt;Chapter 8: Data Wrangling: Join, Combine, and Reshape&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch09.ipynb" rel="nofollow"&gt;Chapter 9: Plotting and Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch10.ipynb" rel="nofollow"&gt;Chapter 10: Data Aggregation and Group Operations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch11.ipynb" rel="nofollow"&gt;Chapter 11: Time Series&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch12.ipynb" rel="nofollow"&gt;Chapter 12: Advanced pandas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch13.ipynb" rel="nofollow"&gt;Chapter 13: Introduction to Modeling Libraries in Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/ch14.ipynb" rel="nofollow"&gt;Chapter 14: Data Analysis Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/github/pydata/pydata-book/blob/2nd-edition/appa.ipynb" rel="nofollow"&gt;Appendix A: Advanced NumPy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-code" class="anchor" aria-hidden="true" href="#code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code&lt;/h3&gt;
&lt;p&gt;The code in this repository, including all code samples in the notebooks listed
above, is released under the &lt;a href="LICENSE-CODE"&gt;MIT license&lt;/a&gt;. Read more at the
&lt;a href="https://opensource.org/licenses/MIT" rel="nofollow"&gt;Open Source Initiative&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>wesm</author><guid isPermaLink="false">https://github.com/wesm/pydata-book</guid><pubDate>Sat, 04 Jan 2020 00:06:00 GMT</pubDate></item><item><title>virgili0/Virgilio #7 in Jupyter Notebook, This week</title><link>https://github.com/virgili0/Virgilio</link><description>&lt;p&gt;&lt;i&gt;Your new Mentor for Data Science E-Learning.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-virgilio" class="anchor" aria-hidden="true" href="#virgilio"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;em&gt;Virgilio&lt;/em&gt;&lt;/h1&gt;
&lt;h4&gt;&lt;a id="user-content-your-new-mentor-for-data-science-e-learning" class="anchor" aria-hidden="true" href="#your-new-mentor-for-data-science-e-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Your new Mentor for Data Science E-Learning.&lt;/h4&gt;
&lt;p&gt;Join our community:   &lt;a href="https://www.facebook.com/groups/mathfordatascience/?notif_id=1576071669338330" rel="nofollow"&gt;&lt;img height="24px" src="https://camo.githubusercontent.com/707de57448c727d1086eef95ab883c780b749931/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f66616365626f6f6b2d34354b25323067726f75702532306d656d626572732d626c75652e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/badge/facebook-45K%20group%20members-blue.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/UpQ8bb7" rel="nofollow"&gt;&lt;img height="24px" src="https://camo.githubusercontent.com/9b0e0cc54a5a222ada2528d8b05b933153c66c7b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646973636f72642d35302532306f6e6c696e6525323075736572732d677265656e2e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/badge/discord-50%20online%20users-green.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://docs.google.com/forms/d/e/1FAIpQLSeVJ9N7ae8Wr07tfSuHkP5i_5Fa-4Lp5V4fBevsinWyx6t17g/viewform" rel="nofollow"&gt;&lt;img height="24px" src="https://camo.githubusercontent.com/b10f25e6bbf851f7ea83234d92f249103ee6dfae/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6e6577736c65747465722d35303025323073756273637269626572732d79656c6c6f772e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/badge/newsletter-500%20subscribers-yellow.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;blockquote&gt;
&lt;p&gt;Virgilio is an open source initiative, aiming to mentor and guide anyone in the world of Data Science and Machine Learning. Our vision is to give &lt;em&gt;everyone&lt;/em&gt; the chance to get involved in this field, get self-started as a practitioner, gain new cutting edge practical skills and learn to navigate through the infinite web of resources and find the ones useful for &lt;em&gt;you&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e652d41e2104dadcc8c6b2d209e00ee6f1caa190/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f632f63652f56697267696c5f2e6a7067"&gt;&lt;img width="480px" src="https://camo.githubusercontent.com/e652d41e2104dadcc8c6b2d209e00ee6f1caa190/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f632f63652f56697267696c5f2e6a7067" data-canonical-src="https://upload.wikimedia.org/wikipedia/commons/c/ce/Virgil_.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/div&gt;
&lt;br&gt;
&lt;h3&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#what-is-virgilio"&gt;&lt;em&gt;What&lt;/em&gt; is Virgilio&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#structure"&gt;Structure&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#paradiso"&gt;Paradiso&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#purgatorio"&gt;Purgatorio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#inferno"&gt;Inferno&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#complete-learning-paths"&gt;Complete Learning Paths&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#About"&gt;About&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#license"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contribute"&gt;Contribute&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-what-is-virgilio" class="anchor" aria-hidden="true" href="#what-is-virgilio"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is Virgilio?&lt;/h1&gt;
&lt;p&gt;Studying and reading through the Internet means swimming in an infinite jungle of chaotic information, even more so in rapidly changing innovative fields.&lt;/p&gt;
&lt;p&gt;Have you ever felt overwhelmed when trying to approach Data Science without a real “path” to follow?
Are you tired of clicking “Run”, “Run”, “Run”.. on a Jupyter Notebook, with that false sense of confidence given by the comfort zone of the work of others?&lt;/p&gt;
&lt;p&gt;Have you ever got confused because of the several and contradicting names for the same algorithm or approach, from different websites and fragmented tutorials?&lt;/p&gt;
&lt;p&gt;We will address these critical issues for free, for everyone.&lt;/p&gt;
&lt;p&gt;Hi, I'm &lt;a href="https://en.wikipedia.org/wiki/Virgil" rel="nofollow"&gt;Virgilio&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Like I did with &lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Dante_Alighieri" rel="nofollow"&gt;Dante&lt;/a&gt;&lt;/em&gt;, just some centuries ago, I'll be your mentor and reference point during your journey through this &lt;em&gt;selva oscura&lt;/em&gt;, providing you complete and organic learning paths for several fields, tools, skills and more.&lt;/p&gt;
&lt;p&gt;The vision of Virgilio is to give everyone the possibility to get into the incredible world of the Data Science and Machine Learning and the business and creative possibilities that they offer, to get self-started as a practitioner, gain new cutting edge practical skills or just learn to discriminate good information from poor information.&lt;/p&gt;
&lt;p&gt;We are doing this by providing only high-quality and coherent content, with clear step-by-step paths and a consistent naming system.&lt;/p&gt;
&lt;p&gt;Imagine Virgilio as an E-Mentor who will tell you what do to get the next step, the next skill, or to apply them in practice to create value.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;But what does it mean in practice?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In other words, what's the &lt;strong&gt;target&lt;/strong&gt; of the Virgilio project?&lt;/p&gt;
&lt;p&gt;There are different scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;em&gt;student&lt;/em&gt; from a different field who wants to explore the intersections and the possibilities offered by the Machine Learning and Statistical methods.&lt;/li&gt;
&lt;li&gt;A &lt;em&gt;curious individual&lt;/em&gt; who came in touch with one of the buzzwords related to these fields and wants to discriminate between reliable and unreliable information.&lt;/li&gt;
&lt;li&gt;An &lt;em&gt;experienced practitioner&lt;/em&gt; who wants to have a reference point for the latest techniques, papers and best practices.&lt;/li&gt;
&lt;li&gt;A &lt;em&gt;manager&lt;/em&gt; who wants to understand the possibilities of ML applied to their actual problems, like integration with production systems or new solutions from scratch.&lt;/li&gt;
&lt;li&gt;A &lt;em&gt;businessman&lt;/em&gt; who wants to understand if his data are suitable for an ML project, and what could be the real business value.&lt;/li&gt;
&lt;li&gt;A &lt;em&gt;salesman&lt;/em&gt; who needs to stay up-to-date with the latest technologies and Jargon.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-structure" class="anchor" aria-hidden="true" href="#structure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Structure&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;WIP notice: we are in the progress of migrating the content from the old conceptual organisation to the new one. Please be patient while we make Virgilio more awesome!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="map.PNG"&gt;&lt;img src="map.PNG" alt="Figure 1" title="1" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As you can imagine it’s not easy to intercept all these different needs, so our solution ended up in a hierarchical structure which distinguish the content based on different levels of abstraction.&lt;/p&gt;
&lt;p&gt;To do this, we got our inspiration from Dante’s amazing masterpiece &lt;a href="https://en.wikipedia.org/wiki/Divina_Commedia" rel="nofollow"&gt;“La Divina Commedia”&lt;/a&gt;, written in over 20 years of work and published for the first time in 1323 d.c.&lt;/p&gt;
&lt;p&gt;Dante’s journey wouldn’t have been possible without his companion and guide, Virgilio, a roman famous poet (70 a.c.) who inspired generations of artists since the Roman hegemony in Europe.&lt;/p&gt;
&lt;p&gt;In his journey, Dante travel across the different levels of the catholic conception of the divine world at that time, starting from the Inferno (the prison of the damned), passing through the Purgatorio and reaching eventually the Paradiso (you can call it Valhalla or Nirvana, as you prefer :-) ).&lt;/p&gt;
&lt;p&gt;In your journey, you will start from scratch and eventually reach the theoretical knowledge and solid expendable skill.&lt;/p&gt;
&lt;p&gt;The parallelism is natural:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="order.png"&gt;&lt;img src="order.png" alt="Figure 2" title="1" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Going from top to bottom increases the level of detail and decreases the level of abstraction&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;strong&gt;Paradiso&lt;/strong&gt; you won’t find a single line of code or a math formula, just plain English.
Here’s the place for introductions, simple explanations, demystifications, and meta-guides (for example a guide about the best way to use Virgilio).
It’s the best place for the not-techies, beginners and literally everyone who wants to get in touch with Data Science and Machine Learning without getting bored into technical details.
Do you want to communicate these innovative fields? Pass from the Paradiso!&lt;/p&gt;
&lt;p&gt;In the &lt;strong&gt;Purgatorio&lt;/strong&gt; you can find technical guides for beginners (in the field or in general IT).
For example, you’ll find guides about Python, maths, and statistics.
You will find guides about study techniques, soft skills and you’ll learn how to develop an analytical mindset too.
It’s an obliged step before the Hell.
Depending on your starting skill, you’ll probably spend here most of the time, learning to code, understand math concepts and more!
&lt;em&gt;If you’re a complete beginner&lt;/em&gt;, follow the track we proposed, starting from the Fundamentals.&lt;/p&gt;
&lt;p&gt;In the &lt;strong&gt;Inferno&lt;/strong&gt; you won’t find gentle introductions or generic explanations, but a lot of different detailed guides, topics, hands-on tutorials and more!
You’ll find an entire section dedicated to research and daily updates from the field! You’ll find guides like “how to train a massive neural network over hundreds of GPUs efficiently” or “How to deal with huge datasets”, or “how to fine-tune a preprocessing pipeline”. Think about Inferno as the place where you will pick up the sub-field you prefer and dive into that.
It’s impossible to learn everything at once! One of the Virgilio’s most important learning strategies is “One enemy at time”, "Divide and conquer!".
The three specializations that we provide are Computer Vision, Natural Language Processing, and Agent-based and Reinforcement Learning.
These learning paths are the “final bosses” of the Virgilio’s experience: once you’ll have completed them you will hopefully be skilled enough to land an internship or tackle real business problems!&lt;/p&gt;
&lt;p&gt;Above these you’ll find a plenty of other useful zones:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Business Skills: these are necessary to unlock the business value in the real world, and they are probably the most valuable asset for a “data guy” to have in his pocket.&lt;/li&gt;
&lt;li&gt;Tools: here you find guides about useful tools for programming, or scientific computing in general.&lt;/li&gt;
&lt;li&gt;Research: here you will learn how to find the right papers and digest them. In addition, you’ll discover which teams to follow for your interests.&lt;/li&gt;
&lt;li&gt;Massive computation: here you’ll find hints and resources for computing on clusters, optimize your system and other advanced topics.&lt;/li&gt;
&lt;li&gt;ML for Business applications: here we provide additional resources to select a sector and see what are the today’s available techniques for the problems of your interest.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-paradiso" class="anchor" aria-hidden="true" href="#paradiso"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Paradiso&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="serving/paradiso/demystification-ai-ml-dl/demystification-ai-ml-dl.md"&gt;Demystification of the key concepts of Artificial Intelligence and Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/paradiso/what-do-you-need-for-ml/what-do-you-need-for-ml.md"&gt;What do you need for ML? &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/paradiso/do-you-really-need-ml/do-you-really-need-ml.md"&gt;Do you really need ML?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/paradiso/use-cases/use-cases.md"&gt;ML use cases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/paradiso/virgilio-teaching-strategy/virgilio-teaching-strategy.md"&gt;Virgilio's Teaching Strategy - Learning to Learn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/paradiso/introduction-to-ml/introduction-to-ml.md"&gt;Introduction to ML&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-purgatorio" class="anchor" aria-hidden="true" href="#purgatorio"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Purgatorio&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Fundamentals
&lt;ul&gt;
&lt;li&gt;&lt;a href="serving/purgatorio/fundamentals/math-fundamentals/math-fundamentals.md"&gt;Math Fundamentals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/purgatorio/fundamentals/statistics-fundamentals/statistics-fundamentals.md"&gt;Statistics Fundamentals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/purgatorio/fundamentals/python-fundamentals/python-fundamentals.md"&gt;Python Fundamentals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/purgatorio/fundamentals/jupyter-notebook/jupyter-notebook.md"&gt;Jupyter Notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/purgatorio/fundamentals/the-data-science-process/the-data-science-process.md"&gt;The Data Science Process&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Define The Scope and Ask Questions
&lt;ul&gt;
&lt;li&gt;&lt;a href="serving/purgatorio/define-the-scope-and-ask-questions/frame-the-problem/frame-the-problem.md"&gt;Frame The Problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/purgatorio/define-the-scope-and-ask-questions/usage-and-integration/usage-and-integration.md"&gt;Usage and Integration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/purgatorio/define-the-scope-and-ask-questions/starting-a-data-project/starting-a-data-project.md"&gt;Starting a Data Project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/purgatorio/define-the-scope-and-ask-questions/workspace-setup-and-cloud-computing/workspace-setup-and-cloud-computing.md"&gt;WorkSpace Setup and Cloud Computing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Collect and Prepare Data
&lt;ul&gt;
&lt;li&gt;&lt;a href="serving/purgatorio/collect-and-prepare-data/data-preparation/data-preparation.md"&gt;Data Preparation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/purgatorio/collect-and-prepare-data/data-visualization/data-visualization.md"&gt;Data Visualization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Select and Train Machine Learning Models
&lt;ul&gt;
&lt;li&gt;&lt;a href="serving/purgatorio/select-and-train-machine-learning-models/machine-learning/machine-learning.md"&gt;Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Evaluate and Fine-Tune&lt;/li&gt;
&lt;li&gt;Launch and Mantain the System&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-inferno" class="anchor" aria-hidden="true" href="#inferno"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Inferno&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Computer Vision
&lt;ul&gt;
&lt;li&gt;&lt;a href="serving/inferno/computer-vision/introduction-to-computer-vision/introduction-to-computer-vision.ipynb"&gt;Introduction to Computer Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/inferno/computer-vision/object-instance-segmentation/object-instance-segmentation.ipynb"&gt;Object Instance Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/inferno/computer-vision/object-tracking/object-tracking.ipynb"&gt;Object Tracking&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Natural Language Processing&lt;/li&gt;
&lt;li&gt;Virtual Assistants
&lt;ul&gt;
&lt;li&gt;&lt;a href="serving/inferno/virtual-assistants/dialogflow-chatbot/dialogflow-chatbot.md"&gt;Build a Virtual Assistant with DialogFlow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reinforcement Learning&lt;/li&gt;
&lt;li&gt;Soft Skills
&lt;ul&gt;
&lt;li&gt;&lt;a href="serving/inferno/soft-skills/impactful-presentations/impactful-presentations.md"&gt;Impactful Presentations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tools
&lt;ul&gt;
&lt;li&gt;&lt;a href="serving/inferno/tools/geo-gebra/geo-gebra.md"&gt;Geo Gebra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/inferno/tools/latex/latex.md"&gt;Latex&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/inferno/tools/regex/regex.ipynb"&gt;Regex&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/inferno/tools/wolfram-alpha/wolfram-alpha.md"&gt;Wolfram Alpha&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Research
&lt;ul&gt;
&lt;li&gt;&lt;a href="serving/inferno/research/zotero/zotero.md"&gt;Zotero&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="serving/inferno/research/sota-papers/sota-papers.md"&gt;State-of-Art Papers Explained&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Massive Computation&lt;/li&gt;
&lt;li&gt;Machine Learning for Business Applications&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-complete-learning-paths" class="anchor" aria-hidden="true" href="#complete-learning-paths"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Complete Learning Paths&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="LearningPaths/Machine%20Learning%20Engineer%20Career%20Path"&gt;Machine Learning Study Path&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-about" class="anchor" aria-hidden="true" href="#about"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About&lt;/h2&gt;
&lt;p&gt;Virgilio is developed and mantained by &lt;a href="docs/contributors.md"&gt;these awesome people&lt;/a&gt;.
You can email us &lt;code&gt;virgilio.datascience (at) gmail.com&lt;/code&gt; or join the &lt;a href="https://discord.gg/UpQ8bb7" rel="nofollow"&gt;Discord chat&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contribute" class="anchor" aria-hidden="true" href="#contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribute&lt;/h3&gt;
&lt;p&gt;That's awesome! Check the &lt;a href="https://github.com/virgili0/Virgilio/blob/master/docs/contributing.md"&gt;contribution guidelines&lt;/a&gt; and get involved in our project!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h3&gt;
&lt;p&gt;The project is licensed under the &lt;a href="LICENSE.md"&gt;GPLv3 terms&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>virgili0</author><guid isPermaLink="false">https://github.com/virgili0/Virgilio</guid><pubDate>Sat, 04 Jan 2020 00:07:00 GMT</pubDate></item><item><title>selfteaching/the-craft-of-selfteaching #8 in Jupyter Notebook, This week</title><link>https://github.com/selfteaching/the-craft-of-selfteaching</link><description>&lt;p&gt;&lt;i&gt;One has no future if one couldn't teach themself.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-the-craft-of-selfteaching" class="anchor" aria-hidden="true" href="#the-craft-of-selfteaching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;the-craft-of-selfteaching&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;One has no future if one couldn't teach themself&lt;a href="#fn1" name="user-content-fn1b"&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;&lt;a id="user-content-自学是门手艺" class="anchor" aria-hidden="true" href="#自学是门手艺"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;自学是门手艺&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;没有自学能力的人没有未来&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;作者：李笑来&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;特别感谢&lt;strong&gt;霍炬&lt;/strong&gt;（&lt;a href="https://github.com/virushuo"&gt;@virushuo&lt;/a&gt;）、&lt;strong&gt;洪强宁&lt;/strong&gt;（&lt;a href="https://github.com/hongqn"&gt;@hongqn&lt;/a&gt;) 两位良师诤友在此书写作过程中给予我的巨大帮助！&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; pseudo-code of selfteaching in Python&lt;/span&gt;

&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;teach_yourself&lt;/span&gt;(&lt;span class="pl-smi"&gt;anything&lt;/span&gt;):
    &lt;span class="pl-k"&gt;while&lt;/span&gt; &lt;span class="pl-k"&gt;not&lt;/span&gt; create():
        learn()
        practice()
    &lt;span class="pl-k"&gt;return&lt;/span&gt; teach_yourself(another)

teach_yourself(coding)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;请先行阅读 &lt;a href="T-appendix.jupyter-installation-and-setup.ipynb"&gt;T-appendix.jupyter-installation-and-setup&lt;/a&gt; 以便在本地安装 &lt;a href="https://github.com/jupyterlab/jupyterlab"&gt;Jupyterlab&lt;/a&gt; 而后就能用更好的体验阅读本书。&lt;/p&gt;
&lt;p&gt;有兴趣帮忙的朋友，请先行阅读 &lt;a href="02.proof-of-work.ipynb"&gt;如何使用 Pull Request 为这本书校对&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;2019 年 3 月 23 日，新增 Markdown 版本：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://github.com/selfteaching/the-craft-of-selfteaching/tree/master/markdown"&gt;https://github.com/selfteaching/the-craft-of-selfteaching/tree/master/markdown&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-目录" class="anchor" aria-hidden="true" href="#目录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目录&lt;/h3&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="01.preface.ipynb"&gt;01.preface（&lt;strong&gt;前言&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="02.proof-of-work.ipynb"&gt;02.proof-of-work（&lt;strong&gt;如何证明你真的读过这本书？&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.A.better.teachyourself.ipynb"&gt;Part.1.A.better.teachyourself（&lt;strong&gt;为什么一定要掌握自学能力？&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.B.why.start.from.learning.coding.ipynb"&gt;Part.1.B.why.start.from.learning.coding（&lt;strong&gt;为什么把编程当作自学的入口？&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.C.must.learn.sth.only.by.reading.ipynb"&gt;Part.1.C.must.learn.sth.only.by.reading（&lt;strong&gt;只靠阅读习得新技能&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.D.preparation.for.reading.ipynb"&gt;Part.1.D.preparation.for.reading（&lt;strong&gt;开始阅读前的一些准备&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.1.entrance.ipynb"&gt;Part.1.E.1.entrance（&lt;strong&gt;入口&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.2.values-and-their-operators.ipynb"&gt;Part.1.E.2.values-and-their-operators（&lt;strong&gt;值及其相应的运算&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.3.controlflow.ipynb"&gt;Part.1.E.3.controlflow（&lt;strong&gt;流程控制&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.4.functions.ipynb"&gt;Part.1.E.4.functions（&lt;strong&gt;函数&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.5.strings.ipynb"&gt;Part.1.E.5.strings（&lt;strong&gt;字符串&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.6.containers.ipynb"&gt;Part.1.E.6.containers（&lt;strong&gt;数据容器&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.E.7.files.ipynb"&gt;Part.1.E.7.files（&lt;strong&gt;文件&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.F.deal-with-forward-references.ipynb"&gt;Part.1.F.deal-with-forward-references（&lt;strong&gt;如何从容应对含有过多 “过早引用” 的知识？&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.1.G.The-Python-Tutorial-local.ipynb"&gt;Part.1.G.The-Python-Tutorial-local（&lt;strong&gt;官方教程：The Python Tutorial&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.A.clumsy-and-patience.ipynb"&gt;Part.2.A.clumsy-and-patience（&lt;strong&gt;笨拙与耐心&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.B.deliberate-practicing.ipynb"&gt;Part.2.B.deliberate-practicing（&lt;strong&gt;刻意练习&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.C.why-start-from-writing-functions.ipynb"&gt;Part.2.C.why-start-from-writing-functions（&lt;strong&gt;为什么从函数开始？&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.1-args.ipynb"&gt;Part.2.D.1-args（&lt;strong&gt;关于参数（上）&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.2-aargs.ipynb"&gt;Part.2.D.2-aargs（&lt;strong&gt;关于参数（下）&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.3-lambda.ipynb"&gt;Part.2.D.3-lambda（&lt;strong&gt;化名与匿名&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.4-recursion.ipynb"&gt;Part.2.D.4-recursion（&lt;strong&gt;递归函数&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.5-docstrings.ipynb"&gt;Part.2.D.5-docstrings（&lt;strong&gt;函数的文档&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.6-modules.ipynb"&gt;Part.2.D.6-modules（&lt;strong&gt;保存到文件的函数&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.7-tdd.ipynb"&gt;Part.2.D.7-tdd（&lt;strong&gt;测试驱动的开发&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.D.8-main.ipynb"&gt;Part.2.D.8-main（&lt;strong&gt;可执行的 Python 文件&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.2.E.deliberate-thinking.ipynb"&gt;Part.2.E.deliberate-thinking（&lt;strong&gt;刻意思考&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.A.conquering-difficulties.ipynb"&gt;Part.3.A.conquering-difficulties（&lt;strong&gt;战胜难点&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.B.1.classes-1.ipynb"&gt;Part.3.B.1.classes-1（&lt;strong&gt;类 —— 面向对象编程&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.B.2.classes-2.ipynb"&gt;Part.3.B.2.classes-2（&lt;strong&gt;类 —— Python 的实现&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.B.3.decorator-iterator-generator.ipynb"&gt;Part.3.B.3.decorator-iterator-generator（&lt;strong&gt;函数工具&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.B.4.regex.ipynb"&gt;Part.3.B.4.regex（&lt;strong&gt;正则表达式&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.B.5.bnf-ebnf-pebnf.ipynb"&gt;Part.3.B.5.bnf-ebnf-pebnf（&lt;strong&gt;BNF 以及 EBNF&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.C.breaking-good-and-bad.ipynb"&gt;Part.3.C.breaking-good-and-bad（&lt;strong&gt;拆解&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.D.indispensable-illusion.ipynb"&gt;Part.3.D.indispensable-illusion（&lt;strong&gt;刚需幻觉&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.E.to-be-thorough.ipynb"&gt;Part.3.E.to-be-thorough（&lt;strong&gt;全面 —— 自学的境界&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.F.social-selfteaching.ipynb"&gt;Part.3.F.social-selfteaching（&lt;strong&gt;自学者的社交&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.G.the-golden-age-and-google.ipynb"&gt;Part.3.G.the-golden-age-and-google（&lt;strong&gt;这是自学者的黄金时代&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Part.3.H.prevent-focus-drifting.ipynb"&gt;Part.3.H.prevent-focus-drifting（&lt;strong&gt;避免注意力漂移&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Q.good-communiation.ipynb"&gt;Q.good-communiation（&lt;strong&gt;如何成为优秀沟通者&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="R.finale.ipynb"&gt;R.finale（&lt;strong&gt;自学者的终点&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="S.whats-next.ipynb"&gt;S.whats-next（&lt;strong&gt;下一步干什么？&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="T-appendix.editor.vscode.ipynb"&gt;T-appendix.editor.vscode（&lt;strong&gt;Visual Studio Code 的安装与配置&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="T-appendix.git-introduction.ipynb"&gt;T-appendix.git-introduction（&lt;strong&gt;Git 简介&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="T-appendix.jupyter-installation-and-setup.ipynb"&gt;T-appendix.jupyter-installation-and-setup（&lt;strong&gt;Jupyterlab 的安装与配置&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="T-appendix.symbols.ipynb"&gt;T-appendix.symbols（&lt;strong&gt;这些符号都代表什么？&lt;/strong&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;本书的版权协议为 &lt;a href="https://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" rel="nofollow"&gt;CC-BY-NC-ND license&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/CC-BY-NC-ND.png?raw=true"&gt;&lt;img src="images/CC-BY-NC-ND.png?raw=true" alt="CC-BY-NC-ND" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;脚注&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name="user-content-fn1"&gt;[1]&lt;/a&gt;：&lt;a href="https://en.oxforddictionaries.com/usage/themselves-or-themself" rel="nofollow"&gt;'Themselves' or 'themself'? -- Oxford Dictionary&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="#fn1b"&gt;↑Back to Content↑&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>selfteaching</author><guid isPermaLink="false">https://github.com/selfteaching/the-craft-of-selfteaching</guid><pubDate>Sat, 04 Jan 2020 00:08:00 GMT</pubDate></item><item><title>fastai/course-nlp #9 in Jupyter Notebook, This week</title><link>https://github.com/fastai/course-nlp</link><description>&lt;p&gt;&lt;i&gt;A Code-First Introduction to NLP course&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-a-code-first-intro-to-natural-language-processing" class="anchor" aria-hidden="true" href="#a-code-first-intro-to-natural-language-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A Code-First Intro to Natural Language Processing&lt;/h1&gt;
&lt;p&gt;You can find out about the course in &lt;a href="https://www.fast.ai/2019/07/08/fastai-nlp/" rel="nofollow"&gt;this blog post&lt;/a&gt; and all &lt;a href="https://www.youtube.com/playlist?list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9" rel="nofollow"&gt;lecture videos are available here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This course was originally taught in the &lt;a href="https://www.usfca.edu/arts-sciences/graduate-programs/analytics" rel="nofollow"&gt;University of San Francisco's Masters of Science in Data Science&lt;/a&gt; program, summer 2019.  The course is taught in Python with Jupyter Notebooks, using libraries such as sklearn, nltk, pytorch, and fastai.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h2&gt;
&lt;p&gt;The following topics will be covered:&lt;/p&gt;
&lt;p&gt;1. What is NLP?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A changing field&lt;/li&gt;
&lt;li&gt;Resources&lt;/li&gt;
&lt;li&gt;Tools&lt;/li&gt;
&lt;li&gt;Python libraries&lt;/li&gt;
&lt;li&gt;Example applications&lt;/li&gt;
&lt;li&gt;Ethics issues&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2. Topic Modeling with NMF and SVD&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stop words, stemming, &amp;amp; lemmatization&lt;/li&gt;
&lt;li&gt;Term-document matrix&lt;/li&gt;
&lt;li&gt;Topic Frequency-Inverse Document Frequency (TF-IDF)&lt;/li&gt;
&lt;li&gt;Singular Value Decomposition (SVD)&lt;/li&gt;
&lt;li&gt;Non-negative Matrix Factorization (NMF)&lt;/li&gt;
&lt;li&gt;Truncated SVD, Randomized SVD&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3. Sentiment classification with Naive Bayes, Logistic regression, and ngrams&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sparse matrix storage&lt;/li&gt;
&lt;li&gt;Counters&lt;/li&gt;
&lt;li&gt;the fastai library&lt;/li&gt;
&lt;li&gt;Naive Bayes&lt;/li&gt;
&lt;li&gt;Logistic regression&lt;/li&gt;
&lt;li&gt;Ngrams&lt;/li&gt;
&lt;li&gt;Logistic regression with Naive Bayes features, with trigrams&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;4. Regex (and re-visiting tokenization)&lt;/p&gt;
&lt;p&gt;5. Language modeling &amp;amp; sentiment classification with deep learning&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Language model&lt;/li&gt;
&lt;li&gt;Transfer learning&lt;/li&gt;
&lt;li&gt;Sentiment classification&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;6. Translation with RNNs&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Review Embeddings&lt;/li&gt;
&lt;li&gt;Bleu metric&lt;/li&gt;
&lt;li&gt;Teacher Forcing&lt;/li&gt;
&lt;li&gt;Bidirectional&lt;/li&gt;
&lt;li&gt;Attention&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;7. Translation with the Transformer architecture&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transformer Model&lt;/li&gt;
&lt;li&gt;Multi-head attention&lt;/li&gt;
&lt;li&gt;Masking&lt;/li&gt;
&lt;li&gt;Label smoothing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;8. Bias &amp;amp; ethics in NLP&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bias in word embeddings&lt;/li&gt;
&lt;li&gt;types of bias&lt;/li&gt;
&lt;li&gt;attention economy&lt;/li&gt;
&lt;li&gt;drowning in fraudulent/fake info&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-why-is-this-course-taught-in-a-weird-order" class="anchor" aria-hidden="true" href="#why-is-this-course-taught-in-a-weird-order"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why is this course taught in a weird order?&lt;/h2&gt;
&lt;p&gt;This course is structured with a &lt;em&gt;top-down&lt;/em&gt; teaching method, which is different from how most math courses operate.  Typically, in a &lt;em&gt;bottom-up&lt;/em&gt; approach, you first learn all the separate components you will be using, and then you gradually build them up into more complex structures.  The problems with this are that students often lose motivation, don't have a sense of the "big picture", and don't know what they'll need.&lt;/p&gt;
&lt;p&gt;Harvard Professor David Perkins has a book, &lt;a href="https://www.amazon.com/Making-Learning-Whole-Principles-Transform/dp/0470633719" rel="nofollow"&gt;Making Learning Whole&lt;/a&gt; in which he uses baseball as an analogy.  We don't require kids to memorize all the rules of baseball and understand all the technical details before we let them play the game.  Rather, they start playing with a just general sense of it, and then gradually learn more rules/details as time goes on.&lt;/p&gt;
&lt;p&gt;If you took the fast.ai deep learning course, that is what we used.  You can hear more about my teaching philosophy &lt;a href="http://www.fast.ai/2016/10/08/teaching-philosophy/" rel="nofollow"&gt;in this blog post&lt;/a&gt; or &lt;a href="https://vimeo.com/214233053" rel="nofollow"&gt;this talk I gave at the San Francisco Machine Learning meetup&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All that to say, don't worry if you don't understand everything at first!  You're not supposed to.  We will start using some "black boxes" and then we'll dig into the lower level details later.&lt;/p&gt;
&lt;p&gt;To start, focus on what things DO, not what they ARE.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fastai</author><guid isPermaLink="false">https://github.com/fastai/course-nlp</guid><pubDate>Sat, 04 Jan 2020 00:09:00 GMT</pubDate></item><item><title>dsgiitr/d2l-pytorch #10 in Jupyter Notebook, This week</title><link>https://github.com/dsgiitr/d2l-pytorch</link><description>&lt;p&gt;&lt;i&gt;This project reproduces the book Dive Into Deep Learning (www.d2l.ai), adapting the code from MXNet into PyTorch.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/48b996ced5cc2698b283f5f96ea5dd25b40992f0/68747470733a2f2f64726976652e676f6f676c652e636f6d2f75633f6578706f72743d766965772669643d3172384a72424f386d2d656548744f4c2d64594e445745684a4332366e7571687a"&gt;&lt;img width="60%" src="https://camo.githubusercontent.com/48b996ced5cc2698b283f5f96ea5dd25b40992f0/68747470733a2f2f64726976652e676f6f676c652e636f6d2f75633f6578706f72743d766965772669643d3172384a72424f386d2d656548744f4c2d64594e445745684a4332366e7571687a" data-canonical-src="https://drive.google.com/uc?export=view&amp;amp;id=1r8JrBO8m-eeHtOL-dYNDWEhJC26nuqhz" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This project is adapted from the original &lt;a href="https://d2l.ai" rel="nofollow"&gt;Dive Into Deep Learning&lt;/a&gt; book by Aston Zhang, Zachary C. Lipton, Mu Li, Alex J. Smola and all the community contributors. GitHub of the original book: &lt;a href="https://github.com/d2l-ai/d2l-en"&gt;https://github.com/d2l-ai/d2l-en&lt;/a&gt;. We have made an effort to modify the book and convert the MXnet code snippets into PyTorch.&lt;/p&gt;
&lt;p&gt;Note: Some ipynb notebooks may not be rendered perfectly in Github. We suggest &lt;code&gt;cloning&lt;/code&gt; the repo or using &lt;a href="https://nbviewer.jupyter.org/" rel="nofollow"&gt;nbviewer&lt;/a&gt; to view the notebooks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-chapters" class="anchor" aria-hidden="true" href="#chapters"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Chapters&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ch02 Installation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch02_Installation/INSTALL.md"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ch03 Introduction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch03_Introduction/Introduction.ipynb"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ch04 The Preliminaries: A Crashcourse&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;4.1 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch04_The_Preliminaries_A_Crashcourse/Data_Manipulation.ipynb"&gt;Data Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;4.2 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch04_The_Preliminaries_A_Crashcourse/Linear_Algebra.ipynb"&gt;Linear Algebra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;4.3 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch04_The_Preliminaries_A_Crashcourse/Automatic_Differentiation.ipynb"&gt;Automatic Differentiation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;4.4 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch04_The_Preliminaries_A_Crashcourse/Probability_and_Statistics.ipynb"&gt;Probability and Statistics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;4.5 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch04_The_Preliminaries_A_Crashcourse/Naive_Bayes_Classification.ipynb"&gt;Naive Bayes Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;4.6 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch04_The_Preliminaries_A_Crashcourse/Documentation.ipynb"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ch05 Linear Neural Networks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;5.1 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch05_Linear_Neural_Networks/Linear_Regression.ipynb"&gt;Linear Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;5.2 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch05_Linear_Neural_Networks/Linear_Regression_Implementation_from_Scratch.ipynb"&gt;Linear Regression Implementation from Scratch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;5.3 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch05_Linear_Neural_Networks/Concise_Implementation_of_Linear_Regression.ipynb"&gt;Concise Implementation of Linear Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;5.4 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch05_Linear_Neural_Networks/Softmax_Regression.ipynb"&gt;Softmax Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;5.5 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch05_Linear_Neural_Networks/Image_Classification_Data(Fashion-MNIST).ipynb"&gt;Image Classification Data (Fashion-MNIST)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;5.6 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch05_Linear_Neural_Networks/Implementation_of_Softmax_Regression_from_Scratch.ipynb"&gt;Implementation of Softmax Regression from Scratch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;5.7 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch05_Linear_Neural_Networks/Concise_Implementation_of_Softmax_Regression.ipynb"&gt;Concise Implementation of Softmax Regression&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ch06 Multilayer Perceptrons&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;6.1 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch06_Multilayer_Perceptrons/Multilayer_Perceptron.ipynb"&gt;Multilayer Perceptron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;6.2 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch06_Multilayer_Perceptrons/Implementation_of_Multilayer_Perceptron_from_Scratch.ipynb"&gt;Implementation of Multilayer Perceptron from Scratch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;6.3 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch06_Multilayer_Perceptrons/Concise_Implementation_of_Multilayer_Perceptron.ipynb"&gt;Concise Implementation of Multilayer Perceptron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;6.4 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch06_Multilayer_Perceptrons/Model_Selection_Underfitting_and_Overfitting.ipynb"&gt;Model Selection Underfitting and Overfitting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;6.5 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch06_Multilayer_Perceptrons/Weight_Decay.ipynb"&gt;Weight Decay&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;6.6 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch06_Multilayer_Perceptrons/Dropout.ipynb"&gt;Dropout&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;6.7 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch06_Multilayer_Perceptrons/Forward_Propagation_Backward_Propagation_and_Computational_Graphs.ipynb"&gt;Forward Propagation Backward Propagation and Computational Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;6.8 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch06_Multilayer_Perceptrons/Numerical_Stability_and_Initialization.ipynb"&gt;Numerical Stability and Initialization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;6.9 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch06_Multilayer_Perceptrons/Considering_The_Environment.ipynb"&gt;Considering the Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;6.10 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch06_Multilayer_Perceptrons/Predicting_House_Prices_on_Kaggle.ipynb"&gt;Predicting House Prices on Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ch07 Deep Learning Computation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;7.1 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch07_Deep_Learning_Computation/Layers_and_Blocks.ipynb"&gt;Layers and Blocks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;7.2 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch07_Deep_Learning_Computation/Parameter_Management.ipynb"&gt;Parameter Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;7.3 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch07_Deep_Learning_Computation/Deferred_Initialization.ipynb"&gt;Deferred Initialization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;7.4 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch07_Deep_Learning_Computation/Custom_Layers.ipynb"&gt;Custom Layers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;7.5 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch07_Deep_Learning_Computation/File_I_O.ipynb"&gt;File I/O&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;7.6 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch07_Deep_Learning_Computation/GPUs.ipynb"&gt;GPUs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ch08 Convolutional Neural Networks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;8.1 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch08_Convolutional_Neural_Networks/From_Dense_Layers_to_Convolutions.ipynb"&gt;From Dense Layers to Convolutions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;8.2 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch08_Convolutional_Neural_Networks/Convolutions_For_Images.ipynb"&gt;Convolutions for Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;8.3 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch08_Convolutional_Neural_Networks/Padding_and_Stride.ipynb"&gt;Padding and Stride&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;8.4 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch08_Convolutional_Neural_Networks/Multiple_Input_and_Output_Channels.ipynb"&gt;Multiple Input and Output Channels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;8.5 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch08_Convolutional_Neural_Networks/Pooling.ipynb"&gt;Pooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;8.6 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch08_Convolutional_Neural_Networks/Convolutional_Neural_Networks(LeNet).ipynb"&gt;Convolutional Neural Networks (LeNet)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ch09 Modern Convolutional Networks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;9.1 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch09_Modern_Convolutional_Networks/AlexNet.ipynb"&gt;Deep Convolutional Neural Networks (AlexNet)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;9.2 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch09_Modern_Convolutional_Networks/VGG.ipynb"&gt;Networks Using Blocks (VGG)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;9.3 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch09_Modern_Convolutional_Networks/Network_in_Network(NiN).ipynb"&gt;Network in Network (NiN)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;9.4 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch09_Modern_Convolutional_Networks/Networks_with_Parallel_Concatenations_(GoogLeNet).ipynb"&gt;Networks with Parallel Concatenations (GoogLeNet)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;9.5 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch09_Modern_Convolutional_Networks/Batch_Normalization.ipynb"&gt;Batch Normalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;9.6 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch09_Modern_Convolutional_Networks/Residual_Networks_(ResNet).ipynb"&gt;Residual Networks (ResNet)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;9.7 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch09_Modern_Convolutional_Networks/Densely_Connected_Networks_(DenseNet).ipynb"&gt;Densely Connected Networks (DenseNet)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ch10 Recurrent Neural Networks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;10.1 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Sequence_Models.ipynb"&gt;Sequence Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.2 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Language_Models.ipynb"&gt;Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.3 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Recurrent_Neural_Networks.ipynb"&gt;Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.4 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Text_Preprocessing.ipynb"&gt;Text Preprocessing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.5 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Implementation_of_Recurrent_Neural_Networks_from_Scratch.ipynb"&gt;Implementation of Recurrent Neural Networks from Scratch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.6 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Concise_Implementation_of_Recurrent_Neural_Networks.ipynb"&gt;Concise Implementation of Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.7 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Backpropagation_Through_Time.ipynb"&gt;Backpropagation Through Time&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.8 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Gated_Recurrent_Units.ipynb"&gt;Gated Recurrent Units (GRU)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.9 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Long_Short_Term_Memory.ipynb"&gt;Long Short Term Memory (LSTM)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.10 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Deep_Recurrent_Neural_Networks.ipynb"&gt;Deep Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.11 Bidirectional Recurrent Neural Networks&lt;/li&gt;
&lt;li&gt;10.12 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Machine_Translation_and_Data_Sets.ipynb"&gt;Machine Translation and DataSets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.13 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Encoder-Decoder_Architecture.ipynb"&gt;Encoder-Decoder Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.14 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Sequence_to_Sequence.ipynb"&gt;Sequence to Sequence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.15 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch10_Recurrent_Neural_Networks/Beam_Search.ipynb"&gt;Beam Search&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ch11 Attention Mechanism&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;11.1 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch11_Attention_Mechanism/Attention_Mechanism.ipynb"&gt;Attention Mechanism&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;11.2 Sequence to Sequence with Attention Mechanism&lt;/li&gt;
&lt;li&gt;11.3 Transformer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ch12 Optimization Algorithms&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;12.1 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch12_Optimization_Algorithms/Optimization_And_Deep_Learning.ipynb"&gt;Optimization and Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;12.2 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch12_Optimization_Algorithms/Convexity.ipynb"&gt;Convexity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;12.3 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch12_Optimization_Algorithms/Gradient_Descent.ipynb"&gt;Gradient Descent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;12.4 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch12_Optimization_Algorithms/Stochastic_Gradient_Descent.ipynb"&gt;Stochastic Gradient Descent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;12.5 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch12_Optimization_Algorithms/Mini-batch_Stochastic_Gradient_Descent.ipynb"&gt;Mini-batch Stochastic Gradient Descent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;12.6 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch12_Optimization_Algorithms/Momentum.ipynb"&gt;Momentum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;12.7 Adagrad&lt;/li&gt;
&lt;li&gt;12.8 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch12_Optimization_Algorithms/RMSProp.ipynb"&gt;RMSProp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;12.9 Adadelta&lt;/li&gt;
&lt;li&gt;12.10 Adam&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ch14 Computer Vision&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;14.1 Image Augmentation&lt;/li&gt;
&lt;li&gt;14.2 Fine Tuning&lt;/li&gt;
&lt;li&gt;14.3 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch14_Computer_Vision/Object_Detection_and_Bounding_Boxes.ipynb"&gt;Object Detection and Bounding Boxes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;14.4 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch14_Computer_Vision/Anchor_Boxes.ipynb"&gt;Anchor Boxes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;14.5 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch14_Computer_Vision/Multiscale_Object_Detection.ipynb"&gt;Multiscale Object Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;14.6 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch14_Computer_Vision/Object_Detection_Data_Set.ipynb"&gt;Object Detection Data Set (Pikachu)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;14.7 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch14_Computer_Vision/Single_Shot_Multibox_Detection.ipynb"&gt;Single Shot Multibox Detection (SSD)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;14.8 Region-based CNNs (R-CNNs)&lt;/li&gt;
&lt;li&gt;14.9 Semantic Segmentation and Data Sets&lt;/li&gt;
&lt;li&gt;14.10 Transposed Convolution&lt;/li&gt;
&lt;li&gt;14.11 Fully Convolutional Networks (FCN)&lt;/li&gt;
&lt;li&gt;14.12 &lt;a href="https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch14_Computer_Vision/Neural_Style_Transfer.ipynb"&gt;Neural Style Transfer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;14.13 Image Classification (CIFAR-10) on Kaggle&lt;/li&gt;
&lt;li&gt;14.14 Dog Breed Identification (ImageNet Dogs) on Kaggle&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Please feel free to open a Pull Request to contribute a notebook in PyTorch for the rest of the chapters. Before starting     out with the notebook, open an issue with the name of the notebook in order to contribute for the same. We will assign         that issue to you (if no one has been assigned earlier).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Strictly follow the naming conventions for the IPython Notebooks and the subsections.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Also, if you think there's any section that requires more/better explanation, please use the issue tracker to
open an issue and let us know about the same. We'll get back as soon as possible.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find some code that needs improvement and submit a pull request.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find a reference that we missed and submit a pull request.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Try not to submit huge pull requests since this makes them hard to understand and incorporate.
Better send several smaller ones.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-support" class="anchor" aria-hidden="true" href="#support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support&lt;/h2&gt;
&lt;p&gt;If you like this repo and find it useful, please consider (★) starring it, so that it can reach a broader audience.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-references" class="anchor" aria-hidden="true" href="#references"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Original Book &lt;a href="https://d2l.ai" rel="nofollow"&gt;Dive Into Deep Learning&lt;/a&gt; -&amp;gt; &lt;a href="https://github.com/d2l-ai/d2l-en"&gt;Github Repo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href="https://github.com/zackchase/mxnet-the-straight-dope"&gt;Deep Learning - The Straight Dope&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href="https://github.com/zackchase/mxnet-the-straight-dope/blob/master/cheatsheets/pytorch_gluon.md"&gt;PyTorch - MXNet Cheatsheet&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-cite" class="anchor" aria-hidden="true" href="#cite"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cite&lt;/h2&gt;
&lt;p&gt;If you use this work or code for your research please cite the original book with the following bibtex entry.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@book{zhang2020dive,
    title={Dive into Deep Learning},
    author={Aston Zhang and Zachary C. Lipton and Mu Li and Alexander J. Smola},
    note={\url{https://d2l.ai}},
    year={2020}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dsgiitr</author><guid isPermaLink="false">https://github.com/dsgiitr/d2l-pytorch</guid><pubDate>Sat, 04 Jan 2020 00:10:00 GMT</pubDate></item><item><title>huseinzol05/Stock-Prediction-Models #11 in Jupyter Notebook, This week</title><link>https://github.com/huseinzol05/Stock-Prediction-Models</link><description>&lt;p&gt;&lt;i&gt;Gathers machine learning and deep learning models for Stock forecasting including trading bots and simulations&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
    &lt;a href="#readme"&gt;
        &lt;img alt="logo" width="50%" src="output/evolution-strategy.png" style="max-width:100%;"&gt;
    &lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a href="https://github.com/huseinzol05/Stock-Prediction-Models/blob/master/LICENSE"&gt;&lt;img alt="MIT License" src="https://camo.githubusercontent.com/65c6912b68aeea16375c94041820c27b3d8d9c8b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4170616368652d2d4c6963656e73652d2d322e302d79656c6c6f772e737667" data-canonical-src="https://img.shields.io/badge/License-Apache--License--2.0-yellow.svg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a href="#"&gt;&lt;img src="https://camo.githubusercontent.com/a109e6ff3099b0fe22cf4964a86453b3992990d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646565706c6561726e696e672d33302d2d6d6f64656c732d737563636573732e737667" data-canonical-src="https://img.shields.io/badge/deeplearning-30--models-success.svg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a href="#"&gt;&lt;img src="https://camo.githubusercontent.com/49a8b81e45fcd97bb447147c89e1dc8d7ba5db83/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6167656e742d32332d2d6d6f64656c732d737563636573732e737667" data-canonical-src="https://img.shields.io/badge/agent-23--models-success.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Stock-Prediction-Models&lt;/strong&gt;, Gathers machine learning and deep learning models for Stock forecasting, included trading bots and simulations.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/huseinzol05/Stock-Prediction-Models#models"&gt;Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huseinzol05/Stock-Prediction-Models#agents"&gt;Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="realtime-agent"&gt;Realtime Agent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huseinzol05/Stock-Prediction-Models#data-explorations"&gt;Data Explorations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huseinzol05/Stock-Prediction-Models#simulations"&gt;Simulations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huseinzol05/Stock-Prediction-Models#tensorflow-js"&gt;Tensorflow-js&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huseinzol05/Stock-Prediction-Models#misc"&gt;Misc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huseinzol05/Stock-Prediction-Models#results"&gt;Results&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/huseinzol05/Stock-Prediction-Models#results-agent"&gt;Results Agent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huseinzol05/Stock-Prediction-Models#results-signal-prediction"&gt;Results signal prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huseinzol05/Stock-Prediction-Models#results-analysis"&gt;Results analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huseinzol05/Stock-Prediction-Models#results-simulation"&gt;Results simulation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-models" class="anchor" aria-hidden="true" href="#models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Models&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-deep-learning-models" class="anchor" aria-hidden="true" href="#deep-learning-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="deep-learning"&gt;Deep-learning models&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;LSTM&lt;/li&gt;
&lt;li&gt;LSTM Bidirectional&lt;/li&gt;
&lt;li&gt;LSTM 2-Path&lt;/li&gt;
&lt;li&gt;GRU&lt;/li&gt;
&lt;li&gt;GRU Bidirectional&lt;/li&gt;
&lt;li&gt;GRU 2-Path&lt;/li&gt;
&lt;li&gt;Vanilla&lt;/li&gt;
&lt;li&gt;Vanilla Bidirectional&lt;/li&gt;
&lt;li&gt;Vanilla 2-Path&lt;/li&gt;
&lt;li&gt;LSTM Seq2seq&lt;/li&gt;
&lt;li&gt;LSTM Bidirectional Seq2seq&lt;/li&gt;
&lt;li&gt;LSTM Seq2seq VAE&lt;/li&gt;
&lt;li&gt;GRU Seq2seq&lt;/li&gt;
&lt;li&gt;GRU Bidirectional Seq2seq&lt;/li&gt;
&lt;li&gt;GRU Seq2seq VAE&lt;/li&gt;
&lt;li&gt;Attention-is-all-you-Need&lt;/li&gt;
&lt;li&gt;CNN-Seq2seq&lt;/li&gt;
&lt;li&gt;Dilated-CNN-Seq2seq&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Bonus&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How to use one of the model to forecast &lt;code&gt;t + N&lt;/code&gt;, &lt;a href="deep-learning/how-to-forecast.ipynb"&gt;how-to-forecast.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Consensus, how to use sentiment data to forecast &lt;code&gt;t + N&lt;/code&gt;, &lt;a href="deep-learning/sentiment-consensus.ipynb"&gt;sentiment-consensus.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-stacking-models" class="anchor" aria-hidden="true" href="#stacking-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="stacking"&gt;Stacking models&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Deep Feed-forward Auto-Encoder Neural Network to reduce dimension + Deep Recurrent Neural Network + ARIMA + Extreme Boosting Gradient Regressor&lt;/li&gt;
&lt;li&gt;Adaboost + Bagging + Extra Trees + Gradient Boosting + Random Forest + XGB&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-agents" class="anchor" aria-hidden="true" href="#agents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="agent"&gt;Agents&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Turtle-trading agent&lt;/li&gt;
&lt;li&gt;Moving-average agent&lt;/li&gt;
&lt;li&gt;Signal rolling agent&lt;/li&gt;
&lt;li&gt;Policy-gradient agent&lt;/li&gt;
&lt;li&gt;Q-learning agent&lt;/li&gt;
&lt;li&gt;Evolution-strategy agent&lt;/li&gt;
&lt;li&gt;Double Q-learning agent&lt;/li&gt;
&lt;li&gt;Recurrent Q-learning agent&lt;/li&gt;
&lt;li&gt;Double Recurrent Q-learning agent&lt;/li&gt;
&lt;li&gt;Duel Q-learning agent&lt;/li&gt;
&lt;li&gt;Double Duel Q-learning agent&lt;/li&gt;
&lt;li&gt;Duel Recurrent Q-learning agent&lt;/li&gt;
&lt;li&gt;Double Duel Recurrent Q-learning agent&lt;/li&gt;
&lt;li&gt;Actor-critic agent&lt;/li&gt;
&lt;li&gt;Actor-critic Duel agent&lt;/li&gt;
&lt;li&gt;Actor-critic Recurrent agent&lt;/li&gt;
&lt;li&gt;Actor-critic Duel Recurrent agent&lt;/li&gt;
&lt;li&gt;Curiosity Q-learning agent&lt;/li&gt;
&lt;li&gt;Recurrent Curiosity Q-learning agent&lt;/li&gt;
&lt;li&gt;Duel Curiosity Q-learning agent&lt;/li&gt;
&lt;li&gt;Neuro-evolution agent&lt;/li&gt;
&lt;li&gt;Neuro-evolution with Novelty search agent&lt;/li&gt;
&lt;li&gt;ABCD strategy agent&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-data-explorations" class="anchor" aria-hidden="true" href="#data-explorations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="misc"&gt;Data Explorations&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;stock market study on TESLA stock, &lt;a href="misc/tesla-study.ipynb"&gt;tesla-study.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Outliers study using K-means, SVM, and Gaussian on TESLA stock, &lt;a href="misc/outliers.ipynb"&gt;outliers.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Overbought-Oversold study on TESLA stock, &lt;a href="misc/overbought-oversold.ipynb"&gt;overbought-oversold.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Which stock you need to buy? &lt;a href="misc/which-stock.ipynb"&gt;which-stock.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-simulations" class="anchor" aria-hidden="true" href="#simulations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="simulation"&gt;Simulations&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Simple Monte Carlo, &lt;a href="simulation/monte-carlo-drift.ipynb"&gt;monte-carlo-drift.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Dynamic volatility Monte Carlo, &lt;a href="simulation/monte-carlo-dynamic-volatility.ipynb"&gt;monte-carlo-dynamic-volatility.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Drift Monte Carlo, &lt;a href="simulation/monte-carlo-drift.ipynb"&gt;monte-carlo-drift.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Multivariate Drift Monte Carlo BTC/USDT with Bitcurate sentiment, &lt;a href="simulation/multivariate-drift-monte-carlo.ipynb"&gt;multivariate-drift-monte-carlo.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Portfolio optimization, &lt;a href="simulation/portfolio-optimization.ipynb"&gt;portfolio-optimization.ipynb&lt;/a&gt;, inspired from &lt;a href="https://pythonforfinance.net/2017/01/21/investment-portfolio-optimisation-with-python/" rel="nofollow"&gt;https://pythonforfinance.net/2017/01/21/investment-portfolio-optimisation-with-python/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-tensorflow-js" class="anchor" aria-hidden="true" href="#tensorflow-js"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="stock-forecasting-js"&gt;Tensorflow-js&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I code &lt;a href="deep-learning/1.lstm.ipynb"&gt;LSTM Recurrent Neural Network&lt;/a&gt; and &lt;a href="agent/simple-agent.ipynb"&gt;Simple signal rolling agent&lt;/a&gt; inside Tensorflow JS, you can try it here, &lt;a href="https://huseinhouse.com/stock-forecasting-js/" rel="nofollow"&gt;huseinhouse.com/stock-forecasting-js&lt;/a&gt;, you can download any historical CSV and upload dynamically.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-misc" class="anchor" aria-hidden="true" href="#misc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="misc"&gt;Misc&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;fashion trending prediction with cross-validation, &lt;a href="misc/fashion-forecasting.ipynb"&gt;fashion-forecasting.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bitcoin analysis with LSTM prediction, &lt;a href="misc/bitcoin-analysis-lstm.ipynb"&gt;bitcoin-analysis-lstm.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kijang Emas Bank Negara, &lt;a href="misc/kijang-emas-bank-negara.ipynb"&gt;kijang-emas-bank-negara.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-results" class="anchor" aria-hidden="true" href="#results"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Results&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-results-agent" class="anchor" aria-hidden="true" href="#results-agent"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Results Agent&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;This agent only able to buy or sell 1 unit per transaction.&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Turtle-trading agent, &lt;a href="agent/1.turtle-agent.ipynb"&gt;turtle-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/turtle-agent.png"&gt;&lt;img src="output-agent/turtle-agent.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Moving-average agent, &lt;a href="agent/2.moving-average-agent.ipynb"&gt;moving-average-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/moving-average-agent.png"&gt;&lt;img src="output-agent/moving-average-agent.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Signal rolling agent, &lt;a href="agent/3.signal-rolling-agent.ipynb"&gt;signal-rolling-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/signal-rolling-agent.png"&gt;&lt;img src="output-agent/signal-rolling-agent.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="4"&gt;
&lt;li&gt;Policy-gradient agent, &lt;a href="agent/4.policy-gradient-agent.ipynb"&gt;policy-gradient-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/policy-gradient-agent.png"&gt;&lt;img src="output-agent/policy-gradient-agent.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="5"&gt;
&lt;li&gt;Q-learning agent, &lt;a href="agent/5.q-learning-agent.ipynb"&gt;q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/q-learning-agent.png"&gt;&lt;img src="output-agent/q-learning-agent.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="6"&gt;
&lt;li&gt;Evolution-strategy agent, &lt;a href="agent/6.evolution-strategy-agent.ipynb"&gt;evolution-strategy-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/evolution-strategy-agent.png"&gt;&lt;img src="output-agent/evolution-strategy-agent.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="7"&gt;
&lt;li&gt;Double Q-learning agent, &lt;a href="agent/7.double-q-learning-agent.ipynb"&gt;double-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/double-q-learning.png"&gt;&lt;img src="output-agent/double-q-learning.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="8"&gt;
&lt;li&gt;Recurrent Q-learning agent, &lt;a href="agent/8.recurrent-q-learning-agent.ipynb"&gt;recurrent-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/recurrent-q-learning.png"&gt;&lt;img src="output-agent/recurrent-q-learning.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="9"&gt;
&lt;li&gt;Double Recurrent Q-learning agent, &lt;a href="agent/9.double-recurrent-q-learning-agent.ipynb"&gt;double-recurrent-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/double-recurrent-q-learning.png"&gt;&lt;img src="output-agent/double-recurrent-q-learning.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="10"&gt;
&lt;li&gt;Duel Q-learning agent, &lt;a href="agent/10.duel-q-learning-agent.ipynb"&gt;duel-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/double-q-learning.png"&gt;&lt;img src="output-agent/double-q-learning.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="11"&gt;
&lt;li&gt;Double Duel Q-learning agent, &lt;a href="agent/11.double-duel-q-learning-agent.ipynb"&gt;double-duel-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/double-duel-q-learning.png"&gt;&lt;img src="output-agent/double-duel-q-learning.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="12"&gt;
&lt;li&gt;Duel Recurrent Q-learning agent, &lt;a href="agent/12.duel-recurrent-q-learning-agent.ipynb"&gt;duel-recurrent-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/duel-recurrent-q-learning.png"&gt;&lt;img src="output-agent/duel-recurrent-q-learning.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="13"&gt;
&lt;li&gt;Double Duel Recurrent Q-learning agent, &lt;a href="agent/13.double-duel-recurrent-q-learning-agent.ipynb"&gt;double-duel-recurrent-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/double-duel-recurrent-q-learning.png"&gt;&lt;img src="output-agent/double-duel-recurrent-q-learning.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="14"&gt;
&lt;li&gt;Actor-critic agent, &lt;a href="agent/14.actor-critic-agent.ipynb"&gt;actor-critic-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/actor-critic.png"&gt;&lt;img src="output-agent/actor-critic.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="15"&gt;
&lt;li&gt;Actor-critic Duel agent, &lt;a href="agent/14.actor-critic-duel-agent.ipynb"&gt;actor-critic-duel-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/actor-critic-duel.png"&gt;&lt;img src="output-agent/actor-critic-duel.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="16"&gt;
&lt;li&gt;Actor-critic Recurrent agent, &lt;a href="agent/16.actor-critic-recurrent-agent.ipynb"&gt;actor-critic-recurrent-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/actor-critic-recurrent.png"&gt;&lt;img src="output-agent/actor-critic-recurrent.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="17"&gt;
&lt;li&gt;Actor-critic Duel Recurrent agent, &lt;a href="agent/17.actor-critic-duel-recurrent-agent.ipynb"&gt;actor-critic-duel-recurrent-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/actor-critic-duel-recurrent.png"&gt;&lt;img src="output-agent/actor-critic-duel-recurrent.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="18"&gt;
&lt;li&gt;Curiosity Q-learning agent, &lt;a href="agent/18.curiosity-q-learning-agent.ipynb"&gt;curiosity-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/curiosity-q-learning.png"&gt;&lt;img src="output-agent/curiosity-q-learning.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="19"&gt;
&lt;li&gt;Recurrent Curiosity Q-learning agent, &lt;a href="agent/19.recurrent-curiosity-q-learning-agent.ipynb"&gt;recurrent-curiosity-q-learning.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/recurrent-curiosity-q-learning.png"&gt;&lt;img src="output-agent/recurrent-curiosity-q-learning.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="20"&gt;
&lt;li&gt;Duel Curiosity Q-learning agent, &lt;a href="agent/20.duel-curiosity-q-learning-agent.ipynb"&gt;duel-curiosity-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/duel-curiosity-q-learning.png"&gt;&lt;img src="output-agent/duel-curiosity-q-learning.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="21"&gt;
&lt;li&gt;Neuro-evolution agent, &lt;a href="agent/21.neuro-evolution-agent.ipynb"&gt;neuro-evolution.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/neuro-evolution.png"&gt;&lt;img src="output-agent/neuro-evolution.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="22"&gt;
&lt;li&gt;Neuro-evolution with Novelty search agent, &lt;a href="agent/22.neuro-evolution-novelty-search-agent.ipynb"&gt;neuro-evolution-novelty-search.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/neuro-evolution-novelty-search.png"&gt;&lt;img src="output-agent/neuro-evolution-novelty-search.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="23"&gt;
&lt;li&gt;ABCD strategy agent, &lt;a href="agent/23.abcd-strategy-agent.ipynb"&gt;abcd-strategy.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output-agent/abcd-strategy.png"&gt;&lt;img src="output-agent/abcd-strategy.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-results-signal-prediction" class="anchor" aria-hidden="true" href="#results-signal-prediction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Results signal prediction&lt;/h3&gt;
&lt;p&gt;I will cut the dataset to train and test datasets,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Train dataset derived from starting timestamp until last 30 days&lt;/li&gt;
&lt;li&gt;Test dataset derived from last 30 days until end of the dataset&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So we will let the model do forecasting based on last 30 days, and we will going to repeat the experiment for 10 times. You can increase it locally if you want, and tuning parameters will help you by a lot.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;LSTM, accuracy 95.693%, time taken for 1 epoch 01:09&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/lstm.png"&gt;&lt;img src="output/lstm.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;LSTM Bidirectional, accuracy 93.8%, time taken for 1 epoch 01:40&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/bidirectional-lstm.png"&gt;&lt;img src="output/bidirectional-lstm.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;LSTM 2-Path, accuracy 94.63%, time taken for 1 epoch 01:39&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/lstm-2path.png"&gt;&lt;img src="output/lstm-2path.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="4"&gt;
&lt;li&gt;GRU, accuracy 94.63%, time taken for 1 epoch 02:10&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/gru.png"&gt;&lt;img src="output/gru.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="5"&gt;
&lt;li&gt;GRU Bidirectional, accuracy 92.5673%, time taken for 1 epoch 01:40&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/bidirectional-gru.png"&gt;&lt;img src="output/bidirectional-gru.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="6"&gt;
&lt;li&gt;GRU 2-Path, accuracy 93.2117%, time taken for 1 epoch 01:39&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/gru-2path.png"&gt;&lt;img src="output/gru-2path.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="7"&gt;
&lt;li&gt;Vanilla, accuracy 91.4686%, time taken for 1 epoch 00:52&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/vanilla.png"&gt;&lt;img src="output/vanilla.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="8"&gt;
&lt;li&gt;Vanilla Bidirectional, accuracy 88.9927%, time taken for 1 epoch 01:06&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/bidirectional-vanilla.png"&gt;&lt;img src="output/bidirectional-vanilla.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="9"&gt;
&lt;li&gt;Vanilla 2-Path, accuracy 91.5406%, time taken for 1 epoch 01:08&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/vanilla-2path.png"&gt;&lt;img src="output/vanilla-2path.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="10"&gt;
&lt;li&gt;LSTM Seq2seq, accuracy 94.9817%, time taken for 1 epoch 01:36&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/lstm-seq2seq.png"&gt;&lt;img src="output/lstm-seq2seq.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="11"&gt;
&lt;li&gt;LSTM Bidirectional Seq2seq, accuracy 94.517%, time taken for 1 epoch 02:30&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/bidirectional-lstm-seq2seq.png"&gt;&lt;img src="output/bidirectional-lstm-seq2seq.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="12"&gt;
&lt;li&gt;LSTM Seq2seq VAE, accuracy 95.4190%, time taken for 1 epoch 01:48&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/lstm-seq2seq-vae.png"&gt;&lt;img src="output/lstm-seq2seq-vae.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="13"&gt;
&lt;li&gt;GRU Seq2seq, accuracy 90.8854%, time taken for 1 epoch 01:34&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/gru-seq2seq.png"&gt;&lt;img src="output/gru-seq2seq.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="14"&gt;
&lt;li&gt;GRU Bidirectional Seq2seq, accuracy 67.9915%, time taken for 1 epoch 02:30&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/bidirectional-gru-seq2seq.png"&gt;&lt;img src="output/bidirectional-gru-seq2seq.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="15"&gt;
&lt;li&gt;GRU Seq2seq VAE, accuracy 89.1321%, time taken for 1 epoch 01:48&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/gru-seq2seq-vae.png"&gt;&lt;img src="output/gru-seq2seq-vae.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="16"&gt;
&lt;li&gt;Attention-is-all-you-Need, accuracy 94.2482%, time taken for 1 epoch 01:41&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/attention-is-all-you-need.png"&gt;&lt;img src="output/attention-is-all-you-need.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="17"&gt;
&lt;li&gt;CNN-Seq2seq, accuracy 90.74%, time taken for 1 epoch 00:43&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/cnn-seq2seq.png"&gt;&lt;img src="output/cnn-seq2seq.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="18"&gt;
&lt;li&gt;Dilated-CNN-Seq2seq, accuracy 95.86%, time taken for 1 epoch 00:14&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/dilated-cnn-seq2seq.png"&gt;&lt;img src="output/dilated-cnn-seq2seq.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bonus&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How to forecast,&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/how-to-forecast.png"&gt;&lt;img src="output/how-to-forecast.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Sentiment consensus,&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="output/sentiment-consensus.png"&gt;&lt;img src="output/sentiment-consensus.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-results-analysis" class="anchor" aria-hidden="true" href="#results-analysis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Results analysis&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Outliers study using K-means, SVM, and Gaussian on TESLA stock&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="misc/outliers.png"&gt;&lt;img src="misc/outliers.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Overbought-Oversold study on TESLA stock&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="misc/overbought-oversold.png"&gt;&lt;img src="misc/overbought-oversold.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Which stock you need to buy?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="misc/which-stock.png"&gt;&lt;img src="misc/which-stock.png" width="40%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-results-simulation" class="anchor" aria-hidden="true" href="#results-simulation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Results simulation&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Simple Monte Carlo&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="simulation/monte-carlo-simple.png"&gt;&lt;img src="simulation/monte-carlo-simple.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Dynamic volatity Monte Carlo&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="simulation/monte-carlo-dynamic-volatility.png"&gt;&lt;img src="simulation/monte-carlo-dynamic-volatility.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Drift Monte Carlo&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="simulation/monte-carlo-drift.png"&gt;&lt;img src="simulation/monte-carlo-drift.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="4"&gt;
&lt;li&gt;Multivariate Drift Monte Carlo BTC/USDT with Bitcurate sentiment&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="simulation/multivariate-drift-monte-carlo.png"&gt;&lt;img src="simulation/multivariate-drift-monte-carlo.png" width="70%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol start="5"&gt;
&lt;li&gt;Portfolio optimization&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="simulation/portfolio-optimization.png"&gt;&lt;img src="simulation/portfolio-optimization.png" width="40%" align="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>huseinzol05</author><guid isPermaLink="false">https://github.com/huseinzol05/Stock-Prediction-Models</guid><pubDate>Sat, 04 Jan 2020 00:11:00 GMT</pubDate></item><item><title>Pierian-Data/Complete-Python-3-Bootcamp #12 in Jupyter Notebook, This week</title><link>https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</link><description>&lt;p&gt;&lt;i&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-complete-python-3-bootcamp" class="anchor" aria-hidden="true" href="#complete-python-3-bootcamp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Complete-Python-3-Bootcamp&lt;/h1&gt;
&lt;p&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/p&gt;
&lt;p&gt;Get it now for 95% off with the link:
&lt;a href="https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB" rel="nofollow"&gt;https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Pierian-Data</author><guid isPermaLink="false">https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</guid><pubDate>Sat, 04 Jan 2020 00:12:00 GMT</pubDate></item><item><title>jackfrued/Python-100-Days #13 in Jupyter Notebook, This week</title><link>https://github.com/jackfrued/Python-100-Days</link><description>&lt;p&gt;&lt;i&gt;Python - 100天从新手到大师&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-python---100天从新手到大师" class="anchor" aria-hidden="true" href="#python---100天从新手到大师"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python - 100天从新手到大师&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;作者：骆昊&lt;/p&gt;
&lt;p&gt;最近有很多想学习Python的小伙伴陆陆续续加入我们的交流群，目前我们的交流群人数已经超过一万人。我们的目标是打造一个优质的Python交流社区，一方面为想学习Python的初学者扫平入门过程中的重重障碍；另一方为新入行的开发者提供问道的途径，帮助他们迅速成长为优秀的职业人；此外，有经验的开发者可以利用这个平台把自己的工作经验无偿分享或有偿提供出来，让大家都能够得到职业技能以及综合素质的全面提升。之前的公开课和线下技术交流活动因为工作的关系荒废了一段时间了，但是各位小伙伴仍然活跃在交流群并一如既往的支持我们，在此向大家表示感谢。近期开始持续更新前15天和最后10天的内容，前15天是写给初学者的，我希望把上手的难度进一步降低，例子程序更加简单清晰；最后10天是Python项目实战和面试相关的东西，我希望内容更详实和完整，尤其是第100天的面试题部分；创作不易，感谢大家的打赏支持，这些钱不会用于购买咖啡而是通过腾讯公益平台捐赠给需要帮助的人（&lt;a href="./%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97.md"&gt;点击&lt;/a&gt;了解捐赠情况）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-qq-group.png"&gt;&lt;img src="./res/python-qq-group.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-python应用领域和就业形势分析" class="anchor" aria-hidden="true" href="#python应用领域和就业形势分析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python应用领域和就业形势分析&lt;/h3&gt;
&lt;p&gt;简单的说，Python是一个“优雅”、“明确”、“简单”的编程语言。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;学习曲线低，非专业人士也能上手&lt;/li&gt;
&lt;li&gt;开源系统，拥有强大的生态圈&lt;/li&gt;
&lt;li&gt;解释型语言，完美的平台可移植性&lt;/li&gt;
&lt;li&gt;支持面向对象和函数式编程&lt;/li&gt;
&lt;li&gt;能够通过调用C/C++代码扩展功能&lt;/li&gt;
&lt;li&gt;代码规范程度高，可读性强&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目前几个比较流行的领域，Python都有用武之地。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;云基础设施 - Python / Java / Go&lt;/li&gt;
&lt;li&gt;DevOps - Python / Shell / Ruby / Go&lt;/li&gt;
&lt;li&gt;网络爬虫 - Python / PHP / C++&lt;/li&gt;
&lt;li&gt;数据分析挖掘 - Python / R / Scala / Matlab&lt;/li&gt;
&lt;li&gt;机器学习 - Python / R / Java / Lisp&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作为一名Python开发者，主要的就业领域包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python服务器后台开发 / 游戏服务器开发 / 数据接口开发工程师&lt;/li&gt;
&lt;li&gt;Python自动化运维工程师&lt;/li&gt;
&lt;li&gt;Python数据分析 / 数据可视化 / 大数据工程师&lt;/li&gt;
&lt;li&gt;Python爬虫工程师&lt;/li&gt;
&lt;li&gt;Python聊天机器人开发 / 图像识别和视觉算法 / 深度学习工程师&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图显示了主要城市Python招聘需求量及薪资待遇排行榜（截止到2018年5月）。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-top-10.png"&gt;&lt;img src="./res/python-top-10.png" alt="Python招聘需求及薪资待遇Top 10" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-bj-salary.png"&gt;&lt;img src="./res/python-bj-salary.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-salary-chengdu.png"&gt;&lt;img src="./res/python-salary-chengdu.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;给初学者的几个建议：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make English as your working language.&lt;/li&gt;
&lt;li&gt;Practice makes perfect.&lt;/li&gt;
&lt;li&gt;All experience comes from mistakes.&lt;/li&gt;
&lt;li&gt;Don't be one of the leeches.&lt;/li&gt;
&lt;li&gt;Either stand out or kicked out.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day0115---python语言基础" class="anchor" aria-hidden="true" href="#day0115---python语言基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day01~15 - &lt;a href="./Day01-15"&gt;Python语言基础&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day01---初识python" class="anchor" aria-hidden="true" href="#day01---初识python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day01 - &lt;a href="./Day01-15/01.%E5%88%9D%E8%AF%86Python.md"&gt;初识Python&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Python简介 - Python的历史 / Python的优缺点 / Python的应用领域&lt;/li&gt;
&lt;li&gt;搭建编程环境 - Windows环境 / Linux环境 / MacOS环境&lt;/li&gt;
&lt;li&gt;从终端运行Python程序 - Hello, world / print函数 / 运行程序&lt;/li&gt;
&lt;li&gt;使用IDLE - 交互式环境(REPL) / 编写多行代码 / 运行程序 / 退出IDLE&lt;/li&gt;
&lt;li&gt;注释 - 注释的作用 / 单行注释 / 多行注释&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day02---语言元素" class="anchor" aria-hidden="true" href="#day02---语言元素"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day02 - &lt;a href="./Day01-15/02.%E8%AF%AD%E8%A8%80%E5%85%83%E7%B4%A0.md"&gt;语言元素&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;程序和进制 - 指令和程序 / 冯诺依曼机 / 二进制和十进制 / 八进制和十六进制&lt;/li&gt;
&lt;li&gt;变量和类型 - 变量的命名 / 变量的使用 / input函数 / 检查变量类型 / 类型转换&lt;/li&gt;
&lt;li&gt;数字和字符串 - 整数 / 浮点数 / 复数 / 字符串 / 字符串基本操作 / 字符编码&lt;/li&gt;
&lt;li&gt;运算符 - 数学运算符 / 赋值运算符 / 比较运算符 / 逻辑运算符 / 身份运算符 / 运算符的优先级&lt;/li&gt;
&lt;li&gt;应用案例 - 华氏温度转换成摄氏温度 / 输入圆的半径计算周长和面积 / 输入年份判断是否是闰年&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day03---分支结构" class="anchor" aria-hidden="true" href="#day03---分支结构"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day03 - &lt;a href="./Day01-15/03.%E5%88%86%E6%94%AF%E7%BB%93%E6%9E%84.md"&gt;分支结构&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;分支结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图&lt;/li&gt;
&lt;li&gt;if语句 - 简单的if / if-else结构 / if-elif-else结构 / 嵌套的if&lt;/li&gt;
&lt;li&gt;应用案例 - 用户身份验证 / 英制单位与公制单位互换 / 掷骰子决定做什么 / 百分制成绩转等级制 / 分段函数求值 / 输入三条边的长度如果能构成三角形就计算周长和面积&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day04---循环结构" class="anchor" aria-hidden="true" href="#day04---循环结构"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day04 - &lt;a href="./Day01-15/04.%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84.md"&gt;循环结构&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;循环结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图&lt;/li&gt;
&lt;li&gt;while循环 - 基本结构 / break语句 / continue语句&lt;/li&gt;
&lt;li&gt;for循环 - 基本结构 / range类型 / 循环中的分支结构 / 嵌套的循环 / 提前结束程序&lt;/li&gt;
&lt;li&gt;应用案例 - 1~100求和 / 判断素数 / 猜数字游戏 / 打印九九表 / 打印三角形图案 / 猴子吃桃 / 百钱百鸡&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day05---构造程序逻辑" class="anchor" aria-hidden="true" href="#day05---构造程序逻辑"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day05 - &lt;a href="./Day01-15/05.%E6%9E%84%E9%80%A0%E7%A8%8B%E5%BA%8F%E9%80%BB%E8%BE%91.md"&gt;构造程序逻辑&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;经典案例：水仙花数 / 百钱百鸡 / Craps赌博游戏&lt;/li&gt;
&lt;li&gt;练习题目：斐波那契数列 / 完美数 / 素数&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day06---函数和模块的使用" class="anchor" aria-hidden="true" href="#day06---函数和模块的使用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day06 - &lt;a href="./Day01-15/06.%E5%87%BD%E6%95%B0%E5%92%8C%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8.md"&gt;函数和模块的使用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;函数的作用 - 代码的坏味道 / 用函数封装功能模块&lt;/li&gt;
&lt;li&gt;定义函数 - def语句 / 函数名 / 参数列表 / return语句 / 调用自定义函数&lt;/li&gt;
&lt;li&gt;调用函数 - Python内置函数 /  导入模块和函数&lt;/li&gt;
&lt;li&gt;函数的参数 - 默认参数 / 可变参数 / 关键字参数 / 命名关键字参数&lt;/li&gt;
&lt;li&gt;函数的返回值 - 没有返回值  / 返回单个值 / 返回多个值&lt;/li&gt;
&lt;li&gt;作用域问题 - 局部作用域 / 嵌套作用域 / 全局作用域 / 内置作用域 / 和作用域相关的关键字&lt;/li&gt;
&lt;li&gt;用模块管理函数 - 模块的概念 / 用自定义模块管理函数 / 命名冲突的时候会怎样（同一个模块和不同的模块）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day07---字符串和常用数据结构" class="anchor" aria-hidden="true" href="#day07---字符串和常用数据结构"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day07 - &lt;a href="./Day01-15/07.%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.md"&gt;字符串和常用数据结构&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;字符串的使用 - 计算长度 / 下标运算 / 切片 / 常用方法&lt;/li&gt;
&lt;li&gt;列表基本用法 - 定义列表 / 用下表访问元素 / 下标越界 / 添加元素 / 删除元素 / 修改元素 / 切片 / 循环遍历&lt;/li&gt;
&lt;li&gt;列表常用操作 - 连接 / 复制(复制元素和复制数组) / 长度 / 排序 / 倒转 / 查找&lt;/li&gt;
&lt;li&gt;生成列表 - 使用range创建数字列表 / 生成表达式 / 生成器&lt;/li&gt;
&lt;li&gt;元组的使用 - 定义元组 / 使用元组中的值 / 修改元组变量 / 元组和列表转换&lt;/li&gt;
&lt;li&gt;集合基本用法 - 集合和列表的区别 /  创建集合 / 添加元素 / 删除元素 /  清空&lt;/li&gt;
&lt;li&gt;集合常用操作 - 交集 / 并集 / 差集 / 对称差 / 子集 / 超集&lt;/li&gt;
&lt;li&gt;字典的基本用法 - 字典的特点 / 创建字典 / 添加元素 / 删除元素 / 取值 / 清空&lt;/li&gt;
&lt;li&gt;字典常用操作 - keys()方法 / values()方法 / items()方法 / setdefault()方法&lt;/li&gt;
&lt;li&gt;基础练习 - 跑马灯效果 / 列表找最大元素 / 统计考试成绩的平均分 / Fibonacci数列 / 杨辉三角&lt;/li&gt;
&lt;li&gt;综合案例 - 双色球选号 / 井字棋&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day08---面向对象编程基础" class="anchor" aria-hidden="true" href="#day08---面向对象编程基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day08 - &lt;a href="./Day01-15/08.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80.md"&gt;面向对象编程基础&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;类和对象 - 什么是类 / 什么是对象 / 面向对象其他相关概念&lt;/li&gt;
&lt;li&gt;定义类 - 基本结构 / 属性和方法 / 构造器 / 析构器 / __str__方法&lt;/li&gt;
&lt;li&gt;使用对象 - 创建对象 / 给对象发消息&lt;/li&gt;
&lt;li&gt;面向对象的四大支柱 - 抽象 / 封装 / 继承 / 多态&lt;/li&gt;
&lt;li&gt;基础练习 - 定义学生类 / 定义时钟类 / 定义图形类 / 定义汽车类&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day09---面向对象进阶" class="anchor" aria-hidden="true" href="#day09---面向对象进阶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day09 - &lt;a href="./Day01-15/09.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%BF%9B%E9%98%B6.md"&gt;面向对象进阶&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;属性 - 类属性 / 实例属性 / 属性访问器 / 属性修改器 / 属性删除器 / 使用__slots__&lt;/li&gt;
&lt;li&gt;类中的方法 - 实例方法 / 类方法 / 静态方法&lt;/li&gt;
&lt;li&gt;运算符重载 - __add__ / __sub__ / __or__ /__getitem__ / __setitem__ / __len__ / __repr__ / __gt__ / __lt__ / __le__ / __ge__ / __eq__ / __ne__ / __contains__&lt;/li&gt;
&lt;li&gt;类(的对象)之间的关系 - 关联 / 继承 / 依赖&lt;/li&gt;
&lt;li&gt;继承和多态 - 什么是继承 / 继承的语法 / 调用父类方法 / 方法重写 / 类型判定 / 多重继承 / 菱形继承(钻石继承)和C3算法&lt;/li&gt;
&lt;li&gt;综合案例 - 工资结算系统 / 图书自动折扣系统 / 自定义分数类&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day10---图形用户界面和游戏开发" class="anchor" aria-hidden="true" href="#day10---图形用户界面和游戏开发"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day10 - &lt;a href="./Day01-15/10.%E5%9B%BE%E5%BD%A2%E7%94%A8%E6%88%B7%E7%95%8C%E9%9D%A2%E5%92%8C%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91.md"&gt;图形用户界面和游戏开发&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;使用tkinter开发GUI程序&lt;/li&gt;
&lt;li&gt;使用pygame三方库开发游戏应用&lt;/li&gt;
&lt;li&gt;“大球吃小球”游戏&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day11---文件和异常" class="anchor" aria-hidden="true" href="#day11---文件和异常"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day11 - &lt;a href="./Day01-15/11.%E6%96%87%E4%BB%B6%E5%92%8C%E5%BC%82%E5%B8%B8.md"&gt;文件和异常&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;读文件 - 读取整个文件 / 逐行读取 / 文件路径&lt;/li&gt;
&lt;li&gt;写文件 - 覆盖写入 / 追加写入 / 文本文件 / 二进制文件&lt;/li&gt;
&lt;li&gt;异常处理 - 异常机制的重要性 / try-except代码块 / else代码块 / finally代码块 / 内置异常类型 / 异常栈 / raise语句&lt;/li&gt;
&lt;li&gt;数据持久化 - CSV文件概述 / csv模块的应用 / JSON数据格式 / json模块的应用&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day12---字符串和正则表达式" class="anchor" aria-hidden="true" href="#day12---字符串和正则表达式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day12 - &lt;a href="./Day01-15/12.%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F.md"&gt;字符串和正则表达式&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;字符串高级操作 - 转义字符 / 原始字符串 / 多行字符串 / in和 not in运算符 / is开头的方法 / join和split方法 / strip相关方法 / pyperclip模块 / 不变字符串和可变字符串 / StringIO的使用&lt;/li&gt;
&lt;li&gt;正则表达式入门 - 正则表达式的作用 / 元字符 / 转义 / 量词 / 分组 / 零宽断言 /贪婪匹配与惰性匹配懒惰 / 使用re模块实现正则表达式操作（匹配、搜索、替换、捕获）&lt;/li&gt;
&lt;li&gt;使用正则表达式 - re模块 / compile函数 / group和groups方法 / match方法 / search方法 / findall和finditer方法 / sub和subn方法 / split方法&lt;/li&gt;
&lt;li&gt;应用案例 - 使用正则表达式验证输入的字符串&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day13---进程和线程" class="anchor" aria-hidden="true" href="#day13---进程和线程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day13 - &lt;a href="./Day01-15/13.%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B.md"&gt;进程和线程&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;进程和线程的概念 - 什么是进程 / 什么是线程 / 多线程的应用场景&lt;/li&gt;
&lt;li&gt;使用进程 - fork函数 / multiprocessing模块 / 进程池 / 进程间通信&lt;/li&gt;
&lt;li&gt;使用线程 - thread模块 / threading模块 / Thread类 / Lock类 / Condition类 / 线程池&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day14---网络编程入门和网络应用开发" class="anchor" aria-hidden="true" href="#day14---网络编程入门和网络应用开发"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day14 - &lt;a href="./Day01-15/14.%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91.md"&gt;网络编程入门和网络应用开发&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;计算机网络基础 - 计算机网络发展史 / “TCP-IP”模型 / IP地址 / 端口 / 协议 / 其他相关概念&lt;/li&gt;
&lt;li&gt;网络应用模式 - “客户端-服务器”模式 / “浏览器-服务器”模式&lt;/li&gt;
&lt;li&gt;基于HTTP协议访问网络资源 - 网络API概述 / 访问URL / requests模块 / 解析JSON格式数据&lt;/li&gt;
&lt;li&gt;Python网络编程 - 套接字的概念 / socket模块 /  socket函数 / 创建TCP服务器 / 创建TCP客户端 / 创建UDP服务器 / 创建UDP客户端 / SocketServer模块&lt;/li&gt;
&lt;li&gt;电子邮件 - SMTP协议 / POP3协议 / IMAP协议 / smtplib模块 / poplib模块 / imaplib模块&lt;/li&gt;
&lt;li&gt;短信服务 - 调用短信服务网关&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day15---图像和文档处理" class="anchor" aria-hidden="true" href="#day15---图像和文档处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day15 - &lt;a href="./Day01-15/15.%E5%9B%BE%E5%83%8F%E5%92%8C%E5%8A%9E%E5%85%AC%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86.md"&gt;图像和文档处理&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;用Pillow处理图片 - 图片读写 / 图片合成 / 几何变换 / 色彩转换 / 滤镜效果&lt;/li&gt;
&lt;li&gt;读写Word文档 - 文本内容的处理 / 段落 / 页眉和页脚 / 样式的处理&lt;/li&gt;
&lt;li&gt;读写Excel文件 - xlrd模块 / xlwt模块&lt;/li&gt;
&lt;li&gt;生成PDF文件 - pypdf2模块 / reportlab模块&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day16day20---python语言进阶-" class="anchor" aria-hidden="true" href="#day16day20---python语言进阶-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day16~Day20 - &lt;a href="./Day16-20/16-20.Python%E8%AF%AD%E8%A8%80%E8%BF%9B%E9%98%B6.md"&gt;Python语言进阶 &lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;常用数据结构&lt;/li&gt;
&lt;li&gt;函数的高级用法 - “一等公民” / 高阶函数 / Lambda函数 / 作用域和闭包 / 装饰器&lt;/li&gt;
&lt;li&gt;面向对象高级知识 - “三大支柱” / 类与类之间的关系 / 垃圾回收 / 魔术属性和方法 / 混入 / 元类 / 面向对象设计原则 / GoF设计模式&lt;/li&gt;
&lt;li&gt;迭代器和生成器 - 相关魔术方法 / 创建生成器的两种方式 /&lt;/li&gt;
&lt;li&gt;并发和异步编程 - 多线程 / 多进程 / 异步IO / async和await&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day2130---web前端入门" class="anchor" aria-hidden="true" href="#day2130---web前端入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day21~30 - &lt;a href="./Day21-30/21-30.Web%E5%89%8D%E7%AB%AF%E6%A6%82%E8%BF%B0.md"&gt;Web前端入门&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用HTML标签承载页面内容&lt;/li&gt;
&lt;li&gt;用CSS渲染页面&lt;/li&gt;
&lt;li&gt;用JavaScript处理交互式行为&lt;/li&gt;
&lt;li&gt;jQuery入门和提高&lt;/li&gt;
&lt;li&gt;Vue.js入门&lt;/li&gt;
&lt;li&gt;Element的使用&lt;/li&gt;
&lt;li&gt;Bootstrap的使用&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day3135---玩转linux操作系统" class="anchor" aria-hidden="true" href="#day3135---玩转linux操作系统"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day31~35 - &lt;a href="./Day31-35/31-35.%E7%8E%A9%E8%BD%ACLinux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.md"&gt;玩转Linux操作系统&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;操作系统发展史和Linux概述&lt;/li&gt;
&lt;li&gt;Linux基础命令&lt;/li&gt;
&lt;li&gt;Linux中的实用程序&lt;/li&gt;
&lt;li&gt;Linux的文件系统&lt;/li&gt;
&lt;li&gt;Vim编辑器的应用&lt;/li&gt;
&lt;li&gt;环境变量和Shell编程&lt;/li&gt;
&lt;li&gt;软件的安装和服务的配置&lt;/li&gt;
&lt;li&gt;网络访问和管理&lt;/li&gt;
&lt;li&gt;其他相关内容&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day3640---数据库基础和进阶" class="anchor" aria-hidden="true" href="#day3640---数据库基础和进阶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day36~40 - &lt;a href="./Day36-40"&gt;数据库基础和进阶&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="./Day36-40/36-38.%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93MySQL.md"&gt;关系型数据库MySQL&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;关系型数据库概述&lt;/li&gt;
&lt;li&gt;MySQL的安装和使用&lt;/li&gt;
&lt;li&gt;SQL的使用
&lt;ul&gt;
&lt;li&gt;DDL - 数据定义语言 - create / drop / alter&lt;/li&gt;
&lt;li&gt;DML - 数据操作语言 - insert / delete / update / select&lt;/li&gt;
&lt;li&gt;DCL - 数据控制语言 - grant / revoke&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;相关知识
&lt;ul&gt;
&lt;li&gt;范式理论 - 设计二维表的指导思想&lt;/li&gt;
&lt;li&gt;数据完整性&lt;/li&gt;
&lt;li&gt;数据一致性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在Python中操作MySQL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="./Day36-40/39-40.NoSQL%E5%85%A5%E9%97%A8.md"&gt;NoSQL入门&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;NoSQL概述&lt;/li&gt;
&lt;li&gt;Redis概述&lt;/li&gt;
&lt;li&gt;Mongo概述&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day4155---实战django" class="anchor" aria-hidden="true" href="#day4155---实战django"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day41~55 - &lt;a href="./Day41-55"&gt;实战Django&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day41---快速上手" class="anchor" aria-hidden="true" href="#day41---快速上手"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day41 - &lt;a href="./Day41-55/41.%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B.md"&gt;快速上手&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Web应用工作原理和HTTP协议&lt;/li&gt;
&lt;li&gt;Django框架概述&lt;/li&gt;
&lt;li&gt;5分钟快速上手&lt;/li&gt;
&lt;li&gt;使用视图模板&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day42---深入模型" class="anchor" aria-hidden="true" href="#day42---深入模型"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day42 - &lt;a href="./Day41-55/42.%E6%B7%B1%E5%85%A5%E6%A8%A1%E5%9E%8B.md"&gt;深入模型&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;关系型数据库配置&lt;/li&gt;
&lt;li&gt;管理后台的使用&lt;/li&gt;
&lt;li&gt;使用ORM完成对模型的CRUD操作&lt;/li&gt;
&lt;li&gt;Django模型最佳实践&lt;/li&gt;
&lt;li&gt;模型定义参考&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day43---静态资源和ajax请求" class="anchor" aria-hidden="true" href="#day43---静态资源和ajax请求"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day43 - &lt;a href="./Day41-55/43.%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E5%92%8CAjax%E8%AF%B7%E6%B1%82.md"&gt;静态资源和Ajax请求&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;加载静态资源&lt;/li&gt;
&lt;li&gt;用Ajax请求获取数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day44---表单的应用" class="anchor" aria-hidden="true" href="#day44---表单的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day44 - &lt;a href="./Day41-55/44.%E8%A1%A8%E5%8D%95%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;表单的应用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;表单和表单控件&lt;/li&gt;
&lt;li&gt;跨站请求伪造和CSRF令牌&lt;/li&gt;
&lt;li&gt;Form和ModelForm&lt;/li&gt;
&lt;li&gt;表单验证&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day45---cookie和session" class="anchor" aria-hidden="true" href="#day45---cookie和session"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day45 - &lt;a href="./Day41-55/45.Cookie%E5%92%8CSession.md"&gt;Cookie和Session&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;实现用户跟踪&lt;/li&gt;
&lt;li&gt;cookie和session的关系&lt;/li&gt;
&lt;li&gt;Django框架对session的支持&lt;/li&gt;
&lt;li&gt;视图函数中的cookie读写操作&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day46---报表和日志" class="anchor" aria-hidden="true" href="#day46---报表和日志"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day46 - &lt;a href="./Day41-55/46.%E6%8A%A5%E8%A1%A8%E5%92%8C%E6%97%A5%E5%BF%97.md"&gt;报表和日志&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;通过HttpResponse修改响应头&lt;/li&gt;
&lt;li&gt;使用StreamingHttpResponse处理大文件&lt;/li&gt;
&lt;li&gt;使用xlwt生成Excel报表&lt;/li&gt;
&lt;li&gt;使用reportlab生成PDF报表&lt;/li&gt;
&lt;li&gt;使用ECharts生成前端图表&lt;/li&gt;
&lt;li&gt;配置日志和Django-Debug-Toolbar&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day47---中间件的应用" class="anchor" aria-hidden="true" href="#day47---中间件的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day47 - &lt;a href="./Day41-55/47.%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;中间件的应用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;什么是中间件&lt;/li&gt;
&lt;li&gt;Django框架内置的中间件&lt;/li&gt;
&lt;li&gt;自定义中间件及其应用场景&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day48---前后端分离开发入门" class="anchor" aria-hidden="true" href="#day48---前后端分离开发入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day48 - &lt;a href="./Day41-55/48.%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%BC%80%E5%8F%91%E5%85%A5%E9%97%A8.md"&gt;前后端分离开发入门&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;返回JSON格式的数据&lt;/li&gt;
&lt;li&gt;用Vue.js渲染页面&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day49---restful架构和drf入门" class="anchor" aria-hidden="true" href="#day49---restful架构和drf入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day49 - &lt;a href="./Day41-55/49.RESTful%E6%9E%B6%E6%9E%84%E5%92%8CDRF%E5%85%A5%E9%97%A8.md"&gt;RESTful架构和DRF入门&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day50---restful架构和drf进阶" class="anchor" aria-hidden="true" href="#day50---restful架构和drf进阶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day50 - &lt;a href="./Day41-55/50.RESTful%E6%9E%B6%E6%9E%84%E5%92%8CDRF%E8%BF%9B%E9%98%B6.md"&gt;RESTful架构和DRF进阶&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day51---使用缓存" class="anchor" aria-hidden="true" href="#day51---使用缓存"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day51 - &lt;a href="./Day41-55/51.%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98.md"&gt;使用缓存&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;网站优化第一定律&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在Django项目中使用Redis提供缓存服务&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在视图函数中读写缓存&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用装饰器实现页面缓存&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为数据接口提供缓存服务&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day52---文件上传和富文本编辑" class="anchor" aria-hidden="true" href="#day52---文件上传和富文本编辑"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day52 - &lt;a href="./Day41-55/52.%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%92%8C%E5%AF%8C%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8.md"&gt;文件上传和富文本编辑&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;文件上传表单控件和图片文件预览&lt;/li&gt;
&lt;li&gt;服务器端如何处理上传的文件&lt;/li&gt;
&lt;li&gt;富文本编辑器概述&lt;/li&gt;
&lt;li&gt;wangEditor的使用&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day53---短信和邮件" class="anchor" aria-hidden="true" href="#day53---短信和邮件"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day53 - &lt;a href="./Day41-55/53.%E7%9F%AD%E4%BF%A1%E5%92%8C%E9%82%AE%E4%BB%B6.md"&gt;短信和邮件&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;常用短信网关平台介绍&lt;/li&gt;
&lt;li&gt;使用螺丝帽发送短信&lt;/li&gt;
&lt;li&gt;Django框架对邮件服务的支持&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day54---异步任务和定时任务" class="anchor" aria-hidden="true" href="#day54---异步任务和定时任务"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day54 - &lt;a href="./Day41-55/54.%E5%BC%82%E6%AD%A5%E4%BB%BB%E5%8A%A1%E5%92%8C%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1.md"&gt;异步任务和定时任务&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;网站优化第二定律&lt;/li&gt;
&lt;li&gt;配置消息队列服务&lt;/li&gt;
&lt;li&gt;在项目中使用celery实现任务异步化&lt;/li&gt;
&lt;li&gt;在项目中使用celery实现定时任务&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day55---单元测试和项目上线" class="anchor" aria-hidden="true" href="#day55---单元测试和项目上线"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day55 - &lt;a href="./Day41-55/55.%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E5%92%8C%E9%A1%B9%E7%9B%AE%E4%B8%8A%E7%BA%BF.md"&gt;单元测试和项目上线&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Python中的单元测试&lt;/li&gt;
&lt;li&gt;Django框架对单元测试的支持&lt;/li&gt;
&lt;li&gt;使用版本控制系统&lt;/li&gt;
&lt;li&gt;配置和使用uWSGI&lt;/li&gt;
&lt;li&gt;动静分离和Nginx配置&lt;/li&gt;
&lt;li&gt;配置HTTPS&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day5660---实战flask" class="anchor" aria-hidden="true" href="#day5660---实战flask"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day56~60 - &lt;a href="./Day56-65"&gt;实战Flask&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day56---flask入门" class="anchor" aria-hidden="true" href="#day56---flask入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day56 - &lt;a href="./Day56-60/56.Flask%E5%85%A5%E9%97%A8.md"&gt;Flask入门&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day57---模板的使用" class="anchor" aria-hidden="true" href="#day57---模板的使用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day57 - &lt;a href="./Day56-60/57.%E6%A8%A1%E6%9D%BF%E7%9A%84%E4%BD%BF%E7%94%A8.md"&gt;模板的使用&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day58---表单的处理" class="anchor" aria-hidden="true" href="#day58---表单的处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day58 - &lt;a href="./Day56-60/58.%E8%A1%A8%E5%8D%95%E7%9A%84%E5%A4%84%E7%90%86.md"&gt;表单的处理&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day59---数据库操作" class="anchor" aria-hidden="true" href="#day59---数据库操作"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day59 - &lt;a href="./Day56-60/59.%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C.md"&gt;数据库操作&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day60---项目实战" class="anchor" aria-hidden="true" href="#day60---项目实战"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day60 - &lt;a href="./Day56-60/60.%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.md"&gt;项目实战&lt;/a&gt;&lt;/h4&gt;
&lt;h3&gt;&lt;a id="user-content-day6165---实战tornado" class="anchor" aria-hidden="true" href="#day6165---实战tornado"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day61~65 - &lt;a href="./Day61-65"&gt;实战Tornado&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day61---预备知识" class="anchor" aria-hidden="true" href="#day61---预备知识"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day61 - &lt;a href="./Day61-65/61.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86.md"&gt;预备知识&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;并发编程&lt;/li&gt;
&lt;li&gt;I/O模式和事件驱动&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day62---tornado入门" class="anchor" aria-hidden="true" href="#day62---tornado入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day62 - &lt;a href="./Day61-65/62.Tornado%E5%85%A5%E9%97%A8.md"&gt;Tornado入门&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Tornado概述&lt;/li&gt;
&lt;li&gt;5分钟上手Tornado&lt;/li&gt;
&lt;li&gt;路由解析&lt;/li&gt;
&lt;li&gt;请求处理器&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day63---异步化" class="anchor" aria-hidden="true" href="#day63---异步化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day63 - &lt;a href="./Day61-65/63.%E5%BC%82%E6%AD%A5%E5%8C%96.md"&gt;异步化&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;aiomysql和aioredis的使用&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day64---websocket的应用" class="anchor" aria-hidden="true" href="#day64---websocket的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day64 - &lt;a href="./Day61-65/64.WebSocket%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;WebSocket的应用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;WebSocket简介&lt;/li&gt;
&lt;li&gt;WebSocket服务器端编程&lt;/li&gt;
&lt;li&gt;WebSocket客户端编程&lt;/li&gt;
&lt;li&gt;项目：Web聊天室&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day65---项目实战" class="anchor" aria-hidden="true" href="#day65---项目实战"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day65 - &lt;a href="./Day61-65/65.%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.md"&gt;项目实战&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;前后端分离开发和接口文档的撰写&lt;/li&gt;
&lt;li&gt;使用Vue.js实现前端渲染&lt;/li&gt;
&lt;li&gt;使用ECharts实现报表功能&lt;/li&gt;
&lt;li&gt;使用WebSocket实现推送服务&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day6675---爬虫开发" class="anchor" aria-hidden="true" href="#day6675---爬虫开发"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day66~75 - &lt;a href="./Day66-75"&gt;爬虫开发&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day66---网络爬虫和相关工具" class="anchor" aria-hidden="true" href="#day66---网络爬虫和相关工具"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day66 - &lt;a href="./Day66-75/66.%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%92%8C%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7.md"&gt;网络爬虫和相关工具&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;网络爬虫的概念及其应用领域&lt;/li&gt;
&lt;li&gt;网络爬虫的合法性探讨&lt;/li&gt;
&lt;li&gt;开发网络爬虫的相关工具&lt;/li&gt;
&lt;li&gt;一个爬虫程序的构成&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day67---数据采集和解析" class="anchor" aria-hidden="true" href="#day67---数据采集和解析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day67 - &lt;a href="./Day66-75/67.%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%92%8C%E8%A7%A3%E6%9E%90.md"&gt;数据采集和解析&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;数据采集的标准和三方库&lt;/li&gt;
&lt;li&gt;页面解析的三种方式：正则表达式解析 / XPath解析 / CSS选择器解析&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day68---存储数据" class="anchor" aria-hidden="true" href="#day68---存储数据"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day68 - &lt;a href="./Day66-75/68.%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE.md"&gt;存储数据&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;如何存储海量数据&lt;/li&gt;
&lt;li&gt;实现数据的缓存&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day69---并发下载" class="anchor" aria-hidden="true" href="#day69---并发下载"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day69 - &lt;a href="./Day66-75/69.%E5%B9%B6%E5%8F%91%E4%B8%8B%E8%BD%BD.md"&gt;并发下载&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;多线程和多进程&lt;/li&gt;
&lt;li&gt;异步I/O和协程&lt;/li&gt;
&lt;li&gt;async和await关键字的使用&lt;/li&gt;
&lt;li&gt;三方库aiohttp的应用&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day70---解析动态内容" class="anchor" aria-hidden="true" href="#day70---解析动态内容"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day70 - &lt;a href="./Day66-75/70.%E8%A7%A3%E6%9E%90%E5%8A%A8%E6%80%81%E5%86%85%E5%AE%B9.md"&gt;解析动态内容&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;JavaScript逆向工程&lt;/li&gt;
&lt;li&gt;使用Selenium获取动态内容&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day71---表单交互和验证码处理" class="anchor" aria-hidden="true" href="#day71---表单交互和验证码处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day71 - &lt;a href="./Day66-75/71.%E8%A1%A8%E5%8D%95%E4%BA%A4%E4%BA%92%E5%92%8C%E9%AA%8C%E8%AF%81%E7%A0%81%E5%A4%84%E7%90%86.md"&gt;表单交互和验证码处理&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;自动提交表单&lt;/li&gt;
&lt;li&gt;Cookie池的应用&lt;/li&gt;
&lt;li&gt;验证码处理&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day72---scrapy入门" class="anchor" aria-hidden="true" href="#day72---scrapy入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day72 - &lt;a href="./Day66-75/72.Scrapy%E5%85%A5%E9%97%A8.md"&gt;Scrapy入门&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Scrapy爬虫框架概述&lt;/li&gt;
&lt;li&gt;安装和使用Scrapy&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day73---scrapy高级应用" class="anchor" aria-hidden="true" href="#day73---scrapy高级应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day73 - &lt;a href="./Day66-75/73.Scrapy%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8.md"&gt;Scrapy高级应用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Spider的用法&lt;/li&gt;
&lt;li&gt;中间件的应用：下载中间件 / 蜘蛛中间件&lt;/li&gt;
&lt;li&gt;Scrapy对接Selenium抓取动态内容&lt;/li&gt;
&lt;li&gt;Scrapy部署到Docker&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day74---scrapy分布式实现" class="anchor" aria-hidden="true" href="#day74---scrapy分布式实现"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day74 - &lt;a href="./Day66-75/74.Scrapy%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E7%8E%B0.md"&gt;Scrapy分布式实现&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;分布式爬虫的原理&lt;/li&gt;
&lt;li&gt;Scrapy分布式实现&lt;/li&gt;
&lt;li&gt;使用Scrapyd实现分布式部署&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day75---爬虫项目实战" class="anchor" aria-hidden="true" href="#day75---爬虫项目实战"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day75 - &lt;a href="./Day66-75/75.%E7%88%AC%E8%99%AB%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.md"&gt;爬虫项目实战&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;爬取招聘网站数据&lt;/li&gt;
&lt;li&gt;爬取房地产行业数据&lt;/li&gt;
&lt;li&gt;爬取二手车交易平台数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day7690---数据处理和机器学习" class="anchor" aria-hidden="true" href="#day7690---数据处理和机器学习"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day76~90 - &lt;a href="./Day76-90"&gt;数据处理和机器学习&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day76---机器学习基础" class="anchor" aria-hidden="true" href="#day76---机器学习基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day76 - &lt;a href="./Day76-90/76.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md"&gt;机器学习基础&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day77---pandas的应用" class="anchor" aria-hidden="true" href="#day77---pandas的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day77 - &lt;a href="./Day76-90/77.Pandas%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;Pandas的应用&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day78---numpy和scipy的应用" class="anchor" aria-hidden="true" href="#day78---numpy和scipy的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day78 - &lt;a href="./Day76-90/78.NumPy%E5%92%8CSciPy%E7%9A%84%E5%BA%94%E7%94%A8"&gt;NumPy和SciPy的应用&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day79---matplotlib和数据可视化" class="anchor" aria-hidden="true" href="#day79---matplotlib和数据可视化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day79 - &lt;a href="./Day76-90/79.Matplotlib%E5%92%8C%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96"&gt;Matplotlib和数据可视化&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day80---k最近邻knn分类" class="anchor" aria-hidden="true" href="#day80---k最近邻knn分类"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day80 - &lt;a href="./Day76-90/80.k%E6%9C%80%E8%BF%91%E9%82%BB%E5%88%86%E7%B1%BB.md"&gt;k最近邻(KNN)分类&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day81---决策树" class="anchor" aria-hidden="true" href="#day81---决策树"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day81 - &lt;a href="./Day76-90/81.%E5%86%B3%E7%AD%96%E6%A0%91.md"&gt;决策树&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day82---贝叶斯分类" class="anchor" aria-hidden="true" href="#day82---贝叶斯分类"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day82 - &lt;a href="./Day76-90/82.%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB.md"&gt;贝叶斯分类&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day83---支持向量机svm" class="anchor" aria-hidden="true" href="#day83---支持向量机svm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day83 - &lt;a href="./Day76-90/83.%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.md"&gt;支持向量机(SVM)&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day84---k-均值聚类" class="anchor" aria-hidden="true" href="#day84---k-均值聚类"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day84 - &lt;a href="./Day76-90/84.K-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB.md"&gt;K-均值聚类&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day85---回归分析" class="anchor" aria-hidden="true" href="#day85---回归分析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day85 - &lt;a href="./Day76-90/85.%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90.md"&gt;回归分析&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day86---大数据分析入门" class="anchor" aria-hidden="true" href="#day86---大数据分析入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day86 - &lt;a href="./Day76-90/86.%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%85%A5%E9%97%A8.md"&gt;大数据分析入门&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day87---大数据分析进阶" class="anchor" aria-hidden="true" href="#day87---大数据分析进阶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day87 - &lt;a href="./Day76-90/87.%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%BF%9B%E9%98%B6.md"&gt;大数据分析进阶&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day88---tensorflow入门" class="anchor" aria-hidden="true" href="#day88---tensorflow入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day88 - &lt;a href="./Day76-90/88.Tensorflow%E5%85%A5%E9%97%A8.md"&gt;Tensorflow入门&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day89---tensorflow实战" class="anchor" aria-hidden="true" href="#day89---tensorflow实战"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day89 - &lt;a href="./Day76-90/89.Tensorflow%E5%AE%9E%E6%88%98.md"&gt;Tensorflow实战&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day90---推荐系统" class="anchor" aria-hidden="true" href="#day90---推荐系统"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day90 - &lt;a href="./Day76-90/90.%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.md"&gt;推荐系统&lt;/a&gt;&lt;/h4&gt;
&lt;h3&gt;&lt;a id="user-content-day91100---团队项目开发" class="anchor" aria-hidden="true" href="#day91100---团队项目开发"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day91~100 - &lt;a href="./Day91-100"&gt;团队项目开发&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-第91天团队项目开发的问题和解决方案" class="anchor" aria-hidden="true" href="#第91天团队项目开发的问题和解决方案"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第91天：&lt;a href="./Day91-100/91.%E5%9B%A2%E9%98%9F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md"&gt;团队项目开发的问题和解决方案&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;软件过程模型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;经典过程模型（瀑布模型）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可行性分析（研究做还是不做），输出《可行性分析报告》。&lt;/li&gt;
&lt;li&gt;需求分析（研究做什么），输出《需求规格说明书》和产品界面原型图。&lt;/li&gt;
&lt;li&gt;概要设计和详细设计，输出概念模型图（ER图）、物理模型图、类图、时序图等。&lt;/li&gt;
&lt;li&gt;编码 / 测试。&lt;/li&gt;
&lt;li&gt;上线 / 维护。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;瀑布模型最大的缺点是无法拥抱需求变化，整套流程结束后才能看到产品，团队士气低落。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;敏捷开发（Scrum）- 产品所有者、Scrum Master、研发人员 - Sprint&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;产品的Backlog（用户故事、产品原型）。&lt;/li&gt;
&lt;li&gt;计划会议（评估和预算）。&lt;/li&gt;
&lt;li&gt;日常开发（站立会议、番茄工作法、结对编程、测试先行、代码重构……）。&lt;/li&gt;
&lt;li&gt;修复bug（问题描述、重现步骤、测试人员、被指派人）。&lt;/li&gt;
&lt;li&gt;发布版本。&lt;/li&gt;
&lt;li&gt;评审会议（Showcase，用户需要参与）。&lt;/li&gt;
&lt;li&gt;回顾会议（对当前迭代周期做一个总结）。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;补充：敏捷软件开发宣言&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;个体和互动&lt;/strong&gt; 高于 流程和工具&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;工作的软件&lt;/strong&gt; 高于 详尽的文档&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;客户合作&lt;/strong&gt; 高于 合同谈判&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;响应变化&lt;/strong&gt; 高于 遵循计划&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/agile-scrum-sprint-cycle.png"&gt;&lt;img src="./res/agile-scrum-sprint-cycle.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;角色：产品所有者（决定做什么，能对需求拍板的人）、团队负责人（解决各种问题，专注如何更好的工作，屏蔽外部对开发团队的影响）、开发团队（项目执行人员，具体指开发人员和测试人员）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;准备工作：商业案例和资金、合同、憧憬、初始产品需求、初始发布计划、入股、组建团队。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;敏捷团队通常人数为8-10人。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;工作量估算：将开发任务量化，包括原型、Logo设计、UI设计、前端开发等，尽量把每个工作分解到最小任务量，最小任务量标准为工作时间不能超过两天，然后估算总体项目时间。把每个任务都贴在看板上面，看板上分三部分：to do（待完成）、in progress（进行中）和done（已完成）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;项目团队组建&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;团队的构成和角色&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;说明：谢谢付祥英女士绘制了下面这张精美的公司组织架构图。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/company_architecture.png"&gt;&lt;img src="./res/company_architecture.png" alt="company_architecture" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;编程规范和代码审查（flake8、pylint）&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/pylint.png"&gt;&lt;img src="./res/pylint.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Python中的一些“惯例”（请参考&lt;a href="Python%E6%83%AF%E4%BE%8B.md"&gt;《Python惯例-如何编写Pythonic的代码》&lt;/a&gt;）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;影响代码可读性的原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;代码注释太少或者没有注释&lt;/li&gt;
&lt;li&gt;代码破坏了语言的最佳实践&lt;/li&gt;
&lt;li&gt;反模式编程（意大利面代码、复制-黏贴编程、自负编程、……）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;团队开发工具介绍&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;版本控制：Git、Mercury&lt;/li&gt;
&lt;li&gt;缺陷管理：&lt;a href="https://about.gitlab.com/" rel="nofollow"&gt;Gitlab&lt;/a&gt;、&lt;a href="http://www.redmine.org.cn/" rel="nofollow"&gt;Redmine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;敏捷闭环工具：&lt;a href="https://www.zentao.net/" rel="nofollow"&gt;禅道&lt;/a&gt;、&lt;a href="https://www.atlassian.com/software/jira/features" rel="nofollow"&gt;JIRA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;持续集成：&lt;a href="https://jenkins.io/" rel="nofollow"&gt;Jenkins&lt;/a&gt;、&lt;a href="https://travis-ci.org/" rel="nofollow"&gt;Travis-CI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;请参考&lt;a href="Day91-100/91.%E5%9B%A2%E9%98%9F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md"&gt;《团队项目开发的问题和解决方案》&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-项目选题和理解业务" class="anchor" aria-hidden="true" href="#项目选题和理解业务"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目选题和理解业务&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;选题范围设定&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CMS（用户端）：新闻聚合网站、问答/分享社区、影评/书评网站等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MIS（用户端+管理端）：KMS、KPI考核系统、HRS、CRM系统、供应链系统、仓储管理系统等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;App后台（管理端+数据接口）：二手交易类、报刊杂志类、小众电商类、新闻资讯类、旅游类、社交类、阅读类等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;其他类型：自身行业背景和工作经验、业务容易理解和把控。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;需求理解、模块划分和任务分配&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需求理解：头脑风暴和竞品分析。&lt;/li&gt;
&lt;li&gt;模块划分：画思维导图（XMind），每个模块是一个枝节点，每个具体的功能是一个叶节点（用动词表述），需要确保每个叶节点无法再生出新节点，确定每个叶子节点的重要性、优先级和工作量。&lt;/li&gt;
&lt;li&gt;任务分配：由项目负责人根据上面的指标为每个团队成员分配任务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/requirements_by_xmind.png"&gt;&lt;img src="./res/requirements_by_xmind.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;制定项目进度表（每日更新）&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;th&gt;人员&lt;/th&gt;
&lt;th&gt;状态&lt;/th&gt;
&lt;th&gt;完成&lt;/th&gt;
&lt;th&gt;工时&lt;/th&gt;
&lt;th&gt;计划开始&lt;/th&gt;
&lt;th&gt;实际开始&lt;/th&gt;
&lt;th&gt;计划结束&lt;/th&gt;
&lt;th&gt;实际结束&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;评论&lt;/td&gt;
&lt;td&gt;添加评论&lt;/td&gt;
&lt;td&gt;王大锤&lt;/td&gt;
&lt;td&gt;正在进行&lt;/td&gt;
&lt;td&gt;50%&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;删除评论&lt;/td&gt;
&lt;td&gt;王大锤&lt;/td&gt;
&lt;td&gt;等待&lt;/td&gt;
&lt;td&gt;0%&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;查看评论&lt;/td&gt;
&lt;td&gt;白元芳&lt;/td&gt;
&lt;td&gt;正在进行&lt;/td&gt;
&lt;td&gt;20%&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;需要进行代码审查&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;评论投票&lt;/td&gt;
&lt;td&gt;白元芳&lt;/td&gt;
&lt;td&gt;等待&lt;/td&gt;
&lt;td&gt;0%&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2018/8/8&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/8&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OOAD和数据库设计&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;UML（统一建模语言）的类图&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/uml-class-diagram.png"&gt;&lt;img src="./res/uml-class-diagram.png" alt="uml" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过模型创建表（正向工程）&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python manage.py makemigrations app
python manage.py migrate&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用PowerDesigner绘制物理模型图。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/power-designer-pdm.png"&gt;&lt;img src="./res/power-designer-pdm.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过数据表创建模型（反向工程）&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python manage.py inspectdb &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; app/models.py&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-第92天docker容器详解" class="anchor" aria-hidden="true" href="#第92天docker容器详解"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第92天：&lt;a href="./Day91-100/92.Docker%E5%AE%B9%E5%99%A8%E8%AF%A6%E8%A7%A3.md"&gt;Docker容器详解&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Docker简介&lt;/li&gt;
&lt;li&gt;安装Docker&lt;/li&gt;
&lt;li&gt;使用Docker创建容器（Nginx、MySQL、Redis、Gitlab、Jenkins）&lt;/li&gt;
&lt;li&gt;构建Docker镜像（Dockerfile的编写和相关指令）&lt;/li&gt;
&lt;li&gt;容器编排（Docker-compose）&lt;/li&gt;
&lt;li&gt;集群管理&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-第93天mysql性能优化" class="anchor" aria-hidden="true" href="#第93天mysql性能优化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第93天：&lt;a href="./Day91-100/93.MySQL%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.md"&gt;MySQL性能优化&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第94天网络api接口设计" class="anchor" aria-hidden="true" href="#第94天网络api接口设计"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第94天：&lt;a href="./Day91-100/94.%E7%BD%91%E7%BB%9CAPI%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1.md"&gt;网络API接口设计&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第95天使用django开发商业项目day91-10095使用django开发商业项目md" class="anchor" aria-hidden="true" href="#第95天使用django开发商业项目day91-10095使用django开发商业项目md"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第95天：[使用Django开发商业项目](./Day91-100/95.使用Django开发商业项	目.md)&lt;/h4&gt;
&lt;h5&gt;&lt;a id="user-content-项目开发中的公共问题" class="anchor" aria-hidden="true" href="#项目开发中的公共问题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目开发中的公共问题&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;数据库的配置（多数据库、主从复制、数据库路由）&lt;/li&gt;
&lt;li&gt;缓存的配置（分区缓存、键设置、超时设置、主从复制、故障恢复（哨兵））&lt;/li&gt;
&lt;li&gt;日志的配置&lt;/li&gt;
&lt;li&gt;分析和调试（Django-Debug-ToolBar）&lt;/li&gt;
&lt;li&gt;好用的Python模块（日期计算、图像处理、数据加密、三方API）&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-rest-api设计" class="anchor" aria-hidden="true" href="#rest-api设计"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;REST API设计&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;RESTful架构
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.ruanyifeng.com/blog/2011/09/restful.html" rel="nofollow"&gt;理解RESTful架构&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ruanyifeng.com/blog/2014/05/restful_api.html" rel="nofollow"&gt;RESTful API设计指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html" rel="nofollow"&gt;RESTful API最佳实践&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;API接口文档的撰写
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://rap2.taobao.org/" rel="nofollow"&gt;RAP2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://yapi.demo.qunar.com/" rel="nofollow"&gt;YAPI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.django-rest-framework.org/" rel="nofollow"&gt;django-REST-framework&lt;/a&gt;的应用&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-项目中的重点难点剖析" class="anchor" aria-hidden="true" href="#项目中的重点难点剖析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目中的重点难点剖析&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;使用缓存缓解数据库压力 - Redis&lt;/li&gt;
&lt;li&gt;使用消息队列做解耦合和削峰 - Celery + RabbitMQ&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-第96天软件测试和自动化测试" class="anchor" aria-hidden="true" href="#第96天软件测试和自动化测试"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第96天：&lt;a href="Day91-100/96.%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E5%92%8C%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95.md"&gt;软件测试和自动化测试&lt;/a&gt;&lt;/h4&gt;
&lt;h5&gt;&lt;a id="user-content-单元测试" class="anchor" aria-hidden="true" href="#单元测试"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;单元测试&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;测试的种类&lt;/li&gt;
&lt;li&gt;编写单元测试（unittest、pytest、nose2、tox、ddt、……）&lt;/li&gt;
&lt;li&gt;测试覆盖率（coverage）&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-项目部署" class="anchor" aria-hidden="true" href="#项目部署"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目部署&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;部署前的准备工作
&lt;ul&gt;
&lt;li&gt;关键设置（SECRET_KEY / DEBUG / ALLOWED_HOSTS / 缓存 / 数据库）&lt;/li&gt;
&lt;li&gt;HTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECURE&lt;/li&gt;
&lt;li&gt;日志相关配置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Linux常用命令回顾&lt;/li&gt;
&lt;li&gt;Linux常用服务的安装和配置&lt;/li&gt;
&lt;li&gt;uWSGI/Gunicorn和Nginx的使用
&lt;ul&gt;
&lt;li&gt;Gunicorn和uWSGI的比较
&lt;ul&gt;
&lt;li&gt;对于不需要大量定制化的简单应用程序，Gunicorn是一个不错的选择，uWSGI的学习曲线比Gunicorn要陡峭得多，Gunicorn的默认参数就已经能够适应大多数应用程序。&lt;/li&gt;
&lt;li&gt;uWSGI支持异构部署。&lt;/li&gt;
&lt;li&gt;由于Nginx本身支持uWSGI，在线上一般都将Nginx和uWSGI捆绑在一起部署，而且uWSGI属于功能齐全且高度定制的WSGI中间件。&lt;/li&gt;
&lt;li&gt;在性能上，Gunicorn和uWSGI其实表现相当。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;使用虚拟化技术（Docker）部署测试环境和生产环境&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-性能测试" class="anchor" aria-hidden="true" href="#性能测试"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;性能测试&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;AB的使用&lt;/li&gt;
&lt;li&gt;SQLslap的使用&lt;/li&gt;
&lt;li&gt;sysbench的使用&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-自动化测试" class="anchor" aria-hidden="true" href="#自动化测试"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;自动化测试&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;使用Shell和Python进行自动化测试&lt;/li&gt;
&lt;li&gt;使用Selenium实现自动化测试
&lt;ul&gt;
&lt;li&gt;Selenium IDE&lt;/li&gt;
&lt;li&gt;Selenium WebDriver&lt;/li&gt;
&lt;li&gt;Selenium Remote Control&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;测试工具Robot Framework介绍&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-第97天电商网站技术要点剖析" class="anchor" aria-hidden="true" href="#第97天电商网站技术要点剖析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第97天：&lt;a href="./Day91-100/97.%E7%94%B5%E5%95%86%E7%BD%91%E7%AB%99%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9%E5%89%96%E6%9E%90.md"&gt;电商网站技术要点剖析&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第98天项目部署上线和性能调优" class="anchor" aria-hidden="true" href="#第98天项目部署上线和性能调优"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第98天：&lt;a href="./Day91-100/98.%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E4%B8%8A%E7%BA%BF%E5%92%8C%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98.md"&gt;项目部署上线和性能调优&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;MySQL数据库调优&lt;/li&gt;
&lt;li&gt;Web服务器性能优化
&lt;ul&gt;
&lt;li&gt;Nginx负载均衡配置&lt;/li&gt;
&lt;li&gt;Keepalived实现高可用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;代码性能调优
&lt;ul&gt;
&lt;li&gt;多线程&lt;/li&gt;
&lt;li&gt;异步化&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;静态资源访问优化
&lt;ul&gt;
&lt;li&gt;云存储&lt;/li&gt;
&lt;li&gt;CDN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-第99天面试中的公共问题" class="anchor" aria-hidden="true" href="#第99天面试中的公共问题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第99天：&lt;a href="./Day91-100/99.%E9%9D%A2%E8%AF%95%E4%B8%AD%E7%9A%84%E5%85%AC%E5%85%B1%E9%97%AE%E9%A2%98.md"&gt;面试中的公共问题&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第100天python面试题集" class="anchor" aria-hidden="true" href="#第100天python面试题集"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第100天：&lt;a href="./Day91-100/100.Python%E9%9D%A2%E8%AF%95%E9%A2%98%E9%9B%86.md"&gt;Python面试题集&lt;/a&gt;&lt;/h4&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jackfrued</author><guid isPermaLink="false">https://github.com/jackfrued/Python-100-Days</guid><pubDate>Sat, 04 Jan 2020 00:13:00 GMT</pubDate></item><item><title>datawhalechina/competition-baseline #14 in Jupyter Notebook, This week</title><link>https://github.com/datawhalechina/competition-baseline</link><description>&lt;p&gt;&lt;i&gt;数据科学竞赛各种baseline代码、思路分享&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-数据竞赛baseline--topline分享" class="anchor" aria-hidden="true" href="#数据竞赛baseline--topline分享"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数据竞赛Baseline &amp;amp; Topline分享&lt;/h1&gt;
&lt;p&gt;假如你是数据竞赛的初学者、爱好者，比赛的baseline不仅是比赛思路分享，同时也是一类数据问题的方法总结。本Repo想做的就是将收集并整理并分享各种比赛的baseline方案。&lt;/p&gt;
&lt;p&gt;你可能会问为什么是baseline，而不是获胜者的代码分享？相比于获胜者的代码baseline代码都比较简单，容易整理和学习；其次baseline代码更加实用和简洁，适合入门学习。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-数据竞赛平台" class="anchor" aria-hidden="true" href="#数据竞赛平台"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数据竞赛平台&lt;/h2&gt;
&lt;p&gt;国内外常见的数据竞赛平台：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;国外竞赛平台：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.kaggle.com" rel="nofollow"&gt;Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.drivendata.org" rel="nofollow"&gt;DrivenData&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://competitions.codalab.org" rel="nofollow"&gt;Colalab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.crowdai.org" rel="nofollow"&gt;CrowdAI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://kelvins.esa.int/" rel="nofollow"&gt;Kelvins&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://signate.jp/" rel="nofollow"&gt;Signate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://datahack.analyticsvidhya.com/" rel="nofollow"&gt;analyticsvidhya&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;国内竞赛平台&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://tianchi.aliyun.com" rel="nofollow"&gt;天池&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dianshi.baidu.com/competition" rel="nofollow"&gt;点石&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jdata.jd.com" rel="nofollow"&gt;JData&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pkbigdata.com" rel="nofollow"&gt;DataCastle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.datafountain.cn" rel="nofollow"&gt;DataFountain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://biendata.com" rel="nofollow"&gt;Biendata&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.kesci.com" rel="nofollow"&gt;科赛&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://god.yanxishe.com/" rel="nofollow"&gt;AI研习社&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.turingtopia.com/competitionnew" rel="nofollow"&gt;图灵联邦&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://aistudio.baidu.com/aistudio/competition" rel="nofollow"&gt;AI Studio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.flyai.com/" rel="nofollow"&gt;FlyAI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DataSciCamp竞赛列表：&lt;a href="https://www.datascicamp.com/?sub=DM,CV,NLP,RL,SP" rel="nofollow"&gt;https://www.datascicamp.com/?sub=DM,CV,NLP,RL,SP&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最新的竞赛信息和baseline推送，请关注：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;竞赛公众号：&lt;a href="https://t.zsxq.com/Eyn6EQr" rel="nofollow"&gt;&lt;strong&gt;Coggle数据科学&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;知乎专栏：&lt;a href="https://zhuanlan.zhihu.com/DataAI" rel="nofollow"&gt;机器学习理论与数据竞赛实战&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-竞赛分享" class="anchor" aria-hidden="true" href="#竞赛分享"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;竞赛分享&lt;/h2&gt;
&lt;p&gt;每个比赛的详细分享请见&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition"&gt;competition文件夹&lt;/a&gt;；&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-结构化比赛" class="anchor" aria-hidden="true" href="#结构化比赛"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;结构化比赛&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/DataFountain-%E4%B9%98%E7%94%A8%E8%BD%A6%E7%BB%86%E5%88%86%E5%B8%82%E5%9C%BA%E9%94%80%E9%87%8F%E9%A2%84%E6%B5%8B"&gt;DataFountain-乘用车细分市场销量预测&lt;/a&gt;, 结构化
数据比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/DataFountain-%E7%A6%BB%E6%95%A3%E5%88%B6%E9%80%A0%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%85%B8%E5%9E%8B%E5%B7%A5%E4%BB%B6%E7%9A%84%E8%B4%A8%E9%87%8F%E7%AC%A6%E5%90%88%E7%8E%87%E9%A2%84%E6%B5%8B"&gt;DataFountain-离散制造过程中典型工件的质量符合率预测&lt;/a&gt;, 结构化数据比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/%E8%85%BE%E8%AE%AF-2018%E8%85%BE%E8%AE%AF%E5%B9%BF%E5%91%8A%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9B"&gt;腾讯-2018腾讯广告算法大赛 Rank11&lt;/a&gt;，结构化数据比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/%E8%85%BE%E8%AE%AF-2019%E8%85%BE%E8%AE%AF%E5%B9%BF%E5%91%8A%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9B"&gt;腾讯-2018腾讯广告算法大赛 冠军&lt;/a&gt;，结构化数据比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/Tianchi-%E5%AE%89%E6%B3%B0%E6%9D%AF%E8%B7%A8%E5%A2%83%E7%94%B5%E5%95%86%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9B"&gt;天池-安泰杯跨境电商智能算法大赛&lt;/a&gt;，结构化数据比赛，&lt;strong&gt;冠军法国南部&lt;/strong&gt;分享&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/%E7%82%B9%E7%9F%B3-Retention%20Rate%20of%20Baidu%20Hao%20Kan%20APP%20Users"&gt;点石-Retention Rate of Baidu Hao Kan APP Users&lt;/a&gt;，结构化数据比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/kaggle-two-sigma-connect-rental-listing-inquiries"&gt;kaggle-two-sigma-connect-rental-listing-inquiries&lt;/a&gt;，结构化数据比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/kaggle-allstate-claims-severity"&gt;kaggle-allstate-claims-severity&lt;/a&gt;，结构化数据比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/yanxishe-%E7%99%BD%E8%91%A1%E8%90%84%E9%85%92%E5%93%81%E8%B4%A8%E9%A2%84%E6%B5%8B"&gt;AI研习社-白葡萄酒品质预测&lt;/a&gt;，结构化数据比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/yanxishe-%E8%82%8C%E8%82%89%E6%B4%BB%E5%8A%A8%E7%94%B5%E4%BF%A1%E5%8F%B7%E6%8E%A8%E6%B5%8B%E6%89%8B%E5%8A%BF"&gt;AI研习社-肌肉活动电信号推测手势&lt;/a&gt;，结构化数据比赛&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-cv类型比赛" class="anchor" aria-hidden="true" href="#cv类型比赛"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CV类型比赛&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/Tianchi-%E5%BF%83%E7%94%B5%E4%BA%BA%E6%9C%BA%E6%99%BA%E8%83%BD%E5%A4%A7%E8%B5%9B%E5%BF%83%E7%94%B5%E5%BC%82%E5%B8%B8%E4%BA%8B%E4%BB%B6%E9%A2%84%E6%B5%8B"&gt;天池-心电人机智能大赛心电异常事件预测&lt;/a&gt;, CV类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/DataFountain-%E5%A4%9A%E4%BA%BA%E7%A7%8D%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB"&gt;DataFountain-多人种人脸识别&lt;/a&gt;, CV类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/DataFountain-%E5%9F%BA%E4%BA%8EOCR%E7%9A%84%E8%BA%AB%E4%BB%BD%E8%AF%81%E8%A6%81%E7%B4%A0%E6%8F%90%E5%8F%96"&gt;DataFountain-基于OCR的身份证要素提取&lt;/a&gt;, CV类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/DataFountain-%E8%A7%86%E9%A2%91%E7%89%88%E6%9D%83%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"&gt;DataFountain-视频版权检测算法&lt;/a&gt;，CV类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/kaggle-quickdraw-doodle-recognition"&gt;kaggle-quickdraw-doodle-recognition&lt;/a&gt;，CV类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/TinyMind%E4%BA%BA%E6%B0%91%E5%B8%81%E9%9D%A2%E5%80%BC%26%E5%86%A0%E5%AD%97%E5%8F%B7%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%E6%8C%91%E6%88%98%E8%B5%9B"&gt;TinyMind人民币面值&amp;amp;冠字号编码识别挑战赛&lt;/a&gt;，CV类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/yanxishe-%E8%83%B8%E8%85%94X%E5%85%89%E8%82%BA%E7%82%8E%E6%A3%80%E6%B5%8B"&gt;AI研习社-胸腔X光肺炎检测&lt;/a&gt;，CV类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/yanxishe-%E8%82%BA%E7%82%8EX%E5%85%89%E7%97%85%E7%81%B6%E8%AF%86%E5%88%AB"&gt;AI研习社-肺炎X光病灶识别&lt;/a&gt;，CV类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/yanxishe-%E4%BA%BA%E8%84%B8%E5%B9%B4%E9%BE%84%E8%AF%86%E5%88%AB"&gt;AI研习社-人脸年龄识别&lt;/a&gt;，CV类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/yanxishe-%E7%BE%8E%E9%A3%9F%E8%AF%86%E5%88%AB%E6%8C%91%E6%88%98%EF%BC%881%EF%BC%89%EF%BC%9A%E8%B1%86%E8%85%90VS%E5%9C%9F%E8%B1%86"&gt;AI研习社-美食识别挑战（1）：豆腐VS土豆&lt;/a&gt;，CV类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/yanxishe-%E5%96%B5%E8%84%B8%E5%85%B3%E9%94%AE%E7%82%B9%E6%A3%80%E6%B5%8B"&gt;AI研习社-猫脸关键点检测&lt;/a&gt;，CV类型比赛&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-nlp类型比赛" class="anchor" aria-hidden="true" href="#nlp类型比赛"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NLP类型比赛&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/yanxishe-IMDB%E8%AF%84%E8%AE%BA%E5%89%A7%E9%80%8F%E6%A3%80%E6%B5%8B"&gt;AI研习社-IMDB评论剧透检测&lt;/a&gt;，NLP类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/DataFountain-%E9%87%91%E8%9E%8D%E4%BF%A1%E6%81%AF%E8%B4%9F%E9%9D%A2%E5%8F%8A%E4%B8%BB%E4%BD%93%E5%88%A4%E5%AE%9A"&gt;DataFountain-金融信息负面及主体判定&lt;/a&gt;, NLP类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/DataFountain-%E4%BA%92%E8%81%94%E7%BD%91%E9%87%91%E8%9E%8D%E6%96%B0%E5%AE%9E%E4%BD%93%E5%8F%91%E7%8E%B0"&gt;DataFountain-互联网金融新实体发现&lt;/a&gt;，NLP类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/DataFountain-%E6%8A%80%E6%9C%AF%E9%9C%80%E6%B1%82%E4%B8%8E%E6%8A%80%E6%9C%AF%E6%88%90%E6%9E%9C%E9%A1%B9%E7%9B%AE%E4%B9%8B%E9%97%B4%E5%85%B3%E8%81%94%E5%BA%A6%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B"&gt;DataFountain-技术需求与技术成果项目之间关联度计算模型&lt;/a&gt;，NLP类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/DataFountain-%E4%BA%92%E8%81%94%E7%BD%91%E6%96%B0%E9%97%BB%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90"&gt;DataFountain-互联网新闻情感分析&lt;/a&gt;，NLP类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/biendata-%E6%99%BA%E6%BA%90%26%E8%AE%A1%E7%AE%97%E6%89%80-%E4%BA%92%E8%81%94%E7%BD%91%E8%99%9A%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B%E6%8C%91%E6%88%98%E8%B5%9B"&gt;biendata-智源&amp;amp;计算所-互联网虚假新闻检测挑战赛&lt;/a&gt;，NLP类型比赛&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/Tianchi-%E7%AC%AC%E4%B8%89%E5%B1%8A%E9%98%BF%E9%87%8C%E4%BA%91%E5%AE%89%E5%85%A8%E7%AE%97%E6%B3%95%E6%8C%91%E6%88%98%E8%B5%9B"&gt;Tianchi-第三届阿里云安全算法挑战赛&lt;/a&gt;，NLP类型比赛&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-其他类型" class="anchor" aria-hidden="true" href="#其他类型"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;其他类型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/DataFountain-%E4%BC%81%E4%B8%9A%E7%BD%91%E7%BB%9C%E8%B5%84%E4%BA%A7%E5%8F%8A%E5%AE%89%E5%85%A8%E4%BA%8B%E4%BB%B6%E5%88%86%E6%9E%90%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96"&gt;DataFountain-企业网络资产及安全事件分析与可视化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/DataFountain-%E4%B8%89%E8%A7%92%E5%BD%A2%E5%9B%BE%E8%AE%A1%E7%AE%97%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E5%8F%8A%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96"&gt;DataFountain-三角形图计算算法设计及性能优化&lt;/a&gt;, 计算优化&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/tree/master/competition/DataFountain-%E4%BA%91%E8%AE%A1%E7%AE%97%E6%97%B6%E4%BB%A3%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E5%88%86%E6%9E%90%E4%BC%98%E5%8C%96"&gt;DataFountain-云计算时代的大数据查询分析优化&lt;/a&gt;, 查询优化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其他链接：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Smilexuhc/Data-Competition-TopSolution"&gt;Smile整理的竞赛优胜者代码分享&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chizhu/BDC2019"&gt;chizhi开源的高校赛2019 文本点击预测&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-贡献者按照贡献id排序" class="anchor" aria-hidden="true" href="#贡献者按照贡献id排序"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;贡献者(按照贡献ID排序)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/people/finlayliu/" rel="nofollow"&gt;阿水&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/people/yuconan/" rel="nofollow"&gt;DOTA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/people/kingdoms/activities" rel="nofollow"&gt;Rain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/people/wang-he-13-93/" rel="nofollow"&gt;鱼遇雨欲语与余&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/yphacker"&gt;yphacker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-协作规范" class="anchor" aria-hidden="true" href="#协作规范"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;协作规范&lt;/h2&gt;
&lt;p&gt;欢迎大家fork并贡献代码，但请大家遵守以下规范和建议：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;代码请按照比赛的形式进行整理，写明比赛的网址、数据类型和解题赛题；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;代码请注明运行的环境，以及机器最低配置，如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;操作系统：Linux，内存16G，硬盘无要求；&lt;/li&gt;
&lt;li&gt;Python环境：Python2/3&lt;/li&gt;
&lt;li&gt;Pytorch版本：0.4.0&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;baseline代码只能提供可运行的代码和思路，&lt;strong&gt;请不要提供直接可以提交的结果文件；&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;代码提供者应对代码版权和共享权负责；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果发现Repo存在版权等相关问题，请邮件联系&lt;a href="mailto:finlayliu@qq.com"&gt;finlayliu@qq.com&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-关注我们" class="anchor" aria-hidden="true" href="#关注我们"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;关注我们&lt;/h2&gt;
&lt;div align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/datawhalechina/pumpkin-book/master/res/qrcode.jpeg"&gt;&lt;img src="https://raw.githubusercontent.com/datawhalechina/pumpkin-book/master/res/qrcode.jpeg" width="250" height="270" alt="Datawhale，一个专注于AI领域的学习圈子。初衷是for the learner，和学习者一起成长。目前加入学习社群的人数已经数千人，组织了机器学习，深度学习，数据分析，数据挖掘，爬虫，编程，统计学，Mysql，数据竞赛等多个领域的内容学习，微信搜索公众号Datawhale可以加入我们。" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LICENSE&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/datawhalechina/competition-baseline/blob/master/LICENSE"&gt;GNU General Public License v3.0&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>datawhalechina</author><guid isPermaLink="false">https://github.com/datawhalechina/competition-baseline</guid><pubDate>Sat, 04 Jan 2020 00:14:00 GMT</pubDate></item><item><title>fastai/fastai #15 in Jupyter Notebook, This week</title><link>https://github.com/fastai/fastai</link><description>&lt;p&gt;&lt;i&gt;The fastai deep learning library, plus lessons and tutorials&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://dev.azure.com/fastdotai/fastai/_build/latest?definitionId=1" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a1b1234cce0c844f75224d1df07b4f236f78aee7/68747470733a2f2f6465762e617a7572652e636f6d2f66617374646f7461692f6661737461692f5f617069732f6275696c642f7374617475732f6661737461692e666173746169" alt="Build Status" data-canonical-src="https://dev.azure.com/fastdotai/fastai/_apis/build/status/fastai.fastai" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.python.org/pypi/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/26f7b20369ea7a096cfb30bdf0d14bc6ceda0275/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6661737461692e737667" alt="pypi fastai version" data-canonical-src="https://img.shields.io/pypi/v/fastai.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://anaconda.org/fastai/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2c20a6e61cb1c612b644253db1e3c1f7972d7f0e/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f762f6661737461692f6661737461692e737667" alt="Conda fastai version" data-canonical-src="https://img.shields.io/conda/v/fastai/fastai.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://anaconda.org/fastai/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/39f258e6563b60eef6a88589cd194d3a85033747/68747470733a2f2f616e61636f6e64612e6f72672f6661737461692f6661737461692f6261646765732f706c6174666f726d732e737667" alt="Anaconda-Server Badge" data-canonical-src="https://anaconda.org/fastai/fastai/badges/platforms.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.python.org/pypi/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6dc643192dbbbd8edda826d1be289ba06ef2b57f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6661737461692e737667" alt="fastai python compatibility" data-canonical-src="https://img.shields.io/pypi/pyversions/fastai.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.python.org/pypi/fastai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f600abfa75b593d49643c1710ed42865373f9d75/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f6661737461692e737667" alt="fastai license" data-canonical-src="https://img.shields.io/pypi/l/fastai.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-fastai" class="anchor" aria-hidden="true" href="#fastai"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;fastai&lt;/h1&gt;
&lt;p&gt;The fastai library simplifies training fast and accurate neural nets using modern best practices. See the &lt;a href="https://docs.fast.ai" rel="nofollow"&gt;fastai website&lt;/a&gt; to get started. The library is based on research into deep learning best practices undertaken at &lt;a href="http://www.fast.ai" rel="nofollow"&gt;fast.ai&lt;/a&gt;, and includes "out of the box" support for &lt;a href="https://docs.fast.ai/vision.html#vision" rel="nofollow"&gt;&lt;code&gt;vision&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://docs.fast.ai/text.html#text" rel="nofollow"&gt;&lt;code&gt;text&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://docs.fast.ai/tabular.html#tabular" rel="nofollow"&gt;&lt;code&gt;tabular&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://docs.fast.ai/collab.html#collab" rel="nofollow"&gt;&lt;code&gt;collab&lt;/code&gt;&lt;/a&gt; (collaborative filtering) models. For brief examples, see the &lt;a href="https://github.com/fastai/fastai/tree/master/examples"&gt;examples&lt;/a&gt; folder; detailed examples are provided in the full &lt;a href="https://docs.fast.ai/" rel="nofollow"&gt;documentation&lt;/a&gt;. For instance, here's how to train an MNIST model using &lt;a href="https://arxiv.org/abs/1512.03385" rel="nofollow"&gt;resnet18&lt;/a&gt; (from the &lt;a href="https://github.com/fastai/fastai/blob/master/examples/vision.ipynb"&gt;vision example&lt;/a&gt;):&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; fastai.vision &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;
path &lt;span class="pl-k"&gt;=&lt;/span&gt; untar_data(&lt;span class="pl-c1"&gt;MNIST_PATH&lt;/span&gt;)
data &lt;span class="pl-k"&gt;=&lt;/span&gt; image_data_from_folder(path)
learn &lt;span class="pl-k"&gt;=&lt;/span&gt; cnn_learner(data, models.resnet18, &lt;span class="pl-v"&gt;metrics&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;accuracy)
learn.fit(&lt;span class="pl-c1"&gt;1&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-note-for-coursefastai-students" class="anchor" aria-hidden="true" href="#note-for-coursefastai-students"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Note for &lt;a href="http://course.fast.ai" rel="nofollow"&gt;course.fast.ai&lt;/a&gt; students&lt;/h2&gt;
&lt;p&gt;This document is written for &lt;code&gt;fastai v1&lt;/code&gt;, which we use for the current version the &lt;a href="http://course.fast.ai" rel="nofollow"&gt;course.fast.ai&lt;/a&gt; deep learning courses. If you're following along with a course at &lt;a href="http://course18.fast.ai" rel="nofollow"&gt;course18.fast.ai&lt;/a&gt; (i.e. the machine learning course, which isn't updated for v1) you need to use &lt;code&gt;fastai 0.7&lt;/code&gt;;  please follow the installation instructions &lt;a href="https://forums.fast.ai/t/fastai-v0-install-issues-thread/24652" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt; &lt;em&gt;fastai v1 currently supports Linux only, and requires &lt;strong&gt;PyTorch v1&lt;/strong&gt; and &lt;strong&gt;Python 3.6&lt;/strong&gt; or later. Windows support is at an experimental stage: it should work fine but it's much slower and less well tested. Since Macs don't currently have good Nvidia GPU support, we do not currently prioritize Mac development.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;fastai-1.x&lt;/code&gt; can be installed with either &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;pip&lt;/code&gt; package managers and also from source. At the moment you can't just run &lt;em&gt;install&lt;/em&gt;, since you first need to get the correct &lt;code&gt;pytorch&lt;/code&gt; version installed - thus to get &lt;code&gt;fastai-1.x&lt;/code&gt; installed choose one of the installation recipes below using your favorite python package manager. Note that &lt;strong&gt;PyTorch v1&lt;/strong&gt; and &lt;strong&gt;Python 3.6&lt;/strong&gt; are the minimal version requirements.&lt;/p&gt;
&lt;p&gt;It's highly recommended you install &lt;code&gt;fastai&lt;/code&gt; and its dependencies in a virtual environment (&lt;a href="https://conda.io/docs/user-guide/tasks/manage-environments.html" rel="nofollow"&gt;&lt;code&gt;conda&lt;/code&gt;&lt;/a&gt; or others), so that you don't interfere with system-wide python packages. It's not that you must, but if you experience problems with any dependency packages, please consider using a fresh virtual environment just for &lt;code&gt;fastai&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Starting with pytorch-1.x you no longer need to install a special pytorch-cpu version. Instead use the normal pytorch and it works with and without GPU. But &lt;a href="https://docs.fast.ai/install.html#cpu-build" rel="nofollow"&gt;you can install the cpu build too&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you experience installation problems, please read about &lt;a href="https://github.com/fastai/fastai/blob/master/README.md#installation-issues"&gt;installation issues&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are planning on using &lt;code&gt;fastai&lt;/code&gt; in the jupyter notebook environment, make sure to also install the corresponding &lt;a href="https://docs.fast.ai/install.html#jupyter-notebook-dependencies" rel="nofollow"&gt;packages&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;More advanced installation issues, such as installing only partial dependencies are covered in a dedicated &lt;a href="https://docs.fast.ai/install.html" rel="nofollow"&gt;installation doc&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-conda-install" class="anchor" aria-hidden="true" href="#conda-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Conda Install&lt;/h3&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install -c pytorch -c fastai fastai&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will install the &lt;code&gt;pytorch&lt;/code&gt; build with the latest &lt;code&gt;cudatoolkit&lt;/code&gt; version. If you need a higher or lower &lt;code&gt;CUDA XX&lt;/code&gt; build (e.g. CUDA 9.0), following the instructions &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;here&lt;/a&gt;, to install the desired &lt;code&gt;pytorch&lt;/code&gt; build.&lt;/p&gt;
&lt;p&gt;Note that JPEG decoding can be a bottleneck, particularly if you have a fast GPU. You can optionally install an optimized JPEG decoder as follows (Linux):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda uninstall --force jpeg libtiff -y
conda install -c conda-forge libjpeg-turbo pillow==6.0.0
CC=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;cc -mavx2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; pip install --no-cache-dir -U --force-reinstall --no-binary :all: --compile pillow-simd&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you only care about faster JPEG decompression, it can be &lt;code&gt;pillow&lt;/code&gt; or &lt;code&gt;pillow-simd&lt;/code&gt; in the last command above, the latter speeds up other image processing operations. For the full story see &lt;a href="https://docs.fast.ai/performance.html#faster-image-processing" rel="nofollow"&gt;Pillow-SIMD&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-pypi-install" class="anchor" aria-hidden="true" href="#pypi-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyPI Install&lt;/h3&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install fastai&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By default pip will install the latest &lt;code&gt;pytorch&lt;/code&gt; with the latest &lt;code&gt;cudatoolkit&lt;/code&gt;. If your hardware doesn't support the latest &lt;code&gt;cudatoolkit&lt;/code&gt;, follow the instructions &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;here&lt;/a&gt;, to install a &lt;code&gt;pytorch&lt;/code&gt; build that fits your hardware.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-bug-fix-install" class="anchor" aria-hidden="true" href="#bug-fix-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bug Fix Install&lt;/h3&gt;
&lt;p&gt;If a bug fix was made in git and you can't wait till a new release is made, you can install the bleeding edge version of &lt;code&gt;fastai&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install git+https://github.com/fastai/fastai.git
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-developer-install" class="anchor" aria-hidden="true" href="#developer-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Developer Install&lt;/h3&gt;
&lt;p&gt;The following instructions will result in a &lt;a href="https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs" rel="nofollow"&gt;pip editable install&lt;/a&gt;, so that you can &lt;code&gt;git pull&lt;/code&gt; at any time and your environment will automatically get the updates:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/fastai/fastai
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; fastai
tools/run-after-git-clone
pip install -e &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;.[dev]&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, you can test that the build works by starting the jupyter notebook:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;jupyter notebook&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and executing an example notebook. For example load &lt;code&gt;examples/tabular.ipynb&lt;/code&gt; and run it.&lt;/p&gt;
&lt;p&gt;Please refer to &lt;a href="https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; and &lt;a href="https://docs.fast.ai/dev/develop.html" rel="nofollow"&gt;Notes For Developers&lt;/a&gt; for more details on how to contribute to the &lt;code&gt;fastai&lt;/code&gt; project.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-building-from-source" class="anchor" aria-hidden="true" href="#building-from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building From Source&lt;/h3&gt;
&lt;p&gt;If for any reason you can't use the prepackaged packages and have to build from source, this section is for you.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To build &lt;code&gt;pytorch&lt;/code&gt; from source follow the &lt;a href="https://github.com/pytorch/pytorch#from-source"&gt;complete instructions&lt;/a&gt;. Remember to first install CUDA, CuDNN, and other required libraries as suggested - everything will be very slow without those libraries built into &lt;code&gt;pytorch&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next, you will also need to build &lt;code&gt;torchvision&lt;/code&gt; from source:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/pytorch/vision
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; vision
python setup.py install&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When both &lt;code&gt;pytorch&lt;/code&gt; and &lt;code&gt;torchvision&lt;/code&gt; are installed, first test that you can load each of these libraries:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;import torch
import torchvision&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to validate that they were installed correctly&lt;/p&gt;
&lt;p&gt;Finally, proceed with &lt;code&gt;fastai&lt;/code&gt; installation as normal, either through prepackaged pip or conda builds or installing from source ("the developer install") as explained in the sections above.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-installation-issues" class="anchor" aria-hidden="true" href="#installation-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation Issues&lt;/h2&gt;
&lt;p&gt;If the installation process fails, first make sure &lt;a href="https://github.com/fastai/fastai/blob/master/README.md#is-my-system-supported"&gt;your system is supported&lt;/a&gt;. And if the problem is still not addressed, please refer to the &lt;a href="https://docs.fast.ai/troubleshoot.html" rel="nofollow"&gt;troubleshooting document&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you encounter installation problems with conda, make sure you have the latest &lt;code&gt;conda&lt;/code&gt; client (&lt;code&gt;conda install&lt;/code&gt; will do an update too):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install conda&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-is-my-system-supported" class="anchor" aria-hidden="true" href="#is-my-system-supported"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Is My System Supported?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Python: You need to have python 3.6 or higher&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CPU or GPU&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pytorch&lt;/code&gt; binary package comes with its own CUDA, CuDNN, NCCL, MKL, and other libraries so you don't have to install system-wide NVIDIA's CUDA and related libraries if you don't need them for something else. If you have them installed already it doesn't matter which NVIDIA's CUDA version library you have installed system-wide. Your system could have CUDA 9.0 libraries, and you can still use &lt;code&gt;pytorch&lt;/code&gt; build with CUDA 10.0 libraries without any problem, since the &lt;code&gt;pytorch&lt;/code&gt; binary package is self-contained.&lt;/p&gt;
&lt;p&gt;The only requirement is that you have installed and configured the NVIDIA driver correctly. Usually you can test that by running &lt;code&gt;nvidia-smi&lt;/code&gt;. While it's possible that this application is not available on your system, it's very likely that if it doesn't work, then you don't have your NVIDIA drivers configured properly. And remember that a reboot is always required after installing NVIDIA drivers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Operating System:&lt;/p&gt;
&lt;p&gt;Since fastai-1.0 relies on pytorch-1.0, you need to be able to install pytorch-1.0 first.&lt;/p&gt;
&lt;p&gt;As of this moment pytorch.org's 1.0 version supports:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Platform&lt;/th&gt;
&lt;th&gt;GPU&lt;/th&gt;
&lt;th&gt;CPU&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;linux&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mac&lt;/td&gt;
&lt;td&gt;source&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;windows&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;td&gt;binary&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Legend: &lt;code&gt;binary&lt;/code&gt; = can be installed directly, &lt;code&gt;source&lt;/code&gt; = needs to be built from source.&lt;/p&gt;
&lt;p&gt;If there is no &lt;code&gt;pytorch&lt;/code&gt; preview conda or pip package available for your system, you may still be able to &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;build it from source&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How do you know which pytorch cuda version build to choose?&lt;/p&gt;
&lt;p&gt;It depends on the version of the installed NVIDIA driver. Here are the requirements for CUDA versions supported by pre-built &lt;code&gt;pytorch&lt;/code&gt; releases:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;CUDA Toolkit&lt;/th&gt;
&lt;th&gt;NVIDIA (Linux x86_64)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CUDA 10.0&lt;/td&gt;
&lt;td&gt;&amp;gt;= 410.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CUDA 9.0&lt;/td&gt;
&lt;td&gt;&amp;gt;= 384.81&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CUDA 8.0&lt;/td&gt;
&lt;td&gt;&amp;gt;= 367.48&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So if your NVIDIA driver is less than 384, then you can only use CUDA 8.0. Of course, you can upgrade your drivers to more recent ones if your card supports it.&lt;/p&gt;
&lt;p&gt;You can find a complete table with all variations &lt;a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you use NVIDIA driver 410+, you most likely want to install the &lt;code&gt;cudatoolkit=10.0&lt;/code&gt; pytorch variant, via:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install -c pytorch pytorch cudatoolkit=10.0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or if you need a lower version, use one of:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install -c pytorch pytorch cudatoolkit=8.0
conda install -c pytorch pytorch cudatoolkit=9.0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For other options refer to the complete list of &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;the available pytorch variants&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-updates" class="anchor" aria-hidden="true" href="#updates"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Updates&lt;/h2&gt;
&lt;p&gt;In order to update your environment, simply install &lt;code&gt;fastai&lt;/code&gt; in exactly the same way you did the initial installation.&lt;/p&gt;
&lt;p&gt;Top level files &lt;code&gt;environment.yml&lt;/code&gt; and &lt;code&gt;environment-cpu.yml&lt;/code&gt; belong to the old fastai (0.7). &lt;code&gt;conda env update&lt;/code&gt; is no longer the way to update your &lt;code&gt;fastai-1.x&lt;/code&gt; environment. These files remain because the fastai course-v2 video instructions rely on this setup. Eventually, once fastai course-v3 p1 and p2 will be completed, they will probably be moved to where they belong - under &lt;code&gt;old/&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-guidelines" class="anchor" aria-hidden="true" href="#contribution-guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution guidelines&lt;/h2&gt;
&lt;p&gt;If you want to contribute to &lt;code&gt;fastai&lt;/code&gt;, be sure to review the &lt;a href="https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt;. This project adheres to fastai's &lt;a href="https://github.com/fastai/fastai/blob/master/CODE-OF-CONDUCT.md"&gt;code of conduct&lt;/a&gt;. By participating, you are expected to uphold this code.&lt;/p&gt;
&lt;p&gt;We use GitHub issues for tracking requests and bugs, so please see &lt;a href="https://forums.fast.ai/" rel="nofollow"&gt;fastai forum&lt;/a&gt; for general questions and discussion.&lt;/p&gt;
&lt;p&gt;The fastai project strives to abide by generally accepted best practices in open-source software development:&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-history" class="anchor" aria-hidden="true" href="#history"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;History&lt;/h2&gt;
&lt;p&gt;A detailed history of changes can be found &lt;a href="https://github.com/fastai/fastai/blob/master/CHANGES.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-copyright" class="anchor" aria-hidden="true" href="#copyright"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Copyright&lt;/h2&gt;
&lt;p&gt;Copyright 2017 onwards, fast.ai, Inc. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this project's files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fastai</author><guid isPermaLink="false">https://github.com/fastai/fastai</guid><pubDate>Sat, 04 Jan 2020 00:15:00 GMT</pubDate></item><item><title>priya-dwivedi/Deep-Learning #16 in Jupyter Notebook, This week</title><link>https://github.com/priya-dwivedi/Deep-Learning</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h3&gt;&lt;a id="user-content-deep-learning" class="anchor" aria-hidden="true" href="#deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep-Learning&lt;/h3&gt;
&lt;p&gt;This repository contains deep learning related projects I have done over time. I am very passionate about deep learning and explore interesting ideas and tools. Each project is contained in its own folder.&lt;/p&gt;
&lt;p&gt;I have blogged about a lot of these projects on Medium - &lt;a href="https://medium.com/@priya.dwivedi" rel="nofollow"&gt;https://medium.com/@priya.dwivedi&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I also run a deep learning consultancy - &lt;a href="https://deeplearninganalytics.org/" rel="nofollow"&gt;https://deeplearninganalytics.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you want to collaborate on a project please reach out through my website.&lt;/p&gt;
&lt;p&gt;Hope you enjoy cloning this repo and trying out things yourself&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>priya-dwivedi</author><guid isPermaLink="false">https://github.com/priya-dwivedi/Deep-Learning</guid><pubDate>Sat, 04 Jan 2020 00:16:00 GMT</pubDate></item><item><title>fengdu78/Data-Science-Notes #17 in Jupyter Notebook, This week</title><link>https://github.com/fengdu78/Data-Science-Notes</link><description>&lt;p&gt;&lt;i&gt;数据科学的笔记以及资料搜集&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-data-science-notes" class="anchor" aria-hidden="true" href="#data-science-notes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data-Science-Notes&lt;/h1&gt;
&lt;p&gt;数据科学的笔记以及资料搜集，目前尚在更新，部分内容来源于github搜集。&lt;/p&gt;
&lt;p&gt;&lt;a href="0.math"&gt;0.math&lt;/a&gt; （数学基础）&lt;/p&gt;
&lt;p&gt;&lt;a href="1.python-basic"&gt;1.python-basic&lt;/a&gt; （python基础）&lt;/p&gt;
&lt;p&gt;&lt;a href="2.numpy"&gt;2.numpy&lt;/a&gt;（numpy基础）&lt;/p&gt;
&lt;p&gt;&lt;a href="3.pandas"&gt;3.pandas&lt;/a&gt;（pandas基础）&lt;/p&gt;
&lt;p&gt;&lt;a href="4.scipy"&gt;4.scipy&lt;/a&gt;（scipy基础）&lt;/p&gt;
&lt;p&gt;&lt;a href="5.data-visualization"&gt;5.data-visualization&lt;/a&gt;（数据可视化基础，包含matplotlib和seaborn）&lt;/p&gt;
&lt;p&gt;&lt;a href="6.scikit-learn"&gt;6.scikit-learn&lt;/a&gt;（scikit-learn基础）&lt;/p&gt;
&lt;p&gt;&lt;a href="7.machine-learning"&gt;7.machine-learning&lt;/a&gt;（机器学习基础）&lt;/p&gt;
&lt;p&gt;&lt;a href="8.deep-learning"&gt;8.deep-learning&lt;/a&gt;（深度学习基础）&lt;/p&gt;
&lt;p&gt;&lt;a href="9.feature-engineering"&gt;9.feature-engineering&lt;/a&gt;（特征工程基础）&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-参考" class="anchor" aria-hidden="true" href="#参考"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;《统计学习方法》李航&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/data-science-ipython-notebooks"&gt;https://github.com/donnemartin/data-science-ipython-notebooks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apachecn/feature-engineering-for-ml-zh"&gt;https://github.com/apachecn/feature-engineering-for-ml-zh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datawhalechina/pumpkin-book"&gt;https://github.com/datawhalechina/pumpkin-book&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Doraemonzzz/Learning-from-data"&gt;https://github.com/Doraemonzzz/Learning-from-data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wzyonggege/statistical-learning-method"&gt;https://github.com/wzyonggege/statistical-learning-method&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/WenDesi/lihang_book_algorithm"&gt;https://github.com/WenDesi/lihang_book_algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/course/ml" rel="nofollow"&gt;https://www.coursera.org/course/ml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mooc.guokr.com/note/12/" rel="nofollow"&gt;https://mooc.guokr.com/note/12/&lt;/a&gt; &lt;a href="https://mooc.guokr.com/user/2133483357/" rel="nofollow"&gt;小小人_V&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;《python科学计算》&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-关于作者" class="anchor" aria-hidden="true" href="#关于作者"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;关于作者&lt;/h2&gt;
&lt;p&gt;微信公众号：机器学习初学者 &lt;a target="_blank" rel="noopener noreferrer" href="images/gongzhong.jpg"&gt;&lt;img src="images/gongzhong.jpg" alt="gongzhong" style="max-width:100%;"&gt;&lt;/a&gt;
知识星球：黄博的机器学习圈子&lt;a target="_blank" rel="noopener noreferrer" href="images/zhishixingqiu1.jpg"&gt;&lt;img src="images/zhishixingqiu1.jpg" alt="xingqiu" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.zhihu.com/people/fengdu78/activities" rel="nofollow"&gt;我的知乎&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：github下载太慢的话，关注我的公众号：“机器学习初学者”，回复“学习路线”即可下载本仓库的镜像文件，整个仓库压缩成一个iso。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果需要引用这个Repo:&lt;/p&gt;
&lt;p&gt;格式： &lt;code&gt;fengdu78, Data-Science-Notes, (2019), GitHub repository, https://github.com/fengdu78/Data-Science-Notes&lt;/code&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fengdu78</author><guid isPermaLink="false">https://github.com/fengdu78/Data-Science-Notes</guid><pubDate>Sat, 04 Jan 2020 00:17:00 GMT</pubDate></item><item><title>udacity/deep-learning-v2-pytorch #18 in Jupyter Notebook, This week</title><link>https://github.com/udacity/deep-learning-v2-pytorch</link><description>&lt;p&gt;&lt;i&gt;Projects and exercises for the latest Deep Learning ND program https://www.udacity.com/course/deep-learning-nanodegree--nd101&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deep-learning-pytorch" class="anchor" aria-hidden="true" href="#deep-learning-pytorch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning (PyTorch)&lt;/h1&gt;
&lt;p&gt;This repository contains material related to Udacity's &lt;a href="https://www.udacity.com/course/deep-learning-nanodegree--nd101" rel="nofollow"&gt;Deep Learning Nanodegree program&lt;/a&gt;. It consists of a bunch of tutorial notebooks for various deep learning topics. In most cases, the notebooks lead you through implementing models such as convolutional networks, recurrent networks, and GANs. There are other topics covered such as weight initialization and batch normalization.&lt;/p&gt;
&lt;p&gt;There are also notebooks used as projects for the Nanodegree program. In the program itself, the projects are reviewed by real people (Udacity reviewers), but the starting code is available here, as well.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table Of Contents&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-tutorials" class="anchor" aria-hidden="true" href="#tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorials&lt;/h3&gt;
&lt;h3&gt;&lt;a id="user-content-introduction-to-neural-networks" class="anchor" aria-hidden="true" href="#introduction-to-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction to Neural Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-neural-networks"&gt;Introduction to Neural Networks&lt;/a&gt;: Learn how to implement gradient descent and apply it to predicting patterns in student admissions data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/sentiment-analysis-network"&gt;Sentiment Analysis with NumPy&lt;/a&gt;: &lt;a href="http://iamtrask.github.io/" rel="nofollow"&gt;Andrew Trask&lt;/a&gt; leads you through building a sentiment analysis model, predicting if some text is positive or negative.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-to-pytorch"&gt;Introduction to PyTorch&lt;/a&gt;: Learn how to build neural networks in PyTorch and use pre-trained networks for state-of-the-art image classifiers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-convolutional-neural-networks" class="anchor" aria-hidden="true" href="#convolutional-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Convolutional Neural Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/convolutional-neural-networks"&gt;Convolutional Neural Networks&lt;/a&gt;: Visualize the output of layers that make up a CNN. Learn how to define and train a CNN for classifying &lt;a href="https://en.wikipedia.org/wiki/MNIST_database" rel="nofollow"&gt;MNIST data&lt;/a&gt;, a handwritten digit database that is notorious in the fields of machine and deep learning. Also, define and train a CNN for classifying images in the &lt;a href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="nofollow"&gt;CIFAR10 dataset&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/transfer-learning"&gt;Transfer Learning&lt;/a&gt;. In practice, most people don't train their own networks on huge datasets; they use &lt;strong&gt;pre-trained&lt;/strong&gt; networks such as VGGnet. Here you'll use VGGnet to help classify images of flowers without training an end-to-end network from scratch.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/weight-initialization"&gt;Weight Initialization&lt;/a&gt;: Explore how initializing network weights affects performance.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/autoencoder"&gt;Autoencoders&lt;/a&gt;: Build models for image compression and de-noising, using feedforward and convolutional networks in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/style-transfer"&gt;Style Transfer&lt;/a&gt;: Extract style and content features from images, using a pre-trained network. Implement style transfer according to the paper, &lt;a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="nofollow"&gt;Image Style Transfer Using Convolutional Neural Networks&lt;/a&gt; by Gatys et. al. Define appropriate losses for iteratively creating a target, style-transferred image of your own design!&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-recurrent-neural-networks" class="anchor" aria-hidden="true" href="#recurrent-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Recurrent Neural Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/recurrent-neural-networks"&gt;Intro to Recurrent Networks (Time series &amp;amp; Character-level RNN)&lt;/a&gt;: Recurrent neural networks are able to use information about the sequence of data, such as the sequence of characters in text; learn how to implement these in PyTorch for a variety of tasks.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/word2vec-embeddings"&gt;Embeddings (Word2Vec)&lt;/a&gt;: Implement the Word2Vec model to find semantic representations of words for use in natural language processing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/sentiment-rnn"&gt;Sentiment Analysis RNN&lt;/a&gt;: Implement a recurrent neural network that can predict if the text of a moview review is positive or negative.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/attention"&gt;Attention&lt;/a&gt;: Implement attention and apply it to annotation vectors.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-generative-adversarial-networks" class="anchor" aria-hidden="true" href="#generative-adversarial-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generative Adversarial Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/gan-mnist"&gt;Generative Adversarial Network on MNIST&lt;/a&gt;: Train a simple generative adversarial network on the MNIST dataset.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/batch-norm"&gt;Batch Normalization&lt;/a&gt;: Learn how to improve training rates and network stability with batch normalizations.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/dcgan-svhn"&gt;Deep Convolutional GAN (DCGAN)&lt;/a&gt;: Implement a DCGAN to generate new images based on the Street View House Numbers (SVHN) dataset.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/cycle-gan"&gt;CycleGAN&lt;/a&gt;: Implement a CycleGAN that is designed to learn from unpaired and unlabeled data; use trained generators to transform images from summer to winter and vice versa.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-deploying-a-model-with-aws-sagemaker" class="anchor" aria-hidden="true" href="#deploying-a-model-with-aws-sagemaker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deploying a Model (with AWS SageMaker)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/sagemaker-deployment"&gt;All exercise and project notebooks&lt;/a&gt; for the lessons on model deployment can be found in the linked, Github repo. Learn to deploy pre-trained models using AWS SageMaker.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-projects" class="anchor" aria-hidden="true" href="#projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Projects&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-bikesharing"&gt;Predicting Bike-Sharing Patterns&lt;/a&gt;: Implement a neural network in NumPy to predict bike rentals.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-dog-classification"&gt;Dog Breed Classifier&lt;/a&gt;: Build a convolutional neural network with PyTorch to classify any image (even an image of a face) as a specific dog breed.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-tv-script-generation"&gt;TV Script Generation&lt;/a&gt;: Train a recurrent neural network to generate scripts in the style of dialogue from Seinfeld.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-face-generation"&gt;Face Generation&lt;/a&gt;: Use a DCGAN on the CelebA dataset to generate images of new and realistic human faces.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-elective-material" class="anchor" aria-hidden="true" href="#elective-material"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Elective Material&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/tensorflow/intro-to-tensorflow"&gt;Intro to TensorFlow&lt;/a&gt;: Starting building neural networks with TensorFlow.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/keras"&gt;Keras&lt;/a&gt;: Learn to build neural networks and convolutional neural networks with Keras.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-configure-and-manage-your-environment-with-anaconda" class="anchor" aria-hidden="true" href="#configure-and-manage-your-environment-with-anaconda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configure and Manage Your Environment with Anaconda&lt;/h2&gt;
&lt;p&gt;Per the Anaconda &lt;a href="http://conda.pydata.org/docs" rel="nofollow"&gt;docs&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Conda is an open source package management system and environment management system
for installing multiple versions of software packages and their dependencies and
switching easily between them. It works on Linux, OS X and Windows, and was created
for Python programs but can package and distribute any software.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overview&lt;/h2&gt;
&lt;p&gt;Using Anaconda consists of the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install &lt;a href="http://conda.pydata.org/miniconda.html" rel="nofollow"&gt;&lt;code&gt;miniconda&lt;/code&gt;&lt;/a&gt; on your computer, by selecting the latest Python version for your operating system. If you already have &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;miniconda&lt;/code&gt; installed, you should be able to skip this step and move on to step 2.&lt;/li&gt;
&lt;li&gt;Create and activate * a new &lt;code&gt;conda&lt;/code&gt; &lt;a href="http://conda.pydata.org/docs/using/envs.html" rel="nofollow"&gt;environment&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;* Each time you wish to work on any exercises, activate your &lt;code&gt;conda&lt;/code&gt; environment!&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-1-installation" class="anchor" aria-hidden="true" href="#1-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Installation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Download&lt;/strong&gt; the latest version of &lt;code&gt;miniconda&lt;/code&gt; that matches your system.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Linux&lt;/th&gt;
&lt;th&gt;Mac&lt;/th&gt;
&lt;th&gt;Windows&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;64-bit&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh" rel="nofollow"&gt;64-bit (bash installer)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-MacOSX-x86_64.sh" rel="nofollow"&gt;64-bit (bash installer)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-Windows-x86_64.exe" rel="nofollow"&gt;64-bit (exe installer)&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;32-bit&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86.sh" rel="nofollow"&gt;32-bit (bash installer)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repo.continuum.io/miniconda/Miniconda3-latest-Windows-x86.exe" rel="nofollow"&gt;32-bit (exe installer)&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Install&lt;/strong&gt; &lt;a href="http://conda.pydata.org/miniconda.html" rel="nofollow"&gt;miniconda&lt;/a&gt; on your machine. Detailed instructions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Linux:&lt;/strong&gt; &lt;a href="http://conda.pydata.org/docs/install/quick.html#linux-miniconda-install" rel="nofollow"&gt;http://conda.pydata.org/docs/install/quick.html#linux-miniconda-install&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mac:&lt;/strong&gt; &lt;a href="http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install" rel="nofollow"&gt;http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Windows:&lt;/strong&gt; &lt;a href="http://conda.pydata.org/docs/install/quick.html#windows-miniconda-install" rel="nofollow"&gt;http://conda.pydata.org/docs/install/quick.html#windows-miniconda-install&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-2-create-and-activate-the-environment" class="anchor" aria-hidden="true" href="#2-create-and-activate-the-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Create and Activate the Environment&lt;/h2&gt;
&lt;p&gt;For Windows users, these following commands need to be executed from the &lt;strong&gt;Anaconda prompt&lt;/strong&gt; as opposed to a Windows terminal window. For Mac, a normal terminal window will work.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-git-and-version-control" class="anchor" aria-hidden="true" href="#git-and-version-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Git and version control&lt;/h4&gt;
&lt;p&gt;These instructions also assume you have &lt;code&gt;git&lt;/code&gt; installed for working with Github from a terminal window, but if you do not, you can download that first with the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you'd like to learn more about version control and using &lt;code&gt;git&lt;/code&gt; from the command line, take a look at our &lt;a href="https://www.udacity.com/course/version-control-with-git--ud123" rel="nofollow"&gt;free course: Version Control with Git&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Now, we're ready to create our local environment!&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Clone the repository, and navigate to the downloaded folder. This may take a minute or two to clone due to the included image data.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/udacity/deep-learning-v2-pytorch.git
cd deep-learning-v2-pytorch
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;
&lt;p&gt;Create (and activate) a new environment, named &lt;code&gt;deep-learning&lt;/code&gt; with Python 3.6. If prompted to proceed with the install &lt;code&gt;(Proceed [y]/n)&lt;/code&gt; type y.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt; or &lt;strong&gt;Mac&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;conda create -n deep-learning python=3.6
source activate deep-learning
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;conda create --name deep-learning python=3.6
activate deep-learning
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point your command line should look something like: &lt;code&gt;(deep-learning) &amp;lt;User&amp;gt;:deep-learning-v2-pytorch &amp;lt;user&amp;gt;$&lt;/code&gt;. The &lt;code&gt;(deep-learning)&lt;/code&gt; indicates that your environment has been activated, and you can proceed with further package installations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install PyTorch and torchvision; this should install the latest version of PyTorch.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt; or &lt;strong&gt;Mac&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;conda install pytorch torchvision -c pytorch 
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;conda install pytorch -c pytorch
pip install torchvision
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install a few required pip packages, which are specified in the requirements text file (including OpenCV).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="7"&gt;
&lt;li&gt;That's it!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now most of the &lt;code&gt;deep-learning&lt;/code&gt; libraries are available to you. Very occasionally, you will see a repository with an addition requirements file, which exists should you want to use TensorFlow and Keras, for example. In this case, you're encouraged to install another library to your existing environment, or create a new environment for a specific project.&lt;/p&gt;
&lt;p&gt;Now, assuming your &lt;code&gt;deep-learning&lt;/code&gt; environment is still activated, you can navigate to the main repo and start looking at the notebooks:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd
cd deep-learning-v2-pytorch
jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To exit the environment when you have completed your work session, simply close the terminal window.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>udacity</author><guid isPermaLink="false">https://github.com/udacity/deep-learning-v2-pytorch</guid><pubDate>Sat, 04 Jan 2020 00:18:00 GMT</pubDate></item><item><title>mahmoud/awesome-python-applications #19 in Jupyter Notebook, This week</title><link>https://github.com/mahmoud/awesome-python-applications</link><description>&lt;p&gt;&lt;i&gt;💿 Free software that works great, and also happens to be open-source Python. &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-awesome-python-applications" class="anchor" aria-hidden="true" href="#awesome-python-applications"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Awesome Python Applications&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Case studies in successfully shipping Python software&lt;/em&gt; &lt;a href="https://raw.githubusercontent.com/mahmoud/awesome-python-applications/master/atom.xml" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/mahmoud/awesome-python-applications/master/templates/rss.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/mahmoud/awesome-python-applications/master/templates/snake_cd.png"&gt;&lt;img src="https://raw.githubusercontent.com/mahmoud/awesome-python-applications/master/templates/snake_cd.png" width="30%" align="right" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As developers, we spend our days with code. The site you're reading
this on is mostly modules, packages, libraries, frameworks, and the
like. But users see applications.&lt;/p&gt;
&lt;p&gt;When building our own applications, open-source Python applications
are a gold mine of practical patterns that we know work together. A
production application is worth a thousand blog posts and Stack
Overflow answers.&lt;/p&gt;
&lt;p&gt;This document is an always-growing list of &lt;strong&gt;385&lt;/strong&gt;
open-source Python applications arranged by topic, with links to
repositories, docs, and more, generated from &lt;a href="https://github.com/mahmoud/awesome-python-applications/blob/master/projects.yaml"&gt;structured
data&lt;/a&gt;
using &lt;a href="https://github.com/mahmoud/apatite"&gt;apatite&lt;/a&gt;. If you have one
to add or find some information missing, &lt;a href="https://github.com/mahmoud/awesome-python-applications/issues"&gt;please let us
know&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Read &lt;a href="http://sedimental.org/awesome_python_applications.html" rel="nofollow"&gt;&lt;strong&gt;the announcement post&lt;/strong&gt;&lt;/a&gt; to learn more about this list.&lt;br&gt;
Subscribe to &lt;a href="https://raw.githubusercontent.com/mahmoud/awesome-python-applications/master/atom.xml" rel="nofollow"&gt;&lt;strong&gt;the RSS/Atom feed&lt;/strong&gt;&lt;/a&gt; to see new applications added.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#tag-internet"&gt;Internet&lt;/a&gt; &lt;em&gt;(32)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-audio"&gt;Audio&lt;/a&gt; &lt;em&gt;(17)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-video"&gt;Video&lt;/a&gt; &lt;em&gt;(7)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-graphics"&gt;Graphics&lt;/a&gt; &lt;em&gt;(20)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-games"&gt;Games&lt;/a&gt; &lt;em&gt;(10)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-productivity"&gt;Productivity&lt;/a&gt; &lt;em&gt;(24)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-organization"&gt;Organization&lt;/a&gt; &lt;em&gt;(38)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-communication"&gt;Communication&lt;/a&gt; &lt;em&gt;(33)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-education"&gt;Education&lt;/a&gt; &lt;em&gt;(8)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-science"&gt;Science&lt;/a&gt; &lt;em&gt;(22)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-cms"&gt;CMS&lt;/a&gt; &lt;em&gt;(11)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-erp"&gt;ERP&lt;/a&gt; &lt;em&gt;(5)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-static_site"&gt;Static Site&lt;/a&gt; &lt;em&gt;(9)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev"&gt;Dev&lt;/a&gt; &lt;em&gt;(166)&lt;/em&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#tag-dev.scm"&gt;SCM&lt;/a&gt; &lt;em&gt;(17)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.code_review"&gt;Code Review&lt;/a&gt; &lt;em&gt;(4)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.storage"&gt;Storage&lt;/a&gt; &lt;em&gt;(16)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.ops"&gt;Ops&lt;/a&gt; &lt;em&gt;(25)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.security"&gt;Security&lt;/a&gt; &lt;em&gt;(24)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.docs"&gt;Docs&lt;/a&gt; &lt;em&gt;(7)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.editor"&gt;Editor&lt;/a&gt; &lt;em&gt;(12)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.pkg_mgr"&gt;Package Managers&lt;/a&gt; &lt;em&gt;(10)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.pkg_repo"&gt;Package Repositories&lt;/a&gt; &lt;em&gt;(5)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.build"&gt;Build&lt;/a&gt; &lt;em&gt;(13)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.shell"&gt;Shell&lt;/a&gt; &lt;em&gt;(3)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev-other"&gt;Other Dev projects&lt;/a&gt; &lt;em&gt;(31)&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-misc"&gt;Misc&lt;/a&gt; &lt;em&gt;(12)&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;&lt;a id="user-content-internet" class="anchor" aria-hidden="true" href="#internet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-internet" href="#tag-internet"&gt;Internet&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ArchiveBox&lt;/strong&gt; - (&lt;a href="https://github.com/pirate/ArchiveBox"&gt;Repo&lt;/a&gt;, &lt;a href="https://archivebox.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/pirate/ArchiveBox/wiki"&gt;Docs&lt;/a&gt;) Self-hosted web archive, for creating local, browsable backups of content from the web. Imports HTML, JS, PDFs, video, subtitles, git repositories, and more, from Pocket, Pinboard, browser history, etc. &lt;code&gt;(organization, linux, windows, docker)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;archivematica&lt;/strong&gt; - (&lt;a href="https://github.com/artefactual/archivematica"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.archivematica.org/en" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.archivematica.org/en/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Digital preservation system designed to maintain standards-based, long-term access to collections of digital objects, targeted at archivists and librarians. &lt;code&gt;(organization, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Canto&lt;/strong&gt; - (&lt;a href="https://github.com/themoken/canto-next"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Canto_%28news_aggregator%29" rel="nofollow"&gt;WP&lt;/a&gt;) RSS daemon and &lt;a href="https://github.com/themoken/canto-curses"&gt;curses-based client&lt;/a&gt;. &lt;code&gt;(linux, tui)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deluge&lt;/strong&gt; - (&lt;a href="https://github.com/deluge-torrent/deluge"&gt;Repo&lt;/a&gt;, &lt;a href="https://deluge-torrent.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Deluge_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.patreon.com/deluge_cas" rel="nofollow"&gt;Fund&lt;/a&gt;) Popular, lightweight, cross-platform BitTorrent client. &lt;code&gt;(linux, windows, mac, server, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Elixire&lt;/strong&gt; - (&lt;a href="https://gitlab.com/elixire/elixire" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://elixi.re/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://gitlab.com/elixire/api-docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Featureful file host and link shortener with API and support for multiple vanity urls. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FlaskBB&lt;/strong&gt; - (&lt;a href="https://github.com/flaskbb/flaskbb"&gt;Repo&lt;/a&gt;, &lt;a href="https://flaskbb.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://forums.flaskbb.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://flaskbb.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) A classic web forum application (bulletin board) with a modern look. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gPodder&lt;/strong&gt; - (&lt;a href="https://github.com/gpodder/gpodder"&gt;Repo&lt;/a&gt;, &lt;a href="https://gpodder.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Simple, mature media aggregator and podcast client. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hosts&lt;/strong&gt; - (&lt;a href="https://github.com/StevenBlack/hosts"&gt;Repo&lt;/a&gt;) Command-line application which merges reputable &lt;a href="https://en.wikipedia.org/wiki/Hosts_(file)" rel="nofollow"&gt;hosts files&lt;/a&gt; with deduplication for the purpose of blocking undesirable websites via DNS blackhole. &lt;code&gt;(security, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;httpie&lt;/strong&gt; - (&lt;a href="https://github.com/jakubroztocil/httpie"&gt;Repo&lt;/a&gt;, &lt;a href="https://httpie.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/httpie" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line HTTP client with JSON support, syntax highlighting, wget-like downloads, extensions, and more. &lt;code&gt;(dev, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Isso&lt;/strong&gt; - (&lt;a href="https://github.com/posativ/isso"&gt;Repo&lt;/a&gt;, &lt;a href="https://posativ.org/isso" rel="nofollow"&gt;Home&lt;/a&gt;) Lightweight commenting server, designed as a drop-in replacement for Disqus. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;KindleEar&lt;/strong&gt; - (&lt;a href="https://github.com/cdhigh/KindleEar"&gt;Repo&lt;/a&gt;, &lt;a href="https://github.com/cdhigh/KindleEar/blob/master/readme_EN.md"&gt;Docs&lt;/a&gt;) Web application to automatically aggregate RSS into periodical mobi/epub files with images and send it to your kindle or your email. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mylar&lt;/strong&gt; - (&lt;a href="https://github.com/evilhero/mylar"&gt;Repo&lt;/a&gt;) A web-based automated comic book downloader (cbr/cbz) for use with SABnzbd, NZBGet, and torrents. &lt;code&gt;(graphics, linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Neubot&lt;/strong&gt; - (&lt;a href="https://github.com/neubot/neubot"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.neubot.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Lightweight agent which collects data for net-neutrality research. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NewsBlur&lt;/strong&gt; - (&lt;a href="https://github.com/samuelclay/NewsBlur"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.newsblur.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Web-based personal news reader. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Newspipe&lt;/strong&gt; - (&lt;a href="https://gitlab.com/newspipe/newspipe" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://newspipe.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.newspipe.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://github.com/newspipe/newspipe"&gt;gh&lt;/a&gt;, &lt;a href="https://newspipe.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based news aggregator and reader. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nsupdate.info&lt;/strong&gt; - (&lt;a href="https://github.com/nsupdate-info/nsupdate.info"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/nsupdate" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://nsupdateinfo.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Featureful dynamic DNS service, using the Dynamic DNS UPDATE protocol (&lt;a href="https://tools.ietf.org/html/rfc2136" rel="nofollow"&gt;RFC 2136&lt;/a&gt;) to update BIND and other major nameservers. &lt;code&gt;(ops, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nyaa&lt;/strong&gt; - (&lt;a href="https://github.com/nyaadevs/nyaa"&gt;Repo&lt;/a&gt;) Bittorrent tracker software built for anime site &lt;a href="https://nyaa.si/" rel="nofollow"&gt;nyaa.si&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pi-Hole&lt;/strong&gt; - (&lt;a href="https://github.com/pi-hole/pi-hole"&gt;Repo&lt;/a&gt;, &lt;a href="https://pi-hole.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Pi-hole" rel="nofollow"&gt;WP&lt;/a&gt;) Linux network-level advertisement and internet tracker blocking application which acts as a DNS sinkhole, and (optionally) a DHCP server, intended for use on a private network. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Planet&lt;/strong&gt; - (&lt;a href="https://github.com/python/planet"&gt;Repo&lt;/a&gt;, &lt;a href="https://web.archive.org/web/20051029095046/http%3A/www.planetplanet.org" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Planet_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) RSS and Atom feed aggregator, designed to collect posts from the weblogs of members of an Internet community and display them on a single page. Used to power &lt;a href="https://planetpython.org/" rel="nofollow"&gt;Planet Python&lt;/a&gt; and many more. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pol&lt;/strong&gt; - (&lt;a href="https://github.com/taroved/pol"&gt;Repo&lt;/a&gt;, &lt;a href="https://politepol.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Web application which allows users to subscribe to changes on a web site via an autogenerated RSS feed. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyLoad&lt;/strong&gt; - (&lt;a href="https://github.com/pyload/pyload"&gt;Repo&lt;/a&gt;, &lt;a href="https://pyload.net/" rel="nofollow"&gt;Home&lt;/a&gt;) Download manager with a web interface and API. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Qute Browser&lt;/strong&gt; - (&lt;a href="https://github.com/qutebrowser/qutebrowser"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.qutebrowser.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Keyboard-driven, minimal, &lt;code&gt;vim&lt;/code&gt;-like browser based on PyQt5. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reddit&lt;/strong&gt; - (&lt;a href="https://github.com/reddit-archive/reddit"&gt;Repo&lt;/a&gt;, &lt;a href="http://reddit.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Social news forum with voting, commenting, karma, and more. (Archival repo from 2017.) &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SABnzbd&lt;/strong&gt; - (&lt;a href="https://github.com/sabnzbd/sabnzbd"&gt;Repo&lt;/a&gt;, &lt;a href="https://sabnzbd.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://sabnzbd.org/wiki" rel="nofollow"&gt;Docs&lt;/a&gt;) Simple, cross-platform newsreader for downloading from Usenet. Supports many integrations and 16 languages. &lt;code&gt;(linux, windows, mac, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Searx&lt;/strong&gt; - (&lt;a href="https://github.com/asciimoo/searx"&gt;Repo&lt;/a&gt;, &lt;a href="https://asciimoo.github.io/searx" rel="nofollow"&gt;Docs&lt;/a&gt;) Self-hosted metasearch engine, aggregating results from more than 70 services while avoiding tracking and profiling. &lt;code&gt;(security, server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;speedtest-cli&lt;/strong&gt; - (&lt;a href="https://github.com/sivel/speedtest-cli"&gt;Repo&lt;/a&gt;) Command-line interface for testing Internet bandwidth using &lt;a href="https://speedtest.net" rel="nofollow"&gt;speedtest.net&lt;/a&gt;. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;streamlink&lt;/strong&gt; - (&lt;a href="https://github.com/streamlink/streamlink"&gt;Repo&lt;/a&gt;, &lt;a href="https://streamlink.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/streamlink" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line utility that extracts streams from various services and pipes them into a video player of choice. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;syncserver&lt;/strong&gt; - (&lt;a href="https://github.com/mozilla-services/syncserver"&gt;Repo&lt;/a&gt;, &lt;a href="https://mozilla-services.readthedocs.io/en/latest/howtos/run-sync-1.5.html" rel="nofollow"&gt;Docs&lt;/a&gt;) All-in-one package for running a self-hosted Mozilla Firefox Sync server. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tribler&lt;/strong&gt; - (&lt;a href="https://github.com/Tribler/tribler"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.tribler.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Tribler" rel="nofollow"&gt;WP&lt;/a&gt;) Privacy enhanced BitTorrent client with P2P content discovery. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;You-Get&lt;/strong&gt; - (&lt;a href="https://github.com/soimort/you-get"&gt;Repo&lt;/a&gt;, &lt;a href="https://you-get.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Command-line program to browserlessly scrape and stream video, audio, and images from web sites. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;youtube-dl&lt;/strong&gt; - (&lt;a href="https://github.com/rg3/youtube-dl"&gt;Repo&lt;/a&gt;, &lt;a href="http://rg3.github.io/youtube-dl" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/youtube_dl" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line program to browserlessly archive video and audio from YouTube and hundreds of other sites. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ZeroNet&lt;/strong&gt; - (&lt;a href="https://github.com/HelloZeroNet/ZeroNet"&gt;Repo&lt;/a&gt;, &lt;a href="https://zeronet.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/ZeroNet" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://zeronet.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Open, free, and uncensorable websites, using Bitcoin cryptography and BitTorrent network. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-audio" class="anchor" aria-hidden="true" href="#audio"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-audio" href="#tag-audio"&gt;Audio&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Beets&lt;/strong&gt; - (&lt;a href="https://github.com/beetbox/beets"&gt;Repo&lt;/a&gt;, &lt;a href="http://beets.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/beets" rel="nofollow"&gt;PyPI&lt;/a&gt;) Feature-rich command-line music library manager with web UI, duplicate detection, transcoding, and tagging support, integrating with MusicBrainz, Discogs, and more. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exaile&lt;/strong&gt; - (&lt;a href="https://github.com/exaile/exaile"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Exaile" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform audio player, tag editor, and library organizer. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Frescobaldi&lt;/strong&gt; - (&lt;a href="https://github.com/wbsoft/frescobaldi"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Frescobaldi_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) An editor for &lt;a href="https://en.wikipedia.org/wiki/LilyPond" rel="nofollow"&gt;LilyPond&lt;/a&gt; music files. &lt;code&gt;(linux, windows, mac, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Friture&lt;/strong&gt; - (&lt;a href="https://github.com/tlecomte/friture"&gt;Repo&lt;/a&gt;, &lt;a href="http://friture.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Visualizes and analyzes live audio data in real-time, including scope, spectrum analyzer, rolling 2D spectrogram, and more. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Funkwhale&lt;/strong&gt; - (&lt;a href="https://dev.funkwhale.audio/funkwhale/funkwhale" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://funkwhale.audio/en_US" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.funkwhale.audio/" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based, community-driven project that lets you listen and share music and audio within a decentralized, open network. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GNU Radio&lt;/strong&gt; - (&lt;a href="https://github.com/gnuradio/gnuradio"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.gnuradio.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GNU_Radio" rel="nofollow"&gt;WP&lt;/a&gt;) Software development toolkit that provides signal processing blocks to implement software-defined radios and signal-processing systems. &lt;code&gt;(linux, windows, mac, cpp, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GNU Solfege&lt;/strong&gt; - (&lt;a href="http://git.savannah.gnu.org/cgit/solfege.git" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GNU_Solfege" rel="nofollow"&gt;WP&lt;/a&gt;) An ear-training program intended to help musicians improve their skills. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mopidy&lt;/strong&gt; - (&lt;a href="https://github.com/mopidy/mopidy"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.mopidy.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Extensible music player server with plugin support for a wide range of services. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Music Player&lt;/strong&gt; - (&lt;a href="https://github.com/albertz/music-player"&gt;Repo&lt;/a&gt;, &lt;a href="http://albertz.github.io/music-player" rel="nofollow"&gt;Home&lt;/a&gt;) A simple music player designed around an infinite intelligent playlist, with support for headless playback. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MusicBrainz Picard&lt;/strong&gt; - (&lt;a href="https://github.com/metabrainz/picard"&gt;Repo&lt;/a&gt;, &lt;a href="https://picard.musicbrainz.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/MusicBrainz_Picard" rel="nofollow"&gt;WP&lt;/a&gt;) Automatically identify, tag, and organize music albums and other digital audio recordings. &lt;code&gt;(linux, windows, mac, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Musikernel&lt;/strong&gt; - (&lt;a href="https://github.com/j3ffhubb/musikernel"&gt;Repo&lt;/a&gt;) All-in-one Digital Audio Workstation (DAW) with a suite of instrument and effect plugins. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PuddleTag&lt;/strong&gt; - (&lt;a href="https://github.com/keithgg/puddletag"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Puddletag" rel="nofollow"&gt;WP&lt;/a&gt;) An audio tag (metadata) editor for audio file formats. &lt;code&gt;(linux, qt4)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quod Libet&lt;/strong&gt; - (&lt;a href="https://github.com/quodlibet/quodlibet"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Quod_Libet_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform audio player, tag editor, and library organizer. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SoundConverter&lt;/strong&gt; - (&lt;a href="https://github.com/kassoulet/soundconverter"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GNOME_SoundConverter" rel="nofollow"&gt;WP&lt;/a&gt;) A GNOME-based audio file transcoder. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SoundGrain&lt;/strong&gt; - (&lt;a href="https://github.com/belangeo/soundgrain"&gt;Repo&lt;/a&gt;, &lt;a href="http://ajaxsoundstudio.com/software/soundgrain" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=9CA99DH6ES3HA" rel="nofollow"&gt;Fund&lt;/a&gt;) Graphical interface designed for drawing and editing trajectories to control &lt;a href="https://en.wikipedia.org/wiki/Granular_synthesis" rel="nofollow"&gt;granular sound synthesis&lt;/a&gt;. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Supysonic&lt;/strong&gt; - (&lt;a href="https://github.com/spl0k/supysonic"&gt;Repo&lt;/a&gt;) Implementation of the &lt;a href="http://www.subsonic.org/" rel="nofollow"&gt;Subsonic server API&lt;/a&gt;, with support for browsing, streaming, transcoding, scrobbling, and more. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Whipper&lt;/strong&gt; - (&lt;a href="https://github.com/whipper-team/whipper"&gt;Repo&lt;/a&gt;) A CLI-based CD Audio ripper designed for accuracy over speed, with support for overriding hardware caches, accuracy verification, MusicBrainz metadata lookup, hidden tracks, FLAC, and much more. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-video" class="anchor" aria-hidden="true" href="#video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-video" href="#tag-video"&gt;Video&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Flowblade&lt;/strong&gt; - (&lt;a href="https://github.com/jliljebl/flowblade"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Flowblade" rel="nofollow"&gt;WP&lt;/a&gt;) Multitrack, non-linear video editing software for Linux. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Open Streaming Platform&lt;/strong&gt; - (&lt;a href="https://gitlab.com/Deamos/flask-nginx-rtmp-manager" rel="nofollow"&gt;Repo&lt;/a&gt;) Self-hosted video streaming and recording server, designed as an alternative to Twitch and YouTube. &lt;code&gt;(games, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenShot&lt;/strong&gt; - (&lt;a href="https://github.com/OpenShot/openshot-qt"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.openshot.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/OpenShot" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.patreon.com/openshot" rel="nofollow"&gt;Fund&lt;/a&gt;) A cross-platform video editor for FreeBSD, Linux, macOS, and Windows. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pitivi&lt;/strong&gt; - (&lt;a href="https://gitlab.gnome.org/GNOME/pitivi" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Pitivi" rel="nofollow"&gt;WP&lt;/a&gt;) Non-linear video editor for Linux, based on GStreamer. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plumi&lt;/strong&gt; - (&lt;a href="https://github.com/plumi/plumi.app"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Plumi" rel="nofollow"&gt;WP&lt;/a&gt;) Video sharing content management system based on &lt;a href="https://en.wikipedia.org/wiki/Plone_(software)" rel="nofollow"&gt;Plone&lt;/a&gt;. &lt;code&gt;(cms, server, plone)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyVideo&lt;/strong&gt; - (&lt;a href="https://github.com/pyvideo/pyvideo"&gt;Repo&lt;/a&gt;, &lt;a href="https://pyvideo.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Static media index custom-built for the Python community, and all the content our meetings and conferences produce. &lt;code&gt;(static_site, linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vidcutter&lt;/strong&gt; - (&lt;a href="https://github.com/ozmartian/vidcutter"&gt;Repo&lt;/a&gt;) GUI and CLI aiming to be the fastest and simplest way to cut and join video. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-graphics" class="anchor" aria-hidden="true" href="#graphics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-graphics" href="#tag-graphics"&gt;Graphics&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;cartoonify / Draw This.&lt;/strong&gt; - (&lt;a href="https://github.com/danmacnish/cartoonify"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.kapwing.com/cartoonify" rel="nofollow"&gt;Home&lt;/a&gt;) Turn a photograph into a toddler's drawing. Automatically! &lt;code&gt;(console, docker, hardware)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cura&lt;/strong&gt; - (&lt;a href="https://github.com/Ultimaker/Cura"&gt;Repo&lt;/a&gt;, &lt;a href="https://ultimaker.com/software/ultimaker-cura" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Cura_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://ultimaker.com/en/resources/manuals/software" rel="nofollow"&gt;Docs&lt;/a&gt;) Popular desktop software for preparation and control of 3D printing, integrated with CAD workflows. &lt;code&gt;(linux, windows, mac, corp, hardware)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DrawBot&lt;/strong&gt; - (&lt;a href="https://github.com/typemytype/drawbot"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.drawbot.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/DrawBot" rel="nofollow"&gt;WP&lt;/a&gt;) A powerful programmatic 2D drawing application for MacOS X which generates graphics from Python scripts. &lt;code&gt;(education, dev, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FreeCAD&lt;/strong&gt; - (&lt;a href="https://github.com/FreeCAD/FreeCAD"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/FreeCAD" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://salt.bountysource.com/teams/freecad" rel="nofollow"&gt;Fund&lt;/a&gt;) General-purpose parametric 3D CAD modeler and a building information modeling (BIM) software with finite-element-method (FEM) support. &lt;code&gt;(linux, windows, mac, cpp, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gaphor&lt;/strong&gt; - (&lt;a href="https://github.com/gaphor/gaphor"&gt;Repo&lt;/a&gt;, &lt;a href="https://gaphor.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Simple &lt;a href="https://en.wikipedia.org/wiki/Unified_Modeling_Language" rel="nofollow"&gt;UML&lt;/a&gt; modeling tool designed for beginners. &lt;code&gt;(docs, linux, windows, mac, flatpak, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lector&lt;/strong&gt; - (&lt;a href="https://github.com/BasioMeusPuga/Lector"&gt;Repo&lt;/a&gt;) Desktop ebook reader and browser, with support for many formats, including comic book archives. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MakeHuman&lt;/strong&gt; - (&lt;a href="https://bitbucket.org/MakeHuman/makehuman" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/MakeHuman" rel="nofollow"&gt;WP&lt;/a&gt;) 3D computer graphics software designed for the prototyping of photo realistic humanoids. &lt;code&gt;(linux, windows, mac, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Meshroom&lt;/strong&gt; - (&lt;a href="https://github.com/alicevision/meshroom"&gt;Repo&lt;/a&gt;, &lt;a href="http://alicevision.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Photogrammetry pipeline, for turning photographs into 3D models. &lt;code&gt;(linux, windows, mac, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mylar&lt;/strong&gt; - (&lt;a href="https://github.com/evilhero/mylar"&gt;Repo&lt;/a&gt;) A web-based automated comic book downloader (cbr/cbz) for use with SABnzbd, NZBGet, and torrents. &lt;code&gt;(internet, linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MyPaint&lt;/strong&gt; - (&lt;a href="https://github.com/mypaint/mypaint"&gt;Repo&lt;/a&gt;, &lt;a href="http://mypaint.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/MyPaint" rel="nofollow"&gt;WP&lt;/a&gt;) Raster graphics editor for digital painters with a focus on painting rather than image manipulation. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NFO Viewer&lt;/strong&gt; - (&lt;a href="https://github.com/otsaloma/nfoview"&gt;Repo&lt;/a&gt;, &lt;a href="https://otsaloma.io/nfoview" rel="nofollow"&gt;Home&lt;/a&gt;) A simple viewer for NFO files and the ASCII art therein, with preset fonts, encodings, automatic window sizing, and clickable hyperlinks. &lt;code&gt;(misc, linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OCRFeeder&lt;/strong&gt; - (&lt;a href="https://gitlab.gnome.org/GNOME/ocrfeeder" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/OCRFeeder" rel="nofollow"&gt;WP&lt;/a&gt;) An optical character recognition suite for GNOME, with support for command-line OCR engines like CuneiForm, GOCR, Ocrad and Tesseract. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OCRopus&lt;/strong&gt; - (&lt;a href="https://github.com/tmbdev/ocropy"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/OCRopus" rel="nofollow"&gt;WP&lt;/a&gt;) Document analysis and optical character recognition (OCR) system. &lt;code&gt;(linux, mac, console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Octoprint&lt;/strong&gt; - (&lt;a href="https://github.com/foosel/OctoPrint"&gt;Repo&lt;/a&gt;, &lt;a href="https://octoprint.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.patreon.com/foosel" rel="nofollow"&gt;Fund&lt;/a&gt;) Web-based controller for consumer 3D printers. &lt;code&gt;(server, flask, hardware)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PhotoCollage&lt;/strong&gt; - (&lt;a href="https://github.com/adrienverge/PhotoCollage"&gt;Repo&lt;/a&gt;) Automatically lays out a photo collage to fill out a given poster space. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Photonix&lt;/strong&gt; - (&lt;a href="https://github.com/damianmoore/photonix"&gt;Repo&lt;/a&gt;, &lt;a href="https://photonix.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://demo.photonix.org/" rel="nofollow"&gt;Demo&lt;/a&gt;) Web-based photo management, featuring smart filtering with object recognition, location awareness, color analysis, and more. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pynocchio&lt;/strong&gt; - (&lt;a href="https://github.com/mstuttgart/pynocchio"&gt;Repo&lt;/a&gt;, &lt;a href="https://mstuttgart.github.io/pynocchio" rel="nofollow"&gt;Home&lt;/a&gt;) Minimalist comic reader, supporting many common image and archive formats. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quru Image Server&lt;/strong&gt; - (&lt;a href="https://github.com/quru/qis"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.quruimageserver.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://images.quru.com/demo" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://github.com/quru/qis/blob/master/doc/overview.md"&gt;Docs&lt;/a&gt;) High-performance web server for creating and delivering dynamic images. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SK1&lt;/strong&gt; - (&lt;a href="https://github.com/sk1project/sk1-wx"&gt;Repo&lt;/a&gt;, &lt;a href="https://sk1project.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/SK1_%28program%29" rel="nofollow"&gt;WP&lt;/a&gt;) Feature-rich, cross-platform illustration program. &lt;code&gt;(linux, windows, mac, gtk, wx)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Thumbor&lt;/strong&gt; - (&lt;a href="https://github.com/thumbor/thumbor"&gt;Repo&lt;/a&gt;, &lt;a href="http://thumbor.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://thumbor.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Photo thumbnail service with resizing, flipping, and smart cropping of images. &lt;code&gt;(dev, server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-games" class="anchor" aria-hidden="true" href="#games"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-games" href="#tag-games"&gt;Games&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Cataclysm: Dark Days Ahead (Launcher)&lt;/strong&gt; - (&lt;a href="https://github.com/remyroy/CDDA-Game-Launcher"&gt;Repo&lt;/a&gt;, &lt;a href="https://cataclysmdda.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Launcher for popular FOSS game &lt;a href="https://cataclysmdda.org/" rel="nofollow"&gt;CDDA&lt;/a&gt;, which supports automatic updates and mod management. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Frets on Fire X&lt;/strong&gt; - (&lt;a href="https://github.com/fofix/fofix"&gt;Repo&lt;/a&gt;) Highly customizable rhythm game supporting many modes of guitar, bass, drum, and vocal gameplay for up to four players. &lt;code&gt;(linux, windows, pygame)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lucas Chess&lt;/strong&gt; - (&lt;a href="https://github.com/lukasmonk/lucaschess"&gt;Repo&lt;/a&gt;, &lt;a href="http://lucaschess.pythonanywhere.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Featureful chess client for Windows, with some Linux support. &lt;code&gt;(linux, windows, qt4)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lutris&lt;/strong&gt; - (&lt;a href="https://github.com/lutris/lutris"&gt;Repo&lt;/a&gt;, &lt;a href="https://lutris.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Lutris" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.patreon.com/lutris" rel="nofollow"&gt;Fund&lt;/a&gt;) Gaming platform for GNU/Linux, managing game installations with a unified interface. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Open Streaming Platform&lt;/strong&gt; - (&lt;a href="https://gitlab.com/Deamos/flask-nginx-rtmp-manager" rel="nofollow"&gt;Repo&lt;/a&gt;) Self-hosted video streaming and recording server, designed as an alternative to Twitch and YouTube. &lt;code&gt;(video, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyChess&lt;/strong&gt; - (&lt;a href="https://github.com/pychess/pychess"&gt;Repo&lt;/a&gt;, &lt;a href="http://pychess.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/PyChess" rel="nofollow"&gt;WP&lt;/a&gt;) Advanced chess client, suitable for new, casual, and competitive play. &lt;code&gt;(linux, windows, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pyfa&lt;/strong&gt; - (&lt;a href="https://github.com/pyfa-org/Pyfa"&gt;Repo&lt;/a&gt;) Python Fitting Assistant, cross-platform experimentation tool for &lt;a href="https://en.wikipedia.org/wiki/Eve_Online" rel="nofollow"&gt;EVE Online&lt;/a&gt; ship fittings. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PySolFC&lt;/strong&gt; - (&lt;a href="https://github.com/shlomif/PySolFC"&gt;Repo&lt;/a&gt;, &lt;a href="https://pysolfc.sourceforge.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://f-droid.org/en/packages/org.lufebe16.pysolfc" rel="nofollow"&gt;Android&lt;/a&gt;) Highly-portable collection of solitaire card games. &lt;code&gt;(linux, windows, android, kivy, tk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;term2048&lt;/strong&gt; - (&lt;a href="https://github.com/bfontaine/term2048"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.python.org/pypi/term2048" rel="nofollow"&gt;PyPI&lt;/a&gt;) TUI version of &lt;a href="http://gabrielecirulli.github.io/2048/" rel="nofollow"&gt;2048&lt;/a&gt;. &lt;code&gt;(linux, mac, tui)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unknown Horizons&lt;/strong&gt; - (&lt;a href="https://github.com/unknown-horizons/unknown-horizons"&gt;Repo&lt;/a&gt;, &lt;a href="http://unknown-horizons.org/" rel="nofollow"&gt;Home&lt;/a&gt;) 2D real-time strategy simulation with an emphasis on economy and city building. (Not unlike Age of Empires) &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-productivity" class="anchor" aria-hidden="true" href="#productivity"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-productivity" href="#tag-productivity"&gt;Productivity&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Autokey&lt;/strong&gt; - (&lt;a href="https://github.com/autokey/autokey"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/AutoKey" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://pypi.org/project/autokey" rel="nofollow"&gt;PyPI&lt;/a&gt;) Desktop automation utility for Linux and X11. &lt;code&gt;(linux, gtk, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bleachbit&lt;/strong&gt; - (&lt;a href="https://github.com/bleachbit/bleachbit"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.bleachbit.org/" rel="nofollow"&gt;Home&lt;/a&gt;) System cleaner designed to free disk space and maintain privacy. &lt;code&gt;(linux, windows, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BorgBackup&lt;/strong&gt; - (&lt;a href="https://github.com/borgbackup/borg"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.borgbackup.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Deduplicating backup system with optional encryption and other features. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bup&lt;/strong&gt; - (&lt;a href="https://github.com/Bup/Bup"&gt;Repo&lt;/a&gt;, &lt;a href="https://bup.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Efficient backup system based on the git packfile format, providing fast incremental saves and global deduplication. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Excalibur&lt;/strong&gt; - (&lt;a href="https://github.com/camelot-dev/excalibur"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.tryexcalibur.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Web interface to extract tabular data from PDFs. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Glances&lt;/strong&gt; - (&lt;a href="https://github.com/nicolargo/glances"&gt;Repo&lt;/a&gt;, &lt;a href="https://nicolargo.github.io/glances" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://glances.readthedocs.io/en/stable" rel="nofollow"&gt;Docs&lt;/a&gt;) A cross-platform top/htop alternative, providing an overview of system resources. &lt;code&gt;(ops, linux, windows, mac, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gmvault&lt;/strong&gt; - (&lt;a href="https://github.com/gaubert/gmvault"&gt;Repo&lt;/a&gt;, &lt;a href="http://gmvault.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Tool for backing up gmail accounts. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gridsync&lt;/strong&gt; - (&lt;a href="https://github.com/gridsync/gridsync"&gt;Repo&lt;/a&gt;) Cross-platform GUI built to synchronize local directories with Tahoe-LAFS storage grids. &lt;code&gt;(storage, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GTimeLog&lt;/strong&gt; - (&lt;a href="https://github.com/gtimelog/gtimelog"&gt;Repo&lt;/a&gt;, &lt;a href="https://gtimelog.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://ko-fi.com/mgedmin" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://gtimelog.org/docs.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Desktop-based time tracker with support for logging billable/non-billable work. &lt;code&gt;(organization, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kibitzr&lt;/strong&gt; - (&lt;a href="https://github.com/kibitzr/kibitzr"&gt;Repo&lt;/a&gt;, &lt;a href="https://kibitzr.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/kibitzr" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://kibitzr.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Self-hosted personal assistant server for automating routine tasks. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mackup&lt;/strong&gt; - (&lt;a href="https://github.com/lra/mackup"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/mackup" rel="nofollow"&gt;PyPI&lt;/a&gt;) Utility to back up and synchronize application settings, with support for several storage backends (e.g., Dropbox, Git), and dozens of applications. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Metamorphose&lt;/strong&gt; - (&lt;a href="https://github.com/metamorphose/metamorphose2"&gt;Repo&lt;/a&gt;, &lt;a href="http://file-folder-ren.sourceforge.net/" rel="nofollow"&gt;Home&lt;/a&gt;) Graphical mass renaming program for files and folders. &lt;code&gt;(linux, windows, mac, wx)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nuxeo Drive&lt;/strong&gt; - (&lt;a href="https://github.com/nuxeo/nuxeo-drive"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.nuxeo.com/products/drive-desktop-sync" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://doc.nuxeo.com/client-apps/nuxeo-drive" rel="nofollow"&gt;Docs&lt;/a&gt;) Cross-platform desktop synchronization client for the Nuxeo platform. &lt;code&gt;(storage, linux, windows, mac, console, appimage, lgpl, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nvda&lt;/strong&gt; - (&lt;a href="https://github.com/nvaccess/nvda"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.nvaccess.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Non-Visual Desktop Access, a powerful screen reader for Windows. &lt;code&gt;(windows, wx)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plover&lt;/strong&gt; - (&lt;a href="https://github.com/openstenoproject/plover"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.openstenoproject.org/plover" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.openstenoproject.org/donate" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://github.com/openstenoproject/plover/wiki"&gt;Docs&lt;/a&gt;) Background service for automatic translation of stenography movements to keystrokes, enabling typing speeds in excess of 200WPM in any application. &lt;code&gt;(linux, windows, mac, hardware, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Psono&lt;/strong&gt; - (&lt;a href="https://gitlab.com/psono/psono-server" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://psono.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.psono.pw/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://doc.psono.com/" rel="nofollow"&gt;Docs&lt;/a&gt;) Server-based password manager, built for teams. &lt;code&gt;(security, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ranger&lt;/strong&gt; - (&lt;a href="https://github.com/ranger/ranger"&gt;Repo&lt;/a&gt;, &lt;a href="https://ranger.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;) TUI (&lt;a href="https://en.wikipedia.org/wiki/Text-based_user_interface" rel="nofollow"&gt;Text User Interface&lt;/a&gt;) file manager, inspired by vim. &lt;code&gt;(linux, tui)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Redash&lt;/strong&gt; - (&lt;a href="https://github.com/getredash/redash"&gt;Repo&lt;/a&gt;, &lt;a href="https://redash.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Data visualization and dashboard construction geared toward business intelligence, used by Mozilla, SoundCloud, Sentry, and others. &lt;code&gt;(server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ReproZip&lt;/strong&gt; - (&lt;a href="https://github.com/VIDA-NYU/reprozip"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.reprozip.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://examples.reprozip.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://docs.reprozip.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Command-line tool which automatically builds reproducible experiments archives from console commands, designed for use in computational science. &lt;code&gt;(science, linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sunflower&lt;/strong&gt; - (&lt;a href="https://github.com/MeanEYE/Sunflower"&gt;Repo&lt;/a&gt;, &lt;a href="http://sunflower-fm.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Small and highly-customizable twin-panel file manager for Linux with plugin support. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Superset&lt;/strong&gt; - (&lt;a href="https://github.com/apache/incubator-superset"&gt;Repo&lt;/a&gt;, &lt;a href="http://superset.apache.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Data exploration, visualization, and business intelligence web application. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VisiData&lt;/strong&gt; - (&lt;a href="https://github.com/saulpw/visidata"&gt;Repo&lt;/a&gt;, &lt;a href="https://visidata.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://patreon.com/saulpw" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://pypi.org/project/visidata" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://visidata.org/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Interactive multitool for exploring, analyzing, and converting datasets in the terminal. &lt;code&gt;(linux, mac, tui)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vorta&lt;/strong&gt; - (&lt;a href="https://github.com/borgbase/vorta"&gt;Repo&lt;/a&gt;, &lt;a href="https://vorta.borgbase.com/" rel="nofollow"&gt;Home&lt;/a&gt;) GUI backup client built on top of &lt;a href="https://borgbackup.readthedocs.io/" rel="nofollow"&gt;BorgBackup&lt;/a&gt;. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;wttr.in&lt;/strong&gt; - (&lt;a href="https://github.com/chubin/wttr.in"&gt;Repo&lt;/a&gt;, &lt;a href="http://wttr.in/" rel="nofollow"&gt;Home&lt;/a&gt;) Weather forecast service that supports various representations, suitable for the terminal or web browser. &lt;code&gt;(server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-organization" class="anchor" aria-hidden="true" href="#organization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-organization" href="#tag-organization"&gt;Organization&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Ambar&lt;/strong&gt; - (&lt;a href="https://github.com/RD17/ambar"&gt;Repo&lt;/a&gt;, &lt;a href="https://ambar.cloud/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://app.ambar.cloud/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://ambar.cloud/docs/system-requirements" rel="nofollow"&gt;Docs&lt;/a&gt;) Document search engine with automated crawling, OCR, tagging, and instant full-text search. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ArchiveBox&lt;/strong&gt; - (&lt;a href="https://github.com/pirate/ArchiveBox"&gt;Repo&lt;/a&gt;, &lt;a href="https://archivebox.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/pirate/ArchiveBox/wiki"&gt;Docs&lt;/a&gt;) Self-hosted web archive, for creating local, browsable backups of content from the web. Imports HTML, JS, PDFs, video, subtitles, git repositories, and more, from Pocket, Pinboard, browser history, etc. &lt;code&gt;(internet, linux, windows, docker)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;archivematica&lt;/strong&gt; - (&lt;a href="https://github.com/artefactual/archivematica"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.archivematica.org/en" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.archivematica.org/en/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Digital preservation system designed to maintain standards-based, long-term access to collections of digital objects, targeted at archivists and librarians. &lt;code&gt;(internet, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Baby Buddy&lt;/strong&gt; - (&lt;a href="https://github.com/cdubz/babybuddy"&gt;Repo&lt;/a&gt;, &lt;a href="http://demo.baby-buddy.net/" rel="nofollow"&gt;Demo&lt;/a&gt;) Mobile-friendly web application which helps caregivers track sleep, feedings, diaper changes, and tummy time to learn about and predict baby's needs without (as much) guesswork. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;beancount&lt;/strong&gt; - (&lt;a href="https://bitbucket.org/blais/beancount" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://furius.ca/beancount" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/beancount/beancount"&gt;gh&lt;/a&gt;, &lt;a href="https://pypi.org/project/beancount" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://docs.google.com/document/d/1RaondTJCS_IUPBHFNdT8oqFKJjVJDsfsn6JEjBG04eA/edit" rel="nofollow"&gt;Docs&lt;/a&gt;) A double-entry bookkeeping language to define financial transaction records in plain text, then generate a variety of reports, via CLI and web interface. (See also, &lt;a href="https://plaintextaccounting.org/" rel="nofollow"&gt;Plain Text Accounting&lt;/a&gt;). &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Byro&lt;/strong&gt; - (&lt;a href="https://github.com/byro/byro"&gt;Repo&lt;/a&gt;, &lt;a href="https://byro.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based membership administration tool for small and medium sized clubs/NGOs/associations of all kinds, with a focus on the DACH region. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Calibre&lt;/strong&gt; - (&lt;a href="https://github.com/kovidgoyal/calibre"&gt;Repo&lt;/a&gt;, &lt;a href="https://calibre-ebook.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Calibre_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.patreon.com/kovidgoyal" rel="nofollow"&gt;Fund&lt;/a&gt;) E-book manager designed for viewing, converting, editing, and cataloging e-books in all major formats. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Calibre-Web&lt;/strong&gt; - (&lt;a href="https://github.com/janeczku/calibre-web"&gt;Repo&lt;/a&gt;) Web application providing a clean interface for browsing, reading, and downloading ebooks using an existing &lt;a href="https://calibre-ebook.com/" rel="nofollow"&gt;Calibre&lt;/a&gt; database. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CherryTree&lt;/strong&gt; - (&lt;a href="https://github.com/giuspen/cherrytree"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.giuspen.com/cherrytree" rel="nofollow"&gt;Home&lt;/a&gt;) Hierarchical wiki-like personal notepad, featuring rich text and syntax highlighting. &lt;code&gt;(linux, windows, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Collaborate&lt;/strong&gt; - (&lt;a href="https://github.com/propublica/django-collaborative"&gt;Repo&lt;/a&gt;, &lt;a href="https://propublica.gitbook.io/collaborate-user-manual" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based collaboration tool designed by &lt;a href="https://www.propublica.org/nerds/making-collaborative-data-projects-easier-our-new-tool-collaborate-is-here" rel="nofollow"&gt;Propublica&lt;/a&gt; for newsrooms to share datasets, with a workflow built around assigning tips and maintaining contacts. &lt;code&gt;(communication, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CouchPotato&lt;/strong&gt; - (&lt;a href="https://github.com/CouchPotato/CouchPotatoServer"&gt;Repo&lt;/a&gt;, &lt;a href="http://couchpota.to/" rel="nofollow"&gt;Home&lt;/a&gt;) Personal video recorder focused on movies, with support for usenet and torrents. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dupeGuru&lt;/strong&gt; - (&lt;a href="https://github.com/arsenetar/dupeguru"&gt;Repo&lt;/a&gt;, &lt;a href="https://dupeguru.voltaicideas.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://dupeguru.voltaicideas.net/help/en" rel="nofollow"&gt;Docs&lt;/a&gt;) Cross-platform GUI tool to find duplicate files. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dvc (Data Version Control)&lt;/strong&gt; - (&lt;a href="https://github.com/iterative/dvc"&gt;Repo&lt;/a&gt;, &lt;a href="https://dvc.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://dvc.org/doc" rel="nofollow"&gt;Docs&lt;/a&gt;) Command-line tool for version control over data used in machine learning projects. Aims to replace Excel and other tools used to track and deploy model versions. &lt;code&gt;(scm, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fava&lt;/strong&gt; - (&lt;a href="https://github.com/beancount/fava"&gt;Repo&lt;/a&gt;, &lt;a href="https://fava.pythonanywhere.com/huge-example-file/income_statement" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://beancount.github.io/fava" rel="nofollow"&gt;Docs&lt;/a&gt;) Web interface for the double-entry bookkeeping software &lt;a href="http://furius.ca/beancount/" rel="nofollow"&gt;Beancount&lt;/a&gt; with a focus on features and usability. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gramps&lt;/strong&gt; - (&lt;a href="https://github.com/gramps-project/gramps"&gt;Repo&lt;/a&gt;, &lt;a href="https://gramps-project.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Genealogy software that is both intuitive for hobbyists and feature-complete for professional genealogists. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GTimeLog&lt;/strong&gt; - (&lt;a href="https://github.com/gtimelog/gtimelog"&gt;Repo&lt;/a&gt;, &lt;a href="https://gtimelog.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://ko-fi.com/mgedmin" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://gtimelog.org/docs.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Desktop-based time tracker with support for logging billable/non-billable work. &lt;code&gt;(productivity, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Headphones&lt;/strong&gt; - (&lt;a href="https://github.com/rembo10/headphones"&gt;Repo&lt;/a&gt;, &lt;a href="https://github.com/rembo10/headphones/wiki"&gt;Docs&lt;/a&gt;) Web-based digital music library for automating music downloads through Usenet and torrents. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ihatemoney&lt;/strong&gt; - (&lt;a href="https://github.com/spiral-project/ihatemoney"&gt;Repo&lt;/a&gt;, &lt;a href="https://ihatemoney.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://ihatemoney.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application made to ease shared budget management by keeping track of who bought what, when, and for whom. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Indico&lt;/strong&gt; - (&lt;a href="https://github.com/indico/indico"&gt;Repo&lt;/a&gt;, &lt;a href="https://getindico.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://sandbox.getindico.io/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://docs.getindico.io/en/stable/installation" rel="nofollow"&gt;Docs&lt;/a&gt;) Feature-rich web application designed at &lt;a href="https://en.wikipedia.org/wiki/CERN" rel="nofollow"&gt;CERN&lt;/a&gt; for managing events, with support for conference organization workflow, from content management to receiving and reviewing abstracts/papers, event registration, payment integration, room booking, and more. &lt;code&gt;(communication, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Invenio&lt;/strong&gt; - (&lt;a href="https://github.com/inveniosoftware/invenio"&gt;Repo&lt;/a&gt;, &lt;a href="https://invenio.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Customizable platform for running a trusted digital repository. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;jrnl&lt;/strong&gt; - (&lt;a href="https://github.com/maebert/jrnl"&gt;Repo&lt;/a&gt;, &lt;a href="http://jrnl.sh/" rel="nofollow"&gt;Home&lt;/a&gt;) Simple, ecncrypted journal application for your command line. &lt;code&gt;(linux, windows, mac, homebrew)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LazyLibrarian&lt;/strong&gt; - (&lt;a href="https://gitlab.com/LazyLibrarian/LazyLibrarian" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.reddit.com/r/LazyLibrarian" rel="nofollow"&gt;Forum&lt;/a&gt;, &lt;a href="https://lazylibrarian.gitlab.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based digital library organizer with support for following authors and automatic metadata retrieval. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mayan&lt;/strong&gt; - (&lt;a href="https://gitlab.com/mayan-edms/mayan-edms" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.mayan-edms.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.paypal.me/MayanEDMS" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://pypi.org/project/mayan-edms/3.2.7" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://docs.mayan-edms.com/" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based document management system, designed to store, introspect, and categorize files, with OCR, preview, label, signing, and sending capabilities. Also featuring workflow system, role-based access control, and REST API. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MLflow&lt;/strong&gt; - (&lt;a href="https://github.com/mlflow/mlflow"&gt;Repo&lt;/a&gt;, &lt;a href="https://mlflow.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://mlflow.org/docs/latest/index.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Integrated command-line application and web service, supporting an end-to-end machine-learning workflow around tracking, packaging, and deploying. Developed by &lt;a href="https://docs.databricks.com/applications/mlflow/index.html" rel="nofollow"&gt;Databricks&lt;/a&gt;. &lt;code&gt;(dev, linux, mac, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenLibrary&lt;/strong&gt; - (&lt;a href="https://github.com/internetarchive/openlibrary"&gt;Repo&lt;/a&gt;, &lt;a href="https://openlibrary.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Open_Library" rel="nofollow"&gt;WP&lt;/a&gt;) Web application for an open, editable library catalog, used by &lt;a href="https://archive.org/" rel="nofollow"&gt;The Internet Archive&lt;/a&gt; towards building a web page for every book ever published. &lt;code&gt;(linux, windows, mac, docker)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Paperwork&lt;/strong&gt; - (&lt;a href="https://gitlab.gnome.org/World/OpenPaperwork/paperwork" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://openpaper.work/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.patreon.com/openpaper" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://gitlab.gnome.org/World/OpenPaperwork/paperwork/wikis/home" rel="nofollow"&gt;Docs&lt;/a&gt;) Personal document manager for organizing scanned documents and PDFs, with support for OCR, automatic tagging, and search. &lt;code&gt;(linux, windows, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pinry&lt;/strong&gt; - (&lt;a href="https://github.com/pinry/pinry"&gt;Repo&lt;/a&gt;, &lt;a href="https://getpinry.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Tiling image board system for saving, tagging, and sharing images, videos, and websites, like a self-hosted Pinterest. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pretalx&lt;/strong&gt; - (&lt;a href="https://github.com/pretalx/pretalx"&gt;Repo&lt;/a&gt;, &lt;a href="https://pretalx.com/p/about" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.patreon.com/rixx" rel="nofollow"&gt;Fund&lt;/a&gt;) Web-based conference planning tool, with support for Calls for Papers (CFP), scheduling, and speaker management. &lt;code&gt;(communication, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyMedusa&lt;/strong&gt; - (&lt;a href="https://github.com/pymedusa/Medusa"&gt;Repo&lt;/a&gt;, &lt;a href="https://pymedusa.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Video library manager for TV shows, with automatic download support. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Radicale&lt;/strong&gt; - (&lt;a href="https://github.com/Kozea/Radicale"&gt;Repo&lt;/a&gt;, &lt;a href="https://radicale.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://radicale.org/documentation" rel="nofollow"&gt;Docs&lt;/a&gt;) Simple CalDAV (calendar) and CardDAV (contact) server. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RedNotebook&lt;/strong&gt; - (&lt;a href="https://github.com/jendrikseipp/rednotebook"&gt;Repo&lt;/a&gt;, &lt;a href="https://rednotebook.sourceforge.io/downloads.html" rel="nofollow"&gt;Home&lt;/a&gt;) Desktop journal designed for rich text, media, and template-based entries, which can be tagged and searched, as well as exported to plain text, HTML, Latex, or PDF. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scholia&lt;/strong&gt; - (&lt;a href="https://github.com/fnielsen/scholia"&gt;Repo&lt;/a&gt;, &lt;a href="https://tools.wmflabs.org/scholia" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.wikidata.org/wiki/Wikidata%3AScholia" rel="nofollow"&gt;Docs&lt;/a&gt;) Python package and web application for interacting with scholarly information on &lt;a href="https://www.wikidata.org/" rel="nofollow"&gt;Wikidata&lt;/a&gt;. &lt;code&gt;(science, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Senaite&lt;/strong&gt; - (&lt;a href="https://github.com/senaite/senaite.lims"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.senaite.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Web-based, mobile-first laboratory information management system (LIMS). &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SiCKRAGE&lt;/strong&gt; - (&lt;a href="https://git.sickrage.ca/SiCKRAGE/sickrage" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://github.com/SiCKRAGE/SiCKRAGE"&gt;gh&lt;/a&gt;, &lt;a href="https://git.sickrage.ca/SiCKRAGE/sickrage/wikis/FAQ%27s-and-Fixes" rel="nofollow"&gt;Docs&lt;/a&gt;) Video library manager with support for automatic TV show archival. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Taiga&lt;/strong&gt; - (&lt;a href="https://github.com/taigaio/taiga-back"&gt;Repo&lt;/a&gt;, &lt;a href="https://taiga.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="http://taigaio.github.io/taiga-doc/dist" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application built for managing projects with agile development processes. &lt;code&gt;(dev, server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wikid Pad&lt;/strong&gt; - (&lt;a href="https://github.com/WikidPad/WikidPad"&gt;Repo&lt;/a&gt;, &lt;a href="http://wikidpad.sourceforge.net/" rel="nofollow"&gt;Home&lt;/a&gt;) Desktop wiki notebook for storing your thoughts and ideas. &lt;code&gt;(linux, windows, mac, wx)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Xandikos&lt;/strong&gt; - (&lt;a href="https://github.com/jelmer/xandikos"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.xandikos.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Lightweight but relatively complete CardDAV/CalDAV server which backs up changes in a Git repository. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Zim Wiki&lt;/strong&gt; - (&lt;a href="https://github.com/jaap-karssenberg/zim-desktop-wiki"&gt;Repo&lt;/a&gt;, &lt;a href="http://zim-wiki.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Desktop wiki designed for note-taking, list-making, and drafting. &lt;code&gt;(linux, windows, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-communication" class="anchor" aria-hidden="true" href="#communication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-communication" href="#tag-communication"&gt;Communication&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Abilian SBE&lt;/strong&gt; - (&lt;a href="https://github.com/abilian/abilian-sbe"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.abilian.com/" rel="nofollow"&gt;Home&lt;/a&gt;) A "Social Business Engine" with features including lightweight document management, discussions, wikis, timelines, and more. &lt;code&gt;(cms, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Askbot&lt;/strong&gt; - (&lt;a href="https://github.com/ASKBOT/askbot-devel"&gt;Repo&lt;/a&gt;, &lt;a href="https://askbot.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Q&amp;amp;A web platform similar to StackOverflow, complete with tagging, reputation, badges, and more. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitmessage&lt;/strong&gt; - (&lt;a href="https://github.com/Bitmessage/PyBitmessage"&gt;Repo&lt;/a&gt;, &lt;a href="https://bitmessage.org/wiki/Main_Page" rel="nofollow"&gt;Docs&lt;/a&gt;) Reference client for Bitmessage, a peer-to-peer encrypted decentralised communication protocol. &lt;code&gt;(linux, windows, mac, kivy, qt4, tui)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Collaborate&lt;/strong&gt; - (&lt;a href="https://github.com/propublica/django-collaborative"&gt;Repo&lt;/a&gt;, &lt;a href="https://propublica.gitbook.io/collaborate-user-manual" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based collaboration tool designed by &lt;a href="https://www.propublica.org/nerds/making-collaborative-data-projects-easier-our-new-tool-collaborate-is-here" rel="nofollow"&gt;Propublica&lt;/a&gt; for newsrooms to share datasets, with a workflow built around assigning tips and maintaining contacts. &lt;code&gt;(organization, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dak&lt;/strong&gt; - (&lt;a href="https://salsa.debian.org/ftp-team/dak" rel="nofollow"&gt;Repo&lt;/a&gt;) Collection of programs used to maintain the Debian project's email archives. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Django Wiki&lt;/strong&gt; - (&lt;a href="https://github.com/django-wiki/django-wiki"&gt;Repo&lt;/a&gt;, &lt;a href="https://demo.django-wiki.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://django-wiki.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) A simple and mature web-based wiki. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Docassemble&lt;/strong&gt; - (&lt;a href="https://github.com/jhpyle/docassemble"&gt;Repo&lt;/a&gt;, &lt;a href="https://docassemble.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docassemble.org/docs.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Platform for creating mobile-friendly web-based interviews, collecting responses, and much more. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Formspree&lt;/strong&gt; - (&lt;a href="https://github.com/formspree/formspree"&gt;Repo&lt;/a&gt;, &lt;a href="https://formspree.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Web server which turns an HTML form submission into an email, without registration, JavaScript, or custom Python. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gajim&lt;/strong&gt; - (&lt;a href="https://dev.gajim.org/gajim/gajim" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Gajim" rel="nofollow"&gt;WP&lt;/a&gt;) Lightweight, cross-platform instant messaging client for the XMPP protocol. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GlobaLeaks&lt;/strong&gt; - (&lt;a href="https://github.com/globaleaks/GlobaLeaks"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.globaleaks.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Web application to enable secure and anonymous whistleblowing initiatives. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hangups&lt;/strong&gt; - (&lt;a href="https://github.com/tdryer/hangups"&gt;Repo&lt;/a&gt;, &lt;a href="https://snapcraft.io/hangups" rel="nofollow"&gt;Snap&lt;/a&gt;, &lt;a href="https://hangups.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Third-party instant messenger for &lt;a href="https://en.wikipedia.org/wiki/Google_Hangouts" rel="nofollow"&gt;Google Hangouts&lt;/a&gt;, with support for group messaging and other proprietary features. &lt;code&gt;(linux, mac, docker, snap)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hawkpost&lt;/strong&gt; - (&lt;a href="https://github.com/whitesmith/hawkpost"&gt;Repo&lt;/a&gt;, &lt;a href="https://hawkpost.co/" rel="nofollow"&gt;Home&lt;/a&gt;) Web application which enables receiving encrypted messages from less technical senders. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Helios Voting&lt;/strong&gt; - (&lt;a href="https://github.com/benadida/helios-server"&gt;Repo&lt;/a&gt;, &lt;a href="http://heliosvoting.org/" rel="nofollow"&gt;Home&lt;/a&gt;) End-to-end verifiable voting system. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inboxen&lt;/strong&gt; - (&lt;a href="https://github.com/Inboxen/Inboxen"&gt;Repo&lt;/a&gt;, &lt;a href="https://inboxen.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://inboxen.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application which provides an infinite number of unique email inboxes, for segmenting services and maintaining privacy. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Indico&lt;/strong&gt; - (&lt;a href="https://github.com/indico/indico"&gt;Repo&lt;/a&gt;, &lt;a href="https://getindico.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://sandbox.getindico.io/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://docs.getindico.io/en/stable/installation" rel="nofollow"&gt;Docs&lt;/a&gt;) Feature-rich web application designed at &lt;a href="https://en.wikipedia.org/wiki/CERN" rel="nofollow"&gt;CERN&lt;/a&gt; for managing events, with support for conference organization workflow, from content management to receiving and reviewing abstracts/papers, event registration, payment integration, room booking, and more. &lt;code&gt;(organization, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Magic Wormhole&lt;/strong&gt; - (&lt;a href="https://github.com/warner/magic-wormhole"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/magic-wormhole" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://magic-wormhole.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Security- and speed-focused file transfer tool with support for files, text, and directories. &lt;code&gt;(linux, mac, console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mailman&lt;/strong&gt; - (&lt;a href="https://gitlab.com/mailman/mailman" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.list.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GNU_Mailman" rel="nofollow"&gt;WP&lt;/a&gt;) The original listserv, a web application and email server for managing subscriptions and discussion archives. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mailpile&lt;/strong&gt; - (&lt;a href="https://github.com/mailpile/Mailpile"&gt;Repo&lt;/a&gt;, &lt;a href="https://mailpile.is/" rel="nofollow"&gt;Home&lt;/a&gt;) Fast email client with user-friendly encryption and privacy features. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mailu&lt;/strong&gt; - (&lt;a href="https://github.com/Mailu/Mailu"&gt;Repo&lt;/a&gt;, &lt;a href="https://mailu.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Full-featured mail server designed for easy setup and maintenance, supporting IMAP, IMAP+, SMTP, and Submission, as well as a slew of advanced features. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modoboa&lt;/strong&gt; - (&lt;a href="https://github.com/modoboa/modoboa"&gt;Repo&lt;/a&gt;, &lt;a href="https://modoboa.org/en" rel="nofollow"&gt;Home&lt;/a&gt;) Mail hosting and management platform including web UI based on Django. Provides useful components such as an admin panel and webmail. Integrates with Postfix or Dovecot. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MoinMoin&lt;/strong&gt; - (&lt;a href="https://bitbucket.org/thomaswaldmann/moin-2.0" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://moinmo.in/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/MoinMoin" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://moin-20.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Python's own web-based wiki software, used for &lt;a href="https://wiki.python.org/moin/" rel="nofollow"&gt;the official Python wiki&lt;/a&gt; and many others. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OfflineIMAP&lt;/strong&gt; - (&lt;a href="https://github.com/OfflineIMAP/offlineimap"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.offlineimap.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/OfflineIMAP" rel="nofollow"&gt;WP&lt;/a&gt;) IMAP reader and synchronizer. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OnionShare&lt;/strong&gt; - (&lt;a href="https://github.com/micahflee/onionshare"&gt;Repo&lt;/a&gt;, &lt;a href="https://onionshare.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/micahflee/onionshare/wiki"&gt;Docs&lt;/a&gt;) Secure and anonymous file sharing over &lt;a href="https://en.wikipedia.org/wiki/Tor_(anonymity_network)" rel="nofollow"&gt;Tor&lt;/a&gt; services. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pootle&lt;/strong&gt; - (&lt;a href="https://github.com/translate/pootle"&gt;Repo&lt;/a&gt;, &lt;a href="http://pootle.translatehouse.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Pootle" rel="nofollow"&gt;WP&lt;/a&gt;) Web application for collaborative translation. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pretalx&lt;/strong&gt; - (&lt;a href="https://github.com/pretalx/pretalx"&gt;Repo&lt;/a&gt;, &lt;a href="https://pretalx.com/p/about" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.patreon.com/rixx" rel="nofollow"&gt;Fund&lt;/a&gt;) Web-based conference planning tool, with support for Calls for Papers (CFP), scheduling, and speaker management. &lt;code&gt;(organization, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pycsw&lt;/strong&gt; - (&lt;a href="https://github.com/geopython/pycsw"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Pycsw" rel="nofollow"&gt;WP&lt;/a&gt;) Full implementation of the OpenGIS Catalogue Service Implementation Specification. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RapidSMS&lt;/strong&gt; - (&lt;a href="https://github.com/rapidsms/rapidsms"&gt;Repo&lt;/a&gt;, &lt;a href="http://rapidsms.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="http://readthedocs.org/docs/rapidsms" rel="nofollow"&gt;Docs&lt;/a&gt;) Interactive SMS text messaging platform. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SecureDrop&lt;/strong&gt; - (&lt;a href="https://github.com/freedomofpress/securedrop"&gt;Repo&lt;/a&gt;, &lt;a href="https://securedrop.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.securedrop.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Whistleblower submission system for media organizations to securely accept documents from anonymous sources. Originally created by &lt;a href="https://en.wikipedia.org/wiki/Aaron_Swartz" rel="nofollow"&gt;Aaron Swartz&lt;/a&gt; and currently managed by the &lt;a href="https://en.wikipedia.org/wiki/Freedom_of_the_Press_Foundation" rel="nofollow"&gt;Freedom of the Press Foundation&lt;/a&gt;. &lt;code&gt;(server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Socialhome&lt;/strong&gt; - (&lt;a href="https://git.feneas.org/socialhome/socialhome" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://socialhome.network/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/jaywink/socialhome"&gt;gh&lt;/a&gt;, &lt;a href="https://socialhome.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application enabling users to build a federated personal profile with social networking functionality. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Synapse&lt;/strong&gt; - (&lt;a href="https://github.com/matrix-org/synapse"&gt;Repo&lt;/a&gt;, &lt;a href="https://riot.im/app#/home" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.patreon.com/matrixdotorg/overview" rel="nofollow"&gt;Fund&lt;/a&gt;) Reference server for the &lt;a href="https://matrix.org" rel="nofollow"&gt;matrix.org&lt;/a&gt; distributed chat protocol. Used daily by tens of thousands at &lt;a href="https://riot.im/app/" rel="nofollow"&gt;riot.im&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Virtaal&lt;/strong&gt; - (&lt;a href="https://github.com/translate/virtaal"&gt;Repo&lt;/a&gt;, &lt;a href="http://virtaal.translatehouse.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Cross-platform GUI for performing translation, with support for a variety of formats. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Weblate&lt;/strong&gt; - (&lt;a href="https://github.com/WeblateOrg/weblate"&gt;Repo&lt;/a&gt;, &lt;a href="https://weblate.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/Weblate" rel="nofollow"&gt;PyPI&lt;/a&gt;) Web based localization tool with tight version control integration. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Zulip&lt;/strong&gt; - (&lt;a href="https://github.com/zulip/zulip"&gt;Repo&lt;/a&gt;, &lt;a href="https://zulip.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Zulip" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://zulip.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Powerful chat server and web client with support for threaded conversations. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-education" class="anchor" aria-hidden="true" href="#education"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-education" href="#tag-education"&gt;Education&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Anki&lt;/strong&gt; - (&lt;a href="https://github.com/dae/anki"&gt;Repo&lt;/a&gt;, &lt;a href="https://apps.ankiweb.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://apps.ankiweb.net/docs/manual.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Powerful desktop application for flash cards and memorization. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DrawBot&lt;/strong&gt; - (&lt;a href="https://github.com/typemytype/drawbot"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.drawbot.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/DrawBot" rel="nofollow"&gt;WP&lt;/a&gt;) A powerful programmatic 2D drawing application for MacOS X which generates graphics from Python scripts. &lt;code&gt;(graphics, dev, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kolibri&lt;/strong&gt; - (&lt;a href="https://github.com/learningequality/kolibri"&gt;Repo&lt;/a&gt;, &lt;a href="https://learningequality.org/kolibri" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://kolibridemo.learningequality.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://pypi.org/project/kolibri" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://kolibri.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Self-hostable learning web application targeted at making high quality education technology available in low-resource communities (e.g., rural schools, refugee camps, orphanages, non-formal school systems, and prison systems). &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mnemosyne&lt;/strong&gt; - (&lt;a href="https://github.com/mnemosyne-proj/mnemosyne"&gt;Repo&lt;/a&gt;, &lt;a href="https://mnemosyne-proj.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Spaced-repetition flashcard program for efficient memorization. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NBGrader&lt;/strong&gt; - (&lt;a href="https://github.com/jupyter/nbgrader"&gt;Repo&lt;/a&gt;, &lt;a href="https://nbgrader.readthedocs.io/en/stable" rel="nofollow"&gt;Docs&lt;/a&gt;) Jupyter-based application which enables educators to create, assign, and grade assignments in notebook form. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Open edX Platform&lt;/strong&gt; - (&lt;a href="https://github.com/edx/edx-platform"&gt;Repo&lt;/a&gt;, &lt;a href="http://open.edx.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/EdX#Open_edX" rel="nofollow"&gt;WP&lt;/a&gt;) Platform for online education providers, powering &lt;a href="https://en.wikipedia.org/wiki/EdX" rel="nofollow"&gt;edX&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RELATE&lt;/strong&gt; - (&lt;a href="https://github.com/inducer/relate"&gt;Repo&lt;/a&gt;, &lt;a href="https://documen.tician.de/relate" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based courseware with support for course planning and versioning, scheduling, testing, and grading. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tutor&lt;/strong&gt; - (&lt;a href="https://github.com/overhangio/tutor"&gt;Repo&lt;/a&gt;, &lt;a href="https://docs.tutor.overhang.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Docker-based Open edX distribution, both for production and local development, with a goal of easing deployment, customization, upgrading, and scaling. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-science" class="anchor" aria-hidden="true" href="#science"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-science" href="#tag-science"&gt;Science&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;AnuGA&lt;/strong&gt; - (&lt;a href="https://github.com/GeoscienceAustralia/anuga_core"&gt;Repo&lt;/a&gt;, &lt;a href="https://anuga.anu.edu.au/" rel="nofollow"&gt;Home&lt;/a&gt;) Advanced simulation of the shallow water equation, for modeling tsunamis, dam breaks, and floods. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Artisan&lt;/strong&gt; - (&lt;a href="https://github.com/artisan-roaster-scope/artisan"&gt;Repo&lt;/a&gt;, &lt;a href="https://artisan-scope.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://artisan-scope.org/docs/quick-start-guide" rel="nofollow"&gt;Docs&lt;/a&gt;) Desktop visual scope for coffee roasters, which helps coffee roasters record, analyze, and control roast profiles. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ASCEND&lt;/strong&gt; - (&lt;a href="http://code.ascend4.org/ascend/trunk" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://ascend4.org/Main_Page" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/ASCEND" rel="nofollow"&gt;WP&lt;/a&gt;) Mathematical chemical process modelling system developed at Carnegie Mellon University since late 1978. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CellProfiler&lt;/strong&gt; - (&lt;a href="https://github.com/CellProfiler/CellProfiler"&gt;Repo&lt;/a&gt;, &lt;a href="http://cellprofiler.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://cellprofiler.org/cpa" rel="nofollow"&gt;Manual&lt;/a&gt;, &lt;a href="https://github.com/CellProfiler/CellProfiler/wiki"&gt;Docs&lt;/a&gt;) Interactive data exploration, analysis, and classification of biological image sets. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cellxgene&lt;/strong&gt; - (&lt;a href="https://github.com/chanzuckerberg/cellxgene"&gt;Repo&lt;/a&gt;, &lt;a href="https://chanzuckerberg.github.io/cellxgene" rel="nofollow"&gt;Home&lt;/a&gt;) Web-based interactive explorer for single-cell transcriptomics data. &lt;code&gt;(linux, windows, mac, fnd)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CKAN&lt;/strong&gt; - (&lt;a href="https://github.com/ckan/ckan"&gt;Repo&lt;/a&gt;, &lt;a href="https://ckan.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Data management system (DMS) which makes it easy to publish, share, and use data. Data hubs powered by CKAN include &lt;a href="https://datahub.io" rel="nofollow"&gt;datahub.io&lt;/a&gt;, &lt;a href="https://catalog.data.gov" rel="nofollow"&gt;catalog.data.gov&lt;/a&gt;, and &lt;a href="https://europeandataportal.eu/data/en/dataset" rel="nofollow"&gt;europeandataportal.eu&lt;/a&gt;, among many other sites. &lt;code&gt;(server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CoCalc&lt;/strong&gt; - (&lt;a href="https://github.com/sagemathinc/cocalc"&gt;Repo&lt;/a&gt;, &lt;a href="https://cocalc.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/CoCalc" rel="nofollow"&gt;WP&lt;/a&gt;) Collaborative calculation in the cloud, with support for the scientific Python stack, SageMath, R, LaTeX, Markdown, and more. Also features chat, course management, and other supporting functionality. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dissem.in&lt;/strong&gt; - (&lt;a href="https://github.com/dissemin/dissemin"&gt;Repo&lt;/a&gt;, &lt;a href="https://dissem.in/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://dev.dissem.in/" rel="nofollow"&gt;Docs&lt;/a&gt;) Web platform to help researchers upload their papers to open-access repositories. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;InVesalius&lt;/strong&gt; - (&lt;a href="https://github.com/invesalius/invesalius3"&gt;Repo&lt;/a&gt;, &lt;a href="https://invesalius.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/InVesalius" rel="nofollow"&gt;WP&lt;/a&gt;) Generates virtual reconstructions of structures in the human body for medical purposes, including CT and MRI scans. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Manim&lt;/strong&gt; - (&lt;a href="https://github.com/3b1b/manim"&gt;Repo&lt;/a&gt;, &lt;a href="https://manim.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Animation engine for explanatory math videos, primarily designed for &lt;a href="https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw" rel="nofollow"&gt;works by 3blue1brown&lt;/a&gt;. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mayavi&lt;/strong&gt; - (&lt;a href="https://github.com/enthought/mayavi"&gt;Repo&lt;/a&gt;, &lt;a href="http://docs.enthought.com/mayavi/mayavi" rel="nofollow"&gt;Home&lt;/a&gt;) General purpose, cross-platform tool for 2-D and 3-D scientific data visualization. &lt;code&gt;(linux, windows, mac, qt4)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mosaic&lt;/strong&gt; - (&lt;a href="https://github.com/usnistgov/mosaic"&gt;Repo&lt;/a&gt;, &lt;a href="https://pages.nist.gov/mosaic" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pages.nist.gov/mosaic/html/index.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Desktop-based single molecule analysis toolbox that automatically decodes multi-state nanopore data. &lt;code&gt;(linux, windows, mac, gov)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;odemis&lt;/strong&gt; - (&lt;a href="https://github.com/delmic/odemis"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.delmic.com/microscopy-software-odemis" rel="nofollow"&gt;Home&lt;/a&gt;) Desktop imaging workflow software for Delmic microscopes, supporting autofocus, coordinate history, and OME-TIFF and HDF5 export. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OPEM&lt;/strong&gt; - (&lt;a href="https://github.com/ECSIM/opem"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.ecsim.ir/opem/doc" rel="nofollow"&gt;Docs&lt;/a&gt;) A modeling tool for evaluating the performance of &lt;a href="https://en.wikipedia.org/wiki/Proton-exchange_membrane_fuel_cell" rel="nofollow"&gt;proton exchange membrane (PEM) fuel cells&lt;/a&gt;. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Orange&lt;/strong&gt; - (&lt;a href="https://github.com/biolab/orange3"&gt;Repo&lt;/a&gt;, &lt;a href="https://orange.biolab.si/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Orange_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Component-based data mining software for graphical interactive data analysis and visualization. &lt;code&gt;(linux, windows, mac, qt4, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pybliographer&lt;/strong&gt; - (&lt;a href="https://github.com/GNOME/pybliographer"&gt;Repo&lt;/a&gt;, &lt;a href="https://pybliographer.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Bibliographic database manager with a user-friendly desktop UI. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ReproZip&lt;/strong&gt; - (&lt;a href="https://github.com/VIDA-NYU/reprozip"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.reprozip.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://examples.reprozip.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://docs.reprozip.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Command-line tool which automatically builds reproducible experiments archives from console commands, designed for use in computational science. &lt;code&gt;(productivity, linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sage Math&lt;/strong&gt; - (&lt;a href="https://git.sagemath.org/sage.git" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.sagemath.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/SageMath" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform computer algebra system with features covering many aspects of mathematics, including algebra, combinatorics, graph theory, numerical analysis, number theory, calculus, and statistics. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scholia&lt;/strong&gt; - (&lt;a href="https://github.com/fnielsen/scholia"&gt;Repo&lt;/a&gt;, &lt;a href="https://tools.wmflabs.org/scholia" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.wikidata.org/wiki/Wikidata%3AScholia" rel="nofollow"&gt;Docs&lt;/a&gt;) Python package and web application for interacting with scholarly information on &lt;a href="https://www.wikidata.org/" rel="nofollow"&gt;Wikidata&lt;/a&gt;. &lt;code&gt;(organization, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SOFA Statistics&lt;/strong&gt; - (&lt;a href="https://code.launchpad.net/sofastatistics" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.sofastatistics.com/" rel="nofollow"&gt;Home&lt;/a&gt;) User-friendly statistics and analysis with a learn-as-you-go approach. &lt;code&gt;(linux, windows, mac, wx)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Taguette&lt;/strong&gt; - (&lt;a href="https://gitlab.com/remram44/taguette" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.taguette.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/remram44/taguette"&gt;gh&lt;/a&gt;, &lt;a href="https://pypi.org/project/taguette" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://www.taguette.org/getting-started.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based qualitative research tool supporting importing, tagging, highlighting, and exporting many document formats. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Veusz&lt;/strong&gt; - (&lt;a href="https://github.com/veusz/veusz"&gt;Repo&lt;/a&gt;, &lt;a href="https://veusz.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;) 2D and 3D scientific plotting, designed to produce publication-ready PDF or SVG graphs. &lt;code&gt;(linux, windows, mac, qt)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-cms" class="anchor" aria-hidden="true" href="#cms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-cms" href="#tag-cms"&gt;CMS&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Abilian SBE&lt;/strong&gt; - (&lt;a href="https://github.com/abilian/abilian-sbe"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.abilian.com/" rel="nofollow"&gt;Home&lt;/a&gt;) A "Social Business Engine" with features including lightweight document management, discussions, wikis, timelines, and more. &lt;code&gt;(communication, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Django-CMS&lt;/strong&gt; - (&lt;a href="https://github.com/divio/django-cms"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.django-cms.org/en" rel="nofollow"&gt;Home&lt;/a&gt;) Enterprise content management system based on the Django framework with version control, multi-site support, and more. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ella&lt;/strong&gt; - (&lt;a href="https://github.com/ella/ella"&gt;Repo&lt;/a&gt;, &lt;a href="https://ella.readthedocs.io/en/latest/index.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Django-based content management system with a focus on high-traffic news sites and Internet magazines. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mezzanine&lt;/strong&gt; - (&lt;a href="https://github.com/stephenmcd/mezzanine"&gt;Repo&lt;/a&gt;, &lt;a href="http://mezzanine.jupo.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Consistent and flexible content management platform built on the Django framework. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plone&lt;/strong&gt; - (&lt;a href="https://github.com/plone/Plone"&gt;Repo&lt;/a&gt;, &lt;a href="https://plone.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Plone_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Extensible enterprise content management system built on Zope. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plumi&lt;/strong&gt; - (&lt;a href="https://github.com/plumi/plumi.app"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Plumi" rel="nofollow"&gt;WP&lt;/a&gt;) Video sharing content management system based on &lt;a href="https://en.wikipedia.org/wiki/Plone_(software)" rel="nofollow"&gt;Plone&lt;/a&gt;. &lt;code&gt;(video, server, plone)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pretix&lt;/strong&gt; - (&lt;a href="https://github.com/pretix/pretix"&gt;Repo&lt;/a&gt;, &lt;a href="https://pretix.eu/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pretix.eu/about/en/blog" rel="nofollow"&gt;Blog&lt;/a&gt;, &lt;a href="https://pypi.org/project/pretix" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://docs.pretix.eu/en/latest/development/index.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based ticketing software, with support for customizable storefronts, direct payments, box office, and reporting. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyCon&lt;/strong&gt; - (&lt;a href="https://github.com/PyCon/pycon"&gt;Repo&lt;/a&gt;, &lt;a href="https://us.pycon.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pycon.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Content management and conference organization web application, based on Django and &lt;a href="https://github.com/pinax/symposion"&gt;Symposion&lt;/a&gt;. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Saleor&lt;/strong&gt; - (&lt;a href="https://github.com/mirumee/saleor"&gt;Repo&lt;/a&gt;, &lt;a href="https://getsaleor.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Modular, high-performance e-commerce storefront built with Django, GraphQL, and ReactJS. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shuup&lt;/strong&gt; - (&lt;a href="https://github.com/shuup/shuup"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.shuup.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://shuup.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Storefront web application, with support for single- and multi-marketplace models. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wagtail&lt;/strong&gt; - (&lt;a href="https://github.com/wagtail/wagtail"&gt;Repo&lt;/a&gt;, &lt;a href="https://wagtail.io/" rel="nofollow"&gt;Home&lt;/a&gt;) A Django content management system focused on flexibility and user experience. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-erp" class="anchor" aria-hidden="true" href="#erp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-erp" href="#tag-erp"&gt;ERP&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ERP5&lt;/strong&gt; - (&lt;a href="https://lab.nexedi.com/nexedi/erp5" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://erp5.nexedi.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/ERP5" rel="nofollow"&gt;WP&lt;/a&gt;) Web-based ERP, CRM, DMS, and Big Data system with hundreds of built-in modules, designed for corporate scalability. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ERPNext&lt;/strong&gt; - (&lt;a href="https://github.com/frappe/erpnext"&gt;Repo&lt;/a&gt;, &lt;a href="https://erpnext.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/ERPNext" rel="nofollow"&gt;WP&lt;/a&gt;) Web-based ERP system with accounting, inventory, CRM, sales, procurement, project management, and HR. Built on &lt;a href="https://github.com/frappe/frappe"&gt;Frappe&lt;/a&gt; and MariaDB. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Frepple&lt;/strong&gt; - (&lt;a href="https://github.com/frePPLe/frepple"&gt;Repo&lt;/a&gt;, &lt;a href="https://frepple.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://frepple.com/docs/current/user-guide/index.php" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based supply chain planning for production planning and scheduling. &lt;code&gt;(linux, windows, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Odoo&lt;/strong&gt; - (&lt;a href="https://github.com/odoo/odoo"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.odoo.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Odoo" rel="nofollow"&gt;WP&lt;/a&gt;) Web-based ERP and CRM with many built-in modules, plus thousands of apps to suit any business. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tryton&lt;/strong&gt; - (&lt;a href="https://hg.tryton.org/trytond" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.tryton.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Tryton" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://docs.tryton.org/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Modular web-based ERP, designed for companies of all sizes. &lt;code&gt;(server, fdn)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-static-site" class="anchor" aria-hidden="true" href="#static-site"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-static_site" href="#tag-static_site"&gt;Static Site&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Cactus&lt;/strong&gt; - (&lt;a href="https://github.com/eudicots/Cactus"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/cactus" rel="nofollow"&gt;PyPI&lt;/a&gt;) Static website generator using Django templates. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chert&lt;/strong&gt; - (&lt;a href="https://github.com/mahmoud/chert"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/chert" rel="nofollow"&gt;PyPI&lt;/a&gt;) Static site generator with built-in support for listicles, created by this humble author, used to power &lt;a href="https://calver.org" rel="nofollow"&gt;calver.org&lt;/a&gt;, &lt;a href="https://zerover.org" rel="nofollow"&gt;zerover.org&lt;/a&gt;, and &lt;a href="https://sedimental.org/" rel="nofollow"&gt;sedimental.org&lt;/a&gt;, the author's blog. Mostly here as an easter egg :) &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Grow&lt;/strong&gt; - (&lt;a href="https://github.com/grow/grow"&gt;Repo&lt;/a&gt;, &lt;a href="https://grow.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/grow" rel="nofollow"&gt;PyPI&lt;/a&gt;) Static site generator optimized for building interactive, localized microsites, with a focus on workflow and maintainability. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hyde&lt;/strong&gt; - (&lt;a href="https://github.com/hyde/hyde"&gt;Repo&lt;/a&gt;, &lt;a href="http://hyde.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/hyde" rel="nofollow"&gt;PyPI&lt;/a&gt;) Static site generator which began as the Python counterpart to &lt;a href="https://github.com/jekyll/jekyll"&gt;Jekyll&lt;/a&gt;. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lektor&lt;/strong&gt; - (&lt;a href="https://github.com/lektor/lektor"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.getlektor.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Static site generator with built-in admin console and minimal desktop application. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nikola&lt;/strong&gt; - (&lt;a href="https://github.com/getnikola/nikola"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.getnikola.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/nikola" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line static site generator with incremental rebuilds and support for Markdown, reST, Jupyter notebooks, and HTML. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pelican&lt;/strong&gt; - (&lt;a href="https://github.com/getpelican/pelican"&gt;Repo&lt;/a&gt;, &lt;a href="https://blog.getpelican.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/pelican" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line static site generator that supports Markdown and reST syntax. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prosopopee&lt;/strong&gt; - (&lt;a href="https://github.com/Psycojoker/prosopopee"&gt;Repo&lt;/a&gt;, &lt;a href="https://surleschemins.fr/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://pypi.org/project/prosopopee" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://prosopopee.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) A static site generator designed for photographers and others who tell stories with pictures. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyVideo&lt;/strong&gt; - (&lt;a href="https://github.com/pyvideo/pyvideo"&gt;Repo&lt;/a&gt;, &lt;a href="https://pyvideo.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Static media index custom-built for the Python community, and all the content our meetings and conferences produce. &lt;code&gt;(video, linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-dev" class="anchor" aria-hidden="true" href="#dev"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev" href="#tag-dev"&gt;Dev&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Projects related to software development and adjacent technical areas.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-scm" class="anchor" aria-hidden="true" href="#scm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.scm" href="#tag-dev.scm"&gt;SCM&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Allura&lt;/strong&gt; - (&lt;a href="https://github.com/apache/allura"&gt;Repo&lt;/a&gt;, &lt;a href="https://allura.apache.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Apache_Allura" rel="nofollow"&gt;WP&lt;/a&gt;) Software &lt;a href="https://en.wikipedia.org/wiki/Forge_(software)" rel="nofollow"&gt;forge&lt;/a&gt;, with support for git, hg, and svn. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dvc (Data Version Control)&lt;/strong&gt; - (&lt;a href="https://github.com/iterative/dvc"&gt;Repo&lt;/a&gt;, &lt;a href="https://dvc.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://dvc.org/doc" rel="nofollow"&gt;Docs&lt;/a&gt;) Command-line tool for version control over data used in machine learning projects. Aims to replace Excel and other tools used to track and deploy model versions. &lt;code&gt;(organization, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Git Cola&lt;/strong&gt; - (&lt;a href="https://github.com/git-cola/git-cola"&gt;Repo&lt;/a&gt;, &lt;a href="https://git-cola.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Featureful cross-platform GUI wrapper for &lt;code&gt;git&lt;/code&gt;. &lt;code&gt;(linux, windows, mac, qt4, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gitless&lt;/strong&gt; - (&lt;a href="https://github.com/sdg-mit/gitless"&gt;Repo&lt;/a&gt;, &lt;a href="https://gitless.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/gitless" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://gitless.com/#documentation" rel="nofollow"&gt;Docs&lt;/a&gt;) Simple version control system built on top of Git. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GNU Bazaar&lt;/strong&gt; - (&lt;a href="https://code.launchpad.net/bzr" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://bazaar.canonical.com/en" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GNU_Bazaar" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="http://doc.bazaar.canonical.com/en" rel="nofollow"&gt;Docs&lt;/a&gt;) Distributed and client-server revision control system. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kallithea&lt;/strong&gt; - (&lt;a href="https://kallithea-scm.org/repos/kallithea" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Kallithea_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Software &lt;a href="https://en.wikipedia.org/wiki/Forge_(software)" rel="nofollow"&gt;forge&lt;/a&gt; for Mercurial and Git with a built-in push/pull server, full text search, and code-review. Forked from RhodeCode in 2014. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Klaus&lt;/strong&gt; - (&lt;a href="https://github.com/jonashaag/klaus"&gt;Repo&lt;/a&gt;, &lt;a href="http://klausdemo.lophus.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://pypi.org/project/klaus" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://github.com/jonashaag/klaus/wiki"&gt;Docs&lt;/a&gt;) pip-installable web-based viewer for git repositories that "just works". &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Launchpad&lt;/strong&gt; - (&lt;a href="https://launchpad.net/launchpad" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://launchpad.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Launchpad_%28website%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://dev.launchpad.net/" rel="nofollow"&gt;Docs&lt;/a&gt;) Software forge designed and run by Canonical, with support for Git and &lt;a href="https://en.wikipedia.org/wiki/GNU_Bazaar" rel="nofollow"&gt;Bazaar&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mercurial&lt;/strong&gt; - (&lt;a href="https://www.mercurial-scm.org/repo/hg-stable" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.mercurial-scm.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Mercurial" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform distributed revision-control system designed for high performance and advanced branching/merging capabilities. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pagure&lt;/strong&gt; - (&lt;a href="https://pagure.io/pagure" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://pagure.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Software &lt;a href="https://en.wikipedia.org/wiki/Forge_(software)" rel="nofollow"&gt;forge&lt;/a&gt; focused on git and developed by the Fedora engineering team. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Patchwork&lt;/strong&gt; - (&lt;a href="https://github.com/getpatchwork/patchwork"&gt;Repo&lt;/a&gt;, &lt;a href="http://jk.ozlabs.org/projects/patchwork" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://patchwork.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based patch tracking system designed to facilitate code contribution to an open-source project. Designed and used for Linux kernel subsystem development. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RabbitVCS&lt;/strong&gt; - (&lt;a href="https://github.com/rabbitvcs/rabbitvcs"&gt;Repo&lt;/a&gt;, &lt;a href="http://rabbitvcs.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="http://wiki.rabbitvcs.org/wiki" rel="nofollow"&gt;Docs&lt;/a&gt;) Tools providing straightforward graphical access to Subversion or Git within a variety of clients, including as Nautilus, Thunar, Nemo, Caja, and the command line. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RhodeCode&lt;/strong&gt; - (&lt;a href="https://code.rhodecode.com/rhodecode-enterprise-ce" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://rhodecode.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/RhodeCode" rel="nofollow"&gt;WP&lt;/a&gt;) Self-hosted platform for behind-the-firewall source code management, providing centralized control over Git, Mercurial, and Subversion. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Roundup&lt;/strong&gt; - (&lt;a href="http://hg.code.sf.net/p/roundup/code" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Roundup_%28issue_tracker%29" rel="nofollow"&gt;WP&lt;/a&gt;) Highly-customizable issue tracking system featuring command-line, web, and email interfaces, used by the official Python bug tracker at &lt;a href="https://bugs.python.org" rel="nofollow"&gt;bugs.python.org&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TortoiseHg&lt;/strong&gt; - (&lt;a href="https://bitbucket.org/tortoisehg/thg/src" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://tortoisehg.bitbucket.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://bitbucket.org/tortoisehg/thg/wiki/developers/Home" rel="nofollow"&gt;Docs&lt;/a&gt;) Windows shell extension and a series of applications for the Mercurial distributed revision control system. Also includes GNOME and CLI support. &lt;code&gt;(linux, windows, qt4, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Trac&lt;/strong&gt; - (&lt;a href="https://github.com/edgewall/trac"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Trac" rel="nofollow"&gt;WP&lt;/a&gt;) Enhanced web-based wiki and issue tracking system for software development projects. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ViewVC&lt;/strong&gt; - (&lt;a href="https://github.com/viewvc/viewvc"&gt;Repo&lt;/a&gt;, &lt;a href="http://viewvc.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Browser interface for CVS and Subversion version control repositories. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-code-review" class="anchor" aria-hidden="true" href="#code-review"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.code_review" href="#tag-dev.code_review"&gt;Code Review&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Diffoscope&lt;/strong&gt; - (&lt;a href="https://salsa.debian.org/reproducible-builds/diffoscope" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://diffoscope.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://try.diffoscope.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://pypi.org/project/diffoscope" rel="nofollow"&gt;PyPI&lt;/a&gt;) Web-based deep comparison of files, archives, and directories, including support for diffing tarballs, ISO images, and PDFs. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Meld&lt;/strong&gt; - (&lt;a href="https://github.com/GNOME/meld"&gt;Repo&lt;/a&gt;, &lt;a href="http://meldmerge.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Visual diff and merge tool targeted at developers, providing two- and three-way comparison of both files and directories, and supports many version control systems including Git, Mercurial, Bazaar, and Subversion. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Review Board&lt;/strong&gt; - (&lt;a href="https://github.com/reviewboard/reviewboard"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.reviewboard.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Extensible code review tool for projects and companies of all sizes. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rietveld&lt;/strong&gt; - (&lt;a href="https://github.com/rietveld-codereview/rietveld"&gt;Repo&lt;/a&gt;, &lt;a href="https://codereview.appspot.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Rietveld_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Django-based collaborative code review tool for Subversion written by &lt;a href="https://en.wikipedia.org/wiki/Guido_van_Rossum" rel="nofollow"&gt;Guido van Rossum&lt;/a&gt; to run on &lt;a href="https://en.wikipedia.org/wiki/Google_App_Engine" rel="nofollow"&gt;Google AppEngine&lt;/a&gt;. The basis for &lt;a href="https://en.wikipedia.org/wiki/Gerrit_(software)" rel="nofollow"&gt;Gerrit&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-storage" class="anchor" aria-hidden="true" href="#storage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.storage" href="#tag-dev.storage"&gt;Storage&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;B2&lt;/strong&gt; - (&lt;a href="https://github.com/Backblaze/B2_Command_Line_Tool"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.python.org/pypi/b2" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line tool that gives easy access to all of the capabilities of Backblaze's &lt;a href="https://www.backblaze.com/b2/cloud-storage.html" rel="nofollow"&gt;B2 Cloud Storage&lt;/a&gt;. &lt;code&gt;(linux, windows, mac, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Barman&lt;/strong&gt; - (&lt;a href="https://github.com/2ndquadrant-it/barman"&gt;Repo&lt;/a&gt;) Remote backup and disaster recovery for PostgreSQL. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Datasette&lt;/strong&gt; - (&lt;a href="https://github.com/simonw/datasette"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/datasette" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://datasette.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) A tool for exploring and publishing data, backed by SQLite. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EdgeDB&lt;/strong&gt; - (&lt;a href="https://github.com/edgedb/edgedb"&gt;Repo&lt;/a&gt;, &lt;a href="https://edgedb.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://edgedb.com/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) High-performance object-relational database built on top of PostgreSQL, featuring strict, strong typing, built-in migrations, and GraphQL support. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FreeNAS&lt;/strong&gt; - (&lt;a href="https://github.com/freenas/freenas"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.freenas.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.ixsystems.com/documentation/freenas" rel="nofollow"&gt;Docs&lt;/a&gt;) Operating system designed to be installed virtually any hardware platform, for sharing &lt;a href="https://en.wikipedia.org/wiki/ZFS" rel="nofollow"&gt;ZFS&lt;/a&gt;-based storage over a network, using SMB, NFS, AFP, FTP, and more. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gridsync&lt;/strong&gt; - (&lt;a href="https://github.com/gridsync/gridsync"&gt;Repo&lt;/a&gt;) Cross-platform GUI built to synchronize local directories with Tahoe-LAFS storage grids. &lt;code&gt;(productivity, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;kinto&lt;/strong&gt; - (&lt;a href="https://github.com/Kinto/kinto"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.kinto-storage.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="http://docs.kinto-storage.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) A generic JSON document store with sharing and synchronisation capabilities, supporting in-memory and PostgreSQL backends. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nuxeo Drive&lt;/strong&gt; - (&lt;a href="https://github.com/nuxeo/nuxeo-drive"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.nuxeo.com/products/drive-desktop-sync" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://doc.nuxeo.com/client-apps/nuxeo-drive" rel="nofollow"&gt;Docs&lt;/a&gt;) Cross-platform desktop synchronization client for the Nuxeo platform. &lt;code&gt;(productivity, linux, windows, mac, console, appimage, lgpl, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pgcli&lt;/strong&gt; - (&lt;a href="https://github.com/dbcli/pgcli"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.pgcli.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.python.org/pypi/pgcli" rel="nofollow"&gt;PyPI&lt;/a&gt;) Interactive PostgreSQL client that does auto-completion and syntax highlighting. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;s3ql&lt;/strong&gt; - (&lt;a href="https://github.com/s3ql/s3ql"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.rath.org/s3ql-docs/index.html" rel="nofollow"&gt;Docs&lt;/a&gt;) A standards-conforming, full-featured UNIX filesystem for cloud-based storage services (S3, Google Storage, OpenStack), supporting compression, encryption, deduplication, snapshotting, and more. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Seafile&lt;/strong&gt; - (&lt;a href="https://github.com/haiwen/seahub"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Seafile" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform file hosting and synchronization system. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sqlmap&lt;/strong&gt; - (&lt;a href="https://github.com/sqlmapproject/sqlmap"&gt;Repo&lt;/a&gt;, &lt;a href="http://sqlmap.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/sqlmapproject/sqlmap/wiki"&gt;Docs&lt;/a&gt;) Automatic SQL injection and database takeover. &lt;code&gt;(security, console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TahoeLAFS&lt;/strong&gt; - (&lt;a href="https://github.com/tahoe-lafs/tahoe-lafs"&gt;Repo&lt;/a&gt;, &lt;a href="https://tahoe-lafs.org/trac/tahoe-lafs" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Tahoe-LAFS" rel="nofollow"&gt;WP&lt;/a&gt;) Decentralized cloud storage system for robust distributed data storage. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WAL-E&lt;/strong&gt; - (&lt;a href="https://github.com/wal-e/wal-e"&gt;Repo&lt;/a&gt;) Continuous archiving of PostgreSQL WAL files and base backups. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ZEO&lt;/strong&gt; - (&lt;a href="https://github.com/zopefoundation/ZEO"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/ZEO" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://zope.readthedocs.io/en/latest/zopebook/ZEO.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Server and client providing &lt;a href="http://www.zodb.org/" rel="nofollow"&gt;ZODB&lt;/a&gt;-based storage over the network. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ZFSp&lt;/strong&gt; - (&lt;a href="https://github.com/alcarithemad/zfsp"&gt;Repo&lt;/a&gt;) A reverse-engineered &lt;a href="https://en.wikipedia.org/wiki/ZFS" rel="nofollow"&gt;ZFS&lt;/a&gt; implementation, written in Python, without reading the original C. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-ops" class="anchor" aria-hidden="true" href="#ops"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.ops" href="#tag-dev.ops"&gt;Ops&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Airflow&lt;/strong&gt; - (&lt;a href="https://github.com/apache/airflow"&gt;Repo&lt;/a&gt;, &lt;a href="https://airflow.apache.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) A platform to programmatically author, schedule and monitor workflows. &lt;code&gt;(linux, server, corp, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ansible&lt;/strong&gt; - (&lt;a href="https://github.com/ansible/ansible"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.ansible.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.ansible.com/ansible" rel="nofollow"&gt;Docs&lt;/a&gt;) Agentless, playbook-based automation. &lt;code&gt;(linux, mac, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;aws-cli&lt;/strong&gt; - (&lt;a href="https://github.com/aws/aws-cli"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/awscli" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://docs.aws.amazon.com/cli/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Official command-line interface for Amazon Web Services. &lt;code&gt;(console, py26)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beaker&lt;/strong&gt; - (&lt;a href="https://git.beaker-project.org/cgit/beaker" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://beaker-project.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://beaker-project.org/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Hardware integration testing system, used by RedHat to test compatiblity for RHEL and Fedora. &lt;code&gt;(server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cobbler&lt;/strong&gt; - (&lt;a href="https://github.com/Cobbler/Cobbler"&gt;Repo&lt;/a&gt;, &lt;a href="https://cobbler.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Cobbler_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Linux installation server that allows for rapid setup of network installation environments. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DCOS&lt;/strong&gt; - (&lt;a href="https://github.com/dcos/dcos"&gt;Repo&lt;/a&gt;, &lt;a href="https://dcos.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Mesosphere%2C_Inc.#Mesosphere_DC/OS" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://dcos.io/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Management platform for hardware and software resources in datacenters, built on &lt;a href="https://en.wikipedia.org/wiki/Apache_Mesos" rel="nofollow"&gt;Apache Mesos&lt;/a&gt;. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fail2ban&lt;/strong&gt; - (&lt;a href="https://github.com/fail2ban/fail2ban"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.fail2ban.org/wiki/index.php/Main_Page" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Fail2ban" rel="nofollow"&gt;WP&lt;/a&gt;) Daemon to ban hosts that cause multiple authentication errors on Linux servers. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ganeti&lt;/strong&gt; - (&lt;a href="https://github.com/ganeti/ganeti"&gt;Repo&lt;/a&gt;) Virtual machine cluster management tool built on existing virtualization technologies such as &lt;a href="https://en.wikipedia.org/wiki/Xen" rel="nofollow"&gt;Xen&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Kernel-based_Virtual_Machine" rel="nofollow"&gt;KVM&lt;/a&gt;. &lt;code&gt;(linux, server, haskell)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Glances&lt;/strong&gt; - (&lt;a href="https://github.com/nicolargo/glances"&gt;Repo&lt;/a&gt;, &lt;a href="https://nicolargo.github.io/glances" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://glances.readthedocs.io/en/stable" rel="nofollow"&gt;Docs&lt;/a&gt;) A cross-platform top/htop alternative, providing an overview of system resources. &lt;code&gt;(productivity, linux, windows, mac, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gunicorn&lt;/strong&gt; - (&lt;a href="https://github.com/benoitc/gunicorn"&gt;Repo&lt;/a&gt;, &lt;a href="https://gunicorn.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.python.org/pypi/gunicorn" rel="nofollow"&gt;PyPI&lt;/a&gt;) Pluggable, pre-fork WSGI server, started as the counterpart to &lt;a href="https://en.wikipedia.org/wiki/Unicorn_(web_server)" rel="nofollow"&gt;Unicorn&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Healthchecks&lt;/strong&gt; - (&lt;a href="https://github.com/healthchecks/healthchecks"&gt;Repo&lt;/a&gt;, &lt;a href="https://healthchecks.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://healthchecks.io/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based monitor for scheduled jobs (e.g., cron). &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Iris&lt;/strong&gt; - (&lt;a href="https://github.com/linkedin/iris"&gt;Repo&lt;/a&gt;, &lt;a href="https://iris.claims/" rel="nofollow"&gt;Home&lt;/a&gt;) Flexible automated incident paging system, developed by and used at LinkedIn. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nagstamon&lt;/strong&gt; - (&lt;a href="https://github.com/HenriWahl/Nagstamon"&gt;Repo&lt;/a&gt;, &lt;a href="https://nagstamon.ifw-dresden.de/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://nagstamon.ifw-dresden.de/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Status monitor for the desktop, with support for Nagios, Icinga, Opsview, and more. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NColony&lt;/strong&gt; - (&lt;a href="https://github.com/ncolony/ncolony"&gt;Repo&lt;/a&gt;, &lt;a href="http://ncolony.org/en/latest" rel="nofollow"&gt;Home&lt;/a&gt;) Process manager and monitor. &lt;code&gt;(linux, mac, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;netbox&lt;/strong&gt; - (&lt;a href="https://github.com/netbox-community/netbox"&gt;Repo&lt;/a&gt;, &lt;a href="https://netbox.readthedocs.io/en/stable" rel="nofollow"&gt;Docs&lt;/a&gt;) IP address management (IPAM) and data center infrastructure management (DCIM) tool, conceived at Digital Ocean. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nsupdate.info&lt;/strong&gt; - (&lt;a href="https://github.com/nsupdate-info/nsupdate.info"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/nsupdate" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://nsupdateinfo.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Featureful dynamic DNS service, using the Dynamic DNS UPDATE protocol (&lt;a href="https://tools.ietf.org/html/rfc2136" rel="nofollow"&gt;RFC 2136&lt;/a&gt;) to update BIND and other major nameservers. &lt;code&gt;(internet, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Oncall&lt;/strong&gt; - (&lt;a href="https://github.com/linkedin/oncall"&gt;Repo&lt;/a&gt;, &lt;a href="https://oncall.tools/" rel="nofollow"&gt;Home&lt;/a&gt;) Calendar tool designed for on-call management and scheduling, developed by and used at LinkedIn. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenStack&lt;/strong&gt; - (&lt;a href="https://github.com/openstack/openstack"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.openstack.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.openstack.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Cloud operating system that controls large pools of compute, storage, and networking resources throughout a datacenter, manageable through a web-based dashboard. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pulp&lt;/strong&gt; - (&lt;a href="https://github.com/pulp/pulp"&gt;Repo&lt;/a&gt;, &lt;a href="https://pulpproject.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.pulpproject.org/en/3.0/nightly" rel="nofollow"&gt;Docs&lt;/a&gt;) Platform for managing repositories of software packages and making it available to a large numbers of consumers. Developed and used by Red Hat. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ralph&lt;/strong&gt; - (&lt;a href="https://github.com/allegro/ralph"&gt;Repo&lt;/a&gt;, &lt;a href="https://ralph.allegro.tech/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://ralph-ng.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Simple and powerful Asset Management, DCIM, and CMDB system for the data center and back office. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Salt Stack&lt;/strong&gt; - (&lt;a href="https://github.com/saltstack/salt"&gt;Repo&lt;/a&gt;, &lt;a href="https://repo.saltstack.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Automation for the management and configuration of any infrastructure or application at scale. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shinken&lt;/strong&gt; - (&lt;a href="https://github.com/naparuba/shinken"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.shinken-monitoring.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Shinken is a modern, Nagios-compatible monitoring framework, designed to scale for large environments. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spinnaker&lt;/strong&gt; - (&lt;a href="https://github.com/spinnaker/spinnaker"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.spinnaker.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Spinnaker_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.spinnaker.io/concepts" rel="nofollow"&gt;Docs&lt;/a&gt;) Continuous delivery platform developed for Netflix's deployment and management of applications in cloud environments. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;StackStorm&lt;/strong&gt; - (&lt;a href="https://github.com/StackStorm/st2"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.stackstorm.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Rules- and event-driven operational automation for auto-remediation, security responses, troubleshooting, deployments, and more. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Supervisor&lt;/strong&gt; - (&lt;a href="https://github.com/Supervisor/supervisor"&gt;Repo&lt;/a&gt;, &lt;a href="http://supervisord.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Process manager and monitor. &lt;code&gt;(linux, mac, server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-security" class="anchor" aria-hidden="true" href="#security"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.security" href="#tag-dev.security"&gt;Security&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;BYOB (Build Your Own Botnet)&lt;/strong&gt; - (&lt;a href="https://github.com/malwaredllc/byob"&gt;Repo&lt;/a&gt;) Client-server framework (RAT and C2 server) for security researchers to build and operate basic botnets. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CAPE&lt;/strong&gt; - (&lt;a href="https://github.com/ctxis/CAPE"&gt;Repo&lt;/a&gt;, &lt;a href="https://cape.contextis.com/submit" rel="nofollow"&gt;Demo&lt;/a&gt;) Web application designed to automate malware analysis, with a goal of extracting payloads and configuration from uploaded artifacts. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cowrie&lt;/strong&gt; - (&lt;a href="https://github.com/cowrie/cowrie"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.cowrie.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Medium interaction SSH and Telnet honeypot designed to log brute force attacks and the shell interaction performed by the attacker. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GRR Rapid Response&lt;/strong&gt; - (&lt;a href="https://github.com/google/grr"&gt;Repo&lt;/a&gt;, &lt;a href="https://grr-doc.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Server-agent system focused on remote live forensics for quick, browser-based triage and analysis of attacks on fleets of machines, with agent support for Linux, Windows, and OS X. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hosts&lt;/strong&gt; - (&lt;a href="https://github.com/StevenBlack/hosts"&gt;Repo&lt;/a&gt;) Command-line application which merges reputable &lt;a href="https://en.wikipedia.org/wiki/Hosts_(file)" rel="nofollow"&gt;hosts files&lt;/a&gt; with deduplication for the purpose of blocking undesirable websites via DNS blackhole. &lt;code&gt;(internet, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hubble&lt;/strong&gt; - (&lt;a href="https://github.com/hubblestack/hubble"&gt;Repo&lt;/a&gt;, &lt;a href="https://hubblestack.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Modular security compliance client, providing on-demand profile-based auditing, alerting, and reporting. Originally designed for Adobe. &lt;code&gt;(linux, windows, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Infection Monkey&lt;/strong&gt; - (&lt;a href="https://github.com/guardicore/monkey"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.guardicore.com/infectionmonkey" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/guardicore/monkey/wiki"&gt;Docs&lt;/a&gt;) Web-based tool for testing a datacenter's resiliency to perimeter breaches and internal server infection. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;King Phisher&lt;/strong&gt; - (&lt;a href="https://github.com/securestate/king-phisher"&gt;Repo&lt;/a&gt;, &lt;a href="https://king-phisher.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Server-based &lt;a href="https://en.wikipedia.org/wiki/Phishing" rel="nofollow"&gt;phishing&lt;/a&gt; campaign toolkit, used to simulate real-world phishing attacks, with GTK-powered client application. &lt;code&gt;(linux, windows, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LinOTP&lt;/strong&gt; - (&lt;a href="https://github.com/LinOTP/LinOTP"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.linotp.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/LinOTP" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.linotp.org/documentation.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Server supporting two-factor authentication with one-time passwords from several sources, from Yubikeys to SMS. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Maltrail&lt;/strong&gt; - (&lt;a href="https://github.com/stamparm/maltrail"&gt;Repo&lt;/a&gt;) Malicious traffic detection system with web-based monitoring. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MITMproxy&lt;/strong&gt; - (&lt;a href="https://github.com/mitmproxy/mitmproxy"&gt;Repo&lt;/a&gt;, &lt;a href="https://mitmproxy.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Interactive TLS-capable intercepting HTTP proxy for penetration testers and software developers. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MozDef&lt;/strong&gt; - (&lt;a href="https://github.com/mozilla/MozDef"&gt;Repo&lt;/a&gt;, &lt;a href="https://mozdef.readthedocs.io/en/latest?badge=latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Security incident automation with metrics and collaboration tools for defenders. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenSnitch&lt;/strong&gt; - (&lt;a href="https://github.com/evilsocket/opensnitch"&gt;Repo&lt;/a&gt;, &lt;a href="https://opensnitch.io/" rel="nofollow"&gt;Home&lt;/a&gt;) GNU/Linux port of the &lt;a href="https://en.wikipedia.org/wiki/Little_Snitch" rel="nofollow"&gt;Little Snitch&lt;/a&gt; application firewall. &lt;code&gt;(linux, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Passit&lt;/strong&gt; - (&lt;a href="https://gitlab.com/passit/passit-backend" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://passit.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://passit.io/documentation" rel="nofollow"&gt;Docs&lt;/a&gt;) Password management server, providing storage services and group access control list features. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;privacyIDEA&lt;/strong&gt; - (&lt;a href="https://github.com/privacyidea/privacyidea"&gt;Repo&lt;/a&gt;, &lt;a href="https://privacyidea.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/PrivacyIDEA" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://privacyidea.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) A multi factor authentication server running on premises, supporting many different token types and allowing authentication via REST API, RADIUS, PAM, Windows Credential Provider, SAML, OpenID Connect. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Psono&lt;/strong&gt; - (&lt;a href="https://gitlab.com/psono/psono-server" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://psono.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.psono.pw/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://doc.psono.com/" rel="nofollow"&gt;Docs&lt;/a&gt;) Server-based password manager, built for teams. &lt;code&gt;(productivity, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pupy&lt;/strong&gt; - (&lt;a href="https://github.com/n1nj4sec/pupy"&gt;Repo&lt;/a&gt;, &lt;a href="https://github.com/n1nj4sec/pupy/wiki/Installation"&gt;Docs&lt;/a&gt;) Remote administration tool and post-exploitation framework, supporting Windows, Linux, Mac OS X, and Android targets. &lt;code&gt;(linux, docker, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyEW&lt;/strong&gt; - (&lt;a href="https://github.com/joxeankoret/pyew"&gt;Repo&lt;/a&gt;, &lt;a href="https://github.com/joxeankoret/pyew/wiki"&gt;Docs&lt;/a&gt;) Malware analysis tool, with support for hexadecimal viewing, disassembly, PE and ELF formats, plugins, and more. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Searx&lt;/strong&gt; - (&lt;a href="https://github.com/asciimoo/searx"&gt;Repo&lt;/a&gt;, &lt;a href="https://asciimoo.github.io/searx" rel="nofollow"&gt;Docs&lt;/a&gt;) Self-hosted metasearch engine, aggregating results from more than 70 services while avoiding tracking and profiling. &lt;code&gt;(internet, server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spiderfoot&lt;/strong&gt; - (&lt;a href="https://github.com/smicallef/spiderfoot"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.spiderfoot.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.spiderfoot.net/documentation" rel="nofollow"&gt;Docs&lt;/a&gt;) Reconnaissance tool that automatically queries over 100 public data sources to gather intelligence on IP addresses, domain names, e-mail addresses, names, and more. &lt;code&gt;(linux, windows, mac, docker, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sqlmap&lt;/strong&gt; - (&lt;a href="https://github.com/sqlmapproject/sqlmap"&gt;Repo&lt;/a&gt;, &lt;a href="http://sqlmap.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/sqlmapproject/sqlmap/wiki"&gt;Docs&lt;/a&gt;) Automatic SQL injection and database takeover. &lt;code&gt;(storage, console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sshuttle&lt;/strong&gt; - (&lt;a href="https://github.com/sshuttle/sshuttle"&gt;Repo&lt;/a&gt;, &lt;a href="https://sshuttle.readthedocs.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Transparent network proxy server that uses SSH to achieve VPN-like results, without requiring root access. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Universal Radio Hacker (URH)&lt;/strong&gt; - (&lt;a href="https://github.com/jopohl/urh"&gt;Repo&lt;/a&gt;) Wireless protocol investigator, with a focus on analyzing proprietary IoT communication. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;XSStrike&lt;/strong&gt; - (&lt;a href="https://github.com/s0md3v/XSStrike"&gt;Repo&lt;/a&gt;, &lt;a href="https://somdev.me/XSStrike" rel="nofollow"&gt;Home&lt;/a&gt;) &lt;a href="https://en.wikipedia.org/wiki/Cross-site_scripting" rel="nofollow"&gt;Cross Site Scripting&lt;/a&gt; (XSS) detection suite equipped with multiple hand-written parsers, a payload generator, a fuzzing engine, and a performance-focused crawler. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-docs" class="anchor" aria-hidden="true" href="#docs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.docs" href="#tag-dev.docs"&gt;Docs&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;asciidoc&lt;/strong&gt; - (&lt;a href="https://github.com/asciidoc/asciidoc"&gt;Repo&lt;/a&gt;) Text document format for writing notes, documentation, articles, books, slideshows, man pages &amp;amp; blogs. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;doc2dash&lt;/strong&gt; - (&lt;a href="https://github.com/hynek/doc2dash"&gt;Repo&lt;/a&gt;, &lt;a href="https://doc2dash.readthedocs.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/doc2dash" rel="nofollow"&gt;PyPI&lt;/a&gt;) Extensible CLI-based &lt;a href="https://developer.apple.com/library/archive/documentation/DeveloperTools/Conceptual/Documentation_Sets/010-Overview_of_Documentation_Sets/docset_overview.html#//apple_ref/doc/uid/TP40005266-CH13-SW6" rel="nofollow"&gt;Documentation Set&lt;/a&gt; generator intended for use with &lt;a href="https://kapeli.com/dash/" rel="nofollow"&gt;Dash.app&lt;/a&gt; and &lt;a href="https://velocity.silverlakesoftware.com/" rel="nofollow"&gt;other&lt;/a&gt; &lt;a href="https://github.com/dash-docs-el/helm-dash"&gt;compatible&lt;/a&gt; &lt;a href="https://zealdocs.org/" rel="nofollow"&gt;API browsers&lt;/a&gt;. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gaphor&lt;/strong&gt; - (&lt;a href="https://github.com/gaphor/gaphor"&gt;Repo&lt;/a&gt;, &lt;a href="https://gaphor.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Simple &lt;a href="https://en.wikipedia.org/wiki/Unified_Modeling_Language" rel="nofollow"&gt;UML&lt;/a&gt; modeling tool designed for beginners. &lt;code&gt;(graphics, linux, windows, mac, flatpak, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kuma&lt;/strong&gt; - (&lt;a href="https://github.com/mozilla/kuma"&gt;Repo&lt;/a&gt;, &lt;a href="https://developer.mozilla.org/en-US" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://kuma.readthedocs.io/en/latest/installation.html" rel="nofollow"&gt;Docs&lt;/a&gt;) The platform powering the Mozilla Developer Network (MDN) &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mkdocs&lt;/strong&gt; - (&lt;a href="https://github.com/mkdocs/mkdocs"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.mkdocs.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Simple, customizable project documentation, with built-in dev server. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;readthedocs.org&lt;/strong&gt; - (&lt;a href="https://github.com/readthedocs/readthedocs.org"&gt;Repo&lt;/a&gt;, &lt;a href="https://readthedocs.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.readthedocs.io/en/stable" rel="nofollow"&gt;Docs&lt;/a&gt;) Continuous integration platform for building and hosting documentation. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sphinx&lt;/strong&gt; - (&lt;a href="https://github.com/sphinx-doc/sphinx"&gt;Repo&lt;/a&gt;, &lt;a href="http://sphinx-doc.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Documentation tool for interconnected bodies of authorship, from code documentation to books. Used by &lt;a href="https://docs.python.org" rel="nofollow"&gt;the official Python docs&lt;/a&gt;, and many other projects (&lt;a href="https://varnish-cache.org/docs/" rel="nofollow"&gt;not all of them Python&lt;/a&gt;). &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-editor" class="anchor" aria-hidden="true" href="#editor"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.editor" href="#tag-dev.editor"&gt;Editor&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Black&lt;/strong&gt; - (&lt;a href="https://github.com/ambv/black"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/black" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://black.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Uncompromising automatic formatter for Python code. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eric IDE&lt;/strong&gt; - (&lt;a href="http://die-offenbachs.homelinux.org:48888/hg/eric" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://eric-ide.python-projects.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Python editor and IDE, based on Qt, integrating Scintilla editor control. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gedit&lt;/strong&gt; - (&lt;a href="https://gitlab.gnome.org/GNOME/gedit" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Gedit" rel="nofollow"&gt;WP&lt;/a&gt;) The default GNOME text editor makes extensive use of Python, in addition to C. &lt;code&gt;(linux, c, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jupyter Notebook&lt;/strong&gt; - (&lt;a href="https://github.com/jupyter/notebook"&gt;Repo&lt;/a&gt;, &lt;a href="https://jupyter.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Project_Jupyter#Jupyter_Notebook" rel="nofollow"&gt;WP&lt;/a&gt;) Web-based, extensible notebook environment for interactive computing. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Komodo Edit&lt;/strong&gt; - (&lt;a href="https://github.com/Komodo/KomodoEdit"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.activestate.com/products/komodo-edit" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Komodo_Edit" rel="nofollow"&gt;WP&lt;/a&gt;) Multi-language code editor, written in JS, Python, and C++, based on the Mozilla platform. &lt;code&gt;(linux, windows, mac, cpp, js)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Leo Editor&lt;/strong&gt; - (&lt;a href="https://github.com/leo-editor/leo-editor"&gt;Repo&lt;/a&gt;, &lt;a href="http://leoeditor.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Leo_%28text_editor%29" rel="nofollow"&gt;WP&lt;/a&gt;) Personal Information Manager (PIM), IDE, and outliner with a holistic approach to programming and writing. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mu&lt;/strong&gt; - (&lt;a href="https://github.com/mu-editor/mu"&gt;Repo&lt;/a&gt;, &lt;a href="https://codewith.mu/en" rel="nofollow"&gt;Home&lt;/a&gt;) A small, simple editor designed for beginner Python programmers. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ninja IDE&lt;/strong&gt; - (&lt;a href="https://github.com/ninja-ide/ninja-ide"&gt;Repo&lt;/a&gt;, &lt;a href="http://ninja-ide.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Ninja-IDE" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform Python IDE with project management, linting, extensions, and more. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pluma&lt;/strong&gt; - (&lt;a href="https://github.com/mate-desktop/pluma"&gt;Repo&lt;/a&gt;) Small and lightweight UTF-8 text editor for &lt;a href="http://mate-desktop.org/" rel="nofollow"&gt;the MATE environment&lt;/a&gt;. Based on gedit. &lt;code&gt;(linux, c, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ReText&lt;/strong&gt; - (&lt;a href="https://github.com/retext-project/retext"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/ReText" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://github.com/retext-project/retext/wiki"&gt;Docs&lt;/a&gt;) Simple but powerful editor for Markdown and reStructuredText markup languages. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spyder IDE&lt;/strong&gt; - (&lt;a href="https://github.com/spyder-ide/spyder"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.spyder-ide.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Spyder_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Scientific editing and execution environment designed by and for scientists, engineers, and data analysts using Python. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Thonny&lt;/strong&gt; - (&lt;a href="https://github.com/thonny/thonny"&gt;Repo&lt;/a&gt;, &lt;a href="https://thonny.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Thonny" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform Python IDE for beginners, designed for learning to code. &lt;code&gt;(linux, windows, mac, tk)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-package-managers" class="anchor" aria-hidden="true" href="#package-managers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.pkg_mgr" href="#tag-dev.pkg_mgr"&gt;Package Managers&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Conan&lt;/strong&gt; - (&lt;a href="https://github.com/conan-io/conan"&gt;Repo&lt;/a&gt;, &lt;a href="https://conan.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.conan.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Decentralized package manager for binary package management, targeted at C/C++ developers. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conda&lt;/strong&gt; - (&lt;a href="https://github.com/conda/conda"&gt;Repo&lt;/a&gt;, &lt;a href="https://conda.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Conda_%28package_manager%29" rel="nofollow"&gt;WP&lt;/a&gt;) OS-agnostic, system-level binary package manager and ecosystem, with a focus on Python and high-performance scientific computing. &lt;code&gt;(linux, windows, mac, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dnf&lt;/strong&gt; - (&lt;a href="https://github.com/rpm-software-management/dnf"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/DNF_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://dnf.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Dandified YUM (DNF) is the successor to &lt;code&gt;yum&lt;/code&gt; and works everywhere yum worked. &lt;code&gt;(linux, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pip&lt;/strong&gt; - (&lt;a href="https://github.com/pypa/pip"&gt;Repo&lt;/a&gt;, &lt;a href="https://pip.pypa.io/en/stable" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Pip_%28package_manager%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://pypi.org/project/pip" rel="nofollow"&gt;PyPI&lt;/a&gt;) Python's go-to package manager, with a wide range of features and platform support. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pip-tools&lt;/strong&gt; - (&lt;a href="https://github.com/jazzband/pip-tools"&gt;Repo&lt;/a&gt;) A set of command line tools to help you keep your pip-based packages fresh, even when you've pinned them. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pipenv&lt;/strong&gt; - (&lt;a href="https://github.com/pypa/pipenv"&gt;Repo&lt;/a&gt;, &lt;a href="https://pipenv.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Wrapper around &lt;code&gt;pip&lt;/code&gt;, &lt;a href="https://github.com/pypa/virtualenv"&gt;&lt;code&gt;virtualenv&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://github.com/jazzband/pip-tools"&gt;&lt;code&gt;pip-tools&lt;/code&gt;&lt;/a&gt; for a more holistic package management workflow. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Poetry&lt;/strong&gt; - (&lt;a href="https://github.com/sdispater/poetry"&gt;Repo&lt;/a&gt;, &lt;a href="https://poetry.eustace.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://poetry.eustace.io/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) An independent approach to Python dependency management and packaging. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Portage&lt;/strong&gt; - (&lt;a href="https://gitweb.gentoo.org/proj/portage.git" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Portage_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Platform-agnostic Package management system created for and used by Gentoo Linux and also by Chrome OS, Sabayon, and Funtoo Linux. Inspired by FreeBSD ports. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Solaris IPS&lt;/strong&gt; - (&lt;a href="https://github.com/oracle/solaris-ips"&gt;Repo&lt;/a&gt;) Software delivery system backed by network repository, featuring safe execution for zones, use of ZFS for efficiency and rollback, preventing the introduction of invalid packages, and efficient use of bandwidth. &lt;code&gt;(linux, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;yum&lt;/strong&gt; - (&lt;a href="https://github.com/rpm-software-management/yum"&gt;Repo&lt;/a&gt;, &lt;a href="http://yum.baseurl.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Yum_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Automatic updater and package installer/remover for RPM-based systems (Fedora, RHEL, etc.). &lt;code&gt;(linux, corp)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-package-repositories" class="anchor" aria-hidden="true" href="#package-repositories"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.pkg_repo" href="#tag-dev.pkg_repo"&gt;Package Repositories&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Bandersnatch&lt;/strong&gt; - (&lt;a href="https://github.com/pypa/bandersnatch"&gt;Repo&lt;/a&gt;) PyPI mirror client complying with &lt;a href="http://www.python.org/dev/peps/pep-0381/" rel="nofollow"&gt;PEP 381&lt;/a&gt;. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;devpi&lt;/strong&gt; - (&lt;a href="https://github.com/devpi/devpi"&gt;Repo&lt;/a&gt;, &lt;a href="http://doc.devpi.net/" rel="nofollow"&gt;Docs&lt;/a&gt;) PyPI staging server, as well as a packaging, testing, release tool, complete with web and search interface. Like a local PyPI. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;distro-tracker&lt;/strong&gt; - (&lt;a href="https://salsa.debian.org/qa/distro-tracker" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://tracker.debian.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://qa.pages.debian.net/distro-tracker" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application designed to follow the evolution of a Debian-based distribution with email updates and a comprehensive web interface. Powers the &lt;a href="https://tracker.debian.org/" rel="nofollow"&gt;Debian Package Tracker&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SweetTooth Web&lt;/strong&gt; - (&lt;a href="https://gitlab.gnome.org/Infrastructure/extensions-web" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://extensions.gnome.org/" rel="nofollow"&gt;Home&lt;/a&gt;) The web store for extensions to the &lt;a href="https://en.wikipedia.org/wiki/GNOME" rel="nofollow"&gt;GNOME&lt;/a&gt; desktop environment, supporting adding and updating extensions directly from the browser. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Warehouse&lt;/strong&gt; - (&lt;a href="https://github.com/pypa/warehouse"&gt;Repo&lt;/a&gt;, &lt;a href="https://psfmember.org/civicrm/contribute/transact?reset=1&amp;amp;id=13" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://warehouse.pypa.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Server software that powers &lt;a href="https://pypi.org/" rel="nofollow"&gt;PyPI&lt;/a&gt;, where most Python libraries are downloaded from. &lt;code&gt;(server, fnd)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-build" class="anchor" aria-hidden="true" href="#build"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.build" href="#tag-dev.build"&gt;Build&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;bitbake&lt;/strong&gt; - (&lt;a href="https://github.com/openembedded/bitbake"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/BitBake" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.yoctoproject.org/docs/current/bitbake-user-manual/bitbake-user-manual.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Generic task execution engine that allows shell and Python tasks to be run efficiently and in parallel while working within complex inter-task dependency constraints. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;buildbot&lt;/strong&gt; - (&lt;a href="https://github.com/buildbot/buildbot"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Buildbot" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.buildbot.net/" rel="nofollow"&gt;Docs&lt;/a&gt;) Job scheduling system tailored to the needs of continuous integration and software packaging. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Buildout&lt;/strong&gt; - (&lt;a href="https://github.com/buildout/buildout"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Buildout" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="http://docs.buildout.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Extensible deployment automation tool designed for application-centric assembly and deployment, as well as repeatable Python software builds. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;doit&lt;/strong&gt; - (&lt;a href="https://github.com/pydoit/doit"&gt;Repo&lt;/a&gt;, &lt;a href="https://pydoit.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://opencollective.com/doit" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://pydoit.org/contents.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Command-line task management and automation tool, with directives written in Python. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GYP&lt;/strong&gt; - (&lt;a href="https://chromium.googlesource.com/external/gyp" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://gyp.gsrc.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GYP_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) AKA 'Generate Your Projects', a build system that generates other build systems. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JHBuild&lt;/strong&gt; - (&lt;a href="https://gitlab.gnome.org/GNOME/jhbuild" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://wiki.gnome.org/Projects/Jhbuild" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/GNOME/jhbuild"&gt;gh&lt;/a&gt;, &lt;a href="https://developer.gnome.org/jhbuild/stable/getting-started.html.en" rel="nofollow"&gt;Docs&lt;/a&gt;) Tool designed to ease building collections of packages, originally written to build the GNOME desktop from sources. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Meson&lt;/strong&gt; - (&lt;a href="https://github.com/mesonbuild/meson"&gt;Repo&lt;/a&gt;, &lt;a href="http://mesonbuild.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Build system designed for speed and user-friendliness. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pants&lt;/strong&gt; - (&lt;a href="https://github.com/pantsbuild/pants"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.pantsbuild.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Build system designed for monolithic repositories. &lt;code&gt;(linux, mac, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PlatformIO Core&lt;/strong&gt; - (&lt;a href="https://github.com/platformio/platformio-core"&gt;Repo&lt;/a&gt;, &lt;a href="https://platformio.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://platformio.org/donate?utm_source=github&amp;amp;utm_medium=core" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://pypi.org/project/platformio" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://docs.platformio.org/en/latest?utm_source=github&amp;amp;utm_medium=core" rel="nofollow"&gt;Docs&lt;/a&gt;) Multiplatform CLI build system and library manager for IoT development. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;redo&lt;/strong&gt; - (&lt;a href="https://github.com/apenwarr/redo"&gt;Repo&lt;/a&gt;, &lt;a href="https://redo.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) A recursive, general-purpose build sytem, replacing &lt;code&gt;make&lt;/code&gt; with original design by &lt;a href="https://en.wikipedia.org/wiki/Daniel_J._Bernstein" rel="nofollow"&gt;DJB&lt;/a&gt;. &lt;code&gt;(linux, windows, mac, console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SCons&lt;/strong&gt; - (&lt;a href="https://github.com/SCons/scons"&gt;Repo&lt;/a&gt;, &lt;a href="http://scons.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/SCons" rel="nofollow"&gt;WP&lt;/a&gt;) Domain-specific language and build tool, designed to replace Make, autoconf, and ccache. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Snapcraft&lt;/strong&gt; - (&lt;a href="https://github.com/snapcore/snapcraft"&gt;Repo&lt;/a&gt;, &lt;a href="https://snapcraft.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://snapcraft.io/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) A command-line tool to package, distribute, and update apps for Linux and IoT using containerization, developed by Canonical. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Waf&lt;/strong&gt; - (&lt;a href="https://gitlab.com/ita1024/waf" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://waf.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Waf" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://waf.io/book" rel="nofollow"&gt;Docs&lt;/a&gt;) Cross-platform build system designed to improve on SCons. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-shell" class="anchor" aria-hidden="true" href="#shell"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.shell" href="#tag-dev.shell"&gt;Shell&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Ergonomica&lt;/strong&gt; - (&lt;a href="https://github.com/ergonomica/ergonomica"&gt;Repo&lt;/a&gt;, &lt;a href="http://ergonomica.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Cross-platform shell language based on &lt;a href="https://en.wikipedia.org/wiki/S-expression" rel="nofollow"&gt;S-expressions&lt;/a&gt; combined with traditional shell features. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Oil&lt;/strong&gt; - (&lt;a href="https://github.com/oilshell/oil"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.oilshell.org/" rel="nofollow"&gt;Home&lt;/a&gt;) A new &lt;a href="https://en.wikipedia.org/wiki/Bash_(Unix_shell)" rel="nofollow"&gt;bash&lt;/a&gt;- and &lt;a href="https://en.wikipedia.org/wiki/Almquist_shell#dash:_Ubuntu,_Debian_and_POSIX_compliance_of_Linux_distributions" rel="nofollow"&gt;dash&lt;/a&gt; backwards-compatible shell, with an improved language of its own. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Xonsh&lt;/strong&gt; - (&lt;a href="https://github.com/xonsh/xonsh"&gt;Repo&lt;/a&gt;, &lt;a href="https://xon.sh/" rel="nofollow"&gt;Home&lt;/a&gt;) Cross-platform shell language and command prompt. The language is a superset of Python 3.4+ with additional shell primitives. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-other-dev-projects" class="anchor" aria-hidden="true" href="#other-dev-projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev-other" href="#tag-dev-other"&gt;Other Dev projects&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;asciinema&lt;/strong&gt; - (&lt;a href="https://github.com/asciinema/asciinema"&gt;Repo&lt;/a&gt;, &lt;a href="https://asciinema.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Terminal session recorder and replayer. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;autojump&lt;/strong&gt; - (&lt;a href="https://github.com/wting/autojump"&gt;Repo&lt;/a&gt;) A &lt;code&gt;cd&lt;/code&gt; with many heuristics to speed up console filesystem navigation. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;coala&lt;/strong&gt; - (&lt;a href="https://github.com/coala/coala"&gt;Repo&lt;/a&gt;, &lt;a href="https://coala.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Unified command-line interface for linting and fixing code, regardless of programming language. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cookiecutter&lt;/strong&gt; - (&lt;a href="https://github.com/audreyr/cookiecutter"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/cookiecutter" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://cookiecutter.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Utility for creating new projects from shareable templates. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cython&lt;/strong&gt; - (&lt;a href="https://github.com/cython/cython"&gt;Repo&lt;/a&gt;, &lt;a href="https://cython.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/cython" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="http://docs.cython.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Language and compiler designed for high-performance Python and C interoperability. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;doitlive&lt;/strong&gt; - (&lt;a href="https://github.com/sloria/doitlive"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/doitlive" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://doitlive.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Tool for live presentations in the terminal. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DrawBot&lt;/strong&gt; - (&lt;a href="https://github.com/typemytype/drawbot"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.drawbot.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/DrawBot" rel="nofollow"&gt;WP&lt;/a&gt;) A powerful programmatic 2D drawing application for MacOS X which generates graphics from Python scripts. &lt;code&gt;(graphics, education, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gdbgui&lt;/strong&gt; - (&lt;a href="https://github.com/cs01/gdbgui"&gt;Repo&lt;/a&gt;, &lt;a href="https://gdbgui.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/gdbgui" rel="nofollow"&gt;PyPI&lt;/a&gt;) Browser-based frontend for &lt;a href="https://en.wikipedia.org/wiki/GNU_Debugger" rel="nofollow"&gt;gdb&lt;/a&gt;. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GNS3 GUI&lt;/strong&gt; - (&lt;a href="https://github.com/GNS3/gns3-gui"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.gns3.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/gns3-gui" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://docs.gns3.com/" rel="nofollow"&gt;Docs&lt;/a&gt;) Graphical Network Simulator used to emulate, configure, test and troubleshoot virtual and real networks. (Backed by server component &lt;a href="https://github.com/GNS3/gns3-server"&gt;here&lt;/a&gt;.) &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;howdoi&lt;/strong&gt; - (&lt;a href="https://github.com/gleitz/howdoi"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/howdoi" rel="nofollow"&gt;PyPI&lt;/a&gt;) Instant coding answers from StackOverflow on your command line. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;httpie&lt;/strong&gt; - (&lt;a href="https://github.com/jakubroztocil/httpie"&gt;Repo&lt;/a&gt;, &lt;a href="https://httpie.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/httpie" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line HTTP client with JSON support, syntax highlighting, wget-like downloads, extensions, and more. &lt;code&gt;(internet, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IPython&lt;/strong&gt; - (&lt;a href="https://github.com/ipython/ipython"&gt;Repo&lt;/a&gt;, &lt;a href="https://ipython.readthedocs.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Set of enhancements to Python, wrapping it for richer interactivity. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LocalStack&lt;/strong&gt; - (&lt;a href="https://github.com/localstack/localstack"&gt;Repo&lt;/a&gt;, &lt;a href="https://localstack.cloud/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/localstack" rel="nofollow"&gt;PyPI&lt;/a&gt;) Self-hostable version of many AWS services, including S3, Route53, Lambda, Redshift, and much more, designed for testing cloud-centric code. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Locust&lt;/strong&gt; - (&lt;a href="https://github.com/locustio/locust"&gt;Repo&lt;/a&gt;, &lt;a href="https://locust.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.locust.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Scalable user load testing tool for web sites, featuring an interactive web interface. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MLflow&lt;/strong&gt; - (&lt;a href="https://github.com/mlflow/mlflow"&gt;Repo&lt;/a&gt;, &lt;a href="https://mlflow.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://mlflow.org/docs/latest/index.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Integrated command-line application and web service, supporting an end-to-end machine-learning workflow around tracking, packaging, and deploying. Developed by &lt;a href="https://docs.databricks.com/applications/mlflow/index.html" rel="nofollow"&gt;Databricks&lt;/a&gt;. &lt;code&gt;(organization, linux, mac, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PathPicker&lt;/strong&gt; - (&lt;a href="https://github.com/facebook/PathPicker"&gt;Repo&lt;/a&gt;, &lt;a href="http://facebook.github.io/PathPicker" rel="nofollow"&gt;Home&lt;/a&gt;) Shell utility to interactively select paths from the output of other commands. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PeachPy&lt;/strong&gt; - (&lt;a href="https://github.com/Maratyszcza/PeachPy"&gt;Repo&lt;/a&gt;) Highly portable assembler with unified syntax, sporting an extensive user list, including many cryptography libraries for Go. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PINCE&lt;/strong&gt; - (&lt;a href="https://github.com/korcankaraokcu/PINCE"&gt;Repo&lt;/a&gt;) Debugging frontend for GDB focused on reverse engineering video games. &lt;code&gt;(linux, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plinth&lt;/strong&gt; - (&lt;a href="https://salsa.debian.org/freedombox-team/plinth" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://freedombox.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://wiki.debian.org/FreedomBox/Plinth" rel="nofollow"&gt;Docs&lt;/a&gt;) The core functionality and web front-end of &lt;a href="https://freedombox.org/" rel="nofollow"&gt;FreedomBox&lt;/a&gt;, an easy-to-manage, privacy-oriented home server. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Polyaxon&lt;/strong&gt; - (&lt;a href="https://github.com/polyaxon/polyaxon"&gt;Repo&lt;/a&gt;, &lt;a href="https://polyaxon.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.polyaxon.com/" rel="nofollow"&gt;Docs&lt;/a&gt;) A web-based platform for reproducible and scalable machine learning experiment management and metrics-tracking, based on kubernetes, with support for TensorFlow, PyTorch, Keras, and many more. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PPCI&lt;/strong&gt; - (&lt;a href="https://bitbucket.org/windel/ppci" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://godbolt.org/g/eooaPP" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://github.com/windelbouwman/ppci-mirror"&gt;gh&lt;/a&gt;, &lt;a href="https://pypi.org/project/ppci" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://ppci.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) The Pure Python Compiler Infrastructure is a compiler written entirely in Python, containing front-ends for various programming languages (C, c3, WebAssembly, and others) as well as machine code generation backends for various CPUs (6500, arm, avr, x86_64, openrisc, among others). &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RedHat Anaconda&lt;/strong&gt; - (&lt;a href="https://github.com/rhinstaller/anaconda"&gt;Repo&lt;/a&gt;, &lt;a href="https://anaconda-installer.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Installation program used by Fedora, Red Hat Enterprise Linux, and other Linux distributions. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Robot Framework&lt;/strong&gt; - (&lt;a href="https://github.com/robotframework/robotframework"&gt;Repo&lt;/a&gt;, &lt;a href="http://robotframework.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Generic, cross-platform, and language-independent automation framework for acceptance testing, acceptance test driven development (ATDD), and robotic process automation (RPA). Extensible in Python and Java. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ScratchABit&lt;/strong&gt; - (&lt;a href="https://github.com/pfalcon/ScratchABit"&gt;Repo&lt;/a&gt;) Easily retargetable and hackable interactive disassembler with IDAPython-compatible plugin API. &lt;code&gt;(linux, tui)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sentry&lt;/strong&gt; - (&lt;a href="https://github.com/getsentry/sentry"&gt;Repo&lt;/a&gt;, &lt;a href="https://sentry.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Web service and frontend for cross-platform application monitoring, with a focus on error reporting. &lt;code&gt;(server, corp, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Socorro&lt;/strong&gt; - (&lt;a href="https://github.com/mozilla-services/socorro"&gt;Repo&lt;/a&gt;, &lt;a href="https://wiki.mozilla.org/Socorro" rel="nofollow"&gt;Docs&lt;/a&gt;) Web service for collecting crash statistics from Mozilla products, including Firefox, Thunderbird, and &lt;a href="https://crash-stats.mozilla.org/" rel="nofollow"&gt;others&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Taiga&lt;/strong&gt; - (&lt;a href="https://github.com/taigaio/taiga-back"&gt;Repo&lt;/a&gt;, &lt;a href="https://taiga.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="http://taigaio.github.io/taiga-doc/dist" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application built for managing projects with agile development processes. &lt;code&gt;(organization, server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Thumbor&lt;/strong&gt; - (&lt;a href="https://github.com/thumbor/thumbor"&gt;Repo&lt;/a&gt;, &lt;a href="http://thumbor.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://thumbor.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Photo thumbnail service with resizing, flipping, and smart cropping of images. &lt;code&gt;(graphics, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ubiquity&lt;/strong&gt; - (&lt;a href="https://code.launchpad.net/ubiquity" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Ubiquity_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) The default installer for Ubuntu and its derivatives, designed to be run from Live CD or USB. &lt;code&gt;(linux, gtk, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Voltron&lt;/strong&gt; - (&lt;a href="https://github.com/snare/voltron"&gt;Repo&lt;/a&gt;) Extensible debugger wrapper aiming to improve the user experience of various debuggers, such as &lt;a href="https://lldb.llvm.org/" rel="nofollow"&gt;LLDB&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GNU_Debugger" rel="nofollow"&gt;GDB&lt;/a&gt;, and &lt;a href="https://en.wikipedia.org/wiki/WinDbg" rel="nofollow"&gt;WinDbg&lt;/a&gt;. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;YunoHost&lt;/strong&gt; - (&lt;a href="https://github.com/YunoHost/yunohost"&gt;Repo&lt;/a&gt;, &lt;a href="https://yunohost.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://yunohost.org/#/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Server operating system based on Debian Linux aiming to make self-hosting accessible to as many people as possible, with support for several types of hardware. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-misc" class="anchor" aria-hidden="true" href="#misc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-misc" href="#tag-misc"&gt;Misc&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Guake&lt;/strong&gt; - (&lt;a href="https://github.com/Guake/guake"&gt;Repo&lt;/a&gt;, &lt;a href="http://guake-project.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Drop-down terminal for GNOME, reminiscent of first-person game command consoles. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Home Assistant&lt;/strong&gt; - (&lt;a href="https://github.com/home-assistant/home-assistant"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.home-assistant.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://demo.home-assistant.io/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://www.home-assistant.io/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Home automation platform that puts local control and privacy first. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JARVIS on Messenger&lt;/strong&gt; - (&lt;a href="https://github.com/swapagarwal/JARVIS-on-Messenger"&gt;Repo&lt;/a&gt;, &lt;a href="https://m.me/J.A.R.V.I.S.on.Messenger" rel="nofollow"&gt;Home&lt;/a&gt;) Facebook Messenger bot with a wide assortment of features. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NFO Viewer&lt;/strong&gt; - (&lt;a href="https://github.com/otsaloma/nfoview"&gt;Repo&lt;/a&gt;, &lt;a href="https://otsaloma.io/nfoview" rel="nofollow"&gt;Home&lt;/a&gt;) A simple viewer for NFO files and the ASCII art therein, with preset fonts, encodings, automatic window sizing, and clickable hyperlinks. &lt;code&gt;(graphics, linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nicotine+&lt;/strong&gt; - (&lt;a href="https://github.com/Nicotine-Plus/nicotine-plus"&gt;Repo&lt;/a&gt;) Graphical desktop client for the &lt;a href="https://en.wikipedia.org/wiki/Soulseek" rel="nofollow"&gt;Soulseek&lt;/a&gt; peer-to-peer system. &lt;code&gt;(linux, windows, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nimbus&lt;/strong&gt; - (&lt;a href="https://github.com/nimbusproject/nimbus"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.nimbusproject.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Infrastructure-as-a-Service platform geared toward scientific cloud computing. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenLP&lt;/strong&gt; - (&lt;a href="https://code.launchpad.net/openlp" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://openlp.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Presentation software geared toward church usage. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;qtile&lt;/strong&gt; - (&lt;a href="https://github.com/qtile/qtile"&gt;Repo&lt;/a&gt;, &lt;a href="http://qtile.org/" rel="nofollow"&gt;Home&lt;/a&gt;) A small, flexible, scriptable tiling window manager. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;uMap&lt;/strong&gt; - (&lt;a href="https://github.com/umap-project/umap"&gt;Repo&lt;/a&gt;, &lt;a href="https://wiki.openstreetmap.org/wiki/UMap" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application allowing users to create maps with OpenStreetMap layers and embed it on other sites. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wammu&lt;/strong&gt; - (&lt;a href="https://github.com/gammu/wammu"&gt;Repo&lt;/a&gt;, &lt;a href="https://wammu.eu/wammu" rel="nofollow"&gt;Home&lt;/a&gt;) GUI phone manager with read/write support for contacts, todo, calendar, SMS, and more, primarily designed for Nokia and AT-compatible phones. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wicd&lt;/strong&gt; - (&lt;a href="https://code.launchpad.net/wicd" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://wicd.sourceforge.net/download.php" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Wicd" rel="nofollow"&gt;WP&lt;/a&gt;) Graphical utility for managing wired and wireless connections on Linux. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Xpra&lt;/strong&gt; - (&lt;a href="https://xpra.org/svn/Xpra/trunk" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://xpra.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Cross-platform remote display server and client for forwarding applications and desktop screens. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;&lt;a id="user-content-conclusion" class="anchor" aria-hidden="true" href="#conclusion"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;If you have a project to add, &lt;a href="https://github.com/mahmoud/awesome-python-applications/issues"&gt;please let us know&lt;/a&gt;!&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>mahmoud</author><guid isPermaLink="false">https://github.com/mahmoud/awesome-python-applications</guid><pubDate>Sat, 04 Jan 2020 00:19:00 GMT</pubDate></item><item><title>ageron/handson-ml #20 in Jupyter Notebook, This week</title><link>https://github.com/ageron/handson-ml</link><description>&lt;p&gt;&lt;i&gt;A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-notebooks" class="anchor" aria-hidden="true" href="#machine-learning-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning Notebooks&lt;/h1&gt;
&lt;p&gt;This project aims at teaching you the fundamentals of Machine Learning in
python. It contains the example code and solutions to the exercises in my O'Reilly book &lt;a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781491962282/" rel="nofollow"&gt;Hands-on Machine Learning with Scikit-Learn and TensorFlow&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781491962282/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8e10a44b0ddbb9530cc27d877f06db68d9fa1c7d/687474703a2f2f616b616d6169636f766572732e6f7265696c6c792e636f6d2f696d616765732f393738313439313936323238322f6361742e676966" alt="book" data-canonical-src="http://akamaicovers.oreilly.com/images/9781491962282/cat.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Simply open the &lt;a href="http://jupyter.org/" rel="nofollow"&gt;Jupyter&lt;/a&gt; notebooks you are interested in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using &lt;a href="http://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/index.ipynb" rel="nofollow"&gt;jupyter.org's notebook viewer&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;note: &lt;a href="https://github.com/ageron/handson-ml/blob/master/index.ipynb"&gt;github.com's notebook viewer&lt;/a&gt; also works but it is slower and the math formulas are not displayed correctly,&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;by cloning this repository and running Jupyter locally. This option lets you play around with the code. In this case, follow the installation instructions below,&lt;/li&gt;
&lt;li&gt;or by running the notebooks in &lt;a href="https://beta.deepnote.com" rel="nofollow"&gt;Deepnote&lt;/a&gt;. This allows you to play around with the code online in your browser. For example, here's a link to the first chapter: &lt;a href="https://beta.deepnote.com/launch?template=data-science&amp;amp;url=https%3A//github.com/ageron/handson-ml/blob/master/02_end_to_end_machine_learning_project.ipynb" rel="nofollow"&gt;&lt;img height="22" src="https://camo.githubusercontent.com/c3b9bd12a99f8de3301018192105256209bcf800/68747470733a2f2f626574612e646565706e6f74652e636f6d2f627574746f6e732f6c61756e63682d696e2d646565706e6f74652e737667" data-canonical-src="https://beta.deepnote.com/buttons/launch-in-deepnote.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h1&gt;
&lt;p&gt;First, you will need to install &lt;a href="https://git-scm.com/" rel="nofollow"&gt;git&lt;/a&gt;, if you don't have it already.&lt;/p&gt;
&lt;p&gt;Next, clone this repository by opening a terminal and typing the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd $HOME  # or any other development directory you prefer
$ git clone https://github.com/ageron/handson-ml.git
$ cd handson-ml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you do not want to install git, you can instead download &lt;a href="https://github.com/ageron/handson-ml/archive/master.zip"&gt;master.zip&lt;/a&gt;, unzip it, rename the resulting directory to &lt;code&gt;handson-ml&lt;/code&gt; and move it to your development directory.&lt;/p&gt;
&lt;p&gt;If you want to go through chapter 16 on Reinforcement Learning, you will need to &lt;a href="https://gym.openai.com/docs" rel="nofollow"&gt;install OpenAI gym&lt;/a&gt; and its dependencies for Atari simulations.&lt;/p&gt;
&lt;p&gt;If you are familiar with Python and you know how to install Python libraries, go ahead and install the libraries listed in &lt;code&gt;requirements.txt&lt;/code&gt; and jump to the &lt;a href="#starting-jupyter"&gt;Starting Jupyter&lt;/a&gt; section. If you need detailed instructions, please read on.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-python--required-libraries" class="anchor" aria-hidden="true" href="#python--required-libraries"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python &amp;amp; Required Libraries&lt;/h2&gt;
&lt;p&gt;Of course, you obviously need Python. Python 3 is already preinstalled on many systems nowadays. You can check which version you have by typing the following command (you may need to replace &lt;code&gt;python3&lt;/code&gt; with &lt;code&gt;python&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 --version  # for Python 3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Any Python 3 version should be fine, preferably 3.5 or above. If you don't have Python 3, I recommend installing it. To do so, you have several options: on Windows or MacOSX, you can just download it from &lt;a href="https://www.python.org/downloads/" rel="nofollow"&gt;python.org&lt;/a&gt;. On MacOSX, you can alternatively use &lt;a href="https://www.macports.org/" rel="nofollow"&gt;MacPorts&lt;/a&gt; or &lt;a href="https://brew.sh/" rel="nofollow"&gt;Homebrew&lt;/a&gt;. If you are using Python 3.6 on MacOSX, you need to run the following command to install the &lt;code&gt;certifi&lt;/code&gt; package of certificates because Python 3.6 on MacOSX has no certificates to validate SSL connections (see this &lt;a href="https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error" rel="nofollow"&gt;StackOverflow question&lt;/a&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ /Applications/Python\ 3.6/Install\ Certificates.command
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On Linux, unless you know what you are doing, you should use your system's packaging system. For example, on Debian or Ubuntu, type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt-get update
$ sudo apt-get install python3 python3-pip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another option is to download and install &lt;a href="https://www.continuum.io/downloads" rel="nofollow"&gt;Anaconda&lt;/a&gt;. This is a package that includes both Python and many scientific libraries. You should prefer the Python 3 version.&lt;/p&gt;
&lt;p&gt;If you choose to use Anaconda, read the next section, or else jump to the &lt;a href="#using-pip"&gt;Using pip&lt;/a&gt; section.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-anaconda" class="anchor" aria-hidden="true" href="#using-anaconda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using Anaconda&lt;/h2&gt;
&lt;p&gt;Once you have &lt;a href="https://docs.anaconda.com/anaconda/install/" rel="nofollow"&gt;installed Anaconda&lt;/a&gt; (or Miniconda), you can run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda env create -f environment.yml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will give you a conda environment named &lt;code&gt;mlbook&lt;/code&gt;, ready to use! Just activate it and you will have everything setup
for you:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda activate mlbook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You are all set! Next, jump to the &lt;a href="#starting-jupyter"&gt;Starting Jupyter&lt;/a&gt; section.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-pip" class="anchor" aria-hidden="true" href="#using-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using pip&lt;/h2&gt;
&lt;p&gt;If you are not using Anaconda, you need to install several scientific Python libraries that are necessary for this project, in particular NumPy, Matplotlib, Pandas, Jupyter and TensorFlow (and a few others). For this, you can either use Python's integrated packaging system, pip, or you may prefer to use your system's own packaging system (if available, e.g. on Linux, or on MacOSX when using MacPorts or Homebrew). The advantage of using pip is that it is easy to create multiple isolated Python environments with different libraries and different library versions (e.g. one environment for each project). The advantage of using your system's packaging system is that there is less risk of having conflicts between your Python libraries and your system's other packages. Since I have many projects with different library requirements, I prefer to use pip with isolated environments. Moreover, the pip packages are usually the most recent ones available, while Anaconda and system packages often lag behind a bit.&lt;/p&gt;
&lt;p&gt;These are the commands you need to type in a terminal if you want to use pip to install the required libraries. Note: in all the following commands, if you chose to use Python 2 rather than Python 3, you must replace &lt;code&gt;pip3&lt;/code&gt; with &lt;code&gt;pip&lt;/code&gt;, and &lt;code&gt;python3&lt;/code&gt; with &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First you need to make sure you have the latest version of pip installed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --user --upgrade pip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;--user&lt;/code&gt; option will install the latest version of pip only for the current user. If you prefer to install it system wide (i.e. for all users), you must have administrator rights (e.g. use &lt;code&gt;sudo python3&lt;/code&gt; instead of &lt;code&gt;python3&lt;/code&gt; on Linux), and you should remove the &lt;code&gt;--user&lt;/code&gt; option. The same is true of the command below that uses the &lt;code&gt;--user&lt;/code&gt; option.&lt;/p&gt;
&lt;p&gt;Next, you can optionally create an isolated environment. This is recommended as it makes it possible to have a different environment for each project (e.g. one for this project), with potentially very different libraries, and different versions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --user --upgrade virtualenv
$ python3 -m virtualenv -p `which python3` env
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates a new directory called &lt;code&gt;env&lt;/code&gt; in the current directory, containing an isolated Python environment based on Python 3. If you installed multiple versions of Python 3 on your system, you can replace &lt;code&gt;`which python3`&lt;/code&gt; with the path to the Python executable you prefer to use.&lt;/p&gt;
&lt;p&gt;Now you must activate this environment. You will need to run this command every time you want to use this environment.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ source ./env/bin/activate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On Windows, the command is slightly different:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ .\env\Scripts\activate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, use pip to install the required python packages. If you are not using virtualenv, you should add the &lt;code&gt;--user&lt;/code&gt; option (alternatively you could install the libraries system-wide, but this will probably require administrator rights, e.g. using &lt;code&gt;sudo pip3&lt;/code&gt; instead of &lt;code&gt;pip3&lt;/code&gt; on Linux).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --upgrade -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great! You're all set, you just need to start Jupyter now.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-starting-jupyter" class="anchor" aria-hidden="true" href="#starting-jupyter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Starting Jupyter&lt;/h2&gt;
&lt;p&gt;Okay! You can now start Jupyter, simply type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This should open up your browser, and you should see Jupyter's tree view, with the contents of the current directory. If your browser does not open automatically, visit &lt;a href="http://127.0.0.1:8888/tree" rel="nofollow"&gt;127.0.0.1:8888&lt;/a&gt;. Click on &lt;code&gt;index.ipynb&lt;/code&gt; to get started!&lt;/p&gt;
&lt;p&gt;Congrats! You are ready to learn Machine Learning, hands on!&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributors&lt;/h1&gt;
&lt;p&gt;I would like to thank everyone who contributed to this project, either by providing useful feedback, filing issues or submitting Pull Requests. Special thanks go to Steven Bunkley and Ziembla who created the &lt;code&gt;docker&lt;/code&gt; directory.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ageron</author><guid isPermaLink="false">https://github.com/ageron/handson-ml</guid><pubDate>Sat, 04 Jan 2020 00:20:00 GMT</pubDate></item><item><title>jakevdp/PythonDataScienceHandbook #21 in Jupyter Notebook, This week</title><link>https://github.com/jakevdp/PythonDataScienceHandbook</link><description>&lt;p&gt;&lt;i&gt;Python Data Science Handbook: full text in Jupyter Notebooks&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-python-data-science-handbook" class="anchor" aria-hidden="true" href="#python-data-science-handbook"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python Data Science Handbook&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://mybinder.org/v2/gh/jakevdp/PythonDataScienceHandbook/master?filepath=notebooks%2FIndex.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repository contains the entire &lt;a href="http://shop.oreilly.com/product/0636920034919.do" rel="nofollow"&gt;Python Data Science Handbook&lt;/a&gt;, in the form of (free!) Jupyter notebooks.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="notebooks/figures/PDSH-cover.png"&gt;&lt;img src="notebooks/figures/PDSH-cover.png" alt="cover image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-use-this-book" class="anchor" aria-hidden="true" href="#how-to-use-this-book"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to Use this Book&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Read the book in its entirety online at &lt;a href="https://jakevdp.github.io/PythonDataScienceHandbook/" rel="nofollow"&gt;https://jakevdp.github.io/PythonDataScienceHandbook/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the code using the Jupyter notebooks available in this repository's &lt;a href="notebooks"&gt;notebooks&lt;/a&gt; directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Launch executable versions of these notebooks using &lt;a href="http://colab.research.google.com" rel="nofollow"&gt;Google Colab&lt;/a&gt;: &lt;a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Launch a live notebook server with these notebooks using &lt;a href="https://beta.mybinder.org/" rel="nofollow"&gt;binder&lt;/a&gt;: &lt;a href="https://mybinder.org/v2/gh/jakevdp/PythonDataScienceHandbook/master?filepath=notebooks%2FIndex.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Buy the printed book through &lt;a href="http://shop.oreilly.com/product/0636920034919.do" rel="nofollow"&gt;O'Reilly Media&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-about" class="anchor" aria-hidden="true" href="#about"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About&lt;/h2&gt;
&lt;p&gt;The book was written and tested with Python 3.5, though other Python versions (including Python 2.7) should work in nearly all cases.&lt;/p&gt;
&lt;p&gt;The book introduces the core libraries essential for working with data in Python: particularly &lt;a href="http://ipython.org" rel="nofollow"&gt;IPython&lt;/a&gt;, &lt;a href="http://numpy.org" rel="nofollow"&gt;NumPy&lt;/a&gt;, &lt;a href="http://pandas.pydata.org" rel="nofollow"&gt;Pandas&lt;/a&gt;, &lt;a href="http://matplotlib.org" rel="nofollow"&gt;Matplotlib&lt;/a&gt;, &lt;a href="http://scikit-learn.org" rel="nofollow"&gt;Scikit-Learn&lt;/a&gt;, and related packages.
Familiarity with Python as a language is assumed; if you need a quick introduction to the language itself, see the free companion project,
&lt;a href="https://github.com/jakevdp/WhirlwindTourOfPython"&gt;A Whirlwind Tour of Python&lt;/a&gt;: it's a fast-paced introduction to the Python language aimed at researchers and scientists.&lt;/p&gt;
&lt;p&gt;See &lt;a href="http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;Index.ipynb&lt;/a&gt; for an index of the notebooks available to accompany the text.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-software" class="anchor" aria-hidden="true" href="#software"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Software&lt;/h2&gt;
&lt;p&gt;The code in the book was tested with Python 3.5, though most (but not all) will also work correctly with Python 2.7 and other older Python versions.&lt;/p&gt;
&lt;p&gt;The packages I used to run the code in the book are listed in &lt;a href="requirements.txt"&gt;requirements.txt&lt;/a&gt; (Note that some of these exact version numbers may not be available on your platform: you may have to tweak them for your own use).
To install the requirements using &lt;a href="http://conda.pydata.org" rel="nofollow"&gt;conda&lt;/a&gt;, run the following at the command-line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda install --file requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To create a stand-alone environment named &lt;code&gt;PDSH&lt;/code&gt; with Python 3.5 and all the required package versions, run the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda create -n PDSH python=3.5 --file requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can read more about using conda environments in the &lt;a href="http://conda.pydata.org/docs/using/envs.html" rel="nofollow"&gt;Managing Environments&lt;/a&gt; section of the conda documentation.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-code" class="anchor" aria-hidden="true" href="#code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code&lt;/h3&gt;
&lt;p&gt;The code in this repository, including all code samples in the notebooks listed above, is released under the &lt;a href="LICENSE-CODE"&gt;MIT license&lt;/a&gt;. Read more at the &lt;a href="https://opensource.org/licenses/MIT" rel="nofollow"&gt;Open Source Initiative&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-text" class="anchor" aria-hidden="true" href="#text"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Text&lt;/h3&gt;
&lt;p&gt;The text content of the book is released under the &lt;a href="LICENSE-TEXT"&gt;CC-BY-NC-ND license&lt;/a&gt;. Read more at &lt;a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode" rel="nofollow"&gt;Creative Commons&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jakevdp</author><guid isPermaLink="false">https://github.com/jakevdp/PythonDataScienceHandbook</guid><pubDate>Sat, 04 Jan 2020 00:21:00 GMT</pubDate></item><item><title>d2l-ai/berkeley-stat-157 #22 in Jupyter Notebook, This week</title><link>https://github.com/d2l-ai/berkeley-stat-157</link><description>&lt;p&gt;&lt;i&gt;Homepage for STAT 157 at UC Berkeley&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-homepage-for-stat-157-at-uc-berkeley" class="anchor" aria-hidden="true" href="#homepage-for-stat-157-at-uc-berkeley"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Homepage for STAT 157 at UC Berkeley&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://ci.d2l.ai/job/berkeley-stat-157/job/master/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/4fff957858d4ee1968c98ea2a6a6276fbb4b1105/687474703a2f2f63692e64326c2e61692f6a6f622f6265726b656c65792d737461742d3135372f6a6f622f6d61737465722f62616467652f69636f6e" alt="Build Status" data-canonical-src="http://ci.d2l.ai/job/berkeley-stat-157/job/master/badge/icon" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>d2l-ai</author><guid isPermaLink="false">https://github.com/d2l-ai/berkeley-stat-157</guid><pubDate>Sat, 04 Jan 2020 00:22:00 GMT</pubDate></item><item><title>jantic/DeOldify #23 in Jupyter Notebook, This week</title><link>https://github.com/jantic/DeOldify</link><description>&lt;p&gt;&lt;i&gt;A Deep Learning based project for colorizing and restoring old images (and video!)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deoldify" class="anchor" aria-hidden="true" href="#deoldify"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DeOldify&lt;/h1&gt;
&lt;p&gt;Image &lt;a href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColab.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" align="center" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt; |
Video &lt;a href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/VideoColorizerColab.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" align="center" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEW&lt;/strong&gt; Instructions on how to use the Colabs above have been kindly provided in video tutorial form by Old Ireland in Colour's John Breslin.  It's great! Click video image below to watch.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=VaEl0faDw38" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9d812131195cc524d5fe03696fdc284208bedbde/687474703a2f2f696d672e796f75747562652e636f6d2f76692f5661456c306661447733382f302e6a7067" alt="" data-canonical-src="http://img.youtube.com/vi/VaEl0faDw38/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Get more updates on &lt;a href="https://twitter.com/citnaj" rel="nofollow"&gt;Twitter &lt;img src="resource_images/Twitter_Social_Icon_Rounded_Square_Color.svg" width="16" style="max-width:100%;"&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#about-deoldify"&gt;About DeOldify&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#example-videos"&gt;Example Videos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#example-images"&gt;Example Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#stuff-that-should-probably-be-in-a-paper"&gt;Stuff That Should Probably Be In A Paper&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#how-to-achieve-stable-video"&gt;How to Achieve Stable Video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-is-nogan"&gt;What is NoGAN?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#why-three-models"&gt;Why Three Models?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-technical-details"&gt;Technical Details&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#this-project-going-forward"&gt;Going Forward&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#getting-started-yourself"&gt;Getting Started Yourself&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#easiest-approach"&gt;Easiest Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#your-own-machine-not-as-easy"&gt;Your Own Machine&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pretrained-weights"&gt;Pretrained Weights&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-about-deoldify" class="anchor" aria-hidden="true" href="#about-deoldify"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About DeOldify&lt;/h2&gt;
&lt;p&gt;Simply put, the mission of this project is to colorize and restore old images and film footage.
We'll get into the details in a bit, but first let's see some pretty pictures and videos!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-new-and-exciting-stuff-in-deoldify" class="anchor" aria-hidden="true" href="#new-and-exciting-stuff-in-deoldify"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;New and Exciting Stuff in DeOldify&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Glitches and artifacts are almost entirely eliminated&lt;/li&gt;
&lt;li&gt;Better skin (less zombies)&lt;/li&gt;
&lt;li&gt;More highly detailed and photorealistic renders&lt;/li&gt;
&lt;li&gt;Much less "blue bias"&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Video&lt;/strong&gt; - it actually looks good!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NoGAN&lt;/strong&gt; - a new and weird but highly effective way to do GAN training for image to image.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-example-videos" class="anchor" aria-hidden="true" href="#example-videos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Videos&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;  Click images to watch&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-facebook-f8-demo" class="anchor" aria-hidden="true" href="#facebook-f8-demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Facebook F8 Demo&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=l3UXXid04Ys" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/95e149f839667ddcd87e0a1970e3870f6a61c24a/687474703a2f2f696d672e796f75747562652e636f6d2f76692f6c335558586964303459732f302e6a7067" alt="" data-canonical-src="http://img.youtube.com/vi/l3UXXid04Ys/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-silent-movie-examples" class="anchor" aria-hidden="true" href="#silent-movie-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Silent Movie Examples&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=EXn-n2iqEjI" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24d210457f7e8b57ef701788f013f2f72d2eda1c/687474703a2f2f696d672e796f75747562652e636f6d2f76692f45586e2d6e326971456a492f302e6a7067" alt="" data-canonical-src="http://img.youtube.com/vi/EXn-n2iqEjI/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-example-images" class="anchor" aria-hidden="true" href="#example-images"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Images&lt;/h2&gt;
&lt;p&gt;"Migrant Mother" by Dorothea Lange (1936)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/cf0b5cd16cd934cba884172370a78b40b28db00a/68747470733a2f2f692e696d6775722e636f6d2f427430766e6b652e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/cf0b5cd16cd934cba884172370a78b40b28db00a/68747470733a2f2f692e696d6775722e636f6d2f427430766e6b652e6a7067" alt="Migrant Mother" data-canonical-src="https://i.imgur.com/Bt0vnke.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Woman relaxing in her livingroom in Sweden (1920)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/8ae04c8fc773e163705fd8ec24d3a9271806980c/68747470733a2f2f692e696d6775722e636f6d2f31353864306f552e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/8ae04c8fc773e163705fd8ec24d3a9271806980c/68747470733a2f2f692e696d6775722e636f6d2f31353864306f552e6a7067" alt="Sweden Living Room" data-canonical-src="https://i.imgur.com/158d0oU.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"Toffs and Toughs" by Jimmy Sime (1937)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0e3d002bbc787b75359789f8ade0c43b637cded3/68747470733a2f2f692e696d6775722e636f6d2f565975617634492e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/0e3d002bbc787b75359789f8ade0c43b637cded3/68747470733a2f2f692e696d6775722e636f6d2f565975617634492e6a7067" alt="Class Divide" data-canonical-src="https://i.imgur.com/VYuav4I.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanksgiving Maskers (1911)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ba7b6ae2cc2e908346ba56f06ea54061b9b1ee6e/68747470733a2f2f692e696d6775722e636f6d2f6e3871564a35632e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/ba7b6ae2cc2e908346ba56f06ea54061b9b1ee6e/68747470733a2f2f692e696d6775722e636f6d2f6e3871564a35632e6a7067" alt="Thanksgiving Maskers" data-canonical-src="https://i.imgur.com/n8qVJ5c.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Glen Echo Madame Careta Gypsy Camp in Maryland (1925)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/83d69aafb3b306643f99566d08d805099c741e98/68747470733a2f2f692e696d6775722e636f6d2f316f59724a52492e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/83d69aafb3b306643f99566d08d805099c741e98/68747470733a2f2f692e696d6775722e636f6d2f316f59724a52492e6a7067" alt="Gypsy Camp" data-canonical-src="https://i.imgur.com/1oYrJRI.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"Mr. and Mrs. Lemuel Smith and their younger children in their farm house, Carroll County, Georgia." (1941)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/f016893e9d37cab0175d218547699364d9c30f76/68747470733a2f2f692e696d6775722e636f6d2f49326a38796e6d2e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/f016893e9d37cab0175d218547699364d9c30f76/68747470733a2f2f692e696d6775722e636f6d2f49326a38796e6d2e6a7067" alt="Georgia Farmhouse" data-canonical-src="https://i.imgur.com/I2j8ynm.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"Building the Golden Gate Bridge" (est 1937)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/3b1aca12e6009a5b8a47bcfbbc84cd533b22a1de/68747470733a2f2f692e696d6775722e636f6d2f365362466a66712e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/3b1aca12e6009a5b8a47bcfbbc84cd533b22a1de/68747470733a2f2f692e696d6775722e636f6d2f365362466a66712e6a7067" alt="Golden Gate Bridge" data-canonical-src="https://i.imgur.com/6SbFjfq.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;  What you might be wondering is while this render looks cool, are the colors accurate? The original photo certainly makes it look like the towers of the bridge could be white. We looked into this and it turns out the answer is no - the towers were already covered in red primer by this time. So that's something to keep in mind- historical accuracy remains a huge challenge!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;"Terrasse de café, Paris" (1925)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ae76951da1b7106193d81c44d7da2a0b74d60077/68747470733a2f2f692e696d6775722e636f6d2f577072517750352e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/ae76951da1b7106193d81c44d7da2a0b74d60077/68747470733a2f2f692e696d6775722e636f6d2f577072517750352e6a7067" alt="Cafe Paris" data-canonical-src="https://i.imgur.com/WprQwP5.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Norwegian Bride (est late 1890s)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/03ab876e5b758529725e98bceea87f0e610106df/68747470733a2f2f692e696d6775722e636f6d2f4d6d7476725a6d2e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/03ab876e5b758529725e98bceea87f0e610106df/68747470733a2f2f692e696d6775722e636f6d2f4d6d7476725a6d2e6a7067" alt="Norwegian Bride" data-canonical-src="https://i.imgur.com/MmtvrZm.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zitkála-Šá (Lakota: Red Bird), also known as Gertrude Simmons Bonnin (1898)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/60080246c37e01c042194b2d87f4360a25637a7b/68747470733a2f2f692e696d6775722e636f6d2f7a49474d3034332e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/60080246c37e01c042194b2d87f4360a25637a7b/68747470733a2f2f692e696d6775722e636f6d2f7a49474d3034332e6a7067" alt="Native Woman" data-canonical-src="https://i.imgur.com/zIGM043.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chinese Opium Smokers (1880)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5a05086ca8215de683081c6fb29998045fee0ddf/68747470733a2f2f692e696d6775722e636f6d2f6c5647713856712e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/5a05086ca8215de683081c6fb29998045fee0ddf/68747470733a2f2f692e696d6775722e636f6d2f6c5647713856712e6a7067" alt="Opium Real" data-canonical-src="https://i.imgur.com/lVGq8Vq.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-stuff-that-should-probably-be-in-a-paper" class="anchor" aria-hidden="true" href="#stuff-that-should-probably-be-in-a-paper"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stuff That Should Probably Be In A Paper&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-how-to-achieve-stable-video" class="anchor" aria-hidden="true" href="#how-to-achieve-stable-video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to Achieve Stable Video&lt;/h3&gt;
&lt;p&gt;NoGAN training is crucial to getting the kind of stable and colorful images seen in this iteration of DeOldify. NoGAN training combines the benefits of GAN training (wonderful colorization) while eliminating the nasty side effects (like flickering objects in video). Believe it or not, video is rendered using isolated image generation without any sort of temporal modeling tacked on. The process performs 30-60 minutes of the GAN portion of "NoGAN" training, using 1% to 3% of imagenet data once.  Then, as with still image colorization, we "DeOldify" individual frames before rebuilding the video.&lt;/p&gt;
&lt;p&gt;In addition to improved video stability, there is an interesting thing going on here worth mentioning. It turns out the models I run, even different ones and with different training structures, keep arriving at more or less the same solution.  That's even the case for the colorization of things you may think would be arbitrary and unknowable, like the color of clothing, cars, and even special effects (as seen in "Metropolis").&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ea1738479cfd9811faa49b7dc78bb59606e74cfb/68747470733a2f2f7468756d62732e6766796361742e636f6d2f48656176794c6f6e65426c6f77666973682d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/ea1738479cfd9811faa49b7dc78bb59606e74cfb/68747470733a2f2f7468756d62732e6766796361742e636f6d2f48656176794c6f6e65426c6f77666973682d73697a655f726573747269637465642e676966" alt="Metropolis Special FX" data-canonical-src="https://thumbs.gfycat.com/HeavyLoneBlowfish-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My best guess is that the models are learning some interesting rules about how to colorize based on subtle cues present in the black and white images that I certainly wouldn't expect to exist.  This result leads to nicely deterministic and consistent results, and that means you don't have track model colorization decisions because they're not arbitrary.  Additionally, they seem remarkably robust so that even in moving scenes the renders are very consistent.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/007128e9e871429b96bca83aae7f2dfa9f3d9ecc/68747470733a2f2f7468756d62732e6766796361742e636f6d2f46616d696c6961724a7562696c616e744173702d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/007128e9e871429b96bca83aae7f2dfa9f3d9ecc/68747470733a2f2f7468756d62732e6766796361742e636f6d2f46616d696c6961724a7562696c616e744173702d73697a655f726573747269637465642e676966" alt="Moving Scene Example" data-canonical-src="https://thumbs.gfycat.com/FamiliarJubilantAsp-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Other ways to stabilize video add up as well. First, generally speaking rendering at a higher resolution (higher render_factor) will increase stability of colorization decisions.  This stands to reason because the model has higher fidelity image information to work with and will have a greater chance of making the "right" decision consistently.  Closely related to this is the use of resnet101 instead of resnet34 as the backbone of the generator- objects are detected more consistently and correctly with this. This is especially important for getting good, consistent skin rendering.  It can be particularly visually jarring if you wind up with "zombie hands", for example.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2b18ba56365c70078a0672e7aaa2b402e2a25eea/68747470733a2f2f7468756d62732e6766796361742e636f6d2f54687269667479496e666572696f7249736162656c6c696e6577686561746561722d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/2b18ba56365c70078a0672e7aaa2b402e2a25eea/68747470733a2f2f7468756d62732e6766796361742e636f6d2f54687269667479496e666572696f7249736162656c6c696e6577686561746561722d73697a655f726573747269637465642e676966" alt="Zombie Hand Example" data-canonical-src="https://thumbs.gfycat.com/ThriftyInferiorIsabellinewheatear-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Additionally, gaussian noise augmentation during training appears to help but at this point the conclusions as to just how much are bit more tenuous (I just haven't formally measured this yet).  This is loosely based on work done in style transfer video, described here:  &lt;a href="https://medium.com/element-ai-research-lab/stabilizing-neural-style-transfer-for-video-62675e203e42" rel="nofollow"&gt;https://medium.com/element-ai-research-lab/stabilizing-neural-style-transfer-for-video-62675e203e42&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Special thanks go to Rani Horev for his contributions in implementing this noise augmentation.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-what-is-nogan" class="anchor" aria-hidden="true" href="#what-is-nogan"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is NoGAN?&lt;/h3&gt;
&lt;p&gt;This is a new type of GAN training that I've developed to solve some key problems in the previous DeOldify model. It provides the benefits of GAN training while spending minimal time doing direct GAN training.  Instead, most of the training time is spent pretraining the generator and critic separately with more straight-forward, fast and reliable conventional methods.  A key insight here is that those more "conventional" methods generally get you most of the results you need, and that GANs can be used to close the gap on realism. During the very short amount of actual GAN training the generator not only gets the full realistic colorization capabilities that used to take days of progressively resized GAN training, but it also doesn't accrue nearly as much of the artifacts and other ugly baggage of GANs. In fact, you can pretty much eliminate glitches and artifacts almost entirely depending on your approach. As far as I know this is a new technique. And it's incredibly effective.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Original DeOldify Model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5f92319233179b2f204b8739173abf98a69ef39a/68747470733a2f2f7468756d62732e6766796361742e636f6d2f436f6f7264696e6174656456656e657261746564486f676765742d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/5f92319233179b2f204b8739173abf98a69ef39a/68747470733a2f2f7468756d62732e6766796361742e636f6d2f436f6f7264696e6174656456656e657261746564486f676765742d73697a655f726573747269637465642e676966" alt="Before Flicker" data-canonical-src="https://thumbs.gfycat.com/CoordinatedVeneratedHogget-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NoGAN-Based DeOldify Model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/410aabdcd548bde894635617caf09eaa678a7e80/68747470733a2f2f7468756d62732e6766796361742e636f6d2f4f696c79426c61636b417263746963686172652d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/410aabdcd548bde894635617caf09eaa678a7e80/68747470733a2f2f7468756d62732e6766796361742e636f6d2f4f696c79426c61636b417263746963686172652d73697a655f726573747269637465642e676966" alt="After Flicker" data-canonical-src="https://thumbs.gfycat.com/OilyBlackArctichare-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The steps are as follows: First train the generator in a conventional way by itself with just the feature loss. Next, generate images from that, and train the critic on distinguishing between those outputs and real images as a basic binary classifier. Finally, train the generator and critic together in a GAN setting (starting right at the target size of 192px in this case).  Now for the weird part:  All the useful GAN training here only takes place within a very small window of time.  There's an inflection point where it appears the critic has transferred everything it can that is useful to the generator. Past this point, image quality oscillates between the best that you can get at the inflection point, or bad in a predictable way (orangish skin, overly red lips, etc).  There appears to be no productive training after the inflection point.  And this point lies within training on just 1% to 3% of the Imagenet Data!  That amounts to about 30-60 minutes of training at 192px.&lt;/p&gt;
&lt;p&gt;The hard part is finding this inflection point.  So far, I've accomplished this by making a whole bunch of model save checkpoints (every 0.1% of data iterated on) and then just looking for the point where images look great before they go totally bonkers with orange skin (always the first thing to go). Additionally, generator rendering starts immediately getting glitchy and inconsistent at this point, which is no good particularly for video. What I'd really like to figure out is what the tell-tale sign of the inflection point is that can be easily automated as an early stopping point.  Unfortunately, nothing definitive is jumping out at me yet.  For one, it's happening in the middle of training loss decreasing- not when it flattens out, which would seem more reasonable on the surface.&lt;/p&gt;
&lt;p&gt;Another key thing about NoGAN training is you can repeat pretraining the critic on generated images after the initial GAN training, then repeat the GAN training itself in the same fashion.  This is how I was able to get extra colorful results with the "artistic" model.  But this does come at a cost currently- the output of the generator becomes increasingly inconsistent and you have to experiment with render resolution (render_factor) to get the best result.  But the renders are still glitch free and way more consistent than I was ever able to achieve with the original DeOldify model. You can do about five of these repeat cycles, give or take, before you get diminishing returns, as far as I can tell.&lt;/p&gt;
&lt;p&gt;Keep in mind- I haven't been entirely rigorous in figuring out what all is going on in NoGAN- I'll save that for a paper. That means there's a good chance I'm wrong about something.  But I think it's definitely worth putting out there now because I'm finding it very useful- it's solving basically much of my remaining problems I had in DeOldify.&lt;/p&gt;
&lt;p&gt;This builds upon a technique developed in collaboration with Jeremy Howard and Sylvain Gugger for Fast.AI's Lesson 7 in version 3 of Practical Deep Learning for Coders Part I. The particular lesson notebook can be found here: &lt;a href="https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres-gan.ipynb"&gt;https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres-gan.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-why-three-models" class="anchor" aria-hidden="true" href="#why-three-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why Three Models?&lt;/h2&gt;
&lt;p&gt;There are now three models to choose from in DeOldify. Each of these has key strengths and weaknesses, and so have different use cases.  Video is for video of course.  But stable and artistic are both for images, and sometimes one will do images better than the other.&lt;/p&gt;
&lt;p&gt;More details:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Artistic&lt;/strong&gt; - This model achieves the highest quality results in image coloration, in terms of interesting details and vibrance. The most notable drawback however is that it's a bit of a pain to fiddle around with to get the best results (you have to adjust the rendering resolution or render_factor to achieve this).  Additionally, the model does not do as well as stable in a few key common scenarios- nature scenes and portraits.  The model uses a resnet34 backbone on a UNet with an emphasis on depth of layers on the decoder side.  This model was trained with 5 critic pretrain/GAN cycle repeats via NoGAN, in addition to the initial generator/critic pretrain/GAN NoGAN training, at 192px.  This adds up to a total of 32% of Imagenet data trained once (12.5 hours of direct GAN training).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stable&lt;/strong&gt; - This model achieves the best results with landscapes and portraits. Notably, it produces less "zombies"- where faces or limbs stay gray rather than being colored in properly.  It generally has less weird miscolorations than artistic, but it's also less colorful in general.  This model uses a resnet101 backbone on a UNet with an emphasis on width of layers on the decoder side.  This model was trained with 3 critic pretrain/GAN cycle repeats via NoGAN, in addition to the initial generator/critic pretrain/GAN NoGAN training, at 192px.  This adds up to a total of 7% of Imagenet data trained once (3 hours of direct GAN training).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Video&lt;/strong&gt; - This model is optimized for smooth, consistent and flicker-free video.  This would definitely be the least colorful of the three models, but it's honestly not too far off from "stable". The model is the same as "stable" in terms of architecture, but differs in training.  It's trained for a mere 2.2% of Imagenet data once at 192px, using only the initial generator/critic pretrain/GAN NoGAN training (1 hour of direct GAN training).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because the training of the artistic and stable models was done before the "inflection point" of NoGAN training described in "What is NoGAN???" was discovered,  I believe this amount of training on them can be knocked down considerably. As far as I can tell, the models were stopped at "good points" that were well beyond where productive training was taking place.  I'll be looking into this in the future.&lt;/p&gt;
&lt;p&gt;Ideally, eventually these three models will be consolidated into one that has all these good desirable unified.  I think there's a path there, but it's going to require more work!  So for now, the most practical solution appears to be to maintain multiple models.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-the-technical-details" class="anchor" aria-hidden="true" href="#the-technical-details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Technical Details&lt;/h2&gt;
&lt;p&gt;This is a deep learning based model.  More specifically, what I've done is combined the following approaches:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-self-attention-generative-adversarial-network" class="anchor" aria-hidden="true" href="#self-attention-generative-adversarial-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://arxiv.org/abs/1805.08318" rel="nofollow"&gt;Self-Attention Generative Adversarial Network&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Except the generator is a &lt;strong&gt;pretrained U-Net&lt;/strong&gt;, and I've just modified it to have the spectral normalization and self-attention.  It's a pretty straightforward translation.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-two-time-scale-update-rule" class="anchor" aria-hidden="true" href="#two-time-scale-update-rule"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://arxiv.org/abs/1706.08500" rel="nofollow"&gt;Two Time-Scale Update Rule&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This is also very straightforward – it's just one to one generator/critic iterations and higher critic learning rate.
This is modified to incorporate a "threshold" critic loss that makes sure that the critic is "caught up" before moving on to generator training.
This is particularly useful for the "NoGAN" method described below.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-nogan" class="anchor" aria-hidden="true" href="#nogan"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NoGAN&lt;/h3&gt;
&lt;p&gt;There's no paper here! This is a new type of GAN training that I've developed to solve some key problems in the previous DeOldify model.
The gist is that you get the benefits of GAN training while spending minimal time doing direct GAN training.
More details are in the &lt;a href="#what-is-nogan"&gt;What is NoGAN?&lt;/a&gt; section (it's a doozy).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-generator-loss" class="anchor" aria-hidden="true" href="#generator-loss"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generator Loss&lt;/h3&gt;
&lt;p&gt;Loss during NoGAN learning is two parts:  One is a basic Perceptual Loss (or Feature Loss) based on VGG16 – this just biases the generator model to replicate the input image.
The second is the loss score from the critic.  For the curious – Perceptual Loss isn't sufficient by itself to produce good results.
It tends to just encourage a bunch of brown/green/blue – you know, cheating to the test, basically, which neural networks are really good at doing!
Key thing to realize here is that GANs essentially are learning the loss function for you – which is really one big step closer to toward the ideal that we're shooting for in machine learning.
And of course you generally get much better results when you get the machine to learn something you were previously hand coding.
That's certainly the case here.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Of note:&lt;/strong&gt;  There's no longer any "Progressive Growing of GANs" type training going on here.  It's just not needed in lieu of the superior results obtained by the "NoGAN" technique described above.&lt;/p&gt;
&lt;p&gt;The beauty of this model is that it should be generally useful for all sorts of image modification, and it should do it quite well.
What you're seeing above are the results of the colorization model, but that's just one component in a pipeline that I'm developing with the exact same approach.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-this-project-going-forward" class="anchor" aria-hidden="true" href="#this-project-going-forward"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;This Project, Going Forward&lt;/h2&gt;
&lt;p&gt;So that's the gist of this project – I'm looking to make old photos and film look reeeeaaally good with GANs, and more importantly, make the project &lt;em&gt;useful&lt;/em&gt;.
In the meantime though this is going to be my baby and I'll be actively updating and improving the code over the foreseeable future.
I'll try to make this as user-friendly as possible, but I'm sure there's going to be hiccups along the way.&lt;/p&gt;
&lt;p&gt;Oh and I swear I'll document the code properly...eventually.  Admittedly I'm &lt;em&gt;one of those&lt;/em&gt; people who believes in "self documenting code" (LOL).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started-yourself" class="anchor" aria-hidden="true" href="#getting-started-yourself"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started Yourself&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-easiest-approach" class="anchor" aria-hidden="true" href="#easiest-approach"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Easiest Approach&lt;/h3&gt;
&lt;p&gt;The easiest way to get started is to go straight to the Colab notebooks:&lt;/p&gt;
&lt;p&gt;Image &lt;a href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColab.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" align="center" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
| Video &lt;a href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/VideoColorizerColab.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" align="center" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Special thanks to Matt Robinson and María Benavente for their image Colab notebook contributions, and Robert Bell for the video Colab notebook work!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-your-own-machine-not-as-easy" class="anchor" aria-hidden="true" href="#your-own-machine-not-as-easy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Your Own Machine (not as easy)&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-hardware-and-operating-system-requirements" class="anchor" aria-hidden="true" href="#hardware-and-operating-system-requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hardware and Operating System Requirements&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;(Training Only) BEEFY Graphics card&lt;/strong&gt;.  I'd really like to have more memory than the 11 GB in my GeForce 1080TI (11GB).  You'll have a tough time with less.  The Generators and Critic are ridiculously large.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(Colorization Alone) A decent graphics card&lt;/strong&gt;. Approximately 4GB+ memory video cards should be sufficient.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linux (or maybe Windows 10)&lt;/strong&gt;  I'm using Ubuntu 16.04, but nothing about this precludes Windows 10 support as far as I know.  I just haven't tested it and am not going to make it a priority for now.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-easy-install" class="anchor" aria-hidden="true" href="#easy-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Easy Install&lt;/h4&gt;
&lt;p&gt;You should now be able to do a simple install with Anaconda. Here are the steps:&lt;/p&gt;
&lt;p&gt;Open the command line and navigate to the root folder you wish to install.  Then type the following commands&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;git clone https://github.com/jantic/DeOldify.git DeOldify&lt;/span&gt;
&lt;span class="pl-c1"&gt;cd DeOldify&lt;/span&gt;
&lt;span class="pl-c1"&gt;conda env create -f environment.yml&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then start running with these commands:&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;source activate deoldify&lt;/span&gt;
&lt;span class="pl-c1"&gt;jupyter lab&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From there you can start running the notebooks in Jupyter Lab, via the url they provide you in the console.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can also now do "conda activate deoldify" if you have the latest version of conda and in fact that's now recommended. But a lot of people don't have that yet so I'm not going to make it the default instruction here yet.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-note-on-test_images-folder" class="anchor" aria-hidden="true" href="#note-on-test_images-folder"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Note on test_images Folder&lt;/h4&gt;
&lt;p&gt;The images in the &lt;code&gt;test_images&lt;/code&gt; folder have been removed because they were using Git LFS and that costs a lot of money when GitHub actually charges for bandwidth on a popular open source project (they had a billing bug for while that was recently fixed).  The notebooks that use them (the image test ones) still point to images in that directory that I (Jason) have personally and I'd like to keep it that way because, after all, I'm by far the primary and most active developer.  But they won't work for you.  Still, those notebooks are a convenient template for making your own tests if you're so inclined.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-docker-for-jupyter" class="anchor" aria-hidden="true" href="#docker-for-jupyter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker for Jupyter&lt;/h3&gt;
&lt;p&gt;You can build and run the docker using the following process:&lt;/p&gt;
&lt;p&gt;Cloning&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;git clone https://github.com/jantic/DeOldify.git DeOldify&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Building Docker&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;cd DeOldify &amp;amp;&amp;amp; docker build -t deoldify_jupyter -f Dockerfile .&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running Docker&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;echo "http://$(curl ifconfig.io):8888" &amp;amp;&amp;amp; nvidia-docker run --ipc=host --env NOTEBOOK_PASSWORD="pass123" -p 8888:8888 -it deoldify_jupyter&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-docker-for-api" class="anchor" aria-hidden="true" href="#docker-for-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker for API&lt;/h3&gt;
&lt;p&gt;You can build and run the docker using the following process:&lt;/p&gt;
&lt;p&gt;Cloning&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;git clone https://github.com/jantic/DeOldify.git DeOldify&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Building Docker&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;cd DeOldify &amp;amp;&amp;amp; docker build -t deoldify_api -f Dockerfile-api .&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running Docker&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;echo "http://$(curl ifconfig.io):5000" &amp;amp;&amp;amp; nvidia-docker run --ipc=host -p 5000:5000 -d deoldify_api&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Calling the API for image processing&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;curl -X POST "http://MY_SUPER_API_IP:5000/process" -H "accept: image/png" -H "Content-Type: application/json" -d "{\"source_url\":\"http://www.afrikanheritage.com/wp-content/uploads/2015/08/slave-family-P.jpeg\", \"render_factor\":35}" --output colorized_image.png&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Calling the API for video processing&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;curl -X POST "http://MY_SUPER_API_IP:5000/process" -H "accept: application/octet-stream" -H "Content-Type: application/json" -d "{\"source_url\":\"https://v.redd.it/d1ku57kvuf421/HLSPlaylist.m3u8\", \"render_factor\":35}" --output colorized_video.mp4&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you don't have Nvidia Docker, &lt;a href="https://github.com/nvidia/nvidia-docker/wiki/Installation-(version-2.0)#installing-version-20"&gt;here&lt;/a&gt; is the installation guide.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-installation-details" class="anchor" aria-hidden="true" href="#installation-details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation Details&lt;/h3&gt;
&lt;p&gt;This project is built around the wonderful Fast.AI library.  Prereqs, in summary:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Fast.AI 1.0.51&lt;/strong&gt; (and its dependencies).  If you use any higher version you'll see grid artifacts in rendering and tensorboard will malfunction. So yeah...don't do that.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyTorch 1.0.1&lt;/strong&gt; Not the latest version of PyTorch- that will not play nicely with the version of FastAI above.  Note however that the conda install of FastAI 1.0.51 grabs the latest PyTorch, which doesn't work.  This is patched over by our own conda install but fyi.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jupyter Lab&lt;/strong&gt; &lt;code&gt;conda install -c conda-forge jupyterlab&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tensorboard&lt;/strong&gt; (i.e. install Tensorflow) and &lt;strong&gt;TensorboardX&lt;/strong&gt; (&lt;a href="https://github.com/lanpa/tensorboardX"&gt;https://github.com/lanpa/tensorboardX&lt;/a&gt;).  I guess you don't &lt;em&gt;have&lt;/em&gt; to but man, life is so much better with it.  FastAI now comes with built in support for this- you just  need to install the prereqs: &lt;code&gt;conda install -c anaconda tensorflow-gpu&lt;/code&gt; and &lt;code&gt;pip install tensorboardX&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ImageNet&lt;/strong&gt; – Only if you're training, of course. It has proven to be a great dataset for my purposes.  &lt;a href="http://www.image-net.org/download-images" rel="nofollow"&gt;http://www.image-net.org/download-images&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-pretrained-weights" class="anchor" aria-hidden="true" href="#pretrained-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pretrained Weights&lt;/h2&gt;
&lt;p&gt;To start right away on your own machine with your own images or videos without training the models yourself, you'll need to download the "Completed Generator Weights" listed below and drop them in the /models/ folder.&lt;/p&gt;
&lt;p&gt;The colorization inference notebooks should be able to guide you from here. The notebooks to use are named ImageColorizerArtistic.ipynb, ImageColorizerStable.ipynb, and VideoColorizer.ipynb.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-completed-generator-weights" class="anchor" aria-hidden="true" href="#completed-generator-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Completed Generator Weights&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/zkehq1uwahhbc2o/ColorizeArtistic_gen.pth?dl=0" rel="nofollow"&gt;Artistic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/mwjep3vyqk5mkjc/ColorizeStable_gen.pth?dl=0" rel="nofollow"&gt;Stable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/336vn9y4qwyg9yz/ColorizeVideo_gen.pth?dl=0" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-completed-critic-weights" class="anchor" aria-hidden="true" href="#completed-critic-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Completed Critic Weights&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/8g5txfzt2fw8mf5/ColorizeArtistic_crit.pth?dl=0" rel="nofollow"&gt;Artistic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/7a8u20e7xdu1dtd/ColorizeStable_crit.pth?dl=0" rel="nofollow"&gt;Stable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/0401djgo1dfxdzt/ColorizeVideo_crit.pth?dl=0" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pretrain-only-generator-weights" class="anchor" aria-hidden="true" href="#pretrain-only-generator-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pretrain Only Generator Weights&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/9zexurvrve141n9/ColorizeArtistic_PretrainOnly_gen.pth?dl=0" rel="nofollow"&gt;Artistic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/mdnuo1563bb8nh4/ColorizeStable_PretrainOnly_gen.pth?dl=0" rel="nofollow"&gt;Stable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/avzixh1ujf86e8x/ColorizeVideo_PretrainOnly_gen.pth?dl=0" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pretrain-only-critic-weights" class="anchor" aria-hidden="true" href="#pretrain-only-critic-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pretrain Only Critic Weights&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/lakxe8akzjgjnmh/ColorizeArtistic_PretrainOnly_crit.pth?dl=0" rel="nofollow"&gt;Artistic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/b3wka56iyv1fvdc/ColorizeStable_PretrainOnly_crit.pth?dl=0" rel="nofollow"&gt;Stable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/j7og84cbhpa94gs/ColorizeVideo_PretrainOnly_crit.pth?dl=0" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-want-the-old-deoldify" class="anchor" aria-hidden="true" href="#want-the-old-deoldify"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Want the Old DeOldify?&lt;/h2&gt;
&lt;p&gt;We suspect some of you are going to want access to the original DeOldify model for various reasons.  We have that archived here:  &lt;a href="https://github.com/dana-kelley/DeOldify"&gt;https://github.com/dana-kelley/DeOldify&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-want-more" class="anchor" aria-hidden="true" href="#want-more"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Want More?&lt;/h2&gt;
&lt;p&gt;Follow &lt;a href="https://twitter.com/search?q=%23Deoldify" rel="nofollow"&gt;#DeOldify&lt;/a&gt; or &lt;a href="https://twitter.com/citnaj" rel="nofollow"&gt;Jason Antic&lt;/a&gt; on Twitter.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;All code in this repository is under the MIT license as specified by the LICENSE file.&lt;/p&gt;
&lt;p&gt;The model weights listed in this readme under the "Pretrained Weights" section are trained by ourselves and are released under the MIT license.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jantic</author><guid isPermaLink="false">https://github.com/jantic/DeOldify</guid><pubDate>Sat, 04 Jan 2020 00:23:00 GMT</pubDate></item><item><title>amueller/introduction_to_ml_with_python #24 in Jupyter Notebook, This week</title><link>https://github.com/amueller/introduction_to_ml_with_python</link><description>&lt;p&gt;&lt;i&gt;Notebooks and code for the book "Introduction to Machine Learning with Python"&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://mybinder.org/v2/gh/amueller/introduction_to_ml_with_python/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-introduction-to-machine-learning-with-python" class="anchor" aria-hidden="true" href="#introduction-to-machine-learning-with-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction to Machine Learning with Python&lt;/h1&gt;
&lt;p&gt;This repository holds the code for the forthcoming book "Introduction to Machine
Learning with Python" by &lt;a href="http://amueller.io" rel="nofollow"&gt;Andreas Mueller&lt;/a&gt; and &lt;a href="https://twitter.com/sarah_guido" rel="nofollow"&gt;Sarah Guido&lt;/a&gt;.
You can find details about the book on the &lt;a href="http://shop.oreilly.com/product/0636920030515.do" rel="nofollow"&gt;O'Reilly website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The books requires the current stable version of scikit-learn, that is
0.20.0.  Most of the book can also be used with previous versions of
scikit-learn, though you need to adjust the import for everything from the
&lt;code&gt;model_selection&lt;/code&gt; module, mostly &lt;code&gt;cross_val_score&lt;/code&gt;, &lt;code&gt;train_test_split&lt;/code&gt;
and &lt;code&gt;GridSearchCV&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This repository provides the notebooks from which the book is created, together
with the &lt;code&gt;mglearn&lt;/code&gt; library of helper functions to create figures and
datasets.&lt;/p&gt;
&lt;p&gt;For the curious ones, the cover depicts a &lt;a href="https://en.wikipedia.org/wiki/Hellbender" rel="nofollow"&gt;hellbender&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All datasets are included in the repository, with the exception of the aclImdb dataset, which you can download from
the page of &lt;a href="http://ai.stanford.edu/~amaas/data/sentiment/" rel="nofollow"&gt;Andrew Maas&lt;/a&gt;. See the book for details.&lt;/p&gt;
&lt;p&gt;If you get &lt;code&gt;ImportError: No module named mglearn&lt;/code&gt; you can try to install mglearn into your python environment using
the command &lt;code&gt;pip install mglearn&lt;/code&gt; in your terminal or &lt;code&gt;!pip install mglearn&lt;/code&gt; in Jupyter Notebook.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-errata" class="anchor" aria-hidden="true" href="#errata"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Errata&lt;/h2&gt;
&lt;p&gt;Please note that the first print of the book is missing the following line when listing the assumed imports:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; IPython.display &lt;span class="pl-k"&gt;import&lt;/span&gt; display&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Please add this line if you see an error involving &lt;code&gt;display&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The first print of the book used a function called &lt;code&gt;plot_group_kfold&lt;/code&gt;.
This has been renamed to &lt;code&gt;plot_label_kfold&lt;/code&gt; because of a rename in
scikit-learn.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h2&gt;
&lt;p&gt;To run the code, you need the packages &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;scipy&lt;/code&gt;, &lt;code&gt;scikit-learn&lt;/code&gt;, &lt;code&gt;matplotlib&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;pillow&lt;/code&gt;.
Some of the visualizations of decision trees and neural networks structures also require &lt;code&gt;graphviz&lt;/code&gt;. The chapter
on text processing also requirs &lt;code&gt;nltk&lt;/code&gt; and &lt;code&gt;spacy&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The easiest way to set up an environment is by installing &lt;a href="https://www.continuum.io/downloads" rel="nofollow"&gt;Anaconda&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-installing-packages-with-conda" class="anchor" aria-hidden="true" href="#installing-packages-with-conda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing packages with conda:&lt;/h3&gt;
&lt;p&gt;If you already have a Python environment set up, and you are using the &lt;code&gt;conda&lt;/code&gt; package manager, you can get all packages by running&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install numpy scipy scikit-learn matplotlib pandas pillow graphviz python-graphviz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the chapter on text processing you also need to install &lt;code&gt;nltk&lt;/code&gt; and &lt;code&gt;spacy&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install nltk spacy
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-installing-packages-with-pip" class="anchor" aria-hidden="true" href="#installing-packages-with-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing packages with pip&lt;/h3&gt;
&lt;p&gt;If you already have a Python environment and are using pip to install packages, you need to run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install numpy scipy scikit-learn matplotlib pandas pillow graphviz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You also need to install the graphiz C-library, which is easiest using a package manager.
If you are using OS X and homebrew, you can &lt;code&gt;brew install graphviz&lt;/code&gt;. If you are on Ubuntu or debian, you can &lt;code&gt;apt-get install graphviz&lt;/code&gt;.
Installing graphviz on Windows can be tricky and using conda / anaconda is recommended.
For the chapter on text processing you also need to install &lt;code&gt;nltk&lt;/code&gt; and &lt;code&gt;spacy&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install nltk spacy
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-downloading-english-language-model" class="anchor" aria-hidden="true" href="#downloading-english-language-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Downloading English language model&lt;/h3&gt;
&lt;p&gt;For the text processing chapter, you need to download the English language model for spacy using&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python -m spacy download en
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-submitting-errata" class="anchor" aria-hidden="true" href="#submitting-errata"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Submitting Errata&lt;/h2&gt;
&lt;p&gt;If you have errata for the (e-)book, please submit them via the &lt;a href="http://www.oreilly.com/catalog/errata.csp?isbn=0636920030515" rel="nofollow"&gt;O'Reilly Website&lt;/a&gt;.
You can submit fixed to the code as pull-requests here, but I'd appreciate it if you would also submit them there, as this repository doesn't hold the
"master notebooks".&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="cover.jpg"&gt;&lt;img src="cover.jpg" alt="cover" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>amueller</author><guid isPermaLink="false">https://github.com/amueller/introduction_to_ml_with_python</guid><pubDate>Sat, 04 Jan 2020 00:24:00 GMT</pubDate></item><item><title>enggen/Deep-Learning-Coursera #25 in Jupyter Notebook, This week</title><link>https://github.com/enggen/Deep-Learning-Coursera</link><description>&lt;p&gt;&lt;i&gt;Deep Learning Specialization by Andrew Ng, deeplearning.ai.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deep-learning-specialization-on-coursera" class="anchor" aria-hidden="true" href="#deep-learning-specialization-on-coursera"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning Specialization on Coursera&lt;/h1&gt;
&lt;h3&gt;&lt;a id="user-content-master-deep-learning-and-break-into-ai" class="anchor" aria-hidden="true" href="#master-deep-learning-and-break-into-ai"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.coursera.org/specializations/deep-learning" rel="nofollow"&gt;Master Deep Learning, and Break into AI&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This is my personal projects for the course. The course covers deep learning from begginer level to advanced. Highly recommend anyone wanting to break into AI.&lt;/p&gt;
&lt;p&gt;Instructor: &lt;a href=""&gt;Andrew Ng, DeepLearning.ai&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-course-1-neural-networks-and-deep-learning" class="anchor" aria-hidden="true" href="#course-1-neural-networks-and-deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course 1. &lt;a href="https://www.youtube.com/watch?v=CS4cs9xVecg&amp;amp;list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0" rel="nofollow"&gt;Neural Networks and Deep Learning&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Week1 - &lt;a href="https://github.com/enggen/Deep-Learning-Coursera/tree/master/Neural%20Networks%20and%20Deep%20Learning"&gt;Introduction to deep learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Week2 - &lt;a href="https://github.com/enggen/Deep-Learning-deeplearning.ai/blob/master/Neural%20Networks%20and%20Deep%20Learning/Logistic%20Regression%20with%20a%20Neural%20Network%20mindset.ipynb"&gt;Neural Networks Basics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Week3 - &lt;a href="https://github.com/enggen/Deep-Learning-deeplearning.ai/blob/master/Neural%20Networks%20and%20Deep%20Learning/Logistic%20Regression%20with%20a%20Neural%20Network%20mindset.ipynb"&gt;Shallow neural networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Week4 - &lt;a href="https://github.com/enggen/Deep-Learning-deeplearning.ai/tree/master/Neural%20Networks%20and%20Deep%20Learning"&gt;Deep Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-course-2-improving-deep-neural-networks-hyperparameter-tuning-regularization-and-optimization" class="anchor" aria-hidden="true" href="#course-2-improving-deep-neural-networks-hyperparameter-tuning-regularization-and-optimization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course 2. &lt;a href="https://www.youtube.com/watch?v=1waHlpKiNyY&amp;amp;list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc" rel="nofollow"&gt;Improving Deep Neural Networks Hyperparameter tuning, Regularization and Optimization&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Week1 - &lt;a href="https://github.com/enggen/Deep-Learning-deeplearning.ai/tree/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization"&gt;Practical aspects of Deep Learning&lt;/a&gt;
- Setting up your Machine Learning Application
- Regularizing your neural network
- Setting up your optimization problem&lt;/li&gt;
&lt;li&gt;Week2 - &lt;a href="https://github.com/enggen/Deep-Learning-deeplearning.ai/tree/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization"&gt;Optimization algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Week3 - &lt;a href="https://github.com/enggen/Deep-Learning-Coursera/tree/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization"&gt;Hyperparameter tuning, Batch Normalization and Programming Frameworks&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-course-3-structuring-machine-learning-projects" class="anchor" aria-hidden="true" href="#course-3-structuring-machine-learning-projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course 3. &lt;a href="https://www.youtube.com/watch?v=dFX8k1kXhOw&amp;amp;list=PLkDaE6sCZn6E7jZ9sN_xHwSHOdjUxUW_b" rel="nofollow"&gt;Structuring Machine Learning Projects&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Week1 - &lt;a href="https://github.com/enggen/Deep-Learning-Coursera/blob/master/Structuring%20Machine%20Learning%20Projects/Week%201%20Quiz%20-%20Bird%20recognition%20in%20the%20city%20of%20Peacetopia%20(case%20study).md"&gt;Introduction to ML Strategy&lt;/a&gt;
- Setting up your goal
- Comparing to human-level performance&lt;/li&gt;
&lt;li&gt;Week2 - &lt;a href="https://github.com/enggen/Deep-Learning-Coursera/blob/master/Structuring%20Machine%20Learning%20Projects/Week%202%20Quiz%20-%20Autonomous%20driving%20(case%20study).md"&gt;ML Strategy (2)&lt;/a&gt;
- Error Analysis
- Mismatched training and dev/test set
- Learning from multiple tasks
- End-to-end deep learning&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-course-4-convolutional-neural-networks" class="anchor" aria-hidden="true" href="#course-4-convolutional-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course 4. &lt;a href="https://www.youtube.com/watch?v=ArPaAX_PhIs&amp;amp;list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF" rel="nofollow"&gt;Convolutional Neural Networks&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Week1 - &lt;a href="https://github.com/enggen/Deep-Learning-Coursera/tree/master/Convolutional%20Neural%20Networks/Week1"&gt;Foundations of Convolutional Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Week2 - &lt;a href="https://github.com/enggen/Deep-Learning-Coursera/tree/master/Convolutional%20Neural%20Networks/Week2/ResNets"&gt;Deep convolutional models: case studies&lt;/a&gt; - Papers for read:  &lt;a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="nofollow"&gt;ImageNet Classification with Deep Convolutional
Neural Networks&lt;/a&gt;, &lt;a href="https://arxiv.org/pdf/1409.1556.pdf" rel="nofollow"&gt;Very Deep Convolutional Networks For Large-Scale Image Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/enggen/Deep-Learning-Coursera/tree/master/Convolutional%20Neural%20Networks/Week3/Car%20detection%20for%20Autonomous%20Driving"&gt;Week3 - Object detection&lt;/a&gt; - Papers for read: &lt;a href="https://arxiv.org/pdf/1506.02640.pdf" rel="nofollow"&gt;You Only Look Once:
Unified, Real-Time Object Detection&lt;/a&gt;, &lt;a href="https://arxiv.org/pdf/1612.08242.pdf" rel="nofollow"&gt;YOLO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Week4 - &lt;a href="https://github.com/enggen/Deep-Learning-Coursera/tree/master/Convolutional%20Neural%20Networks/Week4"&gt;Special applications: Face recognition &amp;amp; Neural style transfer&lt;/a&gt; - Papers for read: &lt;a href="https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf" rel="nofollow"&gt;DeepFace&lt;/a&gt;, &lt;a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Schroff_FaceNet_A_Unified_2015_CVPR_paper.pdf" rel="nofollow"&gt;FaceNet&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-course-5-sequence-models" class="anchor" aria-hidden="true" href="#course-5-sequence-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course 5. &lt;a href="https://www.youtube.com/watch?v=DejHQYAGb7Q&amp;amp;list=PLkDaE6sCZn6F6wUI9tvS_Gw1vaFAx6rd6" rel="nofollow"&gt;Sequence Models&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Week1 - &lt;a href="https://github.com/enggen/Deep-Learning-Coursera/tree/master/Sequence%20Models/Week1"&gt;Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Week2 - &lt;a href="https://github.com/enggen/Deep-Learning-Coursera/tree/master/Sequence%20Models/Week2"&gt;Natural Language Processing &amp;amp; Word Embeddings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Week3 - &lt;a href="https://github.com/enggen/Deep-Learning-Coursera/tree/master/Sequence%20Models/Week3"&gt;Sequence models &amp;amp; Attention mechanism&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p align="center"&gt; *************************************************************************************************************************************&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>enggen</author><guid isPermaLink="false">https://github.com/enggen/Deep-Learning-Coursera</guid><pubDate>Sat, 04 Jan 2020 00:25:00 GMT</pubDate></item></channel></rss>