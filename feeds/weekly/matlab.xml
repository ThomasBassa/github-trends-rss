<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: MATLAB, This week</title><link>https://github.com/trending/matlab?since=weekly</link><description>The top repositories on GitHub for matlab, measured weekly</description><pubDate>Thu, 02 Jan 2020 01:10:45 GMT</pubDate><lastBuildDate>Thu, 02 Jan 2020 01:10:45 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>AvaisP/machine-learning-programming-assignments-coursera-andrew-ng #1 in MATLAB, This week</title><link>https://github.com/AvaisP/machine-learning-programming-assignments-coursera-andrew-ng</link><description>&lt;p&gt;&lt;i&gt;Solutions to Andrew NG's machine learning course on Coursera&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-programming-assignments-coursera-andrew-ng" class="anchor" aria-hidden="true" href="#machine-learning-programming-assignments-coursera-andrew-ng"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;machine-learning-programming-assignments-coursera-andrew-ng&lt;/h1&gt;
&lt;p&gt;Solutions to Andrew NG's machine learning course on Coursera&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>AvaisP</author><guid isPermaLink="false">https://github.com/AvaisP/machine-learning-programming-assignments-coursera-andrew-ng</guid><pubDate>Thu, 02 Jan 2020 00:01:00 GMT</pubDate></item><item><title>Borye/machine-learning-coursera-1 #2 in MATLAB, This week</title><link>https://github.com/Borye/machine-learning-coursera-1</link><description>&lt;p&gt;&lt;i&gt;This repo is specially created for all the work done my me as a part of Coursera's Machine Learning Course.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-coursera" class="anchor" aria-hidden="true" href="#machine-learning-coursera"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;machine-learning-coursera&lt;/h1&gt;
&lt;p&gt;This repo is specially created for all the work done my me as a part of Coursera's Machine Learning Course.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Borye</author><guid isPermaLink="false">https://github.com/Borye/machine-learning-coursera-1</guid><pubDate>Thu, 02 Jan 2020 00:02:00 GMT</pubDate></item><item><title>HuangCongQing/Algorithms_MathModels #3 in MATLAB, This week</title><link>https://github.com/HuangCongQing/Algorithms_MathModels</link><description>&lt;p&gt;&lt;i&gt;【国赛】【美赛】数学建模相关算法 MATLAB实现（2018年初整理）&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-algorithms_mathmodels" class="anchor" aria-hidden="true" href="#algorithms_mathmodels"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Algorithms_MathModels&lt;/h1&gt;
&lt;p&gt;数学建模相关算法 MATLAB实现&lt;/p&gt;
&lt;p&gt;Fork或借鉴请注明出处 &lt;a href="https://github.com/HuangCongQing"&gt;@ChungKing&lt;/a&gt; . Thx&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;国赛论文资料： 链接：&lt;a href="https://pan.baidu.com/s/1xz8kbFauskpzenlgv4koiQ" rel="nofollow"&gt;https://pan.baidu.com/s/1xz8kbFauskpzenlgv4koiQ&lt;/a&gt;
提取码：3kjt&lt;/li&gt;
&lt;li&gt;美赛资料：链接：&lt;a href="https://github.com/HuangCongQing/Algorithms_MathModels/issues/2#issuecomment-565820094"&gt;https://github.com/HuangCongQing/Algorithms_MathModels/issues/2#issuecomment-565820094&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;数模学习视频：链接：&lt;a href="https://pan.baidu.com/s/1TcL5q1he6YfYFNBi9ZzSlw" rel="nofollow"&gt;https://pan.baidu.com/s/1TcL5q1he6YfYFNBi9ZzSlw&lt;/a&gt;
提取码：osbm&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;本项目为数学建模竞赛中所学习使用的相关算法的MATLAB实现。部分参考于&lt;a href="https://github.com/NarcissusHliangZhao/Algorithm_Implementation_in_MatModel"&gt;NarcissusHliangZhao&lt;/a&gt; 。Thanks。 具体内容包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;《MATLAB 神经网络30个案例分析》&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;《基于MATLAB的高等数学问题求解》&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;模拟退火算法-最优路径&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;层次分析法(AHP)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;元胞自动机(Cellular Automata)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;模糊数学模型(Fuzzy Mathematical Model&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;目标规划(Goal Programming)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;图论(Graph Theory)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;灰色系统建模(Grey System)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;启发式算法(Heuristic Algorithm)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;免疫算法(Immune Algorithm)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;整数规划(Integer Programming)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;《MATLAB智能算法案例》(Intelligence Algorithm)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;插值(Interpolation)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;线性规划(Linear Programming)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多元分析(Multivarite Analysis)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;神经网络(Neural Network)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;非线性规划(Non Linear Programming)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;常微分方程(Oridinary Differential Equation)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;偏微分方程(Partial Differential Equation)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;偏最小二乘法(Partial Least Squares)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;《模式识别与机器学习》(Pattern Recognition and Machine Learning)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;回归分析(Regression Analysis)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;时间序列模型(Time Series)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-下载单个文件夹或文件" class="anchor" aria-hidden="true" href="#下载单个文件夹或文件"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;下载单个文件夹或文件&lt;/h5&gt;
&lt;p&gt;&lt;a href="http://downgit.zhoudaxiaa.com/" rel="nofollow"&gt;http://downgit.zhoudaxiaa.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;将github文件夹或文件&lt;strong&gt;链接&lt;/strong&gt;复制粘贴入DownGit中，选择download即可;&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;&lt;a id="user-content-related-links" class="anchor" aria-hidden="true" href="#related-links"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Related links&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/19714813/answer/18748623" rel="nofollow"&gt;如何入门参与&lt;em&gt;数学建模&lt;/em&gt;？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;论坛——&lt;a href="http://www.mathor.com/forum.php" rel="nofollow"&gt;校苑数模|数学建模&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-大学生相关" class="anchor" aria-hidden="true" href="#大学生相关"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;大学生相关&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/J2r4WQ3GFUy_t0mNe_s5IA" rel="nofollow"&gt;给我们大学生推荐的自学网站（App）&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://mp.weixin.qq.com/s/kWJi___BTCdj5STTxaAz8Q" rel="nofollow"&gt;大学毕业生采访&amp;amp;&amp;amp;大学四年总结分享&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;希望对大家有所帮助！&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LICENSE&lt;/h3&gt;
&lt;p&gt;本项目全部内容遵守 MIT 许可协议.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0cf016a535bd9d48eeddd9a867838339defd455a/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f343334303737322d313539363566646135636465303238312e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430"&gt;&lt;img src="https://camo.githubusercontent.com/0cf016a535bd9d48eeddd9a867838339defd455a/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f343334303737322d313539363566646135636465303238312e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430" alt="" data-canonical-src="https://upload-images.jianshu.io/upload_images/4340772-15965fda5cde0281.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>HuangCongQing</author><guid isPermaLink="false">https://github.com/HuangCongQing/Algorithms_MathModels</guid><pubDate>Thu, 02 Jan 2020 00:03:00 GMT</pubDate></item><item><title>TadasBaltrusaitis/OpenFace #4 in MATLAB, This week</title><link>https://github.com/TadasBaltrusaitis/OpenFace</link><description>&lt;p&gt;&lt;i&gt;OpenFace – a state-of-the art tool intended for facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-openface-220-a-facial-behavior-analysis-toolkit" class="anchor" aria-hidden="true" href="#openface-220-a-facial-behavior-analysis-toolkit"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;OpenFace 2.2.0: a facial behavior analysis toolkit&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/TadasBaltrusaitis/OpenFace" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/4243d567083c3a651ecbadc77c77a00ba697fb40/68747470733a2f2f7472617669732d63692e6f72672f546164617342616c7472757361697469732f4f70656e466163652e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/TadasBaltrusaitis/OpenFace.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/TadasBaltrusaitis/openface/branch/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8c6fb6db38385292d352f1b17205f42469d06fda/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f386d73696b6c786662686c6e736d78702f6272616e63682f6d61737465723f7376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/8msiklxfbhlnsmxp/branch/master?svg=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Over the past few years, there has been an increased interest in automatic facial behavior analysis
and understanding. We present OpenFace – a tool intended for computer vision and machine learning
researchers, affective computing community and people interested in building interactive
applications based on facial behavior analysis. OpenFace is the ﬁrst toolkit capable of facial
landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation
with available source code for both running and training the models. The computer vision algorithms
which represent the core of OpenFace demonstrate state-of-the-art results in all of the above
mentioned tasks. Furthermore, our tool is capable of real-time performance and is able to run from a
simple webcam without any specialist hardware.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/muticomp_logo_black.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/muticomp_logo_black.png" alt="Multicomp logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;OpenFace was originally developed by Tadas Baltrušaitis in collaboration with CMU MultiComp Lab led by Prof. Louis-Philippe Morency. Some of the original algorithms were created while at Rainbow Group, Cambridge University. The OpenFace library is still actively developed at the CMU MultiComp Lab in collaboration with Tadas Baltršaitis. Special thanks to researcher who helped developing, implementing and testing the algorithms present in OpenFace: Amir Zadeh and Yao Chong Lim on work on the CE-CLM model and Erroll Wood for the gaze estimation work.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-wiki" class="anchor" aria-hidden="true" href="#wiki"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WIKI&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;For instructions of how to install/compile/use the project please see &lt;a href="https://github.com/TadasBaltrusaitis/OpenFace/wiki"&gt;WIKI&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-functionality" class="anchor" aria-hidden="true" href="#functionality"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Functionality&lt;/h2&gt;
&lt;p&gt;The system is capable of performing a number of facial analysis tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facial Landmark Detection&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/multi_face_img.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/multi_face_img.png" alt="Sample facial landmark detection image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facial Landmark and head pose tracking (links to YouTube videos)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=V7rV0uy7heQ" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/861e54570c553cb53c797dd8bc57a24f29152655/687474703a2f2f696d672e796f75747562652e636f6d2f76692f56377256307579376865512f302e6a7067" alt="Multiple Face Tracking" width="240" height="180" border="10" data-canonical-src="http://img.youtube.com/vi/V7rV0uy7heQ/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.youtube.com/watch?v=vYOa8Pif5lY" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a9137826a1740e8df2125ef9b76541445e32957e/687474703a2f2f696d672e796f75747562652e636f6d2f76692f76594f6138506966356c592f302e6a7067" alt="Multiple Face Tracking" width="240" height="180" border="10" data-canonical-src="http://img.youtube.com/vi/vYOa8Pif5lY/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facial Action Unit Recognition&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/au_sample.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/au_sample.png" height="280" width="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gaze tracking (image of it in action)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/gaze_ex.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/gaze_ex.png" height="182" width="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facial Feature Extraction (aligned faces and HOG features)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/appearance.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/appearance.png" alt="Sample aligned face and HOG image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you use any of the resources provided on this page in any of your publications we ask you to cite the following work and the work for a relevant submodule you used.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-overall-system" class="anchor" aria-hidden="true" href="#overall-system"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overall system&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;OpenFace 2.0: Facial Behavior Analysis Toolkit&lt;/strong&gt;
Tadas Baltrušaitis, Amir Zadeh, Yao Chong Lim, and Louis-Philippe Morency,
&lt;em&gt;IEEE International Conference on Automatic Face and Gesture Recognition&lt;/em&gt;, 2018&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-facial-landmark-detection-and-tracking" class="anchor" aria-hidden="true" href="#facial-landmark-detection-and-tracking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Facial landmark detection and tracking&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Convolutional experts constrained local model for facial landmark detection&lt;/strong&gt;
A. Zadeh, T. Baltrušaitis, and Louis-Philippe Morency.
&lt;em&gt;Computer Vision and Pattern Recognition Workshops&lt;/em&gt;, 2017&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Constrained Local Neural Fields for robust facial landmark detection in the wild&lt;/strong&gt;
Tadas Baltrušaitis, Peter Robinson, and Louis-Philippe Morency.
in IEEE Int. &lt;em&gt;Conference on Computer Vision Workshops, 300 Faces in-the-Wild Challenge&lt;/em&gt;, 2013.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-eye-gaze-tracking" class="anchor" aria-hidden="true" href="#eye-gaze-tracking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Eye gaze tracking&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Rendering of Eyes for Eye-Shape Registration and Gaze Estimation&lt;/strong&gt;
Erroll Wood, Tadas Baltrušaitis, Xucong Zhang, Yusuke Sugano, Peter Robinson, and Andreas Bulling
in &lt;em&gt;IEEE International Conference on Computer Vision (ICCV)&lt;/em&gt;, 2015&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-facial-action-unit-detection" class="anchor" aria-hidden="true" href="#facial-action-unit-detection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Facial Action Unit detection&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Cross-dataset learning and person-specific normalisation for automatic Action Unit detection&lt;/strong&gt;
Tadas Baltrušaitis, Marwa Mahmoud, and Peter Robinson
in &lt;em&gt;Facial Expression Recognition and Analysis Challenge&lt;/em&gt;,
&lt;em&gt;IEEE International Conference on Automatic Face and Gesture Recognition&lt;/em&gt;, 2015&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-commercial-license" class="anchor" aria-hidden="true" href="#commercial-license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Commercial license&lt;/h1&gt;
&lt;p&gt;For inquiries about the commercial licensing of the OpenFace toolkit please visit &lt;a href="https://www.flintbox.com/public/project/50632/" rel="nofollow"&gt;https://www.flintbox.com/public/project/50632/&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-final-remarks" class="anchor" aria-hidden="true" href="#final-remarks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Final remarks&lt;/h1&gt;
&lt;p&gt;I did my best to make sure that the code runs out of the box but there are always issues and I would be grateful for your understanding that this is research code and a research project. If you encounter any problems/bugs/issues please contact me on github or by emailing me at &lt;a href="mailto:tadyla@gmail.com"&gt;tadyla@gmail.com&lt;/a&gt; for any bug reports/questions/suggestions. I prefer questions and bug reports on github as that provides visibility to others who might be encountering same issues or who have the same questions.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-copyright" class="anchor" aria-hidden="true" href="#copyright"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Copyright&lt;/h1&gt;
&lt;p&gt;Copyright can be found in the Copyright.txt&lt;/p&gt;
&lt;p&gt;You have to respect dlib, OpenBLAS, and OpenCV licenses.&lt;/p&gt;
&lt;p&gt;Furthermore you have to respect the licenses of the datasets used for model training - &lt;a href="https://github.com/TadasBaltrusaitis/OpenFace/wiki/Datasets"&gt;https://github.com/TadasBaltrusaitis/OpenFace/wiki/Datasets&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>TadasBaltrusaitis</author><guid isPermaLink="false">https://github.com/TadasBaltrusaitis/OpenFace</guid><pubDate>Thu, 02 Jan 2020 00:04:00 GMT</pubDate></item><item><title>rasmusbergpalm/DeepLearnToolbox #5 in MATLAB, This week</title><link>https://github.com/rasmusbergpalm/DeepLearnToolbox</link><description>&lt;p&gt;&lt;i&gt;Matlab/Octave toolbox for deep learning. Includes Deep Belief Nets, Stacked Autoencoders, Convolutional Neural Nets, Convolutional Autoencoders and vanilla Neural Nets. Each method has examples to get you started.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-deprecation-notice" class="anchor" aria-hidden="true" href="#deprecation-notice"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deprecation notice.&lt;/h2&gt;
&lt;p&gt;This toolbox is outdated and no longer maintained.&lt;/p&gt;
&lt;p&gt;There are much better tools available for deep learning than this toolbox, e.g. &lt;a href="http://deeplearning.net/software/theano/" rel="nofollow"&gt;Theano&lt;/a&gt;, &lt;a href="http://torch.ch/" rel="nofollow"&gt;torch&lt;/a&gt; or &lt;a href="http://www.tensorflow.org/" rel="nofollow"&gt;tensorflow&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I would suggest you use one of the tools mentioned above rather than use this toolbox.&lt;/p&gt;
&lt;p&gt;Best, Rasmus.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-deeplearntoolbox" class="anchor" aria-hidden="true" href="#deeplearntoolbox"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DeepLearnToolbox&lt;/h1&gt;
&lt;p&gt;A Matlab toolbox for Deep Learning.&lt;/p&gt;
&lt;p&gt;Deep Learning is a new subfield of machine learning that focuses on learning deep hierarchical models of data.
It is inspired by the human brain's apparent deep (layered, hierarchical) architecture.
A good overview of the theory of Deep Learning theory is
&lt;a href="http://www.iro.umontreal.ca/~bengioy/papers/ftml_book.pdf" rel="nofollow"&gt;Learning Deep Architectures for AI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For a more informal introduction, see the following videos by Geoffrey Hinton and Andrew Ng.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.youtube.com/watch?v=AyzOUbkUf3M" rel="nofollow"&gt;The Next Generation of Neural Networks&lt;/a&gt; (Hinton, 2007)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.youtube.com/watch?v=VdIURAu1-aU" rel="nofollow"&gt;Recent Developments in Deep Learning&lt;/a&gt; (Hinton, 2010)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.youtube.com/watch?v=ZmNOAtZIgIk" rel="nofollow"&gt;Unsupervised Feature Learning and Deep Learning&lt;/a&gt; (Ng, 2011)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you use this toolbox in your research please cite &lt;a href="http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6284" rel="nofollow"&gt;Prediction as a candidate for learning deep hierarchical models of data&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@MASTERSTHESIS\{IMM2012-06284,
    author       = "R. B. Palm",
    title        = "Prediction as a candidate for learning deep hierarchical models of data",
    year         = "2012",
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Contact: rasmusbergpalm at gmail dot com&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-directories-included-in-the-toolbox" class="anchor" aria-hidden="true" href="#directories-included-in-the-toolbox"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Directories included in the toolbox&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;NN/&lt;/code&gt;   - A library for Feedforward Backpropagation Neural Networks&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CNN/&lt;/code&gt;  - A library for Convolutional Neural Networks&lt;/p&gt;
&lt;p&gt;&lt;code&gt;DBN/&lt;/code&gt;  - A library for Deep Belief Networks&lt;/p&gt;
&lt;p&gt;&lt;code&gt;SAE/&lt;/code&gt;  - A library for Stacked Auto-Encoders&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CAE/&lt;/code&gt; - A library for Convolutional Auto-Encoders&lt;/p&gt;
&lt;p&gt;&lt;code&gt;util/&lt;/code&gt; - Utility functions used by the libraries&lt;/p&gt;
&lt;p&gt;&lt;code&gt;data/&lt;/code&gt; - Data used by the examples&lt;/p&gt;
&lt;p&gt;&lt;code&gt;tests/&lt;/code&gt; - unit tests to verify toolbox is working&lt;/p&gt;
&lt;p&gt;For references on each library check REFS.md&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Download.&lt;/li&gt;
&lt;li&gt;addpath(genpath('DeepLearnToolbox'));&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-example-deep-belief-network" class="anchor" aria-hidden="true" href="#example-deep-belief-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example: Deep Belief Network&lt;/h2&gt;
&lt;div class="highlight highlight-source-matlab"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;function&lt;/span&gt; &lt;span class="pl-en"&gt;test_example_DBN&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;span class="pl-smi"&gt;load&lt;/span&gt; mnist_uint8;&lt;/span&gt;

train_x = double(train_x) &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255&lt;/span&gt;;
test_x  = double(test_x)  &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255&lt;/span&gt;;
train_y = double(train_y);
test_y  = double(test_y);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt;  ex1 train a 100 hidden unit RBM and visualize its weights&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
dbn.sizes = [&lt;span class="pl-c1"&gt;100&lt;/span&gt;];
opts.numepochs =   &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;
opts.momentum  =   &lt;span class="pl-c1"&gt;0&lt;/span&gt;;
opts.alpha     =   &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
dbn = dbnsetup(dbn, train_x, opts);
dbn = dbntrain(dbn, train_x, opts);
figure; visualize(dbn.rbm{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}.&lt;span class="pl-k"&gt;W'&lt;/span&gt;);   &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Visualize the RBM weights&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt;  ex2 train a 100-100 hidden unit DBN and use its weights to initialize a NN&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;train dbn&lt;/span&gt;
dbn.sizes = [&lt;span class="pl-c1"&gt;100&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt;];
opts.numepochs =   &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;
opts.momentum  =   &lt;span class="pl-c1"&gt;0&lt;/span&gt;;
opts.alpha     =   &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
dbn = dbnsetup(dbn, train_x, opts);
dbn = dbntrain(dbn, train_x, opts);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;unfold dbn to nn&lt;/span&gt;
nn = dbnunfoldtonn(dbn, &lt;span class="pl-c1"&gt;10&lt;/span&gt;);
nn.activation_function = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sigm&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;train nn&lt;/span&gt;
opts.numepochs =  &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;
nn = nntrain(nn, train_x, train_y, opts);
[er, bad] = nntest(nn, test_x, test_y);

assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.10&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-example-stacked-auto-encoders" class="anchor" aria-hidden="true" href="#example-stacked-auto-encoders"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example: Stacked Auto-Encoders&lt;/h2&gt;
&lt;div class="highlight highlight-source-matlab"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;function&lt;/span&gt; &lt;span class="pl-en"&gt;test_example_SAE&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;span class="pl-smi"&gt;load&lt;/span&gt; mnist_uint8;&lt;/span&gt;

train_x = double(train_x)/&lt;span class="pl-c1"&gt;255&lt;/span&gt;;
test_x  = double(test_x)/&lt;span class="pl-c1"&gt;255&lt;/span&gt;;
train_y = double(train_y);
test_y  = double(test_y);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt;  ex1 train a 100 hidden unit SDAE and use it to initialize a FFNN&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Setup and train a stacked denoising autoencoder (SDAE)&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
sae = saesetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt;]);
sae.ae{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}.activation_function       = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sigm&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;
sae.ae{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}.learningRate              = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
sae.ae{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}.inputZeroMaskedFraction   = &lt;span class="pl-c1"&gt;0.5&lt;/span&gt;;
opts.numepochs =   &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;
sae = saetrain(sae, train_x, opts);
visualize(sae.ae{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}.W{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}(:,&lt;span class="pl-c1"&gt;2&lt;/span&gt;:&lt;span class="pl-k"&gt;end&lt;/span&gt;)&lt;span class="pl-k"&gt;'&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt; Use the SDAE to initialize a FFNN&lt;/span&gt;
nn = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);
nn.activation_function              = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sigm&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;
nn.learningRate                     = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
nn.W{&lt;span class="pl-c1"&gt;1&lt;/span&gt;} = sae.ae{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}.W{&lt;span class="pl-c1"&gt;1&lt;/span&gt;};

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt; Train the FFNN&lt;/span&gt;
opts.numepochs =   &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;
nn = nntrain(nn, train_x, train_y, opts);
[er, bad] = nntest(nn, test_x, test_y);
assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.16&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-example-convolutional-neural-nets" class="anchor" aria-hidden="true" href="#example-convolutional-neural-nets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example: Convolutional Neural Nets&lt;/h2&gt;
&lt;div class="highlight highlight-source-matlab"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;function&lt;/span&gt; &lt;span class="pl-en"&gt;test_example_CNN&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;span class="pl-smi"&gt;load&lt;/span&gt; mnist_uint8;&lt;/span&gt;

train_x = double(reshape(&lt;span class="pl-k"&gt;train_x'&lt;/span&gt;,&lt;span class="pl-c1"&gt;28&lt;/span&gt;,&lt;span class="pl-c1"&gt;28&lt;/span&gt;,&lt;span class="pl-c1"&gt;60000&lt;/span&gt;))/&lt;span class="pl-c1"&gt;255&lt;/span&gt;;
test_x = double(reshape(&lt;span class="pl-k"&gt;test_x'&lt;/span&gt;,&lt;span class="pl-c1"&gt;28&lt;/span&gt;,&lt;span class="pl-c1"&gt;28&lt;/span&gt;,&lt;span class="pl-c1"&gt;10000&lt;/span&gt;))/&lt;span class="pl-c1"&gt;255&lt;/span&gt;;
train_y = double(&lt;span class="pl-k"&gt;train_y'&lt;/span&gt;);
test_y = double(&lt;span class="pl-k"&gt;test_y'&lt;/span&gt;);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex1 Train a 6c-2s-12c-2s Convolutional neural network &lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;will run 1 epoch in about 200 second and get around 11% error. &lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;With 100 epochs you'll get around 1.2% error&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
cnn.layers = {
    struct(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;type&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;i&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;input layer&lt;/span&gt;
    struct(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;type&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;c&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;outputmaps&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;6&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kernelsize&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;5&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;convolution layer&lt;/span&gt;
    struct(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;type&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;s&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;scale&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;sub sampling layer&lt;/span&gt;
    struct(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;type&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;c&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;outputmaps&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;12&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kernelsize&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;5&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;convolution layer&lt;/span&gt;
    struct(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;type&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;s&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;scale&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;subsampling layer&lt;/span&gt;
};
cnn = cnnsetup(cnn, train_x, train_y);

opts.alpha = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
opts.batchsize = &lt;span class="pl-c1"&gt;50&lt;/span&gt;;
opts.numepochs = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;

cnn = cnntrain(cnn, train_x, train_y, opts);

[er, bad] = cnntest(cnn, test_x, test_y);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;plot mean squared error&lt;/span&gt;
figure; plot(cnn.rL);

assert(er&amp;lt;0.12, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-example-neural-networks" class="anchor" aria-hidden="true" href="#example-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example: Neural Networks&lt;/h2&gt;
&lt;div class="highlight highlight-source-matlab"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;function&lt;/span&gt; &lt;span class="pl-en"&gt;test_example_NN&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;span class="pl-smi"&gt;load&lt;/span&gt; mnist_uint8;&lt;/span&gt;

train_x = double(train_x) &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255&lt;/span&gt;;
test_x  = double(test_x)  &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255&lt;/span&gt;;
train_y = double(train_y);
test_y  = double(test_y);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt; normalize&lt;/span&gt;
[train_x, mu, sigma] = zscore(train_x);
test_x = normalize(test_x, mu, sigma);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex1 vanilla neural net&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
nn = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);
opts.numepochs =  &lt;span class="pl-c1"&gt;1&lt;/span&gt;;   &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Number of full sweeps through data&lt;/span&gt;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Take a mean gradient step over this many samples&lt;/span&gt;
[nn, L] = nntrain(nn, train_x, train_y, opts);

[er, bad] = nntest(nn, test_x, test_y);

assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.08&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex2 neural net with L2 weight decay&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
nn = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);

nn.weightPenaltyL2 = &lt;span class="pl-c1"&gt;1e-4&lt;/span&gt;;  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  L2 weight decay&lt;/span&gt;
opts.numepochs =  &lt;span class="pl-c1"&gt;1&lt;/span&gt;;        &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Number of full sweeps through data&lt;/span&gt;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;       &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Take a mean gradient step over this many samples&lt;/span&gt;

nn = nntrain(nn, train_x, train_y, opts);

[er, bad] = nntest(nn, test_x, test_y);
assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.1&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);


&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex3 neural net with dropout&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
nn = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);

nn.dropoutFraction = &lt;span class="pl-c1"&gt;0.5&lt;/span&gt;;   &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Dropout fraction &lt;/span&gt;
opts.numepochs =  &lt;span class="pl-c1"&gt;1&lt;/span&gt;;        &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Number of full sweeps through data&lt;/span&gt;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;       &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Take a mean gradient step over this many samples&lt;/span&gt;

nn = nntrain(nn, train_x, train_y, opts);

[er, bad] = nntest(nn, test_x, test_y);
assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.1&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex4 neural net with sigmoid activation function&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
nn = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);

nn.activation_function = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sigm&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Sigmoid activation function&lt;/span&gt;
nn.learningRate = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;                &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Sigm require a lower learning rate&lt;/span&gt;
opts.numepochs =  &lt;span class="pl-c1"&gt;1&lt;/span&gt;;                &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Number of full sweeps through data&lt;/span&gt;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;               &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Take a mean gradient step over this many samples&lt;/span&gt;

nn = nntrain(nn, train_x, train_y, opts);

[er, bad] = nntest(nn, test_x, test_y);
assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.1&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex5 plotting functionality&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
nn = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;20&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);
opts.numepochs         = &lt;span class="pl-c1"&gt;5&lt;/span&gt;;            &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Number of full sweeps through data&lt;/span&gt;
nn.output              = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;softmax&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  use softmax output&lt;/span&gt;
opts.batchsize         = &lt;span class="pl-c1"&gt;1000&lt;/span&gt;;         &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Take a mean gradient step over this many samples&lt;/span&gt;
opts.plot              = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;            &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  enable plotting&lt;/span&gt;

nn = nntrain(nn, train_x, train_y, opts);

[er, bad] = nntest(nn, test_x, test_y);
assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.1&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex6 neural net with sigmoid activation and plotting of validation and training error&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt; split training data into training and validation data&lt;/span&gt;
vx   = train_x(&lt;span class="pl-c1"&gt;1&lt;/span&gt;:&lt;span class="pl-c1"&gt;10000&lt;/span&gt;,:);
tx = train_x(&lt;span class="pl-c1"&gt;10001&lt;/span&gt;:&lt;span class="pl-k"&gt;end&lt;/span&gt;,:);
vy   = train_y(&lt;span class="pl-c1"&gt;1&lt;/span&gt;:&lt;span class="pl-c1"&gt;10000&lt;/span&gt;,:);
ty = train_y(&lt;span class="pl-c1"&gt;10001&lt;/span&gt;:&lt;span class="pl-k"&gt;end&lt;/span&gt;,:);

rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
nn                      = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;20&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);     
nn.output               = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;softmax&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;                   &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  use softmax output&lt;/span&gt;
opts.numepochs          = &lt;span class="pl-c1"&gt;5&lt;/span&gt;;                           &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Number of full sweeps through data&lt;/span&gt;
opts.batchsize          = &lt;span class="pl-c1"&gt;1000&lt;/span&gt;;                        &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Take a mean gradient step over this many samples&lt;/span&gt;
opts.plot               = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;                           &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  enable plotting&lt;/span&gt;
nn = nntrain(nn, tx, ty, opts, vx, vy);                &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  nntrain takes validation set as last two arguments (optionally)&lt;/span&gt;

[er, bad] = nntest(nn, test_x, test_y);
assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.1&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://bitdeli.com/free" title="Bitdeli Badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/00e5bbbe78ce5418547b4672181b673cccc1c89c/68747470733a2f2f64327765637a68766c38323376302e636c6f756466726f6e742e6e65742f7261736d75736265726770616c6d2f646565706c6561726e746f6f6c626f782f7472656e642e706e67" alt="Bitdeli Badge" data-canonical-src="https://d2weczhvl823v0.cloudfront.net/rasmusbergpalm/deeplearntoolbox/trend.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>rasmusbergpalm</author><guid isPermaLink="false">https://github.com/rasmusbergpalm/DeepLearnToolbox</guid><pubDate>Thu, 02 Jan 2020 00:05:00 GMT</pubDate></item><item><title>atinesh-s/Coursera-Machine-Learning-Stanford #6 in MATLAB, This week</title><link>https://github.com/atinesh-s/Coursera-Machine-Learning-Stanford</link><description>&lt;p&gt;&lt;i&gt;Machine learning-Stanford University&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-coursera" class="anchor" aria-hidden="true" href="#machine-learning-coursera"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning (Coursera)&lt;/h1&gt;
&lt;p&gt;This is my solution to all the programming assignments and quizzes of Machine-Learning (Coursera) taught by Andrew Ng. After completing this course you will get a broad idea of Machine learning algorithms. Try to solve all the assignments by yourself first, but if you get stuck somewhere then feel free to browse the code.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Lectures Slides&lt;/li&gt;
&lt;li&gt;Solution to programming assignment&lt;/li&gt;
&lt;li&gt;Solution to Quizzes&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-certificate" class="anchor" aria-hidden="true" href="#certificate"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Certificate&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/account/accomplishments/certificate/GDDBFB572MUQ" rel="nofollow"&gt;Verified Certificate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-references" class="anchor" aria-hidden="true" href="#references"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.coursera.org/learn/machine-learning" rel="nofollow"&gt;[1] Machine Learning - Stanford University&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>atinesh-s</author><guid isPermaLink="false">https://github.com/atinesh-s/Coursera-Machine-Learning-Stanford</guid><pubDate>Thu, 02 Jan 2020 00:06:00 GMT</pubDate></item><item><title>hhping/LDPC_en-decoder #7 in MATLAB, This week</title><link>https://github.com/hhping/LDPC_en-decoder</link><description>&lt;p&gt;&lt;i&gt;LDPC编码解码matlab代码和Verilog代码及资料&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;This repo does not have a README.&lt;/i&gt;&lt;/p&gt;</description><author>hhping</author><guid isPermaLink="false">https://github.com/hhping/LDPC_en-decoder</guid><pubDate>Thu, 02 Jan 2020 00:07:00 GMT</pubDate></item></channel></rss>