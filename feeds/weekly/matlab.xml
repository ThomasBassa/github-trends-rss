<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: MATLAB, This week</title><link>https://github.com/trending/matlab?since=weekly</link><description>The top repositories on GitHub for matlab, measured weekly</description><pubDate>Sun, 02 Feb 2020 01:10:52 GMT</pubDate><lastBuildDate>Sun, 02 Feb 2020 01:10:52 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>atinesh-s/Coursera-Machine-Learning-Stanford #1 in MATLAB, This week</title><link>https://github.com/atinesh-s/Coursera-Machine-Learning-Stanford</link><description>&lt;p&gt;&lt;i&gt;Machine learning-Stanford University&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-coursera" class="anchor" aria-hidden="true" href="#machine-learning-coursera"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning (Coursera)&lt;/h1&gt;
&lt;p&gt;This is my solution to all the programming assignments and quizzes of Machine-Learning (Coursera) taught by Andrew Ng. After completing this course you will get a broad idea of Machine learning algorithms. Try to solve all the assignments by yourself first, but if you get stuck somewhere then feel free to browse the code.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Lectures Slides&lt;/li&gt;
&lt;li&gt;Solution to programming assignment&lt;/li&gt;
&lt;li&gt;Solution to Quizzes&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-certificate" class="anchor" aria-hidden="true" href="#certificate"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Certificate&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/account/accomplishments/certificate/GDDBFB572MUQ" rel="nofollow"&gt;Verified Certificate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-references" class="anchor" aria-hidden="true" href="#references"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.coursera.org/learn/machine-learning" rel="nofollow"&gt;[1] Machine Learning - Stanford University&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>atinesh-s</author><guid isPermaLink="false">https://github.com/atinesh-s/Coursera-Machine-Learning-Stanford</guid><pubDate>Sun, 02 Feb 2020 00:01:00 GMT</pubDate></item><item><title>BIMK/PlatEMO #2 in MATLAB, This week</title><link>https://github.com/BIMK/PlatEMO</link><description>&lt;p&gt;&lt;i&gt;Evolutionary multi-objective optimization platform&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./Doc/logo.png"&gt;&lt;img src="./Doc/logo.png" width="256" height="256" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;  
&lt;h1&gt;&lt;a id="user-content-platemo" class="anchor" aria-hidden="true" href="#platemo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PlatEMO&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/BIMK/PlatEMO/archive/master.zip"&gt;&lt;img src="https://camo.githubusercontent.com/60b2e104217818ea0706e204aaeb52889e4277e1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f776e6c6f61642d4c61746573742d79656c6c6f772e737667" alt="" data-canonical-src="https://img.shields.io/badge/Download-Latest-yellow.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/BIMK/PlatEMO/releases/"&gt;&lt;img src="https://camo.githubusercontent.com/a937e90f46f8f309d041125cc9e76dd9f855a60d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f42494d4b2f506c6174454d4f2e737667" alt="" data-canonical-src="https://img.shields.io/github/release/BIMK/PlatEMO.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="#PlatEMO"&gt;&lt;img src="https://camo.githubusercontent.com/29182b460d257897b808b436a175dd3ac5e09b2e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d61746c61622d25334525334425323032303134612532302d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/Matlab-%3E%3D%202014a%20-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="#PlatEMO"&gt;&lt;img src="https://camo.githubusercontent.com/c2089b82da22e530e36e7f825c55464b3cc9b18e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f57696e646f77732d506173732d627269676874677265656e2e737667" alt="" data-canonical-src="https://img.shields.io/badge/Windows-Pass-brightgreen.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="#PlatEMO"&gt;&lt;img src="https://camo.githubusercontent.com/1638e630880206a9e39ffca48c5208c4933cc8b9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e75782d506173732d627269676874677265656e2e737667" alt="" data-canonical-src="https://img.shields.io/badge/Linux-Pass-brightgreen.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="#PlatEMO"&gt;&lt;img src="https://camo.githubusercontent.com/2e16b98fc4082773919cced9fd255ed247d80015/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d61634f532d56616c69646174696e672d7265642e737667" alt="" data-canonical-src="https://img.shields.io/badge/MacOS-Validating-red.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;br&gt;
Evolutionary multi-objective optimization platform&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;100+ open source evolutionary algorithms&lt;/li&gt;
&lt;li&gt;200+ open source multi-objective test problems&lt;/li&gt;
&lt;li&gt;Powerful GUI for performing experiments in parallel&lt;/li&gt;
&lt;li&gt;Generating results in the format of Excel or LaTeX table by one-click operation&lt;/li&gt;
&lt;li&gt;State-of-the-art algorithms will be included continuously&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thank you very much for using PlatEMO. The copyright of PlatEMO belongs to the BIMK Group. This
tool is mainly for research and educational purposes. The codes were implemented based on our
understanding of the algorithms published in the papers. You should not rely upon the material or
information on the website as a basis for making any business, legal or any other decisions. We
assume no responsibilities for any consequences of your using any algorithms in the tool. All
publications using the platform should acknowledge the use of “PlatEMO” and reference the
following literature:&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-copyright" class="anchor" aria-hidden="true" href="#copyright"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Copyright&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The Copyright of the PlatEMO belongs to the BIMK group. You are free to &lt;a href="https://github.com/BIMK/PlatEMO/releases"&gt;use the PlatEMO&lt;/a&gt; for &lt;strong&gt;research purposes&lt;/strong&gt;. All publications which use this platform or any code in the platform should &lt;strong&gt;acknowledge the use of "PlatEMO" and reference&lt;/strong&gt; &lt;em&gt;"Ye Tian, Ran Cheng, Xingyi Zhang, and Yaochu Jin, PlatEMO: A MATLAB Platform for Evolutionary Multi-Objective Optimization [Educational Forum], IEEE Computational Intelligence Magazine, 2017, 12(4): 73-87".&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;@article{PlatEMO,
  title={{PlatEMO}: A {MATLAB} platform for evolutionary multi-objective optimization},
  author={Tian, Ye and Cheng, Ran and Zhang, Xingyi and Jin, Yaochu},
  journal={IEEE Computational Intelligence Magazine},
  volume={12},
  number={4},
  pages={73--87},
  year={2017},
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;&lt;a id="user-content-release-highlights-of-platemo-24" class="anchor" aria-hidden="true" href="#release-highlights-of-platemo-24"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Release Highlights of PlatEMO 2.4&lt;/h1&gt;
&lt;p&gt;&lt;a href="./Doc/releasenote.md"&gt;Release Note can be found here&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Add two algorithms: MSEA and OSP-NSDE. There are currently 110 algorithms in the platform.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-features-of-platemo" class="anchor" aria-hidden="true" href="#features-of-platemo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features of PlatEMO&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Totally Developed in MATLAB&lt;br&gt;
PlatEMO consists of a number of MATLAB functions without using any other libraries. Any machines able to run MATLAB can use PlatEMO regardless of the operating system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Includes Many Popular Algorithms&lt;br&gt;
PlatEMO includes more than ninety existing popular MOEAs, including genetic algorithm, differential evolution, particle swarm optimization, memetic algorithm, estimation of distribution algorithm, and surrogate model based algorithm. Most of them are representative algorithms published in top journals after 2010.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Various Figure Demonstrations&lt;br&gt;
Users can select various figures to be displayed, including the Pareto front of the result, the Pareto set of the result, the true Pareto front, and the evolutionary trajectories of any performance indicator values.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Powerful and Friendly GUI&lt;br&gt;
PlatEMO provides a powerful and friendly GUI, where users can configure all the settings and perform experiments in parallel via the GUI without writing any code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generates Data in the Format of Excel or LaTeX&lt;br&gt;
Users can save the statistical experimental results generated by PlatEMO as an Excel table or LaTeX table, which can be directly used in academic writings.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-support" class="anchor" aria-hidden="true" href="#support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;[&lt;strong&gt;recommend&lt;/strong&gt;] You can ask any question in &lt;a href="https://github.com/BIMK/PlatEMO/issues"&gt;issues block&lt;/a&gt; and upload your contribution by pulling request(PR).&lt;/li&gt;
&lt;li&gt;If you want to add your MOEA, MOP, operator or performance indicator to PlatEMO, please send the MATLAB code (able to be used in PlatEMO) and the relevant literature to &lt;a href="mailto:field910921@gmail.com"&gt;field910921@gmail.com&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If you have any question, comment or suggestion to PlatEMO or the algorithms in PlatEMO, please contact Ye Tian (&lt;a href="mailto:field910921@gmail.com"&gt;field910921@gmail.com&lt;/a&gt;) or join the group of QQ(Group number: 100065008).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./Doc/QQgroupNumber.jpg"&gt;&lt;img src="./Doc/QQgroupNumber.jpg" width="180" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;  
&lt;h1&gt;&lt;a id="user-content-acknowledge" class="anchor" aria-hidden="true" href="#acknowledge"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledge&lt;/h1&gt;
&lt;p&gt;This repo belongs to BIMK group and has been transferred project from &lt;a href="http://bimk.ahu.edu.cn/" rel="nofollow"&gt;BIMK&lt;/a&gt; to github by Ye Tian and Shichen Peng&lt;a href="https://github.com/anonymone"&gt;@anonymone&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>BIMK</author><guid isPermaLink="false">https://github.com/BIMK/PlatEMO</guid><pubDate>Sun, 02 Feb 2020 00:02:00 GMT</pubDate></item><item><title>TadasBaltrusaitis/OpenFace #3 in MATLAB, This week</title><link>https://github.com/TadasBaltrusaitis/OpenFace</link><description>&lt;p&gt;&lt;i&gt;OpenFace – a state-of-the art tool intended for facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-openface-220-a-facial-behavior-analysis-toolkit" class="anchor" aria-hidden="true" href="#openface-220-a-facial-behavior-analysis-toolkit"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;OpenFace 2.2.0: a facial behavior analysis toolkit&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/TadasBaltrusaitis/OpenFace" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/4243d567083c3a651ecbadc77c77a00ba697fb40/68747470733a2f2f7472617669732d63692e6f72672f546164617342616c7472757361697469732f4f70656e466163652e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/TadasBaltrusaitis/OpenFace.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/TadasBaltrusaitis/openface/branch/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8c6fb6db38385292d352f1b17205f42469d06fda/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f386d73696b6c786662686c6e736d78702f6272616e63682f6d61737465723f7376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/8msiklxfbhlnsmxp/branch/master?svg=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Over the past few years, there has been an increased interest in automatic facial behavior analysis
and understanding. We present OpenFace – a tool intended for computer vision and machine learning
researchers, affective computing community and people interested in building interactive
applications based on facial behavior analysis. OpenFace is the ﬁrst toolkit capable of facial
landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation
with available source code for both running and training the models. The computer vision algorithms
which represent the core of OpenFace demonstrate state-of-the-art results in all of the above
mentioned tasks. Furthermore, our tool is capable of real-time performance and is able to run from a
simple webcam without any specialist hardware.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/muticomp_logo_black.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/muticomp_logo_black.png" alt="Multicomp logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;OpenFace was originally developed by Tadas Baltrušaitis in collaboration with CMU MultiComp Lab led by Prof. Louis-Philippe Morency. Some of the original algorithms were created while at Rainbow Group, Cambridge University. The OpenFace library is still actively developed at the CMU MultiComp Lab in collaboration with Tadas Baltršaitis. Special thanks to researcher who helped developing, implementing and testing the algorithms present in OpenFace: Amir Zadeh and Yao Chong Lim on work on the CE-CLM model and Erroll Wood for the gaze estimation work.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-wiki" class="anchor" aria-hidden="true" href="#wiki"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WIKI&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;For instructions of how to install/compile/use the project please see &lt;a href="https://github.com/TadasBaltrusaitis/OpenFace/wiki"&gt;WIKI&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-functionality" class="anchor" aria-hidden="true" href="#functionality"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Functionality&lt;/h2&gt;
&lt;p&gt;The system is capable of performing a number of facial analysis tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facial Landmark Detection&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/multi_face_img.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/multi_face_img.png" alt="Sample facial landmark detection image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facial Landmark and head pose tracking (links to YouTube videos)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=V7rV0uy7heQ" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/861e54570c553cb53c797dd8bc57a24f29152655/687474703a2f2f696d672e796f75747562652e636f6d2f76692f56377256307579376865512f302e6a7067" alt="Multiple Face Tracking" width="240" height="180" border="10" data-canonical-src="http://img.youtube.com/vi/V7rV0uy7heQ/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.youtube.com/watch?v=vYOa8Pif5lY" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a9137826a1740e8df2125ef9b76541445e32957e/687474703a2f2f696d672e796f75747562652e636f6d2f76692f76594f6138506966356c592f302e6a7067" alt="Multiple Face Tracking" width="240" height="180" border="10" data-canonical-src="http://img.youtube.com/vi/vYOa8Pif5lY/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facial Action Unit Recognition&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/au_sample.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/au_sample.png" height="280" width="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gaze tracking (image of it in action)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/gaze_ex.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/gaze_ex.png" height="182" width="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facial Feature Extraction (aligned faces and HOG features)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/appearance.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/appearance.png" alt="Sample aligned face and HOG image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you use any of the resources provided on this page in any of your publications we ask you to cite the following work and the work for a relevant submodule you used.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-overall-system" class="anchor" aria-hidden="true" href="#overall-system"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overall system&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;OpenFace 2.0: Facial Behavior Analysis Toolkit&lt;/strong&gt;
Tadas Baltrušaitis, Amir Zadeh, Yao Chong Lim, and Louis-Philippe Morency,
&lt;em&gt;IEEE International Conference on Automatic Face and Gesture Recognition&lt;/em&gt;, 2018&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-facial-landmark-detection-and-tracking" class="anchor" aria-hidden="true" href="#facial-landmark-detection-and-tracking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Facial landmark detection and tracking&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Convolutional experts constrained local model for facial landmark detection&lt;/strong&gt;
A. Zadeh, T. Baltrušaitis, and Louis-Philippe Morency.
&lt;em&gt;Computer Vision and Pattern Recognition Workshops&lt;/em&gt;, 2017&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Constrained Local Neural Fields for robust facial landmark detection in the wild&lt;/strong&gt;
Tadas Baltrušaitis, Peter Robinson, and Louis-Philippe Morency.
in IEEE Int. &lt;em&gt;Conference on Computer Vision Workshops, 300 Faces in-the-Wild Challenge&lt;/em&gt;, 2013.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-eye-gaze-tracking" class="anchor" aria-hidden="true" href="#eye-gaze-tracking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Eye gaze tracking&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Rendering of Eyes for Eye-Shape Registration and Gaze Estimation&lt;/strong&gt;
Erroll Wood, Tadas Baltrušaitis, Xucong Zhang, Yusuke Sugano, Peter Robinson, and Andreas Bulling
in &lt;em&gt;IEEE International Conference on Computer Vision (ICCV)&lt;/em&gt;, 2015&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-facial-action-unit-detection" class="anchor" aria-hidden="true" href="#facial-action-unit-detection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Facial Action Unit detection&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Cross-dataset learning and person-specific normalisation for automatic Action Unit detection&lt;/strong&gt;
Tadas Baltrušaitis, Marwa Mahmoud, and Peter Robinson
in &lt;em&gt;Facial Expression Recognition and Analysis Challenge&lt;/em&gt;,
&lt;em&gt;IEEE International Conference on Automatic Face and Gesture Recognition&lt;/em&gt;, 2015&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-commercial-license" class="anchor" aria-hidden="true" href="#commercial-license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Commercial license&lt;/h1&gt;
&lt;p&gt;For inquiries about the commercial licensing of the OpenFace toolkit please visit &lt;a href="https://www.flintbox.com/public/project/50632/" rel="nofollow"&gt;https://www.flintbox.com/public/project/50632/&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-final-remarks" class="anchor" aria-hidden="true" href="#final-remarks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Final remarks&lt;/h1&gt;
&lt;p&gt;I did my best to make sure that the code runs out of the box but there are always issues and I would be grateful for your understanding that this is research code and a research project. If you encounter any problems/bugs/issues please contact me on github or by emailing me at &lt;a href="mailto:tadyla@gmail.com"&gt;tadyla@gmail.com&lt;/a&gt; for any bug reports/questions/suggestions. I prefer questions and bug reports on github as that provides visibility to others who might be encountering same issues or who have the same questions.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-copyright" class="anchor" aria-hidden="true" href="#copyright"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Copyright&lt;/h1&gt;
&lt;p&gt;Copyright can be found in the Copyright.txt&lt;/p&gt;
&lt;p&gt;You have to respect dlib, OpenBLAS, and OpenCV licenses.&lt;/p&gt;
&lt;p&gt;Furthermore you have to respect the licenses of the datasets used for model training - &lt;a href="https://github.com/TadasBaltrusaitis/OpenFace/wiki/Datasets"&gt;https://github.com/TadasBaltrusaitis/OpenFace/wiki/Datasets&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>TadasBaltrusaitis</author><guid isPermaLink="false">https://github.com/TadasBaltrusaitis/OpenFace</guid><pubDate>Sun, 02 Feb 2020 00:03:00 GMT</pubDate></item></channel></rss>