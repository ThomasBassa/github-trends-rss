<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: SystemVerilog, This week</title><link>https://github.com/trending/systemverilog?since=weekly</link><description>The top repositories on GitHub for systemverilog, measured weekly</description><pubDate>Mon, 20 Jan 2020 01:06:26 GMT</pubDate><lastBuildDate>Mon, 20 Jan 2020 01:06:26 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>lowRISC/ibex #1 in SystemVerilog, This week</title><link>https://github.com/lowRISC/ibex</link><description>&lt;p&gt;&lt;i&gt;Ibex is a small 32 bit RISC-V CPU core (RV32IMC/EMC) with a two stage pipeline, previously known as zero-riscy.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://dev.azure.com/lowrisc/ibex/_build/latest?definitionId=3&amp;amp;branchName=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e8450197997fbc2ee6dffe20f35f08047b3436ec/68747470733a2f2f6465762e617a7572652e636f6d2f6c6f77726973632f696265782f5f617069732f6275696c642f7374617475732f6c6f77524953432e696265783f6272616e63684e616d653d6d6173746572" alt="Build Status" data-canonical-src="https://dev.azure.com/lowrisc/ibex/_apis/build/status/lowRISC.ibex?branchName=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-ibex-risc-v-core" class="anchor" aria-hidden="true" href="#ibex-risc-v-core"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ibex RISC-V Core&lt;/h1&gt;
&lt;p&gt;Ibex is a small and efficient, 32-bit, in-order RISC-V core with a 2-stage pipeline that implements
the RV32IMC instruction set architecture.&lt;/p&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="doc/images/blockdiagram.svg"&gt;&lt;img src="doc/images/blockdiagram.svg" width="650" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ibex offers several configuration parameters to meet the needs of various application scenarios.
The options include two different choices for the architecture of the multiplier and divider unit,
as well as the possibility to drop the support for the "M" extension completely. In addition, the
"E" extension can be enabled when opting for a minimum-area configuration.&lt;/p&gt;
&lt;p&gt;This core was initially developed as part of the &lt;a href="https://www.pulp-platform.org" rel="nofollow"&gt;PULP platform&lt;/a&gt;
under the name "Zero-riscy" [&lt;a href="https://doi.org/10.1109/PATMOS.2017.8106976" rel="nofollow"&gt;1&lt;/a&gt;], and has been
contributed to &lt;a href="https://www.lowrisc.org" rel="nofollow"&gt;lowRISC&lt;/a&gt; who maintains it and develops it further. It is
under active development, with further code cleanups, feature additions, and test and verification
planned for the future.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;The Ibex user manual can be
&lt;a href="https://ibex-core.readthedocs.io/en/latest/" rel="nofollow"&gt;read online at ReadTheDocs&lt;/a&gt;. It is also contained in
the &lt;code&gt;doc&lt;/code&gt; folder of this repository.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;We highly appreciate community contributions. To ease our work of reviewing your contributions,
please:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create your own branch to commit your changes and then open a Pull Request.&lt;/li&gt;
&lt;li&gt;Split large contributions into smaller commits addressing individual changes or bug fixes. Do not
mix unrelated changes into the same commit!&lt;/li&gt;
&lt;li&gt;Write meaningful commit messages. For more information, please check out the &lt;a href="https://github.com/lowrisc/ibex/blob/master/CONTRIBUTING.md"&gt;contribution
guide&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If asked to modify your changes, do fixup your commits and rebase your branch to maintain a
clean history.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When contributing SystemVerilog source code, please try to be consistent and adhere to &lt;a href="https://github.com/lowRISC/style-guides/blob/master/VerilogCodingStyle.md"&gt;our Verilog
coding style guide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When contributing C or C++ source code, please try to adhere to &lt;a href="https://docs.opentitan.org/doc/rm/c_cpp_coding_style/" rel="nofollow"&gt;the OpenTitan C++ coding style
guide&lt;/a&gt;.
All C and C++ code should be formatted with clang-format before committing.
Either run &lt;code&gt;clang-format -i filename.cc&lt;/code&gt; or &lt;code&gt;git clang-format&lt;/code&gt; on added files.&lt;/p&gt;
&lt;p&gt;To get started, please check out the &lt;a href="https://github.com/lowrisc/ibex/issues?q=is%3Aissue+is%3Aopen+label%3A%22Good+First+Issue%22"&gt;"Good First Issue"
list&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-issues-and-troubleshooting" class="anchor" aria-hidden="true" href="#issues-and-troubleshooting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Issues and Troubleshooting&lt;/h2&gt;
&lt;p&gt;If you find any problems or issues with Ibex or the documentation, please check out the &lt;a href="https://github.com/lowrisc/ibex/issues"&gt;issue
tracker&lt;/a&gt; and create a new issue if your problem is
not yet tracked.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-questions" class="anchor" aria-hidden="true" href="#questions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Questions?&lt;/h2&gt;
&lt;p&gt;Do not hesitate to contact us, e.g., on our public &lt;a href="https://lowrisc.zulipchat.com/#narrow/stream/198227-ibex" rel="nofollow"&gt;Ibex channel on
Zulip&lt;/a&gt;!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Unless otherwise noted, everything in this repository is covered by the Apache
License, Version 2.0 (see LICENSE for full text).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credits&lt;/h2&gt;
&lt;p&gt;Many people have contributed to Ibex through the years. Please have a look at
the &lt;a href="CREDITS.md"&gt;credits file&lt;/a&gt; and the commit history for more information.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-references" class="anchor" aria-hidden="true" href="#references"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://doi.org/10.1109/PATMOS.2017.8106976" rel="nofollow"&gt;Schiavone, Pasquale Davide, et al. "Slow and steady wins the race? A comparison of
ultra-low-power RISC-V cores for Internet-of-Things applications."
&lt;em&gt;27th International Symposium on Power and Timing Modeling, Optimization and Simulation
(PATMOS 2017)&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>lowRISC</author><guid isPermaLink="false">https://github.com/lowRISC/ibex</guid><pubDate>Mon, 20 Jan 2020 00:01:00 GMT</pubDate></item><item><title>Xilinx/Vitis-AI #2 in SystemVerilog, This week</title><link>https://github.com/Xilinx/Vitis-AI</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;div align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="doc/img/Vitis-AI.png"&gt;&lt;img width="100%" height="100%" src="doc/img/Vitis-AI.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;br&gt;
Vitis AI is Xilinx’s development stack for AI inference on Xilinx hardware platforms, including both edge devices and Alveo cards. It consists of optimized IP, tools, libraries, models, and example designs. It is designed with high efficiency and ease of use in mind, unleashing the full potential of AI acceleration on Xilinx FPGA and ACAP.  
&lt;br&gt;
&lt;br&gt;
&lt;div align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="doc/img/Vitis-AI-arch.png"&gt;&lt;img width="45%" height="45%" src="doc/img/Vitis-AI-arch.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;br&gt;
Vitis AI is composed of the following key components:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;AI Model Zoo&lt;/strong&gt;  - A comprehensive set of pre-optimized models that are ready to deploy on Xilinx devices.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI Optimizer&lt;/strong&gt; - An optional model optimizer that can prune a model by up to 90%. It is seperately available with commercial licenses.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI Quantizer&lt;/strong&gt; - A powerful quantizer that supports model quantization, calibration, and fine tuning.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI Compiler&lt;/strong&gt; - Compiles the quantized model to a high-efficient instruction set and data flow.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI Profiler&lt;/strong&gt; - Perform an in-depth analysis of the efficiency and utilization of AI inference implementation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI Library&lt;/strong&gt; - Offers high-level yet optimized C++ APIs for AI applications from edge to cloud.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DPU&lt;/strong&gt; - Efficient and scalable IP cores can be customized to meet the needs for many different applications&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Learn More:&lt;/strong&gt; &lt;a href="https://www.xilinx.com/products/design-tools/vitis/vitis-ai.html" rel="nofollow"&gt;Vitis AI Overview&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-see-whats-new" class="anchor" aria-hidden="true" href="#see-whats-new"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="doc/release-notes/1.x.md"&gt;See What's New&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="doc/release-notes/1.x.md"&gt;Release Notes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Unified Vitis AI APIs with 7 samples for edge to cloud deployment&lt;/li&gt;
&lt;li&gt;Fully support Vitis flow with XRT 2019.2 and Vitis DPU&lt;/li&gt;
&lt;li&gt;Model number in Model Zoo increased to 50 with 15 new Tensorflow models&lt;/li&gt;
&lt;li&gt;Neptune API for X + AI and Butler API for Multiprocess &amp;amp; Scaleout support for cloud deployment&lt;/li&gt;
&lt;li&gt;Introduce adaptive operating layer to support non-Linux RTOS such as QNX&lt;/li&gt;
&lt;li&gt;Vitis AI Library is open source with XRT 2019.2 support&lt;/li&gt;
&lt;li&gt;Tensorflow and Darkenet model pruning&lt;/li&gt;
&lt;li&gt;Ease of use enhancements
&lt;ul&gt;
&lt;li&gt;Docker Images for both tool and runtime&lt;/li&gt;
&lt;li&gt;Cross compilation support for Zynq/ZU+ MPSoC platform&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;To facilitate the setup of Vitis AI environment, the docker container is used for Vitis AI package distribution.
Vitis AI consists of three docker container images: two vitis-ai-docker-tools images and one vitis-ai-docker-runtime image.
The two vitis-ai-docker-tools images are for GPU and CPU environments respectively.
The vitis-ai-docker-tools contains the Vitis AI quantizer, AI compiler and examples.
The vitis-ai-docker-runtime is the runtime docker image for DPU-v2 development, which holds Vitis AI installation package
for Xilinx ZCU102 and ZCU104 evaluation boards, samples, and Arm GCC cross-compilation toolchain.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Clone the Vitis-AI repository to obtain the examples, reference code, and scripts.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Xilinx/Vitis-AI  

cd Vitis-AI
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="doc/install_docker/README.md"&gt;Install Docker&lt;/a&gt; - if Docker not installed on your machine yet&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.docker.com/install/linux/linux-postinstall/" rel="nofollow"&gt;Ensure your linux user is in the group docker&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="doc/install_docker/load_run_docker.md"&gt;Load&amp;amp;Run Docker Container&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Get started with examples&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="mpsoc/README.md"&gt;ZU+ MPSoC/Zynq-7000&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="alveo/README.md"&gt;Alveo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-programming-with-vitis-ai" class="anchor" aria-hidden="true" href="#programming-with-vitis-ai"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Programming with Vitis AI&lt;/h2&gt;
&lt;p&gt;Vitis AI offers a unified set of high-level C++/Python programming APIs to run AI applications across edge-to-cloud platforms, including DPUv1 and DPUv3 for Alveo,&lt;br&gt;
and DPUv2 for Zynq Ultrascale+ MPSoC and Zynq-7000. It brings the benefits to easily port AI applications from cloud to edge and vice versa.
7 samples in &lt;a href="mpsoc/vitis_ai_samples_zcu102"&gt;Vitis AI Samples for Zynq&lt;/a&gt; and &lt;a href="alveo/examples/vitis_ai_alveo_samples"&gt;Vitis AI Samples for Alveo&lt;/a&gt; are available
to help you get familiar with the unfied programming APIs.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ID&lt;/th&gt;
&lt;th&gt;Example Name&lt;/th&gt;
&lt;th&gt;Models&lt;/th&gt;
&lt;th&gt;Framework&lt;/th&gt;
&lt;th&gt;Notes&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;resnet50&lt;/td&gt;
&lt;td&gt;ResNet50&lt;/td&gt;
&lt;td&gt;Caffe&lt;/td&gt;
&lt;td&gt;Image classification with Vitis AI unified C++ APIs.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;resnet50_mt_py&lt;/td&gt;
&lt;td&gt;ResNet50&lt;/td&gt;
&lt;td&gt;TensorFlow&lt;/td&gt;
&lt;td&gt;Multi-threading image classification with Vitis AI unified Python APIs.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;inception_v1_mt_py&lt;/td&gt;
&lt;td&gt;Inception-v1&lt;/td&gt;
&lt;td&gt;TensorFlow&lt;/td&gt;
&lt;td&gt;Multi-threading image classification with Vitis AI unified Python APIs.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;pose_detection&lt;/td&gt;
&lt;td&gt;SSD, Pose detection&lt;/td&gt;
&lt;td&gt;Caffe&lt;/td&gt;
&lt;td&gt;Pose detection with Vitis AI unified C++ APIs.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;video_analysis&lt;/td&gt;
&lt;td&gt;SSD&lt;/td&gt;
&lt;td&gt;Caffe&lt;/td&gt;
&lt;td&gt;Traffic detection with Vitis AI unified C++ APIs.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;adas_detection&lt;/td&gt;
&lt;td&gt;YOLO-v3&lt;/td&gt;
&lt;td&gt;Caffe&lt;/td&gt;
&lt;td&gt;ADAS detection with Vitis AI unified C++ APIs.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;segmentation&lt;/td&gt;
&lt;td&gt;FPN&lt;/td&gt;
&lt;td&gt;Caffe&lt;/td&gt;
&lt;td&gt;Semantic segmentation with Vitis AI unified C++ APIs.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For more information, please refer to &lt;a href="http://www.xilinx.com/support/documentation/sw_manuals/vitis_ai/1_0/ug1414-vitis-ai.pdf" rel="nofollow"&gt;Vitis AI User Guide&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-references" class="anchor" aria-hidden="true" href="#references"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.xilinx.com/products/design-tools/vitis/vitis-ai.html" rel="nofollow"&gt;Vitis AI Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.xilinx.com/support/documentation/sw_manuals/vitis_ai/1_0/ug1414-vitis-ai.pdf" rel="nofollow"&gt;Vitis AI User Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Xilinx/Vitis-AI/tree/master/AI-Model-Zoo"&gt;Vitis AI Model Zoo with Performance &amp;amp; Accuracy Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.xilinx.com/en/get-started/ai.html" rel="nofollow"&gt;Tutorials &amp;amp; Articles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.xilinx.com/support/documentation/white_papers/wp504-accel-dnns.pdf" rel="nofollow"&gt;Performance Whitepaper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-system-requirements" class="anchor" aria-hidden="true" href="#system-requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="doc/system_requirements.md"&gt;System Requirements&lt;/a&gt;&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-questions-and-support" class="anchor" aria-hidden="true" href="#questions-and-support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Questions and Support&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="doc/faq.md"&gt;FAQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://forums.xilinx.com/t5/Machine-Learning/bd-p/Deephi" rel="nofollow"&gt;Vitis AI Forum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Xilinx</author><guid isPermaLink="false">https://github.com/Xilinx/Vitis-AI</guid><pubDate>Mon, 20 Jan 2020 00:02:00 GMT</pubDate></item></channel></rss>