<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Lua, This week</title><link>https://github.com/trending/lua?since=weekly</link><description>The top repositories on GitHub for lua, measured weekly</description><pubDate>Fri, 08 Nov 2019 01:07:45 GMT</pubDate><lastBuildDate>Fri, 08 Nov 2019 01:07:45 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>apache/incubator-apisix #1 in Lua, This week</title><link>https://github.com/apache/incubator-apisix</link><description>&lt;p&gt;&lt;i&gt;Cloud-Native Microservices API Gateway&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;
&lt;p&gt;&lt;a href="README_CN.md"&gt;中文&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-apisix" class="anchor" aria-hidden="true" href="#apisix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;APISIX&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/apache/incubator-apisix" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1ed9f512514c97c413e71e4c8f5240edeefb11fc/68747470733a2f2f7472617669732d63692e6f72672f6170616368652f696e63756261746f722d6170697369782e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/apache/incubator-apisix.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/apache/incubator-apisix/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/8051e9938a1ab39cf002818dfceb6b6092f34d68/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;QQ group&lt;/strong&gt;: 552030619&lt;/li&gt;
&lt;li&gt;Mail list: Mail to &lt;a href="mailto:dev-subscribe@apisix.apache.org"&gt;dev-subscribe@apisix.apache.org&lt;/a&gt;, follow the reply to subscribe the mail list.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gitter.im/apisix/community?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/568da9652db68475b3c235e1274c91d42c378149/68747470733a2f2f6261646765732e6769747465722e696d2f6170697369782f636f6d6d756e6974792e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/apisix/community.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/intent/follow?screen_name=apisixfast" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8aeaef778a0e54bb395d635f5b1bfdf8a48abde2/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f617069736978666173742e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f77" alt="Twitter" data-canonical-src="https://img.shields.io/twitter/follow/apisixfast.svg?style=social&amp;amp;label=Follow" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;APISIX is a cloud-native microservices API gateway, delivering the ultimate performance, security, open source and scalable platform for all your APIs and microservices.&lt;/p&gt;
&lt;p&gt;APISIX is based on Nginx and etcd. Compared with traditional API gateways, APISIX has dynamic routing and plug-in hot loading, which is especially suitable for API management under micro-service system.&lt;/p&gt;
&lt;p&gt;&lt;a href="#Installation"&gt;Installation&lt;/a&gt; | &lt;a href="doc/README.md"&gt;Documentation&lt;/a&gt; | &lt;a href="#development-manual-of-apisix"&gt;Development ENV&lt;/a&gt; | &lt;a href="FAQ.md"&gt;FAQ&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-why-apisix" class="anchor" aria-hidden="true" href="#why-apisix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why APISIX?&lt;/h2&gt;
&lt;p&gt;If you are building a website, mobile device or IoT (Internet of Things) application, you may need to use an API gateway to handle interface traffic.&lt;/p&gt;
&lt;p&gt;APISIX is a cloud-based microservices API gateway that handles traditional north-south traffic and handles east-west traffic between services.&lt;/p&gt;
&lt;p&gt;APISIX provides dynamic load balancing, authentication, rate limiting, other plugins through plugin mechanisms, and supports plugins you develop yourself.&lt;/p&gt;
&lt;p&gt;For more detailed information, see the &lt;a href="https://www.iresty.com/download/Choosing%20the%20Right%20Microservice%20API%20Gateway%20for%20the%20Enterprise%20User.pdf" rel="nofollow"&gt;White Paper&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="doc/images/apisix.png"&gt;&lt;img src="doc/images/apisix.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Run Environment&lt;/strong&gt;: Both OpenResty and Tengine are supported.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cloud-Native&lt;/strong&gt;: Platform agnostic, No vendor lock-in, APISIX can run from bare-metal to Kubernetes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins.md"&gt;Hot Updates And Hot Plugins&lt;/a&gt;&lt;/strong&gt;: Continuously updates its configurations and plugins without restarts!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic Load Balancing&lt;/strong&gt;: Round-robin load balancing with weight.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hash-based Load Balancing&lt;/strong&gt;: Load balance with consistent hashing sessions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/https.md"&gt;SSL&lt;/a&gt;&lt;/strong&gt;: Dynamically load an SSL certificate.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HTTP(S) Forward Proxy&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/health-check.md"&gt;Health Checks&lt;/a&gt;&lt;/strong&gt;：Enable health check on the upstream node, and will automatically filter unhealthy nodes during load balancing to ensure system stability.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Circuit-Breaker&lt;/strong&gt;: Intelligent tracking of unhealthy upstream services.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Authentications&lt;/strong&gt;: &lt;a href="doc/plugins/key-auth.md"&gt;key-auth&lt;/a&gt;, &lt;a href="doc/plugins/jwt-auth.md"&gt;JWT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/limit-req.md"&gt;Limit-req&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/limit-count.md"&gt;Limit-count&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/limit-conn.md"&gt;Limit-concurrency&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/proxy-rewrite.md"&gt;Proxy Rewrite&lt;/a&gt;&lt;/strong&gt;: Support for rewriting the &lt;code&gt;host&lt;/code&gt;, &lt;code&gt;uri&lt;/code&gt;, &lt;code&gt;schema&lt;/code&gt;, &lt;code&gt;enable_websocket&lt;/code&gt;, &lt;code&gt;headers&lt;/code&gt; information upstream of the request.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenTracing: &lt;a href="doc/plugins/zipkin.md"&gt;support Apache Skywalking and Zipkin&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Monitoring And Metrics&lt;/strong&gt;: &lt;a href="doc/plugins/prometheus.md"&gt;Prometheus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/grpc-proxy.md"&gt;gRPC proxy&lt;/a&gt;&lt;/strong&gt;：Proxying gRPC traffic.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/grpc-transcoding.md"&gt;gRPC transcoding&lt;/a&gt;&lt;/strong&gt;：Supports protocol transcoding so that clients can access your gRPC API by using HTTP/JSON.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/serverless.md"&gt;Serverless&lt;/a&gt;&lt;/strong&gt;: Invoke functions in each phase in APISIX.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Custom plugins&lt;/strong&gt;: Allows hooking of common phases, such as &lt;code&gt;rewrite&lt;/code&gt;, &lt;code&gt;access&lt;/code&gt;, &lt;code&gt;header filer&lt;/code&gt;, &lt;code&gt;body filter&lt;/code&gt; and &lt;code&gt;log&lt;/code&gt;, also allows to hook the &lt;code&gt;balancer&lt;/code&gt; stage.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dashboard&lt;/strong&gt;: Built-in dashboard to control APISIX.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Version Control&lt;/strong&gt;: Supports rollbacks of operations.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CLI&lt;/strong&gt;: start\stop\reload APISIX through the command line.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;REST API&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Proxy Websocket&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IPv6&lt;/strong&gt;: Use IPv6 to match route.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clustering&lt;/strong&gt;: APISIX nodes are stateless, creates clustering of the configuration center, please refer to &lt;a href="https://github.com/etcd-io/etcd/blob/master/Documentation/v2/clustering.md"&gt;etcd Clustering Guide&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: plug-in mechanism is easy to extend.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;High performance&lt;/strong&gt;: The single-core QPS reaches 24k with an average delay of less than 0.6 milliseconds.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Anti-ReDoS(Regular expression Denial of Service)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IP Whitelist/Blacklist&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IdP&lt;/strong&gt;: Support external authentication services, such as Auth0, okta, etc., users can use this to connect to Oauth2.0 and other authentication methods.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/stand-alone.md"&gt;Stand-alone mode&lt;/a&gt;&lt;/strong&gt;: Supports to load route rules from local yaml file, it is more friendly such as under the kubernetes(k8s).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Global Rule&lt;/strong&gt;: Allows to run any plugin for all request, eg: limit rate, IP filter etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/stream-proxy.md"&gt;TCP/UDP Proxy&lt;/a&gt;&lt;/strong&gt;: Dynamic TCP/UDP proxy.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="doc/plugins/mqtt-proxy.md"&gt;Dynamic MQTT Proxy&lt;/a&gt;&lt;/strong&gt;: Supports to load balance MQTT by &lt;code&gt;client_id&lt;/code&gt;, both support MQTT &lt;a href="http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html" rel="nofollow"&gt;3.1.*&lt;/a&gt;, &lt;a href="https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html" rel="nofollow"&gt;5.0&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ACL&lt;/strong&gt;: TODO.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bot detection&lt;/strong&gt;: TODO.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-online-demo-dashboard" class="anchor" aria-hidden="true" href="#online-demo-dashboard"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Online Demo Dashboard&lt;/h2&gt;
&lt;p&gt;We provide an online dashboard &lt;a href="http://apisix.iresty.com" rel="nofollow"&gt;demo version&lt;/a&gt;， make it easier for you to understand APISIX.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;APISIX Installed and tested in the following systems(OpenResty MUST &amp;gt;= 1.15.8.1, or Tengine &amp;gt;= 2.3.2):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CentOS 7&lt;/li&gt;
&lt;li&gt;Ubuntu 16.04&lt;/li&gt;
&lt;li&gt;Ubuntu 18.04&lt;/li&gt;
&lt;li&gt;Debian 9&lt;/li&gt;
&lt;li&gt;Debian 10&lt;/li&gt;
&lt;li&gt;macOS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ARM64&lt;/strong&gt; Ubuntu 18.04&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are four ways to install APISIX:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if you are using CentOS 7, it is recommended to use &lt;a href="#install-from-rpm-for-centos-7"&gt;RPM&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;if you are using macOS, only git clone and install by manual are supported. Please take a look at &lt;a href="doc/dev-manual.md"&gt;dev manual&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;other systems please use &lt;a href="#install-from-luarocks-not-support-macos"&gt;Luarocks&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;You can also install from &lt;a href="https://github.com/iresty/docker-apisix"&gt;Docker image&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The main steps to install APISIX:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Runtime dependency: OpenResty or Tengine.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenResty: Reference &lt;a href="http://openresty.org/en/installation.html" rel="nofollow"&gt;http://openresty.org/en/installation.html&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Tengine: Please take a look at this installation step script &lt;a href=".travis/linux_tengine_runner.sh"&gt;Install Tengine at Ubuntu&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Configuration center: Reference &lt;a href="https://github.com/etcd-io/etcd"&gt;etcd&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NOTE&lt;/em&gt;: APISIX currently only supports the v2 protocol storage to etcd, but the latest version of etcd (starting with 3.4) has turned off the v2 protocol by default. You need to add &lt;code&gt;--enable-v2=true&lt;/code&gt; to the startup parameter to enable the v2 protocol. The development of the v3 protocol supporting etcd has begun and will soon be available.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install APISIX service.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-install-from-rpm-for-centos-7" class="anchor" aria-hidden="true" href="#install-from-rpm-for-centos-7"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install from RPM for CentOS 7&lt;/h3&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo yum install yum-utils
sudo yum-config-manager --add-repo https://openresty.org/package/centos/openresty.repo
sudo yum install -y openresty etcd
sudo service etcd start

sudo yum install -y https://github.com/apache/incubator-apisix/releases/download/v0.8/apisix-0.8-0.el7.noarch.rpm&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can try APISIX with the &lt;a href="#quickstart"&gt;&lt;strong&gt;Quickstart&lt;/strong&gt;&lt;/a&gt; now.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-install-from-luarocks-not-support-macos" class="anchor" aria-hidden="true" href="#install-from-luarocks-not-support-macos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install from Luarocks (not support macOS)&lt;/h3&gt;
&lt;h5&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h5&gt;
&lt;p&gt;APISIX is based on &lt;a href="https://openresty.org/" rel="nofollow"&gt;OpenResty&lt;/a&gt; or &lt;a href="http://tengine.taobao.org/" rel="nofollow"&gt;Tengine&lt;/a&gt;, the configures data storage and distribution via &lt;a href="https://github.com/etcd-io/etcd"&gt;etcd&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We recommend that you use &lt;a href="https://luarocks.org/" rel="nofollow"&gt;luarocks&lt;/a&gt; to install APISIX, and for different operating systems have different dependencies, see more: &lt;a href="doc/install-dependencies.md"&gt;Install Dependencies&lt;/a&gt;&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-install-apisix" class="anchor" aria-hidden="true" href="#install-apisix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install APISIX&lt;/h5&gt;
&lt;p&gt;APISIX is installed by running the following commands in your terminal.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;install the master branch via curl&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo sh -c &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;curl -fsSL https://raw.githubusercontent.com/apache/incubator-apisix/master/utils/install-apisix.sh&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;install the specified version via Luarock:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; install apisix with version v0.8&lt;/span&gt;
sudo luarocks install --lua-dir=/path/openresty/luajit apisix 0.8

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; old luarocks may not support `lua-dir`, we can remove option `lua-dir`&lt;/span&gt;
sudo luarocks install apisix 0.8&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;Installation complete&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If all goes well, you will see the message like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    apisix 0.7-0 is now built and installed in /usr/local/apisix/deps (license: Apache License 2.0)

    + sudo rm -f /usr/local/bin/apisix
    + sudo ln -s /usr/local/apisix/deps/bin/apisix /usr/local/bin/apisix
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Congratulations, you have already installed APISIX successfully.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-development-manual-of-apisix" class="anchor" aria-hidden="true" href="#development-manual-of-apisix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development Manual of APISIX&lt;/h2&gt;
&lt;p&gt;If you are a developer, you can view the &lt;a href="doc/dev-manual.md"&gt;dev manual&lt;/a&gt; for more details.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-quickstart" class="anchor" aria-hidden="true" href="#quickstart"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quickstart&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;start server:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo apisix start&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;note&lt;/em&gt;: If you are in a development environment, start server by command &lt;code&gt;make run&lt;/code&gt;.&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;try limit count plugin&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Limit count plugin is a good start to try APISIX,
you can follow the &lt;a href="doc/plugins/limit-count.md"&gt;documentation of limit count&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Then you can try more &lt;a href="doc/README.md#plugins"&gt;plugins&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-deploy-to-the-cloud" class="anchor" aria-hidden="true" href="#deploy-to-the-cloud"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deploy to the Cloud&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-aws" class="anchor" aria-hidden="true" href="#aws"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;AWS&lt;/h3&gt;
&lt;p&gt;The recommended approach is to deploy APISIX with &lt;a href="https://aws.amazon.com/cdk/" rel="nofollow"&gt;AWS CDK&lt;/a&gt; on &lt;a href="https://aws.amazon.com/fargate/" rel="nofollow"&gt;AWS Fargate&lt;/a&gt; which helps you decouple the APISIX layer and the upstream layer on top of a fully-managed and secure serverless container compute environment with autoscaling capabilities.&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://github.com/pahud/cdk-samples/blob/master/typescript/apisix/README.md"&gt;this guide&lt;/a&gt; by &lt;a href="https://github.com/pahud"&gt;Pahud Hsieh&lt;/a&gt; and learn how to provision the recommended architecture 100% in AWS CDK.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-dashboard" class="anchor" aria-hidden="true" href="#dashboard"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dashboard&lt;/h2&gt;
&lt;p&gt;APISIX has the built-in dashboard，open &lt;code&gt;http://127.0.0.1:9080/apisix/dashboard/&lt;/code&gt; with a browser and try it.&lt;/p&gt;
&lt;p&gt;Do not need to fill the user name and password, log in directly.&lt;/p&gt;
&lt;p&gt;Dashboard allow any remote IP by default, and you can modify &lt;code&gt;allow_admin&lt;/code&gt; in &lt;code&gt;conf/config.yaml&lt;/code&gt; by yourself, to list the list of IPs allowed to access.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-benchmark" class="anchor" aria-hidden="true" href="#benchmark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Benchmark&lt;/h2&gt;
&lt;p&gt;Using Google Cloud's 4 core server, APISIX's QPS reach to 60,000 with a latency of only 500 microseconds.&lt;/p&gt;
&lt;p&gt;You can view the &lt;a href="doc/benchmark.md"&gt;benchmark documentation&lt;/a&gt; for more detailed information.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-architecture-design" class="anchor" aria-hidden="true" href="#architecture-design"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Architecture Design&lt;/h2&gt;
&lt;p&gt;&lt;a href="doc/architecture-design.md"&gt;Development Documentation&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-videos-and-articles" class="anchor" aria-hidden="true" href="#videos-and-articles"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Videos And Articles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;2019.10.30 &lt;a href="https://www.upyun.com/opentalk/440.html" rel="nofollow"&gt;Introduction to Apache APISIX Microservice Gateway Extreme Performance Architecture(Chinese)&lt;/a&gt; .&lt;/li&gt;
&lt;li&gt;2019.8.31 &lt;a href="https://www.upyun.com/opentalk/433.html" rel="nofollow"&gt;APISIX technology selection, testing and continuous integration(Chinese)&lt;/a&gt; .&lt;/li&gt;
&lt;li&gt;2019.8.31 &lt;a href="https://www.upyun.com/opentalk/437.html" rel="nofollow"&gt;APISIX high performance practice 2(Chinese)&lt;/a&gt; .&lt;/li&gt;
&lt;li&gt;2019.7.6 &lt;a href="https://www.upyun.com/opentalk/429.html" rel="nofollow"&gt;APISIX high performance practice(Chinese)&lt;/a&gt; .&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-who-uses-apisix" class="anchor" aria-hidden="true" href="#who-uses-apisix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Who Uses APISIX?&lt;/h2&gt;
&lt;p&gt;A wide variety of companies and organizations use APISIX for research, production and commercial product.
Here is the User Wall of APISIX.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="doc/images/user-wall.jpg"&gt;&lt;img src="doc/images/user-wall.jpg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Users are encouraged to add themselves to the &lt;a href="doc/powered-by.md"&gt;Powered By&lt;/a&gt; page.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-landscape" class="anchor" aria-hidden="true" href="#landscape"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Landscape&lt;/h2&gt;
&lt;p&gt;APISIX enriches the &lt;a href="https://landscape.cncf.io/category=api-gateway&amp;amp;format=card-mode&amp;amp;grouping=category" rel="nofollow"&gt;CNCF API Gateway Landscape&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="doc/images/cncf-landscope.jpg"&gt;&lt;img src="doc/images/cncf-landscope.jpg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-faq" class="anchor" aria-hidden="true" href="#faq"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FAQ&lt;/h2&gt;
&lt;p&gt;There are often some questions asked by developers in the community. We have arranged them in the &lt;a href="FAQ.md"&gt;FAQ&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If your concerns are not among them, please submit issue to communicate with us.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;See &lt;a href="Contributing.md"&gt;CONTRIBUTING&lt;/a&gt; for details on submitting patches and the contribution workflow.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;inspired by Kong and Orange.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>apache</author><guid isPermaLink="false">https://github.com/apache/incubator-apisix</guid><pubDate>Fri, 08 Nov 2019 00:01:00 GMT</pubDate></item><item><title>cardwing/Codes-for-Lane-Detection #2 in Lua, This week</title><link>https://github.com/cardwing/Codes-for-Lane-Detection</link><description>&lt;p&gt;&lt;i&gt;Learning Lightweight Lane Detection CNNs by Self Attention Distillation (ICCV 2019)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;Codes for &lt;a href="https://arxiv.org/abs/1908.00821" rel="nofollow"&gt;"Learning Lightweight Lane Detection CNNs by Self Attention Distillation"&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repo also contains Tensorflow implementation of &lt;a href="https://arxiv.org/abs/1712.06080" rel="nofollow"&gt;"Spatial As Deep: Spatial CNN for Traffic Scene Understanding"&lt;/a&gt;. (SCNN-Tensorflow)&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-news" class="anchor" aria-hidden="true" href="#news"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;News&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="./ERFNet-CULane-PyTorch"&gt;ERFNet-CULane-PyTorch&lt;/a&gt; has been released. (It can achieve &lt;strong&gt;73.1&lt;/strong&gt; F1-measure in CULane testing set)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="./ENet-Label-Torch"&gt;ENet-Label-Torch&lt;/a&gt;, &lt;a href="./ENet-TuSimple-Torch"&gt;ENet-TuSimple-Torch&lt;/a&gt; and &lt;a href="./ENet-BDD100K-Torch"&gt;ENet-BDD100K-Torch&lt;/a&gt; have been released.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Key features:&lt;/p&gt;
&lt;p&gt;(1) ENet-label is a &lt;strong&gt;light-weight&lt;/strong&gt; lane detection model based on &lt;a href="https://arxiv.org/abs/1606.02147" rel="nofollow"&gt;ENet&lt;/a&gt; and adopts &lt;strong&gt;self attention distillation&lt;/strong&gt; (more details can be found in our paper).&lt;/p&gt;
&lt;p&gt;(2) It has &lt;strong&gt;20&lt;/strong&gt; × fewer parameters and runs &lt;strong&gt;10&lt;/strong&gt; × faster compared to the state-of-the-art SCNN, and achieves &lt;strong&gt;72.0&lt;/strong&gt; (F1-measure) on CULane testing set (better than SCNN which achieves 71.6). It also achieves &lt;strong&gt;96.64%&lt;/strong&gt; accuracy in TuSimple testing set (better than SCNN which achieves 96.53%) and &lt;strong&gt;36.56%&lt;/strong&gt; accuracy in BDD100K testing set (better than SCNN which achieves 35.79%).&lt;/p&gt;
&lt;p&gt;(3) Applying ENet-SAD to &lt;a href="https://unsupervised-llamas.com/llamas/" rel="nofollow"&gt;LLAMAS&lt;/a&gt; dataset yields &lt;strong&gt;0.635&lt;/strong&gt; mAP in the &lt;a href="https://unsupervised-llamas.com/llamas/benchmark_multi" rel="nofollow"&gt;multi-class lane marker segmentation task&lt;/a&gt;, which is much better than the baseline algorithm which achieves 0.500 mAP. Details can be found in &lt;a href="https://github.com/cardwing/unsupervised_llamas/tree/master/ENet-SAD-Simple"&gt;this repo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;(Do not hesitate to try our model!!!)&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Multi-GPU training has been supported. Just change BATCH_SIZE and GPU_NUM in global_config.py, and then use &lt;code&gt;CUDA_VISIBLE_DEVICES="0,1,2,3" python file_name.py&lt;/code&gt;. Thanks @ yujincheng08.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;&lt;a id="user-content-content" class="anchor" aria-hidden="true" href="#content"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Content&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#Installation"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Datasets"&gt;Datasets&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#TuSimple"&gt;TuSimple&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#CULane"&gt;CULane&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#BDD100K"&gt;BDD100K&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#SCNN-Tensorflow"&gt;SCNN-Tensorflow&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#Test"&gt;Test&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Train"&gt;Train&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#Performance"&gt;Performance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Others"&gt;Others&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#Citation"&gt;Citation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Acknowledgement"&gt;Acknowledgement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Contact"&gt;Contact&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Install necessary packages:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;    conda create -n tensorflow_gpu pip python=3.5
    source activate tensorflow_gpu
    pip install --upgrade tensorflow-gpu==1.3.0
    pip3 install -r SCNN-Tensorflow/lane-detection-model/requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Download VGG-16:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Download the vgg.npy &lt;a href="https://github.com/machrisaa/tensorflow-vgg"&gt;here&lt;/a&gt; and put it in SCNN-Tensorflow/lane-detection-model/data.&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Pre-trained model for testing:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Download the pre-trained model &lt;a href="https://drive.google.com/open?id=1-E0Bws7-v35vOVfqEXDTJdfovUTQ2sf5" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-datasets" class="anchor" aria-hidden="true" href="#datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Datasets&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-tusimple" class="anchor" aria-hidden="true" href="#tusimple"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TuSimple&lt;/h2&gt;
&lt;p&gt;The ground-truth labels of TuSimple testing set is now available at &lt;a href="https://github.com/TuSimple/tusimple-benchmark/issues/3"&gt;TuSimple&lt;/a&gt;. The annotated training (#frame = 3268) and validation labels (#frame = 358) can be found &lt;a href="https://github.com/cardwing/Codes-for-Lane-Detection/issues/11"&gt;here&lt;/a&gt;, please use them (list-name.txt) to replace the train_gt.txt and val_gt.txt in &lt;a href="./SCNN-Tensorflow/lane-detection-model/tools/train_lanenet.py"&gt;train_lanenet.py&lt;/a&gt;. Moreover, you need to resize the image to 256 x 512 instead of 288 x 800 in TuSimple. Remember to change the maximum index of rows and columns, and detailed explanations can be seen &lt;a href="https://github.com/cardwing/Codes-for-Lane-Detection/issues/18"&gt;here&lt;/a&gt;. Please evaluate your pred.json using the labels and &lt;a href="https://github.com/TuSimple/tusimple-benchmark/blob/master/evaluate/lane.py"&gt;this script&lt;/a&gt;. Besides, to generate pred.json, you can refer to &lt;a href="https://github.com/cardwing/Codes-for-Lane-Detection/issues/4"&gt;this issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-culane" class="anchor" aria-hidden="true" href="#culane"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CULane&lt;/h2&gt;
&lt;p&gt;The whole dataset is available at &lt;a href="https://xingangpan.github.io/projects/CULane.html" rel="nofollow"&gt;CULane&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-bdd100k" class="anchor" aria-hidden="true" href="#bdd100k"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;BDD100K&lt;/h2&gt;
&lt;p&gt;The whole dataset is available at &lt;a href="http://bdd-data.berkeley.edu/" rel="nofollow"&gt;BDD100K&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-scnn-tensorflow" class="anchor" aria-hidden="true" href="#scnn-tensorflow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SCNN-Tensorflow&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-test" class="anchor" aria-hidden="true" href="#test"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Test&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;cd SCNN-Tensorflow/lane-detection-model
CUDA_VISIBLE_DEVICES="0" python tools/test_lanenet.py --weights_path path/to/model_weights_file --image_path path/to/image_name_list --save_dir to_be_saved_dir
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that path/to/image_name_list should be like &lt;a href="./SCNN-Tensorflow/lane-detection-model/demo_file/test_img.txt"&gt;test_img.txt&lt;/a&gt;. Now, you get the probability maps from our model. To get the final performance, you need to follow &lt;a href="https://github.com/XingangPan/SCNN"&gt;SCNN&lt;/a&gt; to get curve lines from probability maps as well as calculate precision, recall and F1-measure.&lt;/p&gt;
&lt;p&gt;Reminder: you should check &lt;a href="./SCNN-Tensorflow/lane-detection-model/data_provider/lanenet_data_processor.py"&gt;lanenet_data_processor.py&lt;/a&gt; and &lt;a href="./SCNN-Tensorflow/lane-detection-model/data_provider/lanenet_data_processor.py"&gt;lanenet_data_processor_test.py&lt;/a&gt; to ensure that the processing of image path is right. You are recommended to use the absolute path in your image path list. Besides, this code needs batch size used in training and testing to be consistent. To enable arbitrary batch size in the testing phase, please refer to &lt;a href="https://github.com/cardwing/Codes-for-Lane-Detection/issues/10"&gt;this issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-train" class="anchor" aria-hidden="true" href="#train"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES="0" python tools/train_lanenet.py --net vgg --dataset_dir path/to/CULane-dataset/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that path/to/CULane-dataset/ should contain files like &lt;a href="./SCNN-Tensorflow/lane-detection-model/demo_file/train_gt.txt"&gt;train_gt.txt&lt;/a&gt; and &lt;a href="./SCNN-Tensorflow/lane-detection-model/demo_file/train_gt.txt"&gt;val_gt.txt&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-performance" class="anchor" aria-hidden="true" href="#performance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Performance&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;TuSimple testing set:&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Model&lt;/th&gt;
&lt;th align="center"&gt;Accuracy&lt;/th&gt;
&lt;th align="center"&gt;FP&lt;/th&gt;
&lt;th align="center"&gt;FN&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/XingangPan/SCNN"&gt;SCNN-Torch&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;96.53%&lt;/td&gt;
&lt;td align="center"&gt;0.0617&lt;/td&gt;
&lt;td align="center"&gt;0.0180&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;SCNN-Tensorflow&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;ENet-Label-Torch&lt;/td&gt;
&lt;td align="center"&gt;96.64%&lt;/td&gt;
&lt;td align="center"&gt;0.0602&lt;/td&gt;
&lt;td align="center"&gt;0.0205&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The pre-trained model for testing is here. (coming soon!) Note that in TuSimple, SCNN-Torch is based on ResNet-101 while SCNN-Tensorflow is based on VGG-16. In CULane and BDD100K, both SCNN-Torch and SCNN-Tensorflow are based on VGG-16.&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;CULane testing set (F1-measure):&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Category&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://github.com/XingangPan/SCNN"&gt;SCNN-Torch&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;SCNN-Tensorflow&lt;/th&gt;
&lt;th align="center"&gt;ENet-Label-Torch&lt;/th&gt;
&lt;th align="center"&gt;ERFNet-CULane-PyTorch&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Normal&lt;/td&gt;
&lt;td align="center"&gt;90.6&lt;/td&gt;
&lt;td align="center"&gt;90.2&lt;/td&gt;
&lt;td align="center"&gt;90.7&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;91.5&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Crowded&lt;/td&gt;
&lt;td align="center"&gt;69.7&lt;/td&gt;
&lt;td align="center"&gt;71.9&lt;/td&gt;
&lt;td align="center"&gt;70.8&lt;/td&gt;
&lt;td align="center"&gt;71.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Night&lt;/td&gt;
&lt;td align="center"&gt;66.1&lt;/td&gt;
&lt;td align="center"&gt;64.6&lt;/td&gt;
&lt;td align="center"&gt;65.9&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;67.1&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;No line&lt;/td&gt;
&lt;td align="center"&gt;43.4&lt;/td&gt;
&lt;td align="center"&gt;45.8&lt;/td&gt;
&lt;td align="center"&gt;44.7&lt;/td&gt;
&lt;td align="center"&gt;45.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Shadow&lt;/td&gt;
&lt;td align="center"&gt;66.9&lt;/td&gt;
&lt;td align="center"&gt;73.8&lt;/td&gt;
&lt;td align="center"&gt;70.6&lt;/td&gt;
&lt;td align="center"&gt;71.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Arrow&lt;/td&gt;
&lt;td align="center"&gt;84.1&lt;/td&gt;
&lt;td align="center"&gt;83.8&lt;/td&gt;
&lt;td align="center"&gt;85.8&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;87.2&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Dazzle light&lt;/td&gt;
&lt;td align="center"&gt;58.5&lt;/td&gt;
&lt;td align="center"&gt;59.5&lt;/td&gt;
&lt;td align="center"&gt;64.4&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;66.0&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Curve&lt;/td&gt;
&lt;td align="center"&gt;64.4&lt;/td&gt;
&lt;td align="center"&gt;63.4&lt;/td&gt;
&lt;td align="center"&gt;65.4&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;66.3&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Crossroad&lt;/td&gt;
&lt;td align="center"&gt;1990&lt;/td&gt;
&lt;td align="center"&gt;4137&lt;/td&gt;
&lt;td align="center"&gt;2729&lt;/td&gt;
&lt;td align="center"&gt;2199&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Total&lt;/td&gt;
&lt;td align="center"&gt;71.6&lt;/td&gt;
&lt;td align="center"&gt;71.3&lt;/td&gt;
&lt;td align="center"&gt;72.0&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;73.1&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Runtime(ms)&lt;/td&gt;
&lt;td align="center"&gt;133.5&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;td align="center"&gt;13.4&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;10.2&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Parameter(M)&lt;/td&gt;
&lt;td align="center"&gt;20.72&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;0.98&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;2.49&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The pre-trained model for testing is &lt;a href="https://drive.google.com/open?id=1-E0Bws7-v35vOVfqEXDTJdfovUTQ2sf5" rel="nofollow"&gt;here&lt;/a&gt;. Note that you need to exchange the order of VGG-MEAN in test_lanenet.py and change the order of input images from RGB to BGR since the pre-trained model uses opencv to read images. You can further boost the performance by referring to &lt;a href="https://github.com/cardwing/Codes-for-Lane-Detection/issues/5"&gt;this issue&lt;/a&gt;.&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;BDD100K testing set:&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Model&lt;/th&gt;
&lt;th align="center"&gt;Accuracy&lt;/th&gt;
&lt;th align="center"&gt;IoU&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/XingangPan/SCNN"&gt;SCNN-Torch&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;35.79%&lt;/td&gt;
&lt;td align="center"&gt;15.84&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;SCNN-Tensorflow&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;td align="center"&gt;--&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;ENet-Label-Torch&lt;/td&gt;
&lt;td align="center"&gt;36.56%&lt;/td&gt;
&lt;td align="center"&gt;16.02&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The accuracy and IoU of lane pixels are computed. The pre-trained model for testing is here. (coming soon!)&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-others" class="anchor" aria-hidden="true" href="#others"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Others&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you use the codes, please cite the following publications:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{hou2019learning,
  title={Learning Lightweight Lane Detection CNNs by Self Attention Distillation},
  author={Hou, Yuenan and Ma, Zheng and Liu, Chunxiao and Loy, Chen Change},
  journal={arXiv preprint arXiv:1908.00821},
  year={2019}
}

@inproceedings{pan2018SCNN,  
  author = {Xingang Pan, Jianping Shi, Ping Luo, Xiaogang Wang, and Xiaoou Tang},  
  title = {Spatial As Deep: Spatial CNN for Traffic Scene Understanding},  
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},  
  month = {February},  
  year = {2018}  
}

@misc{hou2019agnostic,
    title={Agnostic Lane Detection},
    author={Yuenan Hou},
    year={2019},
    eprint={1905.03704},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgement" class="anchor" aria-hidden="true" href="#acknowledgement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;This repo is built upon &lt;a href="https://github.com/XingangPan/SCNN"&gt;SCNN&lt;/a&gt; and &lt;a href="https://github.com/MaybeShewill-CV/lanenet-lane-detection"&gt;LaneNet&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h2&gt;
&lt;p&gt;If you have any problems in reproducing the results, just raise an issue in this repo.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-to-do-list" class="anchor" aria-hidden="true" href="#to-do-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;To-Do List&lt;/h2&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Test SCNN-Tensorflow in TuSimple and BDD100K&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; Provide detailed instructions to run SCNN-Tensorflow in TuSimple and BDD100K&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; Upload our light-weight model (ENet-SAD) and its training &amp;amp; testing scripts&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>cardwing</author><guid isPermaLink="false">https://github.com/cardwing/Codes-for-Lane-Detection</guid><pubDate>Fri, 08 Nov 2019 00:02:00 GMT</pubDate></item><item><title>dsasmblr/cheat-engine #3 in Lua, This week</title><link>https://github.com/dsasmblr/cheat-engine</link><description>&lt;p&gt;&lt;i&gt;Cheat Engine scripts, tutorials, tools, and more.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-cheat-engine-scripts-tutorials-tools-etc" class="anchor" aria-hidden="true" href="#cheat-engine-scripts-tutorials-tools-etc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cheat Engine Scripts, Tutorials, Tools, Etc.&lt;/h1&gt;
&lt;p&gt;This is my personal repository of all things Cheat Engine! Eventually, it'll fill out as I make more of my private work public.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lua-scripts" class="anchor" aria-hidden="true" href="#lua-scripts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lua Scripts:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;PNG Extractor&lt;/strong&gt;: Attempts to find and extract .PNG images from a process you've opened with Cheat Engine.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exponentiation and Nan Filter&lt;/strong&gt;: Removes exponentiated (e.g. 3.136598246E-32) and nan (not a number) results from found results list. Handy for weeding out values that could cause crashes when attempting to mass-change or mass-lock values. &lt;em&gt;&lt;strong&gt;(WARNING: EXTREMELY SLOW! NOT RECOMMENDED FOR USE WITH MORE THAN ~5000-10000 RESULTS.)&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Remove Values with Decimal Points&lt;/strong&gt;: Removes results from the found results list that contain a decimal point. Handy for filtering values that aren't perfectly rounded floats/doubles. &lt;em&gt;&lt;strong&gt;(WARNING: EXTREMELY SLOW! NOT RECOMMENDED FOR USE WITH MORE THAN ~20000 RESULTS.)&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-cheat-tables-cts" class="anchor" aria-hidden="true" href="#cheat-tables-cts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cheat Tables (CTs):&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Mega Man 11 - No Collision and Infinite Jump&lt;/strong&gt;: This CT contains the cheats I created via Cheat Engine in &lt;a href="https://youtu.be/rqD45b0oCJc" rel="nofollow"&gt;this Mega Man 11 video tutorial&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Borderlands 3 Cheats&lt;/strong&gt;: This CT contains various cheats I've created for BL3 tutorial videos, as well as just for fun!&lt;/li&gt;
&lt;/ol&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dsasmblr</author><guid isPermaLink="false">https://github.com/dsasmblr/cheat-engine</guid><pubDate>Fri, 08 Nov 2019 00:03:00 GMT</pubDate></item><item><title>Stephan-S/FS19_AutoDrive #4 in Lua, This week</title><link>https://github.com/Stephan-S/FS19_AutoDrive</link><description>&lt;p&gt;&lt;i&gt;FS19 version of AutoDrive - Developer Version&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-fs19_autodrive" class="anchor" aria-hidden="true" href="#fs19_autodrive"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FS19_AutoDrive&lt;/h1&gt;
&lt;p&gt;FS19 version of AutoDrive&lt;/p&gt;
&lt;p&gt;If you want to support my development effort, the best way is to open issues on any bugs you encounter or for features you would like to be added to the mod.&lt;/p&gt;
&lt;p&gt;Wer die Weiterentwicklung des Mods unterstützen möchte, kann dies am Besten durch fleißiges Erstellen von Issues zu gefundenen Bugs und/oder gewünschten Erweiterungen zum Mod tun.&lt;/p&gt;
&lt;p&gt;If you like my work, feel free to buy me a coffee (of which I drink quite a lot :D )
&lt;a href="https://www.buymeacoffee.com/9Di7EUSI2" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/031fc5a134cdca5ae3460822aba371e63f794233/68747470733a2f2f7777772e6275796d6561636f666665652e636f6d2f6173736574732f696d672f637573746f6d5f696d616765732f6f72616e67655f696d672e706e67" alt="Buy Me A Coffee" data-canonical-src="https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.paypal.me/StephanSchlosser" rel="nofollow"&gt;https://www.paypal.me/StephanSchlosser&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Stephan-S</author><guid isPermaLink="false">https://github.com/Stephan-S/FS19_AutoDrive</guid><pubDate>Fri, 08 Nov 2019 00:04:00 GMT</pubDate></item><item><title>Kong/kong #5 in Lua, This week</title><link>https://github.com/Kong/kong</link><description>&lt;p&gt;&lt;i&gt;🦍 The Cloud-Native API Gateway &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://konghq.com/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9e4fe7914c7357861223aa535d7ca9858253c96e/68747470733a2f2f6b6f6e6768712e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f30352f6b6f6e672d6c6f676f2d6769746875622d726561646d652e706e67" alt="" data-canonical-src="https://konghq.com/wp-content/uploads/2018/05/kong-logo-github-readme.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/Kong/kong/branches" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/032b58c2a2e0a2a8dbb0c1fe60a0236e1042b7ad/68747470733a2f2f7472617669732d63692e6f72672f4b6f6e672f6b6f6e672e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/Kong/kong.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/Kong/kong/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/8051e9938a1ab39cf002818dfceb6b6092f34d68/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://twitter.com/intent/follow?screen_name=thekonginc" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/295bb78a3be8393e728bb4ad7470bd98a1c5062d/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f7468656b6f6e67696e632e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f77" alt="Twitter" data-canonical-src="https://img.shields.io/twitter/follow/thekonginc.svg?style=social&amp;amp;label=Follow" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kong is a cloud-native, fast, scalable, and distributed Microservice
Abstraction Layer &lt;em&gt;(also known as an API Gateway, API Middleware or in some
cases Service Mesh)&lt;/em&gt;. Made available as an open-source project in 2015, its
core values are high performance and extensibility.&lt;/p&gt;
&lt;p&gt;Actively maintained, Kong is widely used in production at companies ranging
from startups to Global 5000 as well as government organizations.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://konghq.com/install" rel="nofollow"&gt;Installation&lt;/a&gt; |
&lt;a href="https://docs.konghq.com" rel="nofollow"&gt;Documentation&lt;/a&gt; |
&lt;a href="https://discuss.konghq.com" rel="nofollow"&gt;Forum&lt;/a&gt; |
&lt;a href="https://konghq.com/blog" rel="nofollow"&gt;Blog&lt;/a&gt; |
IRC (freenode): &lt;a href="https://webchat.freenode.net/?channels=kong" rel="nofollow"&gt;#kong&lt;/a&gt; |
&lt;a href="https://bintray.com/kong/kong-nightly/master" rel="nofollow"&gt;Nightly Builds&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-summary" class="anchor" aria-hidden="true" href="#summary"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#why-kong"&gt;&lt;strong&gt;Why Kong?&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#features"&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#distributions"&gt;&lt;strong&gt;Distributions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#development"&gt;&lt;strong&gt;Development&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#enterprise-support--demo"&gt;&lt;strong&gt;Enterprise Support &amp;amp; Demo&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;&lt;strong&gt;License&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-why-kong" class="anchor" aria-hidden="true" href="#why-kong"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why Kong?&lt;/h2&gt;
&lt;p&gt;If you are building for the web, mobile, or IoT (Internet of Things) you will
likely end up needing common functionality to run your actual software. Kong
can help by acting as a gateway (or a sidecar) for microservices requests while
providing load balancing, logging, authentication, rate-limiting,
transformations, and more through plugins.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://konghq.com/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d4d0dcb22c223db0bf2e301aab0dddb3015f1729/68747470733a2f2f6b6f6e6768712e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f30352f6b6f6e672d62656e65666974732d6769746875622d726561646d652e706e67" alt="" data-canonical-src="https://konghq.com/wp-content/uploads/2018/05/kong-benefits-github-readme.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cloud-Native&lt;/strong&gt;: Platform agnostic, Kong can run from bare metal to
Kubernetes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic Load Balancing&lt;/strong&gt;: Load balance traffic across multiple upstream
services.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hash-based Load Balancing&lt;/strong&gt;: Load balance with consistent hashing/sticky
sessions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Circuit-Breaker&lt;/strong&gt;: Intelligent tracking of unhealthy upstream services.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Health Checks:&lt;/strong&gt; Active and passive monitoring of your upstream services.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Service Discovery&lt;/strong&gt;: Resolve SRV records in third-party DNS resolvers like
Consul.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Serverless&lt;/strong&gt;: Invoke and secure AWS Lambda or OpenWhisk functions directly
from Kong.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WebSockets&lt;/strong&gt;: Communicate to your upstream services via WebSockets.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gRPC&lt;/strong&gt;: Communicate to your gRPC services and observe your traffic with logging
and observability plugins&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OAuth2.0&lt;/strong&gt;: Easily add OAuth2.0 authentication to your APIs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Logging&lt;/strong&gt;: Log requests and responses to your system over HTTP, TCP, UDP,
or to disk.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: ACL, Bot detection, whitelist/blacklist IPs, etc...&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Syslog&lt;/strong&gt;: Logging to System log.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SSL&lt;/strong&gt;: Setup a Specific SSL Certificate for an underlying service or API.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Monitoring&lt;/strong&gt;: Live monitoring provides key load and performance server
metrics.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Forward Proxy&lt;/strong&gt;: Make Kong connect to intermediary transparent HTTP proxies.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Authentications&lt;/strong&gt;: HMAC, JWT, Basic, and more.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rate-limiting&lt;/strong&gt;: Block and throttle requests based on many variables.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformations&lt;/strong&gt;: Add, remove, or manipulate HTTP requests and responses.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt;: Cache and serve responses at the proxy layer.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CLI&lt;/strong&gt;: Control your Kong cluster from the command line.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;REST API&lt;/strong&gt;: Kong can be operated with its RESTful API for maximum
flexibility.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Geo-Replicated&lt;/strong&gt;: Configs are always up-to-date across different regions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Failure Detection &amp;amp; Recovery&lt;/strong&gt;: Kong is unaffected if one of your Cassandra
nodes goes down.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clustering&lt;/strong&gt;: All Kong nodes auto-join the cluster keeping their config
updated across nodes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: Distributed by nature, Kong scales horizontally by simply
adding nodes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt;: Kong handles load with ease by scaling and using NGINX at
the core.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plugins&lt;/strong&gt;: Extendable architecture for adding functionality to Kong and
APIs.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more info about plugins and integrations, you can check out the &lt;a href="https://docs.konghq.com/hub/" rel="nofollow"&gt;Kong
Hub&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-distributions" class="anchor" aria-hidden="true" href="#distributions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Distributions&lt;/h2&gt;
&lt;p&gt;Kong comes in many shapes. While this repository contains its core's source
code, other repos are also under active development:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/docker-kong"&gt;Kong Docker&lt;/a&gt;: A Dockerfile for
running Kong in Docker.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/kong/releases"&gt;Kong Packages&lt;/a&gt;: Pre-built packages
for Debian, Red Hat, and OS X distributions (shipped with each release).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/kong-vagrant"&gt;Kong Vagrant&lt;/a&gt;: A Vagrantfile for
provisioning a development-ready environment for Kong.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/homebrew-kong"&gt;Kong Homebrew&lt;/a&gt;: Homebrew Formula
for Kong.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/kong-dist-cloudformation"&gt;Kong CloudFormation&lt;/a&gt;:
Kong in a 1-click deployment for AWS EC2.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://aws.amazon.com/marketplace/pp/B06WP4TNKL" rel="nofollow"&gt;Kong AWS AMI&lt;/a&gt;: Kong AMI on
the AWS Marketplace.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/kong-dist-azure"&gt;Kong on Microsoft Azure&lt;/a&gt;: Run Kong
using Azure Resource Manager.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/heroku/heroku-kong"&gt;Kong on Heroku&lt;/a&gt;: Deploy Kong on
Heroku in one click.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.instaclustr.com/solutions/managed-cassandra-for-kong/" rel="nofollow"&gt;Kong and Instaclustr&lt;/a&gt;: Let
Instaclustr manage your Cassandra cluster.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kong/kubernetes-ingress-controller"&gt;Kubernetes Ingress Controller for Kong&lt;/a&gt;:
Use Kong for Kubernetes Ingress.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bintray.com/kong/kong-nightly/master" rel="nofollow"&gt;Nightly Builds&lt;/a&gt;: Builds of the master branch available
every morning at about 9AM PST.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-development" class="anchor" aria-hidden="true" href="#development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development&lt;/h2&gt;
&lt;p&gt;If you are planning on developing on Kong, you'll need a development
installation. The &lt;code&gt;next&lt;/code&gt; branch holds the latest unreleased source code.&lt;/p&gt;
&lt;p&gt;You can read more about writing your own plugins in the &lt;a href="https://docs.konghq.com/latest/plugin-development/" rel="nofollow"&gt;Plugin Development
Guide&lt;/a&gt;, or browse an
online version of Kong's source code documentation in the &lt;a href="https://docs.konghq.com/latest/pdk/" rel="nofollow"&gt;Plugin Development
Kit (PDK) Reference&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h4&gt;
&lt;p&gt;You can use Docker / docker-compose and a mounted volume to develop Kong by
following the instructions on &lt;a href="https://github.com/Kong/kong-build-tools#developing-kong"&gt;Kong/kong-build-tools&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-vagrant" class="anchor" aria-hidden="true" href="#vagrant"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Vagrant&lt;/h4&gt;
&lt;p&gt;You can use a Vagrant box running Kong and Postgres that you can find at
&lt;a href="https://github.com/Kong/kong-vagrant"&gt;Kong/kong-vagrant&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-source-install" class="anchor" aria-hidden="true" href="#source-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source Install&lt;/h4&gt;
&lt;p&gt;Kong mostly is an OpenResty application made of Lua source files, but also
requires some additional third-party dependencies. We recommend installing
those by following the source install instructions at
&lt;a href="https://docs.konghq.com/install/source/" rel="nofollow"&gt;https://docs.konghq.com/install/source/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Instead of following the second step (Install Kong), clone this repository
and install the latest Lua sources instead of the currently released ones:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ git clone https://github.com/Kong/kong
$ &lt;span class="pl-c1"&gt;cd&lt;/span&gt; kong/

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; you might want to switch to the development branch. See CONTRIBUTING.md&lt;/span&gt;
$ git checkout next

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; install the Lua sources&lt;/span&gt;
$ luarocks make&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-running-for-development" class="anchor" aria-hidden="true" href="#running-for-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running for development&lt;/h4&gt;
&lt;p&gt;Check out the &lt;a href="https://github.com/Kong/kong/blob/next/kong.conf.default#L244"&gt;development section&lt;/a&gt;
of the default configuration file for properties to tweak in order to ease
the development process for Kong.&lt;/p&gt;
&lt;p&gt;Modifying the &lt;a href="https://github.com/openresty/lua-nginx-module#lua_package_path"&gt;&lt;code&gt;lua_package_path&lt;/code&gt;&lt;/a&gt;
and &lt;a href="https://github.com/openresty/lua-nginx-module#lua_package_cpath"&gt;&lt;code&gt;lua_package_cpath&lt;/code&gt;&lt;/a&gt;
directives will allow Kong to find your custom plugin's source code wherever it
might be in your system.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-tests" class="anchor" aria-hidden="true" href="#tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tests&lt;/h4&gt;
&lt;p&gt;Install the development dependencies (&lt;a href="https://github.com/Olivine-Labs/busted"&gt;busted&lt;/a&gt;, &lt;a href="https://github.com/mpeterv/luacheck"&gt;luacheck&lt;/a&gt;) with:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ make dev&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Kong relies on three test suites using the &lt;a href="https://github.com/Olivine-Labs/busted"&gt;busted&lt;/a&gt; testing library:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Unit tests&lt;/li&gt;
&lt;li&gt;Integration tests, which require Postgres and Cassandra to be up and running&lt;/li&gt;
&lt;li&gt;Plugins tests, which require Postgres to be running&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first can simply be run after installing busted and running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make test
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, the integration and plugins tests will spawn a Kong instance and
perform their tests against it. As so, consult/edit the &lt;code&gt;spec/kong_tests.conf&lt;/code&gt;
configuration file to make your test instance point to your Postgres/Cassandra
servers, depending on your needs.&lt;/p&gt;
&lt;p&gt;You can run the integration tests (assuming &lt;strong&gt;both&lt;/strong&gt; Postgres and Cassandra are
running and configured according to &lt;code&gt;spec/kong_tests.conf&lt;/code&gt;) with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make test-integration
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the plugins tests with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make test-plugins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, all suites can be run at once by simply using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make test-all
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Consult the &lt;a href=".ci/run_tests.sh"&gt;run_tests.sh&lt;/a&gt; script for a more advanced example
usage of the tests suites and the Makefile.&lt;/p&gt;
&lt;p&gt;Finally, a very useful tool in Lua development (as with many other dynamic
languages) is performing static linting of your code. You can use &lt;a href="https://github.com/mpeterv/luacheck"&gt;luacheck&lt;/a&gt;
(installed with &lt;code&gt;make dev&lt;/code&gt;) for this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make lint
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-makefile" class="anchor" aria-hidden="true" href="#makefile"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Makefile&lt;/h4&gt;
&lt;p&gt;When developing, you can use the &lt;code&gt;Makefile&lt;/code&gt; for doing the following operations:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="right"&gt;Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;install&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Install the Kong luarock globally&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;dev&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Install development dependencies&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;lint&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Lint Lua files in &lt;code&gt;kong/&lt;/code&gt; and &lt;code&gt;spec/&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;test&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Run the unit tests suite&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;test-integration&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Run the integration tests suite&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;test-plugins&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Run the plugins test suite&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;code&gt;test-all&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Run all unit + integration + plugins tests at once&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-enterprise-support--demo" class="anchor" aria-hidden="true" href="#enterprise-support--demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Enterprise Support &amp;amp; Demo&lt;/h2&gt;
&lt;p&gt;If you are working in a large organization you should learn more about &lt;a href="https://konghq.com/kong-enterprise-edition/" rel="nofollow"&gt;Kong
Enterprise&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;Copyright 2016-2019 Kong Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Kong</author><guid isPermaLink="false">https://github.com/Kong/kong</guid><pubDate>Fri, 08 Nov 2019 00:05:00 GMT</pubDate></item><item><title>phillipi/pix2pix #6 in Lua, This week</title><link>https://github.com/phillipi/pix2pix</link><description>&lt;p&gt;&lt;i&gt;Image-to-image translation with conditional adversarial nets&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pix2pix" class="anchor" aria-hidden="true" href="#pix2pix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;pix2pix&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://phillipi.github.io/pix2pix/" rel="nofollow"&gt;Project&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/1611.07004" rel="nofollow"&gt;Arxiv&lt;/a&gt; |
&lt;a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"&gt;PyTorch&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Torch implementation for learning a mapping from input images to output images, for example:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="imgs/examples.jpg"&gt;&lt;img src="imgs/examples.jpg" width="900px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Image-to-Image Translation with Conditional Adversarial Networks&lt;br&gt;
&lt;a href="http://web.mit.edu/phillipi/" rel="nofollow"&gt;Phillip Isola&lt;/a&gt;, &lt;a href="https://people.eecs.berkeley.edu/~junyanz/" rel="nofollow"&gt;Jun-Yan Zhu&lt;/a&gt;, &lt;a href="https://people.eecs.berkeley.edu/~tinghuiz/" rel="nofollow"&gt;Tinghui Zhou&lt;/a&gt;, &lt;a href="https://people.eecs.berkeley.edu/~efros/" rel="nofollow"&gt;Alexei A. Efros&lt;/a&gt;&lt;br&gt;
CVPR, 2017.&lt;/p&gt;
&lt;p&gt;On some tasks, decent results can be obtained fairly quickly and on small datasets. For example, to learn to generate facades (example shown above), we trained on just 400 images for about 2 hours (on a single Pascal Titan X GPU). However, for harder problems it may be important to train on far larger datasets, and for many hours or even days.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Please check out our &lt;a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"&gt;PyTorch&lt;/a&gt; implementation for pix2pix and CycleGAN. The PyTorch version is under active development and can produce results comparable to or better than this Torch version.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Linux or OSX&lt;/li&gt;
&lt;li&gt;NVIDIA GPU + CUDA CuDNN (CPU mode and CUDA without CuDNN may work with minimal modification, but untested)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Install torch and dependencies from &lt;a href="https://github.com/torch/distro"&gt;https://github.com/torch/distro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install torch packages &lt;code&gt;nngraph&lt;/code&gt; and &lt;code&gt;display&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;luarocks install nngraph
luarocks install https://raw.githubusercontent.com/szym/display/master/display-scm-0.rockspec&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Clone this repo:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone git@github.com:phillipi/pix2pix.git
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; pix2pix&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Download the dataset (e.g., &lt;a href="http://cmp.felk.cvut.cz/~tylecr1/facade/" rel="nofollow"&gt;CMP Facades&lt;/a&gt;):&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bash ./datasets/download_dataset.sh facades&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Train the model&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=./datasets/facades name=facades_generation which_direction=BtoA th train.lua&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;(CPU only) The same training command without using a GPU or CUDNN. Setting the environment variables &lt;code&gt;gpu=0 cudnn=0&lt;/code&gt; forces CPU only&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=./datasets/facades name=facades_generation which_direction=BtoA gpu=0 cudnn=0 batchSize=10 save_epoch_freq=5 th train.lua&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;(Optionally) start the display server to view results as the model trains. ( See &lt;a href="#display-ui"&gt;Display UI&lt;/a&gt; for more details):&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;th -ldisplay.start 8000 0.0.0.0&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Finally, test the model:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=./datasets/facades name=facades_generation which_direction=BtoA phase=val th test.lua&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The test results will be saved to an html file here: &lt;code&gt;./results/facades_generation/latest_net_G_val/index.html&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-train" class="anchor" aria-hidden="true" href="#train"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=/path/to/data/ name=expt_name which_direction=AtoB th train.lua&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Switch &lt;code&gt;AtoB&lt;/code&gt; to &lt;code&gt;BtoA&lt;/code&gt; to train translation in opposite direction.&lt;/p&gt;
&lt;p&gt;Models are saved to &lt;code&gt;./checkpoints/expt_name&lt;/code&gt; (can be changed by passing &lt;code&gt;checkpoint_dir=your_dir&lt;/code&gt; in train.lua).&lt;/p&gt;
&lt;p&gt;See &lt;code&gt;opt&lt;/code&gt; in train.lua for additional training options.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-test" class="anchor" aria-hidden="true" href="#test"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Test&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_ROOT=/path/to/data/ name=expt_name which_direction=AtoB phase=val th test.lua&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will run the model named &lt;code&gt;expt_name&lt;/code&gt; in direction &lt;code&gt;AtoB&lt;/code&gt; on all images in &lt;code&gt;/path/to/data/val&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Result images, and a webpage to view them, are saved to &lt;code&gt;./results/expt_name&lt;/code&gt; (can be changed by passing &lt;code&gt;results_dir=your_dir&lt;/code&gt; in test.lua).&lt;/p&gt;
&lt;p&gt;See &lt;code&gt;opt&lt;/code&gt; in test.lua for additional testing options.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-datasets" class="anchor" aria-hidden="true" href="#datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Datasets&lt;/h2&gt;
&lt;p&gt;Download the datasets using the following script. Some of the datasets are collected by other researchers. Please cite their papers if you use the data.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bash ./datasets/download_dataset.sh dataset_name&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;facades&lt;/code&gt;: 400 images from &lt;a href="http://cmp.felk.cvut.cz/~tylecr1/facade/" rel="nofollow"&gt;CMP Facades dataset&lt;/a&gt;. [&lt;a href="datasets/bibtex/facades.tex"&gt;Citation&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cityscapes&lt;/code&gt;: 2975 images from the &lt;a href="https://www.cityscapes-dataset.com/" rel="nofollow"&gt;Cityscapes training set&lt;/a&gt;.  [&lt;a href="datasets/bibtex/cityscapes.tex"&gt;Citation&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;maps&lt;/code&gt;: 1096 training images scraped from Google Maps&lt;/li&gt;
&lt;li&gt;&lt;code&gt;edges2shoes&lt;/code&gt;: 50k training images from &lt;a href="http://vision.cs.utexas.edu/projects/finegrained/utzap50k/" rel="nofollow"&gt;UT Zappos50K dataset&lt;/a&gt;. Edges are computed by &lt;a href="https://github.com/s9xie/hed"&gt;HED&lt;/a&gt; edge detector + post-processing.
[&lt;a href="datasets/bibtex/shoes.tex"&gt;Citation&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;edges2handbags&lt;/code&gt;: 137K Amazon Handbag images from &lt;a href="https://github.com/junyanz/iGAN"&gt;iGAN project&lt;/a&gt;. Edges are computed by &lt;a href="https://github.com/s9xie/hed"&gt;HED&lt;/a&gt; edge detector + post-processing. [&lt;a href="datasets/bibtex/handbags.tex"&gt;Citation&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;night2day&lt;/code&gt;: around 20K natural scene images from  &lt;a href="http://transattr.cs.brown.edu/" rel="nofollow"&gt;Transient Attributes dataset&lt;/a&gt; [&lt;a href="datasets/bibtex/transattr.tex"&gt;Citation&lt;/a&gt;]. To train a &lt;code&gt;day2night&lt;/code&gt; pix2pix model, you need to add &lt;code&gt;which_direction=BtoA&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-models" class="anchor" aria-hidden="true" href="#models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Models&lt;/h2&gt;
&lt;p&gt;Download the pre-trained models with the following script. You need to rename the model (e.g., &lt;code&gt;facades_label2image&lt;/code&gt; to &lt;code&gt;/checkpoints/facades/latest_net_G.t7&lt;/code&gt;) after the download has finished.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bash ./models/download_model.sh model_name&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;facades_label2image&lt;/code&gt; (label -&amp;gt; facade): trained on the CMP Facades dataset.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cityscapes_label2image&lt;/code&gt; (label -&amp;gt; street scene): trained on the Cityscapes dataset.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cityscapes_image2label&lt;/code&gt; (street scene -&amp;gt; label): trained on the Cityscapes dataset.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;edges2shoes&lt;/code&gt; (edge -&amp;gt; photo): trained on UT Zappos50K dataset.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;edges2handbags&lt;/code&gt; (edge -&amp;gt; photo): trained on Amazon handbags images.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;day2night&lt;/code&gt; (daytime scene -&amp;gt; nighttime scene): trained on around 100 &lt;a href="http://transattr.cs.brown.edu/" rel="nofollow"&gt;webcams&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-setup-training-and-test-data" class="anchor" aria-hidden="true" href="#setup-training-and-test-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup Training and Test data&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-generating-pairs" class="anchor" aria-hidden="true" href="#generating-pairs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generating Pairs&lt;/h3&gt;
&lt;p&gt;We provide a python script to generate training data in the form of pairs of images {A,B}, where A and B are two different depictions of the same underlying scene. For example, these might be pairs {label map, photo} or {bw image, color image}. Then we can learn to translate A to B or B to A:&lt;/p&gt;
&lt;p&gt;Create folder &lt;code&gt;/path/to/data&lt;/code&gt; with subfolders &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt;. &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt; should each have their own subfolders &lt;code&gt;train&lt;/code&gt;, &lt;code&gt;val&lt;/code&gt;, &lt;code&gt;test&lt;/code&gt;, etc. In &lt;code&gt;/path/to/data/A/train&lt;/code&gt;, put training images in style A. In &lt;code&gt;/path/to/data/B/train&lt;/code&gt;, put the corresponding images in style B. Repeat same for other data splits (&lt;code&gt;val&lt;/code&gt;, &lt;code&gt;test&lt;/code&gt;, etc).&lt;/p&gt;
&lt;p&gt;Corresponding images in a pair {A,B} must be the same size and have the same filename, e.g., &lt;code&gt;/path/to/data/A/train/1.jpg&lt;/code&gt; is considered to correspond to &lt;code&gt;/path/to/data/B/train/1.jpg&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once the data is formatted this way, call:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python scripts/combine_A_and_B.py --fold_A /path/to/data/A --fold_B /path/to/data/B --fold_AB /path/to/data&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will combine each pair of images (A,B) into a single image file, ready for training.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-notes-on-colorization" class="anchor" aria-hidden="true" href="#notes-on-colorization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notes on Colorization&lt;/h3&gt;
&lt;p&gt;No need to run &lt;code&gt;combine_A_and_B.py&lt;/code&gt; for colorization. Instead, you need to prepare some natural images and set &lt;code&gt;preprocess=colorization&lt;/code&gt; in the script. The program will automatically convert each RGB image into Lab color space, and create  &lt;code&gt;L -&amp;gt; ab&lt;/code&gt; image pair during the training. Also set &lt;code&gt;input_nc=1&lt;/code&gt; and &lt;code&gt;output_nc=2&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-extracting-edges" class="anchor" aria-hidden="true" href="#extracting-edges"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Extracting Edges&lt;/h3&gt;
&lt;p&gt;We provide python and Matlab scripts to extract coarse edges from photos. Run &lt;code&gt;scripts/edges/batch_hed.py&lt;/code&gt; to compute &lt;a href="https://github.com/s9xie/hed"&gt;HED&lt;/a&gt; edges. Run &lt;code&gt;scripts/edges/PostprocessHED.m&lt;/code&gt; to simplify edges with additional post-processing steps. Check the code documentation for more details.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-evaluating-labels2photos-on-cityscapes" class="anchor" aria-hidden="true" href="#evaluating-labels2photos-on-cityscapes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Evaluating Labels2Photos on Cityscapes&lt;/h3&gt;
&lt;p&gt;We provide scripts for running the evaluation of the Labels2Photos task on the Cityscapes &lt;strong&gt;validation&lt;/strong&gt; set. We assume that you have installed &lt;code&gt;caffe&lt;/code&gt; (and &lt;code&gt;pycaffe&lt;/code&gt;) in your system. If not, see the &lt;a href="http://caffe.berkeleyvision.org/installation.html" rel="nofollow"&gt;official website&lt;/a&gt; for installation instructions. Once &lt;code&gt;caffe&lt;/code&gt; is successfully installed, download the pre-trained FCN-8s semantic segmentation model (512MB) by running&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bash ./scripts/eval_cityscapes/download_fcn8s.sh&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then make sure &lt;code&gt;./scripts/eval_cityscapes/&lt;/code&gt; is in your system's python path. If not, run the following command to add it&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; PYTHONPATH=&lt;span class="pl-smi"&gt;${PYTHONPATH}&lt;/span&gt;:./scripts/eval_cityscapes/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now you can run the following command to evaluate your predictions:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python ./scripts/eval_cityscapes/evaluate.py --cityscapes_dir /path/to/original/cityscapes/dataset/ --result_dir /path/to/your/predictions/ --output_dir /path/to/output/directory/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Images stored under &lt;code&gt;--result_dir&lt;/code&gt; should contain your model predictions on the Cityscapes &lt;strong&gt;validation&lt;/strong&gt; split, and have the original Cityscapes naming convention (e.g., &lt;code&gt;frankfurt_000001_038418_leftImg8bit.png&lt;/code&gt;). The script will output a text file under &lt;code&gt;--output_dir&lt;/code&gt; containing the metric.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Further notes&lt;/strong&gt;: The pre-trained model is &lt;strong&gt;not&lt;/strong&gt; supposed to work on Cityscapes in the original resolution (1024x2048) as it was trained on 256x256 images that are upsampled to 1024x2048. The purpose of the resizing was to 1) keep the label maps in the original high resolution untouched and 2) avoid the need of changing the standard FCN training code for Cityscapes. To get the &lt;em&gt;ground-truth&lt;/em&gt; numbers in the paper, you need to resize the original Cityscapes images to 256x256 before running the evaluation code.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-display-ui" class="anchor" aria-hidden="true" href="#display-ui"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Display UI&lt;/h2&gt;
&lt;p&gt;Optionally, for displaying images during training and test, use the &lt;a href="https://github.com/szym/display"&gt;display package&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install it with: &lt;code&gt;luarocks install https://raw.githubusercontent.com/szym/display/master/display-scm-0.rockspec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Then start the server with: &lt;code&gt;th -ldisplay.start&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Open this URL in your browser: &lt;a href="http://localhost:8000" rel="nofollow"&gt;http://localhost:8000&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By default, the server listens on localhost. Pass &lt;code&gt;0.0.0.0&lt;/code&gt; to allow external connections on any interface:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;th -ldisplay.start 8000 0.0.0.0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then open &lt;code&gt;http://(hostname):(port)/&lt;/code&gt; in your browser to load the remote desktop.&lt;/p&gt;
&lt;p&gt;L1 error is plotted to the display by default. Set the environment variable &lt;code&gt;display_plot&lt;/code&gt; to a comma-separated list of values &lt;code&gt;errL1&lt;/code&gt;, &lt;code&gt;errG&lt;/code&gt; and &lt;code&gt;errD&lt;/code&gt; to visualize the L1, generator, and discriminator error respectively. For example, to plot only the generator and discriminator errors to the display instead of the default L1 error, set &lt;code&gt;display_plot="errG,errD"&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you use this code for your research, please cite our paper &lt;a href="https://arxiv.org/pdf/1611.07004v1.pdf" rel="nofollow"&gt;Image-to-Image Translation Using Conditional Adversarial Networks&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{pix2pix2017,
  title={Image-to-Image Translation with Conditional Adversarial Networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  journal={CVPR},
  year={2017}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-cat-paper-collection" class="anchor" aria-hidden="true" href="#cat-paper-collection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cat Paper Collection&lt;/h2&gt;
&lt;p&gt;If you love cats, and love reading cool graphics, vision, and learning papers, please check out the Cat Paper Collection:&lt;br&gt;
&lt;a href="https://github.com/junyanz/CatPapers"&gt;[Github]&lt;/a&gt; &lt;a href="http://people.eecs.berkeley.edu/~junyanz/cat/cat_papers.html" rel="nofollow"&gt;[Webpage]&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Code borrows heavily from &lt;a href="https://github.com/soumith/dcgan.torch"&gt;DCGAN&lt;/a&gt;. The data loader is modified from &lt;a href="https://github.com/soumith/dcgan.torch"&gt;DCGAN&lt;/a&gt; and  &lt;a href="https://github.com/pathak22/context-encoder"&gt;Context-Encoder&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>phillipi</author><guid isPermaLink="false">https://github.com/phillipi/pix2pix</guid><pubDate>Fri, 08 Nov 2019 00:06:00 GMT</pubDate></item><item><title>ledgetech/lua-resty-http #7 in Lua, This week</title><link>https://github.com/ledgetech/lua-resty-http</link><description>&lt;p&gt;&lt;i&gt;Lua HTTP client cosocket driver for OpenResty / ngx_lua.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-lua-resty-http" class="anchor" aria-hidden="true" href="#lua-resty-http"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;lua-resty-http&lt;/h1&gt;
&lt;p&gt;Lua HTTP client cosocket driver for &lt;a href="http://openresty.org/" rel="nofollow"&gt;OpenResty&lt;/a&gt; / &lt;a href="https://github.com/openresty/lua-nginx-module"&gt;ngx_lua&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-status" class="anchor" aria-hidden="true" href="#status"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Status&lt;/h1&gt;
&lt;p&gt;Production ready.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;HTTP 1.0 and 1.1&lt;/li&gt;
&lt;li&gt;SSL&lt;/li&gt;
&lt;li&gt;Streaming interface to the response body, for predictable memory usage&lt;/li&gt;
&lt;li&gt;Alternative simple interface for singleshot requests without manual connection step&lt;/li&gt;
&lt;li&gt;Chunked and non-chunked transfer encodings&lt;/li&gt;
&lt;li&gt;Keepalive&lt;/li&gt;
&lt;li&gt;Pipelining&lt;/li&gt;
&lt;li&gt;Trailers&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-api" class="anchor" aria-hidden="true" href="#api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;API&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#new"&gt;new&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#connect"&gt;connect&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#connect_proxy"&gt;connect_proxy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#set_proxy_options"&gt;set_proxy_options&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#set_timeout"&gt;set_timeout&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#set_timeouts"&gt;set_timeouts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ssl_handshake"&gt;ssl_handshake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#set_keepalive"&gt;set_keepalive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#get_reused_times"&gt;get_reused_times&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#close"&gt;close&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#request"&gt;request&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#request_uri"&gt;request_uri&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#request_pipeline"&gt;request_pipeline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#response"&gt;Response&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#resbody_reader"&gt;body_reader&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#resread_body"&gt;read_body&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#resread_trailers"&gt;read_trailers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#proxy"&gt;Proxy&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#proxy_request"&gt;proxy_request&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#proxy_response"&gt;proxy_response&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#utility"&gt;Utility&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#parse_uri"&gt;parse_uri&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#get_client_body_reader"&gt;get_client_body_reader&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-synopsis" class="anchor" aria-hidden="true" href="#synopsis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Synopsis&lt;/h2&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;lua_package_path&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/path/to/lua-resty-http/lib/?.lua;;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-c1"&gt;server&lt;/span&gt; {


  location &lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-c1"&gt;simpleinterface&lt;/span&gt; {
    resolver &lt;span class="pl-c1"&gt;8.8&lt;/span&gt;.8.8;  &lt;span class="pl-k"&gt;#&lt;/span&gt; use &lt;span class="pl-c1"&gt;Google&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;s open DNS server for an example&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;    content_by_lua_block {&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- For simple singleshot requests, use the URI interface.&lt;/span&gt;
&lt;span class="pl-s"&gt;      local http = require "resty.http"&lt;/span&gt;
&lt;span class="pl-s"&gt;      local httpc = http.new()&lt;/span&gt;
&lt;span class="pl-s"&gt;      local res, err = httpc:request_uri("http://example.com/helloworld", {&lt;/span&gt;
&lt;span class="pl-s"&gt;        method = "POST",&lt;/span&gt;
&lt;span class="pl-s"&gt;        body = "a=1&amp;amp;b=2",&lt;/span&gt;
&lt;span class="pl-s"&gt;        headers = {&lt;/span&gt;
&lt;span class="pl-s"&gt;          ["Content-Type"] = "application/x-www-form-urlencoded",&lt;/span&gt;
&lt;span class="pl-s"&gt;        },&lt;/span&gt;
&lt;span class="pl-s"&gt;        keepalive_timeout = 60,&lt;/span&gt;
&lt;span class="pl-s"&gt;        keepalive_pool = 10&lt;/span&gt;
&lt;span class="pl-s"&gt;      })&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      if not res then&lt;/span&gt;
&lt;span class="pl-s"&gt;        ngx.say("failed to request: ", err)&lt;/span&gt;
&lt;span class="pl-s"&gt;        return&lt;/span&gt;
&lt;span class="pl-s"&gt;      end&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- In this simple form, there is no manual connection step, so the body is read&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- all in one go, including any trailers, and the connection closed or keptalive&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- for you.&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      ngx.status = res.status&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      for k,v in pairs(res.headers) do&lt;/span&gt;
&lt;span class="pl-s"&gt;          --&lt;/span&gt;
&lt;span class="pl-s"&gt;      end&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      ngx.say(res.body)&lt;/span&gt;
&lt;span class="pl-s"&gt;    }&lt;/span&gt;
&lt;span class="pl-s"&gt;  }&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;  location /genericinterface {&lt;/span&gt;
&lt;span class="pl-s"&gt;    content_by_lua_block {&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      local http = require "resty.http"&lt;/span&gt;
&lt;span class="pl-s"&gt;      local httpc = http.new()&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- The generic form gives us more control. We must connect manually.&lt;/span&gt;
&lt;span class="pl-s"&gt;      httpc:set_timeout(500)&lt;/span&gt;
&lt;span class="pl-s"&gt;      httpc:connect("127.0.0.1", 80)&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- And request using a path, rather than a full URI.&lt;/span&gt;
&lt;span class="pl-s"&gt;      local res, err = httpc:request({&lt;/span&gt;
&lt;span class="pl-s"&gt;          path = "/helloworld",&lt;/span&gt;
&lt;span class="pl-s"&gt;          headers = {&lt;/span&gt;
&lt;span class="pl-s"&gt;              ["Host"] = "example.com",&lt;/span&gt;
&lt;span class="pl-s"&gt;          },&lt;/span&gt;
&lt;span class="pl-s"&gt;      })&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      if not res then&lt;/span&gt;
&lt;span class="pl-s"&gt;        ngx.say("failed to request: ", err)&lt;/span&gt;
&lt;span class="pl-s"&gt;        return&lt;/span&gt;
&lt;span class="pl-s"&gt;      end&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      -- Now we can use the body_reader iterator, to stream the body according to our desired chunk size.&lt;/span&gt;
&lt;span class="pl-s"&gt;      local reader = res.body_reader&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      repeat&lt;/span&gt;
&lt;span class="pl-s"&gt;        local chunk, err = reader(8192)&lt;/span&gt;
&lt;span class="pl-s"&gt;        if err then&lt;/span&gt;
&lt;span class="pl-s"&gt;          ngx.log(ngx.ERR, err)&lt;/span&gt;
&lt;span class="pl-s"&gt;          break&lt;/span&gt;
&lt;span class="pl-s"&gt;        end&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;        if chunk then&lt;/span&gt;
&lt;span class="pl-s"&gt;          -- process&lt;/span&gt;
&lt;span class="pl-s"&gt;        end&lt;/span&gt;
&lt;span class="pl-s"&gt;      until not chunk&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;/span&gt;
&lt;span class="pl-s"&gt;      local ok, err = httpc:set_keepalive()&lt;/span&gt;
&lt;span class="pl-s"&gt;      if not ok then&lt;/span&gt;
&lt;span class="pl-s"&gt;        ngx.say("failed to set keepalive: ", err)&lt;/span&gt;
&lt;span class="pl-s"&gt;        return&lt;/span&gt;
&lt;span class="pl-s"&gt;      end&lt;/span&gt;
&lt;span class="pl-s"&gt;    }&lt;/span&gt;
&lt;span class="pl-s"&gt;  }&lt;/span&gt;
&lt;span class="pl-s"&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-connection" class="anchor" aria-hidden="true" href="#connection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Connection&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-new" class="anchor" aria-hidden="true" href="#new"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;new&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: httpc = http.new()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Creates the http object. In case of failures, returns &lt;code&gt;nil&lt;/code&gt; and a string describing the error.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-connect" class="anchor" aria-hidden="true" href="#connect"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;connect&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: ok, err = httpc:connect(host, port, options_table?)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;syntax: ok, err = httpc:connect("unix:/path/to/unix.sock", options_table?)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Attempts to connect to the web server.&lt;/p&gt;
&lt;p&gt;Before actually resolving the host name and connecting to the remote backend, this method will always look up the connection pool for matched idle connections created by previous calls of this method.&lt;/p&gt;
&lt;p&gt;An optional Lua table can be specified as the last argument to this method to specify various connect options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pool&lt;/code&gt;
: Specifies a custom name for the connection pool being used. If omitted, then the connection pool name will be generated from the string template &lt;code&gt;&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;&lt;/code&gt; or &lt;code&gt;&amp;lt;unix-socket-path&amp;gt;&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-connect_proxy" class="anchor" aria-hidden="true" href="#connect_proxy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;connect_proxy&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: ok, err = httpc:connect_proxy(proxy_uri, scheme, host, port, proxy_authorization)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Attempts to connect to the web server through the given proxy server. The method accepts the following arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;proxy_uri&lt;/code&gt; - Full URI of the proxy server to use (e.g. &lt;code&gt;http://proxy.example.com:3128/&lt;/code&gt;). Note: Only &lt;code&gt;http&lt;/code&gt; protocol is supported.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;scheme&lt;/code&gt; - The protocol to use between the proxy server and the remote host (&lt;code&gt;http&lt;/code&gt; or &lt;code&gt;https&lt;/code&gt;). If &lt;code&gt;https&lt;/code&gt; is specified as the scheme, &lt;code&gt;connect_proxy()&lt;/code&gt; makes a &lt;code&gt;CONNECT&lt;/code&gt; request to establish a TCP tunnel to the remote host through the proxy server.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host&lt;/code&gt; - The hostname of the remote host to connect to.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;port&lt;/code&gt; - The port of the remote host to connect to.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;proxy_authorization&lt;/code&gt; - The &lt;code&gt;Proxy-Authorization&lt;/code&gt; header value sent to the proxy server via &lt;code&gt;CONNECT&lt;/code&gt; when the &lt;code&gt;scheme&lt;/code&gt; is &lt;code&gt;https&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If an error occurs during the connection attempt, this method returns &lt;code&gt;nil&lt;/code&gt; with a string describing the error. If the connection was successfully established, the method returns &lt;code&gt;1&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;There's a few key points to keep in mind when using this api:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the scheme is &lt;code&gt;https&lt;/code&gt;, you need to perform the TLS handshake with the remote server manually using the &lt;code&gt;ssl_handshake()&lt;/code&gt; method before sending any requests through the proxy tunnel.&lt;/li&gt;
&lt;li&gt;If the scheme is &lt;code&gt;http&lt;/code&gt;, you need to ensure that the requests you send through the connections conforms to &lt;a href="https://tools.ietf.org/html/rfc7230" rel="nofollow"&gt;RFC 7230&lt;/a&gt; and especially &lt;a href="https://tools.ietf.org/html/rfc7230#section-5.3.2" rel="nofollow"&gt;Section 5.3.2.&lt;/a&gt; which states that the request target must be in absolute form. In practice, this means that when you use &lt;code&gt;send_request()&lt;/code&gt;, the &lt;code&gt;path&lt;/code&gt; must be an absolute URI to the resource (e.g. &lt;code&gt;http://example.com/index.html&lt;/code&gt; instead of just &lt;code&gt;/index.html&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-set_timeout" class="anchor" aria-hidden="true" href="#set_timeout"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;set_timeout&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: httpc:set_timeout(time)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Sets the timeout (in ms) protection for subsequent operations, including the &lt;code&gt;connect&lt;/code&gt; method.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-set_timeouts" class="anchor" aria-hidden="true" href="#set_timeouts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;set_timeouts&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: httpc:set_timeouts(connect_timeout, send_timeout, read_timeout)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Sets the connect timeout threshold, send timeout threshold, and read timeout threshold, respectively, in milliseconds, for subsequent socket operations (connect, send, receive, and iterators returned from receiveuntil).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ssl_handshake" class="anchor" aria-hidden="true" href="#ssl_handshake"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ssl_handshake&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: session, err = httpc:ssl_handshake(session, host, verify)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Performs an SSL handshake on the TCP connection, only available in ngx_lua &amp;gt; v0.9.11&lt;/p&gt;
&lt;p&gt;See docs for &lt;a href="https://github.com/openresty/lua-nginx-module#ngxsockettcp"&gt;ngx.socket.tcp&lt;/a&gt; for details.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-set_keepalive" class="anchor" aria-hidden="true" href="#set_keepalive"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;set_keepalive&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: ok, err = httpc:set_keepalive(max_idle_timeout, pool_size)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Attempts to puts the current connection into the ngx_lua cosocket connection pool.&lt;/p&gt;
&lt;p&gt;You can specify the max idle timeout (in ms) when the connection is in the pool and the maximal size of the pool every nginx worker process.&lt;/p&gt;
&lt;p&gt;Only call this method in the place you would have called the &lt;code&gt;close&lt;/code&gt; method instead. Calling this method will immediately turn the current http object into the &lt;code&gt;closed&lt;/code&gt; state. Any subsequent operations other than &lt;code&gt;connect()&lt;/code&gt; on the current object will return the &lt;code&gt;closed&lt;/code&gt; error.&lt;/p&gt;
&lt;p&gt;Note that calling this instead of &lt;code&gt;close&lt;/code&gt; is "safe" in that it will conditionally close depending on the type of request. Specifically, a &lt;code&gt;1.0&lt;/code&gt; request without &lt;code&gt;Connection: Keep-Alive&lt;/code&gt; will be closed, as will a &lt;code&gt;1.1&lt;/code&gt; request with &lt;code&gt;Connection: Close&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In case of success, returns &lt;code&gt;1&lt;/code&gt;. In case of errors, returns &lt;code&gt;nil, err&lt;/code&gt;. In the case where the connection is conditionally closed as described above, returns &lt;code&gt;2&lt;/code&gt; and the error string &lt;code&gt;connection must be closed&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-set_proxy_options" class="anchor" aria-hidden="true" href="#set_proxy_options"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;set_proxy_options&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: httpc:set_proxy_options(opts)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Configure an http proxy to be used with this client instance. The &lt;code&gt;opts&lt;/code&gt; is a table that accepts the following fields:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;http_proxy&lt;/code&gt; - an URI to a proxy server to be used with http requests&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http_proxy_authorization&lt;/code&gt; - a default &lt;code&gt;Proxy-Authorization&lt;/code&gt; header value to be used with &lt;code&gt;http_proxy&lt;/code&gt;, e.g. &lt;code&gt;Basic ZGVtbzp0ZXN0&lt;/code&gt;, which will be overriden if the &lt;code&gt;Proxy-Authorization&lt;/code&gt; request header is present.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;https_proxy&lt;/code&gt; - an URI to a proxy server to be used with https requests&lt;/li&gt;
&lt;li&gt;&lt;code&gt;https_proxy_authorization&lt;/code&gt; - as &lt;code&gt;http_proxy_authorization&lt;/code&gt; but for use with &lt;code&gt;https_proxy&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;no_proxy&lt;/code&gt; - a comma separated list of hosts that should not be proxied.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that proxy options are only applied when using the high-level &lt;code&gt;request_uri()&lt;/code&gt; API.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-get_reused_times" class="anchor" aria-hidden="true" href="#get_reused_times"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;get_reused_times&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: times, err = httpc:get_reused_times()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This method returns the (successfully) reused times for the current connection. In case of error, it returns &lt;code&gt;nil&lt;/code&gt; and a string describing the error.&lt;/p&gt;
&lt;p&gt;If the current connection does not come from the built-in connection pool, then this method always returns &lt;code&gt;0&lt;/code&gt;, that is, the connection has never been reused (yet). If the connection comes from the connection pool, then the return value is always non-zero. So this method can also be used to determine if the current connection comes from the pool.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-close" class="anchor" aria-hidden="true" href="#close"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;close&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: ok, err = http:close()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Closes the current connection and returns the status.&lt;/p&gt;
&lt;p&gt;In case of success, returns &lt;code&gt;1&lt;/code&gt;. In case of errors, returns &lt;code&gt;nil&lt;/code&gt; with a string describing the error.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-requesting" class="anchor" aria-hidden="true" href="#requesting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requesting&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-request" class="anchor" aria-hidden="true" href="#request"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;request&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: res, err = httpc:request(params)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Returns a &lt;code&gt;res&lt;/code&gt; table or &lt;code&gt;nil&lt;/code&gt; and an error message.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;params&lt;/code&gt; table accepts the following fields:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;version&lt;/code&gt; The HTTP version number, currently supporting 1.0 or 1.1.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;method&lt;/code&gt; The HTTP method string.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;path&lt;/code&gt; The path string.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;query&lt;/code&gt; The query string, presented as either a literal string or Lua table..&lt;/li&gt;
&lt;li&gt;&lt;code&gt;headers&lt;/code&gt; A table of request headers.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;body&lt;/code&gt; The request body as a string, or an iterator function (see &lt;a href="#get_client_body_reader"&gt;get_client_body_reader&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ssl_verify&lt;/code&gt; Verify SSL cert matches hostname&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When the request is successful, &lt;code&gt;res&lt;/code&gt; will contain the following fields:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;status&lt;/code&gt; The status code.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reason&lt;/code&gt; The status reason phrase.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;headers&lt;/code&gt; A table of headers. Multiple headers with the same field name will be presented as a table of values.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;has_body&lt;/code&gt; A boolean flag indicating if there is a body to be read.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;body_reader&lt;/code&gt; An iterator function for reading the body in a streaming fashion.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;read_body&lt;/code&gt; A method to read the entire body into a string.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;read_trailers&lt;/code&gt; A method to merge any trailers underneath the headers, after reading the body.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-request_uri" class="anchor" aria-hidden="true" href="#request_uri"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;request_uri&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: res, err = httpc:request_uri(uri, params)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The simple interface. Options supplied in the &lt;code&gt;params&lt;/code&gt; table are the same as in the generic interface, and will override components found in the uri itself.&lt;/p&gt;
&lt;p&gt;There are 3 additional parameters for controlling keepalives:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;keepalive&lt;/code&gt; Set to &lt;code&gt;false&lt;/code&gt; to disable keepalives and immediately close the connection.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;keepalive_timeout&lt;/code&gt; The maximal idle timeout (ms). Defaults to &lt;code&gt;lua_socket_keepalive_timeout&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;keepalive_pool&lt;/code&gt; The maximum number of connections in the pool. Defaults to &lt;code&gt;lua_socket_pool_size&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this mode, there is no need to connect manually first. The connection is made on your behalf, suiting cases where you simply need to grab a URI without too much hassle.&lt;/p&gt;
&lt;p&gt;Additionally there is no ability to stream the response body in this mode. If the request is successful, &lt;code&gt;res&lt;/code&gt; will contain the following fields:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;status&lt;/code&gt; The status code.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;headers&lt;/code&gt; A table of headers.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;body&lt;/code&gt; The response body as a string.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-request_pipeline" class="anchor" aria-hidden="true" href="#request_pipeline"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;request_pipeline&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: responses, err = httpc:request_pipeline(params)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This method works as per the &lt;a href="#request"&gt;request&lt;/a&gt; method above, but &lt;code&gt;params&lt;/code&gt; is instead a table of param tables. Each request is sent in order, and &lt;code&gt;responses&lt;/code&gt; is returned as a table of response handles. For example:&lt;/p&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;local&lt;/span&gt; responses &lt;span class="pl-k"&gt;=&lt;/span&gt; httpc:&lt;span class="pl-c1"&gt;request_pipeline&lt;/span&gt;{
  {
    path &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/b&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
  },
  {
    path &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/c&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
  },
  {
    path &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/d&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
  }
}

&lt;span class="pl-k"&gt;for&lt;/span&gt; i,r &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;ipairs&lt;/span&gt;(responses) &lt;span class="pl-k"&gt;do&lt;/span&gt;
  &lt;span class="pl-k"&gt;if&lt;/span&gt; r.&lt;span class="pl-smi"&gt;status&lt;/span&gt; &lt;span class="pl-k"&gt;then&lt;/span&gt;
    ngx.&lt;span class="pl-c1"&gt;say&lt;/span&gt;(r.&lt;span class="pl-smi"&gt;status&lt;/span&gt;)
    ngx.&lt;span class="pl-c1"&gt;say&lt;/span&gt;(r:&lt;span class="pl-c1"&gt;read_body&lt;/span&gt;())
  &lt;span class="pl-k"&gt;end&lt;/span&gt;
&lt;span class="pl-k"&gt;end&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Due to the nature of pipelining, no responses are actually read until you attempt to use the response fields (status / headers etc). And since the responses are read off in order, you must read the entire body (and any trailers if you have them), before attempting to read the next response.&lt;/p&gt;
&lt;p&gt;Note this doesn't preclude the use of the streaming response body reader. Responses can still be streamed, so long as the entire body is streamed before attempting to access the next response.&lt;/p&gt;
&lt;p&gt;Be sure to test at least one field (such as status) before trying to use the others, in case a socket read error has occurred.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-response" class="anchor" aria-hidden="true" href="#response"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Response&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-resbody_reader" class="anchor" aria-hidden="true" href="#resbody_reader"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;res.body_reader&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;body_reader&lt;/code&gt; iterator can be used to stream the response body in chunk sizes of your choosing, as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;local&lt;/span&gt; reader &lt;span class="pl-k"&gt;=&lt;/span&gt; res.&lt;span class="pl-smi"&gt;body_reader&lt;/span&gt;

&lt;span class="pl-k"&gt;repeat&lt;/span&gt;
  &lt;span class="pl-k"&gt;local&lt;/span&gt; chunk, err &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;reader&lt;/span&gt;(&lt;span class="pl-c1"&gt;8192&lt;/span&gt;)
  &lt;span class="pl-k"&gt;if&lt;/span&gt; err &lt;span class="pl-k"&gt;then&lt;/span&gt;
    ngx.&lt;span class="pl-c1"&gt;log&lt;/span&gt;(ngx.&lt;span class="pl-smi"&gt;ERR&lt;/span&gt;, err)
    &lt;span class="pl-k"&gt;break&lt;/span&gt;
  &lt;span class="pl-k"&gt;end&lt;/span&gt;

  &lt;span class="pl-k"&gt;if&lt;/span&gt; chunk &lt;span class="pl-k"&gt;then&lt;/span&gt;
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;--&lt;/span&gt; process&lt;/span&gt;
  &lt;span class="pl-k"&gt;end&lt;/span&gt;
&lt;span class="pl-k"&gt;until&lt;/span&gt; &lt;span class="pl-k"&gt;not&lt;/span&gt; chunk&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If the reader is called with no arguments, the behaviour depends on the type of connection. If the response is encoded as chunked, then the iterator will return the chunks as they arrive. If not, it will simply return the entire body.&lt;/p&gt;
&lt;p&gt;Note that the size provided is actually a &lt;strong&gt;maximum&lt;/strong&gt; size. So in the chunked transfer case, you may get chunks smaller than the size you ask, as a remainder of the actual HTTP chunks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-resread_body" class="anchor" aria-hidden="true" href="#resread_body"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;res:read_body&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: body, err = res:read_body()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Reads the entire body into a local string.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-resread_trailers" class="anchor" aria-hidden="true" href="#resread_trailers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;res:read_trailers&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: res:read_trailers()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This merges any trailers underneath the &lt;code&gt;res.headers&lt;/code&gt; table itself. Must be called after reading the body.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-proxy" class="anchor" aria-hidden="true" href="#proxy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Proxy&lt;/h1&gt;
&lt;p&gt;There are two convenience methods for when one simply wishes to proxy the current request to the connected upstream, and safely send it downstream to the client, as a reverse proxy. A complete example:&lt;/p&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;local&lt;/span&gt; http &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;require&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;resty.http&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;local&lt;/span&gt; httpc &lt;span class="pl-k"&gt;=&lt;/span&gt; http.&lt;span class="pl-c1"&gt;new&lt;/span&gt;()

httpc:&lt;span class="pl-c1"&gt;set_timeout&lt;/span&gt;(&lt;span class="pl-c1"&gt;500&lt;/span&gt;)
&lt;span class="pl-k"&gt;local&lt;/span&gt; ok, err &lt;span class="pl-k"&gt;=&lt;/span&gt; httpc:&lt;span class="pl-c1"&gt;connect&lt;/span&gt;(HOST, PORT)

&lt;span class="pl-k"&gt;if&lt;/span&gt; &lt;span class="pl-k"&gt;not&lt;/span&gt; ok &lt;span class="pl-k"&gt;then&lt;/span&gt;
  ngx.&lt;span class="pl-c1"&gt;log&lt;/span&gt;(ngx.&lt;span class="pl-smi"&gt;ERR&lt;/span&gt;, err)
  &lt;span class="pl-k"&gt;return&lt;/span&gt;
&lt;span class="pl-k"&gt;end&lt;/span&gt;

httpc:&lt;span class="pl-c1"&gt;set_timeout&lt;/span&gt;(&lt;span class="pl-c1"&gt;2000&lt;/span&gt;)
httpc:&lt;span class="pl-c1"&gt;proxy_response&lt;/span&gt;(httpc:&lt;span class="pl-c1"&gt;proxy_request&lt;/span&gt;())
httpc:&lt;span class="pl-c1"&gt;set_keepalive&lt;/span&gt;()&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-proxy_request" class="anchor" aria-hidden="true" href="#proxy_request"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;proxy_request&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: local res, err = httpc:proxy_request(request_body_chunk_size?)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Performs a request using the current client request arguments, effectively proxying to the connected upstream. The request body will be read in a streaming fashion, according to &lt;code&gt;request_body_chunk_size&lt;/code&gt; (see &lt;a href="#get_client_body_reader"&gt;documentation on the client body reader&lt;/a&gt; below).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-proxy_response" class="anchor" aria-hidden="true" href="#proxy_response"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;proxy_response&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: httpc:proxy_response(res, chunksize?)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Sets the current response based on the given &lt;code&gt;res&lt;/code&gt;. Ensures that hop-by-hop headers are not sent downstream, and will read the response according to &lt;code&gt;chunksize&lt;/code&gt; (see &lt;a href="#resbody_reader"&gt;documentation on the body reader&lt;/a&gt; above).&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-utility" class="anchor" aria-hidden="true" href="#utility"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Utility&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-parse_uri" class="anchor" aria-hidden="true" href="#parse_uri"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;parse_uri&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: local scheme, host, port, path, query? = unpack(httpc:parse_uri(uri, query_in_path?))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This is a convenience function allowing one to more easily use the generic interface, when the input data is a URI.&lt;/p&gt;
&lt;p&gt;As of version &lt;code&gt;0.10&lt;/code&gt;, the optional &lt;code&gt;query_in_path&lt;/code&gt; parameter was added, which specifies whether the querystring is to be included in the &lt;code&gt;path&lt;/code&gt; return value, or separately as its own return value. This defaults to &lt;code&gt;true&lt;/code&gt; in order to maintain backwards compatibility. When set to &lt;code&gt;false&lt;/code&gt;, &lt;code&gt;path&lt;/code&gt; will only include the path, and &lt;code&gt;query&lt;/code&gt; will contain the URI args, not including the &lt;code&gt;?&lt;/code&gt; delimiter.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-get_client_body_reader" class="anchor" aria-hidden="true" href="#get_client_body_reader"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;get_client_body_reader&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;syntax: reader, err = httpc:get_client_body_reader(chunksize?, sock?)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Returns an iterator function which can be used to read the downstream client request body in a streaming fashion. You may also specify an optional default chunksize (default is &lt;code&gt;65536&lt;/code&gt;), or an already established socket in
place of the client request.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;local&lt;/span&gt; req_reader &lt;span class="pl-k"&gt;=&lt;/span&gt; httpc:&lt;span class="pl-c1"&gt;get_client_body_reader&lt;/span&gt;()

&lt;span class="pl-k"&gt;repeat&lt;/span&gt;
  &lt;span class="pl-k"&gt;local&lt;/span&gt; chunk, err &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;req_reader&lt;/span&gt;(&lt;span class="pl-c1"&gt;8192&lt;/span&gt;)
  &lt;span class="pl-k"&gt;if&lt;/span&gt; err &lt;span class="pl-k"&gt;then&lt;/span&gt;
    ngx.&lt;span class="pl-c1"&gt;log&lt;/span&gt;(ngx.&lt;span class="pl-smi"&gt;ERR&lt;/span&gt;, err)
    &lt;span class="pl-k"&gt;break&lt;/span&gt;
  &lt;span class="pl-k"&gt;end&lt;/span&gt;

  &lt;span class="pl-k"&gt;if&lt;/span&gt; chunk &lt;span class="pl-k"&gt;then&lt;/span&gt;
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;--&lt;/span&gt; process&lt;/span&gt;
  &lt;span class="pl-k"&gt;end&lt;/span&gt;
&lt;span class="pl-k"&gt;until&lt;/span&gt; &lt;span class="pl-k"&gt;not&lt;/span&gt; chunk&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This iterator can also be used as the value for the body field in request params, allowing one to stream the request body into a proxied upstream request.&lt;/p&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;local&lt;/span&gt; client_body_reader, err &lt;span class="pl-k"&gt;=&lt;/span&gt; httpc:&lt;span class="pl-c1"&gt;get_client_body_reader&lt;/span&gt;()

&lt;span class="pl-k"&gt;local&lt;/span&gt; res, err &lt;span class="pl-k"&gt;=&lt;/span&gt; httpc:&lt;span class="pl-c1"&gt;request&lt;/span&gt;{
   path &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/helloworld&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
   body &lt;span class="pl-k"&gt;=&lt;/span&gt; client_body_reader,
}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If &lt;code&gt;sock&lt;/code&gt; is specified,&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-author" class="anchor" aria-hidden="true" href="#author"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Author&lt;/h1&gt;
&lt;p&gt;James Hurst &lt;a href="mailto:james@pintsized.co.uk"&gt;james@pintsized.co.uk&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Originally started life based on &lt;a href="https://github.com/bakins/lua-resty-http-simple"&gt;https://github.com/bakins/lua-resty-http-simple&lt;/a&gt;. Cosocket docs and implementation borrowed from the other lua-resty-* cosocket modules.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-licence" class="anchor" aria-hidden="true" href="#licence"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Licence&lt;/h1&gt;
&lt;p&gt;This module is licensed under the 2-clause BSD license.&lt;/p&gt;
&lt;p&gt;Copyright (c) 2013-2016, James Hurst &lt;a href="mailto:james@pintsized.co.uk"&gt;james@pintsized.co.uk&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All rights reserved.&lt;/p&gt;
&lt;p&gt;Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ledgetech</author><guid isPermaLink="false">https://github.com/ledgetech/lua-resty-http</guid><pubDate>Fri, 08 Nov 2019 00:07:00 GMT</pubDate></item><item><title>DiscworldZA/gta-resources #8 in Lua, This week</title><link>https://github.com/DiscworldZA/gta-resources</link><description>&lt;p&gt;&lt;i&gt;All the DiscworldZA GTA Resources&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="readme.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Hi, my name is &lt;a href="https://twitter.com/DiscworldZA" rel="nofollow"&gt;DiscworldZA&lt;/a&gt;. I create GTA V mods for FiveM.&lt;/p&gt;
&lt;p&gt;I create mods while streaming. Give me a follow here for notifications &lt;a href="https://www.twitch.tv/DiscworldZA" rel="nofollow"&gt;Twitch&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is my repo for all the mods I create.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-feedback" class="anchor" aria-hidden="true" href="#feedback"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Feedback.&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Highly recommended&lt;/li&gt;
&lt;li&gt;Report Issues &lt;a href="https://github.com/DiscworldZA/gta-resources/issues"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Want a Mod or Feature? Request &lt;a href="https://github.com/DiscworldZA/gta-resources/issues"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Changelog &lt;a href="https://github.com/DiscworldZA/gta-resources/blob/master/changelog.md"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will create almost anything you can think of. Feel free to request it and I will see about creating it.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-configuration" class="anchor" aria-hidden="true" href="#configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuration&lt;/h1&gt;
&lt;p&gt;Most server owners are not developers but understand the basics. My mods are created highly configurable. Every location or price for the mods will be able to be configured. If you want more configuration options create an &lt;a href="https://github.com/DiscworldZA/gta-resources/issues"&gt;issue&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All ReadMe contains Configuration sections&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-explanation" class="anchor" aria-hidden="true" href="#explanation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Explanation&lt;/h1&gt;
&lt;p&gt;Most of my mods work with the &lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-base"&gt;Base&lt;/a&gt; mod and &lt;a href="https://github.com/ESX-Org/es_extended"&gt;ESX&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The reasoning behind this is to simplify my process and have all my mods up to the same standard and address bug fixing over the whole platform rather individual broken sections.
It is the same concept that &lt;a href="https://github.com/ESX-Org/es_extended"&gt;ESX&lt;/a&gt; works on but for all my needs.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-requirements-for-all-mods" class="anchor" aria-hidden="true" href="#requirements-for-all-mods"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements for all mods&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ESX-Org/es_extended"&gt;ESX&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mythicrp/mythic_notify"&gt;Mythic Notify&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ESX-Org/esx_addonaccount"&gt;ESX Add on Account&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-mod-list" class="anchor" aria-hidden="true" href="#mod-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Mod List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-base"&gt;Disc-Base&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-ammo"&gt;Disc-Ammo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-armory"&gt;Disc-Armory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-autorepair"&gt;Disc-AutoRepair&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-billing"&gt;Disc-Billing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-boot"&gt;Disc-Boot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-compensation"&gt;Disc-Compensation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-carthief"&gt;Disc-CarThief&lt;/a&gt; (my version of &lt;a href="https://github.com/KlibrDM/esx_carthief"&gt;esx_carthief&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-dragme"&gt;Disc-DragMe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-drugruns"&gt;Disc-DrugRuns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-drugsales"&gt;Disc-DrugSales&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-gcphone"&gt;Disc-GcPhone&lt;/a&gt; (add-on to &lt;a href="https://github.com/N3MTV/gcphone"&gt;gcphone&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-hotwire"&gt;Disc-HotWire&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-hud"&gt;Disc-HUD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-identification"&gt;Disc-Identification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-import"&gt;Disc-Import&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-inventoryhud"&gt;Disc-InventoryHUD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-jobcars"&gt;Disc-JobCars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-panic"&gt;Disc-Panic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-property"&gt;Disc-Property&lt;/a&gt; (BETA)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-showid"&gt;Disc-ShowId&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-social"&gt;Disc-Social&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-tax"&gt;Disc-Tax&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-teleport"&gt;Disc-Teleport&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-vehiclepick"&gt;Disc-VehiclePick&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-vehiclesales"&gt;Disc-VehicleSales&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-warrant"&gt;Disc-Warrant&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-ideas" class="anchor" aria-hidden="true" href="#ideas"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ideas&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;NPC Jobs (These are all mods to add depth to the ESX versions)
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-cops"&gt;Disc-Cops&lt;/a&gt; (WIP)&lt;/li&gt;
&lt;li&gt;Disc-EMS&lt;/li&gt;
&lt;li&gt;Disc-Mechanic&lt;/li&gt;
&lt;li&gt;Disc-CarSales&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Unique Garages&lt;/li&gt;
&lt;li&gt;Server Wide Robbery Mechanic&lt;/li&gt;
&lt;li&gt;Search Warrants for Disc-Properties via Disc-Warrants&lt;/li&gt;
&lt;li&gt;Automatic BOLO/Facial Detection&lt;/li&gt;
&lt;li&gt;Handheld Police and EMS devices&lt;/li&gt;
&lt;li&gt;Variable Drug Import and Selling (Allow Drug importing via ship or truck) (Allow Large shipments of drugs)&lt;/li&gt;
&lt;li&gt;Expanding EMS and Cop Procedure (Require documentation to be filed)&lt;/li&gt;
&lt;li&gt;Mechanic Repair Expansion&lt;/li&gt;
&lt;li&gt;Vehicle Shop Documentation (License and Registration)&lt;/li&gt;
&lt;li&gt;Cop Evidence Mechanic&lt;/li&gt;
&lt;li&gt;Judge Job (Allow search warrant authorization, Allow cases to be handled)&lt;/li&gt;
&lt;li&gt;Daily Login Reward System&lt;/li&gt;
&lt;li&gt;Vehicle Keys (Compatible With Hotwire)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h1&gt;
&lt;p&gt;Feel free to use my &lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-base"&gt;Base&lt;/a&gt; mod to create your own! Just credit me in some way. Share your mods you created with my base mod with me!&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-credit" class="anchor" aria-hidden="true" href="#credit"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credit&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Did I forget to credit you for your code?&lt;/li&gt;
&lt;li&gt;Am I using your code without permission?&lt;/li&gt;
&lt;li&gt;Do you want to use my code?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Message me on Discord. I will help you out.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-discord" class="anchor" aria-hidden="true" href="#discord"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Discord&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://discord.gg/S2SckF6" rel="nofollow"&gt;https://discord.gg/S2SckF6&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>DiscworldZA</author><guid isPermaLink="false">https://github.com/DiscworldZA/gta-resources</guid><pubDate>Fri, 08 Nov 2019 00:08:00 GMT</pubDate></item><item><title>jcjohnson/fast-neural-style #9 in Lua, This week</title><link>https://github.com/jcjohnson/fast-neural-style</link><description>&lt;p&gt;&lt;i&gt;Feedforward style transfer&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-fast-neural-style" class="anchor" aria-hidden="true" href="#fast-neural-style"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;fast-neural-style&lt;/h1&gt;
&lt;p&gt;This is the code for the paper&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="http://cs.stanford.edu/people/jcjohns/eccv16/" rel="nofollow"&gt;Perceptual Losses for Real-Time Style Transfer and Super-Resolution&lt;/a&gt;&lt;/strong&gt;
&lt;br&gt;
&lt;a href="http://cs.stanford.edu/people/jcjohns/" rel="nofollow"&gt;Justin Johnson&lt;/a&gt;,
&lt;a href="http://web.stanford.edu/~alahi/" rel="nofollow"&gt;Alexandre Alahi&lt;/a&gt;,
&lt;a href="http://vision.stanford.edu/feifeili/" rel="nofollow"&gt;Li Fei-Fei&lt;/a&gt;
&lt;br&gt;
Presented at &lt;a href="http://www.eccv2016.org/" rel="nofollow"&gt;ECCV 2016&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The paper builds on
&lt;a href="https://arxiv.org/abs/1508.06576" rel="nofollow"&gt;A Neural Algorithm of Artistic Style&lt;/a&gt;
by Leon A. Gatys, Alexander S. Ecker, and Matthias Bethge by training
feedforward neural networks that apply artistic styles to images.
After training, our feedforward networks can stylize images
&lt;strong&gt;hundreds of times faster&lt;/strong&gt; than the optimization-based method presented
by Gatys et al.&lt;/p&gt;
&lt;p&gt;This repository also includes an implementation of instance normalization as
described in the paper &lt;a href="https://arxiv.org/abs/1607.08022" rel="nofollow"&gt;Instance Normalization: The Missing Ingredient for Fast Stylization&lt;/a&gt;
by Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. This simple trick
significantly improves the quality of feedforward style transfer models.&lt;/p&gt;
&lt;p&gt;Stylizing this image of the Stanford campus at a resolution of 1200x630
takes &lt;strong&gt;50 milliseconds&lt;/strong&gt; on a Pascal Titan X:&lt;/p&gt;
&lt;div align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/styles/candy.jpg"&gt;&lt;img src="images/styles/candy.jpg" height="225px" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/content/hoovertowernight.jpg"&gt;&lt;img src="images/content/hoovertowernight.jpg" height="225px" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/outputs/hoovertowernight_candy.jpg"&gt;&lt;img src="images/outputs/hoovertowernight_candy.jpg" height="346px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;In this repository we provide:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The style transfer models &lt;a href="#models-from-the-paper"&gt;used in the paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Additional models &lt;a href="#models-with-instance-normalization"&gt;using instance normalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code for &lt;a href="#running-on-new-images"&gt;running models on new images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A demo that runs models in &lt;a href="#webcam-demo"&gt;real-time off a webcam&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code for &lt;a href="doc/training.md"&gt;training new feedforward style transfer models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;An implementation of &lt;a href="#optimization-based-style-transfer"&gt;optimization-based style transfer&lt;/a&gt;
method described by Gatys et al.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you find this code useful for your research, please cite&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@inproceedings{Johnson2016Perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={European Conference on Computer Vision},
  year={2016}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h2&gt;
&lt;p&gt;All code is implemented in &lt;a href="http://torch.ch/" rel="nofollow"&gt;Torch&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First &lt;a href="http://torch.ch/docs/getting-started.html#installing-torch" rel="nofollow"&gt;install Torch&lt;/a&gt;, then
update / install the following packages:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;luarocks install torch
luarocks install nn
luarocks install image
luarocks install lua-cjson&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-optional-gpu-acceleration" class="anchor" aria-hidden="true" href="#optional-gpu-acceleration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;(Optional) GPU Acceleration&lt;/h3&gt;
&lt;p&gt;If you have an NVIDIA GPU, you can accelerate all operations with CUDA.&lt;/p&gt;
&lt;p&gt;First &lt;a href="https://developer.nvidia.com/cuda-downloads" rel="nofollow"&gt;install CUDA&lt;/a&gt;, then
update / install the following packages:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;luarocks install cutorch
luarocks install cunn&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-optional-cudnn" class="anchor" aria-hidden="true" href="#optional-cudnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;(Optional) cuDNN&lt;/h3&gt;
&lt;p&gt;When using CUDA, you can use cuDNN to accelerate convolutions.&lt;/p&gt;
&lt;p&gt;First &lt;a href="https://developer.nvidia.com/cudnn" rel="nofollow"&gt;download cuDNN&lt;/a&gt; and copy the
libraries to &lt;code&gt;/usr/local/cuda/lib64/&lt;/code&gt;. Then install the Torch bindings for cuDNN:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;luarocks install cudnn&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-pretrained-models" class="anchor" aria-hidden="true" href="#pretrained-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pretrained Models&lt;/h3&gt;
&lt;p&gt;Download all pretrained style transfer models by running the script&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bash models/download_style_transfer_models.sh&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will download ten model files (~200MB) to the folder &lt;code&gt;models/&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-models-from-the-paper" class="anchor" aria-hidden="true" href="#models-from-the-paper"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Models from the paper&lt;/h2&gt;
&lt;p&gt;The style transfer models we used in the paper will be located in the folder &lt;code&gt;models/eccv16&lt;/code&gt;.
Here are some example results where we use these models to stylize this
image of the Chicago skyline with at an image size of 512:&lt;/p&gt;
&lt;div align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/content/chicago.jpg"&gt;&lt;img src="images/content/chicago.jpg" height="185px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/styles/starry_night_crop.jpg"&gt;&lt;img src="images/styles/starry_night_crop.jpg" height="155px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/styles/la_muse.jpg"&gt;&lt;img src="images/styles/la_muse.jpg" height="155px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/styles/composition_vii.jpg"&gt;&lt;img src="images/styles/composition_vii.jpg" height="155px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/styles/wave_crop.jpg"&gt;&lt;img src="images/styles/wave_crop.jpg" height="155px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/outputs/eccv16/chicago_starry_night.jpg"&gt;&lt;img src="images/outputs/eccv16/chicago_starry_night.jpg" height="142px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/outputs/eccv16/chicago_la_muse.jpg"&gt;&lt;img src="images/outputs/eccv16/chicago_la_muse.jpg" height="142px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/outputs/eccv16/chicago_composition_vii.jpg"&gt;&lt;img src="images/outputs/eccv16/chicago_composition_vii.jpg" height="142px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/outputs/eccv16/chicago_wave.jpg"&gt;&lt;img src="images/outputs/eccv16/chicago_wave.jpg" height="142px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-models-with-instance-normalization" class="anchor" aria-hidden="true" href="#models-with-instance-normalization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Models with instance normalization&lt;/h2&gt;
&lt;p&gt;As discussed in the paper
&lt;a href="https://arxiv.org/abs/1607.08022" rel="nofollow"&gt;Instance Normalization: The Missing Ingredient for Fast Stylization&lt;/a&gt;
by Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky, replacing batch
normalization with instance normalization significantly improves the quality
of feedforward style transfer models.&lt;/p&gt;
&lt;p&gt;We have trained several models with instance normalization; after downloading
pretrained models they will be in the folder &lt;code&gt;models/instance_norm&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;These models use the same architecture as those used in our paper, except with
half the number of filters per layer and with instance normalization instead of
batch normalization. Using narrower layers makes the models smaller and faster
without sacrificing model quality.&lt;/p&gt;
&lt;p&gt;Here are some example outputs from these models, with an image size of 1024:&lt;/p&gt;
&lt;div align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/styles/candy.jpg"&gt;&lt;img src="images/styles/candy.jpg" height="174px" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/outputs/chicago_candy.jpg"&gt;&lt;img src="images/outputs/chicago_candy.jpg" height="174px" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/outputs/chicago_udnie.jpg"&gt;&lt;img src="images/outputs/chicago_udnie.jpg" height="174px" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/styles/udnie.jpg"&gt;&lt;img src="images/styles/udnie.jpg" height="174px" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/styles/the_scream.jpg"&gt;&lt;img src="images/styles/the_scream.jpg" height="174px" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/outputs/chicago_scream.jpg"&gt;&lt;img src="images/outputs/chicago_scream.jpg" height="174px" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/outputs/chicago_mosaic.jpg"&gt;&lt;img src="images/outputs/chicago_mosaic.jpg" height="174px" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/styles/mosaic.jpg"&gt;&lt;img src="images/styles/mosaic.jpg" height="174px" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/styles/feathers.jpg"&gt;&lt;img src="images/styles/feathers.jpg" height="173px" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/outputs/chicago_feathers.jpg"&gt;&lt;img src="images/outputs/chicago_feathers.jpg" height="173px" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/outputs/chicago_muse.jpg"&gt;&lt;img src="images/outputs/chicago_muse.jpg" height="173px" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/styles/la_muse.jpg"&gt;&lt;img src="images/styles/la_muse.jpg" height="173px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-running-on-new-images" class="anchor" aria-hidden="true" href="#running-on-new-images"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running on new images&lt;/h2&gt;
&lt;p&gt;The script &lt;code&gt;fast_neural_style.lua&lt;/code&gt; lets you use a trained model to stylize new images:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;th fast_neural_style.lua \
  -model models/eccv16/starry_night.t7 \
  -input_image images/content/chicago.jpg \
  -output_image out.png&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can run the same model on an entire directory of images like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;th fast_neural_style.lua \
  -model models/eccv16/starry_night.t7 \
  -input_dir images/content/ \
  -output_dir out/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can control the size of the output images using the &lt;code&gt;-image_size&lt;/code&gt; flag.&lt;/p&gt;
&lt;p&gt;By default this script runs on CPU; to run on GPU, add the flag &lt;code&gt;-gpu&lt;/code&gt;
specifying the GPU on which to run.&lt;/p&gt;
&lt;p&gt;The full set of options for this script is &lt;a href="doc/flags.md#fast_neural_stylelua"&gt;described here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-webcam-demo" class="anchor" aria-hidden="true" href="#webcam-demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Webcam demo&lt;/h2&gt;
&lt;p&gt;You can use the script &lt;code&gt;webcam_demo.lua&lt;/code&gt; to run one or more models in real-time
off a webcam stream. To run this demo you need to use &lt;code&gt;qlua&lt;/code&gt; instead of &lt;code&gt;th&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;qlua webcam_demo.lua -models models/instance_norm/candy.t7 -gpu 0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can run multiple models at the same time by passing a comma-separated list
to the &lt;code&gt;-models&lt;/code&gt; flag:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;qlua webcam_demo.lua \
  -models models/instance_norm/candy.t7,models/instance_norm/udnie.t7 \
  -gpu 0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With a Pascal Titan X you can easily run four models in realtime at 640x480:&lt;/p&gt;
&lt;div align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="images/webcam.gif"&gt;&lt;img src="images/webcam.gif" width="700px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;The webcam demo depends on a few extra Lua packages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/clementfarabet/lua---camera"&gt;clementfarabet/lua---camera&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/torch/qtlua"&gt;torch/qtlua&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can install / update these packages by running:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;luarocks install camera
luarocks install qtlua&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The full set of options for this script is &lt;a href="doc/flags.md#webcam_demolua"&gt;described here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-training-new-models" class="anchor" aria-hidden="true" href="#training-new-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training new models&lt;/h2&gt;
&lt;p&gt;You can &lt;a href="doc/training.md"&gt;find instructions for training new models here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-optimization-based-style-transfer" class="anchor" aria-hidden="true" href="#optimization-based-style-transfer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Optimization-based Style Transfer&lt;/h2&gt;
&lt;p&gt;The script &lt;code&gt;slow_neural_style.lua&lt;/code&gt; is similar to the
&lt;a href="https://github.com/jcjohnson/neural-style"&gt;original neural-style&lt;/a&gt;, and uses
the optimization-based style-transfer method described by Gatys et al.&lt;/p&gt;
&lt;p&gt;This script uses the same code for computing losses as the feedforward training
script, allowing for fair comparisons between feedforward style transfer networks
and optimization-based style transfer.&lt;/p&gt;
&lt;p&gt;Compared to the original &lt;a href="https://github.com/jcjohnson/neural-style"&gt;neural-style&lt;/a&gt;,
this script has the following improvements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Remove dependency on protobuf and &lt;a href="https://github.com/szagoruyko/loadcaffe"&gt;loadcaffe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support for many more CNN architectures, including ResNets&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The full set of options for this script is &lt;a href="doc/flags.md#slow_neural_stylelua"&gt;described here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Free for personal or research use; for commercial use please contact me.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jcjohnson</author><guid isPermaLink="false">https://github.com/jcjohnson/fast-neural-style</guid><pubDate>Fri, 08 Nov 2019 00:09:00 GMT</pubDate></item><item><title>cmusatyalab/openface #10 in Lua, This week</title><link>https://github.com/cmusatyalab/openface</link><description>&lt;p&gt;&lt;i&gt;Face recognition with deep neural networks.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-openface-----" class="anchor" aria-hidden="true" href="#openface-----"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;OpenFace • &lt;a href="http://travis-ci.org/cmusatyalab/openface" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/7649857bc22a4061aea8a38706cc64b6bca51e45/68747470733a2f2f7472617669732d63692e6f72672f636d7573617479616c61622f6f70656e666163652e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/cmusatyalab/openface.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://github.com/cmusatyalab/openface/releases"&gt;&lt;img src="https://camo.githubusercontent.com/009f288da0baa589849c22cdbc1185bfeaf924ab/687474703a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d302e322e312d626c75652e7376673f7374796c653d666c6174" alt="Release" data-canonical-src="http://img.shields.io/badge/release-0.2.1-blue.svg?style=flat" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/0257a158db7f15a3a2b76dfd75be916fda130867/687474703a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4170616368652d2d322d626c75652e7376673f7374796c653d666c6174" alt="License" data-canonical-src="http://img.shields.io/badge/license-Apache--2-blue.svg?style=flat" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://gitter.im/cmusatyalab/openface" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Free and open source face recognition with
deep neural networks.&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;Website: &lt;a href="http://cmusatyalab.github.io/openface/" rel="nofollow"&gt;http://cmusatyalab.github.io/openface/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://openface-api.readthedocs.org/en/latest/index.html" rel="nofollow"&gt;API Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Join the
&lt;a href="https://groups.google.com/forum/#!forum/cmu-openface" rel="nofollow"&gt;cmu-openface group&lt;/a&gt;
or the
&lt;a href="https://gitter.im/cmusatyalab/openface" rel="nofollow"&gt;gitter chat&lt;/a&gt;
for discussions and installation issues.&lt;/li&gt;
&lt;li&gt;Development discussions and bugs reports are on the
&lt;a href="https://github.com/cmusatyalab/openface/issues"&gt;issue tracker&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;This research was supported by the National Science Foundation (NSF)
under grant number CNS-1518865.  Additional support
was provided by the Intel Corporation, Google, Vodafone, NVIDIA, and the
Conklin Kistler family fund.  Any opinions, findings, conclusions or
recommendations expressed in this material are those of the authors
and should not be attributed to their employers or funding sources.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-whats-in-this-repository" class="anchor" aria-hidden="true" href="#whats-in-this-repository"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What's in this repository?&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/batch-represent"&gt;batch-represent&lt;/a&gt;: Generate representations from
a batch of images. &lt;a href="https://gist.github.com/bamos/f03037f5df7e05ad0cc8"&gt;Example directory structure.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/demos/web"&gt;demos/web&lt;/a&gt;: Real-time web demo.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/demos/compare.py"&gt;demos/compare.py&lt;/a&gt;: Demo to compare two images.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/demos/vis-outputs.lua"&gt;demos/vis-outputs.lua&lt;/a&gt;: Demo to
visualize the network's outputs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/demos/classifier.py"&gt;demos/classifier.py&lt;/a&gt;: Demo to train and use classifiers.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/blob/master/demos/classifier_webcam.py"&gt;demos/classifier_webcam.py&lt;/a&gt;: Demo to use a trained classifier on a webcam stream.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/blob/master/evaluation"&gt;evaluation&lt;/a&gt;: LFW accuracy evaluation scripts.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/openface"&gt;openface&lt;/a&gt;: Python library code.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/models"&gt;models&lt;/a&gt;: Model directory for openface and 3rd party libraries.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/tests"&gt;tests&lt;/a&gt;: Tests for scripts and library code, including neural network training.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/training"&gt;training&lt;/a&gt;: Scripts to train new OpenFace neural network models.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cmusatyalab/openface/tree/master/util"&gt;util&lt;/a&gt;: Utility scripts.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-citations" class="anchor" aria-hidden="true" href="#citations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citations&lt;/h1&gt;
&lt;p&gt;Please cite OpenFace in your publications if it helps your research.
The following is a &lt;a href="http://www.bibtex.org/" rel="nofollow"&gt;BibTeX&lt;/a&gt; and plaintext reference for our
&lt;a href="http://reports-archive.adm.cs.cmu.edu/anon/anon/2016/CMU-CS-16-118.pdf" rel="nofollow"&gt;OpenFace tech report&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@techreport{amos2016openface,
  title={OpenFace: A general-purpose face recognition
    library with mobile applications},
  author={Amos, Brandon and Bartosz Ludwiczuk and Satyanarayanan, Mahadev},
  year={2016},
  institution={CMU-CS-16-118, CMU School of Computer Science},
}

B. Amos, B. Ludwiczuk, M. Satyanarayanan,
"Openface: A general-purpose face recognition library with mobile applications,"
CMU-CS-16-118, CMU School of Computer Science, Tech. Rep., 2016.
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;&lt;a id="user-content-licensing" class="anchor" aria-hidden="true" href="#licensing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Licensing&lt;/h1&gt;
&lt;p&gt;Unless otherwise stated, the source code and trained Torch and Python
model files are copyright Carnegie Mellon University and licensed
under the &lt;a href="./LICENSE"&gt;Apache 2.0 License&lt;/a&gt;.
Portions from the following third party sources have
been modified and are included in this repository.
These portions are noted in the source files and are
copyright their respective authors with
the licenses listed.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Project&lt;/th&gt;
&lt;th&gt;Modified&lt;/th&gt;
&lt;th&gt;License&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/Atcold/torch-TripletEmbedding"&gt;Atcold/torch-TripletEmbedding&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;MIT&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/facebook/fbnn"&gt;facebook/fbnn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;BSD&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>cmusatyalab</author><guid isPermaLink="false">https://github.com/cmusatyalab/openface</guid><pubDate>Fri, 08 Nov 2019 00:10:00 GMT</pubDate></item><item><title>ESX-Org/es_extended #11 in Lua, This week</title><link>https://github.com/ESX-Org/es_extended</link><description>&lt;p&gt;&lt;i&gt;ES Extended Core&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-es_extended" class="anchor" aria-hidden="true" href="#es_extended"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;es_extended&lt;/h1&gt;
&lt;p&gt;es_extended is a roleplay framework for FiveM. It is developed on top of EssentialMode (aka ES), thus commonly named ESX - the &lt;strong&gt;Es&lt;/strong&gt;sentialMode E&lt;strong&gt;x&lt;/strong&gt;tended framework for FiveM.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-links--read-more" class="anchor" aria-hidden="true" href="#links--read-more"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Links &amp;amp; Read more&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://esx-org.github.io/" rel="nofollow"&gt;ESX Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://discord.gg/MsWzPqE" rel="nofollow"&gt;ESX Discord Community&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://forum.fivem.net/t/release-esx-base/39881" rel="nofollow"&gt;FiveM Forum Thread&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://runtime.fivem.net/doc/reference.html" rel="nofollow"&gt;FiveM Native Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-screenshot-preview-todo" class="anchor" aria-hidden="true" href="#screenshot-preview-todo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Screenshot preview (todo)&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/480e11d5b6e7b9b15db422d7939c20d44c880bf3/687474703a2f2f692e696d6775722e636f6d2f615046644a6c332e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/480e11d5b6e7b9b15db422d7939c20d44c880bf3/687474703a2f2f692e696d6775722e636f6d2f615046644a6c332e6a7067" alt="screenshot" data-canonical-src="http://i.imgur.com/aPFdJl3.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Accounts (comes with bank / black money), you can add more accounts&lt;/li&gt;
&lt;li&gt;Advanced inventory system (press &lt;code&gt;F2&lt;/code&gt; ingame)&lt;/li&gt;
&lt;li&gt;Job system&lt;/li&gt;
&lt;li&gt;Loadouts and position synced in database&lt;/li&gt;
&lt;li&gt;The best framework out there for RP servers&lt;/li&gt;
&lt;li&gt;i18n (locale) system&lt;/li&gt;
&lt;li&gt;Plenty of plugins available&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h3&gt;
&lt;p&gt;This order also applies in the startup order.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/brouznouf/fivem-mysql-async"&gt;mysql-async&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kanersps/essentialmode"&gt;essentialmode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kanersps/esplugin_mysql"&gt;esplugin_mysql&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ESX-Org/async"&gt;async&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-download--installation" class="anchor" aria-hidden="true" href="#download--installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Download &amp;amp; Installation&lt;/h3&gt;
&lt;h3&gt;&lt;a id="user-content-using-fvm" class="anchor" aria-hidden="true" href="#using-fvm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using &lt;a href="https://github.com/qlaffont/fvm-installer"&gt;fvm&lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;fvm install --save --folder=essential esx-org/es_extended
fvm install --save --folder=esx esx-org/esx_menu_default
fvm install --save --folder=esx esx-org/esx_menu_dialog
fvm install --save --folder=esx esx-org/esx_menu_list
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-using-git" class="anchor" aria-hidden="true" href="#using-git"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using Git&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;cd resources
git clone https://github.com/ESX-Org/es_extended [essential]/es_extended
git clone https://github.com/ESX-Org/esx_menu_default [esx]/[ui]/esx_menu_default
git clone https://github.com/ESX-Org/esx_menu_dialog [esx]/[ui]/esx_menu_dialog
git clone https://github.com/ESX-Org/esx_menu_list [esx]/[ui]/esx_menu_list
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-manually" class="anchor" aria-hidden="true" href="#manually"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Manually&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Download &lt;a href="https://github.com/ESX-Org/es_extended/releases/latest"&gt;https://github.com/ESX-Org/es_extended/releases/latest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Put it in the &lt;code&gt;resource/[essential]&lt;/code&gt; directory&lt;/li&gt;
&lt;li&gt;Download &lt;a href="https://github.com/ESX-Org/esx_menu_default/releases/latest"&gt;https://github.com/ESX-Org/esx_menu_default/releases/latest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Put it in the &lt;code&gt;resource/[esx]/[ui]&lt;/code&gt; directory&lt;/li&gt;
&lt;li&gt;Download &lt;a href="https://github.com/ESX-Org/esx_menu_dialog/releases/latest"&gt;https://github.com/ESX-Org/esx_menu_dialog/releases/latest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Put it in the &lt;code&gt;resource/[esx]/[ui]&lt;/code&gt; directory&lt;/li&gt;
&lt;li&gt;Download &lt;a href="https://github.com/ESX-Org/esx_menu_list/releases/latest"&gt;https://github.com/ESX-Org/esx_menu_list/releases/latest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Put it in the &lt;code&gt;resource/[esx]/[ui]&lt;/code&gt; directory&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Import &lt;code&gt;es_extended.sql&lt;/code&gt; in your database&lt;/li&gt;
&lt;li&gt;Configure your &lt;code&gt;server.cfg&lt;/code&gt; to look like this&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;start mysql-async
start essentialmode
start esplugin_mysql

start es_extended

start esx_menu_default
start esx_menu_list
start esx_menu_dialog
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;&lt;a id="user-content-legal" class="anchor" aria-hidden="true" href="#legal"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Legal&lt;/h1&gt;
&lt;h3&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h3&gt;
&lt;p&gt;es_extended - EssentialMode Extended framework for FiveM&lt;/p&gt;
&lt;p&gt;Copyright (C) 2015-2019 Jérémie N'gadi&lt;/p&gt;
&lt;p&gt;This program Is free software: you can redistribute it And/Or modify it under the terms Of the GNU General Public License As published by the Free Software Foundation, either version 3 Of the License, Or (at your option) any later version.&lt;/p&gt;
&lt;p&gt;This program Is distributed In the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty Of MERCHANTABILITY Or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License For more details.&lt;/p&gt;
&lt;p&gt;You should have received a copy Of the GNU General Public License along with this program. If Not, see &lt;a href="http://www.gnu.org/licenses/" rel="nofollow"&gt;http://www.gnu.org/licenses/&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ESX-Org</author><guid isPermaLink="false">https://github.com/ESX-Org/es_extended</guid><pubDate>Fri, 08 Nov 2019 00:11:00 GMT</pubDate></item><item><title>scipag/vulscan #12 in Lua, This week</title><link>https://github.com/scipag/vulscan</link><description>&lt;p&gt;&lt;i&gt;Advanced vulnerability scanning with Nmap NSE&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-vulscan---vulnerability-scanning-with-nmap" class="anchor" aria-hidden="true" href="#vulscan---vulnerability-scanning-with-nmap"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;vulscan - Vulnerability Scanning with Nmap&lt;/h1&gt;
&lt;p align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="./logo.png"&gt;&lt;img src="./logo.png" width="300px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Vulscan is a module which enhances nmap to a vulnerability scanner. The nmap option -sV enables version detection per service which is used to determine potential flaws according to the identified product. The data is looked up in an offline version of VulDB.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/adfe9553aae81ff9994c8c85cf04a21026d762ec/68747470733a2f2f7777772e636f6d70757465632e63682f70726f6a656b74652f76756c7363616e2f696e74726f64756374696f6e2f73637265656e73686f742e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/adfe9553aae81ff9994c8c85cf04a21026d762ec/68747470733a2f2f7777772e636f6d70757465632e63682f70726f6a656b74652f76756c7363616e2f696e74726f64756374696f6e2f73637265656e73686f742e706e67" alt="Nmap NSE Vulscan" data-canonical-src="https://www.computec.ch/projekte/vulscan/introduction/screenshot.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;Please install the files into the following folder of your Nmap installation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Nmap\scripts\vulscan\*
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clone the GitHub repository like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/scipag/vulscan scipag_vulscan
ln -s `pwd`/scipag_vulscan /usr/share/nmap/scripts/vulscan    
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;p&gt;You have to run the following minimal command to initiate a simple vulnerability scan:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nmap -sV --script=vulscan/vulscan.nse www.example.com
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-vulnerability-database" class="anchor" aria-hidden="true" href="#vulnerability-database"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Vulnerability Database&lt;/h2&gt;
&lt;p&gt;There are the following pre-installed databases available at the moment:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;scipvuldb.csv - &lt;a href="https://vuldb.com" rel="nofollow"&gt;https://vuldb.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;cve.csv - &lt;a href="https://cve.mitre.org" rel="nofollow"&gt;https://cve.mitre.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;securityfocus.csv - &lt;a href="https://www.securityfocus.com/bid/" rel="nofollow"&gt;https://www.securityfocus.com/bid/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;xforce.csv - &lt;a href="https://exchange.xforce.ibmcloud.com/" rel="nofollow"&gt;https://exchange.xforce.ibmcloud.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;expliotdb.csv - &lt;a href="https://www.exploit-db.com" rel="nofollow"&gt;https://www.exploit-db.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;openvas.csv - &lt;a href="http://www.openvas.org" rel="nofollow"&gt;http://www.openvas.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;securitytracker.csv - &lt;a href="https://www.securitytracker.com" rel="nofollow"&gt;https://www.securitytracker.com&lt;/a&gt; (end-of-life)&lt;/li&gt;
&lt;li&gt;osvdb.csv - &lt;a href="http://www.osvdb.org" rel="nofollow"&gt;http://www.osvdb.org&lt;/a&gt; (end-of-life)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-single-database-mode" class="anchor" aria-hidden="true" href="#single-database-mode"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Single Database Mode&lt;/h2&gt;
&lt;p&gt;You may execute vulscan with the following argument to use a single database:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--script-args vulscandb=your_own_database
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is also possible to create and reference your own databases. This requires to create a database file, which has the following structure:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;id&amp;gt;;&amp;lt;title&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just execute vulscan like you would by refering to one of the pre-delivered databases. Feel free to share your own database and vulnerability connection with me, to add it to the official repository.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-update-database" class="anchor" aria-hidden="true" href="#update-database"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Update Database&lt;/h2&gt;
&lt;p&gt;The vulnerability databases are updated and assembled on a regularly basis. To support the latest disclosed vulnerabilities, keep your local vulnerability databases up-to-date.&lt;/p&gt;
&lt;p&gt;If you want to update your databases, go to the following web site and download these files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.computec.ch/projekte/vulscan/download/cve.csv" rel="nofollow"&gt;https://www.computec.ch/projekte/vulscan/download/cve.csv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.computec.ch/projekte/vulscan/download/exploitdb.csv" rel="nofollow"&gt;https://www.computec.ch/projekte/vulscan/download/exploitdb.csv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.computec.ch/projekte/vulscan/download/openvas.csv" rel="nofollow"&gt;https://www.computec.ch/projekte/vulscan/download/openvas.csv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.computec.ch/projekte/vulscan/download/osvdb.csv" rel="nofollow"&gt;https://www.computec.ch/projekte/vulscan/download/osvdb.csv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.computec.ch/projekte/vulscan/download/scipvuldb.csv" rel="nofollow"&gt;https://www.computec.ch/projekte/vulscan/download/scipvuldb.csv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.computec.ch/projekte/vulscan/download/securityfocus.csv" rel="nofollow"&gt;https://www.computec.ch/projekte/vulscan/download/securityfocus.csv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.computec.ch/projekte/vulscan/download/securitytracker.csv" rel="nofollow"&gt;https://www.computec.ch/projekte/vulscan/download/securitytracker.csv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.computec.ch/projekte/vulscan/download/xforce.csv" rel="nofollow"&gt;https://www.computec.ch/projekte/vulscan/download/xforce.csv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Copy the files into your vulscan folder:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/vulscan/
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-version-detection" class="anchor" aria-hidden="true" href="#version-detection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Version Detection&lt;/h2&gt;
&lt;p&gt;If the version detection was able to identify the software version and the vulnerability database is providing such details, also this data is matched.&lt;/p&gt;
&lt;p&gt;Disabling this feature might introduce false-positive but might also eliminate false-negatives and increase performance slighty. If you want to disable additional version matching, use the following argument:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--script-args vulscanversiondetection=0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Version detection of vulscan is only as good as Nmap version detection and the vulnerability database entries are. Some databases do not provide conclusive version information, which may lead to a lot of false-positives (as can be seen for Apache servers).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-match-priority" class="anchor" aria-hidden="true" href="#match-priority"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Match Priority&lt;/h2&gt;
&lt;p&gt;The script is trying to identify the best matches only. If no positive match could been found, the best possible match (with might be a false-positive) is put on display.&lt;/p&gt;
&lt;p&gt;If you want to show all matches, which might introduce a lot of false-positives but might be useful for further investigation, use the following argument:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--script-args vulscanshowall=1
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-interactive-mode" class="anchor" aria-hidden="true" href="#interactive-mode"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive Mode&lt;/h2&gt;
&lt;p&gt;The interactive mode helps you to override version detection results for every port. Use the following argument to enable the interactive mode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--script-args vulscaninteractive=1
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-reporting" class="anchor" aria-hidden="true" href="#reporting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reporting&lt;/h2&gt;
&lt;p&gt;All matching results are printed one by line. The default layout for this is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[{id}] {title}\n
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is possible to use another pre-defined report structure with the following argument:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--script-args vulscanoutput=details
--script-args vulscanoutput=listid
--script-args vulscanoutput=listlink
--script-args vulscanoutput=listtitle
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may enforce your own report structure by using the following argument (some examples):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--script-args vulscanoutput='{link}\n{title}\n\n'
--script-args vulscanoutput='ID: {id} - Title: {title} ({matches})\n'
--script-args vulscanoutput='{id} | {product} | {version}\n'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Supported are the following elements for a dynamic report template:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;{id} - ID of the vulnerability&lt;/li&gt;
&lt;li&gt;{title} - Title of the vulnerability&lt;/li&gt;
&lt;li&gt;{matches} - Count of matches&lt;/li&gt;
&lt;li&gt;{product} - Matched product string(s)&lt;/li&gt;
&lt;li&gt;{version} - Matched version string(s)&lt;/li&gt;
&lt;li&gt;{link} - Link to the vulnerability database entry&lt;/li&gt;
&lt;li&gt;\n - Newline&lt;/li&gt;
&lt;li&gt;\t - Tab&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Every default database comes with an url and a link, which is used during the scanning and might be accessed as {link} within the customized report template. To use custom database links, use the following argument:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--script-args "vulscandblink=http://example.org/{id}"
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;Keep in mind that this kind of derivative vulnerability scanning heavily relies on the confidence of the version detection of nmap, the amount of documented vulnerabilities and the accuracy of pattern matching. The existence of potential flaws is not verified with additional scanning nor exploiting techniques.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>scipag</author><guid isPermaLink="false">https://github.com/scipag/vulscan</guid><pubDate>Fri, 08 Nov 2019 00:12:00 GMT</pubDate></item><item><title>ilovecookieee/Glorious-Dotfiles #13 in Lua, This week</title><link>https://github.com/ilovecookieee/Glorious-Dotfiles</link><description>&lt;p&gt;&lt;i&gt;A glorified stolen dot files&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;div align="center"&gt;
    &lt;h1&gt;&lt;a id="user-content-glorious-dotfiles" class="anchor" aria-hidden="true" href="#glorious-dotfiles"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Glorious Dotfiles&lt;/h1&gt;
    &lt;p&gt;There's no place like &lt;b&gt;&lt;code&gt;~&lt;/code&gt;&lt;/b&gt; !&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-details" class="anchor" aria-hidden="true" href="#details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Details&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;OS&lt;/strong&gt;: I use Arch, btw&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WM&lt;/strong&gt;: AwesomeWM&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Terminal Emulators&lt;/strong&gt;: kitty, urxvt-pixbuf, xterm&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compositor&lt;/strong&gt;: compton-tryone-git&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;File Manager&lt;/strong&gt;: nemo&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Launcher&lt;/strong&gt;: rofi-git&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Editor&lt;/strong&gt;: neovim, atom&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Browser&lt;/strong&gt;: firefox&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Music Player&lt;/strong&gt;: ncmpcpp, mpd, mpc&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lock Screen&lt;/strong&gt;: &lt;a href="https://github.com/reorr/mantablockscreen"&gt;mantablockscreen&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Display Manager&lt;/strong&gt;: sddm with &lt;a href="https://www.opencode.net/marianarlt/sddm-sugar-candy" rel="nofollow"&gt;sugar-candy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-an-awesomewm-setup" class="anchor" aria-hidden="true" href="#an-awesomewm-setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;An AwesomeWM Setup&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FEATURES!&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Brightness and Volume OSDs&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Web-Search Rofi&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deepin-Like Application Dashboard&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Battery/Charger Notifications Module&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic Wallpaper Module&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Wallpaper changes based on time. You can modify it here &lt;code&gt;$HOME/.config/awesome/module/wallchange.lua&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Wallpapers are in &lt;code&gt;$HOME/.config/awesome/theme/wallpapers&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-my-current-theme" class="anchor" aria-hidden="true" href="#my-current-theme"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;My Current Theme&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Floppy&lt;/th&gt;
&lt;th&gt;Preview&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Desktop&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ilovecookieee/Glorious-Dotfiles/blob/master/screenshots/floppy/desktop.png"&gt;&lt;img src="https://github.com/ilovecookieee/Glorious-Dotfiles/raw/master/screenshots/floppy/desktop.png" alt="Screenshot" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dirty&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ilovecookieee/Glorious-Dotfiles/blob/master/screenshots/floppy/dirty.png"&gt;&lt;img src="https://github.com/ilovecookieee/Glorious-Dotfiles/raw/master/screenshots/floppy/dirty.png" alt="Screenshot" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dashboard&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ilovecookieee/Glorious-Dotfiles/blob/master/screenshots/floppy/dashboard.png"&gt;&lt;img src="https://github.com/ilovecookieee/Glorious-Dotfiles/raw/master/screenshots/floppy/dashboard.png" alt="Screenshot" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;App Dashboard&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ilovecookieee/Glorious-Dotfiles/blob/master/screenshots/floppy/application-dashboard.png"&gt;&lt;img src="https://github.com/ilovecookieee/Glorious-Dotfiles/raw/master/screenshots/floppy/application-dashboard.png" alt="Screenshot" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lockscreen&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ilovecookieee/Glorious-Dotfiles/blob/master/screenshots/floppy/lockscreen.png"&gt;&lt;img src="https://github.com/ilovecookieee/Glorious-Dotfiles/raw/master/screenshots/floppy/lockscreen.png" alt="Screenshot" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Greeter&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ilovecookieee/Glorious-Dotfiles/blob/master/screenshots/floppy/greeter.png"&gt;&lt;img src="https://github.com/ilovecookieee/Glorious-Dotfiles/raw/master/screenshots/floppy/greeter.png" alt="Screenshot" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-other-themes-preview" class="anchor" aria-hidden="true" href="#other-themes-preview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other themes preview&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Rounded&lt;/th&gt;
&lt;th&gt;Preview&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Desktop&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ilovecookieee/Glorious-Dotfiles/blob/master/screenshots/rounded/desktop.png"&gt;&lt;img src="https://github.com/ilovecookieee/Glorious-Dotfiles/raw/master/screenshots/rounded/desktop.png" alt="Screenshot" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dirty&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ilovecookieee/Glorious-Dotfiles/blob/master/screenshots/rounded/dirty.png"&gt;&lt;img src="https://github.com/ilovecookieee/Glorious-Dotfiles/raw/master/screenshots/rounded/dirty.png" alt="Screenshot" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Application Dashboard&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ilovecookieee/Glorious-Dotfiles/blob/master/screenshots/rounded/appdashboard.png"&gt;&lt;img src="https://github.com/ilovecookieee/Glorious-Dotfiles/raw/master/screenshots/rounded/appdashboard.png" alt="Screenshot" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Lines&lt;/th&gt;
&lt;th&gt;Preview&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Desktop&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ilovecookieee/Glorious-Dotfiles/blob/master/screenshots/lines/desktop.png"&gt;&lt;img src="https://github.com/ilovecookieee/Glorious-Dotfiles/raw/master/screenshots/lines/desktop.png" alt="Screenshot" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dirty&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ilovecookieee/Glorious-Dotfiles/blob/master/screenshots/lines/dirty.png"&gt;&lt;img src="https://github.com/ilovecookieee/Glorious-Dotfiles/raw/master/screenshots/lines/dirty.png" alt="Screenshot" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Application Dashboard&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ilovecookieee/Glorious-Dotfiles/blob/master/screenshots/lines/appdashboard.png"&gt;&lt;img src="https://github.com/ilovecookieee/Glorious-Dotfiles/raw/master/screenshots/lines/appdashboard.png" alt="Screenshot" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h2&gt;
&lt;p&gt;Here is a complete list of dependencies needed for making these AwesomeWM setup to work.
If you notice that something is missing, please open an issue so I can add the dependency to this table.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Dependency&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Why/Where is it needed?&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;awesome-git&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Window manager&lt;/td&gt;
&lt;td&gt;yeah awesome&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;rofi-git&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Window switcher, application launcher and dmenu replacement&lt;/td&gt;
&lt;td&gt;Application launcher&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Compton-tryone&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A compositor for X11&lt;/td&gt;
&lt;td&gt;compositor with kawase-blur&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;blueman&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Manages bluetooth&lt;/td&gt;
&lt;td&gt;For bluetooth widgets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;xfce4-power-manager&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Manages battery/power settings&lt;/td&gt;
&lt;td&gt;Power Settings&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;acpi&lt;/code&gt;,&lt;code&gt;acpid&lt;/code&gt;,&lt;code&gt;acpi_call&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Show battery status and other ACPI info&lt;/td&gt;
&lt;td&gt;Charger notifications&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;pulseaudio&lt;/code&gt;, &lt;code&gt;libpulse&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Sound system&lt;/td&gt;
&lt;td&gt;Volume widgets and keybinds&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;redshift&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Controls screen temperature&lt;/td&gt;
&lt;td&gt;Night mode command&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;mpd&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Server-side application for playing music&lt;/td&gt;
&lt;td&gt;Music widgets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;mpc&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Minimalist command line interface to MPD&lt;/td&gt;
&lt;td&gt;Music widgets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;maim&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Takes screenshots (improved &lt;code&gt;scrot&lt;/code&gt;)&lt;/td&gt;
&lt;td&gt;Screenshot keybinds&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;xclip&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Command line interface to the X11 clipboard&lt;/td&gt;
&lt;td&gt;Useful in taking screenshots&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;feh&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Image viewer and wallpaper setter&lt;/td&gt;
&lt;td&gt;Screenshot previews, wallpapers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;xorg-xwininfo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Window information utility for X&lt;/td&gt;
&lt;td&gt;it just works&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;python3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;an interpreted, interactive, object-oriented programming language&lt;/td&gt;
&lt;td&gt;Web-search Backend&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;xdg_menu&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Generates a list of installed applications&lt;/td&gt;
&lt;td&gt;Useful for generating app list&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;imagemagick&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An image viewing/manipulation program&lt;/td&gt;
&lt;td&gt;Album cover extractor&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;jq&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Command-line JSON processor&lt;/td&gt;
&lt;td&gt;Removable Drive Widget&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h5&gt;&lt;a id="user-content-monospace" class="anchor" aria-hidden="true" href="#monospace"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Monospace&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/elenapan/dotfiles/"&gt;Iosevka Custom&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sans" class="anchor" aria-hidden="true" href="#sans"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sans&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Google Sans&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;San Francisco Display&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;My setup is using the dependencies above, well if you don't want bloat you can install what you want. But these are the recommended dependencies:
&lt;ul&gt;
&lt;li&gt;awesome-git master branch (window manager framework)&lt;/li&gt;
&lt;li&gt;rofi git branch (application launcher)&lt;/li&gt;
&lt;li&gt;blueman (bluetooth widgets)&lt;/li&gt;
&lt;li&gt;xfce4-power-manager (power widget)&lt;/li&gt;
&lt;li&gt;acpi, acpid, acpi_call, upower (battery notifications)&lt;/li&gt;
&lt;li&gt;pulseaudio, alsa-utils (volume/audio keybinds)&lt;/li&gt;
&lt;li&gt;mpd, mpc (music widget)&lt;/li&gt;
&lt;li&gt;maim, xclip (screenshot tool)&lt;/li&gt;
&lt;li&gt;xorg-xwininfo, xprop (custom titlebar)&lt;/li&gt;
&lt;li&gt;python3 (web-search rofi)&lt;/li&gt;
&lt;li&gt;xdg-menu (generates app list)&lt;/li&gt;
&lt;li&gt;imagemagick (extract album cover, music widget)&lt;/li&gt;
&lt;li&gt;jq (removable drive widget)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Copy the selected theme from &lt;code&gt;Glorious-Dotfiles/config/awesome&lt;/code&gt; to &lt;code&gt;$HOME/.config/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename it to &lt;code&gt;awesome&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Reload Awesome using &lt;code&gt;super + shift + r&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-file-structure" class="anchor" aria-hidden="true" href="#file-structure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;File Structure&lt;/h1&gt;
&lt;p&gt;This setup is split in multiple parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rc.lua&lt;/code&gt; the core of configuration. You can enable and disable the modules here and load all your configurations.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;layout&lt;/code&gt; directory contains the panels' configurations. Change panel settings here or load/unload modules.&lt;/li&gt;
&lt;li&gt;In &lt;code&gt;configuration&lt;/code&gt; directory you can find all the configs about the key bindings, client rules, tags, starting apps and etc.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;module&lt;/code&gt; consists of many files that are usually inside the &lt;code&gt;rc.lua&lt;/code&gt; like notifications, app menus, etc. You can load them in the &lt;code&gt;rc.lua&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;themes&lt;/code&gt; folder contains themes and colors of the setup.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;widgets&lt;/code&gt; contains all the widgets(of course). These are used in the panels and dashboard. It contains the wifi, bluetooth, battery widget and many more.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;binaries&lt;/code&gt; contains bash scripts. I recently added this because running multiple bash commands inside lua is clunky at times. So I decided to split them and have their own territory. Right now, it contains the &lt;code&gt;snap&lt;/code&gt; script as screenshot tool and &lt;code&gt;togglewinfx&lt;/code&gt;, the script that toggles the compton blur.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-note" class="anchor" aria-hidden="true" href="#note"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NOTE&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;This setup will not mostly work out of the box because:
&lt;ul&gt;
&lt;li&gt;It is only tested and configured on a 1366x768 resolution (Lenovo x230)&lt;/li&gt;
&lt;li&gt;Some dependencies are not currently installed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Check keybindings using &lt;code&gt;super +  F1&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-about-widgets-and-modules" class="anchor" aria-hidden="true" href="#about-widgets-and-modules"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ABOUT WIDGETS AND MODULES&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;You need a song with hard-coded album cover for music widget to display its cover.&lt;/li&gt;
&lt;li&gt;You can disable the dialog backdrop effect in &lt;code&gt;awesome/configuration/client/rules.lua&lt;/code&gt;. Just search for &lt;code&gt;dialog&lt;/code&gt; and set &lt;code&gt;drawBackdrop&lt;/code&gt; to false in the properties. You can also just unload the module in &lt;code&gt;rc.lua&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Generating an application menu
&lt;ul&gt;
&lt;li&gt;Install &lt;code&gt;xdg-menu&lt;/code&gt;. In Arch, it is called &lt;code&gt;archlinux-xdg-menu&lt;/code&gt; It generates a list of applications installed.&lt;/li&gt;
&lt;li&gt;Execute &lt;code&gt;xdg_menu --format awesome --root-menu /etc/xdg/menus/arch-applications.menu &amp;gt;~/.config/awesome/archmenu.lua&lt;/code&gt; to generate a list to archmenu.lua&lt;/li&gt;
&lt;li&gt;You can just substitute its values to &lt;code&gt;awesome/module/menu.lua&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;So, you need to configure and tweak it by yourself to make it work properly. You can also just open a issue &lt;a href="https://github.com/ilovecookieee/Glorious-Dotfiles/issues/new"&gt;here&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-got-a-problem-just-open-an-issue-here" class="anchor" aria-hidden="true" href="#got-a-problem-just-open-an-issue-here"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Got a problem? Just open an issue &lt;a href="https://github.com/ilovecookieee/Glorious-Dotfiles/issues/new"&gt;here&lt;/a&gt;.&lt;/h1&gt;
&lt;h4&gt;&lt;a id="user-content-suggestion-if-you-have-any-suggestion-on-how-to-improve-this-setup-please-open-an-issue-here" class="anchor" aria-hidden="true" href="#suggestion-if-you-have-any-suggestion-on-how-to-improve-this-setup-please-open-an-issue-here"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Suggestion? If you have any suggestion on how to improve this setup, please open an issue &lt;a href="https://github.com/ilovecookieee/Glorious-Dotfiles/issues/new"&gt;here&lt;/a&gt;.&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Special thanks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PapyElGringo&lt;/strong&gt; for the awesome &lt;a href="https://github.com/PapyElGringo/material-awesome"&gt;material-awesome&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pdonadeo&lt;/strong&gt; for the &lt;a href="https://github.com/pdonadeo/rofi-web-search"&gt;rofi-web-search.py&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/elenapan/dotfiles"&gt;elenapan&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/addy-dclxvi/almighty-dotfiles"&gt;addyfe&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Myself, for not giving up hahaha&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ilovecookieee</author><guid isPermaLink="false">https://github.com/ilovecookieee/Glorious-Dotfiles</guid><pubDate>Fri, 08 Nov 2019 00:13:00 GMT</pubDate></item><item><title>jcjohnson/neural-style #14 in Lua, This week</title><link>https://github.com/jcjohnson/neural-style</link><description>&lt;p&gt;&lt;i&gt;Torch implementation of neural style algorithm&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-neural-style" class="anchor" aria-hidden="true" href="#neural-style"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;neural-style&lt;/h1&gt;
&lt;p&gt;This is a torch implementation of the paper &lt;a href="http://arxiv.org/abs/1508.06576" rel="nofollow"&gt;A Neural Algorithm of Artistic Style&lt;/a&gt;
by Leon A. Gatys, Alexander S. Ecker, and Matthias Bethge.&lt;/p&gt;
&lt;p&gt;The paper presents an algorithm for combining the content of one image with the style of another image using
convolutional neural networks. Here's an example that maps the artistic style of
&lt;a href="https://en.wikipedia.org/wiki/The_Starry_Night" rel="nofollow"&gt;The Starry Night&lt;/a&gt;
onto a night-time photograph of the Stanford campus:&lt;/p&gt;
&lt;div align="center"&gt;
 &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/starry_night_google.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/starry_night_google.jpg" height="223px" style="max-width:100%;"&gt;&lt;/a&gt;
 &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/hoovertowernight.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/hoovertowernight.jpg" height="223px" style="max-width:100%;"&gt;&lt;/a&gt;
 &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/starry_stanford_bigger.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/starry_stanford_bigger.png" width="710px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;Applying the style of different images to the same content image gives interesting results.
Here we reproduce Figure 2 from the paper, which renders a photograph of the Tubingen in Germany in a
variety of styles:&lt;/p&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/tubingen.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/tubingen.jpg" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_shipwreck.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_shipwreck.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_seated_nude.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_seated_nude.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_composition_vii.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_composition_vii.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;Here are the results of applying the style of various pieces of artwork to this photograph of the
golden gate bridge:&lt;/p&gt;
&lt;div align="center" height="200px"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/frida_kahlo.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/frida_kahlo.jpg" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_kahlo.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_kahlo.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/escher_sphere.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/escher_sphere.jpg" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_escher.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_escher.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/woman-with-hat-matisse.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/woman-with-hat-matisse.jpg" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_matisse.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_matisse.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/the_scream.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/the_scream.jpg" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_scream.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_scream.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/starry_night_crop.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/starry_night_crop.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/seated-nude.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/seated-nude.jpg" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_seated.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_seated.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-content--style-tradeoff" class="anchor" aria-hidden="true" href="#content--style-tradeoff"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Content / Style Tradeoff&lt;/h3&gt;
&lt;p&gt;The algorithm allows the user to trade-off the relative weight of the style and content reconstruction terms,
as shown in this example where we port the style of &lt;a href="http://www.wikiart.org/en/pablo-picasso/self-portrait-1907" rel="nofollow"&gt;Picasso's 1907 self-portrait&lt;/a&gt; onto Brad Pitt:&lt;/p&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/picasso_selfport1907.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/picasso_selfport1907.jpg" height="220px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/brad_pitt.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/brad_pitt.jpg" height="220px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_5_style_10.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_5_style_10.png" height="220px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_1_style_10.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_1_style_10.png" height="220px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_01_style_10.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_01_style_10.png" height="220px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_0025_style_10.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_0025_style_10.png" height="220px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-style-scale" class="anchor" aria-hidden="true" href="#style-scale"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Style Scale&lt;/h3&gt;
&lt;p&gt;By resizing the style image before extracting style features, we can control the types of artistic
features that are transfered from the style image; you can control this behavior with the &lt;code&gt;-style_scale&lt;/code&gt; flag.
Below we see three examples of rendering the Golden Gate Bridge in the style of The Starry Night.
From left to right, &lt;code&gt;-style_scale&lt;/code&gt; is 2.0, 1.0, and 0.5.&lt;/p&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale2.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale2.png" height="175px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale1.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale1.png" height="175px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale05.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale05.png" height="175px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-multiple-style-images" class="anchor" aria-hidden="true" href="#multiple-style-images"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Multiple Style Images&lt;/h3&gt;
&lt;p&gt;You can use more than one style image to blend multiple artistic styles.&lt;/p&gt;
&lt;p&gt;Clockwise from upper left: "The Starry Night" + "The Scream", "The Scream" + "Composition VII",
"Seated Nude" + "Composition VII", and "Seated Nude" + "The Starry Night"&lt;/p&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry_scream.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry_scream.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream_composition_vii.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream_composition_vii.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry_seated.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry_seated.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_seated_nude_composition_vii.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_seated_nude_composition_vii.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-style-interpolation" class="anchor" aria-hidden="true" href="#style-interpolation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Style Interpolation&lt;/h3&gt;
&lt;p&gt;When using multiple style images, you can control the degree to which they are blended:&lt;/p&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_3_7.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_3_7.png" height="175px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_5_5.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_5_5.png" height="175px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_7_3.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_7_3.png" height="175px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-transfer-style-but-not-color" class="anchor" aria-hidden="true" href="#transfer-style-but-not-color"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transfer style but not color&lt;/h3&gt;
&lt;p&gt;If you add the flag &lt;code&gt;-original_colors 1&lt;/code&gt; then the output image will retain the colors of the original image;
this is similar to &lt;a href="http://blog.deepart.io/2016/06/04/color-independent-style-transfer/" rel="nofollow"&gt;the recent blog post by deepart.io&lt;/a&gt;.&lt;/p&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry.png" height="185px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream.png" height="185px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_composition_vii.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_composition_vii.png" height="185px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_starry.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_starry.png" height="185px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_scream.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_scream.png" height="185px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_composition_vii.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_composition_vii.png" height="185px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup:&lt;/h2&gt;
&lt;p&gt;Dependencies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/torch/torch7"&gt;torch7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/szagoruyko/loadcaffe"&gt;loadcaffe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Optional dependencies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For CUDA backend:
&lt;ul&gt;
&lt;li&gt;CUDA 6.5+&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/torch/cunn"&gt;cunn&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For cuDNN backend:
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/soumith/cudnn.torch"&gt;cudnn.torch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For OpenCL backend:
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/hughperkins/cltorch"&gt;cltorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/hughperkins/clnn"&gt;clnn&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After installing dependencies, you'll need to run the following script to download the VGG model:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sh models/download_models.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will download the original &lt;a href="https://gist.github.com/ksimonyan/3785162f95cd2d5fee77#file-readme-md"&gt;VGG-19 model&lt;/a&gt;.
Leon Gatys has graciously provided the modified version of the VGG-19 model that was used in their paper;
this will also be downloaded. By default the original VGG-19 model is used.&lt;/p&gt;
&lt;p&gt;If you have a smaller memory GPU then using NIN Imagenet model will be better and gives slightly worse yet comparable results. You can get the details on the model from &lt;a href="https://github.com/BVLC/caffe/wiki/Model-Zoo"&gt;BVLC Caffe ModelZoo&lt;/a&gt; and can download the files from &lt;a href="https://drive.google.com/folderview?id=0B0IedYUunOQINEFtUi1QNWVhVVU&amp;amp;usp=drive_web" rel="nofollow"&gt;NIN-Imagenet Download Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can find detailed installation instructions for Ubuntu in the &lt;a href="INSTALL.md"&gt;installation guide&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;p&gt;Basic usage:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;th neural_style.lua -style_image &amp;lt;image.jpg&amp;gt; -content_image &amp;lt;image.jpg&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;OpenCL usage with NIN Model (This requires you download the NIN Imagenet model files as described above):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;th neural_style.lua -style_image examples/inputs/picasso_selfport1907.jpg -content_image examples/inputs/brad_pitt.jpg -output_image profile.png -model_file models/nin_imagenet_conv.caffemodel -proto_file models/train_val.prototxt -gpu 0 -backend clnn -num_iterations 1000 -seed 123 -content_layers relu0,relu3,relu7,relu12 -style_layers relu0,relu3,relu7,relu12 -content_weight 10 -style_weight 1000 -image_size 512 -optimizer adam
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/examples/outputs/pitt_picasso_nin_opencl.png"&gt;&lt;img src="/examples/outputs/pitt_picasso_nin_opencl.png" alt="OpenCL NIN Model Picasso Brad Pitt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To use multiple style images, pass a comma-separated list like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-style_image starry_night.jpg,the_scream.jpg&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Note that paths to images should not contain the &lt;code&gt;~&lt;/code&gt; character to represent your home directory; you should instead use a relative
path or a full absolute path.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Options&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-image_size&lt;/code&gt;: Maximum side length (in pixels) of of the generated image. Default is 512.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-style_blend_weights&lt;/code&gt;: The weight for blending the style of multiple style images, as a
comma-separated list, such as &lt;code&gt;-style_blend_weights 3,7&lt;/code&gt;. By default all style images
are equally weighted.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-gpu&lt;/code&gt;: Zero-indexed ID of the GPU to use; for CPU mode set &lt;code&gt;-gpu&lt;/code&gt; to -1.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Optimization options&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-content_weight&lt;/code&gt;: How much to weight the content reconstruction term. Default is 5e0.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-style_weight&lt;/code&gt;: How much to weight the style reconstruction term. Default is 1e2.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-tv_weight&lt;/code&gt;: Weight of total-variation (TV) regularization; this helps to smooth the image.
Default is 1e-3. Set to 0 to disable TV regularization.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-num_iterations&lt;/code&gt;: Default is 1000.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-init&lt;/code&gt;: Method for generating the generated image; one of &lt;code&gt;random&lt;/code&gt; or &lt;code&gt;image&lt;/code&gt;.
Default is &lt;code&gt;random&lt;/code&gt; which uses a noise initialization as in the paper; &lt;code&gt;image&lt;/code&gt;
initializes with the content image.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-optimizer&lt;/code&gt;: The optimization algorithm to use; either &lt;code&gt;lbfgs&lt;/code&gt; or &lt;code&gt;adam&lt;/code&gt;; default is &lt;code&gt;lbfgs&lt;/code&gt;.
L-BFGS tends to give better results, but uses more memory. Switching to ADAM will reduce memory usage;
when using ADAM you will probably need to play with other parameters to get good results, especially
the style weight, content weight, and learning rate; you may also want to normalize gradients when
using ADAM.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-learning_rate&lt;/code&gt;: Learning rate to use with the ADAM optimizer. Default is 1e1.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-normalize_gradients&lt;/code&gt;: If this flag is present, style and content gradients from each layer will be
L1 normalized. Idea from &lt;a href="https://github.com/andersbll/neural_artistic_style"&gt;andersbll/neural_artistic_style&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Output options&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-output_image&lt;/code&gt;: Name of the output image. Default is &lt;code&gt;out.png&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-print_iter&lt;/code&gt;: Print progress every &lt;code&gt;print_iter&lt;/code&gt; iterations. Set to 0 to disable printing.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-save_iter&lt;/code&gt;: Save the image every &lt;code&gt;save_iter&lt;/code&gt; iterations. Set to 0 to disable saving intermediate results.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Layer options&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-content_layers&lt;/code&gt;: Comma-separated list of layer names to use for content reconstruction.
Default is &lt;code&gt;relu4_2&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-style_layers&lt;/code&gt;: Comma-separated list of layer names to use for style reconstruction.
Default is &lt;code&gt;relu1_1,relu2_1,relu3_1,relu4_1,relu5_1&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Other options&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-style_scale&lt;/code&gt;: Scale at which to extract features from the style image. Default is 1.0.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-original_colors&lt;/code&gt;: If you set this to 1, then the output image will keep the colors of the content image.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-proto_file&lt;/code&gt;: Path to the &lt;code&gt;deploy.txt&lt;/code&gt; file for the VGG Caffe model.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-model_file&lt;/code&gt;: Path to the &lt;code&gt;.caffemodel&lt;/code&gt; file for the VGG Caffe model.
Default is the original VGG-19 model; you can also try the normalized VGG-19 model used in the paper.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pooling&lt;/code&gt;: The type of pooling layers to use; one of &lt;code&gt;max&lt;/code&gt; or &lt;code&gt;avg&lt;/code&gt;. Default is &lt;code&gt;max&lt;/code&gt;.
The VGG-19 models uses max pooling layers, but the paper mentions that replacing these layers with average
pooling layers can improve the results. I haven't been able to get good results using average pooling, but
the option is here.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend&lt;/code&gt;: &lt;code&gt;nn&lt;/code&gt;, &lt;code&gt;cudnn&lt;/code&gt;, or &lt;code&gt;clnn&lt;/code&gt;. Default is &lt;code&gt;nn&lt;/code&gt;. &lt;code&gt;cudnn&lt;/code&gt; requires
&lt;a href="https://github.com/soumith/cudnn.torch"&gt;cudnn.torch&lt;/a&gt; and may reduce memory usage.
&lt;code&gt;clnn&lt;/code&gt; requires &lt;a href="https://github.com/hughperkins/cltorch"&gt;cltorch&lt;/a&gt; and &lt;a href="https://github.com/hughperkins/clnn"&gt;clnn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-cudnn_autotune&lt;/code&gt;: When using the cuDNN backend, pass this flag to use the built-in cuDNN autotuner to select
the best convolution algorithms for your architecture. This will make the first iteration a bit slower and can
take a bit more memory, but may significantly speed up the cuDNN backend.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-frequently-asked-questions" class="anchor" aria-hidden="true" href="#frequently-asked-questions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Frequently Asked Questions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Generated image has saturation artifacts:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://cloud.githubusercontent.com/assets/1310570/9694690/fa8e8782-5328-11e5-9c91-11f7b215ad19.png"&gt;&lt;img src="https://cloud.githubusercontent.com/assets/1310570/9694690/fa8e8782-5328-11e5-9c91-11f7b215ad19.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Update the &lt;code&gt;image&lt;/code&gt; packge to the latest version: &lt;code&gt;luarocks install image&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Running without a GPU gives an error message complaining about &lt;code&gt;cutorch&lt;/code&gt; not found&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt;
Pass the flag &lt;code&gt;-gpu -1&lt;/code&gt; when running in CPU-only mode&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; The program runs out of memory and dies&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Try reducing the image size: &lt;code&gt;-image_size 256&lt;/code&gt; (or lower). Note that different image sizes will likely
require non-default values for &lt;code&gt;-style_weight&lt;/code&gt; and &lt;code&gt;-content_weight&lt;/code&gt; for optimal results.
If you are running on a GPU, you can also try running with &lt;code&gt;-backend cudnn&lt;/code&gt; to reduce memory usage.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Get the following error message:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;models/VGG_ILSVRC_19_layers_deploy.prototxt.cpu.lua:7: attempt to call method 'ceil' (a nil value)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Update &lt;code&gt;nn&lt;/code&gt; package to the latest version: &lt;code&gt;luarocks install nn&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Get an error message complaining about &lt;code&gt;paths.extname&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Update &lt;code&gt;torch.paths&lt;/code&gt; package to the latest version: &lt;code&gt;luarocks install paths&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; NIN Imagenet model is not giving good results.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Make sure the correct &lt;code&gt;-proto_file&lt;/code&gt; is selected. Also make sure the correct parameters for &lt;code&gt;-content_layers&lt;/code&gt; and &lt;code&gt;-style_layers&lt;/code&gt; are set. (See OpenCL usage example above.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; &lt;code&gt;-backend cudnn&lt;/code&gt; is slower than default NN backend&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Add the flag &lt;code&gt;-cudnn_autotune&lt;/code&gt;; this will use the built-in cuDNN autotuner to select the best convolution algorithms.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-memory-usage" class="anchor" aria-hidden="true" href="#memory-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Memory Usage&lt;/h2&gt;
&lt;p&gt;By default, &lt;code&gt;neural-style&lt;/code&gt; uses the &lt;code&gt;nn&lt;/code&gt; backend for convolutions and L-BFGS for optimization.
These give good results, but can both use a lot of memory. You can reduce memory usage with the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Use cuDNN&lt;/strong&gt;: Add the flag &lt;code&gt;-backend cudnn&lt;/code&gt; to use the cuDNN backend. This will only work in GPU mode.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use ADAM&lt;/strong&gt;: Add the flag &lt;code&gt;-optimizer adam&lt;/code&gt; to use ADAM instead of L-BFGS. This should significantly
reduce memory usage, but may require tuning of other parameters for good results; in particular you should
play with the learning rate, content weight, style weight, and also consider using gradient normalization.
This should work in both CPU and GPU modes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reduce image size&lt;/strong&gt;: If the above tricks are not enough, you can reduce the size of the generated image;
pass the flag &lt;code&gt;-image_size 256&lt;/code&gt; to generate an image at half the default size.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With the default settings, &lt;code&gt;neural-style&lt;/code&gt; uses about 3.5GB of GPU memory on my system;
switching to ADAM and cuDNN reduces the GPU memory footprint to about 1GB.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-speed" class="anchor" aria-hidden="true" href="#speed"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speed&lt;/h2&gt;
&lt;p&gt;Speed can vary a lot depending on the backend and the optimizer.
Here are some times for running 500 iterations with &lt;code&gt;-image_size=512&lt;/code&gt; on a Maxwell Titan X with different settings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-backend nn -optimizer lbfgs&lt;/code&gt;: 62 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend nn -optimizer adam&lt;/code&gt;: 49 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend cudnn -optimizer lbfgs&lt;/code&gt;: 79 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend cudnn -cudnn_autotune -optimizer lbfgs&lt;/code&gt;: 58 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend cudnn -cudnn_autotune -optimizer adam&lt;/code&gt;: 44 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend clnn -optimizer lbfgs&lt;/code&gt;: 169 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend clnn -optimizer adam&lt;/code&gt;: 106 seconds&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are the same benchmarks on a Pascal Titan X with cuDNN 5.0 on CUDA 8.0 RC:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-backend nn -optimizer lbfgs&lt;/code&gt;: 43 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend nn -optimizer adam&lt;/code&gt;: 36 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend cudnn -optimizer lbfgs&lt;/code&gt;: 45 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend cudnn -cudnn_autotune -optimizer lbfgs&lt;/code&gt;: 30 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend cudnn -cudnn_autotune -optimizer adam&lt;/code&gt;: 22 seconds&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-multi-gpu-scaling" class="anchor" aria-hidden="true" href="#multi-gpu-scaling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Multi-GPU scaling&lt;/h2&gt;
&lt;p&gt;You can use multiple GPUs to process images at higher resolutions; different layers of the network will be
computed on different GPUs. You can control which GPUs are used with the &lt;code&gt;-gpu&lt;/code&gt; flag, and you can control
how to split layers across GPUs using the &lt;code&gt;-multigpu_strategy&lt;/code&gt; flag.&lt;/p&gt;
&lt;p&gt;For example in a server with four GPUs, you can give the flag &lt;code&gt;-gpu 0,1,2,3&lt;/code&gt; to process on GPUs 0, 1, 2, and
3 in that order; by also giving the flag &lt;code&gt;-multigpu_strategy 3,6,12&lt;/code&gt; you indicate that the first two layers
should be computed on GPU 0, layers 3 to 5 should be computed on GPU 1, layers 6 to 11 should be computed on
GPU 2, and the remaining layers should be computed on GPU 3. You will need to tune the &lt;code&gt;-multigpu_strategy&lt;/code&gt;
for your setup in order to achieve maximal resolution.&lt;/p&gt;
&lt;p&gt;We can achieve very high quality results at high resolution by combining multi-GPU processing with multiscale
generation as described in the paper
&lt;a href="https://arxiv.org/abs/1611.07865" rel="nofollow"&gt;&lt;strong&gt;Controlling Perceptual Factors in Neural Style Transfer&lt;/strong&gt;&lt;/a&gt; by Leon A. Gatys,
Alexander S. Ecker, Matthias Bethge, Aaron Hertzmann and Eli Shechtman.&lt;/p&gt;
&lt;p&gt;Here is a 3620 x 1905 image generated on a server with four Pascal Titan X GPUs:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/starry_stanford_bigger.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/starry_stanford_bigger.png" height="400px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The script used to generate this image &lt;a href="examples/multigpu_scripts/starry_stanford.sh"&gt;can be found here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-implementation-details" class="anchor" aria-hidden="true" href="#implementation-details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Implementation details&lt;/h2&gt;
&lt;p&gt;Images are initialized with white noise and optimized using L-BFGS.&lt;/p&gt;
&lt;p&gt;We perform style reconstructions using the &lt;code&gt;conv1_1&lt;/code&gt;, &lt;code&gt;conv2_1&lt;/code&gt;, &lt;code&gt;conv3_1&lt;/code&gt;, &lt;code&gt;conv4_1&lt;/code&gt;, and &lt;code&gt;conv5_1&lt;/code&gt; layers
and content reconstructions using the &lt;code&gt;conv4_2&lt;/code&gt; layer. As in the paper, the five style reconstruction losses have
equal weights.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you find this code useful for your research, please cite:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@misc{Johnson2015,
  author = {Johnson, Justin},
  title = {neural-style},
  year = {2015},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/jcjohnson/neural-style}},
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jcjohnson</author><guid isPermaLink="false">https://github.com/jcjohnson/neural-style</guid><pubDate>Fri, 08 Nov 2019 00:14:00 GMT</pubDate></item></channel></rss>