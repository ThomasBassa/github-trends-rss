<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Python, This week</title><link>https://github.com/trending/python?since=weekly</link><description>The top repositories on GitHub for python, measured weekly</description><pubDate>Fri, 20 Dec 2019 01:08:22 GMT</pubDate><lastBuildDate>Fri, 20 Dec 2019 01:08:22 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>testerSunshine/12306 #1 in Python, This week</title><link>https://github.com/testerSunshine/12306</link><description>&lt;p&gt;&lt;i&gt;12306智能刷票，订票&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h3&gt;&lt;a id="user-content-12306-购票小助手" class="anchor" aria-hidden="true" href="#12306-购票小助手"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;12306 购票小助手&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-python版本" class="anchor" aria-hidden="true" href="#python版本"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;python版本&lt;/h4&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 2.7.10 - 2.7.15&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 3.6 - 3.7.4&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 2.7.9&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-已有功能" class="anchor" aria-hidden="true" href="#已有功能"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;已有功能&lt;/h4&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 自动打码&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 自动登录&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 准点预售和捡漏&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 智能候补&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 邮件通知&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; server酱通知&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-依赖库" class="anchor" aria-hidden="true" href="#依赖库"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;依赖库&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;验证码目前可以本地识别，需要下载模型，放于项目根目录，全部代码来源于此项目 &lt;a href="https://github.com/zhaipro/easy12306"&gt;传送门&lt;/a&gt;，表示感谢
&lt;pre&gt;&lt;code&gt;  1. 模型下载链接:https://pan.baidu.com/s/1rS155VjweWVWIJogakechA  密码:bmlm
     群里面也可以下载
  2. git仓库下载：https://github.com/testerSunshine/12306model.git
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;自托管云打码服务器搭建：&lt;a href="https://github.com/YinAoXiong/12306_code_server"&gt;12306_code_server&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;如果大家有空闲的服务器，可搭建之后在这个 &lt;a href="https://github.com/testerSunshine/12306/issues/446"&gt;issues&lt;/a&gt; 里面填入自己的服务器(请注意服务器安全！)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;项目依赖 &lt;a href="requirements.txt"&gt;requirements.txt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;安装方法x:
&lt;ul&gt;
&lt;li&gt;root用户(避免多python环境产生问题): &lt;code&gt;pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;非root用户（避免安装和运行时使用了不同环境）: &lt;code&gt;pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;许多windows的用户装不了tensorflow的话，可以适当降低版本或者升高版本都是可以的
&lt;pre&gt;&lt;code&gt;1. tensorflow的兼容版本 1.14.0rc\1.14.0rc\1.15.0\1.15.0rc
以上版本都测试无问题
2. 如果pip代理的清华源无法下载，可以更换其他源解决此问题
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-项目使用说明" class="anchor" aria-hidden="true" href="#项目使用说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目使用说明&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;服务器启动:
&lt;ul&gt;
&lt;li&gt;修改&lt;a href="TickerConfig.py"&gt;配置&lt;/a&gt;文件
&lt;ul&gt;
&lt;li&gt;可以配置邮箱,配置邮箱的格式在&lt;a href="TickerConfig.py"&gt;配置&lt;/a&gt;里面可以看到ex
&lt;pre&gt;&lt;code&gt;# 测试邮箱和server酱是否可用， server酱测试的前提是server酱开关开启
# 可以配置server酱提醒（推荐）[配置教程](https://www.jianshu.com/p/8d10b5b9c4e3)
# 用python3 还是python 完全取决于安装的时候配置的环境变量是否为python3,以下启动默认环境变量为python3
python3 run.py t
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;配置&lt;a href="TickerConfig.py"&gt;配置&lt;/a&gt;文件的时候，需注意空格和遵循python语法格式&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;启动前请先筛选cdn，这点很&lt;code&gt;重要&lt;/code&gt;
&lt;pre&gt;&lt;code&gt;python3 run.py c
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;启动服务
&lt;pre&gt;&lt;code&gt;python3 run.py r
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;如果你不知道如何操作，下面的命令可能会帮助你
&lt;pre&gt;&lt;code&gt;python3 run.py -h

——————————————————————————
sage: run.py [-h] operate

positional arguments:
  operate     r: 运行抢票程序, c: 过滤cdn, t: 测试邮箱和server酱，server酱
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;如果你的服务器安装了docker与docker-compose, 那么就可以通过&lt;code&gt;docker-compose&lt;/code&gt;进行启动,&lt;code&gt;docker.sh&lt;/code&gt;脚本对此进行了封装，可以通过如下命令进行启动
&lt;ul&gt;
&lt;li&gt;1、&lt;code&gt;sudo ./docker.sh run&lt;/code&gt; #创建一个镜像并启动容器，如果镜像已经创建过了会直接启动容器。&lt;/li&gt;
&lt;li&gt;2、&lt;code&gt;sudo ./docker.sh restart&lt;/code&gt; #修改配置文件后，通过此名命令可重新加载容器运行&lt;/li&gt;
&lt;li&gt;3、&lt;code&gt;sudo ./docker.sh rm&lt;/code&gt; #删除容器&lt;/li&gt;
&lt;li&gt;4、&lt;code&gt;sudo ./docker.sh drun&lt;/code&gt; #后台运行容器&lt;/li&gt;
&lt;li&gt;5、&lt;code&gt;sudo ./docker.sh logs&lt;/code&gt; #在后台运行时，通过此命令查看运行的内容&lt;/li&gt;
&lt;li&gt;注: 针对没有docker环境的同学提供了docker安装脚本(&lt;strong&gt;centos7&lt;/strong&gt;)
- &lt;code&gt;sudo ./docker_install_centos.sh&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;注: 若只有docker没有docker-compose. 可通过&lt;code&gt;pip install docker-compose&lt;/code&gt;进行下载&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-目录对应说明" class="anchor" aria-hidden="true" href="#目录对应说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目录对应说明&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;agency - cdn代理&lt;/li&gt;
&lt;li&gt;config - 项目配置&lt;/li&gt;
&lt;li&gt;verify - 自动打码&lt;/li&gt;
&lt;li&gt;init - 项目主运行目录&lt;/li&gt;
&lt;li&gt;inter - 接口&lt;/li&gt;
&lt;li&gt;myException - 异常&lt;/li&gt;
&lt;li&gt;myUrllib  request网络请求库&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-思路图" class="anchor" aria-hidden="true" href="#思路图"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;思路图&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a target="_blank" rel="noopener noreferrer" href="uml/uml.png"&gt;&lt;img src="uml/uml.png" alt="image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-项目声明" class="anchor" aria-hidden="true" href="#项目声明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目声明：&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;本软件只供学习交流使用，勿作为商业用途，交流群号
&lt;ul&gt;
&lt;li&gt;1群：286271084(已满)&lt;/li&gt;
&lt;li&gt;2群：649992274(已满)&lt;/li&gt;
&lt;li&gt;3群：632501142(已满)&lt;/li&gt;
&lt;li&gt;4群: 606340519(已满)&lt;/li&gt;
&lt;li&gt;5群: 948526733(已满)&lt;/li&gt;
&lt;li&gt;7群: 660689659(已满)&lt;/li&gt;
&lt;li&gt;8群: 620629239(已满)&lt;/li&gt;
&lt;li&gt;6群: 608792930(未满)&lt;/li&gt;
&lt;li&gt;9群: 693035807(未满)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;请不要重复加群，一个群就可以了，把机会留给更多人&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;进群先看公告！！！进群先看公告！！！进群先看公告！！！ 重要的事情说三遍&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;能为你抢到一张回家的票，是我最大的心愿&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-日志列子" class="anchor" aria-hidden="true" href="#日志列子"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;日志列子&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;成功log，如果是购票失败的，请带上失败的log给我，我尽力帮你调，也可加群一起交流，程序只是加速买票的过程，并不一定能买到票
&lt;pre&gt;&lt;code&gt;正在第355次查询  乘车日期: 2018-02-12  车次G4741,G2365,G1371,G1377,G1329 查询无票  代理设置 无  总耗时429ms
车次: G4741 始发车站: 上海 终点站: 邵阳 二等座:有
正在尝试提交订票...
尝试提交订单...
出票成功
排队成功, 当前余票还剩余: 359 张
正在使用自动识别验证码功能
验证码通过,正在提交订单
提交订单成功！
排队等待时间预计还剩 -12 ms
排队等待时间预计还剩 -6 ms
排队等待时间预计还剩 -7 ms
排队等待时间预计还剩 -4 ms
排队等待时间预计还剩 -4 ms
恭喜您订票成功，订单号为：EB52743573, 请立即打开浏览器登录12306，访问‘未完成订单’，在30分钟内完成支付！
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-使用帮助一些安装问题和使用反馈较多的问题" class="anchor" aria-hidden="true" href="#使用帮助一些安装问题和使用反馈较多的问题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;使用帮助(一些安装问题和使用反馈较多的问题)：&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;测试邮箱是否可用 &lt;a href="https://github.com/testerSunshine/12306/issues/107"&gt;邮箱配置问题看issues&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;学生票issues &lt;a href="https://github.com/testerSunshine/12306/issues/47"&gt;学生票修改&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;依赖安装不对的问题（ImportError）&lt;a href="https://github.com/testerSunshine/12306/issues/91"&gt;requirements.txt问题&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若快豆子疑问 &lt;a href="https://github.com/testerSunshine/12306/issues/67"&gt;点我&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;IOError: 【Errno 0】 Error 问题 &lt;a href="https://github.com/testerSunshine/12306/issues/159"&gt;点我&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;测试下单接口是否可用，有两个下单接口，随便用哪个都ok&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果下载验证码过期或者下载失败的问题，应该是12306封ip的策略，多重试几次，12306现在封服务器(阿里云和腾讯云)ip比较严重，尽量不要放在服务器里面&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;目前12306对服务器ip比较敏感，大家还是在自己家里挂着吧&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;自动更换ip软件目前已支持TPLINK和小米路由器，只限家庭网络&lt;a href="https://github.com/testerSunshine/AutoRouterIP"&gt;点我跳转&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-感谢一下小伙伴对本项目提供的帮助" class="anchor" aria-hidden="true" href="#感谢一下小伙伴对本项目提供的帮助"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;感谢一下小伙伴对本项目提供的帮助&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;@&lt;a href="mailto:sun7127@126.com"&gt;sun7127@126.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;@ 才&lt;/li&gt;
&lt;li&gt;@&lt;a href="https://github.com/MonsterTan"&gt;MonsterTan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;以及所有为此项目提供pr的同学&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-更新日志" class="anchor" aria-hidden="true" href="#更新日志"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;更新日志&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="Update.md"&gt;更新日志&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>testerSunshine</author><guid isPermaLink="false">https://github.com/testerSunshine/12306</guid><pubDate>Fri, 20 Dec 2019 00:01:00 GMT</pubDate></item><item><title>marblexu/PythonPlantsVsZombies #2 in Python, This week</title><link>https://github.com/marblexu/PythonPlantsVsZombies</link><description>&lt;p&gt;&lt;i&gt;a simple PlantsVsZombies game&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pythonplantsvszombies" class="anchor" aria-hidden="true" href="#pythonplantsvszombies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PythonPlantsVsZombies&lt;/h1&gt;
&lt;p&gt;A simple PlantsVsZombies game. &lt;br&gt;
&lt;code&gt;It's only for personal learning and noncommercial use. If this game infringes the copyright, please let me know.&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;implement plants: sunflower, peashooter, wallnut, snowpeashooter, cherrybomb, threepeashooter, chomper, puffshroom, potatomine, spikeweed, scaredyshroom, squash, scaredyshroom, jalapeno, sunShroom, iceShroom, hypnoShroom.&lt;/li&gt;
&lt;li&gt;implement zombies: zombie, flagzombie, coneheadzombie, bucketheadzombie, newspaperzombie.&lt;/li&gt;
&lt;li&gt;use json file to store level data (e.g.position and time of zombies, background info)&lt;/li&gt;
&lt;li&gt;support to select plant cards at the beginning of the level&lt;/li&gt;
&lt;li&gt;support day level, night level, moving card select level and wallnut bowling level&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-requirement" class="anchor" aria-hidden="true" href="#requirement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirement&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Python 3.7&lt;/li&gt;
&lt;li&gt;Notice: python version 3.7 is advisable, but not required. For LINUX: if your Linux system has a preinstalled python 3+, it's ok to run this game. Updating to python 3.7 directly may break LINUX Mint.&lt;/li&gt;
&lt;li&gt;Python-Pygame 1.9&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-how-to-start-game" class="anchor" aria-hidden="true" href="#how-to-start-game"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How To Start Game&lt;/h1&gt;
&lt;p&gt;$ python main.py&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-how-to-play" class="anchor" aria-hidden="true" href="#how-to-play"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to Play&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;use mouse to collect sun, select the plant cards and seed the plant&lt;/li&gt;
&lt;li&gt;you can set the start level by changing START_LEVEL_NUM value in source/constants.py
&lt;ul&gt;
&lt;li&gt;level 1 and 2：day level&lt;/li&gt;
&lt;li&gt;level 3: night level&lt;/li&gt;
&lt;li&gt;level 4: moving card select level&lt;/li&gt;
&lt;li&gt;level 5: wallnut bowling level&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-demo" class="anchor" aria-hidden="true" href="#demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Demo&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/marblexu/PythonPlantsVsZombies/master/demo/demo1.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/marblexu/PythonPlantsVsZombies/master/demo/demo1.jpg" alt="demo1" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/marblexu/PythonPlantsVsZombies/master/demo/demo2.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/marblexu/PythonPlantsVsZombies/master/demo/demo2.jpg" alt="demo2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>marblexu</author><guid isPermaLink="false">https://github.com/marblexu/PythonPlantsVsZombies</guid><pubDate>Fri, 20 Dec 2019 00:02:00 GMT</pubDate></item><item><title>shengqiangzhang/examples-of-web-crawlers #3 in Python, This week</title><link>https://github.com/shengqiangzhang/examples-of-web-crawlers</link><description>&lt;p&gt;&lt;i&gt;一些非常有趣的python爬虫例子,对新手比较友好,主要爬取淘宝、天猫、微信、豆瓣、QQ等网站。(Some interesting examples of python crawlers that are friendly to beginners. )&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="MD" data-path="README.MD"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-一些非常有趣的python爬虫例子对新手比较友好" class="anchor" aria-hidden="true" href="#一些非常有趣的python爬虫例子对新手比较友好"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;p align="center"&gt;一些非常有趣的python爬虫例子,对新手比较友好&lt;/p&gt;&lt;/h1&gt;
&lt;p align="center"&gt;
    &lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers"&gt;&lt;img src="https://camo.githubusercontent.com/c61da9e28a8aa9d92d6c4d90172578afcf817090/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7374617475732d7570646174696e672d627269676874677265656e2e737667" data-canonical-src="https://img.shields.io/badge/status-updating-brightgreen.svg" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://github.com/python/cpython"&gt;&lt;img src="https://camo.githubusercontent.com/d832f382aa014a184d51184d51211e1105ea52da/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e372d4646313439332e737667" data-canonical-src="https://img.shields.io/badge/Python-3.7-FF1493.svg" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://opensource.org/licenses/mit-license.php" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/40dcd2cc6ccc53394ef5c22b006f3681797cc09b/68747470733a2f2f6261646765732e66726170736f66742e636f6d2f6f732f6d69742f6d69742e737667" data-canonical-src="https://badges.frapsoft.com/os/mit/mit.svg" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers"&gt;&lt;img src="https://camo.githubusercontent.com/4b0b497da019de861029ecfbcee26efc14f864fd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f7265706f2d73697a652f7368656e677169616e677a68616e672f6578616d706c65732d6f662d7765622d637261776c657273" data-canonical-src="https://img.shields.io/github/repo-size/shengqiangzhang/examples-of-web-crawlers" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/graphs/contributors"&gt;&lt;img src="https://camo.githubusercontent.com/0cce082de29ed96d4a2736e99f70a000f567cf32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6e7472696275746f72732f7368656e677169616e677a68616e672f6578616d706c65732d6f662d7765622d637261776c6572733f636f6c6f723d626c7565" data-canonical-src="https://img.shields.io/github/contributors/shengqiangzhang/examples-of-web-crawlers?color=blue" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/stargazers"&gt;&lt;img src="https://camo.githubusercontent.com/9e079750352959ffc9006f895e0df00e7708284b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368656e677169616e677a68616e672f6578616d706c65732d6f662d7765622d637261776c6572732e7376673f6c6f676f3d676974687562" data-canonical-src="https://img.shields.io/github/stars/shengqiangzhang/examples-of-web-crawlers.svg?logo=github" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/network/members"&gt;&lt;img src="https://camo.githubusercontent.com/244876c27add1e212163319e8b4ba5554574e67c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f7368656e677169616e677a68616e672f6578616d706c65732d6f662d7765622d637261776c6572732e7376673f636f6c6f723d626c7565266c6f676f3d676974687562" data-canonical-src="https://img.shields.io/github/forks/shengqiangzhang/examples-of-web-crawlers.svg?color=blue&amp;amp;logo=github" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://www.python.org/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a3301bd38765e3d3e31c1990c586db7a15b02dc2/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f632f63332f507974686f6e2d6c6f676f2d6e6f746578742e737667" align="right" height="48" width="48" data-canonical-src="https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-简介" class="anchor" aria-hidden="true" href="#简介"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;简介&lt;/h2&gt;
&lt;p&gt;一些常见的网站爬虫例子，代码通用性较高，时效性较久。&lt;strong&gt;项目代码对新手比较友好&lt;/strong&gt;，尽量用简单的python代码，并配有大量注释。&lt;/p&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-1淘宝模拟登录" class="anchor" aria-hidden="true" href="#1淘宝模拟登录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/tree/master/1.%E6%B7%98%E5%AE%9D%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95"&gt;1.淘宝模拟登录&lt;/a&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-使用教程" class="anchor" aria-hidden="true" href="#使用教程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;使用教程&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.google.com/chrome/" rel="nofollow"&gt;点击这里下载&lt;/a&gt;下载chrome浏览器&lt;/li&gt;
&lt;li&gt;查看chrome浏览器的版本号，&lt;a href="http://chromedriver.storage.googleapis.com/index.html" rel="nofollow"&gt;点击这里下载&lt;/a&gt;对应版本号的chromedriver驱动&lt;/li&gt;
&lt;li&gt;pip安装下列包
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; pip install selenium&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://account.weibo.com/set/bindsns/bindtaobao" rel="nofollow"&gt;点击这里&lt;/a&gt;登录微博，并通过微博绑定淘宝账号密码&lt;/li&gt;
&lt;li&gt;在main中填写chromedriver的绝对路径&lt;/li&gt;
&lt;li&gt;在main中填写微博账号密码&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;改成你的chromedriver的完整路径地址&lt;/span&gt;
chromedriver_path &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/Users/bird/Desktop/chromedriver.exe&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; 
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;改成你的微博账号&lt;/span&gt;
weibo_username &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;改成你的微博账号&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;改成你的微博密码&lt;/span&gt;
weibo_password &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;改成你的微博密码&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-演示图片" class="anchor" aria-hidden="true" href="#演示图片"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;演示图片&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="1.%E6%B7%98%E5%AE%9D%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95/example.gif"&gt;&lt;img src="1.%E6%B7%98%E5%AE%9D%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95/example.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-2天猫商品数据爬虫" class="anchor" aria-hidden="true" href="#2天猫商品数据爬虫"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/tree/master/2.%E5%A4%A9%E7%8C%AB%E5%95%86%E5%93%81%E6%95%B0%E6%8D%AE%E7%88%AC%E8%99%AB(%E5%B7%B2%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95)"&gt;2.天猫商品数据爬虫&lt;/a&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-使用教程-1" class="anchor" aria-hidden="true" href="#使用教程-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;使用教程&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.google.com/chrome/" rel="nofollow"&gt;点击这里下载&lt;/a&gt;下载chrome浏览器&lt;/li&gt;
&lt;li&gt;查看chrome浏览器的版本号，&lt;a href="http://chromedriver.storage.googleapis.com/index.html" rel="nofollow"&gt;点击这里下载&lt;/a&gt;对应版本号的chromedriver驱动&lt;/li&gt;
&lt;li&gt;pip安装下列包
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; pip install selenium&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; pip install pyquery&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://account.weibo.com/set/bindsns/bindtaobao" rel="nofollow"&gt;点击这里&lt;/a&gt;登录微博，并通过微博绑定淘宝账号密码&lt;/li&gt;
&lt;li&gt;在main中填写chromedriver的绝对路径&lt;/li&gt;
&lt;li&gt;在main中填写微博账号密码&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;改成你的chromedriver的完整路径地址&lt;/span&gt;
chromedriver_path &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/Users/bird/Desktop/chromedriver.exe&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; 
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;改成你的微博账号&lt;/span&gt;
weibo_username &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;改成你的微博账号&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;改成你的微博密码&lt;/span&gt;
weibo_password &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;改成你的微博密码&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-演示图片-1" class="anchor" aria-hidden="true" href="#演示图片-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;演示图片&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="2.%E5%A4%A9%E7%8C%AB%E5%95%86%E5%93%81%E6%95%B0%E6%8D%AE%E7%88%AC%E8%99%AB(%E5%B7%B2%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95)/example.gif"&gt;&lt;img src="2.%E5%A4%A9%E7%8C%AB%E5%95%86%E5%93%81%E6%95%B0%E6%8D%AE%E7%88%AC%E8%99%AB(%E5%B7%B2%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95)/example.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="2.%E5%A4%A9%E7%8C%AB%E5%95%86%E5%93%81%E6%95%B0%E6%8D%AE%E7%88%AC%E8%99%AB(%E5%B7%B2%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95)/example2.png"&gt;&lt;img src="2.%E5%A4%A9%E7%8C%AB%E5%95%86%E5%93%81%E6%95%B0%E6%8D%AE%E7%88%AC%E8%99%AB(%E5%B7%B2%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95)/example2.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-3爬取淘宝我已购买的宝贝数据" class="anchor" aria-hidden="true" href="#3爬取淘宝我已购买的宝贝数据"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/tree/master/3.%E6%B7%98%E5%AE%9D%E5%B7%B2%E4%B9%B0%E5%88%B0%E7%9A%84%E5%AE%9D%E8%B4%9D%E6%95%B0%E6%8D%AE%E7%88%AC%E8%99%AB(%E5%B7%B2%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95)"&gt;3.爬取淘宝我已购买的宝贝数据&lt;/a&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-使用教程-2" class="anchor" aria-hidden="true" href="#使用教程-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;使用教程&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.google.com/chrome/" rel="nofollow"&gt;点击这里下载&lt;/a&gt;下载chrome浏览器&lt;/li&gt;
&lt;li&gt;查看chrome浏览器的版本号，&lt;a href="http://chromedriver.storage.googleapis.com/index.html" rel="nofollow"&gt;点击这里下载&lt;/a&gt;对应版本号的chromedriver驱动&lt;/li&gt;
&lt;li&gt;pip安装下列包
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; pip install selenium&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; pip install pyquery&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://account.weibo.com/set/bindsns/bindtaobao" rel="nofollow"&gt;点击这里&lt;/a&gt;登录微博，并通过微博绑定淘宝账号密码&lt;/li&gt;
&lt;li&gt;在main中填写chromedriver的绝对路径&lt;/li&gt;
&lt;li&gt;在main中填写微博账号密码&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;改成你的chromedriver的完整路径地址&lt;/span&gt;
chromedriver_path &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/Users/bird/Desktop/chromedriver.exe&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; 
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;改成你的微博账号&lt;/span&gt;
weibo_username &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;改成你的微博账号&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;改成你的微博密码&lt;/span&gt;
weibo_password &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;改成你的微博密码&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-演示图片-2" class="anchor" aria-hidden="true" href="#演示图片-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;演示图片&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="3.%E6%B7%98%E5%AE%9D%E5%B7%B2%E4%B9%B0%E5%88%B0%E7%9A%84%E5%AE%9D%E8%B4%9D%E6%95%B0%E6%8D%AE%E7%88%AC%E8%99%AB(%E5%B7%B2%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95)/example.gif"&gt;&lt;img src="3.%E6%B7%98%E5%AE%9D%E5%B7%B2%E4%B9%B0%E5%88%B0%E7%9A%84%E5%AE%9D%E8%B4%9D%E6%95%B0%E6%8D%AE%E7%88%AC%E8%99%AB(%E5%B7%B2%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95)/example.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="3.%E6%B7%98%E5%AE%9D%E5%B7%B2%E4%B9%B0%E5%88%B0%E7%9A%84%E5%AE%9D%E8%B4%9D%E6%95%B0%E6%8D%AE%E7%88%AC%E8%99%AB(%E5%B7%B2%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95)/example2.png"&gt;&lt;img src="3.%E6%B7%98%E5%AE%9D%E5%B7%B2%E4%B9%B0%E5%88%B0%E7%9A%84%E5%AE%9D%E8%B4%9D%E6%95%B0%E6%8D%AE%E7%88%AC%E8%99%AB(%E5%B7%B2%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95)/example2.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-4每天不同时间段通过微信发消息提醒女友" class="anchor" aria-hidden="true" href="#4每天不同时间段通过微信发消息提醒女友"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/tree/master/4.%E6%AF%8F%E5%A4%A9%E4%B8%8D%E5%90%8C%E6%97%B6%E9%97%B4%E6%AE%B5%E9%80%9A%E8%BF%87%E5%BE%AE%E4%BF%A1%E5%8F%91%E6%B6%88%E6%81%AF%E6%8F%90%E9%86%92%E5%A5%B3%E5%8F%8B"&gt;4.每天不同时间段通过微信发消息提醒女友&lt;/a&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-简介-1" class="anchor" aria-hidden="true" href="#简介-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;简介&lt;/h3&gt;
&lt;p&gt;有时候，你很想关心她，但是你太忙了，以至于她一直抱怨，觉得你不够关心她。你暗自下决心，下次一定要准时发消息给她，哪怕是几句话，可是你又忘记了。你觉得自己很委屈&lt;g-emoji class="g-emoji" alias="sob" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f62d.png"&gt;😭&lt;/g-emoji&gt;，但是她又觉得你不负责。&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;现在，再不用担心了&lt;/strong&gt;，用python就可以给女友定时发提示消息了，&lt;strong&gt;而且不会漏过每一个关键时刻&lt;/strong&gt;，每天&lt;strong&gt;早上起床、中午吃饭、晚上吃饭、晚上睡觉&lt;/strong&gt;，都会准时发消息给她了，而且还可以让她&lt;strong&gt;学习英语单词&lt;/strong&gt;哦！&lt;/p&gt;
&lt;br&gt;
在生日来临之时，自动发祝福语。在节日来临之时，比如**三八妇女节、女神节、情人节、春节、圣诞节**，自动发问候语哦，再也不用担心他说你没有仪式感了&lt;g-emoji class="g-emoji" alias="grinning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f600.png"&gt;😀&lt;/g-emoji&gt;
&lt;br&gt;
&lt;p&gt;最重要的时候，实时可以知道女友的&lt;strong&gt;情感情绪指数&lt;/strong&gt;哦，再也不用担心女友莫名其妙生气了。&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-使用教程-3" class="anchor" aria-hidden="true" href="#使用教程-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;使用教程&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;pip安装下列包&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; pip install wxpy&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; pip install requests&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="2"&gt;
&lt;li&gt;设置以下内容&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 设置config.ini相关信息&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-演示图片-3" class="anchor" aria-hidden="true" href="#演示图片-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;演示图片&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="4.每天不同时间段通过微信发消息提醒女友/example1.png"&gt;&lt;img src="4.每天不同时间段通过微信发消息提醒女友/example1.png" width="310" alt="example1" style="max-width:100%;"&gt;&lt;/a&gt;&lt;a target="_blank" rel="noopener noreferrer" href="4.每天不同时间段通过微信发消息提醒女友/example2.png"&gt;&lt;img src="4.每天不同时间段通过微信发消息提醒女友/example2.png" width="310" alt="example2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="4.每天不同时间段通过微信发消息提醒女友/example3.png"&gt;&lt;img src="4.每天不同时间段通过微信发消息提醒女友/example3.png" width="620" alt="example3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-5爬取5k分辨率超清唯美壁纸" class="anchor" aria-hidden="true" href="#5爬取5k分辨率超清唯美壁纸"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/tree/master/5.%E7%88%AC%E5%8F%965K%E5%88%86%E8%BE%A8%E7%8E%87%E8%B6%85%E6%B8%85%E5%94%AF%E7%BE%8E%E5%A3%81%E7%BA%B8"&gt;5.爬取5K分辨率超清唯美壁纸&lt;/a&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-简介-2" class="anchor" aria-hidden="true" href="#简介-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;简介&lt;/h3&gt;
&lt;p&gt;壁纸的选择其实很大程度上能看出电脑主人的内心世界，有的人喜欢风景，有的人喜欢星空，有的人喜欢美女，有的人喜欢动物。然而，终究有一天你已经产生审美疲劳了，但你下定决定要换壁纸的时候，又发现网上的壁纸要么分辨率低，要么带有水印。&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;这里有一款Mac下的小清新壁纸神器&lt;a href="http://paper.meiyuan.in/" rel="nofollow"&gt;Pap.er&lt;/a&gt;，可能是Mac下最好的壁纸软件，&lt;strong&gt;自带5K超清分辨率壁纸&lt;/strong&gt;，富有多种类型壁纸，当我们想在Windows或者Linux下使用的时候，就可以考虑将&lt;strong&gt;5K超清分辨率壁纸&lt;/strong&gt;爬取下来。&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-使用教程-4" class="anchor" aria-hidden="true" href="#使用教程-4"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;使用教程&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;确保以下库均已安装：&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 如果没有安装，请使用pip install module安装&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; requests
&lt;span class="pl-k"&gt;import&lt;/span&gt; filetype
&lt;span class="pl-k"&gt;import&lt;/span&gt; os
&lt;span class="pl-k"&gt;import&lt;/span&gt; json
&lt;span class="pl-k"&gt;from&lt;/span&gt; contextlib &lt;span class="pl-k"&gt;import&lt;/span&gt; closing&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-演示图片-4" class="anchor" aria-hidden="true" href="#演示图片-4"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;演示图片&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="5.%E7%88%AC%E5%8F%965K%E5%88%86%E8%BE%A8%E7%8E%87%E8%B6%85%E6%B8%85%E5%94%AF%E7%BE%8E%E5%A3%81%E7%BA%B8/example1.png"&gt;&lt;img src="5.%E7%88%AC%E5%8F%965K%E5%88%86%E8%BE%A8%E7%8E%87%E8%B6%85%E6%B8%85%E5%94%AF%E7%BE%8E%E5%A3%81%E7%BA%B8/example1.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="5.%E7%88%AC%E5%8F%965K%E5%88%86%E8%BE%A8%E7%8E%87%E8%B6%85%E6%B8%85%E5%94%AF%E7%BE%8E%E5%A3%81%E7%BA%B8/example2.gif"&gt;&lt;img src="5.%E7%88%AC%E5%8F%965K%E5%88%86%E8%BE%A8%E7%8E%87%E8%B6%85%E6%B8%85%E5%94%AF%E7%BE%8E%E5%A3%81%E7%BA%B8/example2.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-6爬取豆瓣排行榜电影数据含gui界面版" class="anchor" aria-hidden="true" href="#6爬取豆瓣排行榜电影数据含gui界面版"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/tree/master/6.%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E6%8E%92%E8%A1%8C%E6%A6%9C%E7%94%B5%E5%BD%B1%E6%95%B0%E6%8D%AE(%E5%90%ABGUI%E7%95%8C%E9%9D%A2%E7%89%88)"&gt;6.爬取豆瓣排行榜电影数据(含GUI界面版)&lt;/a&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-简介-3" class="anchor" aria-hidden="true" href="#简介-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;简介&lt;/h3&gt;
&lt;p&gt;这个项目源于大三某课程设计。平常经常需要搜索一些电影，但是不知道哪些评分高且评价人数多的电影。为了方便使用，就将原来的项目重新改写了。当做是对爬虫技术、可视化技术的实践了。主要是通过从排行榜和从影片关键词两种方式爬取电影数据。&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-使用教程-5" class="anchor" aria-hidden="true" href="#使用教程-5"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;使用教程&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;打开&lt;a href="http://chromedriver.storage.googleapis.com/index.html" rel="nofollow"&gt;http://chromedriver.storage.googleapis.com/index.html&lt;/a&gt;，根据自己的操作系统下载对应的chromedriver&lt;/li&gt;
&lt;li&gt;打开当前面目录下的**getMovieInRankingList.py**，定位到第59行，将&lt;code&gt;executable_path=/Users/bird/Desktop/chromedriver.exe&lt;/code&gt;修改成你自己的chromedriver路径&lt;/li&gt;
&lt;li&gt;打开pycharm，依次安装以下包&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;pip install Pillow&lt;/li&gt;
&lt;li&gt;pip install selenium&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-演示图片-5" class="anchor" aria-hidden="true" href="#演示图片-5"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;演示图片&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="6.%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E6%8E%92%E8%A1%8C%E6%A6%9C%E7%94%B5%E5%BD%B1%E6%95%B0%E6%8D%AE(%E5%90%ABGUI%E7%95%8C%E9%9D%A2%E7%89%88)/example_rating.png"&gt;&lt;img src="6.%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E6%8E%92%E8%A1%8C%E6%A6%9C%E7%94%B5%E5%BD%B1%E6%95%B0%E6%8D%AE(%E5%90%ABGUI%E7%95%8C%E9%9D%A2%E7%89%88)/example_rating.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="6.%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E6%8E%92%E8%A1%8C%E6%A6%9C%E7%94%B5%E5%BD%B1%E6%95%B0%E6%8D%AE(%E5%90%ABGUI%E7%95%8C%E9%9D%A2%E7%89%88)/example_keyword.png"&gt;&lt;img src="6.%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E6%8E%92%E8%A1%8C%E6%A6%9C%E7%94%B5%E5%BD%B1%E6%95%B0%E6%8D%AE(%E5%90%ABGUI%E7%95%8C%E9%9D%A2%E7%89%88)/example_keyword.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-包含功能" class="anchor" aria-hidden="true" href="#包含功能"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;包含功能&lt;/h3&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 根据关键字搜索电影&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 根据排行榜(TOP250)搜索电影&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 显示IMDB评分及其他基本信息&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 提供多个在线视频站点，无需vip&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 提供多个云盘站点搜索该视频，以便保存到云盘&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 提供多个站点下载该视频&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 等待更新&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-存在问题" class="anchor" aria-hidden="true" href="#存在问题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;存在问题&lt;/h3&gt;
&lt;p&gt;目前没有加入反爬虫策略，如果运行出现403 forbidden提示，则说明暂时被禁止，解决方式如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加入cookies&lt;/li&gt;
&lt;li&gt;采用随机延时方式&lt;/li&gt;
&lt;li&gt;采用IP代理池方式(较不稳定)&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-7多线程代理池爬取天天基金网股票数据无需使用爬虫框架" class="anchor" aria-hidden="true" href="#7多线程代理池爬取天天基金网股票数据无需使用爬虫框架"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/tree/master/7.%E7%88%AC%E5%8F%96%E5%A4%A9%E5%A4%A9%E5%9F%BA%E9%87%91%E7%BD%91%E6%89%80%E6%9C%89%E5%9F%BA%E9%87%91%E6%95%B0%E6%8D%AE"&gt;7.多线程+代理池爬取天天基金网、股票数据(无需使用爬虫框架)&lt;/a&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-简介-4" class="anchor" aria-hidden="true" href="#简介-4"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;简介&lt;/h3&gt;
&lt;p&gt;提到爬虫，大部分人都会想到使用Scrapy工具，但是仅仅停留在会使用的阶段。为了增加对爬虫机制的理解，我们可以手动实现多线程的爬虫过程，同时，引入IP代理池进行基本的反爬操作。&lt;/p&gt;
&lt;p&gt;本次使用天天基金网进行爬虫，该网站具有反爬机制，同时数量足够大，多线程效果较为明显。&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-技术路线" class="anchor" aria-hidden="true" href="#技术路线"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;技术路线&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;IP代理池&lt;/li&gt;
&lt;li&gt;多线程&lt;/li&gt;
&lt;li&gt;爬虫与反爬&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-数据格式" class="anchor" aria-hidden="true" href="#数据格式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数据格式&lt;/h3&gt;
&lt;p&gt;000056,建信消费升级混合,2019-03-26,1.7740,1.7914,0.98,2019-03-27 15:00&lt;/p&gt;
&lt;p&gt;000031,华夏复兴混合,2019-03-26,1.5650,1.5709,0.38,2019-03-27 15:00&lt;/p&gt;
&lt;p&gt;000048,华夏双债增强债券C,2019-03-26,1.2230,1.2236,0.05,2019-03-27 15:00&lt;/p&gt;
&lt;p&gt;000008,嘉实中证500ETF联接A,2019-03-26,1.4417,1.4552,0.93,2019-03-27 15:00&lt;/p&gt;
&lt;p&gt;000024,大摩双利增强债券A,2019-03-26,1.1670,1.1674,0.04,2019-03-27 15:00&lt;/p&gt;
&lt;p&gt;000054,鹏华双债增利债券,2019-03-26,1.1697,1.1693,-0.03,2019-03-27 15:00&lt;/p&gt;
&lt;p&gt;000016,华夏纯债债券C,2019-03-26,1.1790,1.1793,0.03,2019-03-27 15:00&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-功能截图" class="anchor" aria-hidden="true" href="#功能截图"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;功能截图&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="7.%E7%88%AC%E5%8F%96%E5%A4%A9%E5%A4%A9%E5%9F%BA%E9%87%91%E7%BD%91%E6%89%80%E6%9C%89%E5%9F%BA%E9%87%91%E6%95%B0%E6%8D%AE/example.gif"&gt;&lt;img src="7.%E7%88%AC%E5%8F%96%E5%A4%A9%E5%A4%A9%E5%9F%BA%E9%87%91%E7%BD%91%E6%89%80%E6%9C%89%E5%9F%BA%E9%87%91%E6%95%B0%E6%8D%AE/example.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-配置说明" class="anchor" aria-hidden="true" href="#配置说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;配置说明&lt;/h3&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;	&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 确保安装以下库，如果没有，请在python3环境下执行pip install 模块名&lt;/span&gt;
	&lt;span class="pl-k"&gt;import&lt;/span&gt; requests
	&lt;span class="pl-k"&gt;import&lt;/span&gt; random
	&lt;span class="pl-k"&gt;import&lt;/span&gt; re
	&lt;span class="pl-k"&gt;import&lt;/span&gt; queue
	&lt;span class="pl-k"&gt;import&lt;/span&gt; threading
	&lt;span class="pl-k"&gt;import&lt;/span&gt; csv
	&lt;span class="pl-k"&gt;import&lt;/span&gt; json&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-8一键生成微信个人专属数据报告了解你的微信社交历史" class="anchor" aria-hidden="true" href="#8一键生成微信个人专属数据报告了解你的微信社交历史"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/tree/master/8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)"&gt;8.一键生成微信个人专属数据报告(了解你的微信社交历史))&lt;/a&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-简介-5" class="anchor" aria-hidden="true" href="#简介-5"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;简介&lt;/h3&gt;
&lt;p&gt;你是否想过生成一份属于你的微信个人数据报告，了解你的微信社交历史。现在，我们基于python对微信好友进行全方位数据分析，包括：昵称、性别、年龄、地区、备注名、个性签名、头像、群聊、公众号等。&lt;/p&gt;
&lt;p&gt;其中，在分析好友类型方面，主要统计出你的陌生人、星标好友、不让他看我的朋友圈的好友、不看他的朋友圈的好友数据。在分析地区方面，主要统计所有好友在全国的分布以及对好友数最多的省份进行进一步分析。在其他方面，统计出你的好友性别比例、猜出你最亲密的好友，分析你的特殊好友，找出与你所在共同群聊数最多的好友数据，对你的好友个性签名进行分析，对你的好友头像进行分析，并进一步检测出使用真人头像的好友数据。&lt;/p&gt;
&lt;p&gt;目前网上关于这方面的数据分析文章比较多，但是运行起来比较麻烦，&lt;strong&gt;而本程序的运行十分简单，只需要扫码登录一步操作即可。&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-功能截图-1" class="anchor" aria-hidden="true" href="#功能截图-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;功能截图&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example1.png"&gt;&lt;img src="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example1.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example2.png"&gt;&lt;img src="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example2.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example5.png"&gt;&lt;img src="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example5.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example6.png"&gt;&lt;img src="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example6.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example7.png"&gt;&lt;img src="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example7.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example8.png"&gt;&lt;img src="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example8.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example10.png"&gt;&lt;img src="8.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E5%BE%AE%E4%BF%A1%E4%B8%AA%E4%BA%BA%E4%B8%93%E5%B1%9E%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%91%8A(%E4%BA%86%E8%A7%A3%E4%BD%A0%E7%9A%84%E5%BE%AE%E4%BF%A1%E7%A4%BE%E4%BA%A4%E5%8E%86%E5%8F%B2)/example10.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-如何运行" class="anchor" aria-hidden="true" href="#如何运行"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;如何运行&lt;/h3&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 跳转到当前目录&lt;/span&gt;
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; 目录名
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 先卸载依赖库&lt;/span&gt;
pip uninstall -y -r requirement.txt
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 再重新安装依赖库&lt;/span&gt;
pip install -r requirement.txt
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 开始运行&lt;/span&gt;
python generate_wx_data.py&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-如何打包成二进制可执行文件" class="anchor" aria-hidden="true" href="#如何打包成二进制可执行文件"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;如何打包成二进制可执行文件&lt;/h3&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 安装pyinstaller&lt;/span&gt;
pip install pyinstaller
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 跳转到当前目录&lt;/span&gt;
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; 目录名
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 先卸载依赖库&lt;/span&gt;
pip uninstall -y -r requirement.txt
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 再重新安装依赖库&lt;/span&gt;
pip install -r requirement.txt
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 更新 setuptools&lt;/span&gt;
pip install --upgrade setuptools
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 开始打包&lt;/span&gt;
pyinstaller generate_wx_data.py&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-9一键生成qq个人历史报告" class="anchor" aria-hidden="true" href="#9一键生成qq个人历史报告"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/tree/master/9.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90QQ%E4%B8%AA%E4%BA%BA%E5%8E%86%E5%8F%B2%E6%8A%A5%E5%91%8A"&gt;9.一键生成QQ个人历史报告&lt;/a&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-简介-6" class="anchor" aria-hidden="true" href="#简介-6"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;简介&lt;/h3&gt;
&lt;p&gt;近几年，由于微信的流行，大部分人不再频繁使用QQ，所以我们对于自己的QQ数据并不是特别了解。我相信，如果能够生成一份属于自己的QQ历史报告，那将是无比开心的一件事。&lt;/p&gt;
&lt;p&gt;目前网上关于QQ的数据分析工具较少，原因是QQ相关接口比较复杂。&lt;strong&gt;而本程序的运行十分简单，具有良好的用户交互界面，只需要扫码登录一步操作即可。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;目前本程序获取的数据包括：QQ详细数据、手机在线时间、非隐身状态下在线时间、QQ活跃时间、单向好友数量、QQ财产分析、群聊分析、过去一年我退出的群聊数据、退去一个月我删除的好友数据、所有代付信息、我最在意的人以及最在意我的人。&lt;strong&gt;由于相关的数据接口有访问限制，所以本程序并没有对QQ好友进行分析。&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-功能截图-2" class="anchor" aria-hidden="true" href="#功能截图-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;功能截图&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="9.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90QQ%E4%B8%AA%E4%BA%BA%E5%8E%86%E5%8F%B2%E6%8A%A5%E5%91%8A/example1.png"&gt;&lt;img src="9.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90QQ%E4%B8%AA%E4%BA%BA%E5%8E%86%E5%8F%B2%E6%8A%A5%E5%91%8A/example1.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="9.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90QQ%E4%B8%AA%E4%BA%BA%E5%8E%86%E5%8F%B2%E6%8A%A5%E5%91%8A/example2.png"&gt;&lt;img src="9.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90QQ%E4%B8%AA%E4%BA%BA%E5%8E%86%E5%8F%B2%E6%8A%A5%E5%91%8A/example2.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="9.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90QQ%E4%B8%AA%E4%BA%BA%E5%8E%86%E5%8F%B2%E6%8A%A5%E5%91%8A/example3.png"&gt;&lt;img src="9.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90QQ%E4%B8%AA%E4%BA%BA%E5%8E%86%E5%8F%B2%E6%8A%A5%E5%91%8A/example3.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="9.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90QQ%E4%B8%AA%E4%BA%BA%E5%8E%86%E5%8F%B2%E6%8A%A5%E5%91%8A/example4.png"&gt;&lt;img src="9.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90QQ%E4%B8%AA%E4%BA%BA%E5%8E%86%E5%8F%B2%E6%8A%A5%E5%91%8A/example4.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-如何运行-1" class="anchor" aria-hidden="true" href="#如何运行-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;如何运行&lt;/h3&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 跳转到当前目录&lt;/span&gt;
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; 目录名
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 先卸载依赖库&lt;/span&gt;
pip uninstall -y -r requirement.txt
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 再重新安装依赖库&lt;/span&gt;
pip install -r requirement.txt
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 开始运行&lt;/span&gt;
python main.py&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-10一键生成个人微信朋友圈数据电子书" class="anchor" aria-hidden="true" href="#10一键生成个人微信朋友圈数据电子书"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/tree/master/10.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E4%B8%AA%E4%BA%BA%E5%BE%AE%E4%BF%A1%E6%9C%8B%E5%8F%8B%E5%9C%88%E6%95%B0%E6%8D%AE%E7%94%B5%E5%AD%90%E4%B9%A6"&gt;10.一键生成个人微信朋友圈数据电子书&lt;/a&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-简介-7" class="anchor" aria-hidden="true" href="#简介-7"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;简介&lt;/h3&gt;
&lt;p&gt;微信朋友圈保留着你的数据，它留住了美好的回忆，记录了我们成长的点点滴滴。发朋友圈从某种意义上来讲是在记录生活，感受生活，并从中看到了每个人每一步的成长。&lt;/p&gt;
&lt;p&gt;这么一份珍贵的记忆，何不将它保存下来呢？只需一杯咖啡的时间，即可一键打印你的朋友圈。它可以是纸质书，也可以是电子书，可以长久保存，比洗照片好，又有时间足迹记忆。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这本书，可以用来：&lt;/li&gt;
&lt;li&gt;送给孩子的生日礼物&lt;/li&gt;
&lt;li&gt;送给伴侣的生日礼物&lt;/li&gt;
&lt;li&gt;送给未来的自己&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;现在，你可以选择打印电子书或者纸质书。打印纸质书的话，可以找第三方机构花钱购买；&lt;strong&gt;打印电子书的话，我们完全可以自己动手生成，这可以省下一笔不小的开支&lt;/strong&gt;。&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-功能截图-3" class="anchor" aria-hidden="true" href="#功能截图-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;功能截图&lt;/h3&gt;
&lt;p&gt;在开始写代码思路之前，我们先看看最终生成的效果。&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-电子书效果图片引用自出书啦" class="anchor" aria-hidden="true" href="#电子书效果图片引用自出书啦"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;电子书效果(图片引用自&lt;a href="https://chushu.la/" rel="nofollow"&gt;出书啦&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="10.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E4%B8%AA%E4%BA%BA%E5%BE%AE%E4%BF%A1%E6%9C%8B%E5%8F%8B%E5%9C%88%E6%95%B0%E6%8D%AE%E7%94%B5%E5%AD%90%E4%B9%A6/image/page1.png"&gt;&lt;img src="10.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E4%B8%AA%E4%BA%BA%E5%BE%AE%E4%BF%A1%E6%9C%8B%E5%8F%8B%E5%9C%88%E6%95%B0%E6%8D%AE%E7%94%B5%E5%AD%90%E4%B9%A6/image/page1.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="10.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E4%B8%AA%E4%BA%BA%E5%BE%AE%E4%BF%A1%E6%9C%8B%E5%8F%8B%E5%9C%88%E6%95%B0%E6%8D%AE%E7%94%B5%E5%AD%90%E4%B9%A6/image/page2.png"&gt;&lt;img src="10.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E4%B8%AA%E4%BA%BA%E5%BE%AE%E4%BF%A1%E6%9C%8B%E5%8F%8B%E5%9C%88%E6%95%B0%E6%8D%AE%E7%94%B5%E5%AD%90%E4%B9%A6/image/page2.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-纸质书效果图片引用自心书" class="anchor" aria-hidden="true" href="#纸质书效果图片引用自心书"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;纸质书效果(图片引用自&lt;a href="https://weixinshu.com/library/unboxing" rel="nofollow"&gt;心书&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="10.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E4%B8%AA%E4%BA%BA%E5%BE%AE%E4%BF%A1%E6%9C%8B%E5%8F%8B%E5%9C%88%E6%95%B0%E6%8D%AE%E7%94%B5%E5%AD%90%E4%B9%A6/image/page3.jpeg"&gt;&lt;img src="10.%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90%E4%B8%AA%E4%BA%BA%E5%BE%AE%E4%BF%A1%E6%9C%8B%E5%8F%8B%E5%9C%88%E6%95%B0%E6%8D%AE%E7%94%B5%E5%AD%90%E4%B9%A6/image/page3.jpeg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-如何运行-2" class="anchor" aria-hidden="true" href="#如何运行-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;如何运行&lt;/h3&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 跳转到当前目录&lt;/span&gt;
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; 目录名
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 先卸载依赖库&lt;/span&gt;
pip uninstall -y -r requirement.txt
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 再重新安装依赖库&lt;/span&gt;
pip install -r requirement.txt
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 开始运行&lt;/span&gt;
python main.py&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-11一键分析你的上网行为web页面可视化" class="anchor" aria-hidden="true" href="#11一键分析你的上网行为web页面可视化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers/tree/master/11.%E4%B8%80%E9%94%AE%E5%88%86%E6%9E%90%E4%BD%A0%E7%9A%84%E4%B8%8A%E7%BD%91%E8%A1%8C%E4%B8%BA(web%E9%A1%B5%E9%9D%A2%E5%8F%AF%E8%A7%86%E5%8C%96)"&gt;11.一键分析你的上网行为(web页面可视化)&lt;/a&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-简介-8" class="anchor" aria-hidden="true" href="#简介-8"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;简介&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;想看看你最近一年都在干嘛？看看你平时上网是在摸鱼还是认真工作？想写年度汇报总结，但是苦于没有数据？现在，它来了。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是一个能让你了解自己的浏览历史的Chrome浏览历史记录分析程序，&lt;strong&gt;他适用于Chrome浏览器或者以Chromium为内核的浏览器。目前国内大部分浏览器均是以Chromium为内核的浏览器，所以基本上都可以使用。但是不支持以下浏览器：IE浏览器、Firefox浏览器、Safari浏览器。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在该页面中你将可以查看有关自己在过去的时间里所访问浏览的域名、URL以及忙碌天数的前十排名以及相关的数据图表。&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-功能截图-4" class="anchor" aria-hidden="true" href="#功能截图-4"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;功能截图&lt;/h3&gt;
&lt;p&gt;在开始写代码思路之前，我们先看看最终生成的效果。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="11.%E4%B8%80%E9%94%AE%E5%88%86%E6%9E%90%E4%BD%A0%E7%9A%84%E4%B8%8A%E7%BD%91%E8%A1%8C%E4%B8%BA(web%E9%A1%B5%E9%9D%A2%E5%8F%AF%E8%A7%86%E5%8C%96)/demo.gif"&gt;&lt;img src="11.%E4%B8%80%E9%94%AE%E5%88%86%E6%9E%90%E4%BD%A0%E7%9A%84%E4%B8%8A%E7%BD%91%E8%A1%8C%E4%B8%BA(web%E9%A1%B5%E9%9D%A2%E5%8F%AF%E8%A7%86%E5%8C%96)/demo.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-如何运行-3" class="anchor" aria-hidden="true" href="#如何运行-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;如何运行&lt;/h3&gt;
&lt;p&gt;在线演示程序:&lt;a href="http://39.106.118.77:8090" rel="nofollow"&gt;http://39.106.118.77:8090&lt;/a&gt;(普通服务器，勿测压)&lt;/p&gt;
&lt;p&gt;运行本程序十分简单，只需要按照以下命令即可运行：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 跳转到当前目录&lt;/span&gt;
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; 目录名
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 先卸载依赖库&lt;/span&gt;
pip uninstall -y -r requirement.txt
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 再重新安装依赖库&lt;/span&gt;
pip install -r requirement.txt
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 开始运行&lt;/span&gt;
python app.py

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 运行成功后，通过浏览器打开http://localhost:8090&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-如何下载" class="anchor" aria-hidden="true" href="#如何下载"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;如何下载&lt;/h2&gt;
&lt;p&gt;本仓库大小为&lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers"&gt;&lt;img src="https://camo.githubusercontent.com/4b0b497da019de861029ecfbcee26efc14f864fd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f7265706f2d73697a652f7368656e677169616e677a68616e672f6578616d706c65732d6f662d7765622d637261776c657273" data-canonical-src="https://img.shields.io/github/repo-size/shengqiangzhang/examples-of-web-crawlers" style="max-width:100%;"&gt;&lt;/a&gt;, 为提高下载速度, 建议使用代理服务器下载。&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;没有或不懂如何设置代理服务器的&lt;a target="_blank" rel="noopener noreferrer" href="./chinese_flag.png"&gt;&lt;img src="./chinese_flag.png" alt="chinese_flag" style="max-width:100%;"&gt;&lt;/a&gt;&lt;strong&gt;中国用户&lt;/strong&gt;, 请跳转至本仓库同步镜像&lt;a href="https://gitee.com/shengqiangzhang/examples-of-web-crawlers" rel="nofollow"&gt;码云Gitee&lt;/a&gt;进行下载, 以便获得较快的下载速度。&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-补充" class="anchor" aria-hidden="true" href="#补充"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;补充&lt;/h2&gt;
&lt;p&gt;项目持续更新，欢迎您&lt;a href="https://github.com/shengqiangzhang/examples-of-web-crawlers"&gt;star本项目&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://opensource.org/licenses/MIT" rel="nofollow"&gt;The MIT License (MIT)&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>shengqiangzhang</author><guid isPermaLink="false">https://github.com/shengqiangzhang/examples-of-web-crawlers</guid><pubDate>Fri, 20 Dec 2019 00:03:00 GMT</pubDate></item><item><title>programthink/zhao #4 in Python, This week</title><link>https://github.com/programthink/zhao</link><description>&lt;p&gt;&lt;i&gt;【编程随想】整理的《太子党关系网络》，专门揭露赵国的权贵&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="wiki" data-path="README.wiki"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;
&lt;p&gt;&lt;/p&gt;&lt;table id="user-content-toc" summary="Contents"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;div id="user-content-toctitle"&gt;&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h2&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="#"&gt;俺整理的《太子党关系网络》&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="#-2"&gt;简介&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#-3"&gt;下载说明&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#-4"&gt;多人协作说明&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#-5"&gt;数据格式说明&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#-6"&gt;目录说明&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="#data_"&gt;data 目录&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#bin_"&gt;bin 目录&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#download_"&gt;download 目录&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#-7"&gt;编译脚本使用说明&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="#-8"&gt;脚本的命令行参数&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#-9"&gt;依赖的软件&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#-10"&gt;致“反对此项目的墙内程序员”&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;a id="user-content-俺整理的太子党关系网络" class="anchor" aria-hidden="true" href="#俺整理的太子党关系网络"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name=""&gt;&lt;/a&gt;&lt;span id=""&gt;俺整理的《太子党关系网络》&lt;/span&gt;&lt;/h1&gt;




&lt;h2&gt;&lt;a id="user-content-简介" class="anchor" aria-hidden="true" href="#简介"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content--2"&gt;&lt;/a&gt;&lt;span id="user-content--2"&gt;简介&lt;/span&gt;&lt;/h2&gt;



&lt;p&gt;此项目创建于2016年2月，专门用来揭露天朝的权贵（也就是传说中的“赵家人”）。
&lt;/p&gt;
&lt;p&gt;俺把这几年收集整理的数据开源到 GitHub，便于多人协作——大伙儿群策群力，一起来曝光权贵家族。
&lt;/p&gt;
&lt;p&gt;初次上传的数据包括：700多个数据文件（ &lt;b&gt;对应700多人，130多个家族&lt;/b&gt; ），另有200多张图片（人物头像）。随着俺不断完善，数据会越来越多。
&lt;/p&gt;
&lt;p&gt;对这个项目，俺会【持续更新】。比如朝廷每次换届的时候，俺都会补充新的素材。
&lt;/p&gt;
&lt;p&gt;为了确保数据的可信度，俺主要参考“维基百科”以及一些国际权威媒体的报道（比如《纽约时报》、《华尔街日版》、《金融时报》等等）。
&lt;/p&gt;
&lt;p&gt;另外，对于某些客观事实（比如：生卒年月、简历、亲戚关系），俺也参考了天朝政府的官方网站，以及墙内的“百度百科”。
&lt;/p&gt;


&lt;h2&gt;&lt;a id="user-content-下载说明" class="anchor" aria-hidden="true" href="#下载说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content--3"&gt;&lt;/a&gt;&lt;span id="user-content--3"&gt;下载说明&lt;/span&gt;&lt;/h2&gt;



&lt;p&gt;GitHub 提供了“下载整个项目”的功能，但是会比较大。
&lt;/p&gt;
&lt;p&gt;如果你仅仅想看《太子党关系网络》这份文档，只需在首页上方点击进入 &lt;b&gt;download&lt;/b&gt; 这个目录。
&lt;/p&gt;
&lt;p&gt;该目录下有 &lt;b&gt;pdf&lt;/b&gt; 和 &lt;b&gt;jpg&lt;/b&gt; 两个子目录，分别存放对应的 &lt;b&gt;【文件类型】&lt;/b&gt; 。你想要看哪一种文件格式，就进入哪个子目录里面。
&lt;/p&gt;
&lt;p&gt;进入【文件类型】的子目录之后，会看到一个文件列表（目前有13个文件）。先点击你想要的某个文件，会进入该文件的页面。
&lt;/p&gt;
&lt;p&gt;然后在【右上方】你会看到一个 &lt;b&gt;Raw 按钮&lt;/b&gt; ，在这个按钮上点【右键】，在【右键菜单】里面选“保存”或“另存为”，就可以把这个文件下载到你本机。
&lt;/p&gt;


&lt;h2&gt;&lt;a id="user-content-多人协作说明" class="anchor" aria-hidden="true" href="#多人协作说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content--4"&gt;&lt;/a&gt;&lt;span id="user-content--4"&gt;多人协作说明&lt;/span&gt;&lt;/h2&gt;



&lt;p&gt;俺非常希望有更多的网友参与该项目，大伙儿一起来完善天朝权贵家族的资料。
&lt;/p&gt;
&lt;p&gt;想要参与的同学，可以通过如下方式：
&lt;/p&gt;






&lt;p&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;到&lt;a href="https://program-think.blogspot.com/" rel="nofollow"&gt;俺博客&lt;/a&gt;留言进行反馈，补充信息或反馈错误。&lt;/li&gt;&lt;li&gt;在&lt;a href="https://github.com/programthink/zhao/issues"&gt;本项目发一个 issue&lt;/a&gt;，补充信息或反馈错误。&lt;/li&gt;&lt;li&gt;Fork 该项目，进行修改，然后向俺发一个 Pull Request&lt;/li&gt;&lt;/ul&gt;
（后面两种方式，你需要有 GitHub 的帐号）
&lt;p&gt;&lt;/p&gt;


&lt;h2&gt;&lt;a id="user-content-数据格式说明" class="anchor" aria-hidden="true" href="#数据格式说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content--5"&gt;&lt;/a&gt;&lt;span id="user-content--5"&gt;数据格式说明&lt;/span&gt;&lt;/h2&gt;



&lt;p&gt;本项目的数据文件，全部采用&lt;a href="https://zh.wikipedia.org/wiki/YAML" rel="nofollow"&gt;YAML 格式&lt;/a&gt;。这种格式非常简洁明了，有利于完全不懂技术的网友参与编辑。
&lt;/p&gt;
&lt;p&gt;而且俺在每一个 YAML 格式的文件中都写了详细的注释，便于其他网友修改。
&lt;/p&gt;


&lt;h2&gt;&lt;a id="user-content-目录说明" class="anchor" aria-hidden="true" href="#目录说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content--6"&gt;&lt;/a&gt;&lt;span id="user-content--6"&gt;目录说明&lt;/span&gt;&lt;/h2&gt;




&lt;h3&gt;&lt;a id="user-content-data-目录" class="anchor" aria-hidden="true" href="#data-目录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-data_"&gt;&lt;/a&gt;&lt;span id="user-content-data_"&gt;data 目录&lt;/span&gt;&lt;/h3&gt;



&lt;p&gt;data 目录用来保存数据文件，该目录下另有如下三个子目录：
&lt;/p&gt;


&lt;p&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;person&lt;/li&gt;&lt;/ul&gt;
这个目录存放个人的资料，每个人一个目录，目录名就是人名。对于偶尔有同名的情况，在目录名末尾追加数字序号来区分。
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;每个目录下都有一个 brief.yaml 文件，包含此人的简介。
&lt;/p&gt;
&lt;p&gt;有些目录下还有一个 portrait.png 文件，对应此人的头像。
&lt;/p&gt;


&lt;p&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;company&lt;/li&gt;&lt;/ul&gt;
这个目录存放与太子党有关的公司或组织机构。目录结构与 person 类似。
&lt;p&gt;&lt;/p&gt;


&lt;p&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;family&lt;/li&gt;&lt;/ul&gt;
这个目录存放家族关系的信息。每个家族是一个 yaml 格式的文件。
&lt;p&gt;&lt;/p&gt;

&lt;h3&gt;&lt;a id="user-content-bin-目录" class="anchor" aria-hidden="true" href="#bin-目录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-bin_"&gt;&lt;/a&gt;&lt;span id="user-content-bin_"&gt;bin 目录&lt;/span&gt;&lt;/h3&gt;



&lt;p&gt;该目录存放编译脚本。该脚本的使用参见下面的章节。
&lt;/p&gt;

&lt;h3&gt;&lt;a id="user-content-download-目录" class="anchor" aria-hidden="true" href="#download-目录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-download_"&gt;&lt;/a&gt;&lt;span id="user-content-download_"&gt;download 目录&lt;/span&gt;&lt;/h3&gt;



&lt;p&gt;该目录存放制作好的文件，目前先提供 jpg 和 pdf 两种格式。
&lt;/p&gt;
&lt;p&gt;如果你需要其它格式，可以用 bin 目录下的编译脚本自行搞定（编译脚本的使用，参见下面的章节）。
&lt;/p&gt;


&lt;h2&gt;&lt;a id="user-content-编译脚本使用说明" class="anchor" aria-hidden="true" href="#编译脚本使用说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content--7"&gt;&lt;/a&gt;&lt;span id="user-content--7"&gt;编译脚本使用说明&lt;/span&gt;&lt;/h2&gt;



&lt;p&gt;（俺是在 Linux 上编写该脚本，尚未在 Windows 上进行测试）
&lt;/p&gt;
&lt;p&gt;如果你在 Windows 上使用碰到问题，可以到&lt;a href="https://program-think.blogspot.com/" rel="nofollow"&gt;俺博客&lt;/a&gt;留言进行反馈。也可以在&lt;a href="https://github.com/programthink/zhao/issues"&gt;本项目发一个 issue&lt;/a&gt;。
&lt;/p&gt;

&lt;h3&gt;&lt;a id="user-content-脚本的命令行参数" class="anchor" aria-hidden="true" href="#脚本的命令行参数"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content--8"&gt;&lt;/a&gt;&lt;span id="user-content--8"&gt;脚本的命令行参数&lt;/span&gt;&lt;/h3&gt;



&lt;p&gt;俺使用 python 作为编译脚本，该脚本位于 bin 目录下。
&lt;/p&gt;
&lt;p&gt;通过该脚本可以把原始数据生成为 dot 语言的脚本。然后再调用 Graphviz 把 dot 脚本生成各种格式（比如：pdf、jpeg）。
&lt;/p&gt;
&lt;p&gt;要使用该脚本，先在命令行模式下进入 bin 目录，然后运行如下命令：
&lt;/p&gt;
&lt;p&gt;（生成 pdf 格式的示例）
&lt;/p&gt;
&lt;p&gt;&lt;b&gt;python make.py pdf&lt;/b&gt;
&lt;/p&gt;
&lt;p&gt;（生成 jpg 格式的示例）
&lt;/p&gt;
&lt;p&gt;&lt;b&gt;python make.py jpg&lt;/b&gt;
&lt;/p&gt;

&lt;h3&gt;&lt;a id="user-content-依赖的软件" class="anchor" aria-hidden="true" href="#依赖的软件"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content--9"&gt;&lt;/a&gt;&lt;span id="user-content--9"&gt;依赖的软件&lt;/span&gt;&lt;/h3&gt;



&lt;p&gt;要使用上述脚本，你需要事先安装相关的软件（如下）
&lt;/p&gt;


&lt;p&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Python（2 或 3）&lt;/li&gt;&lt;/ul&gt;
因为俺用的是 Python 脚本，所以你需要先安装 python 软件。
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;目前 Python 有两种大版本——python2 和 python3——俺的编译脚本 &lt;b&gt;【同时兼容】&lt;/b&gt; 这两种 Python 的大版本。
&lt;/p&gt;
&lt;p&gt;对于 Python 的小版本，俺本人在 &lt;b&gt;2.7&lt;/b&gt; 和 &lt;b&gt;3.5&lt;/b&gt; 上测试通过。2.6 和 3.4 估计也可以。
&lt;/p&gt;


&lt;p&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;PyYAML&lt;/li&gt;&lt;/ul&gt;
这是一个基于 python 开发的软件包，专门用来处理 YAML 格式的文件。
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;你需要在你的 python 环境中安装该软件包。其官方链接如下：
&lt;/p&gt;
&lt;p&gt;&lt;a href="http://pyyaml.org/wiki/PyYAML" rel="nofollow"&gt;PyYAML 的官网的 wiki&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;&lt;a href="https://pypi.python.org/pypi/PyYAML" rel="nofollow"&gt;Python 官网的 PYPI&lt;/a&gt;
&lt;/p&gt;


&lt;p&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Graphviz&lt;/li&gt;&lt;/ul&gt;
这个软件是用来生成【关系图】的。关于该这个软件，俺已经写了一篇扫盲教程：
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;《&lt;a href="https://program-think.blogspot.com/2016/02/opensource-review-graphviz.html" rel="nofollow"&gt;开源项目：【自动】绘图工具Graphviz——《太子党关系网络》就是用它制作&lt;/a&gt;》
&lt;/p&gt;


&lt;h2&gt;&lt;a id="user-content-致反对此项目的墙内程序员" class="anchor" aria-hidden="true" href="#致反对此项目的墙内程序员"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content--10"&gt;&lt;/a&gt;&lt;span id="user-content--10"&gt;致“反对此项目的墙内程序员”&lt;/span&gt;&lt;/h2&gt;



&lt;p&gt;本项目上线第二天，就收获 363 个 star 兼 88 个 fork，甚至还挤进 GitHub 的“当日 Trending”——俺很荣幸，也很高兴有这么多人给俺捧场。
&lt;/p&gt;
&lt;p&gt;但是在&lt;a href="https://github.com/programthink/zhao/issues"&gt;本项目的 issue 列表&lt;/a&gt;中也看到好几个反对此项目的程序员（应该都来自墙内），他们担心这个项目导致 GitHub 被 GFW 封杀。
&lt;/p&gt;
&lt;p&gt;这几年来，类似的言论俺已经看了不少。就好比强盗拿刀杀人，围观者不但没有谴责强盗，反而去谴责卖刀的店家——这就是传说中的“斯德哥尔摩综合症”。
&lt;/p&gt;
&lt;p&gt;有兴趣的同学，可以看俺之前的博文——《&lt;a href="https://program-think.blogspot.com/2012/06/stockholm-syndrome.html" rel="nofollow"&gt;天朝民众的心理分析：斯德哥尔摩综合症&lt;/a&gt;》&lt;/p&gt;&lt;/article&gt;&lt;/div&gt;</description><author>programthink</author><guid isPermaLink="false">https://github.com/programthink/zhao</guid><pubDate>Fri, 20 Dec 2019 00:04:00 GMT</pubDate></item><item><title>luka1199/geo-heatmap #5 in Python, This week</title><link>https://github.com/luka1199/geo-heatmap</link><description>&lt;p&gt;&lt;i&gt;:world_map: Generate an interactive geo heatmap from your Google location data&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-geo-heatmap" class="anchor" aria-hidden="true" href="#geo-heatmap"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Geo Heatmap&lt;/h1&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/45404400/63515170-7a9cd280-c4ea-11e9-8875-e693622ac26e.png"&gt;&lt;img src="https://user-images.githubusercontent.com/45404400/63515170-7a9cd280-c4ea-11e9-8875-e693622ac26e.png" alt="screenshot" width="400" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a script that generates an interactive geo heatmap from your Google location history data using Python, Folium and OpenStreetMap.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-1-install-python-3" class="anchor" aria-hidden="true" href="#1-install-python-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Install Python 3+&lt;/h3&gt;
&lt;p&gt;If you don't already have Python 3+ installed, grab it from &lt;a href="https://www.python.org/downloads/" rel="nofollow"&gt;https://www.python.org/downloads/&lt;/a&gt;. You'll want to download install the latest version of &lt;strong&gt;Python 3.x&lt;/strong&gt;. As of 2019-11-22, that is Version 3.8.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-2-get-your-location-data" class="anchor" aria-hidden="true" href="#2-get-your-location-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Get Your Location Data&lt;/h3&gt;
&lt;p&gt;Here you can find out how to download your Google data: &lt;a href="https://support.google.com/accounts/answer/3024190?hl=en" rel="nofollow"&gt;https://support.google.com/accounts/answer/3024190?hl=en&lt;/a&gt;&lt;br&gt;
Here you can download all of the data that Google has stored on you: &lt;a href="https://takeout.google.com/" rel="nofollow"&gt;https://takeout.google.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To use this script, you only need to select and download your "Location History", which Google will provide to you as a JSON file by default.  KML is also an output option and is accepted for this program.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-3-clone-this-repository" class="anchor" aria-hidden="true" href="#3-clone-this-repository"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. Clone This Repository&lt;/h3&gt;
&lt;p&gt;On &lt;a href="https://github.com/luka1199/geo-heatmap"&gt;https://github.com/luka1199/geo-heatmap&lt;/a&gt;, click the green "Clone or Download" button at the top right of the page. If you want to get started with this script more quickly, click the "Download ZIP" button, and extract the ZIP somewhere on your computer.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-4-install-dependencies" class="anchor" aria-hidden="true" href="#4-install-dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4. Install Dependencies&lt;/h3&gt;
&lt;p&gt;In a &lt;a href="https://tutorial.djangogirls.org/en/intro_to_command_line/#what-is-the-command-line" rel="nofollow"&gt;command prompt or Terminal window&lt;/a&gt;, &lt;a href="https://tutorial.djangogirls.org/en/intro_to_command_line/#change-current-directory" rel="nofollow"&gt;navigate to the directory&lt;/a&gt; containing this repository's files. Then, type the following, and press enter:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install -r requirements.txt&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-5-run-the-script" class="anchor" aria-hidden="true" href="#5-run-the-script"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;5. Run the Script&lt;/h3&gt;
&lt;p&gt;In the same command prompt or Terminal window, type the following, and press enter:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python geo_heatmap.py &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;file&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; [&lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;file&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; ...]&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Replace the string &lt;code&gt;&amp;lt;file&amp;gt;&lt;/code&gt; from above with the path to any of the following files:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The &lt;code&gt;Location History.json&lt;/code&gt; JSON file from Google Takeout&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;Location History.kml&lt;/code&gt; KML file from Google Takeout&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;takeout-*.zip&lt;/code&gt; raw download from Google Takeout that contains either of the above files&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples:&lt;/h4&gt;
&lt;p&gt;Single file:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python geo_heatmap.py C:&lt;span class="pl-cce"&gt;\U&lt;/span&gt;sers&lt;span class="pl-cce"&gt;\T&lt;/span&gt;estuser&lt;span class="pl-cce"&gt;\D&lt;/span&gt;esktop&lt;span class="pl-cce"&gt;\l&lt;/span&gt;ocations.json&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python geo_heatmap.py &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;C:\Users\Testuser\Desktop\Location History.json&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python geo_heatmap.py locations.json&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Multiple files:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python geo_heatmap.py locations.json locations.kml takeout.zip&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Using the stream option (for users with Memory Errors):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python geo_heatmap.py -s locations.json&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Set a date range:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python geo_heatmap.py --min-date 2017-01-02 --max-date 2018-12-30 locations.json&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage:&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;usage: geo_heatmap.py [-h] [-o] [--min-date YYYY-MM-DD]
                      [--max-date YYYY-MM-DD] [-s] [--map MAP]
                      file [file ...]

positional arguments:
  file                  Any of the following files:
                        1. Your location history JSON file from Google Takeout
                        2. Your location history KML file from Google Takeout
                        3. The takeout-*.zip raw download from Google Takeout
                        that contains either of the above files

optional arguments:
  -h, --help            show this help message and exit
  -o , --output         Path of heatmap HTML output file.
  --min-date YYYY-MM-DD
                        The earliest date from which you want to see data in the heatmap.
  --max-date YYYY-MM-DD
                        The latest date from which you want to see data in the heatmap.
  -s, --stream          Option to iteratively load data.
  --map MAP, -m MAP     The name of the map tiles you want to use.
                        (e.g. 'OpenStreetMap', 'StamenTerrain', 'StamenToner', 'StamenWatercolor')
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-6-review-the-results" class="anchor" aria-hidden="true" href="#6-review-the-results"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;6. Review the Results&lt;/h3&gt;
&lt;p&gt;The script will generate a HTML file named &lt;code&gt;heatmap.html&lt;/code&gt;. This file will automatically open in your browser once the script completes. Enjoy!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-faq" class="anchor" aria-hidden="true" href="#faq"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FAQ&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-im-getting-an-out-of-memory-error-or-memoryerror-when-i-try-to-run-the-script-whats-going-on" class="anchor" aria-hidden="true" href="#im-getting-an-out-of-memory-error-or-memoryerror-when-i-try-to-run-the-script-whats-going-on"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;I'm getting an "Out of Memory" error or &lt;code&gt;MemoryError&lt;/code&gt; when I try to run the script. What's going on?&lt;/h3&gt;
&lt;p&gt;Your &lt;code&gt;LocationHistory.json&lt;/code&gt; file is probably huge, and Python is running out of memory when the script tries to parse that file.&lt;/p&gt;
&lt;p&gt;To fix this, download and install the 64-bit version of Python. To do this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;a href="https://www.python.org/downloads/" rel="nofollow"&gt;python.org&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Click the link corresponding to your OS next to "Looking for Python with a different OS?"&lt;/li&gt;
&lt;li&gt;Click the "Latest Python 3 Release" link.&lt;/li&gt;
&lt;li&gt;Scroll down to "Files".&lt;/li&gt;
&lt;li&gt;Click to download the x64 release. For example, on Windows, that's the "Windows x86-64 executable installer" link.&lt;/li&gt;
&lt;li&gt;Install!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If this does not fix the issue you can use the stream option:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python geo_heatmap.py -s &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;file&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will be slower but will use much less memory to load your location data.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-im-getting-a-syntaxerror-when-running-pip-install--r-requirementstxt-or-python-geo_heatmappy-file-what-am-i-doing-wrong" class="anchor" aria-hidden="true" href="#im-getting-a-syntaxerror-when-running-pip-install--r-requirementstxt-or-python-geo_heatmappy-file-what-am-i-doing-wrong"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;I'm getting a &lt;code&gt;SyntaxError&lt;/code&gt; when running &lt;code&gt;pip install -r requirements.txt&lt;/code&gt; or &lt;code&gt;python geo_heatmap.py &amp;lt;file&amp;gt;&lt;/code&gt;. What am I doing wrong?&lt;/h3&gt;
&lt;p&gt;You are probably using the python interpreter to run these commands. Try to run them in cmd.exe or Windows PowerShell (Windows) or the Terminal (Linux, MacOS).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-im-getting-the-error-message-typeerror-__init__-got-an-unexpected-keyword-argument-max_value-what-can-i-do-to-fix-this" class="anchor" aria-hidden="true" href="#im-getting-the-error-message-typeerror-__init__-got-an-unexpected-keyword-argument-max_value-what-can-i-do-to-fix-this"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;I'm getting the error message &lt;code&gt;TypeError: __init__() got an unexpected keyword argument 'max_value'&lt;/code&gt;. What can I do to fix this?&lt;/h3&gt;
&lt;p&gt;Try to run:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip uninstall progressbar
pip install progressbar2&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You probably have progressbar installed, which uses &lt;code&gt;maxval&lt;/code&gt; as an argument for &lt;code&gt;__init__&lt;/code&gt;. Progressbar2 uses &lt;code&gt;max_value&lt;/code&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>luka1199</author><guid isPermaLink="false">https://github.com/luka1199/geo-heatmap</guid><pubDate>Fri, 20 Dec 2019 00:05:00 GMT</pubDate></item><item><title>soimort/you-get #6 in Python, This week</title><link>https://github.com/soimort/you-get</link><description>&lt;p&gt;&lt;i&gt;:arrow_double_down: Dumb downloader that scrapes the web&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-you-get" class="anchor" aria-hidden="true" href="#you-get"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;You-Get&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://pypi.python.org/pypi/you-get/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/59a8468e96c17f2aad012be69c1364f393073a69/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f796f752d6765742e737667" alt="PyPI version" data-canonical-src="https://img.shields.io/pypi/v/you-get.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.org/soimort/you-get" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ecb41bc19c41a53ecdc7dc7e44d195b6c1cfcde2/68747470733a2f2f7472617669732d63692e6f72672f736f696d6f72742f796f752d6765742e737667" alt="Build Status" data-canonical-src="https://travis-ci.org/soimort/you-get.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/soimort/you-get?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTICE: Read &lt;a href="https://github.com/soimort/you-get/blob/develop/CONTRIBUTING.md"&gt;this&lt;/a&gt; if you are looking for the conventional "Issues" tab.&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href="https://you-get.org/" rel="nofollow"&gt;You-Get&lt;/a&gt; is a tiny command-line utility to download media contents (videos, audios, images) from the Web, in case there is no other handy way to do it.&lt;/p&gt;
&lt;p&gt;Here's how you use &lt;code&gt;you-get&lt;/code&gt; to download a video from &lt;a href="https://www.youtube.com/watch?v=jNQXAC9IVRw" rel="nofollow"&gt;YouTube&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;$ &lt;span class="pl-s1"&gt;you-get &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;https://www.youtube.com/watch?v=jNQXAC9IVRw&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c1"&gt;site:                YouTube&lt;/span&gt;
&lt;span class="pl-c1"&gt;title:               Me at the zoo&lt;/span&gt;
&lt;span class="pl-c1"&gt;stream:&lt;/span&gt;
&lt;span class="pl-c1"&gt;    - itag:          43&lt;/span&gt;
&lt;span class="pl-c1"&gt;      container:     webm&lt;/span&gt;
&lt;span class="pl-c1"&gt;      quality:       medium&lt;/span&gt;
&lt;span class="pl-c1"&gt;      size:          0.5 MiB (564215 bytes)&lt;/span&gt;
&lt;span class="pl-c1"&gt;    # download-with: you-get --itag=43 [URL]&lt;/span&gt;

&lt;span class="pl-c1"&gt;Downloading Me at the zoo.webm ...&lt;/span&gt;
&lt;span class="pl-c1"&gt; 100% (  0.5/  0.5MB) ├██████████████████████████████████┤[1/1]    6 MB/s&lt;/span&gt;

&lt;span class="pl-c1"&gt;Saving Me at the zoo.en.srt ... Done.&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And here's why you might want to use it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You enjoyed something on the Internet, and just want to download them for your own pleasure.&lt;/li&gt;
&lt;li&gt;You watch your favorite videos online from your computer, but you are prohibited from saving them. You feel that you have no control over your own computer. (And it's not how an open Web is supposed to work.)&lt;/li&gt;
&lt;li&gt;You want to get rid of any closed-source technology or proprietary JavaScript code, and disallow things like Flash running on your computer.&lt;/li&gt;
&lt;li&gt;You are an adherent of hacker culture and free software.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What &lt;code&gt;you-get&lt;/code&gt; can do for you:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download videos / audios from popular websites such as YouTube, Youku, Niconico, and a bunch more. (See the &lt;a href="#supported-sites"&gt;full list of supported sites&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Stream an online video in your media player. No web browser, no more ads.&lt;/li&gt;
&lt;li&gt;Download images (of interest) by scraping a web page.&lt;/li&gt;
&lt;li&gt;Download arbitrary non-HTML contents, i.e., binary files.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Interested? &lt;a href="#installation"&gt;Install it&lt;/a&gt; now and &lt;a href="#getting-started"&gt;get started by examples&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Are you a Python programmer? Then check out &lt;a href="https://github.com/soimort/you-get"&gt;the source&lt;/a&gt; and fork it!&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/af66ed3ad2d9fd159b9f5fdc92ba0a1804cff642/68747470733a2f2f692e696d6775722e636f6d2f4766746846417a2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/af66ed3ad2d9fd159b9f5fdc92ba0a1804cff642/68747470733a2f2f692e696d6775722e636f6d2f4766746846417a2e706e67" alt="" data-canonical-src="https://i.imgur.com/GfthFAz.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prerequisites&lt;/h3&gt;
&lt;p&gt;The following dependencies are necessary:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://www.python.org/downloads/" rel="nofollow"&gt;Python&lt;/a&gt;&lt;/strong&gt;  3.2 or above&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://www.ffmpeg.org/" rel="nofollow"&gt;FFmpeg&lt;/a&gt;&lt;/strong&gt; 1.0 or above&lt;/li&gt;
&lt;li&gt;(Optional) &lt;a href="https://rtmpdump.mplayerhq.hu/" rel="nofollow"&gt;RTMPDump&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-option-1-install-via-pip" class="anchor" aria-hidden="true" href="#option-1-install-via-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 1: Install via pip&lt;/h3&gt;
&lt;p&gt;The official release of &lt;code&gt;you-get&lt;/code&gt; is distributed on &lt;a href="https://pypi.python.org/pypi/you-get" rel="nofollow"&gt;PyPI&lt;/a&gt;, and can be installed easily from a PyPI mirror via the &lt;a href="https://en.wikipedia.org/wiki/Pip_(package_manager)" rel="nofollow"&gt;pip&lt;/a&gt; package manager. Note that you must use the Python 3 version of &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pip3 install you-get
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-option-2-install-via-antigen-for-zsh-users" class="anchor" aria-hidden="true" href="#option-2-install-via-antigen-for-zsh-users"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 2: Install via &lt;a href="https://github.com/zsh-users/antigen"&gt;Antigen&lt;/a&gt; (for Zsh users)&lt;/h3&gt;
&lt;p&gt;Add the following line to your &lt;code&gt;.zshrc&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;antigen bundle soimort/you-get
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-option-3-download-from-github" class="anchor" aria-hidden="true" href="#option-3-download-from-github"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 3: Download from GitHub&lt;/h3&gt;
&lt;p&gt;You may either download the &lt;a href="https://github.com/soimort/you-get/archive/master.zip"&gt;stable&lt;/a&gt; (identical with the latest release on PyPI) or the &lt;a href="https://github.com/soimort/you-get/archive/develop.zip"&gt;develop&lt;/a&gt; (more hotfixes, unstable features) branch of &lt;code&gt;you-get&lt;/code&gt;. Unzip it, and put the directory containing the &lt;code&gt;you-get&lt;/code&gt; script into your &lt;code&gt;PATH&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Alternatively, run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ [sudo] python3 setup.py install
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 setup.py install --user
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to install &lt;code&gt;you-get&lt;/code&gt; to a permanent path.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-option-4-git-clone" class="anchor" aria-hidden="true" href="#option-4-git-clone"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 4: Git clone&lt;/h3&gt;
&lt;p&gt;This is the recommended way for all developers, even if you don't often code in Python.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone git://github.com/soimort/you-get.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then put the cloned directory into your &lt;code&gt;PATH&lt;/code&gt;, or run &lt;code&gt;./setup.py install&lt;/code&gt; to install &lt;code&gt;you-get&lt;/code&gt; to a permanent path.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-option-5-homebrew-mac-only" class="anchor" aria-hidden="true" href="#option-5-homebrew-mac-only"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 5: Homebrew (Mac only)&lt;/h3&gt;
&lt;p&gt;You can install &lt;code&gt;you-get&lt;/code&gt; easily via:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ brew install you-get
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-option-6-pkg-freebsd-only" class="anchor" aria-hidden="true" href="#option-6-pkg-freebsd-only"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 6: pkg (FreeBSD only)&lt;/h3&gt;
&lt;p&gt;You can install &lt;code&gt;you-get&lt;/code&gt; easily via:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# pkg install you-get
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-shell-completion" class="anchor" aria-hidden="true" href="#shell-completion"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Shell completion&lt;/h3&gt;
&lt;p&gt;Completion definitions for Bash, Fish and Zsh can be found in &lt;a href="https://github.com/soimort/you-get/tree/develop/contrib/completion"&gt;&lt;code&gt;contrib/completion&lt;/code&gt;&lt;/a&gt;. Please consult your shell's manual for how to take advantage of them.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-upgrading" class="anchor" aria-hidden="true" href="#upgrading"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Upgrading&lt;/h2&gt;
&lt;p&gt;Based on which option you chose to install &lt;code&gt;you-get&lt;/code&gt;, you may upgrade it via:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pip3 install --upgrade you-get
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or download the latest release via:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get https://github.com/soimort/you-get/archive/master.zip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to get the latest &lt;code&gt;develop&lt;/code&gt; branch without messing up the PIP, you can try:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pip3 install --upgrade git+https://github.com/soimort/you-get@develop
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-download-a-video" class="anchor" aria-hidden="true" href="#download-a-video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Download a video&lt;/h3&gt;
&lt;p&gt;When you get a video of interest, you might want to use the &lt;code&gt;--info&lt;/code&gt;/&lt;code&gt;-i&lt;/code&gt; option to see all available quality and formats:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get -i 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
site:                YouTube
title:               Me at the zoo
streams:             # Available quality and codecs
    [ DASH ] ____________________________________
    - itag:          242
      container:     webm
      quality:       320x240
      size:          0.6 MiB (618358 bytes)
    # download-with: you-get --itag=242 [URL]

    - itag:          395
      container:     mp4
      quality:       320x240
      size:          0.5 MiB (550743 bytes)
    # download-with: you-get --itag=395 [URL]

    - itag:          133
      container:     mp4
      quality:       320x240
      size:          0.5 MiB (498558 bytes)
    # download-with: you-get --itag=133 [URL]

    - itag:          278
      container:     webm
      quality:       192x144
      size:          0.4 MiB (392857 bytes)
    # download-with: you-get --itag=278 [URL]

    - itag:          160
      container:     mp4
      quality:       192x144
      size:          0.4 MiB (370882 bytes)
    # download-with: you-get --itag=160 [URL]

    - itag:          394
      container:     mp4
      quality:       192x144
      size:          0.4 MiB (367261 bytes)
    # download-with: you-get --itag=394 [URL]

    [ DEFAULT ] _________________________________
    - itag:          43
      container:     webm
      quality:       medium
      size:          0.5 MiB (568748 bytes)
    # download-with: you-get --itag=43 [URL]

    - itag:          18
      container:     mp4
      quality:       small
    # download-with: you-get --itag=18 [URL]

    - itag:          36
      container:     3gp
      quality:       small
    # download-with: you-get --itag=36 [URL]

    - itag:          17
      container:     3gp
      quality:       small
    # download-with: you-get --itag=17 [URL]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, the one on the top is the one you will get. If that looks cool to you, download it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
site:                YouTube
title:               Me at the zoo
stream:
    - itag:          242
      container:     webm
      quality:       320x240
      size:          0.6 MiB (618358 bytes)
    # download-with: you-get --itag=242 [URL]

Downloading Me at the zoo.webm ...
 100% (  0.6/  0.6MB) ├██████████████████████████████████████████████████████████████████████████████┤[2/2]    2 MB/s
Merging video parts... Merged into Me at the zoo.webm

Saving Me at the zoo.en.srt ... Done.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(If a YouTube video has any closed captions, they will be downloaded together with the video file, in SubRip subtitle format.)&lt;/p&gt;
&lt;p&gt;Or, if you prefer another format (mp4), just use whatever the option &lt;code&gt;you-get&lt;/code&gt; shows to you:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get --itag=18 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;At this point, format selection has not been generally implemented for most of our supported sites; in that case, the default format to download is the one with the highest quality.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ffmpeg&lt;/code&gt; is a required dependency, for downloading and joining videos streamed in multiple parts (e.g. on some sites like Youku), and for YouTube videos of 1080p or high resolution.&lt;/li&gt;
&lt;li&gt;If you don't want &lt;code&gt;you-get&lt;/code&gt; to join video parts after downloading them, use the &lt;code&gt;--no-merge&lt;/code&gt;/&lt;code&gt;-n&lt;/code&gt; option.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-download-anything-else" class="anchor" aria-hidden="true" href="#download-anything-else"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Download anything else&lt;/h3&gt;
&lt;p&gt;If you already have the URL of the exact resource you want, you can download it directly with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get https://stallman.org/rms.jpg
Site:       stallman.org
Title:      rms
Type:       JPEG Image (image/jpeg)
Size:       0.06 MiB (66482 Bytes)

Downloading rms.jpg ...
100.0% (  0.1/0.1  MB) ├████████████████████████████████████████┤[1/1]  127 kB/s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Otherwise, &lt;code&gt;you-get&lt;/code&gt; will scrape the web page and try to figure out if there's anything interesting to you:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get http://kopasas.tumblr.com/post/69361932517
Site:       Tumblr.com
Title:      kopasas
Type:       Unknown type (None)
Size:       0.51 MiB (536583 Bytes)

Site:       Tumblr.com
Title:      tumblr_mxhg13jx4n1sftq6do1_1280
Type:       Portable Network Graphics (image/png)
Size:       0.51 MiB (536583 Bytes)

Downloading tumblr_mxhg13jx4n1sftq6do1_1280.png ...
100.0% (  0.5/0.5  MB) ├████████████████████████████████████████┤[1/1]   22 MB/s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This feature is an experimental one and far from perfect. It works best on scraping large-sized images from popular websites like Tumblr and Blogger, but there is really no universal pattern that can apply to any site on the Internet.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-search-on-google-videos-and-download" class="anchor" aria-hidden="true" href="#search-on-google-videos-and-download"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Search on Google Videos and download&lt;/h3&gt;
&lt;p&gt;You can pass literally anything to &lt;code&gt;you-get&lt;/code&gt;. If it isn't a valid URL, &lt;code&gt;you-get&lt;/code&gt; will do a Google search and download the most relevant video for you. (It might not be exactly the thing you wish to see, but still very likely.)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get "Richard Stallman eats"
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-pause-and-resume-a-download" class="anchor" aria-hidden="true" href="#pause-and-resume-a-download"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pause and resume a download&lt;/h3&gt;
&lt;p&gt;You may use &lt;kbd&gt;Ctrl&lt;/kbd&gt;+&lt;kbd&gt;C&lt;/kbd&gt; to interrupt a download.&lt;/p&gt;
&lt;p&gt;A temporary &lt;code&gt;.download&lt;/code&gt; file is kept in the output directory. Next time you run &lt;code&gt;you-get&lt;/code&gt; with the same arguments, the download progress will resume from the last session. In case the file is completely downloaded (the temporary &lt;code&gt;.download&lt;/code&gt; extension is gone), &lt;code&gt;you-get&lt;/code&gt; will just skip the download.&lt;/p&gt;
&lt;p&gt;To enforce re-downloading, use the &lt;code&gt;--force&lt;/code&gt;/&lt;code&gt;-f&lt;/code&gt; option. (&lt;strong&gt;Warning:&lt;/strong&gt; doing so will overwrite any existing file or temporary file with the same name!)&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-set-the-path-and-name-of-downloaded-file" class="anchor" aria-hidden="true" href="#set-the-path-and-name-of-downloaded-file"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Set the path and name of downloaded file&lt;/h3&gt;
&lt;p&gt;Use the &lt;code&gt;--output-dir&lt;/code&gt;/&lt;code&gt;-o&lt;/code&gt; option to set the path, and &lt;code&gt;--output-filename&lt;/code&gt;/&lt;code&gt;-O&lt;/code&gt; to set the name of the downloaded file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get -o ~/Videos -O zoo.webm 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Tips:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;These options are helpful if you encounter problems with the default video titles, which may contain special characters that do not play well with your current shell / operating system / filesystem.&lt;/li&gt;
&lt;li&gt;These options are also helpful if you write a script to batch download files and put them into designated folders with designated names.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-proxy-settings" class="anchor" aria-hidden="true" href="#proxy-settings"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Proxy settings&lt;/h3&gt;
&lt;p&gt;You may specify an HTTP proxy for &lt;code&gt;you-get&lt;/code&gt; to use, via the &lt;code&gt;--http-proxy&lt;/code&gt;/&lt;code&gt;-x&lt;/code&gt; option:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get -x 127.0.0.1:8087 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, the system proxy setting (i.e. the environment variable &lt;code&gt;http_proxy&lt;/code&gt;) is applied by default. To disable any proxy, use the &lt;code&gt;--no-proxy&lt;/code&gt; option.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tips:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you need to use proxies a lot (in case your network is blocking certain sites), you might want to use &lt;code&gt;you-get&lt;/code&gt; with &lt;a href="https://github.com/rofl0r/proxychains-ng"&gt;proxychains&lt;/a&gt; and set &lt;code&gt;alias you-get="proxychains -q you-get"&lt;/code&gt; (in Bash).&lt;/li&gt;
&lt;li&gt;For some websites (e.g. Youku), if you need access to some videos that are only available in mainland China, there is an option of using a specific proxy to extract video information from the site: &lt;code&gt;--extractor-proxy&lt;/code&gt;/&lt;code&gt;-y&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-watch-a-video" class="anchor" aria-hidden="true" href="#watch-a-video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Watch a video&lt;/h3&gt;
&lt;p&gt;Use the &lt;code&gt;--player&lt;/code&gt;/&lt;code&gt;-p&lt;/code&gt; option to feed the video into your media player of choice, e.g. &lt;code&gt;mpv&lt;/code&gt; or &lt;code&gt;vlc&lt;/code&gt;, instead of downloading it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get -p vlc 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or, if you prefer to watch the video in a browser, just without ads or comment section:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get -p chromium 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Tips:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is possible to use the &lt;code&gt;-p&lt;/code&gt; option to start another download manager, e.g., &lt;code&gt;you-get -p uget-gtk 'https://www.youtube.com/watch?v=jNQXAC9IVRw'&lt;/code&gt;, though they may not play together very well.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-load-cookies" class="anchor" aria-hidden="true" href="#load-cookies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Load cookies&lt;/h3&gt;
&lt;p&gt;Not all videos are publicly available to anyone. If you need to log in your account to access something (e.g., a private video), it would be unavoidable to feed the browser cookies to &lt;code&gt;you-get&lt;/code&gt; via the &lt;code&gt;--cookies&lt;/code&gt;/&lt;code&gt;-c&lt;/code&gt; option.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As of now, we are supporting two formats of browser cookies: Mozilla &lt;code&gt;cookies.sqlite&lt;/code&gt; and Netscape &lt;code&gt;cookies.txt&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-reuse-extracted-data" class="anchor" aria-hidden="true" href="#reuse-extracted-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reuse extracted data&lt;/h3&gt;
&lt;p&gt;Use &lt;code&gt;--url&lt;/code&gt;/&lt;code&gt;-u&lt;/code&gt; to get a list of downloadable resource URLs extracted from the page. Use &lt;code&gt;--json&lt;/code&gt; to get an abstract of extracted data in the JSON format.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For the time being, this feature has &lt;strong&gt;NOT&lt;/strong&gt; been stabilized and the JSON schema may have breaking changes in the future.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-supported-sites" class="anchor" aria-hidden="true" href="#supported-sites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Supported Sites&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Site&lt;/th&gt;
&lt;th align="left"&gt;URL&lt;/th&gt;
&lt;th align="center"&gt;Videos?&lt;/th&gt;
&lt;th align="center"&gt;Images?&lt;/th&gt;
&lt;th align="center"&gt;Audios?&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;YouTube&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.youtube.com/" rel="nofollow"&gt;https://www.youtube.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Twitter&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://twitter.com/" rel="nofollow"&gt;https://twitter.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;VK&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://vk.com/" rel="nofollow"&gt;http://vk.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Vine&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://vine.co/" rel="nofollow"&gt;https://vine.co/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Vimeo&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://vimeo.com/" rel="nofollow"&gt;https://vimeo.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Vidto&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://vidto.me/" rel="nofollow"&gt;http://vidto.me/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Videomega&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://videomega.tv/" rel="nofollow"&gt;http://videomega.tv/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Veoh&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.veoh.com/" rel="nofollow"&gt;http://www.veoh.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Tumblr&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.tumblr.com/" rel="nofollow"&gt;https://www.tumblr.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;TED&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.ted.com/" rel="nofollow"&gt;http://www.ted.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;SoundCloud&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://soundcloud.com/" rel="nofollow"&gt;https://soundcloud.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;SHOWROOM&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.showroom-live.com/" rel="nofollow"&gt;https://www.showroom-live.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Pinterest&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.pinterest.com/" rel="nofollow"&gt;https://www.pinterest.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;MusicPlayOn&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://en.musicplayon.com/" rel="nofollow"&gt;http://en.musicplayon.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;MTV81&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.mtv81.com/" rel="nofollow"&gt;http://www.mtv81.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Mixcloud&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.mixcloud.com/" rel="nofollow"&gt;https://www.mixcloud.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Metacafe&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.metacafe.com/" rel="nofollow"&gt;http://www.metacafe.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Magisto&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.magisto.com/" rel="nofollow"&gt;http://www.magisto.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Khan Academy&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.khanacademy.org/" rel="nofollow"&gt;https://www.khanacademy.org/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Internet Archive&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://archive.org/" rel="nofollow"&gt;https://archive.org/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Instagram&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://instagram.com/" rel="nofollow"&gt;https://instagram.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;InfoQ&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.infoq.com/presentations/" rel="nofollow"&gt;http://www.infoq.com/presentations/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Imgur&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://imgur.com/" rel="nofollow"&gt;http://imgur.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Heavy Music Archive&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.heavy-music.ru/" rel="nofollow"&gt;http://www.heavy-music.ru/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Google+&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://plus.google.com/" rel="nofollow"&gt;https://plus.google.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Freesound&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.freesound.org/" rel="nofollow"&gt;http://www.freesound.org/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Flickr&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.flickr.com/" rel="nofollow"&gt;https://www.flickr.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;FC2 Video&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://video.fc2.com/" rel="nofollow"&gt;http://video.fc2.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Facebook&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.facebook.com/" rel="nofollow"&gt;https://www.facebook.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;eHow&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.ehow.com/" rel="nofollow"&gt;http://www.ehow.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Dailymotion&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.dailymotion.com/" rel="nofollow"&gt;http://www.dailymotion.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Coub&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://coub.com/" rel="nofollow"&gt;http://coub.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;CBS&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.cbs.com/" rel="nofollow"&gt;http://www.cbs.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Bandcamp&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://bandcamp.com/" rel="nofollow"&gt;http://bandcamp.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;AliveThai&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://alive.in.th/" rel="nofollow"&gt;http://alive.in.th/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;interest.me&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://ch.interest.me/tvn" rel="nofollow"&gt;http://ch.interest.me/tvn&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;755&lt;br&gt;ナナゴーゴー&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://7gogo.jp/" rel="nofollow"&gt;http://7gogo.jp/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;niconico&lt;br&gt;ニコニコ動画&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.nicovideo.jp/" rel="nofollow"&gt;http://www.nicovideo.jp/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;163&lt;br&gt;网易视频&lt;br&gt;网易云音乐&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://v.163.com/" rel="nofollow"&gt;http://v.163.com/&lt;/a&gt;&lt;br&gt;&lt;a href="http://music.163.com/" rel="nofollow"&gt;http://music.163.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;56网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.56.com/" rel="nofollow"&gt;http://www.56.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;AcFun&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.acfun.cn/" rel="nofollow"&gt;http://www.acfun.cn/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Baidu&lt;br&gt;百度贴吧&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://tieba.baidu.com/" rel="nofollow"&gt;http://tieba.baidu.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;爆米花网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.baomihua.com/" rel="nofollow"&gt;http://www.baomihua.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;bilibili&lt;br&gt;哔哩哔哩&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.bilibili.com/" rel="nofollow"&gt;http://www.bilibili.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;豆瓣&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.douban.com/" rel="nofollow"&gt;http://www.douban.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;斗鱼&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.douyutv.com/" rel="nofollow"&gt;http://www.douyutv.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Panda&lt;br&gt;熊猫&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.panda.tv/" rel="nofollow"&gt;http://www.panda.tv/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;凤凰视频&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://v.ifeng.com/" rel="nofollow"&gt;http://v.ifeng.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;风行网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.fun.tv/" rel="nofollow"&gt;http://www.fun.tv/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;iQIYI&lt;br&gt;爱奇艺&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.iqiyi.com/" rel="nofollow"&gt;http://www.iqiyi.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;激动网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.joy.cn/" rel="nofollow"&gt;http://www.joy.cn/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;酷6网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.ku6.com/" rel="nofollow"&gt;http://www.ku6.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;酷狗音乐&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.kugou.com/" rel="nofollow"&gt;http://www.kugou.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;酷我音乐&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.kuwo.cn/" rel="nofollow"&gt;http://www.kuwo.cn/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;乐视网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.le.com/" rel="nofollow"&gt;http://www.le.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;荔枝FM&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.lizhi.fm/" rel="nofollow"&gt;http://www.lizhi.fm/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;秒拍&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.miaopai.com/" rel="nofollow"&gt;http://www.miaopai.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;MioMio弹幕网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.miomio.tv/" rel="nofollow"&gt;http://www.miomio.tv/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;MissEvan&lt;br&gt;猫耳FM&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.missevan.com/" rel="nofollow"&gt;http://www.missevan.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;痞客邦&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.pixnet.net/" rel="nofollow"&gt;https://www.pixnet.net/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;PPTV聚力&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.pptv.com/" rel="nofollow"&gt;http://www.pptv.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;齐鲁网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://v.iqilu.com/" rel="nofollow"&gt;http://v.iqilu.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;QQ&lt;br&gt;腾讯视频&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://v.qq.com/" rel="nofollow"&gt;http://v.qq.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;企鹅直播&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://live.qq.com/" rel="nofollow"&gt;http://live.qq.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Sina&lt;br&gt;新浪视频&lt;br&gt;微博秒拍视频&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://video.sina.com.cn/" rel="nofollow"&gt;http://video.sina.com.cn/&lt;/a&gt;&lt;br&gt;&lt;a href="http://video.weibo.com/" rel="nofollow"&gt;http://video.weibo.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Sohu&lt;br&gt;搜狐视频&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://tv.sohu.com/" rel="nofollow"&gt;http://tv.sohu.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Tudou&lt;br&gt;土豆&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.tudou.com/" rel="nofollow"&gt;http://www.tudou.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;虾米&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.xiami.com/" rel="nofollow"&gt;http://www.xiami.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;阳光卫视&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.isuntv.com/" rel="nofollow"&gt;http://www.isuntv.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;音悦Tai&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.yinyuetai.com/" rel="nofollow"&gt;http://www.yinyuetai.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Youku&lt;br&gt;优酷&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.youku.com/" rel="nofollow"&gt;http://www.youku.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;战旗TV&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.zhanqi.tv/lives" rel="nofollow"&gt;http://www.zhanqi.tv/lives&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;央视网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.cntv.cn/" rel="nofollow"&gt;http://www.cntv.cn/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Naver&lt;br&gt;네이버&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://tvcast.naver.com/" rel="nofollow"&gt;http://tvcast.naver.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;芒果TV&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.mgtv.com/" rel="nofollow"&gt;http://www.mgtv.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;火猫TV&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.huomao.com/" rel="nofollow"&gt;http://www.huomao.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;阳光宽频网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.365yg.com/" rel="nofollow"&gt;http://www.365yg.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;西瓜视频&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.ixigua.com/" rel="nofollow"&gt;https://www.ixigua.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;快手&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.kuaishou.com/" rel="nofollow"&gt;https://www.kuaishou.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;抖音&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.douyin.com/" rel="nofollow"&gt;https://www.douyin.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;TikTok&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.tiktok.com/" rel="nofollow"&gt;https://www.tiktok.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;中国体育(TV)&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://v.zhibo.tv/" rel="nofollow"&gt;http://v.zhibo.tv/&lt;/a&gt; &lt;br&gt;&lt;a href="http://video.zhibo.tv/" rel="nofollow"&gt;http://video.zhibo.tv/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;知乎&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.zhihu.com/" rel="nofollow"&gt;https://www.zhihu.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For all other sites not on the list, the universal extractor will take care of finding and downloading interesting resources from the page.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-known-bugs" class="anchor" aria-hidden="true" href="#known-bugs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Known bugs&lt;/h3&gt;
&lt;p&gt;If something is broken and &lt;code&gt;you-get&lt;/code&gt; can't get you things you want, don't panic. (Yes, this happens all the time!)&lt;/p&gt;
&lt;p&gt;Check if it's already a known problem on &lt;a href="https://github.com/soimort/you-get/wiki/Known-Bugs"&gt;https://github.com/soimort/you-get/wiki/Known-Bugs&lt;/a&gt;. If not, follow the guidelines on &lt;a href="https://github.com/soimort/you-get/blob/develop/CONTRIBUTING.md"&gt;how to report an issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-involved" class="anchor" aria-hidden="true" href="#getting-involved"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Involved&lt;/h2&gt;
&lt;p&gt;You can reach us on the Gitter channel &lt;a href="https://gitter.im/soimort/you-get" rel="nofollow"&gt;#soimort/you-get&lt;/a&gt; (here's how you &lt;a href="http://irc.gitter.im" rel="nofollow"&gt;set up your IRC client&lt;/a&gt; for Gitter). If you have a quick question regarding &lt;code&gt;you-get&lt;/code&gt;, ask it there.&lt;/p&gt;
&lt;p&gt;If you are seeking to report an issue or contribute, please make sure to read &lt;a href="https://github.com/soimort/you-get/blob/develop/CONTRIBUTING.md"&gt;the guidelines&lt;/a&gt; first.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-legal-issues" class="anchor" aria-hidden="true" href="#legal-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Legal Issues&lt;/h2&gt;
&lt;p&gt;This software is distributed under the &lt;a href="https://raw.github.com/soimort/you-get/master/LICENSE.txt"&gt;MIT license&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In particular, please be aware that&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Translated to human words:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;In case your use of the software forms the basis of copyright infringement, or you use the software for any other illegal purposes, the authors cannot take any responsibility for you.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We only ship the code here, and how you are going to use it is left to your own discretion.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authors&lt;/h2&gt;
&lt;p&gt;Made by &lt;a href="https://github.com/soimort"&gt;@soimort&lt;/a&gt;, who is in turn powered by &lt;g-emoji class="g-emoji" alias="coffee" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2615.png"&gt;☕️&lt;/g-emoji&gt;, &lt;g-emoji class="g-emoji" alias="beer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f37a.png"&gt;🍺&lt;/g-emoji&gt; and &lt;g-emoji class="g-emoji" alias="ramen" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f35c.png"&gt;🍜&lt;/g-emoji&gt;.&lt;/p&gt;
&lt;p&gt;You can find the &lt;a href="https://github.com/soimort/you-get/graphs/contributors"&gt;list of all contributors&lt;/a&gt; here.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>soimort</author><guid isPermaLink="false">https://github.com/soimort/you-get</guid><pubDate>Fri, 20 Dec 2019 00:06:00 GMT</pubDate></item><item><title>pypa/pipenv #7 in Python, This week</title><link>https://github.com/pypa/pipenv</link><description>&lt;p&gt;&lt;i&gt; Python Development Workflow for Humans.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pipenv-python-development-workflow-for-humans" class="anchor" aria-hidden="true" href="#pipenv-python-development-workflow-for-humans"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pipenv: Python Development Workflow for Humans&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://python.org/pypi/pipenv" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ddcec9bd175bc46adeae3dcfbd0e42b817567543/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f706970656e762e737667" alt="image" data-canonical-src="https://img.shields.io/pypi/v/pipenv.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://python.org/pypi/pipenv" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a18c8cf8feb5c3924140910ee5182465bba0caba/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f706970656e762e737667" alt="image" data-canonical-src="https://img.shields.io/pypi/l/pipenv.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://dev.azure.com/pypa/pipenv/_build/latest?definitionId=16&amp;amp;branchName=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/314a359968b93abf7574a576c7dd9370134bb39c/68747470733a2f2f6465762e617a7572652e636f6d2f707970612f706970656e762f5f617069732f6275696c642f7374617475732f506970656e7625323043493f6272616e63684e616d653d6d6173746572" alt="Azure Pipelines Build Status" data-canonical-src="https://dev.azure.com/pypa/pipenv/_apis/build/status/Pipenv%20CI?branchName=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://python.org/pypi/pipenv" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/371188aa1f78d780711f0dc8337bd4689be457cd/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f706970656e762e737667" alt="image" data-canonical-src="https://img.shields.io/pypi/pyversions/pipenv.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://saythanks.io/to/kennethreitz" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0c9f6dc1c6a604b58d3c56bc5d7624e44f7eee2b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5361792532305468616e6b732d212d3145414544422e737667" alt="image" data-canonical-src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Pipenv&lt;/strong&gt; is a tool that aims to bring the best of all packaging worlds
(bundler, composer, npm, cargo, yarn, etc.) to the Python world.
&lt;em&gt;Windows is a first-class citizen, in our world.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It automatically creates and manages a virtualenv for your projects, as
well as adds/removes packages from your &lt;code&gt;Pipfile&lt;/code&gt; as you
install/uninstall packages. It also generates the ever-important
&lt;code&gt;Pipfile.lock&lt;/code&gt;, which is used to produce deterministic builds.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://gist.githubusercontent.com/jlusk/855d611bbcfa2b159839db73d07f6ce9/raw/7f5743401809f7e630ee8ff458faa980e19924a0/pipenv.gif"&gt;&lt;img src="https://gist.githubusercontent.com/jlusk/855d611bbcfa2b159839db73d07f6ce9/raw/7f5743401809f7e630ee8ff458faa980e19924a0/pipenv.gif" alt="GIF demonstrating Pipenv's usage" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The problems that Pipenv seeks to solve are multi-faceted:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You no longer need to use &lt;code&gt;pip&lt;/code&gt; and &lt;code&gt;virtualenv&lt;/code&gt; separately. They
work together.&lt;/li&gt;
&lt;li&gt;Managing a &lt;code&gt;requirements.txt&lt;/code&gt; file &lt;a href="https://www.kennethreitz.org/essays/a-better-pip-workflow" rel="nofollow"&gt;can be
problematic&lt;/a&gt;,
so Pipenv uses the upcoming &lt;code&gt;Pipfile&lt;/code&gt; and &lt;code&gt;Pipfile.lock&lt;/code&gt; instead,
which is superior for basic use cases.&lt;/li&gt;
&lt;li&gt;Hashes are used everywhere, always. Security. Automatically expose
security vulnerabilities.&lt;/li&gt;
&lt;li&gt;Give you insight into your dependency graph (e.g. &lt;code&gt;$ pipenv graph&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Streamline development workflow by loading &lt;code&gt;.env&lt;/code&gt; files.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can quickly play with Pipenv right in your browser:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://rootnroll.com/d/pipenv/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0621dcc124d4ea555e5493be0f69c5ffeb009b65/68747470733a2f2f63646e2e7261776769742e636f6d2f726f6f746e726f6c6c2f6c6962726172792f6173736574732f7472792e737667" alt="Try in browser" data-canonical-src="https://cdn.rawgit.com/rootnroll/library/assets/try.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;If you're on MacOS, you can install Pipenv easily with Homebrew:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ brew install pipenv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or, if you're using Debian Buster+:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt install pipenv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or, if you're using Fedora:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo dnf install pipenv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or, if you're using FreeBSD:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# pkg install py36-pipenv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Otherwise, refer to the &lt;a href="https://pipenv.kennethreitz.org/en/latest/#install-pipenv-today" rel="nofollow"&gt;documentation&lt;/a&gt; for instructions.&lt;/p&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="sparkles" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png"&gt;✨&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="cake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f370.png"&gt;🍰&lt;/g-emoji&gt;&lt;g-emoji class="g-emoji" alias="sparkles" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png"&gt;✨&lt;/g-emoji&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content--user-testimonials" class="anchor" aria-hidden="true" href="#-user-testimonials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;☤ User Testimonials&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Jannis Leidel&lt;/strong&gt;, former pip maintainer---&lt;/p&gt;
&lt;p&gt;:   &lt;em&gt;Pipenv is the porcelain I always wanted to build for pip. It fits
my brain and mostly replaces virtualenvwrapper and manual pip calls
for me. Use it.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;David Gang&lt;/strong&gt;---&lt;/p&gt;
&lt;p&gt;:   &lt;em&gt;This package manager is really awesome. For the first time I know
exactly what my dependencies are which I installed and what the
transitive dependencies are. Combined with the fact that installs
are deterministic, makes this package manager first class, like
cargo&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Justin Myles Holmes&lt;/strong&gt;---&lt;/p&gt;
&lt;p&gt;:   &lt;em&gt;Pipenv is finally an abstraction meant to engage the mind instead
of merely the filesystem.&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content--features" class="anchor" aria-hidden="true" href="#-features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;☤ Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Enables truly &lt;em&gt;deterministic builds&lt;/em&gt;, while easily specifying &lt;em&gt;only
what you want&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Generates and checks file hashes for locked dependencies.&lt;/li&gt;
&lt;li&gt;Automatically install required Pythons, if &lt;code&gt;pyenv&lt;/code&gt; is available.&lt;/li&gt;
&lt;li&gt;Automatically finds your project home, recursively, by looking for a
&lt;code&gt;Pipfile&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Automatically generates a &lt;code&gt;Pipfile&lt;/code&gt;, if one doesn't exist.&lt;/li&gt;
&lt;li&gt;Automatically creates a virtualenv in a standard location.&lt;/li&gt;
&lt;li&gt;Automatically adds/removes packages to a &lt;code&gt;Pipfile&lt;/code&gt; when they are
un/installed.&lt;/li&gt;
&lt;li&gt;Automatically loads &lt;code&gt;.env&lt;/code&gt; files, if they exist.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The main commands are &lt;code&gt;install&lt;/code&gt;, &lt;code&gt;uninstall&lt;/code&gt;, and &lt;code&gt;lock&lt;/code&gt;, which
generates a &lt;code&gt;Pipfile.lock&lt;/code&gt;. These are intended to replace
&lt;code&gt;$ pip install&lt;/code&gt; usage, as well as manual virtualenv management (to
activate a virtualenv, run &lt;code&gt;$ pipenv shell&lt;/code&gt;).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-basic-concepts" class="anchor" aria-hidden="true" href="#basic-concepts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Basic Concepts&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A virtualenv will automatically be created, when one doesn't exist.&lt;/li&gt;
&lt;li&gt;When no parameters are passed to &lt;code&gt;install&lt;/code&gt;, all packages
&lt;code&gt;[packages]&lt;/code&gt; specified will be installed.&lt;/li&gt;
&lt;li&gt;To initialize a Python 3 virtual environment, run
&lt;code&gt;$ pipenv --three&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;To initialize a Python 2 virtual environment, run &lt;code&gt;$ pipenv --two&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Otherwise, whatever virtualenv defaults to will be the default.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-other-commands" class="anchor" aria-hidden="true" href="#other-commands"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other Commands&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;shell&lt;/code&gt; will spawn a shell with the virtualenv activated.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;run&lt;/code&gt; will run a given command from the virtualenv, with any
arguments forwarded (e.g. &lt;code&gt;$ pipenv run python&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;check&lt;/code&gt; asserts that PEP 508 requirements are being met by the
current environment.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;graph&lt;/code&gt; will print a pretty graph of all your installed
dependencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-shell-completion" class="anchor" aria-hidden="true" href="#shell-completion"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Shell Completion&lt;/h3&gt;
&lt;p&gt;For example, with fish, put this in your
&lt;code&gt;~/.config/fish/completions/pipenv.fish&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;eval (pipenv --completion)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively, with bash, put this in your &lt;code&gt;.bashrc&lt;/code&gt; or &lt;code&gt;.bash_profile&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;eval "$(pipenv --completion)"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Magic shell completions are now enabled! There is also a &lt;a href="https://github.com/fisherman/pipenv"&gt;fish
plugin&lt;/a&gt;, which will automatically
activate your subshells for you!&lt;/p&gt;
&lt;p&gt;Fish is the best shell. You should use it.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content--usage" class="anchor" aria-hidden="true" href="#-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;☤ Usage&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;$ pipenv
Usage: pipenv [OPTIONS] COMMAND [ARGS]...

Options:
  --where          Output project home information.
  --venv           Output virtualenv information.
  --py             Output Python interpreter information.
  --envs           Output Environment Variable options.
  --rm             Remove the virtualenv.
  --bare           Minimal output.
  --completion     Output completion (to be eval'd).
  --man            Display manpage.
  --three / --two  Use Python 3/2 when creating virtualenv.
  --python TEXT    Specify which version of Python virtualenv should use.
  --site-packages  Enable site-packages for the virtualenv.
  --version        Show the version and exit.
  -h, --help       Show this message and exit.


Usage Examples:
   Create a new project using Python 3.7, specifically:
   $ pipenv --python 3.7

   Remove project virtualenv (inferred from current directory):
   $ pipenv --rm

   Install all dependencies for a project (including dev):
   $ pipenv install --dev

   Create a lockfile containing pre-releases:
   $ pipenv lock --pre

   Show a graph of your installed dependencies:
   $ pipenv graph

   Check your installed dependencies for security vulnerabilities:
   $ pipenv check

   Install a local setup.py into your virtual environment/Pipfile:
   $ pipenv install -e .

   Use a lower-level pip command:
   $ pipenv run pip freeze

Commands:
  check      Checks for security vulnerabilities and against PEP 508 markers
             provided in Pipfile.
  clean      Uninstalls all packages not specified in Pipfile.lock.
  graph      Displays currently–installed dependency graph information.
  install    Installs provided packages and adds them to Pipfile, or (if no
             packages are given), installs all packages from Pipfile.
  lock       Generates Pipfile.lock.
  open       View a given module in your editor.
  run        Spawns a command installed into the virtualenv.
  shell      Spawns a shell within the virtualenv.
  sync       Installs all packages specified in Pipfile.lock.
  uninstall  Un-installs a provided package and removes it from Pipfile.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Locate the project:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pipenv --where
/Users/kennethreitz/Library/Mobile Documents/com~apple~CloudDocs/repos/kr/pipenv/test
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Locate the virtualenv:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pipenv --venv
/Users/kennethreitz/.local/share/virtualenvs/test-Skyy4vre
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Locate the Python interpreter:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pipenv --py
/Users/kennethreitz/.local/share/virtualenvs/test-Skyy4vre/bin/python
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Install packages:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pipenv install
Creating a virtualenv for this project...
...
No package provided, installing all dependencies.
Virtualenv location: /Users/kennethreitz/.local/share/virtualenvs/test-EJkjoYts
Installing dependencies from Pipfile.lock...
...

To activate this project's virtualenv, run the following:
$ pipenv shell
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Installing from git:&lt;/p&gt;
&lt;p&gt;You can install packages with pipenv from git and other version control systems using URLs formatted according to the following rule:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;vcs_type&amp;gt;+&amp;lt;scheme&amp;gt;://&amp;lt;location&amp;gt;/&amp;lt;user_or_organization&amp;gt;/&amp;lt;repository&amp;gt;@&amp;lt;branch_or_tag&amp;gt;#&amp;lt;package_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The only optional section is the &lt;code&gt;@&amp;lt;branch_or_tag&amp;gt;&lt;/code&gt; section.  When using git over SSH, you may use the shorthand vcs and scheme alias &lt;code&gt;git+git@&amp;lt;location&amp;gt;:&amp;lt;user_or_organization&amp;gt;/&amp;lt;repository&amp;gt;@&amp;lt;branch_or_tag&amp;gt;#&amp;lt;package_name&amp;gt;&lt;/code&gt;. Note that this is translated to &lt;code&gt;git+ssh://git@&amp;lt;location&amp;gt;&lt;/code&gt; when parsed.&lt;/p&gt;
&lt;p&gt;Valid values for &lt;code&gt;&amp;lt;vcs_type&amp;gt;&lt;/code&gt; include &lt;code&gt;git&lt;/code&gt;, &lt;code&gt;bzr&lt;/code&gt;, &lt;code&gt;svn&lt;/code&gt;, and &lt;code&gt;hg&lt;/code&gt;.  Valid values for &lt;code&gt;&amp;lt;scheme&amp;gt;&lt;/code&gt; include &lt;code&gt;http,&lt;/code&gt;, &lt;code&gt;https&lt;/code&gt;, &lt;code&gt;ssh&lt;/code&gt;, and &lt;code&gt;file&lt;/code&gt;.  In specific cases you also have access to other schemes: &lt;code&gt;svn&lt;/code&gt; may be combined with &lt;code&gt;svn&lt;/code&gt; as a scheme, and &lt;code&gt;bzr&lt;/code&gt; can be combined with &lt;code&gt;sftp&lt;/code&gt; and &lt;code&gt;lp&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Note that it is &lt;strong&gt;strongly recommended&lt;/strong&gt; that you install any version-controlled dependencies in editable mode, using &lt;code&gt;pipenv install -e&lt;/code&gt;, in order to ensure that dependency resolution can be performed with an up to date copy of the repository each time it is performed, and that it includes all known dependencies.&lt;/p&gt;
&lt;p&gt;Below is an example usage which installs the git repository located at &lt;code&gt;https://github.com/requests/requests.git&lt;/code&gt; from tag &lt;code&gt;v2.19.1&lt;/code&gt; as package name &lt;code&gt;requests&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pipenv install -e git+https://github.com/requests/requests.git@v2.19#egg=requests
Creating a Pipfile for this project...
Installing -e git+https://github.com/requests/requests.git@v2.19.1#egg=requests...
[...snipped...]
Adding -e git+https://github.com/requests/requests.git@v2.19.1#egg=requests to Pipfile's [packages]...
[...]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can read more about &lt;a href="https://pip.pypa.io/en/stable/reference/pip_install/#vcs-support" rel="nofollow"&gt;pip's implementation of vcs support here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Install a dev dependency:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pipenv install pytest --dev
Installing pytest...
...
Adding pytest to Pipfile's [dev-packages]...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Show a dependency graph:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pipenv graph
requests==2.18.4
  - certifi [required: &amp;gt;=2017.4.17, installed: 2017.7.27.1]
  - chardet [required: &amp;gt;=3.0.2,&amp;lt;3.1.0, installed: 3.0.4]
  - idna [required: &amp;gt;=2.5,&amp;lt;2.7, installed: 2.6]
  - urllib3 [required: &amp;lt;1.23,&amp;gt;=1.21.1, installed: 1.22]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Generate a lockfile:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pipenv lock
Assuring all dependencies from Pipfile are installed...
Locking [dev-packages] dependencies...
Locking [packages] dependencies...
Note: your project now has only default [packages] installed.
To install [dev-packages], run: $ pipenv install --dev
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Install all dev dependencies:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pipenv install --dev
Pipfile found at /Users/kennethreitz/repos/kr/pip2/test/Pipfile. Considering this to be the project home.
Pipfile.lock out of date, updating...
Assuring all dependencies from Pipfile are installed...
Locking [dev-packages] dependencies...
Locking [packages] dependencies...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Uninstall everything:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pipenv uninstall --all
No package provided, un-installing all dependencies.
Found 25 installed package(s), purging...
...
Environment now purged and fresh!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use the shell:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pipenv shell
Loading .env environment variables…
Launching subshell in virtual environment. Type 'exit' or 'Ctrl+D' to return.
$ ▯
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content--documentation" class="anchor" aria-hidden="true" href="#-documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;☤ Documentation&lt;/h2&gt;
&lt;p&gt;Documentation resides over at &lt;a href="https://pipenv.kennethreitz.org/en/latest/" rel="nofollow"&gt;pipenv.org&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>pypa</author><guid isPermaLink="false">https://github.com/pypa/pipenv</guid><pubDate>Fri, 20 Dec 2019 00:07:00 GMT</pubDate></item><item><title>pjialin/py12306 #8 in Python, This week</title><link>https://github.com/pjialin/py12306</link><description>&lt;p&gt;&lt;i&gt;🚂 12306 购票助手，支持集群，多账号，多任务购票以及 Web 页面管理 &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content--py12306-购票助手" class="anchor" aria-hidden="true" href="#-py12306-购票助手"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="steam_locomotive" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f682.png"&gt;🚂&lt;/g-emoji&gt; py12306 购票助手&lt;/h1&gt;
&lt;p&gt;分布式，多账号，多任务购票&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 多日期查询余票&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 自动打码下单&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 用户状态恢复&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 电话语音通知&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 多账号、多任务、多线程支持&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 单个任务多站点查询&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 分布式运行&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; Docker 支持&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 动态修改配置文件&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 邮件通知&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; Web 管理页面&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 微信消息通知&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 代理池支持 (&lt;a href="https://github.com/pjialin/pyproxy-async"&gt;pyproxy-async&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-使用" class="anchor" aria-hidden="true" href="#使用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;使用&lt;/h2&gt;
&lt;p&gt;py12306 需要运行在 python 3.6 以上版本（其它版本暂未测试)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 安装依赖&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/pjialin/py12306

pip install -r requirements.txt&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2. 配置程序&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;cp env.py.example env.py&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;自动打码&lt;/p&gt;
&lt;p&gt;&lt;del&gt;验证码可以本地识别，所用的模型和算法均来自 &lt;a href="https://github.com/zhaipro/easy12306"&gt;https://github.com/zhaipro/easy12306&lt;/a&gt; 十分感谢！&lt;/del&gt; 验证码识别已迁移到服务器进行识别，无需本地安装环境。但服务器资源有限，并发过高会触发限流导致部分请求识别失败，如需在本地识别，可以参考这个仓库 &lt;a href="https://github.com/pjialin/12306-ocr"&gt;https://github.com/pjialin/12306-ocr&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;del&gt;注：免费打码无法保证持续可用，如失效请手动切换到若快平台，需要先到 &lt;a href="http://www.ruokuai.com/login" rel="nofollow"&gt;http://www.ruokuai.com&lt;/a&gt; 注册一个账号后填写到配置中&lt;/del&gt;（若快已停止服务，目前只能设置&lt;strong&gt;free&lt;/strong&gt;打码模式）&lt;/p&gt;
&lt;p&gt;语音通知&lt;/p&gt;
&lt;p&gt;语音验证码使用的是阿里云 API 市场上的一个服务商，需要到 &lt;a href="https://market.aliyun.com/products/56928004/cmapi026600.html" rel="nofollow"&gt;https://market.aliyun.com/products/56928004/cmapi026600.html&lt;/a&gt; 购买后将 appcode 填写到配置中&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. 启动前测试&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;目前提供了一些简单的测试，包括用户账号检测，乘客信息检测，车站检测等&lt;/p&gt;
&lt;p&gt;开始测试 -t&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python main.py -t&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;测试通知消息 (语音, 邮件) -t -n&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 默认不会进行通知测试，要对通知进行测试需要加上 -n 参数 &lt;/span&gt;
python main.py -t -n&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;4. 运行程序&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python main.py&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-参数列表" class="anchor" aria-hidden="true" href="#参数列表"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;参数列表&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;-t 测试配置信息&lt;/li&gt;
&lt;li&gt;-t -n 测试配置信息以及通知消息&lt;/li&gt;
&lt;li&gt;-c 指定自定义配置文件位置&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-分布式集群" class="anchor" aria-hidden="true" href="#分布式集群"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;分布式集群&lt;/h3&gt;
&lt;p&gt;集群依赖于 redis，目前支持情况&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单台主节点多个子节点同时运行&lt;/li&gt;
&lt;li&gt;主节点宕机后自动切换提升子节点为主节点&lt;/li&gt;
&lt;li&gt;主节点恢复后自动恢复为真实主节点&lt;/li&gt;
&lt;li&gt;配置通过主节点同步到所有子节点&lt;/li&gt;
&lt;li&gt;主节点配置修改后无需重启子节点，支持自动更新&lt;/li&gt;
&lt;li&gt;子节点消息实时同步到主节点&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;使用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将配置文件的中 &lt;code&gt;CLUSTER_ENABLED&lt;/code&gt; 打开即开启分布式&lt;/p&gt;
&lt;p&gt;目前提供了一个单独的子节点配置文件 &lt;code&gt;env.slave.py.example&lt;/code&gt; 将文件修改为 &lt;code&gt;env.slave.py&lt;/code&gt;， 通过 &lt;code&gt;python main.py -c env.slave.py&lt;/code&gt; 即可快速启动&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-docker-使用" class="anchor" aria-hidden="true" href="#docker-使用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker 使用&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1. 将配置文件下载到本地&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;docker run --rm pjialin/py12306 cat /config/env.py &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; env.py
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 或&lt;/span&gt;
curl https://raw.githubusercontent.com/pjialin/py12306/master/env.docker.py.example -o env.py&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2. 修改好配置后运行&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;docker run --rm --name py12306 -p 8008:8008 -d -v &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;pwd&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;:/config -v py12306:/data pjialin/py12306&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;当前目录会多一个 12306.log 的日志文件， &lt;code&gt;tail -f 12306.log&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-docker-compose-中使用" class="anchor" aria-hidden="true" href="#docker-compose-中使用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker-compose 中使用&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1. 复制配置文件&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cp docker-compose.yml.example docker-compose.yml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2. 从 docker-compose 运行&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在&lt;code&gt;docker-compose.yml&lt;/code&gt;所在的目录使用命令&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-web-管理页面" class="anchor" aria-hidden="true" href="#web-管理页面"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web 管理页面&lt;/h2&gt;
&lt;p&gt;目前支持用户和任务以及实时日志查看，更多功能后续会不断加入&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;打开 Web 功能需要将配置中的 &lt;code&gt;WEB_ENABLE&lt;/code&gt; 打开，启动程序后访问当前主机地址 + 端口号 (默认 8008) 即可，如 &lt;a href="http://127.0.0.1:8008" rel="nofollow"&gt;http://127.0.0.1:8008&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-更新" class="anchor" aria-hidden="true" href="#更新"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;更新&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;19-01-10
&lt;ul&gt;
&lt;li&gt;支持分布式集群&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;19-01-11
&lt;ul&gt;
&lt;li&gt;配置文件支持动态修改&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;19-01-12
&lt;ul&gt;
&lt;li&gt;新增免费打码&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;19-01-14
&lt;ul&gt;
&lt;li&gt;新增 Web 页面支持&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;19-01-15
&lt;ul&gt;
&lt;li&gt;新增 钉钉通知&lt;/li&gt;
&lt;li&gt;新增 Telegram 通知&lt;/li&gt;
&lt;li&gt;新增 ServerChan 和 PushBear 微信推送&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;19-01-18
&lt;ul&gt;
&lt;li&gt;新增 CDN 查询&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-截图" class="anchor" aria-hidden="true" href="#截图"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;截图&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-web-管理页面-1" class="anchor" aria-hidden="true" href="#web-管理页面-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web 管理页面&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/pjialin/py12306/blob/master/data/images/web.png"&gt;&lt;img src="https://github.com/pjialin/py12306/raw/master/data/images/web.png" alt="Web 管理页面图片" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-下单成功" class="anchor" aria-hidden="true" href="#下单成功"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;下单成功&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/pjialin/py12306/blob/master/data/images/order_success.png"&gt;&lt;img src="https://github.com/pjialin/py12306/raw/master/data/images/order_success.png" alt="下单成功图片" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-关于防封" class="anchor" aria-hidden="true" href="#关于防封"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;关于防封&lt;/h3&gt;
&lt;p&gt;目前查询和登录操作是分开的，查询是不依赖用户是否登录，放在 A 云 T 云容易被限制 ip，建议在其它网络环境下运行&lt;/p&gt;
&lt;p&gt;交流群 &lt;a href="https://jq.qq.com/?_wv=1027&amp;amp;k=5PgzDwV" rel="nofollow"&gt;780289875&lt;/a&gt;，微信群&lt;g-emoji class="g-emoji" alias="point_down" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f447.png"&gt;👇&lt;/g-emoji&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a92aa5d3e717707d04944a4d039ea974bf3bf59e/68747470733a2f2f646f632e706a69616c696e2e636f6d2f696d616765732f7150327178714738664f7277333476623161556f68552e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/a92aa5d3e717707d04944a4d039ea974bf3bf59e/68747470733a2f2f646f632e706a69616c696e2e636f6d2f696d616765732f7150327178714738664f7277333476623161556f68552e706e67" alt="微信群图片" data-canonical-src="https://doc.pjialin.com/images/qP2qxqG8fOrw34vb1aUohU.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-online-ide" class="anchor" aria-hidden="true" href="#online-ide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Online IDE&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://gitpod.io#https://github.com/pjialin/py12306" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1eb1ddfea6092593649f0117f7262ffa8fbd3017/68747470733a2f2f676974706f642e696f2f627574746f6e2f6f70656e2d696e2d676974706f642e737667" alt="在 Gitpod 中打开" data-canonical-src="https://gitpod.io/button/open-in-gitpod.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-thanks" class="anchor" aria-hidden="true" href="#thanks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Thanks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;感谢大佬 &lt;a href="https://github.com/testerSunshine/12306"&gt;testerSunshine&lt;/a&gt;，借鉴了部分实现&lt;/li&gt;
&lt;li&gt;感谢所有提供 pr 的大佬&lt;/li&gt;
&lt;li&gt;感谢大佬 &lt;a href="https://github.com/zhaipro/easy12306"&gt;zhaipro&lt;/a&gt; 的验证码本地识别模型与算法&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/pjialin/py12306/blob/master/LICENSE"&gt;Apache License.&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>pjialin</author><guid isPermaLink="false">https://github.com/pjialin/py12306</guid><pubDate>Fri, 20 Dec 2019 00:08:00 GMT</pubDate></item><item><title>zhaoolee/ChromeAppHeroes #9 in Python, This week</title><link>https://github.com/zhaoolee/ChromeAppHeroes</link><description>&lt;p&gt;&lt;i&gt;🌈谷粒-Chrome插件英雄榜, 为优秀的Chrome插件写一本中文说明书, 让Chrome插件英雄们造福人类~  ChromePluginHeroes, Write a Chinese manual for the excellent Chrome plugin, let the Chrome plugin heroes benefit the human~&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9ac21b8aea054eb48fc404fd429638bf.jpeg"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9ac21b8aea054eb48fc404fd429638bf.jpeg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/996icu/996.ICU/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/41215df7ff78cefe41536bf897fe1c7e55b10bd2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d416e74692532303939362d626c75652e737667" alt="LICENSE" data-canonical-src="https://img.shields.io/badge/license-Anti%20996-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://996.icu" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/13ac320a9a774e316fe72ffb1eaacf09b01b59a3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c696e6b2d3939362e6963752d7265642e737667" alt="996.icu" data-canonical-src="https://img.shields.io/badge/link-996.icu-red.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1f62c412c50e5397395878c4da31205080db55ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265"&gt;&lt;img src="https://camo.githubusercontent.com/1f62c412c50e5397395878c4da31205080db55ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265" alt="https://img.shields.io/github/issues/zhaoolee/ChromeAppHeroes.svg?style=popout-square" data-canonical-src="https://img.shields.io/github/issues/zhaoolee/ChromeAppHeroes.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/eae70f04ac75459320f0ec7397f12bded49476bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265"&gt;&lt;img src="https://camo.githubusercontent.com/eae70f04ac75459320f0ec7397f12bded49476bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265" alt="https://img.shields.io/github/stars/zhaoolee/ChromeAppHeroes.svg?style=popout-square" data-canonical-src="https://img.shields.io/github/stars/zhaoolee/ChromeAppHeroes.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-谷粒-chrome插件英雄榜" class="anchor" aria-hidden="true" href="#谷粒-chrome插件英雄榜"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;谷粒-Chrome插件英雄榜&lt;/h1&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="rainbow" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f308.png"&gt;🌈&lt;/g-emoji&gt;谷粒-Chrome插件英雄榜, 为优秀的Chrome插件写一本中文说明书, 让Chrome插件英雄们造福人类~
ChromeAppHeroes, Write a Chinese manual for the excellent Chrome plugin, let the Chrome plugin heroes benefit the human~&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/5ecd2856f287477c89c20efb7de11a9b.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/5ecd2856f287477c89c20efb7de11a9b.png" alt="谷粒VI设计.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;感谢&lt;a href="https://github.com/LuoJiangYong"&gt;老罗巴扎嘿&lt;/a&gt;为本项目设计的新的Logo | &lt;a href="https://zhaoolee.gitbooks.io/chrome/content/gu-li-qu-yi.html" rel="nofollow"&gt;谷粒文化(老罗巴扎嘿语录)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-相关项目推广-用chrome学编程" class="anchor" aria-hidden="true" href="#相关项目推广-用chrome学编程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;相关项目推广: &lt;a href="https://github.com/zhaoolee/ProgrammingWithChrome"&gt;用Chrome学编程&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;《用Chrome学编程(如何用Chrome优雅装B)》, 用Gif图展示Chrome的骚操作, 充分挖掘Chrome的编程潜力! &lt;a href="https://github.com/zhaoolee/ProgrammingWithChrome"&gt;https://github.com/zhaoolee/ProgrammingWithChrome&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-项目新增cn服务器" class="anchor" aria-hidden="true" href="#项目新增cn服务器"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目新增CN服务器&lt;/h2&gt;
&lt;p&gt;本项目使用了大量Gif图片, 而且github在国内的访问速度非常不稳定,导致文章页面打开稍慢, 为了解决大陆用户访问项目速度慢的问题, zhaoolee在阿里云买了一台5M的VPS, 已将所有文章链接替换到v2fy.com域名下, 访问速度会非常快, 而且图片支持懒加载, 可以节省下载gif图的流量,入口为&lt;a href="https://www.v2fy.com/ChromeAppHeroes/" rel="nofollow"&gt;https://www.v2fy.com/ChromeAppHeroes/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;海外用户:&lt;a href="https://zhaoolee.com/ChromeAppHeroes/" rel="nofollow"&gt;备用入口&lt;/a&gt;依然保留&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-目录点击以下标题-可以进入文章页" class="anchor" aria-hidden="true" href="#目录点击以下标题-可以进入文章页"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目录(点击以下标题, 可以进入文章页~)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/061-image-assistant/" rel="nofollow"&gt;061《ImageAssistant》图片助手批量图片下载器&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/060_tabagotchi/" rel="nofollow"&gt;060《Tabagotchi》为减缓全球变暖做出贡献&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/059_page_speed_insight_and_check_list/" rel="nofollow"&gt;059《PageSpeed Insight and CheckList》为网页优化提供建议和量化指标&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/058_ip_address/" rel="nofollow"&gt;058《IP-Address》快速查看当前设备IP&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/057_webp_save_as_png/" rel="nofollow"&gt;057《图片另存为JPG/PNG/WebP》让WebP图片下载为PNG格式&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/056_search/" rel="nofollow"&gt;056《Search》为Chrome设置搜索引擎关键词&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/055_keylines/" rel="nofollow"&gt;055《Keylines》为网页元素添加随机描边颜色&lt;/a&gt; | &lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/055_keylines.html" rel="nofollow"&gt;备用链接&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/054_er_xiang_yi_tu_sou_tu/" rel="nofollow"&gt;054《二箱 以图搜图》让你在搜图方面随心所欲（为所欲为）&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/053_shu_biao_dian_ji_te_xiao/" rel="nofollow"&gt;053《鼠标点击特效 (๑•́ ∀ •̀๑)》为鼠标点击添加有趣的特效&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/052_site_palette/" rel="nofollow"&gt;052《Site Palette》自动提取网站配色&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/051_custom_cursor_for_chrome/" rel="nofollow"&gt;051《Custom Cursor for Chrome™》为Chrome换上可爱初音光标&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/050_google_results_previewer/" rel="nofollow"&gt;050《Google Results Previewer》无点击查看谷歌搜索结果&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/049_web_server_for_chrome/" rel="nofollow"&gt;049《Web Server for Chrome》搭建本地Web服务器, 实现局域网共享文件夹&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/048_words_discoverer/" rel="nofollow"&gt;048《Words Discoverer》高亮标注单词,提升你的词汇量&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/047_go_to_tab/" rel="nofollow"&gt;047《Go to Tab》快速跳转到打开的网页&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/046_whatfont/" rel="nofollow"&gt;046《WhatFont》字体爱好者优雅查看网页字体&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/045_restlet_client/" rel="nofollow"&gt;045《Restlet Client》优秀的Api测试工具&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/044_gu_ge_fang_wen_zhu_shou/" rel="nofollow"&gt;044《谷歌访问助手》访问Chrome商店 Gmail 谷歌搜索&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/043_dream_afar_new_tab/" rel="nofollow"&gt;043《Dream Afar New Tab》探索世界的新方式&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/042_edge/" rel="nofollow"&gt;042 在Edge中安装Chrome扩展程序&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/041_copy_all_urls/" rel="nofollow"&gt;041《Copy All Urls》优雅地保存-开启多个标签页&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/040_gitzip_for_github/" rel="nofollow"&gt;040《GitZip for github》从Github批量下载表情包&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/039_simplify_gmail/" rel="nofollow"&gt;039《Simplify Gmail》让网页版Gmail更清爽&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/038_alexa_traffic_rank/" rel="nofollow"&gt;038《Alexa Traffic Rank》一键查看网站全球排名&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/037_saladict/" rel="nofollow"&gt;037《Saladict》谷歌!有道!我全都要! 聚合词典, 并行翻译&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/036_screen_shader/" rel="nofollow"&gt;036《Screen Shader》把网页调成暖色，你的眼睛会感谢你&lt;g-emoji class="g-emoji" alias="pray" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f64f.png"&gt;🙏&lt;/g-emoji&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/035_print_friendly_and_pdf/" rel="nofollow"&gt;035《Print Friendly &amp;amp; PDF》让你拥有最佳的打印阅读体验&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/034_astro_bot/" rel="nofollow"&gt;034《Astro Bot》用新标签页刷编程题&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/033_yi_ye/" rel="nofollow"&gt;033《一叶》在任意网页开启实时弹幕 聊天窗口 留言板&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/032_smallpdf/" rel="nofollow"&gt;032《Smallpdf》简单好用的线上PDF工具&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/031_onetab/" rel="nofollow"&gt;031《OneTab》把多个Tab转换为一个列表&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/030_jue_jin/" rel="nofollow"&gt;030《掘金》相信优质技术内容的力量&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/029_simread/" rel="nofollow"&gt;029 《SimpRead》为任意网页开启阅读模式&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/028_adblock/" rel="nofollow"&gt;028《AdBlock》Adblock自定义屏蔽简书广告&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/027_text/" rel="nofollow"&gt;027《Text》来自Chrome实验室的跨平台记事本&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/026_quickey_launcher/" rel="nofollow"&gt;026《Quickey Launcher》打开网站只需一键&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/025_console/" rel="nofollow"&gt;025《Console》Chrome自带好用的计算器&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/024_dark_reader/" rel="nofollow"&gt;024《Dark Reader》为任意网站启用夜间模式&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/023_fireshot/" rel="nofollow"&gt;023《FireShot》一键滚动截屏整个网页&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/022kuo_zhan_guan_li_qi/" rel="nofollow"&gt;022《扩展管理器》管理你的Chrome扩展&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/021_bi_li_bi_li_zhu_shou/" rel="nofollow"&gt;021《哔哩哔哩助手》助你快速成为B站老司机&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/020_boxel_rebound/" rel="nofollow"&gt;020《Boxel Rebound》“嗨到中毒”的弹跳小方块(附自制赛道分享方法)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/019_mega/" rel="nofollow"&gt;019《MEGA》网盘可以良心到什么程度? 试试MEGA吧!&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/018_enhanced_github/" rel="nofollow"&gt;018《Enhanced Github》从“冰柜”到“冰棍儿”,下载Github单个文件&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/017_xin_lang_wei_bo_tu_chuang/" rel="nofollow"&gt;017《新浪微博图床》本地Markdown编写更流畅, 新浪微博图床来帮忙&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/016_jie_chu_b_zhan_qu_yu_xian_zhi/" rel="nofollow"&gt;016《解除B站区域限制》查看进击的巨人第三季&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/015_xpath_helper/" rel="nofollow"&gt;015 《XPath Helper》完成Bing每日壁纸的小爬虫&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/014_chao_ji_ma_li_ao_you_xi/" rel="nofollow"&gt;014《超级马里奥游戏》Chrome变身小霸王&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/013_quick_qr/" rel="nofollow"&gt;013《Quick QR》用二维码实现云粘贴&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/012_ourstickys/" rel="nofollow"&gt;012《OurStickys》Chrome特色网页便签纸&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/011_whatruns/" rel="nofollow"&gt;011 《whatruns》一键分析网站技术栈&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/010_speedtest/" rel="nofollow"&gt;010《speedtest》网络测速插件speedtest&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/009_vimium/" rel="nofollow"&gt;009《vimium》Chrome与vim双神器融合&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/008_chrome_cleaner_pro/" rel="nofollow"&gt;008《Chrome Cleaner Pro》为Chrome加速&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/007_loom/" rel="nofollow"&gt;007《loom》 Chrome翻录网页视频神器&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/006_similarsites/" rel="nofollow"&gt;006《SimilarSites》 一键查找姊妹网站 SimilarSites&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/005_video_speed_controller/" rel="nofollow"&gt;005《Video Speed Controller》 刷课（刷剧）神器！给网页视频加个速(最快可达16倍!)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/004_tampermonkey/" rel="nofollow"&gt;004《Tampermonkey》 油猴子! 给浏览器开个挂&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/003_secure_shell_app/" rel="nofollow"&gt;003《Secure Shell App》 Chrome中开启ssh一种什么体验&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/002_chrono/" rel="nofollow"&gt;002《chrono》 让Chrome下载资源更容易&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.v2fy.com/p/001_markdown_here/" rel="nofollow"&gt;001《markdown-here》 Markdown一键转换到"富文本格式"&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-开源插件推广作者自荐" class="anchor" aria-hidden="true" href="#开源插件推广作者自荐"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;开源插件推广(作者自荐)&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;作者主页&lt;/th&gt;
&lt;th&gt;开源信息&lt;/th&gt;
&lt;th&gt;简介&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://chrome.google.com/webstore/detail/the-fucking-github/agajobpbaphiohkbkjigcalebbfmofdo" rel="nofollow"&gt;The Fucking Github&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/lvxianchao"&gt;lvxianchao&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/lvxianchao/the-fucking-github"&gt;Github仓库地址&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;很方便地查看、整理、搜索你已经 Star 过的项目和搜索 Github 上的项目。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://chrome.google.com/webstore/detail/hitup/eiokaohkigpbonodjcbjpecbnccijkjb" rel="nofollow"&gt;HitUP&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/wonderbeyond"&gt;wonderbeyond&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/wonderbeyond/HitUP"&gt;Github仓库地址&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;利用 New Tab “空白页” 助您保持对流行技术趋势的跟进，附带其它福利。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://chrome.google.com/webstore/detail/gitako-github-file-tree/giljefjcheohhamkjphiebfjnlphnokk" rel="nofollow"&gt;Gitako - Github file tree&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/EnixCoda"&gt;EnixCoda&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/EnixCoda/Gitako"&gt;Github仓库地址&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;功能上类似于大名鼎鼎的 Octotree ，但是用了更现代化的前端工具，性能好很多。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://chrome.google.com/webstore/detail/githuber/janmcneaglgklfljjcpihkkomeghljnf" rel="nofollow"&gt;GITHUBER&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/zhuowenli"&gt;zhuowenli&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/zhuowenli/githuber"&gt;Github仓库地址&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;这是一个帮助 GitHub 开发者每日发现优质内容的 Chrome 主页拓展。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/60c92f0de3d44bb7a612d08e2e1f3d18.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/60c92f0de3d44bb7a612d08e2e1f3d18.png" alt="造福人类.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-咦微信打赏" class="anchor" aria-hidden="true" href="#咦微信打赏"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;咦?(微信打赏)&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c4fdea49e11241e392d6bcaa33855897.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c4fdea49e11241e392d6bcaa33855897.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;赞赏金额&lt;/th&gt;
&lt;th&gt;赞赏者(微信名)&lt;/th&gt;
&lt;th&gt;赞赏时间&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;20.00&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年8月2日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;20.00&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年7月11日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12.34&lt;/td&gt;
&lt;td&gt;张明辉&lt;/td&gt;
&lt;td&gt;2019年8月20日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;六小登登&lt;/td&gt;
&lt;td&gt;2019年9月5日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;云淡风晴&lt;/td&gt;
&lt;td&gt;2019年7月24日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;金三古月&lt;/td&gt;
&lt;td&gt;2019年6月2日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;Azuno&lt;/td&gt;
&lt;td&gt;2019年6月1日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;邦妥&lt;/td&gt;
&lt;td&gt;2019年5月22日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;enjoy life&lt;/td&gt;
&lt;td&gt;2019年9月20日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;L__hoo原&lt;/td&gt;
&lt;td&gt;2019年9月20日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;梦想旅程(公众号:苏生不惑)&lt;/td&gt;
&lt;td&gt;2019年9月14日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;1111&lt;/td&gt;
&lt;td&gt;2019年7月27日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;那都不重要&lt;/td&gt;
&lt;td&gt;2019年5月19日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;Lismg&lt;/td&gt;
&lt;td&gt;2019年6月5日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;small胖&lt;/td&gt;
&lt;td&gt;2019年7月9日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2.00&lt;/td&gt;
&lt;td&gt;良辰美&lt;/td&gt;
&lt;td&gt;2019年7月20日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2.00&lt;/td&gt;
&lt;td&gt;@Coolstar&lt;/td&gt;
&lt;td&gt;2019年7月6日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年9月26日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;夏天的小虫子&lt;/td&gt;
&lt;td&gt;2019年9月23日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年7月26日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;2019年7月12日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年6月13日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;Walter Wu&lt;/td&gt;
&lt;td&gt;2019年6月1日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;Joseph&lt;/td&gt;
&lt;td&gt;2019年4月24日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年4月12日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;于云鹏Edward&lt;/td&gt;
&lt;td&gt;2019年4月12日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;黄金星&lt;/td&gt;
&lt;td&gt;2019年4月11日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;Cloud 9&lt;/td&gt;
&lt;td&gt;2019年4月5日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.20&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年7月25日&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;感谢以上赞赏者对本开源项目的支持[手动滑稽]&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-061imageassistant图片助手批量图片下载器" class="anchor" aria-hidden="true" href="#061imageassistant图片助手批量图片下载器"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/061-image-assistant/" rel="nofollow"&gt;061《ImageAssistant》图片助手批量图片下载器&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/69475211-6cba5e80-0e05-11ea-8364-2fdaf073cdb0.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/69475211-6cba5e80-0e05-11ea-8364-2fdaf073cdb0.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;《ImageAssistant》图片助手批量图片下载器,在提取网页图片的方面,功能非常全面, 能提取绝大多数图片网站的资源, 如果你经常为无法提取网页图片资源发愁, 相信这款扩展程序能为你带来惊喜&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-060tabagotchi为减缓全球变暖做出贡献" class="anchor" aria-hidden="true" href="#060tabagotchi为减缓全球变暖做出贡献"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/060_tabagotchi/" rel="nofollow"&gt;060《Tabagotchi》为减缓全球变暖做出贡献&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63478935-7b1f7400-c4be-11e9-8679-5f4a6a56c89c.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63478935-7b1f7400-c4be-11e9-8679-5f4a6a56c89c.gif" alt="tabagotchi" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tabagotchi扩展以一种有趣的方式, 提醒我们减少标签页数量, 减少了计算机产生的热量, 为阻止全球变暖做出了贡献~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-059pagespeed-insight-and-checklist为网页优化提供建议和量化指标" class="anchor" aria-hidden="true" href="#059pagespeed-insight-and-checklist为网页优化提供建议和量化指标"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/059_page_speed_insight_and_check_list/" rel="nofollow"&gt;059《PageSpeed Insight and CheckList》为网页优化提供建议和量化指标&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63309328-f818e500-c328-11e9-8f1a-68fed13a4015.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63309328-f818e500-c328-11e9-8f1a-68fed13a4015.gif" alt="pag_speed" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63309327-f7804e80-c328-11e9-8eab-9055db8a5d2c.png"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63309327-f7804e80-c328-11e9-8eab-9055db8a5d2c.png" alt="001" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;PageSpeed Insight and CheckList 和 Google Page Speed 结合使用, 能够为网页质量评分,量化网页优化的效果,也为优化网页指明了方向,对前端工程师而言,是非常重要的工具&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-058ip-address快速查看当前设备ip" class="anchor" aria-hidden="true" href="#058ip-address快速查看当前设备ip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/058_ip_address/" rel="nofollow"&gt;058《IP-Address》快速查看当前设备IP&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63222725-ee369b00-c1dd-11e9-986e-cbc002168db8.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63222725-ee369b00-c1dd-11e9-986e-cbc002168db8.gif" alt="ip_address" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;获取当前设备的IP地址,对于开发者而言,是一个经常遇到的问题,而《IP-Address》这款简洁小巧的软件, 能满足我们的需求&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-057图片另存为jpgpngwebp让webp图片下载为png格式" class="anchor" aria-hidden="true" href="#057图片另存为jpgpngwebp让webp图片下载为png格式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/057_webp_save_as_png/" rel="nofollow"&gt;057《图片另存为JPG/PNG/WebP》让WebP图片下载为PNG格式&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63221240-ce48ac80-c1c8-11e9-9860-376fedc0845e.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63221240-ce48ac80-c1c8-11e9-9860-376fedc0845e.gif" alt="save_as_png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;WebP是非常先进的格式, 但由于Photoshop这类元老级图像编辑软件不支持, 我们只能将图片为png格式,再进行编辑, 先进技术改变世界, 需要一个过程, 而在过程中提供一个折中的方案(把WebP装换为png, 再将png图片装换为WebP), 也是一件有价值的事~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-056search为chrome设置搜索引擎关键词" class="anchor" aria-hidden="true" href="#056search为chrome设置搜索引擎关键词"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/056_search/" rel="nofollow"&gt;056《Search》为Chrome设置搜索引擎关键词&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/62503773-3c37c000-b828-11e9-9605-4ecce76830ec.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/62503773-3c37c000-b828-11e9-9605-4ecce76830ec.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在早期的网址导航主页上, 可以通过点击选择不同的搜索引擎进行搜索(数量有限, 而且不支持自定义), 而Chrome搜索更极客一些, 通过&lt;strong&gt;自定义关键词加空格&lt;/strong&gt;的方法, 在搜索引擎之间自由切换, 是一种兼具扩展性与易用性的做法&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-055keylines为网页元素添加随机描边颜色-" class="anchor" aria-hidden="true" href="#055keylines为网页元素添加随机描边颜色-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/055_keylines/" rel="nofollow"&gt;055《Keylines》为网页元素添加随机描边颜色 &lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61917657-dbcf9580-af80-11e9-87d3-528609ab85b0.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61917657-dbcf9580-af80-11e9-87d3-528609ab85b0.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Keylines的实现原理非常简单(为网页dom元素添加了outline属性), 但展示的效果却非常惊艳, 这应该归功于Keylines作者优秀的想法, 很多时候, 优秀的软件并不一定使用了很难掌握的技术, 而是包含了作者优秀的想法~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-054二箱以图搜图让你在搜图方面随心所欲为所欲为" class="anchor" aria-hidden="true" href="#054二箱以图搜图让你在搜图方面随心所欲为所欲为"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/054_er_xiang_yi_tu_sou_tu/" rel="nofollow"&gt;054《二箱+以图搜图》让你在搜图方面随心所欲（为所欲为）&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61757068-93ce3880-adf1-11e9-8903-ebf313fb6098.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61757068-93ce3880-adf1-11e9-8903-ebf313fb6098.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;《二箱 以图搜图》是一款简单实用的搜图小工具，如果你是一名设计师, 可以帮你快速查找他人设计作品中所用的素材来源, 提升你的工作效率~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-053鼠标点击特效-๑́--̀๑为鼠标点击添加有趣的特效" class="anchor" aria-hidden="true" href="#053鼠标点击特效-๑́--̀๑为鼠标点击添加有趣的特效"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/053_shu_biao_dian_ji_te_xiao/" rel="nofollow"&gt;053《鼠标点击特效 (๑•́ ∀ •̀๑)》为鼠标点击添加有趣的特效&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61600040-04921b00-ac61-11e9-8446-533752d71de1.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61600040-04921b00-ac61-11e9-8446-533752d71de1.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;《鼠标点击特效 (๑•́ ∀ •̀๑)》是一款为鼠标点击添加有趣的特效的扩展程序,虽然没啥实际用途,但很好玩, 录制一些有趣的网页小程序时, 会非常出彩~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-052site-palette自动提取网站配色" class="anchor" aria-hidden="true" href="#052site-palette自动提取网站配色"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/052_site_palette/" rel="nofollow"&gt;052《Site Palette》自动提取网站配色&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61169390-2f101400-a58f-11e9-8769-4d62b7b64f37.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61169390-2f101400-a58f-11e9-8769-4d62b7b64f37.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Site Palette使用简单, 功能实用, 没有广告, 是典型的小而美的扩展程序, 这类扩展程序越多, Chrome的用户体验也就越好~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-051custom-cursor-for-chrome为chrome换上可爱初音光标" class="anchor" aria-hidden="true" href="#051custom-cursor-for-chrome为chrome换上可爱初音光标"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/051_custom_cursor_for_chrome/" rel="nofollow"&gt;051《Custom Cursor for Chrome™》为Chrome换上可爱初音光标&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61166967-d0846f00-a569-11e9-9141-15cef4983098.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61166967-d0846f00-a569-11e9-9141-15cef4983098.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;早期的QQ空间和个人博客, 我们会给页面加各种各样的装饰, 连鼠标指针也要定制一下, 当时感觉乐趣无穷, 后面就失去了兴趣, 对于个人博客, 感觉越简洁越好, 于是就有了Next这些大量留白的博客主题,但我感觉在Next这类主题中加一些定制化的小物件也是不错的, 在简洁与花哨之间找到平衡, 不正是生活的乐趣之源么~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-050google-results-previewer无点击查看谷歌搜索结果" class="anchor" aria-hidden="true" href="#050google-results-previewer无点击查看谷歌搜索结果"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/050_google_results_previewer/" rel="nofollow"&gt;050《Google Results Previewer》无点击查看谷歌搜索结果&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/9219a092f0f4eb1c6f614c1667b316d1.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/9219a092f0f4eb1c6f614c1667b316d1.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Google Results Previewer的功能简单实用, 也没有多余的设置, 属于新手友好型工具&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-049web-server-for-chrome搭建本地web服务器-实现局域网共享文件夹" class="anchor" aria-hidden="true" href="#049web-server-for-chrome搭建本地web服务器-实现局域网共享文件夹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/049_web_server_for_chrome/" rel="nofollow"&gt;049《Web Server for Chrome》搭建本地Web服务器, 实现局域网共享文件夹&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/74d3eb882b103e0fb1e5e5dd651c052f.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/74d3eb882b103e0fb1e5e5dd651c052f.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Web Server for Chrome可以帮我们在本地快速开启http服务,让开发和测试变得更加简单, 如果你想和同处某个局域网的小伙伴, 建立一个共享文件夹, Web Server for Chrome或许是你最简单的实现方法~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-048words-discoverer背单词新姿势提升你的词汇量" class="anchor" aria-hidden="true" href="#048words-discoverer背单词新姿势提升你的词汇量"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/048_words_discoverer/" rel="nofollow"&gt;048《Words Discoverer》背单词新姿势,提升你的词汇量&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/305439fdd84017da654e00f16aaee752.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/305439fdd84017da654e00f16aaee752.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Words Discoverer(中文译名: 单词发现者),&lt;strong&gt;可以突出显示网页上罕见的英语字典词汇和惯用语。促进英语语言学习并扩大词汇量&lt;/strong&gt;,通过自动高亮网页单词, 辅助单词记忆是一个很好的路子, 建议过一段时间,就稍微调高&lt;strong&gt;不突出显示 最常用的英语单词&lt;/strong&gt;的数量, 比如从默认的15%调整到16%,  单词发现者与沙拉查词结合使用, 真的是体验极佳~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-047go-to-tab快速跳转到打开的网页" class="anchor" aria-hidden="true" href="#047go-to-tab快速跳转到打开的网页"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/047_go_to_tab/" rel="nofollow"&gt;047《Go to Tab》快速跳转到打开的网页&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/59550928-2a623b00-8fa4-11e9-8525-8e830907463b.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/59550928-2a623b00-8fa4-11e9-8525-8e830907463b.gif" alt="2019-06-15-18 54 23" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Go to Tab对于工作期间大量打开页面, 又长时间不关机的程序员们, 是非常有帮助的&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-046whatfont字体爱好者优雅查看网页字体" class="anchor" aria-hidden="true" href="#046whatfont字体爱好者优雅查看网页字体"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/046_whatfont/" rel="nofollow"&gt;046《WhatFont》字体爱好者优雅查看网页字体&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/59549312-4529b500-8f8e-11e9-8107-004486a02258.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/59549312-4529b500-8f8e-11e9-8107-004486a02258.gif" alt="font 2019-06-15 16_04_10" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;WhatFont属于功能非常单一的小工具, 让字体爱好者优雅查看网页字体属性, 如果你对漂亮字体有一份执念, 推荐到&lt;a href="https://fonts.google.com/" rel="nofollow"&gt;https://fonts.google.com/&lt;/a&gt;, &lt;a href="https://www.myfonts.com/" rel="nofollow"&gt;https://www.myfonts.com/&lt;/a&gt;
等字体网站,找寻更多可爱的字体~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-045restlet-client优秀的api测试工具" class="anchor" aria-hidden="true" href="#045restlet-client优秀的api测试工具"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/045_restlet_client/" rel="nofollow"&gt;045《Restlet Client》优秀的Api测试工具&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/89ea1e51dab48d5a84f089adf33eb274.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/89ea1e51dab48d5a84f089adf33eb274.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Restlet Client是一款开发实用工具, 支持一键导入Postman等api测试工具的测试用例&lt;/li&gt;
&lt;li&gt;近来, Postman开始主推自己的70M左右的客户端安装包, 功能没什么改进, 体积却变得超大,而且Postman的Chrome扩展程序, 对macOS的支持不太好(每次打开, 都会弹窗报一个错)&lt;/li&gt;
&lt;li&gt;Restlet Client依然只是一个开箱即用的Chrome扩展程序, 非常适合硬盘空间有限的小伙伴使用(软件功能够用就可以了~)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-044谷歌访问助手访问chrome商店-gmail-谷歌搜索" class="anchor" aria-hidden="true" href="#044谷歌访问助手访问chrome商店-gmail-谷歌搜索"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/044_gu_ge_fang_wen_zhu_shou/" rel="nofollow"&gt;044《谷歌访问助手》访问Chrome商店 Gmail 谷歌搜索&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/deff71a536ba4027a01fe3c7a558c277.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/deff71a536ba4027a01fe3c7a558c277.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;《谷歌访问助手》可以让我们访问Chrome商店, 以及谷歌搜索, 谷歌Gmail等服务
&lt;code&gt;仅为香港地区用户提，供方便科研,外贸提供帮助,不良用户,将封锁访问IP,后果自负&lt;/code&gt;, 谷歌访问助手需要你设置主页为&lt;code&gt;https://2018.hao245.com/&lt;/code&gt;才能使用, 有百度全家桶, 360全家桶的流氓内涵~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-043dream-afar-new-tab探索世界的新方式" class="anchor" aria-hidden="true" href="#043dream-afar-new-tab探索世界的新方式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/043_dream_afar_new_tab/" rel="nofollow"&gt;043《Dream Afar New Tab》探索世界的新方式&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e40b7bec41ce4ac892578bc88a03d25c.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e40b7bec41ce4ac892578bc88a03d25c.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;《Dream Afar New Tab》的设计非常漂亮, 功能调节也非常简单, 只有两级菜单, 壁纸也非常精美, 对浏览器颜值有要求的小伙伴, 可以试一试~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-042-在edge中安装chrome扩展程序" class="anchor" aria-hidden="true" href="#042-在edge中安装chrome扩展程序"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/042_edge/" rel="nofollow"&gt;042 在Edge中安装Chrome扩展程序&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/a131b9833d20424ab93cb258ab8542e8.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/a131b9833d20424ab93cb258ab8542e8.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Edge可以安装绝大多数Chrome商店中的扩展, 但Chrome中的谷歌开发App程序, 类似&lt;a href="https://chrome.google.com/webstore/detail/secure-shell-app/pnhechapfaindjhompbnflcldabbghjo" rel="nofollow"&gt;Secure Shell App&lt;/a&gt;, 目前是无法安装的, 新版Edge使用了Chrome的Chromium内核, 可以兼容安装Chrome生态中的各种应用程序,为Edge未来的发展带来了无限可能~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-041copy-all-urls优雅地保存-开启多个标签页" class="anchor" aria-hidden="true" href="#041copy-all-urls优雅地保存-开启多个标签页"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/041_copy_all_urls/" rel="nofollow"&gt;041《Copy All Urls》优雅地保存-开启多个标签页&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/eac219ff189a4295bbf88974b045ba5b.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/eac219ff189a4295bbf88974b045ba5b.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Copy All Urls属于小而美地工具，如果你每天都需要查看几个固定的网页, Copy All Urls能帮你省很多时间~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-040gitzip-for-github从github批量下载表情包" class="anchor" aria-hidden="true" href="#040gitzip-for-github从github批量下载表情包"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/040_gitzip_for_github/" rel="nofollow"&gt;040《GitZip for github》从Github批量下载表情包&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/f5b923dc4a21437484e90859342ed366.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/f5b923dc4a21437484e90859342ed366.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;以前介绍过Github快速下载单个文件的扩展工具&lt;a href="https://zhaoolee.gitbooks.io/chrome/content/018enhanced-github300b-cong-201c-bing-gui-201d-dao-201c-bing-gun-er-201d2c-xia-zai-github-dan-ge-wen-jian.html" rel="nofollow"&gt;《Enhanced Github》&lt;/a&gt; , 《Enhanced Github》 和 《GitZip for github》 结合到一起, 就可以让我们快速下载, github任意仓库任意文件夹的优质资源了~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-039simplify-gmail让网页版gmail更清爽" class="anchor" aria-hidden="true" href="#039simplify-gmail让网页版gmail更清爽"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/039_simplify_gmail/" rel="nofollow"&gt;039《Simplify Gmail》让网页版Gmail更清爽&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c9b1aa8201c24208b0e0aedfcdbdc992.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c9b1aa8201c24208b0e0aedfcdbdc992.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;好的扩展程序就应该这样, 让人见到后耳目一新, 使用的方法却非常简单。
如果你并没有注册过Gmail邮箱, 可以尝试注册一个, Gmail是非常好用的, 拥有规范的接口, 不会随便拦截邮件, 也不会在页面铺满广告&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-038alexa-traffic-rank一键查看网站全球排名" class="anchor" aria-hidden="true" href="#038alexa-traffic-rank一键查看网站全球排名"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/038_alexa_traffic_rank/" rel="nofollow"&gt;038《Alexa Traffic Rank》一键查看网站全球排名&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fcefd45a5cc74e4c824f567535f79c5c.webp"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fcefd45a5cc74e4c824f567535f79c5c.webp" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Alexa给出的网站排名, 是目前公认最具参考价值的排名, 打开一个新站点, 查一下新站点的Alexa排名, 以及与它类似的站点, 让我们很快对新站点的定位, 有一个大致的认知~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-037saladict谷歌有道我全都要-聚合词典-并行翻译" class="anchor" aria-hidden="true" href="#037saladict谷歌有道我全都要-聚合词典-并行翻译"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/037_saladict/" rel="nofollow"&gt;037《Saladict》谷歌!有道!我全都要! 聚合词典, 并行翻译&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/07322f3c4b13484a8a048194558cec5c.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/07322f3c4b13484a8a048194558cec5c.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;沙拉查词(Saladict)是一款非常优秀的查词扩展, 上文只是提及了它最常用的一些功能, 沙拉查词的后台管理选项非常丰富, 感兴趣的小伙伴可以慢慢探索&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-036screen-shader把屏幕调成暖色你的眼睛会感谢你" class="anchor" aria-hidden="true" href="#036screen-shader把屏幕调成暖色你的眼睛会感谢你"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/036_screen_shader/" rel="nofollow"&gt;036《Screen Shader》把屏幕调成暖色，你的眼睛会感谢你&lt;g-emoji class="g-emoji" alias="pray" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f64f.png"&gt;🙏&lt;/g-emoji&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/3a94a283267047c39114694706de7293.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/3a94a283267047c39114694706de7293.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;对于长时间看电脑的办公人员, 可以尝试吧屏幕调成暖色, 开始可能会不习惯, 但后面会感觉眼睛会舒服很多, 你的眼睛也会感谢你的~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-035print-friendly--pdf让你拥有最佳的打印阅读体验" class="anchor" aria-hidden="true" href="#035print-friendly--pdf让你拥有最佳的打印阅读体验"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/035_print_friendly_and_pdf/" rel="nofollow"&gt;035《Print Friendly &amp;amp; PDF》让你拥有最佳的打印阅读体验&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/a71d2b280298482ba2408482c1537bf9.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/a71d2b280298482ba2408482c1537bf9.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;《Print Friendly &amp;amp; PDF》是一款文件打印chrome插件，会在打印之前删除垃圾广告，导航和无用浮窗从而实现页面优化，让你拥有最佳的打印阅读体验, 如果你经常需要打印网页, 可以通过《Print Friendly &amp;amp; PDF》让你的打印工作变得省时省力~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-034astro-bot用新标签页刷编程题" class="anchor" aria-hidden="true" href="#034astro-bot用新标签页刷编程题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/034_astro_bot/" rel="nofollow"&gt;034《Astro Bot》用新标签页刷编程题&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/671d39ca714f437fa1d287bfb988724e.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/671d39ca714f437fa1d287bfb988724e.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Astro Bot可以在新标签页,展示一道与程序相关的问题或相关新闻&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-033一叶在任意网页开启实时弹幕-聊天窗口-留言板" class="anchor" aria-hidden="true" href="#033一叶在任意网页开启实时弹幕-聊天窗口-留言板"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/033_yi_ye/" rel="nofollow"&gt;033《一叶》在任意网页开启实时弹幕 聊天窗口 留言板&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6a328e8eb9984f5abea5816c681b8e4e.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6a328e8eb9984f5abea5816c681b8e4e.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;一叶是一款很有想法的产品,但目前用户量还是很少, 对此,我个人也有一些想法,如果官方可以效仿pokemongo这类寻宝游戏,在各大网站的主页对应的留言板内,埋下一些有意思的彩蛋,让用户去寻宝,或许会有利于产品的推广~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-032smallpdf简单好用的线上pdf工具" class="anchor" aria-hidden="true" href="#032smallpdf简单好用的线上pdf工具"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/032_smallpdf/" rel="nofollow"&gt;032《Smallpdf》简单好用的线上PDF工具&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/2c00d25291db4750963c60e78344d4cc.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/2c00d25291db4750963c60e78344d4cc.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Smallpdf是一个非常好用的PDF工具,可以收藏起来,作为日常办公的工具, Smallpdf可以进行多份pdf在线合并, pdf在线编辑, 如果你是一个经常和PDF打交道的人, 可不要错过它~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-031onetab把多个tab转换为一个列表" class="anchor" aria-hidden="true" href="#031onetab把多个tab转换为一个列表"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/031_onetab/" rel="nofollow"&gt;031《OneTab》把多个Tab转换为一个列表&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/93781d48870742e08dc68fa17e79169e.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/93781d48870742e08dc68fa17e79169e.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;当你发现自己有太多的标签页时,单击OneTab图标,所有标签页会转换成一个列表,当你需要再次访问这些标签页时,点击OneTab图标唤出列表,点击列表恢复标签页&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-030掘金相信优质技术内容的力量" class="anchor" aria-hidden="true" href="#030掘金相信优质技术内容的力量"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/030_jue_jin/" rel="nofollow"&gt;030《掘金》相信优质技术内容的力量&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fcca47d65f2542808281c17ec379d7d9.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fcca47d65f2542808281c17ec379d7d9.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;如果你想对 程序员, 产品经理, 设计师的行业知识有所了解, 可以没事儿打开掘金插件看一看, 如果你感觉很喜欢里面的内容, 可以到掘金官网 &lt;a href="https://juejin.im/" rel="nofollow"&gt;https://juejin.im/&lt;/a&gt; 逛一逛&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-029-simpread为任意网页开启阅读模式" class="anchor" aria-hidden="true" href="#029-simpread为任意网页开启阅读模式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/029_simread/" rel="nofollow"&gt;029 《SimpRead》为任意网页开启阅读模式&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/0f9aa9ca332c4325806f92784af9f9ac.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/0f9aa9ca332c4325806f92784af9f9ac.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
为网页开启阅读模式, 能让我们更专注于内容, 不会被花花绿绿的广告推广分散精力, 而SimpRead就是一歀为网页开启&lt;strong&gt;阅读模式&lt;/strong&gt;的插件&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-028adblockadblock屏蔽简书广告" class="anchor" aria-hidden="true" href="#028adblockadblock屏蔽简书广告"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/028_adblock/" rel="nofollow"&gt;028《AdBlock》Adblock屏蔽简书广告&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e149c42ac1f343b88f50e522cba9ad64.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e149c42ac1f343b88f50e522cba9ad64.gif" alt="屏蔽简书广告" style="max-width:100%;"&gt;&lt;/a&gt;
Adblock的功能非常丰富, 但很多功能基本用不到, 普通用户只需要开启Adblock, 能使用右键工具屏蔽不喜欢的广告, 也就够用了~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-027text来自chrome实验室的跨平台记事本" class="anchor" aria-hidden="true" href="#027text来自chrome实验室的跨平台记事本"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/027_text/" rel="nofollow"&gt;027《Text》来自Chrome实验室的跨平台记事本&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6e287798ca1d4b939705447d4b8b2b3b.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6e287798ca1d4b939705447d4b8b2b3b.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Text由谷歌Chrome实验室研发并开源, 开源地址&lt;a href="https://github.com/GoogleChromeLabs/text-app"&gt;https://github.com/GoogleChromeLabs/text-app&lt;/a&gt; , Text属于小而美的产品, 功能不算强大, 但是够用, 而且借助Chrome完成了跨平台(在Linux也可以使用哦~)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-026quickey-launcher打开网站只需一键" class="anchor" aria-hidden="true" href="#026quickey-launcher打开网站只需一键"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/026_quickey_launcher/" rel="nofollow"&gt;026《Quickey Launcher》打开网站只需一键&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/322a82d214b34ff2ba70d9c1cd71d276.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/322a82d214b34ff2ba70d9c1cd71d276.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
Quickey Launcher以优雅的方式, 为任意网页绑定一个快捷键, 绑定完成后, 即可通过快捷键,打开网页&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-025consolechrome自带好用的计算器" class="anchor" aria-hidden="true" href="#025consolechrome自带好用的计算器"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/025_console/" rel="nofollow"&gt;025《Console》Chrome自带好用的计算器&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c7bc7cabd06a453dbed2bae0a2bf08d5.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c7bc7cabd06a453dbed2bae0a2bf08d5.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Chrome计算机的好用之处: 既可以看到加数字的记录,也可以实时预览运算的结果, 输入完成后还可以很方便的核查一遍, 还有一点: Chrome计算器观赏性强(逼格很高)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-024dark-reader为任意网站启用夜间模式" class="anchor" aria-hidden="true" href="#024dark-reader为任意网站启用夜间模式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/024_dark_reader/" rel="nofollow"&gt;024《Dark Reader》为任意网站启用夜间模式&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/35e84f58945d4775a31154ea4dc51cac.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/35e84f58945d4775a31154ea4dc51cac.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;喜欢夜间模式的小伙伴, Dark Reader应该可以满足你了~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5&gt;&lt;a id="user-content-023fireshot一键滚动截屏整个网页" class="anchor" aria-hidden="true" href="#023fireshot一键滚动截屏整个网页"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/023_fireshot/" rel="nofollow"&gt;023《FireShot》一键滚动截屏整个网页&lt;/a&gt;&lt;/h5&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/81ac43fe1d6e454b93dc7f3ae57d96cd.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/81ac43fe1d6e454b93dc7f3ae57d96cd.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
总体来讲, FireShot是一款不错的软件, 免费且功能够用, 滚动截图的功能比同类软件做的都要好&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-022扩展管理器管理你的chrome扩展" class="anchor" aria-hidden="true" href="#022扩展管理器管理你的chrome扩展"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/022kuo_zhan_guan_li_qi/" rel="nofollow"&gt;022《扩展管理器》管理你的Chrome扩展&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/0480fffebb10437c8d5555f085de9006.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/0480fffebb10437c8d5555f085de9006.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
如果Chrome安装的插件很多, 我们可以对插件进行分组, 按照场景,启用不同组的插件&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-021哔哩哔哩助手助你快速成为b站老司机" class="anchor" aria-hidden="true" href="#021哔哩哔哩助手助你快速成为b站老司机"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/021_bi_li_bi_li_zhu_shou/" rel="nofollow"&gt;021《哔哩哔哩助手》助你快速成为B站老司机&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6ccb9837b60d4d79814a8add20723d97.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6ccb9837b60d4d79814a8add20723d97.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;哔哩哔哩助手, 功能实用,开发者也一直保持着较高频率的更新,可以放心食用~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-020boxel-rebound嗨到中毒的弹跳小方块附自制赛道分享方法" class="anchor" aria-hidden="true" href="#020boxel-rebound嗨到中毒的弹跳小方块附自制赛道分享方法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/020_boxel_rebound/" rel="nofollow"&gt;020《Boxel Rebound》“嗨到中毒”的弹跳小方块(附自制赛道分享方法)&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/dbc83cc53c26492db8843ff3e35fc75d.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/dbc83cc53c26492db8843ff3e35fc75d.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
Boxel Rebound是一个偏极客的小游戏, 玩法简单, 可以自由创建赛道, 分享赛道, 获取别人的赛道进行二次开发; 无论你是Mac用户,Windows用户,Linux用户, 只要安装了Chrome浏览器, 就可以玩耍Boxel Rebound&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-019mega网盘可以良心到什么程度-试试mega吧" class="anchor" aria-hidden="true" href="#019mega网盘可以良心到什么程度-试试mega吧"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/019_mega/" rel="nofollow"&gt;019《MEGA》网盘可以良心到什么程度? 试试MEGA吧!&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b5aea0b5e3c54f0a9a050a754a67093d.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b5aea0b5e3c54f0a9a050a754a67093d.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;没有限速的概念(真的被百度盘的限速策略恶心到了)&lt;/li&gt;
&lt;li&gt;在国内可用(google虽好, 但国内用不了, MEGAsync亲测国内可用)&lt;/li&gt;
&lt;li&gt;云端加密, 资源不会被封杀&lt;/li&gt;
&lt;li&gt;官方提供了Linux客户端&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-018enhanced-github从冰柜到冰棍儿下载github单个文件" class="anchor" aria-hidden="true" href="#018enhanced-github从冰柜到冰棍儿下载github单个文件"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/018_enhanced_github/" rel="nofollow"&gt;018《Enhanced Github》从“冰柜”到“冰棍儿”,下载Github单个文件&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/769a22f995d74226ba4104aba7e8ab59.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/769a22f995d74226ba4104aba7e8ab59.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/00541b7bd6954f8ea2a6a1beaebbb79b.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/00541b7bd6954f8ea2a6a1beaebbb79b.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
我需要Github给我一根冰棍解暑,Github却坚持把装有冰棍的冰柜也送给我（哥们儿真够意思）... 有了Enhanced Github这款插件, 我们可以下载Github优秀项目中最核心的代码文件进行学习, 而不是 下载 整个仓库作为藏品&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-017新浪微博图床本地markdown编写更流畅-新浪微博图床来帮忙" class="anchor" aria-hidden="true" href="#017新浪微博图床本地markdown编写更流畅-新浪微博图床来帮忙"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/017_xin_lang_wei_bo_tu_chuang/" rel="nofollow"&gt;017《新浪微博图床》本地Markdown编写更流畅, 新浪微博图床来帮忙&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/48c12b3864f84e988e073209fd7cf8e4.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/48c12b3864f84e988e073209fd7cf8e4.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
用Markdown写文章, 如果文章中使用了本地配图, 那本地配图就要和文章一起打包,否则别人是看不到图片的,如果把本地图片放到网络服务器, 然后直接把图片的url粘贴到文章里面, 就可以免除图片打包的步骤&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-016解除b站区域限制查看进击的巨人第三季" class="anchor" aria-hidden="true" href="#016解除b站区域限制查看进击的巨人第三季"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/016_jie_chu_b_zhan_qu_yu_xian_zhi/" rel="nofollow"&gt;016《解除B站区域限制》查看进击的巨人第三季&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/34d50d4d15094ca08e1bbd76c477122a.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/34d50d4d15094ca08e1bbd76c477122a.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/99fd518796894945aa87225a5022c453.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/99fd518796894945aa87225a5022c453.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
解除B站区域限制,B站老司机必备技能&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-015xpath-helper完成bing每日壁纸的小爬虫" class="anchor" aria-hidden="true" href="#015xpath-helper完成bing每日壁纸的小爬虫"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/015_xpath_helper/" rel="nofollow"&gt;015《XPath Helper》完成Bing每日壁纸的小爬虫&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/308bec78f4674130b85a5852f0b25a88.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/308bec78f4674130b85a5852f0b25a88.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;XPath是一个辅助我们写爬虫的小插件, 我们可以用XPath辅助我们完成一个Bing壁纸的小爬虫~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-014超级马里奥游戏chrome变身小霸王" class="anchor" aria-hidden="true" href="#014超级马里奥游戏chrome变身小霸王"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/014_chao_ji_ma_li_ao_you_xi/" rel="nofollow"&gt;014《超级马里奥游戏》Chrome变身小霸王&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/008f3bd3c8b8483b9d70be5d5ed4f9ee.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/008f3bd3c8b8483b9d70be5d5ed4f9ee.gif" alt="超级玛丽.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;用Chrome玩超级马里奥是一种什么体验? 哈哈, 好玩! 《超级马里奥游戏》这款插件,可以让你打开Chrome, 随时玩一局超级玛丽, 嘿嘿&lt;g-emoji class="g-emoji" alias="yum" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f60b.png"&gt;😋&lt;/g-emoji&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-013quick-qr用二维码实现云粘贴" class="anchor" aria-hidden="true" href="#013quick-qr用二维码实现云粘贴"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/013_quick_qr/" rel="nofollow"&gt;013《Quick QR》用二维码实现云粘贴&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b59f299316624e86aa7cdd379a02aac4.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b59f299316624e86aa7cdd379a02aac4.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;通过Quick QR, 我们可以不借助任何通讯软件,通过手机扫码,获取PC浏览器上任意一段文字信息(云粘贴板哦~)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-012ourstickyschrome特色网页便签纸" class="anchor" aria-hidden="true" href="#012ourstickyschrome特色网页便签纸"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/012_ourstickys/" rel="nofollow"&gt;012《OurStickys》Chrome特色网页便签纸&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/62597d60ffd6443396725c9677951221.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/62597d60ffd6443396725c9677951221.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;向众人介绍喜欢的网页功能时,可以边讲,边向网页打便签,这样既能让人眼前一亮,也让听众容易抓住重点~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-011-whatruns一键分析网站技术栈" class="anchor" aria-hidden="true" href="#011-whatruns一键分析网站技术栈"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/011_whatruns/" rel="nofollow"&gt;011 《whatruns》一键分析网站技术栈&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/28cc002358c647878b54f9bcaaf67a0a.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/28cc002358c647878b54f9bcaaf67a0a.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;如果你对当前浏览的网站非常感兴趣, 可以通过whatruns了解软件的技术栈, 比如看看这个名为facebook用了什么技术&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-010speedtest网络测速插件speedtest" class="anchor" aria-hidden="true" href="#010speedtest网络测速插件speedtest"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/010_speedtest/" rel="nofollow"&gt;010《speedtest》网络测速插件speedtest&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9aa1e5323a6a4cbcb96304b33a5261c8.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9aa1e5323a6a4cbcb96304b33a5261c8.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;当上网速度很慢的时候, 人们想到的第一件事就进行网络测速,在window上, 只要你安装了360全家桶, 测速功能就是默认安装的, 但测速这种功能根本不需要安装到本地, 交给浏览器就好了&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-009vimiumchrome与vim双神器融合" class="anchor" aria-hidden="true" href="#009vimiumchrome与vim双神器融合"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/009_vimium/" rel="nofollow"&gt;009《vimium》Chrome与vim双神器融合&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/7d6e9fadef3f48409c81a8c76d24e0cc.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/7d6e9fadef3f48409c81a8c76d24e0cc.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;vimium可以让我们只使用键盘就可以浏览网页, 如果你第一次看到有人使用vimium, 它的操作方式绝对能让你感到惊艳~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-008chrome-cleaner-pro为chrome加速" class="anchor" aria-hidden="true" href="#008chrome-cleaner-pro为chrome加速"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/008_chrome_cleaner_pro/" rel="nofollow"&gt;008《Chrome Cleaner Pro》为Chrome加速&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/30899ae22f644a9bb62eb8b24d75c884.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/30899ae22f644a9bb62eb8b24d75c884.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Chrome经过最近几年的发展, 强力的扩展越来越多, 离Chrome OS的目标也越来越近, 软件做大了就会有类似Windows的通病, 软件会变慢, 让Chrome变快的最简单方式就是清理垃圾, 而Chrome Cleaner Pro走的是一键清理的路子~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-007loom-chrome翻录网页视频神器" class="anchor" aria-hidden="true" href="#007loom-chrome翻录网页视频神器"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/007_loom/" rel="nofollow"&gt;007《loom》 Chrome翻录网页视频神器&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/4058cf0008074c5f86b8eb1684e7a1a0.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/4058cf0008074c5f86b8eb1684e7a1a0.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Loom可以一键录制浏览器的单个标签页(盗版翻录视频的神器), 录制完成后自动生成在线网页,进行视频播放, 可以下载刚刚录制的视频, 也可以为刚刚生成的在线视频设置密码(盗版录屏加发布一条龙服务~)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-006similarsites-一键查找姊妹网站-similarsites" class="anchor" aria-hidden="true" href="#006similarsites-一键查找姊妹网站-similarsites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/006_similarsites/" rel="nofollow"&gt;006《SimilarSites》 一键查找姊妹网站 SimilarSites&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/26c6c604be1c41e88ebfe79c733173b0.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/26c6c604be1c41e88ebfe79c733173b0.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;当你浏览一个很棒的站点的时候, 或许你会想到, 和它"差不多"的站点有哪些, 尤其是针对一些资源站点, 这个站点没有, 而它同类的站点"往往有"! SimilarSites, 它的作用只有一个, 发现同类站点!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-005video-speed-controller-刷课刷剧神器给网页视频加个速最快可达16倍" class="anchor" aria-hidden="true" href="#005video-speed-controller-刷课刷剧神器给网页视频加个速最快可达16倍"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/005_video_speed_controller/" rel="nofollow"&gt;005《Video Speed Controller》 刷课（刷剧）神器！给网页视频加个速(最快可达16倍!)&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/083c51a1c32a4ad6931646bb005fd5a3.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/083c51a1c32a4ad6931646bb005fd5a3.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;刷一些没营养视频的时候, 我们会有倍速播放视频的需求, 而网站的在线播放器一般只提供不高于4倍的播放速度, 而Video Speed Controller可以将视频播放速度提高到16倍速~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-004tampermonkey-油猴子-给浏览器开个挂" class="anchor" aria-hidden="true" href="#004tampermonkey-油猴子-给浏览器开个挂"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/004_tampermonkey/" rel="nofollow"&gt;004《Tampermonkey》 油猴子! 给浏览器开个挂&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e87601eb459549b3b8e33994fc3fdfb4.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e87601eb459549b3b8e33994fc3fdfb4.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;油猴子必备成为Chrome的第二应用商店, 有了油猴子, 你可以免费查看VIP视频, 清除各种网页广告, 在豆瓣影评页面显示电影资源的下载地址~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-003secure-shell-app-chrome中开启ssh一种什么体验" class="anchor" aria-hidden="true" href="#003secure-shell-app-chrome中开启ssh一种什么体验"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/003_secure_shell_app/" rel="nofollow"&gt;003《Secure Shell App》 Chrome中开启ssh一种什么体验&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/87b66b4cbd12426bbab65a3443f1f1ec.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/87b66b4cbd12426bbab65a3443f1f1ec.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;很多小白想要通过购买服务器搭建自己的VPN, 购买服务器后, 第一步就是要通过ssh登录服务器, 而Windows并没有自带ssh软件,现在你无需下载putty或xshell ,可以通过这款Secure Shell App在chrome直接实现ssh登录服务器了&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-002-chrono-让chrome下载资源更容易" class="anchor" aria-hidden="true" href="#002-chrono-让chrome下载资源更容易"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/002_chrono/" rel="nofollow"&gt;002 《chrono》 让Chrome下载资源更容易&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b574ee1798984ff49396837b620f51ef.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b574ee1798984ff49396837b620f51ef.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;chrono可以非常方便的嗅探识别网页中的资源, 然后一键下载所有资源(收图喽!)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-001markdown-here-markdown一键转换到富文本格式" class="anchor" aria-hidden="true" href="#001markdown-here-markdown一键转换到富文本格式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://www.v2fy.com/p/001_markdown_here/" rel="nofollow"&gt;001《markdown-here》 Markdown一键转换到"富文本格式"&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fc5de2eb22184a138c618728cfb40ede.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fc5de2eb22184a138c618728cfb40ede.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;有了markdown-here这个插件, 可以在网页版 QQ邮箱, Gmail, 新浪头条文章, 里面使用mardown格式进行书写,然后一键转换为富文本&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-他人眼中的-chrome插件英雄榜商业互吹模块" class="anchor" aria-hidden="true" href="#他人眼中的-chrome插件英雄榜商业互吹模块"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;他人眼中的 Chrome插件英雄榜(商业互吹模块)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/88386634" rel="nofollow"&gt;《这份“插件英雄榜Top20”才是Chrome的正确打开方式！》&lt;/a&gt; 作者: &lt;a href="https://me.csdn.net/dQCFKyQDXYm3F8rB0" rel="nofollow"&gt;AI科技大本营&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58636515" rel="nofollow"&gt;《Chrome 插件英雄榜》&lt;/a&gt; 作者: &lt;a href="https://www.zhihu.com/people/loonggg/activities" rel="nofollow"&gt;非著名程序员&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://openingsource.org/6190/zh-tw/" rel="nofollow"&gt;《開源日報第363期》&lt;/a&gt; 作者: &lt;a href="https://openingsource.org/" rel="nofollow"&gt;开源工厂&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/Y-9ht-E7-OdJOEDDb3yyWw" rel="nofollow"&gt;《一根火柴的N种打开方式》&lt;/a&gt; 作者: &lt;a href="https://github.com/LuoJiangYong"&gt;老罗巴扎嘿&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-名字起啥好" class="anchor" aria-hidden="true" href="#名字起啥好"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;名字起啥好?&lt;/h2&gt;
&lt;p&gt;将这个仓库命名为&lt;strong&gt;Chrome扩展英雄榜&lt;/strong&gt;可能更准确些,但&lt;strong&gt;插件&lt;/strong&gt;这个名词, 更通俗易懂, 所以就使用了&lt;strong&gt;Chrome插件英雄榜&lt;/strong&gt;这个命名 ,感谢@&lt;a href="https://github.com/hjthjthjt"&gt;hjthjthjt&lt;/a&gt; 给出的&lt;a href="https://github.com/zhaoolee/ChromeAppHeroes/issues/14"&gt;issue&lt;/a&gt;纠正&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-推荐姊妹仓库" class="anchor" aria-hidden="true" href="#推荐姊妹仓库"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/zhaoolee/StarsAndClown"&gt;推荐姊妹仓库&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;本仓库的姊妹篇:**&lt;a href="https://github.com/zhaoolee/StarsAndClown"&gt;《Github星聚弃疗榜》&lt;/a&gt;**为Github创意项目写一本推荐书，让Github优秀项目造福人类~ 已开源到Github: &lt;a href="https://github.com/zhaoolee/StarsAndClown"&gt;https://github.com/zhaoolee/StarsAndClown&lt;/a&gt; 同样有趣有料哦~&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-感谢" class="anchor" aria-hidden="true" href="#感谢"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;感谢&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;感谢 掘金沸点运营 &lt;a href="https://juejin.im/user/5b39bd7de51d4558d43ff06d" rel="nofollow"&gt;@清蒸不是水煮&lt;/a&gt; 给出的 &lt;strong&gt;正面最开始放个索引目录比较好&lt;/strong&gt; 的小建议&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;感谢&lt;a href="https://www.jianshu.com/" rel="nofollow"&gt;简书&lt;/a&gt;社区提供超棒的Markdown编辑器,&lt;strong&gt;Chrome插件英雄榜&lt;/strong&gt;的编辑工作,几乎全部由通过简书编辑器完成&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;** emm... &lt;a href="https://zhaoolee.com/ChromeAppHeroes/download_the_chrome_extension_from_the_store.html" rel="nofollow"&gt;从官方商店下载Chrome插件的方法&lt;/a&gt;**&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Chrome插件英雄榜&lt;/strong&gt; Github地址: &lt;a href="https://github.com/zhaoolee/ChromeAppHeroes"&gt;https://github.com/zhaoolee/ChromeAppHeroes&lt;/a&gt;
我需要你的支持, 希望你能为本项目填加一个 &lt;g-emoji class="g-emoji" alias="star2" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png"&gt;🌟&lt;/g-emoji&gt;星.
I need your support, I hope you can add a star &lt;g-emoji class="g-emoji" alias="star2" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png"&gt;🌟&lt;/g-emoji&gt; to this project.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-一根火柴的n种打开方式谷粒文化" class="anchor" aria-hidden="true" href="#一根火柴的n种打开方式谷粒文化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/meaning_of_gu_li.html" rel="nofollow"&gt;一根火柴的N种打开方式(谷粒文化)&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9ac21b8aea054eb48fc404fd429638bf.jpeg"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9ac21b8aea054eb48fc404fd429638bf.jpeg" alt="smartmockups_juunlhbe.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/dc9ab48d958843c98f2a4c9336cff748.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/dc9ab48d958843c98f2a4c9336cff748.png" alt="2.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-项目相关阅读" class="anchor" aria-hidden="true" href="#项目相关阅读"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目相关阅读&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/chrome_extended_resources_site.html" rel="nofollow"&gt;Chrome扩展资源站点推荐&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>zhaoolee</author><guid isPermaLink="false">https://github.com/zhaoolee/ChromeAppHeroes</guid><pubDate>Fri, 20 Dec 2019 00:09:00 GMT</pubDate></item><item><title>python-poetry/poetry #10 in Python, This week</title><link>https://github.com/python-poetry/poetry</link><description>&lt;p&gt;&lt;i&gt;Python dependency management and packaging made easy.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-poetry-dependency-management-for-python" class="anchor" aria-hidden="true" href="#poetry-dependency-management-for-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Poetry: Dependency Management for Python&lt;/h1&gt;
&lt;p&gt;Poetry helps you declare, manage and install dependencies of Python projects,
ensuring you have the right stack everywhere.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/python-poetry/poetry/master/assets/install.gif"&gt;&lt;img src="https://raw.githubusercontent.com/python-poetry/poetry/master/assets/install.gif" alt="Poetry Install" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It supports Python 2.7 and 3.4+.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/python-poetry/poetry/workflows/Tests/badge.svg"&gt;&lt;img src="https://github.com/python-poetry/poetry/workflows/Tests/badge.svg" alt="Tests Status" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://python-poetry.org/docs/" rel="nofollow"&gt;complete documentation&lt;/a&gt; is available on the &lt;a href="https://python-poetry.org" rel="nofollow"&gt;official website&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;Poetry provides a custom installer that will install &lt;code&gt;poetry&lt;/code&gt; isolated
from the rest of your system by vendorizing its dependencies. This is the
recommended way of installing &lt;code&gt;poetry&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py &lt;span class="pl-k"&gt;|&lt;/span&gt; python&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Alternatively, you can download the &lt;code&gt;get-poetry.py&lt;/code&gt; file and execute it separately.&lt;/p&gt;
&lt;p&gt;If you want to install prerelease versions, you can do so by passing &lt;code&gt;--preview&lt;/code&gt; to &lt;code&gt;get-poetry.py&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python get-poetry.py --preview&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Similarly, if you want to install a specific version, you can use &lt;code&gt;--version&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python get-poetry.py --version 0.7.0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Using &lt;code&gt;pip&lt;/code&gt; to install &lt;code&gt;poetry&lt;/code&gt; is also possible.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install --user poetry&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Be aware, however, that it will also install poetry's dependencies
which might cause conflicts.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-updating-poetry" class="anchor" aria-hidden="true" href="#updating-poetry"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Updating &lt;code&gt;poetry&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Updating poetry to the latest stable version is as simple as calling the &lt;code&gt;self update&lt;/code&gt; command.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;poetry self update&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you want to install prerelease versions, you can use the &lt;code&gt;--preview&lt;/code&gt; option.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;poetry self update --preview&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And finally, if you want to install a specific version you can pass it as an argument
to &lt;code&gt;self update&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;poetry self update 1.0.0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;!!!note&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;If you are still on poetry version &amp;lt; 1.0 use `poetry self:update` instead.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-enable-tab-completion-for-bash-fish-or-zsh" class="anchor" aria-hidden="true" href="#enable-tab-completion-for-bash-fish-or-zsh"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Enable tab completion for Bash, Fish, or Zsh&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;poetry&lt;/code&gt; supports generating completion scripts for Bash, Fish, and Zsh.
See &lt;code&gt;poetry help completions&lt;/code&gt; for full details, but the gist is as simple as using one of the following:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Bash&lt;/span&gt;
poetry completions bash &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; /etc/bash_completion.d/poetry.bash-completion

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Bash (macOS/Homebrew)&lt;/span&gt;
poetry completions bash &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;brew --prefix&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;/etc/bash_completion.d/poetry.bash-completion

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Fish&lt;/span&gt;
poetry completions fish &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/.config/fish/completions/poetry.fish

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Zsh&lt;/span&gt;
poetry completions zsh &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/.zfunc/_poetry

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Zsh (macOS/Homebrew)&lt;/span&gt;
poetry completions zsh &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;brew --prefix&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;/share/zsh/site-functions/_poetry&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; you may need to restart your shell in order for the changes to take
effect.&lt;/p&gt;
&lt;p&gt;For &lt;code&gt;zsh&lt;/code&gt;, you must then add the following line in your &lt;code&gt;~/.zshrc&lt;/code&gt; before
&lt;code&gt;compinit&lt;/code&gt; (not for homebrew setup):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;fpath+=&lt;span class="pl-k"&gt;~&lt;/span&gt;/.zfunc&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;poetry&lt;/code&gt; is a tool to handle dependency installation as well as building and packaging of Python packages.
It only needs one file to do all of that: the new, &lt;a href="https://www.python.org/dev/peps/pep-0518/" rel="nofollow"&gt;standardized&lt;/a&gt; &lt;code&gt;pyproject.toml&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In other words, poetry uses &lt;code&gt;pyproject.toml&lt;/code&gt; to replace &lt;code&gt;setup.py&lt;/code&gt;, &lt;code&gt;requirements.txt&lt;/code&gt;, &lt;code&gt;setup.cfg&lt;/code&gt;, &lt;code&gt;MANIFEST.in&lt;/code&gt; and the newly added &lt;code&gt;Pipfile&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-toml"&gt;&lt;pre&gt;[&lt;span class="pl-en"&gt;tool&lt;/span&gt;.&lt;span class="pl-en"&gt;poetry&lt;/span&gt;]
&lt;span class="pl-smi"&gt;name&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;my-package&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-smi"&gt;version&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;0.1.0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-smi"&gt;description&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;The description of the package&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;

&lt;span class="pl-smi"&gt;license&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MIT&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;

&lt;span class="pl-smi"&gt;authors&lt;/span&gt; = [
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Sébastien Eustace &amp;lt;sebastien@eustace.io&amp;gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
]

&lt;span class="pl-smi"&gt;readme&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;README.md&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Markdown files are supported&lt;/span&gt;

&lt;span class="pl-smi"&gt;repository&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;https://github.com/python-poetry/poetry&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-smi"&gt;homepage&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;https://github.com/python-poetry/poetry&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;

&lt;span class="pl-smi"&gt;keywords&lt;/span&gt; = [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;packaging&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;poetry&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]

[&lt;span class="pl-en"&gt;tool&lt;/span&gt;.&lt;span class="pl-en"&gt;poetry&lt;/span&gt;.&lt;span class="pl-en"&gt;dependencies&lt;/span&gt;]
&lt;span class="pl-smi"&gt;python&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;~2.7 || ^3.2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Compatible python versions must be declared here&lt;/span&gt;
&lt;span class="pl-smi"&gt;toml&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;^0.9&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Dependencies with extras&lt;/span&gt;
&lt;span class="pl-smi"&gt;requests&lt;/span&gt; = { &lt;span class="pl-smi"&gt;version&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;^2.13&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;extras&lt;/span&gt; = [ &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;security&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; ] }
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Python specific dependencies with prereleases allowed&lt;/span&gt;
&lt;span class="pl-smi"&gt;pathlib2&lt;/span&gt; = { &lt;span class="pl-smi"&gt;version&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;^2.2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;python&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;~2.7&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;allow-prereleases&lt;/span&gt; = &lt;span class="pl-c1"&gt;true&lt;/span&gt; }
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Git dependencies&lt;/span&gt;
&lt;span class="pl-smi"&gt;cleo&lt;/span&gt; = { &lt;span class="pl-smi"&gt;git&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;https://github.com/sdispater/cleo.git&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;branch&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;master&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; }

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Optional dependencies (extras)&lt;/span&gt;
&lt;span class="pl-smi"&gt;pendulum&lt;/span&gt; = { &lt;span class="pl-smi"&gt;version&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;^1.4&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;optional&lt;/span&gt; = &lt;span class="pl-c1"&gt;true&lt;/span&gt; }

[&lt;span class="pl-en"&gt;tool&lt;/span&gt;.&lt;span class="pl-en"&gt;poetry&lt;/span&gt;.&lt;span class="pl-en"&gt;dev-dependencies&lt;/span&gt;]
&lt;span class="pl-smi"&gt;pytest&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;^3.0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-smi"&gt;pytest-cov&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;^2.4&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;

[&lt;span class="pl-en"&gt;tool&lt;/span&gt;.&lt;span class="pl-en"&gt;poetry&lt;/span&gt;.&lt;span class="pl-en"&gt;scripts&lt;/span&gt;]
&lt;span class="pl-smi"&gt;my-script&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;my_package:main&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There are some things we can notice here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It will try to enforce &lt;a href="http://semver.org" rel="nofollow"&gt;semantic versioning&lt;/a&gt; as the best practice in version naming.&lt;/li&gt;
&lt;li&gt;You can specify the readme, included and excluded files: no more &lt;code&gt;MANIFEST.in&lt;/code&gt;.
&lt;code&gt;poetry&lt;/code&gt; will also use VCS ignore files (like &lt;code&gt;.gitignore&lt;/code&gt;) to populate the &lt;code&gt;exclude&lt;/code&gt; section.&lt;/li&gt;
&lt;li&gt;Keywords (up to 5) can be specified and will act as tags on the packaging site.&lt;/li&gt;
&lt;li&gt;The dependencies sections support caret, tilde, wildcard, inequality and multiple requirements.&lt;/li&gt;
&lt;li&gt;You must specify the python versions for which your package is compatible.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;poetry&lt;/code&gt; will also detect if you are inside a virtualenv and install the packages accordingly.
So, &lt;code&gt;poetry&lt;/code&gt; can be installed globally and used everywhere.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;poetry&lt;/code&gt; also comes with a full fledged dependency resolution library.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-why" class="anchor" aria-hidden="true" href="#why"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why?&lt;/h2&gt;
&lt;p&gt;Packaging systems and dependency management in Python are rather convoluted and hard to understand for newcomers.
Even for seasoned developers it might be cumbersome at times to create all files needed in a Python project: &lt;code&gt;setup.py&lt;/code&gt;,
&lt;code&gt;requirements.txt&lt;/code&gt;, &lt;code&gt;setup.cfg&lt;/code&gt;, &lt;code&gt;MANIFEST.in&lt;/code&gt; and the newly added &lt;code&gt;Pipfile&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So I wanted a tool that would limit everything to a single configuration file to do:
dependency management, packaging and publishing.&lt;/p&gt;
&lt;p&gt;It takes inspiration in tools that exist in other languages, like &lt;code&gt;composer&lt;/code&gt; (PHP) or &lt;code&gt;cargo&lt;/code&gt; (Rust).&lt;/p&gt;
&lt;p&gt;And, finally, there is no reliable tool to properly resolve dependencies in Python, so I started &lt;code&gt;poetry&lt;/code&gt;
to bring an exhaustive dependency resolver to the Python community.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-what-about-pipenv" class="anchor" aria-hidden="true" href="#what-about-pipenv"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What about Pipenv?&lt;/h3&gt;
&lt;p&gt;In short: I do not like the CLI it provides, or some of the decisions made,
and I think we can make a better and more intuitive one. Here are a few things
that I don't like.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-dependency-resolution" class="anchor" aria-hidden="true" href="#dependency-resolution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependency resolution&lt;/h4&gt;
&lt;p&gt;The dependency resolution is erratic and will fail even if there is a solution. Let's take an example:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pipenv install oslo.utils==1.4.0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;will fail with this error:&lt;/p&gt;
&lt;pre lang="text"&gt;&lt;code&gt;Could not find a version that matches pbr!=0.7,!=2.1.0,&amp;lt;1.0,&amp;gt;=0.6,&amp;gt;=2.0.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;while Poetry will get you the right set of packages:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;poetry add oslo.utils=1.4.0&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;results in :&lt;/p&gt;
&lt;pre lang="text"&gt;&lt;code&gt;  - Installing pytz (2018.3)
  - Installing netifaces (0.10.6)
  - Installing netaddr (0.7.19)
  - Installing oslo.i18n (2.1.0)
  - Installing iso8601 (0.1.12)
  - Installing six (1.11.0)
  - Installing babel (2.5.3)
  - Installing pbr (0.11.1)
  - Installing oslo.utils (1.4.0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is possible thanks to the efficient dependency resolver at the heart of Poetry.&lt;/p&gt;
&lt;p&gt;Here is a breakdown of what exactly happens here:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;oslo.utils (1.4.0)&lt;/code&gt; depends on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pbr (&amp;gt;=0.6,!=0.7,&amp;lt;1.0)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Babel (&amp;gt;=1.3)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;six (&amp;gt;=1.9.0)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;iso8601 (&amp;gt;=0.1.9)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;oslo.i18n (&amp;gt;=1.3.0)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;netaddr (&amp;gt;=0.7.12)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;netifaces (&amp;gt;=0.10.4)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What interests us is &lt;code&gt;pbr (&amp;gt;=0.6,!=0.7,&amp;lt;1.0)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;At this point, poetry will choose &lt;code&gt;pbr==0.11.1&lt;/code&gt; which is the latest version that matches the constraint.&lt;/p&gt;
&lt;p&gt;Next it will try to select &lt;code&gt;oslo.i18n==3.20.0&lt;/code&gt; which is the latest version that matches &lt;code&gt;oslo.i18n (&amp;gt;=1.3.0)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;However this version requires &lt;code&gt;pbr (!=2.1.0,&amp;gt;=2.0.0)&lt;/code&gt; which is incompatible with &lt;code&gt;pbr==0.11.1&lt;/code&gt;,
so &lt;code&gt;poetry&lt;/code&gt; will try to find a version of &lt;code&gt;oslo.i18n&lt;/code&gt; that satisfies &lt;code&gt;pbr (&amp;gt;=0.6,!=0.7,&amp;lt;1.0)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;By analyzing the releases of &lt;code&gt;oslo.i18n&lt;/code&gt;, it will find &lt;code&gt;oslo.i18n==2.1.0&lt;/code&gt; which requires &lt;code&gt;pbr (&amp;gt;=0.11,&amp;lt;2.0)&lt;/code&gt;.
At this point the rest of the resolution is straightforward since there is no more conflict.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://python-poetry.org" rel="nofollow"&gt;Official Website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/python-poetry/poetry/issues"&gt;Issue Tracker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://discordapp.com/invite/awxPgve" rel="nofollow"&gt;Discord&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>python-poetry</author><guid isPermaLink="false">https://github.com/python-poetry/poetry</guid><pubDate>Fri, 20 Dec 2019 00:10:00 GMT</pubDate></item><item><title>NVlabs/stylegan #11 in Python, This week</title><link>https://github.com/NVlabs/stylegan</link><description>&lt;p&gt;&lt;i&gt;StyleGAN - Official TensorFlow Implementation&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-stylegan--official-tensorflow-implementation" class="anchor" aria-hidden="true" href="#stylegan--official-tensorflow-implementation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;StyleGAN — Official TensorFlow Implementation&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/d4c11ac2b538cba463dfd1e43d05fe4f30f2d33d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d677265656e2e7376673f7374796c653d706c6173746963"&gt;&lt;img src="https://camo.githubusercontent.com/d4c11ac2b538cba463dfd1e43d05fe4f30f2d33d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d677265656e2e7376673f7374796c653d706c6173746963" alt="Python 3.6" data-canonical-src="https://img.shields.io/badge/python-3.6-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/11658cad8470d233bb733d0b72dc9f85738b0c60/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f74656e736f72666c6f772d312e31302d677265656e2e7376673f7374796c653d706c6173746963"&gt;&lt;img src="https://camo.githubusercontent.com/11658cad8470d233bb733d0b72dc9f85738b0c60/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f74656e736f72666c6f772d312e31302d677265656e2e7376673f7374796c653d706c6173746963" alt="TensorFlow 1.10" data-canonical-src="https://img.shields.io/badge/tensorflow-1.10-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a5dab5f383e89d8397bd6a26b35ecafbca94277c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6375646e6e2d372e332e312d677265656e2e7376673f7374796c653d706c6173746963"&gt;&lt;img src="https://camo.githubusercontent.com/a5dab5f383e89d8397bd6a26b35ecafbca94277c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6375646e6e2d372e332e312d677265656e2e7376673f7374796c653d706c6173746963" alt="cuDNN 7.3.1" data-canonical-src="https://img.shields.io/badge/cudnn-7.3.1-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1a94f8355ec38c4cee39dec1e250552a499c37ac/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d43435f42592d2d4e432d677265656e2e7376673f7374796c653d706c6173746963"&gt;&lt;img src="https://camo.githubusercontent.com/1a94f8355ec38c4cee39dec1e250552a499c37ac/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d43435f42592d2d4e432d677265656e2e7376673f7374796c653d706c6173746963" alt="License CC BY-NC" data-canonical-src="https://img.shields.io/badge/license-CC_BY--NC-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./stylegan-teaser.png"&gt;&lt;img src="./stylegan-teaser.png" alt="Teaser image" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;strong&gt;Picture:&lt;/strong&gt; &lt;em&gt;These people are not real – they were produced by our generator that allows control over different aspects of the image.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This repository contains the official TensorFlow implementation of the following paper:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;A Style-Based Generator Architecture for Generative Adversarial Networks&lt;/strong&gt;&lt;br&gt;
Tero Karras (NVIDIA), Samuli Laine (NVIDIA), Timo Aila (NVIDIA)&lt;br&gt;
&lt;a href="https://arxiv.org/abs/1812.04948" rel="nofollow"&gt;https://arxiv.org/abs/1812.04948&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;em&gt;We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For business inquiries, please contact &lt;a href="mailto:researchinquiries@nvidia.com"&gt;researchinquiries@nvidia.com&lt;/a&gt;&lt;br&gt;
For press and other inquiries, please contact Hector Marinez at &lt;a href="mailto:hmarinez@nvidia.com"&gt;hmarinez@nvidia.com&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;★★★ NEW: StyleGAN2 is available at &lt;a href="https://github.com/NVlabs/stylegan2"&gt;https://github.com/NVlabs/stylegan2&lt;/a&gt; ★★★&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h2&gt;
&lt;p&gt;Material related to our paper is available via the following links:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Paper: &lt;a href="https://arxiv.org/abs/1812.04948" rel="nofollow"&gt;https://arxiv.org/abs/1812.04948&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/kSLJriaOumA" rel="nofollow"&gt;https://youtu.be/kSLJriaOumA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code: &lt;a href="https://github.com/NVlabs/stylegan"&gt;https://github.com/NVlabs/stylegan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;FFHQ: &lt;a href="https://github.com/NVlabs/ffhq-dataset"&gt;https://github.com/NVlabs/ffhq-dataset&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additional material can be found on Google Drive:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Path&lt;/th&gt;
&lt;th align="left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://drive.google.com/open?id=1uka3a1noXHAydRPRbknqwKVGODvnmUBX" rel="nofollow"&gt;StyleGAN&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Main folder.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;├  &lt;a href="https://drive.google.com/open?id=1v-HkF3Ehrpon7wVIx4r5DLcko_U_V6Lt" rel="nofollow"&gt;stylegan-paper.pdf&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;High-quality version of the paper PDF.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;├  &lt;a href="https://drive.google.com/open?id=1uzwkZHQX_9pYg1i0d1Nbe3D9xPO8-qBf" rel="nofollow"&gt;stylegan-video.mp4&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;High-quality version of the result video.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;├  &lt;a href="https://drive.google.com/open?id=1-l46akONUWF6LCpDoeq63H53rD7MeiTd" rel="nofollow"&gt;images&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Example images produced using our generator.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│  ├  &lt;a href="https://drive.google.com/open?id=1ToY5P4Vvf5_c3TyUizQ8fckFFoFtBvD8" rel="nofollow"&gt;representative-images&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;High-quality images to be used in articles, blog posts, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│  └  &lt;a href="https://drive.google.com/open?id=100DJ0QXyG89HZzB4w2Cbyf4xjNK54cQ1" rel="nofollow"&gt;100k-generated-images&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;100,000 generated images for different amounts of truncation.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│     ├  &lt;a href="https://drive.google.com/open?id=14lm8VRN1pr4g_KVe6_LvyDX1PObst6d4" rel="nofollow"&gt;ffhq-1024x1024&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Generated using Flickr-Faces-HQ dataset at 1024×1024.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│     ├  &lt;a href="https://drive.google.com/open?id=1Vxz9fksw4kgjiHrvHkX4Hze4dyThFW6t" rel="nofollow"&gt;bedrooms-256x256&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Generated using LSUN Bedroom dataset at 256×256.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│     ├  &lt;a href="https://drive.google.com/open?id=1MFCvOMdLE2_mpeLPTiDw5dxc2CRuKkzS" rel="nofollow"&gt;cars-512x384&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Generated using LSUN Car dataset at 512×384.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│     └  &lt;a href="https://drive.google.com/open?id=1gq-Gj3GRFiyghTPKhp8uDMA9HV_0ZFWQ" rel="nofollow"&gt;cats-256x256&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Generated using LSUN Cat dataset at 256×256.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;├  &lt;a href="https://drive.google.com/open?id=1N8pOd_Bf8v89NGUaROdbD8-ayLPgyRRo" rel="nofollow"&gt;videos&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Example videos produced using our generator.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│  └  &lt;a href="https://drive.google.com/open?id=1NFO7_vH0t98J13ckJYFd7kuaTkyeRJ86" rel="nofollow"&gt;high-quality-video-clips&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Individual segments of the result video as high-quality MP4.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;├  &lt;a href="https://drive.google.com/open?id=1u2xu7bSrWxrbUxk-dT-UvEJq8IjdmNTP" rel="nofollow"&gt;ffhq-dataset&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Raw data for the &lt;a href="https://github.com/NVlabs/ffhq-dataset"&gt;Flickr-Faces-HQ dataset&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;└  &lt;a href="https://drive.google.com/open?id=1MASQyN5m0voPcx7-9K0r5gObhvvPups7" rel="nofollow"&gt;networks&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Pre-trained networks as pickled instances of &lt;a href="./dnnlib/tflib/network.py"&gt;dnnlib.tflib.Network&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;   ├  &lt;a href="https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ" rel="nofollow"&gt;stylegan-ffhq-1024x1024.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with Flickr-Faces-HQ dataset at 1024×1024.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;   ├  &lt;a href="https://drive.google.com/uc?id=1MGqJl28pN4t7SAtSrPdSRJSQJqahkzUf" rel="nofollow"&gt;stylegan-celebahq-1024x1024.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with CelebA-HQ dataset at 1024×1024.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;   ├  &lt;a href="https://drive.google.com/uc?id=1MOSKeGF0FJcivpBI7s63V9YHloUTORiF" rel="nofollow"&gt;stylegan-bedrooms-256x256.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with LSUN Bedroom dataset at 256×256.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;   ├  &lt;a href="https://drive.google.com/uc?id=1MJ6iCfNtMIRicihwRorsM3b7mmtmK9c3" rel="nofollow"&gt;stylegan-cars-512x384.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with LSUN Car dataset at 512×384.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;   ├  &lt;a href="https://drive.google.com/uc?id=1MQywl0FNt6lHu8E_EUqnRbviagS7fbiJ" rel="nofollow"&gt;stylegan-cats-256x256.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with LSUN Cat dataset at 256×256.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;   └  &lt;a href="https://drive.google.com/open?id=1MvYdWCBuMfnoYGptRH-AgKLbPTsIQLhl" rel="nofollow"&gt;metrics&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Auxiliary networks for the quality and disentanglement metrics.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;      ├  &lt;a href="https://drive.google.com/uc?id=1MzTY44rLToO5APn8TZmfR7_ENSe5aZUn" rel="nofollow"&gt;inception_v3_features.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Standard &lt;a href="https://arxiv.org/abs/1512.00567" rel="nofollow"&gt;Inception-v3&lt;/a&gt; classifier that outputs a raw feature vector.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;      ├  &lt;a href="https://drive.google.com/uc?id=1N2-m9qszOeVC9Tq77WxsLnuWwOedQiD2" rel="nofollow"&gt;vgg16_zhang_perceptual.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Standard &lt;a href="https://arxiv.org/abs/1801.03924" rel="nofollow"&gt;LPIPS&lt;/a&gt; metric to estimate perceptual similarity.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;      ├  &lt;a href="https://drive.google.com/uc?id=1Q5-AI6TwWhCVM7Muu4tBM7rp5nG_gmCX" rel="nofollow"&gt;celebahq-classifier-00-male.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Binary classifier trained to detect a single attribute of CelebA-HQ.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;      └ ⋯&lt;/td&gt;
&lt;td align="left"&gt;Please see the file listing for remaining networks.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-licenses" class="anchor" aria-hidden="true" href="#licenses"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Licenses&lt;/h2&gt;
&lt;p&gt;All material, excluding the Flickr-Faces-HQ dataset, is made available under &lt;a href="https://creativecommons.org/licenses/by-nc/4.0/" rel="nofollow"&gt;Creative Commons BY-NC 4.0&lt;/a&gt; license by NVIDIA Corporation. You can &lt;strong&gt;use, redistribute, and adapt&lt;/strong&gt; the material for &lt;strong&gt;non-commercial purposes&lt;/strong&gt;, as long as you give appropriate credit by &lt;strong&gt;citing our paper&lt;/strong&gt; and &lt;strong&gt;indicating any changes&lt;/strong&gt; that you've made.&lt;/p&gt;
&lt;p&gt;For license information regarding the FFHQ dataset, please refer to the &lt;a href="https://github.com/NVlabs/ffhq-dataset"&gt;Flickr-Faces-HQ repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;inception_v3_features.pkl&lt;/code&gt; and &lt;code&gt;inception_v3_softmax.pkl&lt;/code&gt; are derived from the pre-trained &lt;a href="https://arxiv.org/abs/1512.00567" rel="nofollow"&gt;Inception-v3&lt;/a&gt; network by Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. The network was originally shared under &lt;a href="https://github.com/tensorflow/models/blob/master/LICENSE"&gt;Apache 2.0&lt;/a&gt; license on the &lt;a href="https://github.com/tensorflow/models"&gt;TensorFlow Models&lt;/a&gt; repository.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;vgg16.pkl&lt;/code&gt; and &lt;code&gt;vgg16_zhang_perceptual.pkl&lt;/code&gt; are derived from the pre-trained &lt;a href="https://arxiv.org/abs/1409.1556" rel="nofollow"&gt;VGG-16&lt;/a&gt; network by Karen Simonyan and Andrew Zisserman. The network was originally shared under &lt;a href="https://creativecommons.org/licenses/by/4.0/" rel="nofollow"&gt;Creative Commons BY 4.0&lt;/a&gt; license on the &lt;a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/" rel="nofollow"&gt;Very Deep Convolutional Networks for Large-Scale Visual Recognition&lt;/a&gt; project page.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;vgg16_zhang_perceptual.pkl&lt;/code&gt; is further derived from the pre-trained &lt;a href="https://arxiv.org/abs/1801.03924" rel="nofollow"&gt;LPIPS&lt;/a&gt; weights by Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman, and Oliver Wang. The weights were originally shared under &lt;a href="https://github.com/richzhang/PerceptualSimilarity/blob/master/LICENSE"&gt;BSD 2-Clause "Simplified" License&lt;/a&gt; on the &lt;a href="https://github.com/richzhang/PerceptualSimilarity"&gt;PerceptualSimilarity&lt;/a&gt; repository.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-system-requirements" class="anchor" aria-hidden="true" href="#system-requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;System requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Both Linux and Windows are supported, but we strongly recommend Linux for performance and compatibility reasons.&lt;/li&gt;
&lt;li&gt;64-bit Python 3.6 installation. We recommend Anaconda3 with numpy 1.14.3 or newer.&lt;/li&gt;
&lt;li&gt;TensorFlow 1.10.0 or newer with GPU support.&lt;/li&gt;
&lt;li&gt;One or more high-end NVIDIA GPUs with at least 11GB of DRAM. We recommend NVIDIA DGX-1 with 8 Tesla V100 GPUs.&lt;/li&gt;
&lt;li&gt;NVIDIA driver 391.35 or newer, CUDA toolkit 9.0 or newer, cuDNN 7.3.1 or newer.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-using-pre-trained-networks" class="anchor" aria-hidden="true" href="#using-pre-trained-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using pre-trained networks&lt;/h2&gt;
&lt;p&gt;A minimal example of using a pre-trained StyleGAN generator is given in &lt;a href="./pretrained_example.py"&gt;pretrained_example.py&lt;/a&gt;. When executed, the script downloads a pre-trained StyleGAN generator from Google Drive and uses it to generate an image:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; python pretrained_example.py
Downloading https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ .... done

Gs                              Params    OutputShape          WeightShape
---                             ---       ---                  ---
latents_in                      -         (?, 512)             -
...
images_out                      -         (?, 3, 1024, 1024)   -
---                             ---       ---                  ---
Total                           26219627

&amp;gt; ls results
example.png # https://drive.google.com/uc?id=1UDLT_zb-rof9kKH0GwiJW_bS9MoZi8oP
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A more advanced example is given in &lt;a href="./generate_figures.py"&gt;generate_figures.py&lt;/a&gt;. The script reproduces the figures from our paper in order to illustrate style mixing, noise inputs, and truncation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; python generate_figures.py
results/figure02-uncurated-ffhq.png     # https://drive.google.com/uc?id=1U3r1xgcD7o-Fd0SBRpq8PXYajm7_30cu
results/figure03-style-mixing.png       # https://drive.google.com/uc?id=1U-nlMDtpnf1RcYkaFQtbh5oxnhA97hy6
results/figure04-noise-detail.png       # https://drive.google.com/uc?id=1UX3m39u_DTU6eLnEW6MqGzbwPFt2R9cG
results/figure05-noise-components.png   # https://drive.google.com/uc?id=1UQKPcvYVeWMRccGMbs2pPD9PVv1QDyp_
results/figure08-truncation-trick.png   # https://drive.google.com/uc?id=1ULea0C12zGlxdDQFNLXOWZCHi3QNfk_v
results/figure10-uncurated-bedrooms.png # https://drive.google.com/uc?id=1UEBnms1XMfj78OHj3_cx80mUf_m9DUJr
results/figure11-uncurated-cars.png     # https://drive.google.com/uc?id=1UO-4JtAs64Kun5vIj10UXqAJ1d5Ir1Ke
results/figure12-uncurated-cats.png     # https://drive.google.com/uc?id=1USnJc14prlu3QAYxstrtlfXC9sDWPA-W
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The pre-trained networks are stored as standard pickle files on Google Drive:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Load pre-trained network.
url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl
with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:
    _G, _D, Gs = pickle.load(f)
    # _G = Instantaneous snapshot of the generator. Mainly useful for resuming a previous training run.
    # _D = Instantaneous snapshot of the discriminator. Mainly useful for resuming a previous training run.
    # Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code downloads the file and unpickles it to yield 3 instances of &lt;a href="./dnnlib/tflib/network.py"&gt;dnnlib.tflib.Network&lt;/a&gt;. To generate images, you will typically want to use &lt;code&gt;Gs&lt;/code&gt; – the other two networks are provided for completeness. In order for &lt;code&gt;pickle.load()&lt;/code&gt; to work, you will need to have the &lt;code&gt;dnnlib&lt;/code&gt; source directory in your PYTHONPATH and a &lt;code&gt;tf.Session&lt;/code&gt; set as default. The session can initialized by calling &lt;code&gt;dnnlib.tflib.init_tf()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;There are three ways to use the pre-trained generator:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;code&gt;Gs.run()&lt;/code&gt; for immediate-mode operation where the inputs and outputs are numpy arrays:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Pick latent vector.
rnd = np.random.RandomState(5)
latents = rnd.randn(1, Gs.input_shape[1])

# Generate image.
fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)
images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first argument is a batch of latent vectors of shape &lt;code&gt;[num, 512]&lt;/code&gt;. The second argument is reserved for class labels (not used by StyleGAN). The remaining keyword arguments are optional and can be used to further modify the operation (see below). The output is a batch of images, whose format is dictated by the &lt;code&gt;output_transform&lt;/code&gt; argument.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;code&gt;Gs.get_output_for()&lt;/code&gt; to incorporate the generator as a part of a larger TensorFlow expression:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;latents = tf.random_normal([self.minibatch_per_gpu] + Gs_clone.input_shape[1:])
images = Gs_clone.get_output_for(latents, None, is_validation=True, randomize_noise=True)
images = tflib.convert_images_to_uint8(images)
result_expr.append(inception_clone.get_output_for(images))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code is from &lt;a href="./metrics/frechet_inception_distance.py"&gt;metrics/frechet_inception_distance.py&lt;/a&gt;. It generates a batch of random images and feeds them directly to the &lt;a href="https://arxiv.org/abs/1512.00567" rel="nofollow"&gt;Inception-v3&lt;/a&gt; network without having to convert the data to numpy arrays in between.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Look up &lt;code&gt;Gs.components.mapping&lt;/code&gt; and &lt;code&gt;Gs.components.synthesis&lt;/code&gt; to access individual sub-networks of the generator. Similar to &lt;code&gt;Gs&lt;/code&gt;, the sub-networks are represented as independent instances of &lt;a href="./dnnlib/tflib/network.py"&gt;dnnlib.tflib.Network&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;src_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in src_seeds)
src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]
src_images = Gs.components.synthesis.run(src_dlatents, randomize_noise=False, **synthesis_kwargs)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code is from &lt;a href="./generate_figures.py"&gt;generate_figures.py&lt;/a&gt;. It first transforms a batch of latent vectors into the intermediate &lt;em&gt;W&lt;/em&gt; space using the mapping network and then turns these vectors into a batch of images using the synthesis network. The &lt;code&gt;dlatents&lt;/code&gt; array stores a separate copy of the same &lt;em&gt;w&lt;/em&gt; vector for each layer of the synthesis network to facilitate style mixing.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The exact details of the generator are defined in &lt;a href="./training/networks_stylegan.py"&gt;training/networks_stylegan.py&lt;/a&gt; (see &lt;code&gt;G_style&lt;/code&gt;, &lt;code&gt;G_mapping&lt;/code&gt;, and &lt;code&gt;G_synthesis&lt;/code&gt;). The following keyword arguments can be specified to modify the behavior when calling &lt;code&gt;run()&lt;/code&gt; and &lt;code&gt;get_output_for()&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;truncation_psi&lt;/code&gt; and &lt;code&gt;truncation_cutoff&lt;/code&gt; control the truncation trick that that is performed by default when using &lt;code&gt;Gs&lt;/code&gt; (ψ=0.7, cutoff=8). It can be disabled by setting &lt;code&gt;truncation_psi=1&lt;/code&gt; or &lt;code&gt;is_validation=True&lt;/code&gt;, and the image quality can be further improved at the cost of variation by setting e.g. &lt;code&gt;truncation_psi=0.5&lt;/code&gt;. Note that truncation is always disabled when using the sub-networks directly. The average &lt;em&gt;w&lt;/em&gt; needed to manually perform the truncation trick can be looked up using &lt;code&gt;Gs.get_var('dlatent_avg')&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;randomize_noise&lt;/code&gt; determines whether to use re-randomize the noise inputs for each generated image (&lt;code&gt;True&lt;/code&gt;, default) or whether to use specific noise values for the entire minibatch (&lt;code&gt;False&lt;/code&gt;). The specific values can be accessed via the &lt;code&gt;tf.Variable&lt;/code&gt; instances that are found using &lt;code&gt;[var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When using the mapping network directly, you can specify &lt;code&gt;dlatent_broadcast=None&lt;/code&gt; to disable the automatic duplication of &lt;code&gt;dlatents&lt;/code&gt; over the layers of the synthesis network.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Runtime performance can be fine-tuned via &lt;code&gt;structure='fixed'&lt;/code&gt; and &lt;code&gt;dtype='float16'&lt;/code&gt;. The former disables support for progressive growing, which is not needed for a fully-trained generator, and the latter performs all computation using half-precision floating point arithmetic.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-preparing-datasets-for-training" class="anchor" aria-hidden="true" href="#preparing-datasets-for-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preparing datasets for training&lt;/h2&gt;
&lt;p&gt;The training and evaluation scripts operate on datasets stored as multi-resolution TFRecords. Each dataset is represented by a directory containing the same image data in several resolutions to enable efficient streaming. There is a separate *.tfrecords file for each resolution, and if the dataset contains labels, they are stored in a separate file as well. By default, the scripts expect to find the datasets at &lt;code&gt;datasets/&amp;lt;NAME&amp;gt;/&amp;lt;NAME&amp;gt;-&amp;lt;RESOLUTION&amp;gt;.tfrecords&lt;/code&gt;. The directory can be changed by editing &lt;a href="./config.py"&gt;config.py&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;result_dir = 'results'
data_dir = 'datasets'
cache_dir = 'cache'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To obtain the FFHQ dataset (&lt;code&gt;datasets/ffhq&lt;/code&gt;), please refer to the &lt;a href="https://github.com/NVlabs/ffhq-dataset"&gt;Flickr-Faces-HQ repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To obtain the CelebA-HQ dataset (&lt;code&gt;datasets/celebahq&lt;/code&gt;), please refer to the &lt;a href="https://github.com/tkarras/progressive_growing_of_gans"&gt;Progressive GAN repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To obtain other datasets, including LSUN, please consult their corresponding project pages. The datasets can be converted to multi-resolution TFRecords using the provided &lt;a href="./dataset_tool.py"&gt;dataset_tool.py&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; python dataset_tool.py create_lsun datasets/lsun-bedroom-full ~/lsun/bedroom_lmdb --resolution 256
&amp;gt; python dataset_tool.py create_lsun_wide datasets/lsun-car-512x384 ~/lsun/car_lmdb --width 512 --height 384
&amp;gt; python dataset_tool.py create_lsun datasets/lsun-cat-full ~/lsun/cat_lmdb --resolution 256
&amp;gt; python dataset_tool.py create_cifar10 datasets/cifar10 ~/cifar10
&amp;gt; python dataset_tool.py create_from_images datasets/custom-dataset ~/custom-images
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-training-networks" class="anchor" aria-hidden="true" href="#training-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training networks&lt;/h2&gt;
&lt;p&gt;Once the datasets are set up, you can train your own StyleGAN networks as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Edit &lt;a href="./train.py"&gt;train.py&lt;/a&gt; to specify the dataset and training configuration by uncommenting or editing specific lines.&lt;/li&gt;
&lt;li&gt;Run the training script with &lt;code&gt;python train.py&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The results are written to a newly created directory &lt;code&gt;results/&amp;lt;ID&amp;gt;-&amp;lt;DESCRIPTION&amp;gt;&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The training may take several days (or weeks) to complete, depending on the configuration.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;By default, &lt;code&gt;train.py&lt;/code&gt; is configured to train the highest-quality StyleGAN (configuration F in Table 1) for the FFHQ dataset at 1024×1024 resolution using 8 GPUs. Please note that we have used 8 GPUs in all of our experiments. Training with fewer GPUs may not produce identical results – if you wish to compare against our technique, we strongly recommend using the same number of GPUs.&lt;/p&gt;
&lt;p&gt;Expected training times for the default configuration using Tesla V100 GPUs:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;GPUs&lt;/th&gt;
&lt;th align="left"&gt;1024×1024&lt;/th&gt;
&lt;th align="left"&gt;512×512&lt;/th&gt;
&lt;th align="left"&gt;256×256&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;41 days 4 hours&lt;/td&gt;
&lt;td align="left"&gt;24 days 21 hours&lt;/td&gt;
&lt;td align="left"&gt;14 days 22 hours&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;21 days 22 hours&lt;/td&gt;
&lt;td align="left"&gt;13 days 7 hours&lt;/td&gt;
&lt;td align="left"&gt;9 days 5 hours&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4&lt;/td&gt;
&lt;td align="left"&gt;11 days 8 hours&lt;/td&gt;
&lt;td align="left"&gt;7 days 0 hours&lt;/td&gt;
&lt;td align="left"&gt;4 days 21 hours&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;8&lt;/td&gt;
&lt;td align="left"&gt;6 days 14 hours&lt;/td&gt;
&lt;td align="left"&gt;4 days 10 hours&lt;/td&gt;
&lt;td align="left"&gt;3 days 8 hours&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-evaluating-quality-and-disentanglement" class="anchor" aria-hidden="true" href="#evaluating-quality-and-disentanglement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Evaluating quality and disentanglement&lt;/h2&gt;
&lt;p&gt;The quality and disentanglement metrics used in our paper can be evaluated using &lt;a href="./run_metrics.py"&gt;run_metrics.py&lt;/a&gt;. By default, the script will evaluate the Fréchet Inception Distance (&lt;code&gt;fid50k&lt;/code&gt;) for the pre-trained FFHQ generator and write the results into a newly created directory under &lt;code&gt;results&lt;/code&gt;. The exact behavior can be changed by uncommenting or editing specific lines in &lt;a href="./run_metrics.py"&gt;run_metrics.py&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Expected evaluation time and results for the pre-trained FFHQ generator using one Tesla V100 GPU:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Metric&lt;/th&gt;
&lt;th align="left"&gt;Time&lt;/th&gt;
&lt;th align="left"&gt;Result&lt;/th&gt;
&lt;th align="left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;fid50k&lt;/td&gt;
&lt;td align="left"&gt;16 min&lt;/td&gt;
&lt;td align="left"&gt;4.4159&lt;/td&gt;
&lt;td align="left"&gt;Fréchet Inception Distance using 50,000 images.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ppl_zfull&lt;/td&gt;
&lt;td align="left"&gt;55 min&lt;/td&gt;
&lt;td align="left"&gt;664.8854&lt;/td&gt;
&lt;td align="left"&gt;Perceptual Path Length for full paths in &lt;em&gt;Z&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ppl_wfull&lt;/td&gt;
&lt;td align="left"&gt;55 min&lt;/td&gt;
&lt;td align="left"&gt;233.3059&lt;/td&gt;
&lt;td align="left"&gt;Perceptual Path Length for full paths in &lt;em&gt;W&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ppl_zend&lt;/td&gt;
&lt;td align="left"&gt;55 min&lt;/td&gt;
&lt;td align="left"&gt;666.1057&lt;/td&gt;
&lt;td align="left"&gt;Perceptual Path Length for path endpoints in &lt;em&gt;Z&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ppl_wend&lt;/td&gt;
&lt;td align="left"&gt;55 min&lt;/td&gt;
&lt;td align="left"&gt;197.2266&lt;/td&gt;
&lt;td align="left"&gt;Perceptual Path Length for path endpoints in &lt;em&gt;W&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ls&lt;/td&gt;
&lt;td align="left"&gt;10 hours&lt;/td&gt;
&lt;td align="left"&gt;z: 165.0106&lt;br&gt;w: 3.7447&lt;/td&gt;
&lt;td align="left"&gt;Linear Separability in &lt;em&gt;Z&lt;/em&gt; and &lt;em&gt;W&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Please note that the exact results may vary from run to run due to the non-deterministic nature of TensorFlow.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;We thank Jaakko Lehtinen, David Luebke, and Tuomas Kynkäänniemi for in-depth discussions and helpful comments; Janne Hellsten, Tero Kuosmanen, and Pekka Jänis for compute infrastructure and help with the code release.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>NVlabs</author><guid isPermaLink="false">https://github.com/NVlabs/stylegan</guid><pubDate>Fri, 20 Dec 2019 00:11:00 GMT</pubDate></item><item><title>google-research/ALBERT #12 in Python, This week</title><link>https://github.com/google-research/ALBERT</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-albert" class="anchor" aria-hidden="true" href="#albert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ALBERT&lt;/h1&gt;
&lt;p&gt;***************New October 31, 2019 ***************&lt;/p&gt;
&lt;p&gt;Version 2 of ALBERT models is released. TF-Hub modules are available:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://tfhub.dev/google/albert_base/2" rel="nofollow"&gt;https://tfhub.dev/google/albert_base/2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tfhub.dev/google/albert_large/2" rel="nofollow"&gt;https://tfhub.dev/google/albert_large/2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tfhub.dev/google/albert_xlarge/2" rel="nofollow"&gt;https://tfhub.dev/google/albert_xlarge/2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tfhub.dev/google/albert_xxlarge/2" rel="nofollow"&gt;https://tfhub.dev/google/albert_xxlarge/2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this version, we apply 'no dropout', 'additional training data' and 'long training time' strategies to all models. We train ALBERT-base for 10M steps and other models for 3M steps.&lt;/p&gt;
&lt;p&gt;The result comparison to the v1 models is as followings:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Average&lt;/th&gt;
&lt;th&gt;SQuAD1.1&lt;/th&gt;
&lt;th&gt;SQuAD2.0&lt;/th&gt;
&lt;th&gt;MNLI&lt;/th&gt;
&lt;th&gt;SST-2&lt;/th&gt;
&lt;th&gt;RACE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;V2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ALBERT-base&lt;/td&gt;
&lt;td&gt;82.3&lt;/td&gt;
&lt;td&gt;90.2/83.2&lt;/td&gt;
&lt;td&gt;82.1/79.3&lt;/td&gt;
&lt;td&gt;84.6&lt;/td&gt;
&lt;td&gt;92.9&lt;/td&gt;
&lt;td&gt;66.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ALBERT-large&lt;/td&gt;
&lt;td&gt;85.7&lt;/td&gt;
&lt;td&gt;91.8/85.2&lt;/td&gt;
&lt;td&gt;84.9/81.8&lt;/td&gt;
&lt;td&gt;86.5&lt;/td&gt;
&lt;td&gt;94.9&lt;/td&gt;
&lt;td&gt;75.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ALBERT-xlarge&lt;/td&gt;
&lt;td&gt;87.9&lt;/td&gt;
&lt;td&gt;92.9/86.4&lt;/td&gt;
&lt;td&gt;87.9/84.1&lt;/td&gt;
&lt;td&gt;87.9&lt;/td&gt;
&lt;td&gt;95.4&lt;/td&gt;
&lt;td&gt;80.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ALBERT-xxlarge&lt;/td&gt;
&lt;td&gt;90.9&lt;/td&gt;
&lt;td&gt;94.6/89.1&lt;/td&gt;
&lt;td&gt;89.8/86.9&lt;/td&gt;
&lt;td&gt;90.6&lt;/td&gt;
&lt;td&gt;96.8&lt;/td&gt;
&lt;td&gt;86.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;V1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ALBERT-base&lt;/td&gt;
&lt;td&gt;80.1&lt;/td&gt;
&lt;td&gt;89.3/82.3&lt;/td&gt;
&lt;td&gt;80.0/77.1&lt;/td&gt;
&lt;td&gt;81.6&lt;/td&gt;
&lt;td&gt;90.3&lt;/td&gt;
&lt;td&gt;64.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ALBERT-large&lt;/td&gt;
&lt;td&gt;82.4&lt;/td&gt;
&lt;td&gt;90.6/83.9&lt;/td&gt;
&lt;td&gt;82.3/79.4&lt;/td&gt;
&lt;td&gt;83.5&lt;/td&gt;
&lt;td&gt;91.7&lt;/td&gt;
&lt;td&gt;68.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ALBERT-xlarge&lt;/td&gt;
&lt;td&gt;85.5&lt;/td&gt;
&lt;td&gt;92.5/86.1&lt;/td&gt;
&lt;td&gt;86.1/83.1&lt;/td&gt;
&lt;td&gt;86.4&lt;/td&gt;
&lt;td&gt;92.4&lt;/td&gt;
&lt;td&gt;74.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ALBERT-xxlarge&lt;/td&gt;
&lt;td&gt;91.0&lt;/td&gt;
&lt;td&gt;94.8/89.3&lt;/td&gt;
&lt;td&gt;90.2/87.4&lt;/td&gt;
&lt;td&gt;90.8&lt;/td&gt;
&lt;td&gt;96.9&lt;/td&gt;
&lt;td&gt;86.5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The comparison shows that for ALBERT-base, ALBERT-large, and ALBERT-xlarge, v2 is much better than v1, indicating the importance of applying the above three strategies. On average, ALBERT-xxlarge is slightly worse than the v1, because of the following two reasons: 1) Training additional 1.5 M steps (the only difference between these two models is training for 1.5M steps and 3M steps) did not lead to significant performance improvement. 2) For v1, we did a little bit hyperparameter search among the parameters sets given by BERT, Roberta, and XLnet. For v2, we simply adopt the parameters from v1 except for RACE, where we use a learning rate of 1e-5 and 0 &lt;a href="https://arxiv.org/pdf/1909.11942.pdf" rel="nofollow"&gt;ALBERT DR&lt;/a&gt; (dropout rate for ALBERT in finetuning). The original (v1) RACE hyperparameter will cause model divergence for v2 models. Given that the downstream tasks are sensitive to the fine-tuning hyperparameters, we should be careful about so called slight improvements.&lt;/p&gt;
&lt;p&gt;ALBERT is "A Lite" version of BERT, a popular unsupervised language
representation learning algorithm. ALBERT uses parameter-reduction techniques
that allow for large-scale configurations, overcome previous memory limitations,
and achieve better behavior with respect to model degradation.&lt;/p&gt;
&lt;p&gt;For a technical description of the algorithm, see our paper:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1909.11942" rel="nofollow"&gt;ALBERT: A Lite BERT for Self-supervised Learning of Language Representations&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-release-notes" class="anchor" aria-hidden="true" href="#release-notes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Release Notes&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Initial release: 10/9/2019&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-results" class="anchor" aria-hidden="true" href="#results"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Results&lt;/h1&gt;
&lt;p&gt;Performance of ALBERT on GLUE benchmark results using a single-model setup on
dev:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Models&lt;/th&gt;
&lt;th&gt;MNLI&lt;/th&gt;
&lt;th&gt;QNLI&lt;/th&gt;
&lt;th&gt;QQP&lt;/th&gt;
&lt;th&gt;RTE&lt;/th&gt;
&lt;th&gt;SST&lt;/th&gt;
&lt;th&gt;MRPC&lt;/th&gt;
&lt;th&gt;CoLA&lt;/th&gt;
&lt;th&gt;STS&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;BERT-large&lt;/td&gt;
&lt;td&gt;86.6&lt;/td&gt;
&lt;td&gt;92.3&lt;/td&gt;
&lt;td&gt;91.3&lt;/td&gt;
&lt;td&gt;70.4&lt;/td&gt;
&lt;td&gt;93.2&lt;/td&gt;
&lt;td&gt;88.0&lt;/td&gt;
&lt;td&gt;60.6&lt;/td&gt;
&lt;td&gt;90.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;XLNet-large&lt;/td&gt;
&lt;td&gt;89.8&lt;/td&gt;
&lt;td&gt;93.9&lt;/td&gt;
&lt;td&gt;91.8&lt;/td&gt;
&lt;td&gt;83.8&lt;/td&gt;
&lt;td&gt;95.6&lt;/td&gt;
&lt;td&gt;89.2&lt;/td&gt;
&lt;td&gt;63.6&lt;/td&gt;
&lt;td&gt;91.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RoBERTa-large&lt;/td&gt;
&lt;td&gt;90.2&lt;/td&gt;
&lt;td&gt;94.7&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;92.2&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;86.6&lt;/td&gt;
&lt;td&gt;96.4&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;90.9&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;68.0&lt;/td&gt;
&lt;td&gt;92.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ALBERT (1M)&lt;/td&gt;
&lt;td&gt;90.4&lt;/td&gt;
&lt;td&gt;95.2&lt;/td&gt;
&lt;td&gt;92.0&lt;/td&gt;
&lt;td&gt;88.1&lt;/td&gt;
&lt;td&gt;96.8&lt;/td&gt;
&lt;td&gt;90.2&lt;/td&gt;
&lt;td&gt;68.7&lt;/td&gt;
&lt;td&gt;92.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ALBERT (1.5M)&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;90.8&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;95.3&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;92.2&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;89.2&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;96.9&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;90.9&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;71.4&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;93.0&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Performance of ALBERT-xxl on SQuaD and RACE benchmarks using a single-model
setup:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Models&lt;/th&gt;
&lt;th&gt;SQuAD1.1 dev&lt;/th&gt;
&lt;th&gt;SQuAD2.0 dev&lt;/th&gt;
&lt;th&gt;SQuAD2.0 test&lt;/th&gt;
&lt;th&gt;RACE test (Middle/High)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;BERT-large&lt;/td&gt;
&lt;td&gt;90.9/84.1&lt;/td&gt;
&lt;td&gt;81.8/79.0&lt;/td&gt;
&lt;td&gt;89.1/86.3&lt;/td&gt;
&lt;td&gt;72.0 (76.6/70.1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;XLNet&lt;/td&gt;
&lt;td&gt;94.5/89.0&lt;/td&gt;
&lt;td&gt;88.8/86.1&lt;/td&gt;
&lt;td&gt;89.1/86.3&lt;/td&gt;
&lt;td&gt;81.8 (85.5/80.2)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RoBERTa&lt;/td&gt;
&lt;td&gt;94.6/88.9&lt;/td&gt;
&lt;td&gt;89.4/86.5&lt;/td&gt;
&lt;td&gt;89.8/86.8&lt;/td&gt;
&lt;td&gt;83.2 (86.5/81.3)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UPM&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;89.9/87.2&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;XLNet + SG-Net Verifier++&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;90.1/87.2&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ALBERT (1M)&lt;/td&gt;
&lt;td&gt;94.8/89.2&lt;/td&gt;
&lt;td&gt;89.9/87.2&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;86.0 (88.2/85.1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ALBERT (1.5M)&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;94.8/89.3&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;90.2/87.4&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;90.9/88.1&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;86.5 (89.0/85.5)&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-pre-trained-models" class="anchor" aria-hidden="true" href="#pre-trained-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-trained Models&lt;/h1&gt;
&lt;p&gt;TF-Hub modules are available:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://tfhub.dev/google/albert_base/1" rel="nofollow"&gt;https://tfhub.dev/google/albert_base/1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tfhub.dev/google/albert_large/1" rel="nofollow"&gt;https://tfhub.dev/google/albert_large/1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tfhub.dev/google/albert_xlarge/1" rel="nofollow"&gt;https://tfhub.dev/google/albert_xlarge/1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tfhub.dev/google/albert_xxlarge/1" rel="nofollow"&gt;https://tfhub.dev/google/albert_xxlarge/1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example usage of the TF-Hub module:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tags = set()
if is_training:
  tags.add("train")
albert_module = hub.Module("https://tfhub.dev/google/albert_base/1", tags=tags,
                           trainable=True)
albert_inputs = dict(
    input_ids=input_ids,
    input_mask=input_mask,
    segment_ids=segment_ids)
albert_outputs = albert_module(
    inputs=albert_inputs,
    signature="tokens",
    as_dict=True)

# If you want to use the token-level output, use
# albert_outputs["sequence_output"] instead.
output_layer = albert_outputs["pooled_output"]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For a full example, see &lt;code&gt;run_classifier_with_tfhub.py&lt;/code&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-pre-training-instructions" class="anchor" aria-hidden="true" href="#pre-training-instructions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-training Instructions&lt;/h1&gt;
&lt;p&gt;Use &lt;code&gt;run_pretraining.py&lt;/code&gt; to pretrain ALBERT:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install -r albert/requirements.txt
python -m albert.run_pretraining \
    --output_dir="${OUTPUT_DIR}" \
    --do_train \
    --do_eval \
    &amp;lt;additional flags&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;&lt;a id="user-content-fine-tuning-instructions" class="anchor" aria-hidden="true" href="#fine-tuning-instructions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning Instructions&lt;/h1&gt;
&lt;p&gt;For XNLI, COLA, MNLI, and MRPC, use &lt;code&gt;run_classifier_sp.py&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install -r albert/requirements.txt
python -m albert.run_classifier_sp \
  --task_name=MNLI \
  &amp;lt;additional flags&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should see some output like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;***** Eval results *****
  global_step = ...
  loss = ...
  masked_lm_accuracy = ...
  masked_lm_loss = ...
  sentence_order_accuracy = ...
  sentence_order_loss = ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also fine-tune the model starting from TF-Hub modules using
&lt;code&gt;run_classifier_with_tfhub.py&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install -r albert/requirements.txt
python -m albert.run_classifier_with_tfhub \
  --albert_hub_module_handle=https://tfhub.dev/google/albert_base/1 \
  &amp;lt;additional flags&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>google-research</author><guid isPermaLink="false">https://github.com/google-research/ALBERT</guid><pubDate>Fri, 20 Dec 2019 00:12:00 GMT</pubDate></item><item><title>ray-project/ray #13 in Python, This week</title><link>https://github.com/ray-project/ray</link><description>&lt;p&gt;&lt;i&gt;A fast and simple framework for building and running distributed applications. Ray is packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperparameter tuning library.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="rst" data-path="README.rst"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ray-project/ray/raw/master/doc/source/images/ray_header_logo.png"&gt;&lt;img alt="https://github.com/ray-project/ray/raw/master/doc/source/images/ray_header_logo.png" src="https://github.com/ray-project/ray/raw/master/doc/source/images/ray_header_logo.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;a href="https://travis-ci.com/ray-project/ray" rel="nofollow"&gt;&lt;img alt="https://travis-ci.com/ray-project/ray.svg?branch=master" src="https://camo.githubusercontent.com/7826db77264764c06ed2f6ad890aa004e2130ca8/68747470733a2f2f7472617669732d63692e636f6d2f7261792d70726f6a6563742f7261792e7376673f6272616e63683d6d6173746572" data-canonical-src="https://travis-ci.com/ray-project/ray.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://ray.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img alt="https://readthedocs.org/projects/ray/badge/?version=latest" src="https://camo.githubusercontent.com/1e5cf513573008d0815d8b1981b21f59871c2635/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f7261792f62616467652f3f76657273696f6e3d6c6174657374" data-canonical-src="https://readthedocs.org/projects/ray/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;div&gt;
&lt;div&gt;&lt;br&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Ray is a fast and simple framework for building and running distributed applications.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Ray is packaged with the following libraries for accelerating machine learning workloads:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ray.readthedocs.io/en/latest/tune.html" rel="nofollow"&gt;Tune&lt;/a&gt;: Scalable Hyperparameter Tuning&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ray.readthedocs.io/en/latest/rllib.html" rel="nofollow"&gt;RLlib&lt;/a&gt;: Scalable Reinforcement Learning&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ray.readthedocs.io/en/latest/distributed_training.html" rel="nofollow"&gt;Distributed Training&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Install Ray with: &lt;code&gt;pip install ray&lt;/code&gt;. For nightly wheels, see the &lt;a href="https://ray.readthedocs.io/en/latest/installation.html" rel="nofollow"&gt;Installation page&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-quick-start"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;
&lt;p&gt;Execute Python functions in parallel.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; ray
ray.init()

&lt;span class="pl-en"&gt;@ray.remote&lt;/span&gt;
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;f&lt;/span&gt;(&lt;span class="pl-smi"&gt;x&lt;/span&gt;):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; x &lt;span class="pl-k"&gt;*&lt;/span&gt; x

futures &lt;span class="pl-k"&gt;=&lt;/span&gt; [f.remote(i) &lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;4&lt;/span&gt;)]
&lt;span class="pl-c1"&gt;print&lt;/span&gt;(ray.get(futures))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To use Ray's actor model:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; ray
ray.init()

&lt;span class="pl-en"&gt;@ray.remote&lt;/span&gt;
&lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;Counter&lt;/span&gt;(&lt;span class="pl-c1"&gt;object&lt;/span&gt;):
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__init__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;):
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;

    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;increment&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;):
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n &lt;span class="pl-k"&gt;+=&lt;/span&gt; &lt;span class="pl-c1"&gt;1&lt;/span&gt;

    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;read&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;):
        &lt;span class="pl-k"&gt;return&lt;/span&gt; &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n

counters &lt;span class="pl-k"&gt;=&lt;/span&gt; [Counter.remote() &lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;4&lt;/span&gt;)]
[c.increment.remote() &lt;span class="pl-k"&gt;for&lt;/span&gt; c &lt;span class="pl-k"&gt;in&lt;/span&gt; counters]
futures &lt;span class="pl-k"&gt;=&lt;/span&gt; [c.read.remote() &lt;span class="pl-k"&gt;for&lt;/span&gt; c &lt;span class="pl-k"&gt;in&lt;/span&gt; counters]
&lt;span class="pl-c1"&gt;print&lt;/span&gt;(ray.get(futures))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ray programs can run on a single machine, and can also seamlessly scale to large clusters. To execute the above Ray script in the cloud, just download &lt;a href="https://github.com/ray-project/ray/blob/master/python/ray/autoscaler/aws/example-full.yaml"&gt;this configuration file&lt;/a&gt;, and run:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ray submit [CLUSTER.YAML] example.py --start&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Read more about &lt;a href="https://ray.readthedocs.io/en/latest/autoscaling.html" rel="nofollow"&gt;launching clusters&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-tune-quick-start"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-tune-quick-start" class="anchor" aria-hidden="true" href="#tune-quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tune Quick Start&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ray-project/ray/raw/master/doc/source/images/tune-wide.png"&gt;&lt;img alt="https://github.com/ray-project/ray/raw/master/doc/source/images/tune-wide.png" src="https://github.com/ray-project/ray/raw/master/doc/source/images/tune-wide.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ray.readthedocs.io/en/latest/tune.html" rel="nofollow"&gt;Tune&lt;/a&gt; is a library for hyperparameter tuning at any scale.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Launch a multi-node distributed hyperparameter sweep in less than 10 lines of code.&lt;/li&gt;
&lt;li&gt;Supports any deep learning framework, including PyTorch, TensorFlow, and Keras.&lt;/li&gt;
&lt;li&gt;Visualize results with &lt;a href="https://www.tensorflow.org/get_started/summaries_and_tensorboard" rel="nofollow"&gt;TensorBoard&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Choose among scalable SOTA algorithms such as &lt;a href="https://ray.readthedocs.io/en/latest/tune-schedulers.html#population-based-training-pbt" rel="nofollow"&gt;Population Based Training (PBT)&lt;/a&gt;, &lt;a href="https://ray.readthedocs.io/en/latest/tune-schedulers.html#median-stopping-rule" rel="nofollow"&gt;Vizier's Median Stopping Rule&lt;/a&gt;, &lt;a href="https://ray.readthedocs.io/en/latest/tune-schedulers.html#asynchronous-hyperband" rel="nofollow"&gt;HyperBand/ASHA&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Tune integrates with many optimization libraries such as &lt;a href="http://ax.dev" rel="nofollow"&gt;Facebook Ax&lt;/a&gt;, &lt;a href="https://github.com/hyperopt/hyperopt"&gt;HyperOpt&lt;/a&gt;, and &lt;a href="https://github.com/fmfn/BayesianOptimization"&gt;Bayesian Optimization&lt;/a&gt; and enables you to scale them transparently.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To run this example, you will need to install the following:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ pip install ray[tune] torch torchvision filelock&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This example runs a parallel grid search to train a Convolutional Neural Network using PyTorch.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; torch.optim &lt;span class="pl-k"&gt;as&lt;/span&gt; optim
&lt;span class="pl-k"&gt;from&lt;/span&gt; ray &lt;span class="pl-k"&gt;import&lt;/span&gt; tune
&lt;span class="pl-k"&gt;from&lt;/span&gt; ray.tune.examples.mnist_pytorch &lt;span class="pl-k"&gt;import&lt;/span&gt; (
    get_data_loaders, ConvNet, train, test)


&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;train_mnist&lt;/span&gt;(&lt;span class="pl-smi"&gt;config&lt;/span&gt;):
    train_loader, test_loader &lt;span class="pl-k"&gt;=&lt;/span&gt; get_data_loaders()
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; ConvNet()
    optimizer &lt;span class="pl-k"&gt;=&lt;/span&gt; optim.SGD(model.parameters(), &lt;span class="pl-v"&gt;lr&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;config[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;lr&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;])
    &lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;10&lt;/span&gt;):
        train(model, optimizer, train_loader)
        acc &lt;span class="pl-k"&gt;=&lt;/span&gt; test(model, test_loader)
        tune.track.log(&lt;span class="pl-v"&gt;mean_accuracy&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;acc)


analysis &lt;span class="pl-k"&gt;=&lt;/span&gt; tune.run(
    train_mnist, &lt;span class="pl-v"&gt;config&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;lr&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: tune.grid_search([&lt;span class="pl-c1"&gt;0.001&lt;/span&gt;, &lt;span class="pl-c1"&gt;0.01&lt;/span&gt;, &lt;span class="pl-c1"&gt;0.1&lt;/span&gt;])})

&lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Best config: &lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, analysis.get_best_config(&lt;span class="pl-v"&gt;metric&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;mean_accuracy&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;))

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Get a dataframe for analyzing trial results.&lt;/span&gt;
df &lt;span class="pl-k"&gt;=&lt;/span&gt; analysis.dataframe()&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If TensorBoard is installed, automatically visualize all trial results:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;tensorboard --logdir &lt;span class="pl-k"&gt;~&lt;/span&gt;/ray_results&lt;/pre&gt;&lt;/div&gt;
&lt;a name="user-content-rllib-quick-start"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-rllib-quick-start" class="anchor" aria-hidden="true" href="#rllib-quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RLlib Quick Start&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/ray-project/ray/raw/master/doc/source/images/rllib-wide.jpg"&gt;&lt;img alt="https://github.com/ray-project/ray/raw/master/doc/source/images/rllib-wide.jpg" src="https://github.com/ray-project/ray/raw/master/doc/source/images/rllib-wide.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ray.readthedocs.io/en/latest/rllib.html" rel="nofollow"&gt;RLlib&lt;/a&gt; is an open-source library for reinforcement learning built on top of Ray that offers both high scalability and a unified API for a variety of applications.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install tensorflow  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; or tensorflow-gpu&lt;/span&gt;
pip install ray[rllib]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; also recommended: ray[debug]&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; gym
&lt;span class="pl-k"&gt;from&lt;/span&gt; gym.spaces &lt;span class="pl-k"&gt;import&lt;/span&gt; Discrete, Box
&lt;span class="pl-k"&gt;from&lt;/span&gt; ray &lt;span class="pl-k"&gt;import&lt;/span&gt; tune

&lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;SimpleCorridor&lt;/span&gt;(&lt;span class="pl-e"&gt;gym&lt;/span&gt;.&lt;span class="pl-e"&gt;Env&lt;/span&gt;):
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__init__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;config&lt;/span&gt;):
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.end_pos &lt;span class="pl-k"&gt;=&lt;/span&gt; config[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;corridor_length&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;]
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.cur_pos &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.action_space &lt;span class="pl-k"&gt;=&lt;/span&gt; Discrete(&lt;span class="pl-c1"&gt;2&lt;/span&gt;)
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.observation_space &lt;span class="pl-k"&gt;=&lt;/span&gt; Box(&lt;span class="pl-c1"&gt;0.0&lt;/span&gt;, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.end_pos, &lt;span class="pl-v"&gt;shape&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;, ))

    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;reset&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;):
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.cur_pos &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;
        &lt;span class="pl-k"&gt;return&lt;/span&gt; [&lt;span class="pl-c1"&gt;self&lt;/span&gt;.cur_pos]

    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;step&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;action&lt;/span&gt;):
        &lt;span class="pl-k"&gt;if&lt;/span&gt; action &lt;span class="pl-k"&gt;==&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt; &lt;span class="pl-k"&gt;and&lt;/span&gt; &lt;span class="pl-c1"&gt;self&lt;/span&gt;.cur_pos &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;:
            &lt;span class="pl-c1"&gt;self&lt;/span&gt;.cur_pos &lt;span class="pl-k"&gt;-=&lt;/span&gt; &lt;span class="pl-c1"&gt;1&lt;/span&gt;
        &lt;span class="pl-k"&gt;elif&lt;/span&gt; action &lt;span class="pl-k"&gt;==&lt;/span&gt; &lt;span class="pl-c1"&gt;1&lt;/span&gt;:
            &lt;span class="pl-c1"&gt;self&lt;/span&gt;.cur_pos &lt;span class="pl-k"&gt;+=&lt;/span&gt; &lt;span class="pl-c1"&gt;1&lt;/span&gt;
        done &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;self&lt;/span&gt;.cur_pos &lt;span class="pl-k"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;self&lt;/span&gt;.end_pos
        &lt;span class="pl-k"&gt;return&lt;/span&gt; [&lt;span class="pl-c1"&gt;self&lt;/span&gt;.cur_pos], &lt;span class="pl-c1"&gt;1&lt;/span&gt; &lt;span class="pl-k"&gt;if&lt;/span&gt; done &lt;span class="pl-k"&gt;else&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;, done, {}

tune.run(
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;PPO&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
    &lt;span class="pl-v"&gt;config&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;{
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;env&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: SimpleCorridor,
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;num_workers&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;4&lt;/span&gt;,
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;env_config&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;corridor_length&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;5&lt;/span&gt;}})&lt;/pre&gt;&lt;/div&gt;
&lt;a name="user-content-more-information"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-more-information" class="anchor" aria-hidden="true" href="#more-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More Information&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ray.readthedocs.io/en/latest/index.html" rel="nofollow"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ray-project/tutorial"&gt;Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ray-project.github.io/" rel="nofollow"&gt;Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1712.05889" rel="nofollow"&gt;Ray paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1703.03924" rel="nofollow"&gt;Ray HotOS paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1712.09381" rel="nofollow"&gt;RLlib paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1807.05118" rel="nofollow"&gt;Tune paper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-getting-involved"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-getting-involved" class="anchor" aria-hidden="true" href="#getting-involved"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Involved&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://groups.google.com/forum/#!forum/ray-dev" rel="nofollow"&gt;ray-dev@googlegroups.com&lt;/a&gt;: For discussions about development or any general
questions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://stackoverflow.com/questions/tagged/ray" rel="nofollow"&gt;StackOverflow&lt;/a&gt;: For questions about how to use Ray.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ray-project/ray/issues"&gt;GitHub Issues&lt;/a&gt;: For reporting bugs and feature requests.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ray-project/ray/pulls"&gt;Pull Requests&lt;/a&gt;: For submitting code contributions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.meetup.com/Bay-Area-Ray-Meetup/" rel="nofollow"&gt;Meetup Group&lt;/a&gt;: Join our meetup group.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://forms.gle/9TSdDYUgxYs8SA9e8" rel="nofollow"&gt;Community Slack&lt;/a&gt;: Join our Slack workspace.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/raydistributed" rel="nofollow"&gt;Twitter&lt;/a&gt;: Follow updates on Twitter.&lt;/li&gt;
&lt;/ul&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>ray-project</author><guid isPermaLink="false">https://github.com/ray-project/ray</guid><pubDate>Fri, 20 Dec 2019 00:13:00 GMT</pubDate></item><item><title>MobSF/Mobile-Security-Framework-MobSF #14 in Python, This week</title><link>https://github.com/MobSF/Mobile-Security-Framework-MobSF</link><description>&lt;p&gt;&lt;i&gt;Mobile Security Framework (MobSF) is an automated, all-in-one mobile application (Android/iOS/Windows) pen-testing, malware analysis and security assessment framework capable of performing static and dynamic analysis.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-mobile-security-framework-mobsf" class="anchor" aria-hidden="true" href="#mobile-security-framework-mobsf"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Mobile Security Framework (MobSF)&lt;/h1&gt;
&lt;p&gt;Version: v3.0 beta
&lt;a target="_blank" rel="noopener noreferrer" href="https://cloud.githubusercontent.com/assets/4301109/20019521/cc61f7fc-a2f2-11e6-95f3-407030d9fdde.png"&gt;&lt;img src="https://cloud.githubusercontent.com/assets/4301109/20019521/cc61f7fc-a2f2-11e6-95f3-407030d9fdde.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mobile Security Framework (MobSF) is an automated, all-in-one mobile application (Android/iOS/Windows) pen-testing, malware analysis and security assessment framework capable of performing static and dynamic analysis. MobSF support mobile app binaries (APK, IPA &amp;amp; APPX) along with zipped source code and provides REST APIs for seamless integration with your CI/CD or DevSecOps pipeline.The Dynamic Analyzer helps you to perform runtime security assessment and interactive instrumented testing.&lt;/p&gt;
&lt;p&gt;Made with &lt;a target="_blank" rel="noopener noreferrer" href="https://cloud.githubusercontent.com/assets/4301109/16754758/82e3a63c-4813-11e6-9430-6015d98aeaab.png"&gt;&lt;img src="https://cloud.githubusercontent.com/assets/4301109/16754758/82e3a63c-4813-11e6-9430-6015d98aeaab.png" alt="Love" style="max-width:100%;"&gt;&lt;/a&gt; in India&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.python.org/downloads/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c97ff9febe305d9abad8d163fd5912be60652b41/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e372d626c75652e737667" alt="python" data-canonical-src="https://img.shields.io/badge/python-3.7-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/MobSF/Mobile-Security-Framework-MobSF/"&gt;&lt;img src="https://camo.githubusercontent.com/4a42460f88f172b10e916fec11857648a8a2f2c8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d6f73782532466c696e757825324677696e646f77732d677265656e2e737667" alt="platform" data-canonical-src="https://img.shields.io/badge/platform-osx%2Flinux%2Fwindows-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.gnu.org/licenses/gpl-3.0.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5e8d492ac11131477d835d8f7934a895d236866c/68747470733a2f2f696d672e736869656c64732e696f2f3a6c6963656e73652d67706c332d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/:license-gpl3-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.codacy.com/app/ajinabraham/Mobile-Security-Framework-MobSF" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a63e3b4bd6674f1cfaa35af02a227cf669a850de/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f6365666266623036336330343462303639653338616633353031633165653865" alt="Codacy Badge" data-canonical-src="https://api.codacy.com/project/badge/Grade/cefbfb063c044b069e38af3501c1ee8e" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://sonarcloud.io/dashboard?id=MobSF_Mobile-Security-Framework-MobSF" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/58fff59dd00faf330266882b8a2364e3595c4c1a/68747470733a2f2f736f6e6172636c6f75642e696f2f6170692f70726f6a6563745f6261646765732f6d6561737572653f70726f6a6563743d4d6f6253465f4d6f62696c652d53656375726974792d4672616d65776f726b2d4d6f625346266d65747269633d616c6572745f737461747573" alt="Quality Gate Status" data-canonical-src="https://sonarcloud.io/api/project_badges/measure?project=MobSF_Mobile-Security-Framework-MobSF&amp;amp;metric=alert_status" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.com/MobSF/Mobile-Security-Framework-MobSF" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/18f6f5d4768430e3af5c3218fb939e9b11b4181f/68747470733a2f2f7472617669732d63692e636f6d2f4d6f6253462f4d6f62696c652d53656375726974792d4672616d65776f726b2d4d6f6253462e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/MobSF/Mobile-Security-Framework-MobSF.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pyup.io/repos/github/MobSF/Mobile-Security-Framework-MobSF/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/4468bc52804bb5ce4d8c24a8b554d995a4bc5fb6/68747470733a2f2f707975702e696f2f7265706f732f6769746875622f4d6f6253462f4d6f62696c652d53656375726974792d4672616d65776f726b2d4d6f6253462f736869656c642e737667" alt="Requirements Status" data-canonical-src="https://pyup.io/repos/github/MobSF/Mobile-Security-Framework-MobSF/shield.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://www.toolswatch.org/2018/01/black-hat-arsenal-top-10-security-tools/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/87a7a8d4a49856fe21e0d2b2c3d12b67d60a2fb3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f546f6f6c7357617463682d52616e6b2532303925323025374325323059656172253230323031372d7265642e737667" alt="ToolsWatch Best Security Tools 2017" data-canonical-src="https://img.shields.io/badge/ToolsWatch-Rank%209%20%7C%20Year%202017-red.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://www.toolswatch.org/2017/02/2016-top-security-tools-as-voted-by-toolswatch-org-readers/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/abf7bc1289a10b3a9621a4b2958e19152efa6bbd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f546f6f6c7357617463682d52616e6b2532303525323025374325323059656172253230323031362d7265642e737667" alt="ToolsWatch Best Security Tools 2016" data-canonical-src="https://img.shields.io/badge/ToolsWatch-Rank%205%20%7C%20Year%202016-red.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.blackhat.com/asia-18/arsenal.html#mobile-security-framework-mobsf" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/b381d84fdc674c512e9e2b682373b77ad610bacd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f426c61636b253230486174253230417273656e616c2d41736961253230323031382d626c75652e737667" alt="Blackhat Arsenal Asia 2018" data-canonical-src="https://img.shields.io/badge/Black%20Hat%20Arsenal-Asia%202018-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.blackhat.com/asia-15/arsenal.html#yso-mobile-security-framework" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/426f18d93c0891f43744953ebe9b019f6313fbd8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f426c61636b253230486174253230417273656e616c2d41736961253230323031352d626c75652e737667" alt="Blackhat Arsenal Asia 2015" data-canonical-src="https://img.shields.io/badge/Black%20Hat%20Arsenal-Asia%202015-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MobSF is also bundled with &lt;a href="https://androidtamer.com/tamer4-release" rel="nofollow"&gt;Android Tamer&lt;/a&gt; and &lt;a href="https://blackarch.org/mobile.html" rel="nofollow"&gt;BlackArch&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-buy-us-a-coffee" class="anchor" aria-hidden="true" href="#buy-us-a-coffee"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Buy us a Coffee!&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Your generous donations will keep us motivated.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Paypal:&lt;/em&gt; &lt;a href="https://mobsf.github.io/Mobile-Security-Framework-MobSF/paypal.html" rel="nofollow"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/28491754-14774f54-6f14-11e7-9975-8a5faeda7e30.gif" alt="Donate via Paypal" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Bitcoin:&lt;/em&gt; &lt;a href="https://mobsf.github.io/Mobile-Security-Framework-MobSF/donate.html" rel="nofollow"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/30631105-cb8063c8-9e00-11e7-95df-43c20b840e52.png" alt="Donate Bitcoin" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/MobSF/Mobile-Security-Framework-MobSF/wiki/1.-Documentation"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/70686099-3855f780-1c79-11ea-8141-899e39459da2.png" alt="See MobSF Documentation" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-try-mobsf-static-analyzer-online" class="anchor" aria-hidden="true" href="#try-mobsf-static-analyzer-online"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Try MobSF Static Analyzer Online&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://labs.play-with-docker.com/?stack=https://raw.githubusercontent.com/MobSF/Mobile-Security-Framework-MobSF/master/scripts/stack/docker-compose.yml" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/play-with-docker/stacks/master/assets/images/button.png" alt="Try in PWD" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-collaborators" class="anchor" aria-hidden="true" href="#collaborators"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Collaborators&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://in.linkedin.com/in/ajinabraham" rel="nofollow"&gt;Ajin Abraham&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/37564171-6549d678-2ab6-11e8-9b9d-21327c7f5d5b.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/37564171-6549d678-2ab6-11e8-9b9d-21327c7f5d5b.png" alt="india" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DominikSchlecht"&gt;Dominik Schlecht&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/37564176-743238ba-2ab6-11e8-9666-5d98f0a1d127.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/37564176-743238ba-2ab6-11e8-9666-5d98f0a1d127.png" alt="germany" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/magaofei"&gt;Magaofei&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/44515364-00bbe880-a6e0-11e8-944d-5b48a86427da.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/44515364-00bbe880-a6e0-11e8-944d-5b48a86427da.png" alt="china" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/matandobr"&gt;Matan Dobrushin&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/37564177-782f1758-2ab6-11e8-91e5-c76bde37b330.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/37564177-782f1758-2ab6-11e8-91e5-c76bde37b330.png" alt="israel" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/superpoussin22"&gt;Vincent Nadal&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/37564175-71d6d92c-2ab6-11e8-89d7-d21f5aa0bda8.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/37564175-71d6d92c-2ab6-11e8-89d7-d21f5aa0bda8.png" alt="france" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-presentations" class="anchor" aria-hidden="true" href="#presentations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Presentations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OWASP APPSEC EU 2016 - &lt;a href="http://www.slideshare.net/ajin25/automated-mobile-application-security-assessment-with-mobsf" rel="nofollow"&gt;Slides&lt;/a&gt;, &lt;a href="https://www.youtube.com/watch?v=h00v1euuFXg" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;NULLCON 2016 - &lt;a href="https://www.slideshare.net/ajin25/nullcon-goa-2016-automated-mobile-application-security-testing-with-mobile-security-framework-mobsf" rel="nofollow"&gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;c0c0n 2015 - &lt;a href="https://www.slideshare.net/ajin25/automated-security-analysis-of-android-ios-applications-with-mobile-security-framework-c0c0n-2015" rel="nofollow"&gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;G4H Webcast 2015 - &lt;a href="https://www.youtube.com/watch?v=CysfO6AZmo8" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-e-learning-courses--certifications" class="anchor" aria-hidden="true" href="#e-learning-courses--certifications"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;e-Learning Courses &amp;amp; Certifications&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://opsecx.com/index.php/product/automated-mobile-application-security-assessment-with-mobsf/" rel="nofollow"&gt;Automated Mobile Application Security Assessment with MobSF -MAS (Currently being updated)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://opsecx.com/index.php/product/android-security-tools-expert-atx/" rel="nofollow"&gt;Android Security Tools Expert -ATX&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-mobsf-support-packages" class="anchor" aria-hidden="true" href="#mobsf-support-packages"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MobSF Support Packages&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;For free limited support, use our Slack Channel: &lt;a href="https://mobsf.slack.com/join/shared_invite/enQtNzM2NTAyNzA1MjgxLTdjMzkzNDc3ZjdiMjkwZTZhMmFhNDlkZmMwZDhjNDNmYTAzYWE5NGZlMDIzYzliNTdiMDQ2MTRlYjU1MjkyNGM" rel="nofollow"&gt;mobsf.slack.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;For enterprise support, priority feature requests and live training, see &lt;a href="https://mobsf.github.io/Mobile-Security-Framework-MobSF/support.html" rel="nofollow"&gt;MobSF Support Packages&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-whats-new" class="anchor" aria-hidden="true" href="#whats-new"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What's New?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://mobsf.github.io/Mobile-Security-Framework-MobSF/changelog.html" rel="nofollow"&gt;See Changelog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-feature-requests--bugs" class="anchor" aria-hidden="true" href="#contribution-feature-requests--bugs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution, Feature Requests &amp;amp; Bugs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Read &lt;a href="https://github.com/MobSF/Mobile-Security-Framework-MobSF/blob/master/.github/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; before opening bugs, feature requests and pull request.&lt;/li&gt;
&lt;li&gt;Feature Requests: &lt;a href="https://twitter.com/ajinabraham" rel="nofollow"&gt;@ajinabraham&lt;/a&gt; or &lt;a href="https://twitter.com/OpenSecurity_IN" rel="nofollow"&gt;@OpenSecurity_IN&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For discussions, questions and limited support, use our Slack Channel mobsf.slack.com: &lt;a href="https://mobsf.slack.com/join/shared_invite/enQtNzM2NTAyNzA1MjgxLTdjMzkzNDc3ZjdiMjkwZTZhMmFhNDlkZmMwZDhjNDNmYTAzYWE5NGZlMDIzYzliNTdiMDQ2MTRlYjU1MjkyNGM" rel="nofollow"&gt;Join MobSF Channel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Open Bugs after reading &lt;a href="https://github.com/MobSF/Mobile-Security-Framework-MobSF/blob/master/.github/CONTRIBUTING.md#using-the-issue-tracker"&gt;Guidelines to Report a Bug&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-screenshots" class="anchor" aria-hidden="true" href="#screenshots"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Screenshots&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-static-analysis---android" class="anchor" aria-hidden="true" href="#static-analysis---android"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Static Analysis - Android&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/70381680-c732df00-191c-11ea-86dc-fc2ce93af9df.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/70381680-c732df00-191c-11ea-86dc-fc2ce93af9df.png" alt="android-static-analysis-apk" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/70381695-095c2080-191d-11ea-8254-e2a0c3eef708.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/70381695-095c2080-191d-11ea-8254-e2a0c3eef708.png" alt="android-static-analysis-apk2" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/70381729-92735780-191d-11ea-8671-c72f54f3a4be.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/70381729-92735780-191d-11ea-8671-c72f54f3a4be.png" alt="compare-result" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-static-analysis---ios" class="anchor" aria-hidden="true" href="#static-analysis---ios"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Static Analysis - iOS&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/70666043-dd51df80-1c3b-11ea-9b24-4048fad552fb.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/70666043-dd51df80-1c3b-11ea-9b24-4048fad552fb.png" alt="ios-static-analysis-ipa" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/70381767-5d1b3980-191e-11ea-8adc-20f54554bf5b.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/70381767-5d1b3980-191e-11ea-8adc-20f54554bf5b.png" alt="ios-static-analysis-source" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-dynamic-analysis---android-apk" class="anchor" aria-hidden="true" href="#dynamic-analysis---android-apk"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dynamic Analysis - Android APK&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/70381806-03673f00-191f-11ea-87e4-dee316212101.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/70381806-03673f00-191f-11ea-87e4-dee316212101.png" alt="android-dynamic-analysis" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/70381835-72dd2e80-191f-11ea-8f94-2255c9f605d9.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/70381835-72dd2e80-191f-11ea-8f94-2255c9f605d9.png" alt="android-dynamic-frida-live" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/70381853-c18ac880-191f-11ea-8cf4-2ce44521509c.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/70381853-c18ac880-191f-11ea-8cf4-2ce44521509c.png" alt="android-dynamic-report" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-web-api-viewer" class="anchor" aria-hidden="true" href="#web-api-viewer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web API Viewer&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/4301109/65378797-57c53000-dcdb-11e9-84e9-d5acf887f3aa.png"&gt;&lt;img src="https://user-images.githubusercontent.com/4301109/65378797-57c53000-dcdb-11e9-84e9-d5acf887f3aa.png" alt="android-dynamic-http-tools" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credits&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Abhinav Sejpal (@Abhinav_Sejpal) - For poking me with bugs, feature requests, and UI &amp;amp; UX suggestions.&lt;/li&gt;
&lt;li&gt;Amrutha VC (@amruthavc) - For the new MobSF logo&lt;/li&gt;
&lt;li&gt;Anant Srivastava (@anantshri) - For Activity Tester Idea&lt;/li&gt;
&lt;li&gt;Anto Joseph (@antojosep007) - For the help with SuperSU.&lt;/li&gt;
&lt;li&gt;Bharadwaj Machiraju (@tunnelshade_) - For writing pyWebProxy from scratch&lt;/li&gt;
&lt;li&gt;Dominik Schlecht - For the awesome work on adding Windows Phone App Static Analysis to MobSF&lt;/li&gt;
&lt;li&gt;Esteban - Better Android Manifest Analysis and Static Analysis Improvement.&lt;/li&gt;
&lt;li&gt;Matan Dobrushin - For adding Android ARM Emulator support to MobSF - Special thanks goes for cuckoo-droid, I got inspired by their code and idea for this implementation.&lt;/li&gt;
&lt;li&gt;MindMac - For writing Android Blue Pill&lt;/li&gt;
&lt;li&gt;Rahul (@c0dist) - Kali Support&lt;/li&gt;
&lt;li&gt;Shuxin - Android Binary Analysis&lt;/li&gt;
&lt;li&gt;Thomas Abraham - For JS Hacks on UI.&lt;/li&gt;
&lt;li&gt;Tim Brown (@timb_machine) - For the iOS Binary Analysis Ruleset.&lt;/li&gt;
&lt;li&gt;Oscar Alfonso Diaz - (@OscarAkaElvis) - For Dockerfile contributions&lt;/li&gt;
&lt;li&gt;Abhinav Saxena - (@xandfury) - For Travis CI and Logging integration&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>MobSF</author><guid isPermaLink="false">https://github.com/MobSF/Mobile-Security-Framework-MobSF</guid><pubDate>Fri, 20 Dec 2019 00:14:00 GMT</pubDate></item><item><title>google-research/bert #15 in Python, This week</title><link>https://github.com/google-research/bert</link><description>&lt;p&gt;&lt;i&gt;TensorFlow code and pre-trained models for BERT&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-bert" class="anchor" aria-hidden="true" href="#bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;BERT&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;***** New May 31st, 2019: Whole Word Masking Models *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is a release of several new models which were the result of an improvement
the pre-processing code.&lt;/p&gt;
&lt;p&gt;In the original pre-processing code, we randomly select WordPiece tokens to
mask. For example:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Input Text: the man jumped up , put his basket on phil ##am ##mon ' s head&lt;/code&gt;
&lt;code&gt;Original Masked Input: [MASK] man [MASK] up , put his [MASK] on phil [MASK] ##mon ' s head&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The new technique is called Whole Word Masking. In this case, we always mask
&lt;em&gt;all&lt;/em&gt; of the the tokens corresponding to a word at once. The overall masking
rate remains the same.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Whole Word Masked Input: the man [MASK] up , put his basket on [MASK] [MASK] [MASK] ' s head&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The training is identical -- we still predict each masked WordPiece token
independently. The improvement comes from the fact that the original prediction
task was too 'easy' for words that had been split into multiple WordPieces.&lt;/p&gt;
&lt;p&gt;This can be enabled during data generation by passing the flag
&lt;code&gt;--do_whole_word_mask=True&lt;/code&gt; to &lt;code&gt;create_pretraining_data.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Pre-trained models with Whole Word Masking are linked below. The data and
training were otherwise identical, and the models have identical structure and
vocab to the original models. We only include BERT-Large models. When using
these models, please make it clear in the paper that you are using the Whole
Word Masking variant of BERT-Large.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Uncased (Whole Word Masking)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2019_05_30/wwm_cased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Cased (Whole Word Masking)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th align="center"&gt;SQUAD 1.1 F1/EM&lt;/th&gt;
&lt;th align="center"&gt;Multi NLI Accuracy&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;BERT-Large, Uncased (Original)&lt;/td&gt;
&lt;td align="center"&gt;91.0/84.3&lt;/td&gt;
&lt;td align="center"&gt;86.05&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BERT-Large, Uncased (Whole Word Masking)&lt;/td&gt;
&lt;td align="center"&gt;92.8/86.7&lt;/td&gt;
&lt;td align="center"&gt;87.07&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BERT-Large, Cased (Original)&lt;/td&gt;
&lt;td align="center"&gt;91.5/84.8&lt;/td&gt;
&lt;td align="center"&gt;86.09&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BERT-Large, Cased (Whole Word Masking)&lt;/td&gt;
&lt;td align="center"&gt;92.9/86.7&lt;/td&gt;
&lt;td align="center"&gt;86.46&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;***** New February 7th, 2019: TfHub Module *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;BERT has been uploaded to &lt;a href="https://tfhub.dev" rel="nofollow"&gt;TensorFlow Hub&lt;/a&gt;. See
&lt;code&gt;run_classifier_with_tfhub.py&lt;/code&gt; for an example of how to use the TF Hub module,
or run an example in the browser on
&lt;a href="https://colab.sandbox.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb" rel="nofollow"&gt;Colab&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;***** New November 23rd, 2018: Un-normalized multilingual model + Thai +
Mongolian *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We uploaded a new multilingual model which does &lt;em&gt;not&lt;/em&gt; perform any normalization
on the input (no lower casing, accent stripping, or Unicode normalization), and
additionally inclues Thai and Mongolian.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It is recommended to use this version for developing multilingual models,
especially on languages with non-Latin alphabets.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This does not require any code changes, and can be downloaded here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Multilingual Cased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
104 languages, 12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;***** New November 15th, 2018: SOTA SQuAD 2.0 System *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We released code changes to reproduce our 83% F1 SQuAD 2.0 system, which is
currently 1st place on the leaderboard by 3%. See the SQuAD 2.0 section of the
README for details.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;***** New November 5th, 2018: Third-party PyTorch and Chainer versions of
BERT available *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;NLP researchers from HuggingFace made a
&lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT"&gt;PyTorch version of BERT available&lt;/a&gt;
which is compatible with our pre-trained checkpoints and is able to reproduce
our results. Sosuke Kobayashi also made a
&lt;a href="https://github.com/soskek/bert-chainer"&gt;Chainer version of BERT available&lt;/a&gt;
(Thanks!) We were not involved in the creation or maintenance of the PyTorch
implementation so please direct any questions towards the authors of that
repository.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;***** New November 3rd, 2018: Multilingual and Chinese models available
*****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We have made two new BERT models available:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/multilingual_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Multilingual&lt;/code&gt;&lt;/a&gt;
(Not recommended, use &lt;code&gt;Multilingual Cased&lt;/code&gt; instead)&lt;/strong&gt;: 102 languages,
12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Chinese&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M
parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We use character-based tokenization for Chinese, and WordPiece tokenization for
all other languages. Both models should work out-of-the-box without any code
changes. We did update the implementation of &lt;code&gt;BasicTokenizer&lt;/code&gt; in
&lt;code&gt;tokenization.py&lt;/code&gt; to support Chinese character tokenization, so please update if
you forked it. However, we did not change the tokenization API.&lt;/p&gt;
&lt;p&gt;For more, see the
&lt;a href="https://github.com/google-research/bert/blob/master/multilingual.md"&gt;Multilingual README&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;***** End new information *****&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;BERT&lt;/strong&gt;, or &lt;strong&gt;B&lt;/strong&gt;idirectional &lt;strong&gt;E&lt;/strong&gt;ncoder &lt;strong&gt;R&lt;/strong&gt;epresentations from
&lt;strong&gt;T&lt;/strong&gt;ransformers, is a new method of pre-training language representations which
obtains state-of-the-art results on a wide array of Natural Language Processing
(NLP) tasks.&lt;/p&gt;
&lt;p&gt;Our academic paper which describes BERT in detail and provides full results on a
number of tasks can be found here:
&lt;a href="https://arxiv.org/abs/1810.04805" rel="nofollow"&gt;https://arxiv.org/abs/1810.04805&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To give a few numbers, here are the results on the
&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/" rel="nofollow"&gt;SQuAD v1.1&lt;/a&gt; question answering
task:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SQuAD v1.1 Leaderboard (Oct 8th 2018)&lt;/th&gt;
&lt;th align="center"&gt;Test EM&lt;/th&gt;
&lt;th align="center"&gt;Test F1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1st Place Ensemble - BERT&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;87.4&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;93.2&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2nd Place Ensemble - nlnet&lt;/td&gt;
&lt;td align="center"&gt;86.0&lt;/td&gt;
&lt;td align="center"&gt;91.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1st Place Single Model - BERT&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;85.1&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;91.8&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2nd Place Single Model - nlnet&lt;/td&gt;
&lt;td align="center"&gt;83.5&lt;/td&gt;
&lt;td align="center"&gt;90.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;And several natural language inference tasks:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;System&lt;/th&gt;
&lt;th align="center"&gt;MultiNLI&lt;/th&gt;
&lt;th align="center"&gt;Question NLI&lt;/th&gt;
&lt;th align="center"&gt;SWAG&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;BERT&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;86.7&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;91.1&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;86.3&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OpenAI GPT (Prev. SOTA)&lt;/td&gt;
&lt;td align="center"&gt;82.2&lt;/td&gt;
&lt;td align="center"&gt;88.1&lt;/td&gt;
&lt;td align="center"&gt;75.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Plus many other tasks.&lt;/p&gt;
&lt;p&gt;Moreover, these results were all obtained with almost no task-specific neural
network architecture design.&lt;/p&gt;
&lt;p&gt;If you already know what BERT is and you just want to get started, you can
&lt;a href="#pre-trained-models"&gt;download the pre-trained models&lt;/a&gt; and
&lt;a href="#fine-tuning-with-bert"&gt;run a state-of-the-art fine-tuning&lt;/a&gt; in only a few
minutes.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-what-is-bert" class="anchor" aria-hidden="true" href="#what-is-bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is BERT?&lt;/h2&gt;
&lt;p&gt;BERT is a method of pre-training language representations, meaning that we train
a general-purpose "language understanding" model on a large text corpus (like
Wikipedia), and then use that model for downstream NLP tasks that we care about
(like question answering). BERT outperforms previous methods because it is the
first &lt;em&gt;unsupervised&lt;/em&gt;, &lt;em&gt;deeply bidirectional&lt;/em&gt; system for pre-training NLP.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Unsupervised&lt;/em&gt; means that BERT was trained using only a plain text corpus, which
is important because an enormous amount of plain text data is publicly available
on the web in many languages.&lt;/p&gt;
&lt;p&gt;Pre-trained representations can also either be &lt;em&gt;context-free&lt;/em&gt; or &lt;em&gt;contextual&lt;/em&gt;,
and contextual representations can further be &lt;em&gt;unidirectional&lt;/em&gt; or
&lt;em&gt;bidirectional&lt;/em&gt;. Context-free models such as
&lt;a href="https://www.tensorflow.org/tutorials/representation/word2vec" rel="nofollow"&gt;word2vec&lt;/a&gt; or
&lt;a href="https://nlp.stanford.edu/projects/glove/" rel="nofollow"&gt;GloVe&lt;/a&gt; generate a single "word
embedding" representation for each word in the vocabulary, so &lt;code&gt;bank&lt;/code&gt; would have
the same representation in &lt;code&gt;bank deposit&lt;/code&gt; and &lt;code&gt;river bank&lt;/code&gt;. Contextual models
instead generate a representation of each word that is based on the other words
in the sentence.&lt;/p&gt;
&lt;p&gt;BERT was built upon recent work in pre-training contextual representations —
including &lt;a href="https://arxiv.org/abs/1511.01432" rel="nofollow"&gt;Semi-supervised Sequence Learning&lt;/a&gt;,
&lt;a href="https://blog.openai.com/language-unsupervised/" rel="nofollow"&gt;Generative Pre-Training&lt;/a&gt;,
&lt;a href="https://allennlp.org/elmo" rel="nofollow"&gt;ELMo&lt;/a&gt;, and
&lt;a href="http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html" rel="nofollow"&gt;ULMFit&lt;/a&gt;
— but crucially these models are all &lt;em&gt;unidirectional&lt;/em&gt; or &lt;em&gt;shallowly
bidirectional&lt;/em&gt;. This means that each word is only contextualized using the words
to its left (or right). For example, in the sentence &lt;code&gt;I made a bank deposit&lt;/code&gt; the
unidirectional representation of &lt;code&gt;bank&lt;/code&gt; is only based on &lt;code&gt;I made a&lt;/code&gt; but not
&lt;code&gt;deposit&lt;/code&gt;. Some previous work does combine the representations from separate
left-context and right-context models, but only in a "shallow" manner. BERT
represents "bank" using both its left and right context — &lt;code&gt;I made a ... deposit&lt;/code&gt;
— starting from the very bottom of a deep neural network, so it is &lt;em&gt;deeply
bidirectional&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;BERT uses a simple approach for this: We mask out 15% of the words in the input,
run the entire sequence through a deep bidirectional
&lt;a href="https://arxiv.org/abs/1706.03762" rel="nofollow"&gt;Transformer&lt;/a&gt; encoder, and then predict only
the masked words. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Input: the man went to the [MASK1] . he bought a [MASK2] of milk.
Labels: [MASK1] = store; [MASK2] = gallon
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to learn relationships between sentences, we also train on a simple
task which can be generated from any monolingual corpus: Given two sentences &lt;code&gt;A&lt;/code&gt;
and &lt;code&gt;B&lt;/code&gt;, is &lt;code&gt;B&lt;/code&gt; the actual next sentence that comes after &lt;code&gt;A&lt;/code&gt;, or just a random
sentence from the corpus?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Sentence A: the man went to the store .
Sentence B: he bought a gallon of milk .
Label: IsNextSentence
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Sentence A: the man went to the store .
Sentence B: penguins are flightless .
Label: NotNextSentence
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We then train a large model (12-layer to 24-layer Transformer) on a large corpus
(Wikipedia + &lt;a href="http://yknzhu.wixsite.com/mbweb" rel="nofollow"&gt;BookCorpus&lt;/a&gt;) for a long time (1M
update steps), and that's BERT.&lt;/p&gt;
&lt;p&gt;Using BERT has two stages: &lt;em&gt;Pre-training&lt;/em&gt; and &lt;em&gt;fine-tuning&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pre-training&lt;/strong&gt; is fairly expensive (four days on 4 to 16 Cloud TPUs), but is a
one-time procedure for each language (current models are English-only, but
multilingual models will be released in the near future). We are releasing a
number of pre-trained models from the paper which were pre-trained at Google.
Most NLP researchers will never need to pre-train their own model from scratch.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fine-tuning&lt;/strong&gt; is inexpensive. All of the results in the paper can be
replicated in at most 1 hour on a single Cloud TPU, or a few hours on a GPU,
starting from the exact same pre-trained model. SQuAD, for example, can be
trained in around 30 minutes on a single Cloud TPU to achieve a Dev F1 score of
91.0%, which is the single system state-of-the-art.&lt;/p&gt;
&lt;p&gt;The other important aspect of BERT is that it can be adapted to many types of
NLP tasks very easily. In the paper, we demonstrate state-of-the-art results on
sentence-level (e.g., SST-2), sentence-pair-level (e.g., MultiNLI), word-level
(e.g., NER), and span-level (e.g., SQuAD) tasks with almost no task-specific
modifications.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-what-has-been-released-in-this-repository" class="anchor" aria-hidden="true" href="#what-has-been-released-in-this-repository"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What has been released in this repository?&lt;/h2&gt;
&lt;p&gt;We are releasing the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TensorFlow code for the BERT model architecture (which is mostly a standard
&lt;a href="https://arxiv.org/abs/1706.03762" rel="nofollow"&gt;Transformer&lt;/a&gt; architecture).&lt;/li&gt;
&lt;li&gt;Pre-trained checkpoints for both the lowercase and cased version of
&lt;code&gt;BERT-Base&lt;/code&gt; and &lt;code&gt;BERT-Large&lt;/code&gt; from the paper.&lt;/li&gt;
&lt;li&gt;TensorFlow code for push-button replication of the most important
fine-tuning experiments from the paper, including SQuAD, MultiNLI, and MRPC.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of the code in this repository works out-of-the-box with CPU, GPU, and Cloud
TPU.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pre-trained-models" class="anchor" aria-hidden="true" href="#pre-trained-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-trained models&lt;/h2&gt;
&lt;p&gt;We are releasing the &lt;code&gt;BERT-Base&lt;/code&gt; and &lt;code&gt;BERT-Large&lt;/code&gt; models from the paper.
&lt;code&gt;Uncased&lt;/code&gt; means that the text has been lowercased before WordPiece tokenization,
e.g., &lt;code&gt;John Smith&lt;/code&gt; becomes &lt;code&gt;john smith&lt;/code&gt;. The &lt;code&gt;Uncased&lt;/code&gt; model also strips out any
accent markers. &lt;code&gt;Cased&lt;/code&gt; means that the true case and accent markers are
preserved. Typically, the &lt;code&gt;Uncased&lt;/code&gt; model is better unless you know that case
information is important for your task (e.g., Named Entity Recognition or
Part-of-Speech tagging).&lt;/p&gt;
&lt;p&gt;These models are all released under the same license as the source code (Apache
2.0).&lt;/p&gt;
&lt;p&gt;For information about the Multilingual and Chinese model, see the
&lt;a href="https://github.com/google-research/bert/blob/master/multilingual.md"&gt;Multilingual README&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When using a cased model, make sure to pass &lt;code&gt;--do_lower=False&lt;/code&gt; to the training
scripts. (Or pass &lt;code&gt;do_lower_case=False&lt;/code&gt; directly to &lt;code&gt;FullTokenizer&lt;/code&gt; if you're
using your own script.)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The links to the models are here (right-click, 'Save link as...' on the name):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Uncased (Whole Word Masking)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2019_05_30/wwm_cased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Cased (Whole Word Masking)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Uncased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Uncased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Cased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
12-layer, 768-hidden, 12-heads , 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Cased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Multilingual Cased (New, recommended)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
104 languages, 12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/multilingual_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Multilingual Uncased (Orig, not recommended)&lt;/code&gt;&lt;/a&gt;
(Not recommended, use &lt;code&gt;Multilingual Cased&lt;/code&gt; instead)&lt;/strong&gt;: 102 languages,
12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Chinese&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M
parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each .zip file contains three items:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A TensorFlow checkpoint (&lt;code&gt;bert_model.ckpt&lt;/code&gt;) containing the pre-trained
weights (which is actually 3 files).&lt;/li&gt;
&lt;li&gt;A vocab file (&lt;code&gt;vocab.txt&lt;/code&gt;) to map WordPiece to word id.&lt;/li&gt;
&lt;li&gt;A config file (&lt;code&gt;bert_config.json&lt;/code&gt;) which specifies the hyperparameters of
the model.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-fine-tuning-with-bert" class="anchor" aria-hidden="true" href="#fine-tuning-with-bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning with BERT&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: All results on the paper were fine-tuned on a single Cloud TPU,
which has 64GB of RAM. It is currently not possible to re-produce most of the
&lt;code&gt;BERT-Large&lt;/code&gt; results on the paper using a GPU with 12GB - 16GB of RAM, because
the maximum batch size that can fit in memory is too small. We are working on
adding code to this repository which allows for much larger effective batch size
on the GPU. See the section on &lt;a href="#out-of-memory-issues"&gt;out-of-memory issues&lt;/a&gt; for
more details.&lt;/p&gt;
&lt;p&gt;This code was tested with TensorFlow 1.11.0. It was tested with Python2 and
Python3 (but more thoroughly with Python2, since this is what's used internally
in Google).&lt;/p&gt;
&lt;p&gt;The fine-tuning examples which use &lt;code&gt;BERT-Base&lt;/code&gt; should be able to run on a GPU
that has at least 12GB of RAM using the hyperparameters given.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-fine-tuning-with-cloud-tpus" class="anchor" aria-hidden="true" href="#fine-tuning-with-cloud-tpus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning with Cloud TPUs&lt;/h3&gt;
&lt;p&gt;Most of the examples below assumes that you will be running training/evaluation
on your local machine, using a GPU like a Titan X or GTX 1080.&lt;/p&gt;
&lt;p&gt;However, if you have access to a Cloud TPU that you want to train on, just add
the following flags to &lt;code&gt;run_classifier.py&lt;/code&gt; or &lt;code&gt;run_squad.py&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  --use_tpu=True \
  --tpu_name=$TPU_NAME
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please see the
&lt;a href="https://cloud.google.com/tpu/docs/tutorials/mnist" rel="nofollow"&gt;Google Cloud TPU tutorial&lt;/a&gt;
for how to use Cloud TPUs. Alternatively, you can use the Google Colab notebook
"&lt;a href="https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb" rel="nofollow"&gt;BERT FineTuning with Cloud TPUs&lt;/a&gt;".&lt;/p&gt;
&lt;p&gt;On Cloud TPUs, the pretrained model and the output directory will need to be on
Google Cloud Storage. For example, if you have a bucket named &lt;code&gt;some_bucket&lt;/code&gt;, you
might use the following flags instead:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  --output_dir=gs://some_bucket/my_output_dir/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The unzipped pre-trained model files can also be found in the Google Cloud
Storage folder &lt;code&gt;gs://bert_models/2018_10_18&lt;/code&gt;. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export BERT_BASE_DIR=gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-sentence-and-sentence-pair-classification-tasks" class="anchor" aria-hidden="true" href="#sentence-and-sentence-pair-classification-tasks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sentence (and sentence-pair) classification tasks&lt;/h3&gt;
&lt;p&gt;Before running this example you must download the
&lt;a href="https://gluebenchmark.com/tasks" rel="nofollow"&gt;GLUE data&lt;/a&gt; by running
&lt;a href="https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e"&gt;this script&lt;/a&gt;
and unpack it to some directory &lt;code&gt;$GLUE_DIR&lt;/code&gt;. Next, download the &lt;code&gt;BERT-Base&lt;/code&gt;
checkpoint and unzip it to some directory &lt;code&gt;$BERT_BASE_DIR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This example code fine-tunes &lt;code&gt;BERT-Base&lt;/code&gt; on the Microsoft Research Paraphrase
Corpus (MRPC) corpus, which only contains 3,600 examples and can fine-tune in a
few minutes on most GPUs.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12
&lt;span class="pl-k"&gt;export&lt;/span&gt; GLUE_DIR=/path/to/glue

python run_classifier.py \
  --task_name=MRPC \
  --do_train=true \
  --do_eval=true \
  --data_dir=&lt;span class="pl-smi"&gt;$GLUE_DIR&lt;/span&gt;/MRPC \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_model.ckpt \
  --max_seq_length=128 \
  --train_batch_size=32 \
  --learning_rate=2e-5 \
  --num_train_epochs=3.0 \
  --output_dir=/tmp/mrpc_output/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You should see output like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;***** Eval results *****
  eval_accuracy = 0.845588
  eval_loss = 0.505248
  global_step = 343
  loss = 0.505248
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This means that the Dev set accuracy was 84.55%. Small sets like MRPC have a
high variance in the Dev set accuracy, even when starting from the same
pre-training checkpoint. If you re-run multiple times (making sure to point to
different &lt;code&gt;output_dir&lt;/code&gt;), you should see results between 84% and 88%.&lt;/p&gt;
&lt;p&gt;A few other pre-trained models are implemented off-the-shelf in
&lt;code&gt;run_classifier.py&lt;/code&gt;, so it should be straightforward to follow those examples to
use BERT for any single-sentence or sentence-pair classification task.&lt;/p&gt;
&lt;p&gt;Note: You might see a message &lt;code&gt;Running train on CPU&lt;/code&gt;. This really just means
that it's running on something other than a Cloud TPU, which includes a GPU.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-prediction-from-classifier" class="anchor" aria-hidden="true" href="#prediction-from-classifier"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prediction from classifier&lt;/h4&gt;
&lt;p&gt;Once you have trained your classifier you can use it in inference mode by using
the --do_predict=true command. You need to have a file named test.tsv in the
input folder. Output will be created in file called test_results.tsv in the
output folder. Each line will contain output for each sample, columns are the
class probabilities.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12
&lt;span class="pl-k"&gt;export&lt;/span&gt; GLUE_DIR=/path/to/glue
&lt;span class="pl-k"&gt;export&lt;/span&gt; TRAINED_CLASSIFIER=/path/to/fine/tuned/classifier

python run_classifier.py \
  --task_name=MRPC \
  --do_predict=true \
  --data_dir=&lt;span class="pl-smi"&gt;$GLUE_DIR&lt;/span&gt;/MRPC \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$TRAINED_CLASSIFIER&lt;/span&gt; \
  --max_seq_length=128 \
  --output_dir=/tmp/mrpc_output/&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-squad-11" class="anchor" aria-hidden="true" href="#squad-11"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SQuAD 1.1&lt;/h3&gt;
&lt;p&gt;The Stanford Question Answering Dataset (SQuAD) is a popular question answering
benchmark dataset. BERT (at the time of the release) obtains state-of-the-art
results on SQuAD with almost no task-specific network architecture modifications
or data augmentation. However, it does require semi-complex data pre-processing
and post-processing to deal with (a) the variable-length nature of SQuAD context
paragraphs, and (b) the character-level answer annotations which are used for
SQuAD training. This processing is implemented and documented in &lt;code&gt;run_squad.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To run on SQuAD, you will first need to download the dataset. The
&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/" rel="nofollow"&gt;SQuAD website&lt;/a&gt; does not seem to
link to the v1.1 datasets any longer, but the necessary files can be found here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json" rel="nofollow"&gt;train-v1.1.json&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json" rel="nofollow"&gt;dev-v1.1.json&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/allenai/bi-att-flow/blob/master/squad/evaluate-v1.1.py"&gt;evaluate-v1.1.py&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Download these to some directory &lt;code&gt;$SQUAD_DIR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The state-of-the-art SQuAD results from the paper currently cannot be reproduced
on a 12GB-16GB GPU due to memory constraints (in fact, even batch size 1 does
not seem to fit on a 12GB GPU using &lt;code&gt;BERT-Large&lt;/code&gt;). However, a reasonably strong
&lt;code&gt;BERT-Base&lt;/code&gt; model can be trained on the GPU with these hyperparameters:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_squad.py \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_model.ckpt \
  --do_train=True \
  --train_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v1.1.json \
  --do_predict=True \
  --predict_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json \
  --train_batch_size=12 \
  --learning_rate=3e-5 \
  --num_train_epochs=2.0 \
  --max_seq_length=384 \
  --doc_stride=128 \
  --output_dir=/tmp/squad_base/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The dev set predictions will be saved into a file called &lt;code&gt;predictions.json&lt;/code&gt; in
the &lt;code&gt;output_dir&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/evaluate-v1.1.py &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json ./squad/predictions.json&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Which should produce an output like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;f1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 88.41249612335034, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;exact_match&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 81.2488174077578}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You should see a result similar to the 88.5% reported in the paper for
&lt;code&gt;BERT-Base&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you have access to a Cloud TPU, you can train with &lt;code&gt;BERT-Large&lt;/code&gt;. Here is a
set of hyperparameters (slightly different than the paper) which consistently
obtain around 90.5%-91.0% F1 single-system trained only on SQuAD:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_squad.py \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_model.ckpt \
  --do_train=True \
  --train_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v1.1.json \
  --do_predict=True \
  --predict_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json \
  --train_batch_size=24 \
  --learning_rate=3e-5 \
  --num_train_epochs=2.0 \
  --max_seq_length=384 \
  --doc_stride=128 \
  --output_dir=gs://some_bucket/squad_large/ \
  --use_tpu=True \
  --tpu_name=&lt;span class="pl-smi"&gt;$TPU_NAME&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For example, one random run with these parameters produces the following Dev
scores:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;f1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 90.87081895814865, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;exact_match&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 84.38978240302744}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you fine-tune for one epoch on
&lt;a href="http://nlp.cs.washington.edu/triviaqa/" rel="nofollow"&gt;TriviaQA&lt;/a&gt; before this the results will
be even better, but you will need to convert TriviaQA into the SQuAD json
format.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-squad-20" class="anchor" aria-hidden="true" href="#squad-20"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SQuAD 2.0&lt;/h3&gt;
&lt;p&gt;This model is also implemented and documented in &lt;code&gt;run_squad.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To run on SQuAD 2.0, you will first need to download the dataset. The necessary
files can be found here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json" rel="nofollow"&gt;train-v2.0.json&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json" rel="nofollow"&gt;dev-v2.0.json&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/" rel="nofollow"&gt;evaluate-v2.0.py&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Download these to some directory &lt;code&gt;$SQUAD_DIR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;On Cloud TPU you can run with BERT-Large as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_squad.py \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_model.ckpt \
  --do_train=True \
  --train_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v2.0.json \
  --do_predict=True \
  --predict_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v2.0.json \
  --train_batch_size=24 \
  --learning_rate=3e-5 \
  --num_train_epochs=2.0 \
  --max_seq_length=384 \
  --doc_stride=128 \
  --output_dir=gs://some_bucket/squad_large/ \
  --use_tpu=True \
  --tpu_name=&lt;span class="pl-smi"&gt;$TPU_NAME&lt;/span&gt; \
  --version_2_with_negative=True&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We assume you have copied everything from the output directory to a local
directory called ./squad/. The initial dev set predictions will be at
./squad/predictions.json and the differences between the score of no answer ("")
and the best non-null answer for each question will be in the file
./squad/null_odds.json&lt;/p&gt;
&lt;p&gt;Run this script to tune a threshold for predicting null versus non-null answers:&lt;/p&gt;
&lt;p&gt;python $SQUAD_DIR/evaluate-v2.0.py $SQUAD_DIR/dev-v2.0.json
./squad/predictions.json --na-prob-file ./squad/null_odds.json&lt;/p&gt;
&lt;p&gt;Assume the script outputs "best_f1_thresh" THRESH. (Typical values are between
-1.0 and -5.0). You can now re-run the model to generate predictions with the
derived threshold or alternatively you can extract the appropriate answers from
./squad/nbest_predictions.json.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_squad.py \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_model.ckpt \
  --do_train=False \
  --train_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v2.0.json \
  --do_predict=True \
  --predict_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v2.0.json \
  --train_batch_size=24 \
  --learning_rate=3e-5 \
  --num_train_epochs=2.0 \
  --max_seq_length=384 \
  --doc_stride=128 \
  --output_dir=gs://some_bucket/squad_large/ \
  --use_tpu=True \
  --tpu_name=&lt;span class="pl-smi"&gt;$TPU_NAME&lt;/span&gt; \
  --version_2_with_negative=True \
  --null_score_diff_threshold=&lt;span class="pl-smi"&gt;$THRESH&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-out-of-memory-issues" class="anchor" aria-hidden="true" href="#out-of-memory-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Out-of-memory issues&lt;/h3&gt;
&lt;p&gt;All experiments in the paper were fine-tuned on a Cloud TPU, which has 64GB of
device RAM. Therefore, when using a GPU with 12GB - 16GB of RAM, you are likely
to encounter out-of-memory issues if you use the same hyperparameters described
in the paper.&lt;/p&gt;
&lt;p&gt;The factors that affect memory usage are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;max_seq_length&lt;/code&gt;&lt;/strong&gt;: The released models were trained with sequence lengths
up to 512, but you can fine-tune with a shorter max sequence length to save
substantial memory. This is controlled by the &lt;code&gt;max_seq_length&lt;/code&gt; flag in our
example code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;train_batch_size&lt;/code&gt;&lt;/strong&gt;: The memory usage is also directly proportional to
the batch size.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model type, &lt;code&gt;BERT-Base&lt;/code&gt; vs. &lt;code&gt;BERT-Large&lt;/code&gt;&lt;/strong&gt;: The &lt;code&gt;BERT-Large&lt;/code&gt; model
requires significantly more memory than &lt;code&gt;BERT-Base&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Optimizer&lt;/strong&gt;: The default optimizer for BERT is Adam, which requires a lot
of extra memory to store the &lt;code&gt;m&lt;/code&gt; and &lt;code&gt;v&lt;/code&gt; vectors. Switching to a more memory
efficient optimizer can reduce memory usage, but can also affect the
results. We have not experimented with other optimizers for fine-tuning.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Using the default training scripts (&lt;code&gt;run_classifier.py&lt;/code&gt; and &lt;code&gt;run_squad.py&lt;/code&gt;), we
benchmarked the maximum batch size on single Titan X GPU (12GB RAM) with
TensorFlow 1.11.0:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;System&lt;/th&gt;
&lt;th&gt;Seq Length&lt;/th&gt;
&lt;th&gt;Max Batch Size&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;BERT-Base&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;128&lt;/td&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;320&lt;/td&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;384&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;512&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;BERT-Large&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;128&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;320&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;384&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;512&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Unfortunately, these max batch sizes for &lt;code&gt;BERT-Large&lt;/code&gt; are so small that they
will actually harm the model accuracy, regardless of the learning rate used. We
are working on adding code to this repository which will allow much larger
effective batch sizes to be used on the GPU. The code will be based on one (or
both) of the following techniques:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Gradient accumulation&lt;/strong&gt;: The samples in a minibatch are typically
independent with respect to gradient computation (excluding batch
normalization, which is not used here). This means that the gradients of
multiple smaller minibatches can be accumulated before performing the weight
update, and this will be exactly equivalent to a single larger update.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/openai/gradient-checkpointing"&gt;&lt;strong&gt;Gradient checkpointing&lt;/strong&gt;&lt;/a&gt;:
The major use of GPU/TPU memory during DNN training is caching the
intermediate activations in the forward pass that are necessary for
efficient computation in the backward pass. "Gradient checkpointing" trades
memory for compute time by re-computing the activations in an intelligent
way.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;However, this is not implemented in the current release.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-bert-to-extract-fixed-feature-vectors-like-elmo" class="anchor" aria-hidden="true" href="#using-bert-to-extract-fixed-feature-vectors-like-elmo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using BERT to extract fixed feature vectors (like ELMo)&lt;/h2&gt;
&lt;p&gt;In certain cases, rather than fine-tuning the entire pre-trained model
end-to-end, it can be beneficial to obtained &lt;em&gt;pre-trained contextual
embeddings&lt;/em&gt;, which are fixed contextual representations of each input token
generated from the hidden layers of the pre-trained model. This should also
mitigate most of the out-of-memory issues.&lt;/p&gt;
&lt;p&gt;As an example, we include the script &lt;code&gt;extract_features.py&lt;/code&gt; which can be used
like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Sentence A and Sentence B are separated by the ||| delimiter for sentence&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; pair tasks like question answering and entailment.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; For single sentence inputs, put one sentence per line and DON'T use the&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; delimiter.&lt;/span&gt;
&lt;span class="pl-c1"&gt;echo&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Who was Jim Henson ? ||| Jim Henson was a puppeteer&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; /tmp/input.txt

python extract_features.py \
  --input_file=/tmp/input.txt \
  --output_file=/tmp/output.jsonl \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_model.ckpt \
  --layers=-1,-2,-3,-4 \
  --max_seq_length=128 \
  --batch_size=8&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will create a JSON file (one line per line of input) containing the BERT
activations from each Transformer layer specified by &lt;code&gt;layers&lt;/code&gt; (-1 is the final
hidden layer of the Transformer, etc.)&lt;/p&gt;
&lt;p&gt;Note that this script will produce very large output files (by default, around
15kb for every input token).&lt;/p&gt;
&lt;p&gt;If you need to maintain alignment between the original and tokenized words (for
projecting training labels), see the &lt;a href="#tokenization"&gt;Tokenization&lt;/a&gt; section
below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You may see a message like &lt;code&gt;Could not find trained model in model_dir: /tmp/tmpuB5g5c, running initialization to predict.&lt;/code&gt; This message is expected, it
just means that we are using the &lt;code&gt;init_from_checkpoint()&lt;/code&gt; API rather than the
saved model API. If you don't specify a checkpoint or specify an invalid
checkpoint, this script will complain.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tokenization" class="anchor" aria-hidden="true" href="#tokenization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tokenization&lt;/h2&gt;
&lt;p&gt;For sentence-level tasks (or sentence-pair) tasks, tokenization is very simple.
Just follow the example code in &lt;code&gt;run_classifier.py&lt;/code&gt; and &lt;code&gt;extract_features.py&lt;/code&gt;.
The basic procedure for sentence-level tasks is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Instantiate an instance of &lt;code&gt;tokenizer = tokenization.FullTokenizer&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tokenize the raw text with &lt;code&gt;tokens = tokenizer.tokenize(raw_text)&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Truncate to the maximum sequence length. (You can use up to 512, but you
probably want to use shorter if possible for memory and speed reasons.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add the &lt;code&gt;[CLS]&lt;/code&gt; and &lt;code&gt;[SEP]&lt;/code&gt; tokens in the right place.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Word-level and span-level tasks (e.g., SQuAD and NER) are more complex, since
you need to maintain alignment between your input text and output text so that
you can project your training labels. SQuAD is a particularly complex example
because the input labels are &lt;em&gt;character&lt;/em&gt;-based, and SQuAD paragraphs are often
longer than our maximum sequence length. See the code in &lt;code&gt;run_squad.py&lt;/code&gt; to show
how we handle this.&lt;/p&gt;
&lt;p&gt;Before we describe the general recipe for handling word-level tasks, it's
important to understand what exactly our tokenizer is doing. It has three main
steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Text normalization&lt;/strong&gt;: Convert all whitespace characters to spaces, and
(for the &lt;code&gt;Uncased&lt;/code&gt; model) lowercase the input and strip out accent markers.
E.g., &lt;code&gt;John Johanson's, → john johanson's,&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Punctuation splitting&lt;/strong&gt;: Split &lt;em&gt;all&lt;/em&gt; punctuation characters on both sides
(i.e., add whitespace around all punctuation characters). Punctuation
characters are defined as (a) Anything with a &lt;code&gt;P*&lt;/code&gt; Unicode class, (b) any
non-letter/number/space ASCII character (e.g., characters like &lt;code&gt;$&lt;/code&gt; which are
technically not punctuation). E.g., &lt;code&gt;john johanson's, → john johanson ' s ,&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;WordPiece tokenization&lt;/strong&gt;: Apply whitespace tokenization to the output of
the above procedure, and apply
&lt;a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/text_encoder.py"&gt;WordPiece&lt;/a&gt;
tokenization to each token separately. (Our implementation is directly based
on the one from &lt;code&gt;tensor2tensor&lt;/code&gt;, which is linked). E.g., &lt;code&gt;john johanson ' s , → john johan ##son ' s ,&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The advantage of this scheme is that it is "compatible" with most existing
English tokenizers. For example, imagine that you have a part-of-speech tagging
task which looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Input:  John Johanson 's   house
Labels: NNP  NNP      POS NN
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The tokenized output will look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Tokens: john johan ##son ' s house
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Crucially, this would be the same output as if the raw text were &lt;code&gt;John Johanson's house&lt;/code&gt; (with no space before the &lt;code&gt;'s&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;If you have a pre-tokenized representation with word-level annotations, you can
simply tokenize each input word independently, and deterministically maintain an
original-to-tokenized alignment:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Input&lt;/span&gt;
orig_tokens &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;John&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Johanson&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;'s&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,  &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;house&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;]
labels      &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;NNP&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,  &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;NNP&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,      &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;POS&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;NN&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Output&lt;/span&gt;
bert_tokens &lt;span class="pl-k"&gt;=&lt;/span&gt; []

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Token map will be an int -&amp;gt; int mapping between the `orig_tokens` index and&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; the `bert_tokens` index.&lt;/span&gt;
orig_to_tok_map &lt;span class="pl-k"&gt;=&lt;/span&gt; []

tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; tokenization.FullTokenizer(
    &lt;span class="pl-v"&gt;vocab_file&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;vocab_file, &lt;span class="pl-v"&gt;do_lower_case&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)

bert_tokens.append(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;[CLS]&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;for&lt;/span&gt; orig_token &lt;span class="pl-k"&gt;in&lt;/span&gt; orig_tokens:
  orig_to_tok_map.append(&lt;span class="pl-c1"&gt;len&lt;/span&gt;(bert_tokens))
  bert_tokens.extend(tokenizer.tokenize(orig_token))
bert_tokens.append(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;[SEP]&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; bert_tokens == ["[CLS]", "john", "johan", "##son", "'", "s", "house", "[SEP]"]&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; orig_to_tok_map == [1, 2, 4, 6]&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now &lt;code&gt;orig_to_tok_map&lt;/code&gt; can be used to project &lt;code&gt;labels&lt;/code&gt; to the tokenized
representation.&lt;/p&gt;
&lt;p&gt;There are common English tokenization schemes which will cause a slight mismatch
between how BERT was pre-trained. For example, if your input tokenization splits
off contractions like &lt;code&gt;do n't&lt;/code&gt;, this will cause a mismatch. If it is possible to
do so, you should pre-process your data to convert these back to raw-looking
text, but if it's not possible, this mismatch is likely not a big deal.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pre-training-with-bert" class="anchor" aria-hidden="true" href="#pre-training-with-bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-training with BERT&lt;/h2&gt;
&lt;p&gt;We are releasing code to do "masked LM" and "next sentence prediction" on an
arbitrary text corpus. Note that this is &lt;em&gt;not&lt;/em&gt; the exact code that was used for
the paper (the original code was written in C++, and had some additional
complexity), but this code does generate pre-training data as described in the
paper.&lt;/p&gt;
&lt;p&gt;Here's how to run the data generation. The input is a plain text file, with one
sentence per line. (It is important that these be actual sentences for the "next
sentence prediction" task). Documents are delimited by empty lines. The output
is a set of &lt;code&gt;tf.train.Example&lt;/code&gt;s serialized into &lt;code&gt;TFRecord&lt;/code&gt; file format.&lt;/p&gt;
&lt;p&gt;You can perform sentence segmentation with an off-the-shelf NLP toolkit such as
&lt;a href="https://spacy.io/" rel="nofollow"&gt;spaCy&lt;/a&gt;. The &lt;code&gt;create_pretraining_data.py&lt;/code&gt; script will
concatenate segments until they reach the maximum sequence length to minimize
computational waste from padding (see the script for more details). However, you
may want to intentionally add a slight amount of noise to your input data (e.g.,
randomly truncate 2% of input segments) to make it more robust to non-sentential
input during fine-tuning.&lt;/p&gt;
&lt;p&gt;This script stores all of the examples for the entire input file in memory, so
for large data files you should shard the input file and call the script
multiple times. (You can pass in a file glob to &lt;code&gt;run_pretraining.py&lt;/code&gt;, e.g.,
&lt;code&gt;tf_examples.tf_record*&lt;/code&gt;.)&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;max_predictions_per_seq&lt;/code&gt; is the maximum number of masked LM predictions per
sequence. You should set this to around &lt;code&gt;max_seq_length&lt;/code&gt; * &lt;code&gt;masked_lm_prob&lt;/code&gt; (the
script doesn't do that automatically because the exact value needs to be passed
to both scripts).&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python create_pretraining_data.py \
  --input_file=./sample_text.txt \
  --output_file=/tmp/tf_examples.tfrecord \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --do_lower_case=True \
  --max_seq_length=128 \
  --max_predictions_per_seq=20 \
  --masked_lm_prob=0.15 \
  --random_seed=12345 \
  --dupe_factor=5&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here's how to run the pre-training. Do not include &lt;code&gt;init_checkpoint&lt;/code&gt; if you are
pre-training from scratch. The model configuration (including vocab size) is
specified in &lt;code&gt;bert_config_file&lt;/code&gt;. This demo code only pre-trains for a small
number of steps (20), but in practice you will probably want to set
&lt;code&gt;num_train_steps&lt;/code&gt; to 10000 steps or more. The &lt;code&gt;max_seq_length&lt;/code&gt; and
&lt;code&gt;max_predictions_per_seq&lt;/code&gt; parameters passed to &lt;code&gt;run_pretraining.py&lt;/code&gt; must be the
same as &lt;code&gt;create_pretraining_data.py&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_pretraining.py \
  --input_file=/tmp/tf_examples.tfrecord \
  --output_dir=/tmp/pretraining_output \
  --do_train=True \
  --do_eval=True \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_model.ckpt \
  --train_batch_size=32 \
  --max_seq_length=128 \
  --max_predictions_per_seq=20 \
  --num_train_steps=20 \
  --num_warmup_steps=10 \
  --learning_rate=2e-5&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will produce an output like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;***** Eval results *****
  global_step = 20
  loss = 0.0979674
  masked_lm_accuracy = 0.985479
  masked_lm_loss = 0.0979328
  next_sentence_accuracy = 1.0
  next_sentence_loss = 3.45724e-05
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that since our &lt;code&gt;sample_text.txt&lt;/code&gt; file is very small, this example training
will overfit that data in only a few steps and produce unrealistically high
accuracy numbers.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-pre-training-tips-and-caveats" class="anchor" aria-hidden="true" href="#pre-training-tips-and-caveats"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-training tips and caveats&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;If using your own vocabulary, make sure to change &lt;code&gt;vocab_size&lt;/code&gt; in
&lt;code&gt;bert_config.json&lt;/code&gt;. If you use a larger vocabulary without changing this,
you will likely get NaNs when training on GPU or TPU due to unchecked
out-of-bounds access.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;If your task has a large domain-specific corpus available (e.g., "movie
reviews" or "scientific papers"), it will likely be beneficial to run
additional steps of pre-training on your corpus, starting from the BERT
checkpoint.&lt;/li&gt;
&lt;li&gt;The learning rate we used in the paper was 1e-4. However, if you are doing
additional steps of pre-training starting from an existing BERT checkpoint,
you should use a smaller learning rate (e.g., 2e-5).&lt;/li&gt;
&lt;li&gt;Current BERT models are English-only, but we do plan to release a
multilingual model which has been pre-trained on a lot of languages in the
near future (hopefully by the end of November 2018).&lt;/li&gt;
&lt;li&gt;Longer sequences are disproportionately expensive because attention is
quadratic to the sequence length. In other words, a batch of 64 sequences of
length 512 is much more expensive than a batch of 256 sequences of
length 128. The fully-connected/convolutional cost is the same, but the
attention cost is far greater for the 512-length sequences. Therefore, one
good recipe is to pre-train for, say, 90,000 steps with a sequence length of
128 and then for 10,000 additional steps with a sequence length of 512. The
very long sequences are mostly needed to learn positional embeddings, which
can be learned fairly quickly. Note that this does require generating the
data twice with different values of &lt;code&gt;max_seq_length&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If you are pre-training from scratch, be prepared that pre-training is
computationally expensive, especially on GPUs. If you are pre-training from
scratch, our recommended recipe is to pre-train a &lt;code&gt;BERT-Base&lt;/code&gt; on a single
&lt;a href="https://cloud.google.com/tpu/docs/pricing" rel="nofollow"&gt;preemptible Cloud TPU v2&lt;/a&gt;, which
takes about 2 weeks at a cost of about $500 USD (based on the pricing in
October 2018). You will have to scale down the batch size when only training
on a single Cloud TPU, compared to what was used in the paper. It is
recommended to use the largest batch size that fits into TPU memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pre-training-data" class="anchor" aria-hidden="true" href="#pre-training-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-training data&lt;/h3&gt;
&lt;p&gt;We will &lt;strong&gt;not&lt;/strong&gt; be able to release the pre-processed datasets used in the paper.
For Wikipedia, the recommended pre-processing is to download
&lt;a href="https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2" rel="nofollow"&gt;the latest dump&lt;/a&gt;,
extract the text with
&lt;a href="https://github.com/attardi/wikiextractor"&gt;&lt;code&gt;WikiExtractor.py&lt;/code&gt;&lt;/a&gt;, and then apply
any necessary cleanup to convert it into plain text.&lt;/p&gt;
&lt;p&gt;Unfortunately the researchers who collected the
&lt;a href="http://yknzhu.wixsite.com/mbweb" rel="nofollow"&gt;BookCorpus&lt;/a&gt; no longer have it available for
public download. The
&lt;a href="https://web.eecs.umich.edu/~lahiri/gutenberg_dataset.html" rel="nofollow"&gt;Project Guttenberg Dataset&lt;/a&gt;
is a somewhat smaller (200M word) collection of older books that are public
domain.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://commoncrawl.org/" rel="nofollow"&gt;Common Crawl&lt;/a&gt; is another very large collection of
text, but you will likely have to do substantial pre-processing and cleanup to
extract a usable corpus for pre-training BERT.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-learning-a-new-wordpiece-vocabulary" class="anchor" aria-hidden="true" href="#learning-a-new-wordpiece-vocabulary"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learning a new WordPiece vocabulary&lt;/h3&gt;
&lt;p&gt;This repository does not include code for &lt;em&gt;learning&lt;/em&gt; a new WordPiece vocabulary.
The reason is that the code used in the paper was implemented in C++ with
dependencies on Google's internal libraries. For English, it is almost always
better to just start with our vocabulary and pre-trained models. For learning
vocabularies of other languages, there are a number of open source options
available. However, keep in mind that these are not compatible with our
&lt;code&gt;tokenization.py&lt;/code&gt; library:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/google/sentencepiece"&gt;Google's SentencePiece library&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/text_encoder_build_subword.py"&gt;tensor2tensor's WordPiece generation script&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/rsennrich/subword-nmt"&gt;Rico Sennrich's Byte Pair Encoding library&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-using-bert-in-colab" class="anchor" aria-hidden="true" href="#using-bert-in-colab"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using BERT in Colab&lt;/h2&gt;
&lt;p&gt;If you want to use BERT with &lt;a href="https://colab.research.google.com" rel="nofollow"&gt;Colab&lt;/a&gt;, you can
get started with the notebook
"&lt;a href="https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb" rel="nofollow"&gt;BERT FineTuning with Cloud TPUs&lt;/a&gt;".
&lt;strong&gt;At the time of this writing (October 31st, 2018), Colab users can access a
Cloud TPU completely for free.&lt;/strong&gt; Note: One per user, availability limited,
requires a Google Cloud Platform account with storage (although storage may be
purchased with free credit for signing up with GCP), and this capability may not
longer be available in the future. Click on the BERT Colab that was just linked
for more information.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-faq" class="anchor" aria-hidden="true" href="#faq"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FAQ&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-is-this-code-compatible-with-cloud-tpus-what-about-gpus" class="anchor" aria-hidden="true" href="#is-this-code-compatible-with-cloud-tpus-what-about-gpus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Is this code compatible with Cloud TPUs? What about GPUs?&lt;/h4&gt;
&lt;p&gt;Yes, all of the code in this repository works out-of-the-box with CPU, GPU, and
Cloud TPU. However, GPU training is single-GPU only.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-i-am-getting-out-of-memory-errors-what-is-wrong" class="anchor" aria-hidden="true" href="#i-am-getting-out-of-memory-errors-what-is-wrong"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;I am getting out-of-memory errors, what is wrong?&lt;/h4&gt;
&lt;p&gt;See the section on &lt;a href="#out-of-memory-issues"&gt;out-of-memory issues&lt;/a&gt; for more
information.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-is-there-a-pytorch-version-available" class="anchor" aria-hidden="true" href="#is-there-a-pytorch-version-available"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Is there a PyTorch version available?&lt;/h4&gt;
&lt;p&gt;There is no official PyTorch implementation. However, NLP researchers from
HuggingFace made a
&lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT"&gt;PyTorch version of BERT available&lt;/a&gt;
which is compatible with our pre-trained checkpoints and is able to reproduce
our results. We were not involved in the creation or maintenance of the PyTorch
implementation so please direct any questions towards the authors of that
repository.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-is-there-a-chainer-version-available" class="anchor" aria-hidden="true" href="#is-there-a-chainer-version-available"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Is there a Chainer version available?&lt;/h4&gt;
&lt;p&gt;There is no official Chainer implementation. However, Sosuke Kobayashi made a
&lt;a href="https://github.com/soskek/bert-chainer"&gt;Chainer version of BERT available&lt;/a&gt;
which is compatible with our pre-trained checkpoints and is able to reproduce
our results. We were not involved in the creation or maintenance of the Chainer
implementation so please direct any questions towards the authors of that
repository.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-will-models-in-other-languages-be-released" class="anchor" aria-hidden="true" href="#will-models-in-other-languages-be-released"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Will models in other languages be released?&lt;/h4&gt;
&lt;p&gt;Yes, we plan to release a multi-lingual BERT model in the near future. We cannot
make promises about exactly which languages will be included, but it will likely
be a single model which includes &lt;em&gt;most&lt;/em&gt; of the languages which have a
significantly-sized Wikipedia.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-will-models-larger-than-bert-large-be-released" class="anchor" aria-hidden="true" href="#will-models-larger-than-bert-large-be-released"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Will models larger than &lt;code&gt;BERT-Large&lt;/code&gt; be released?&lt;/h4&gt;
&lt;p&gt;So far we have not attempted to train anything larger than &lt;code&gt;BERT-Large&lt;/code&gt;. It is
possible that we will release larger models if we are able to obtain significant
improvements.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-what-license-is-this-library-released-under" class="anchor" aria-hidden="true" href="#what-license-is-this-library-released-under"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What license is this library released under?&lt;/h4&gt;
&lt;p&gt;All code &lt;em&gt;and&lt;/em&gt; models are released under the Apache 2.0 license. See the
&lt;code&gt;LICENSE&lt;/code&gt; file for more information.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-how-do-i-cite-bert" class="anchor" aria-hidden="true" href="#how-do-i-cite-bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How do I cite BERT?&lt;/h4&gt;
&lt;p&gt;For now, cite &lt;a href="https://arxiv.org/abs/1810.04805" rel="nofollow"&gt;the Arxiv paper&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we submit the paper to a conference or journal, we will update the BibTeX.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;This is not an official Google product.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contact-information" class="anchor" aria-hidden="true" href="#contact-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact information&lt;/h2&gt;
&lt;p&gt;For help or issues using BERT, please submit a GitHub issue.&lt;/p&gt;
&lt;p&gt;For personal communication related to BERT, please contact Jacob Devlin
(&lt;code&gt;jacobdevlin@google.com&lt;/code&gt;), Ming-Wei Chang (&lt;code&gt;mingweichang@google.com&lt;/code&gt;), or
Kenton Lee (&lt;code&gt;kentonl@google.com&lt;/code&gt;).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>google-research</author><guid isPermaLink="false">https://github.com/google-research/bert</guid><pubDate>Fri, 20 Dec 2019 00:15:00 GMT</pubDate></item><item><title>deepfakes/faceswap #16 in Python, This week</title><link>https://github.com/deepfakes/faceswap</link><description>&lt;p&gt;&lt;i&gt;Deepfakes Software For All&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deepfakes_faceswap" class="anchor" aria-hidden="true" href="#deepfakes_faceswap"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;deepfakes_faceswap&lt;/h1&gt;
&lt;p align="center"&gt;
  &lt;a href="https://faceswap.dev" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6b384a8b585b47b32af28e9b5f3ba8a0ce538733/68747470733a2f2f692e696d6775722e636f6d2f7a48766a486e622e706e67" data-canonical-src="https://i.imgur.com/zHvjHnb.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;br&gt;FaceSwap is a tool that utilizes deep learning to recognize and swap faces in pictures and videos.
&lt;/p&gt;
&lt;p align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a76e58803660c2a1d01d9357f5b3c2d414f36a62/68747470733a2f2f692e696d6775722e636f6d2f6e5748464c44662e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/a76e58803660c2a1d01d9357f5b3c2d414f36a62/68747470733a2f2f692e696d6775722e636f6d2f6e5748464c44662e6a7067" data-canonical-src="https://i.imgur.com/nWHFLDf.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
&lt;a href="https://www.patreon.com/bePatron?u=23238350" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3d9b27bdf72d7e5407fbad6f9240f6cadc98a7a5/68747470733a2f2f63352e70617472656f6e2e636f6d2f65787465726e616c2f6c6f676f2f6265636f6d655f615f706174726f6e5f627574746f6e2e706e67" data-canonical-src="https://c5.patreon.com/external/logo/become_a_patron_button.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a href="https://www.youtube.com/watch?v=r1jng79a5xc" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/12108b3cad8c6d7d0a4cc6fc30ec518073783e2f/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f72316a6e673739613578632f302e6a7067" data-canonical-src="https://img.youtube.com/vi/r1jng79a5xc/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;br&gt;Jennifer Lawrence/Steve Buscemi FaceSwap using the Villain model
&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/deepfakes/faceswap" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0f6b969a5658811b3d00f66f8144d6f1d4e93a14/68747470733a2f2f7472617669732d63692e6f72672f6465657066616b65732f66616365737761702e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/deepfakes/faceswap.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://faceswap.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d501174fe7b8b930bc3ddbd536e4ab83f59e2304/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f66616365737761702f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/faceswap/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Make sure you check out &lt;a href="INSTALL.md"&gt;INSTALL.md&lt;/a&gt; before getting started.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#deepfakesfaceswap"&gt;deepfakes_faceswap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#manifesto"&gt;Manifesto&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#faceswap-has-ethical-uses"&gt;FaceSwap has ethical uses.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-setup-and-run-the-project"&gt;How To setup and run the project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#overview"&gt;Overview&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#extract"&gt;Extract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#train"&gt;Train&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#convert"&gt;Convert&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#gui"&gt;GUI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#general-notes"&gt;General notes:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#help-i-need-support"&gt;Help I need support!&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#discord-server"&gt;Discord Server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#faceswap-forum"&gt;FaceSwap Forum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#donate"&gt;Donate&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#patreon"&gt;Patreon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#one-time-donations"&gt;One time Donations&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#torzdf"&gt;@torzdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#andenixa"&gt;@andenixa&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#kvrooman"&gt;@kvrooman&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-contribute"&gt;How to contribute&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#for-people-interested-in-the-generative-models"&gt;For people interested in the generative models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#for-devs"&gt;For devs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#for-non-dev-advanced-users"&gt;For non-dev advanced users&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#for-end-users"&gt;For end-users&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#for-haters"&gt;For haters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#about-githubcomdeepfakes"&gt;About github.com/deepfakes&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#what-is-this-repo"&gt;What is this repo?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#why-this-repo"&gt;Why this repo?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#why-is-it-named-deepfakes-if-it-is-not-udeepfakes"&gt;Why is it named 'deepfakes' if it is not /u/deepfakes?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-if-udeepfakes-feels-bad-about-that"&gt;What if /u/deepfakes feels bad about that?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#about-machine-learning"&gt;About machine learning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#how-does-a-computer-know-how-to-recognizeshape-faces-how-does-machine-learning-work-what-is-a-neural-network"&gt;How does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-manifesto" class="anchor" aria-hidden="true" href="#manifesto"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Manifesto&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-faceswap-has-ethical-uses" class="anchor" aria-hidden="true" href="#faceswap-has-ethical-uses"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FaceSwap has ethical uses.&lt;/h2&gt;
&lt;p&gt;When faceswapping was first developed and published, the technology was groundbreaking, it was a huge step in AI development. It was also completely ignored outside of academia because the code was confusing and fragmentary. It required a thorough understanding of complicated AI techniques and took a lot of effort to figure it out. Until one individual brought it together into a single, cohesive collection. It ran, it worked, and as is so often the way with new technology emerging on the internet, it was immediately used to create inappropriate content. Despite the inappropriate uses the software was given originally, it was the first AI code that anyone could download, run and learn by experimentation without having a Ph.D. in math, computer theory, psychology, and more. Before "deepfakes" these techniques were like black magic, only practiced by those who could understand all of the inner workings as described in esoteric and endlessly complicated books and papers.&lt;/p&gt;
&lt;p&gt;"Deepfakes" changed all that and anyone could participate in AI development. To us, developers, the release of this code opened up a fantastic learning opportunity. It allowed us to build on ideas developed by others, collaborate with a variety of skilled coders, experiment with AI whilst learning new skills and ultimately contribute towards an emerging technology which will only see more mainstream use as it progresses.&lt;/p&gt;
&lt;p&gt;Are there some out there doing horrible things with similar software? Yes. And because of this, the developers have been following strict ethical standards. Many of us don't even use it to create videos, we just tinker with the code to see what it does. Sadly, the media concentrates only on the unethical uses of this software. That is, unfortunately, the nature of how it was first exposed to the public, but it is not representative of why it was created, how we use it now, or what we see in its future. Like any technology, it can be used for good or it can be abused. It is our intention to develop FaceSwap in a way that its potential for abuse is minimized whilst maximizing its potential as a tool for learning, experimenting and, yes, for legitimate faceswapping.&lt;/p&gt;
&lt;p&gt;We are not trying to denigrate celebrities or to demean anyone. We are programmers, we are engineers, we are Hollywood VFX artists, we are activists, we are hobbyists, we are human beings. To this end, we feel that it's time to come out with a standard statement of what this software is and isn't as far as us developers are concerned.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;FaceSwap is not for creating inappropriate content.&lt;/li&gt;
&lt;li&gt;FaceSwap is not for changing faces without consent or with the intent of hiding its use.&lt;/li&gt;
&lt;li&gt;FaceSwap is not for any illicit, unethical, or questionable purposes.&lt;/li&gt;
&lt;li&gt;FaceSwap exists to experiment and discover AI techniques, for social or political commentary, for movies, and for any number of ethical and reasonable uses.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are very troubled by the fact that FaceSwap can be used for unethical and disreputable things. However, we support the development of tools and techniques that can be used ethically as well as provide education and experience in AI for anyone who wants to learn it hands-on. We will take a zero tolerance approach to anyone using this software for any unethical purposes and will actively discourage any such uses.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-how-to-setup-and-run-the-project" class="anchor" aria-hidden="true" href="#how-to-setup-and-run-the-project"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How To setup and run the project&lt;/h1&gt;
&lt;p&gt;FaceSwap is a Python program that will run on multiple Operating Systems including Windows, Linux, and MacOS.&lt;/p&gt;
&lt;p&gt;See &lt;a href="INSTALL.md"&gt;INSTALL.md&lt;/a&gt; for full installation instructions. You will need a modern GPU with CUDA support for best performance. AMD GPUs are partially supported.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overview&lt;/h1&gt;
&lt;p&gt;The project has multiple entry points. You will have to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gather photos and/or videos&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Extract&lt;/strong&gt; faces from your raw photos&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Train&lt;/strong&gt; a model on the faces extracted from the photos/videos&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Convert&lt;/strong&gt; your sources with the model&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Check out &lt;a href="USAGE.md"&gt;USAGE.md&lt;/a&gt; for more detailed instructions.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-extract" class="anchor" aria-hidden="true" href="#extract"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Extract&lt;/h2&gt;
&lt;p&gt;From your setup folder, run &lt;code&gt;python faceswap.py extract&lt;/code&gt;. This will take photos from &lt;code&gt;src&lt;/code&gt; folder and extract faces into &lt;code&gt;extract&lt;/code&gt; folder.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-train" class="anchor" aria-hidden="true" href="#train"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train&lt;/h2&gt;
&lt;p&gt;From your setup folder, run &lt;code&gt;python faceswap.py train&lt;/code&gt;. This will take photos from two folders containing pictures of both faces and train a model that will be saved inside the &lt;code&gt;models&lt;/code&gt; folder.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-convert" class="anchor" aria-hidden="true" href="#convert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Convert&lt;/h2&gt;
&lt;p&gt;From your setup folder, run &lt;code&gt;python faceswap.py convert&lt;/code&gt;. This will take photos from &lt;code&gt;original&lt;/code&gt; folder and apply new faces into &lt;code&gt;modified&lt;/code&gt; folder.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-gui" class="anchor" aria-hidden="true" href="#gui"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GUI&lt;/h2&gt;
&lt;p&gt;Alternatively, you can run the GUI by running &lt;code&gt;python faceswap.py gui&lt;/code&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-general-notes" class="anchor" aria-hidden="true" href="#general-notes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;General notes:&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;All of the scripts mentioned have &lt;code&gt;-h&lt;/code&gt;/&lt;code&gt;--help&lt;/code&gt; options with arguments that they will accept. You're smart, you can figure out how this works, right?!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NB: there is a conversion tool for video. This can be accessed by running &lt;code&gt;python tools.py effmpeg -h&lt;/code&gt;. Alternatively, you can use &lt;a href="https://www.ffmpeg.org" rel="nofollow"&gt;ffmpeg&lt;/a&gt; to convert video into photos, process images, and convert images back to the video.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Some tips:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Reusing existing models will train much faster than starting from nothing.
If there is not enough training data, start with someone who looks similar, then switch the data.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-help-i-need-support" class="anchor" aria-hidden="true" href="#help-i-need-support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Help I need support!&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-discord-server" class="anchor" aria-hidden="true" href="#discord-server"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Discord Server&lt;/h2&gt;
&lt;p&gt;Your best bet is to join the &lt;a href="https://discord.gg/FC54sYg" rel="nofollow"&gt;FaceSwap Discord server&lt;/a&gt; where there are plenty of users willing to help. Please note that, like this repo, this is a SFW Server!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-faceswap-forum" class="anchor" aria-hidden="true" href="#faceswap-forum"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FaceSwap Forum&lt;/h2&gt;
&lt;p&gt;Alternatively, you can post questions in the &lt;a href="https://faceswap.dev/forum" rel="nofollow"&gt;FaceSwap Forum&lt;/a&gt;. Please do not post general support questions in this repo as they are liable to be deleted without response.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-donate" class="anchor" aria-hidden="true" href="#donate"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Donate&lt;/h1&gt;
&lt;p&gt;The developers work tirelessly to improve and develop FaceSwap. Many hours have been put in to provide the software as it is today, but this is an extremely time-consuming process with no financial reward. If you enjoy using the software, please consider donating to the devs, so they can spend more time implementing improvements.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-patreon" class="anchor" aria-hidden="true" href="#patreon"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Patreon&lt;/h2&gt;
&lt;p&gt;The best way to support us is through our Patreon page:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.patreon.com/bePatron?u=23238350" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3d9b27bdf72d7e5407fbad6f9240f6cadc98a7a5/68747470733a2f2f63352e70617472656f6e2e636f6d2f65787465726e616c2f6c6f676f2f6265636f6d655f615f706174726f6e5f627574746f6e2e706e67" alt="become-a-patron" data-canonical-src="https://c5.patreon.com/external/logo/become_a_patron_button.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-one-time-donations" class="anchor" aria-hidden="true" href="#one-time-donations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;One time Donations&lt;/h2&gt;
&lt;p&gt;Alternatively you can give a one off donation to any of our Devs:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-torzdf" class="anchor" aria-hidden="true" href="#torzdf"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;@torzdf&lt;/h3&gt;
&lt;p&gt;There is very little FaceSwap code that hasn't been touched by torzdf. He is responsible for implementing the GUI, FAN aligner, MTCNN detector and porting the Villain, DFL-H128 and DFaker models to FaceSwap, as well as significantly improving many areas of the code.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bitcoin:&lt;/strong&gt; 385a1r9tyZpt5LyZcNk1FALTxC8ZHta7yq&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ethereum:&lt;/strong&gt; 0x18CBbff5fA7C78de7B949A2b0160A0d1bd649f80&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Paypal:&lt;/strong&gt; &lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=JZ8PP3YE9J62L" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/7f7cc4a4a25b1dcfb57772d2d16d8c5b5b1a0dea/68747470733a2f2f7777772e70617970616c6f626a656374732e636f6d2f656e5f47422f692f62746e2f62746e5f646f6e6174655f534d2e676966" alt="torzdf" data-canonical-src="https://www.paypalobjects.com/en_GB/i/btn/btn_donate_SM.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-andenixa" class="anchor" aria-hidden="true" href="#andenixa"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;@andenixa&lt;/h3&gt;
&lt;p&gt;Creator of the Unbalanced and OHR models, as well as expanding various capabilities within the training process. Andenixa is currently working on new models and will take requests for donations.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Paypal:&lt;/strong&gt; &lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=NRVLQYGS6NWTU" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/7f7cc4a4a25b1dcfb57772d2d16d8c5b5b1a0dea/68747470733a2f2f7777772e70617970616c6f626a656374732e636f6d2f656e5f47422f692f62746e2f62746e5f646f6e6174655f534d2e676966" alt="andenixa" data-canonical-src="https://www.paypalobjects.com/en_GB/i/btn/btn_donate_SM.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-kvrooman" class="anchor" aria-hidden="true" href="#kvrooman"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;@kvrooman&lt;/h3&gt;
&lt;p&gt;Responsible for consolidating the converters, adding a lot of code to fix model stability issues, and helping significantly towards making the training process more modular, kvrooman continues to be a very active contributor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ethereum:&lt;/strong&gt; 0x18CBbff5fA7C78de7B949A2b0160A0d1bd649f80&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-how-to-contribute" class="anchor" aria-hidden="true" href="#how-to-contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to contribute&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-for-people-interested-in-the-generative-models" class="anchor" aria-hidden="true" href="#for-people-interested-in-the-generative-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;For people interested in the generative models&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Go to the 'faceswap-model' to discuss/suggest/commit alternatives to the current algorithm.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-for-devs" class="anchor" aria-hidden="true" href="#for-devs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;For devs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Read this README entirely&lt;/li&gt;
&lt;li&gt;Fork the repo&lt;/li&gt;
&lt;li&gt;Play with it&lt;/li&gt;
&lt;li&gt;Check issues with the 'dev' tag&lt;/li&gt;
&lt;li&gt;For devs more interested in computer vision and openCV, look at issues with the 'opencv' tag. Also feel free to add your own alternatives/improvements&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-for-non-dev-advanced-users" class="anchor" aria-hidden="true" href="#for-non-dev-advanced-users"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;For non-dev advanced users&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Read this README entirely&lt;/li&gt;
&lt;li&gt;Clone the repo&lt;/li&gt;
&lt;li&gt;Play with it&lt;/li&gt;
&lt;li&gt;Check issues with the 'advuser' tag&lt;/li&gt;
&lt;li&gt;Also go to the '&lt;a href="https://faceswap.dev/forum" rel="nofollow"&gt;faceswap Forum&lt;/a&gt;' and help others.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-for-end-users" class="anchor" aria-hidden="true" href="#for-end-users"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;For end-users&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Get the code here and play with it if you can&lt;/li&gt;
&lt;li&gt;You can also go to the &lt;a href="https://faceswap.dev/forum" rel="nofollow"&gt;faceswap Forum&lt;/a&gt; and help or get help from others.&lt;/li&gt;
&lt;li&gt;Be patient. This is a relatively new technology for developers as well. Much effort is already being put into making this program easy to use for the average user. It just takes time!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Notice&lt;/strong&gt; Any issue related to running the code has to be opened in the &lt;a href="https://faceswap.dev/forum" rel="nofollow"&gt;faceswap Forum&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-for-haters" class="anchor" aria-hidden="true" href="#for-haters"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;For haters&lt;/h2&gt;
&lt;p&gt;Sorry, no time for that.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-about-githubcomdeepfakes" class="anchor" aria-hidden="true" href="#about-githubcomdeepfakes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About github.com/deepfakes&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-what-is-this-repo" class="anchor" aria-hidden="true" href="#what-is-this-repo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is this repo?&lt;/h2&gt;
&lt;p&gt;It is a community repository for active users.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-why-this-repo" class="anchor" aria-hidden="true" href="#why-this-repo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why this repo?&lt;/h2&gt;
&lt;p&gt;The joshua-wu repo seems not active. Simple bugs like missing &lt;em&gt;http://&lt;/em&gt; in front of urls have not been solved since days.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-why-is-it-named-deepfakes-if-it-is-not-udeepfakes" class="anchor" aria-hidden="true" href="#why-is-it-named-deepfakes-if-it-is-not-udeepfakes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why is it named 'deepfakes' if it is not /u/deepfakes?&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Because a typosquat would have happened sooner or later as project grows&lt;/li&gt;
&lt;li&gt;Because we wanted to recognize the original author&lt;/li&gt;
&lt;li&gt;Because it will better federate contributors and users&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-what-if-udeepfakes-feels-bad-about-that" class="anchor" aria-hidden="true" href="#what-if-udeepfakes-feels-bad-about-that"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What if /u/deepfakes feels bad about that?&lt;/h2&gt;
&lt;p&gt;This is a friendly typosquat, and it is fully dedicated to the project. If /u/deepfakes wants to take over this repo/user and drive the project, he is welcomed to do so (Raise an issue, and he will be contacted on Reddit). Please do not send /u/deepfakes messages for help with the code you find here.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-about-machine-learning" class="anchor" aria-hidden="true" href="#about-machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About machine learning&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-how-does-a-computer-know-how-to-recognizeshape-faces-how-does-machine-learning-work-what-is-a-neural-network" class="anchor" aria-hidden="true" href="#how-does-a-computer-know-how-to-recognizeshape-faces-how-does-machine-learning-work-what-is-a-neural-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?&lt;/h2&gt;
&lt;p&gt;It's complicated. Here's a good video that makes the process understandable:
&lt;a href="https://www.youtube.com/watch?v=R9OHn5ZF4Uo" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/79a507ff49fa46a80eedd7a5d81388dbcc49ecca/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f52394f486e355a4634556f2f302e6a7067" alt="How Machines Learn" data-canonical-src="https://img.youtube.com/vi/R9OHn5ZF4Uo/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here's a slightly more in depth video that tries to explain the basic functioning of a neural network:
&lt;a href="https://www.youtube.com/watch?v=aircAruvnKk" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d94510a786e5984be792a151abb7e69e5e3c3ee6/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f61697263417275766e4b6b2f302e6a7067" alt="How Machines Learn" data-canonical-src="https://img.youtube.com/vi/aircAruvnKk/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;tl;dr: training data + trial and error&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>deepfakes</author><guid isPermaLink="false">https://github.com/deepfakes/faceswap</guid><pubDate>Fri, 20 Dec 2019 00:16:00 GMT</pubDate></item><item><title>developers-against-repressions/devs-against-the-machine #17 in Python, This week</title><link>https://github.com/developers-against-repressions/devs-against-the-machine</link><description>&lt;p&gt;&lt;i&gt;I онлайн-хакатон в поддержку политических заключенных &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-devs-against-the-machine" class="anchor" aria-hidden="true" href="#devs-against-the-machine"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;devs-against-the-machine&lt;/h1&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1463b4920f72cb11e11decc55523333a92178c85/68747470733a2f2f692e6962622e636f2f4b774a6e7631622f6c6f676f6861636b2e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/1463b4920f72cb11e11decc55523333a92178c85/68747470733a2f2f692e6962622e636f2f4b774a6e7631622f6c6f676f6861636b2e6a7067" alt="valya" border="0" width="300" height="300" data-canonical-src="https://i.ibb.co/KwJnv1b/logohack.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align="center"&gt;&lt;a href="https://twitter.com/devs_against" rel="nofollow"&gt;twitter&lt;/a&gt; | &lt;a href="https://www.facebook.com/devsagainstthemachine/" rel="nofollow"&gt;facebook&lt;/a&gt; | &lt;a href="https://t-do.ru/devs_against" rel="nofollow"&gt;telegram&lt;/a&gt;&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;&lt;h2&gt;&lt;a id="user-content-онлайн-хакатон-в-поддержку-политзаключенных-13-15-декабря" class="anchor" aria-hidden="true" href="#онлайн-хакатон-в-поддержку-политзаключенных-13-15-декабря"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Онлайн-хакатон в поддержку политзаключенных 13-15 декабря&lt;/h2&gt;
&lt;p&gt;&lt;a href="README.en.md"&gt;English version&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-что-происходит" class="anchor" aria-hidden="true" href="#что-происходит"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Что происходит?&lt;/h2&gt;
&lt;p&gt;Летом и осенью 2019 года мы стали свидетелями новой &lt;a href="https://zona.media/theme/moscow-trial" rel="nofollow"&gt;волны политических репрессий в России&lt;/a&gt;, поводом для которой стали мирные протесты из-за недопуска независимых кандидатов до выборов в Мосгордуму. Хотя акции проходили мирно, без порчи имущества и насилия со стороны демонстрантов, некоторые участники протестов были арестованы и приговорены &lt;a href="https://www.interfax.ru/russia/675323" rel="nofollow"&gt;к реальным срокам заключения&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;В сентябре мы, представители IT-индустрии, написали &lt;a href="https://github.com/developers-against-repressions/case-212"&gt;открытое письмо в защиту фигурантов московского дела&lt;/a&gt;, которое за несколько дней подписали более двух тысяч специалистов. Также открытые письма написали представители многих других профессиональных сообществ: &lt;a href="https://www.pravmir.ru/otkrytoe-pismo-svyashhennikov-v-zashhitu-zaklyuchennyh-po-moskovskomu-delu/" rel="nofollow"&gt;священники&lt;/a&gt;, &lt;a href="http://project1642640.tilda.ws/" rel="nofollow"&gt;учителя&lt;/a&gt;, &lt;a href="https://www.facebook.com/catherina.gordeeva/posts/10157354255466702" rel="nofollow"&gt;врачи&lt;/a&gt; и многие другие. Могло показаться, что возмущение гражданского общества сработало: шестеро арестованных были отпущены.&lt;/p&gt;
&lt;p&gt;Однако машина репрессий не остановилась. Арестованные по &lt;a href="https://delo212.ru" rel="nofollow"&gt;московскому делу&lt;/a&gt; по-прежнему находятся в &lt;a href="https://delo212.ru/arestanty" rel="nofollow"&gt;СИЗО и под домашним арестом&lt;/a&gt;, продолжаются задержания и суды. На сегодня 16 человек находятся под следствием, семеро осуждены на реальные сроки. И это только московское дело, которое наиболее на слуху, но есть и другие: например, дело «Сети», «Нового величия», ростовское дело.&lt;/p&gt;
&lt;p&gt;Сегодня заключили под стражу нового фигуранта «московского дела» &lt;a href="https://delo212.ru/arestant-surovtsev" rel="nofollow"&gt;Сергея Суровцева&lt;/a&gt;. Сергей — выпускник МАИ, работал над созданием ГЛОНАСС и в Кремниевой Долине. Это уже третий наш коллега, которого задерживают по абсурдному делу о «массовых беспорядках».&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-что-делать" class="anchor" aria-hidden="true" href="#что-делать"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Что делать?&lt;/h2&gt;
&lt;p&gt;Мы против того, чтобы люди подвергались репрессиям за свои убеждения, и мы хотим помочь политзаключённым. Если вы с нами согласны, то наверняка уже думали о том, как можете помочь оказавшимся в беде. В России осталось не так уж много легальных способов участвовать в жизни общества, поэтому мы призываем вас принять участие в &lt;strong&gt;первом онлайн-хакатоне в поддержку политических заключённых!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Это возможность использовать код как способ самовыражения и заявить о своей позиции. Помогут любые проекты, которые покажут, что вам не все равно: обработка данных, бот в телеграме, дизайн сайта — все, что угодно. От шуточной игры в браузере до серьезных и помогающих конкретным организациям проектов. Даже если вы напишите в console.log’е у себя на сайте, что против политических репрессий: на самом деле любая поддержка сейчас важна. Чем больше нас будет и чем более активны мы будем — тем больше у нас шансов оказать влияние на ситуацию.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Важное правило: проекты не должны нарушать законодательство РФ.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-кого-приглашаем-участвовать" class="anchor" aria-hidden="true" href="#кого-приглашаем-участвовать"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Кого приглашаем участвовать?&lt;/h2&gt;
&lt;p&gt;Всех неравнодушных программистов, дизайнеров, менеджеров и правозащитников.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-как-это-будет" class="anchor" aria-hidden="true" href="#как-это-будет"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Как это будет?&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Если вы это читаете, значит мы УЖЕ открыли регистрацию команд&lt;/li&gt;
&lt;li&gt;Чтобы зарегистрировать свою команду, достаточно добавить в папку &lt;code&gt;/projects&lt;/code&gt; файл с уникальным именем в следующем формате:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;Teamname | Project Description | Link to repo 
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Если у вас &lt;a href="https://github.com/developers-against-repressions/devs-against-the-machine/issues/1"&gt;нет команды&lt;/a&gt; или &lt;a href="https://github.com/developers-against-repressions/devs-against-the-machine/issues/2"&gt;идеи&lt;/a&gt;, поищите их в соответствующей теме&lt;/li&gt;
&lt;li&gt;Добавляйтесь в &lt;a href="https://t-do.ru/joinchat/Bjgy21k_M8DjJyzLhC0r6w" rel="nofollow"&gt;чат в телеграме&lt;/a&gt;, подписывайтесь на соцсети, будет много обновлений&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;13 декабря в 20:00&lt;/strong&gt; начнется хакатон — это значит, что вы с командой можете начать реализацию своей идеи&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;15 декабря в 20:00&lt;/strong&gt; хакатон завершается, мы ждем от вас документацию в readme.md со ссылкой на двухминутную презентацию вашего проекта (запись экрана)&lt;/li&gt;
&lt;li&gt;В течение нескольких дней жюри расставит оценки, и мы объявим победителей&lt;/li&gt;
&lt;li&gt;Лучшие проекты получат призы от наших партнеров (Дело 212, Медиазона, moloko plus, фотожурналист Давид Френкель, Barking store)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-что-делать-если-у-меня-нет-идеи-для-проекта" class="anchor" aria-hidden="true" href="#что-делать-если-у-меня-нет-идеи-для-проекта"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Что делать, если у меня нет идеи для проекта?&lt;/h2&gt;
&lt;p&gt;Загляните в эту &lt;a href="https://github.com/developers-against-repressions/devs-against-the-machine/issues"&gt;тему&lt;/a&gt; и выберите один из проектов с label'ом &lt;a href="https://github.com/developers-against-repressions/devs-against-the-machine/issues?utf8=%E2%9C%93&amp;amp;q=label%3Aidea"&gt;idea&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-как-будут-оцениваться-проекты" class="anchor" aria-hidden="true" href="#как-будут-оцениваться-проекты"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Как будут оцениваться проекты?&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-1-уровень-реализации" class="anchor" aria-hidden="true" href="#1-уровень-реализации"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Уровень реализации&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Насколько прототип работоспособен? Концепт реализуемый? Будет ли он поддерживаться в будущем?&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-2-соотвествие-тематике" class="anchor" aria-hidden="true" href="#2-соотвествие-тематике"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Соотвествие тематике&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Как проект помогает и/или поддерживает политзаключенных? Выражает ли он гражданскую позицию?&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-3-субъективная-крутизна-идеи" class="anchor" aria-hidden="true" href="#3-субъективная-крутизна-идеи"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. Субъективная крутизна идеи&lt;/h3&gt;
&lt;p&gt;По каждому пункту оценка от 1 до 10. Голосование проходит тайно, чтобы исключить давление авторитета.
Баллы для каждого проекта суммируются, а затем ранжируются по рейтингу. Первые три проекта из списка получат призы от наших партнеров.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-кто-будет-оценивать-проекты" class="anchor" aria-hidden="true" href="#кто-будет-оценивать-проекты"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Кто будет оценивать проекты?&lt;/h2&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/7f58e0f41f777ce1be6b0ef4d9d626d31f66ec95/68747470733a2f2f692e6962622e636f2f4b37544a5a71512f61696461722d726f756e642e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/7f58e0f41f777ce1be6b0ef4d9d626d31f66ec95/68747470733a2f2f692e6962622e636f2f4b37544a5a71512f61696461722d726f756e642e706e67" alt="Айдар Губайдулин" border="0" width="100" height="100" data-canonical-src="https://i.ibb.co/K7TJZqQ/aidar-round.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;&lt;p align="center"&gt;&lt;b&gt;Айдар Губайдулин &lt;/b&gt;&lt;br&gt;
&lt;i&gt;Выпускник МФТИ. Разработчик&lt;br&gt; Фигурант «московского дела»&lt;br&gt;(покинул Россию, объявлен в международный розыск)&lt;/i&gt;&lt;/p&gt;&lt;p&gt;
&lt;br&gt;
&lt;/p&gt;&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/45b1d7d9afc7bc679b3e2e1a2e4ede01c02dc2e1/68747470733a2f2f692e6962622e636f2f6d47424b3543622f76616c79612d726f756e642e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/45b1d7d9afc7bc679b3e2e1a2e4ede01c02dc2e1/68747470733a2f2f692e6962622e636f2f6d47424b3543622f76616c79612d726f756e642e706e67" alt="Валя Дехтяренко" border="0" width="100" height="100" data-canonical-src="https://i.ibb.co/mGBK5Cb/valya-round.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;&lt;p align="center"&gt;&lt;b&gt;Валя Дехтяренко&lt;/b&gt;&lt;br&gt;
  &lt;i&gt;Координатор «Правозащиты Открытки»&lt;/i&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/39b2d4c7aa95b4533e8c9715cfeb6fe2e1190ce0/68747470733a2f2f692e6962622e636f2f4a33625a684a362f62726167696c6576736b79312e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/39b2d4c7aa95b4533e8c9715cfeb6fe2e1190ce0/68747470733a2f2f692e6962622e636f2f4a33625a684a362f62726167696c6576736b79312e706e67" alt="Виталий Брагилевский" border="0" width="100" height="100" data-canonical-src="https://i.ibb.co/J3bZhJ6/bragilevsky1.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align="center"&gt;&lt;b&gt;Виталий Брагилевский&lt;/b&gt;&lt;br&gt; 
&lt;i&gt;Преподаватель СПбГУ&lt;br&gt; разработчик JetBrains&lt;br&gt; автор книги Haskell in Depth&lt;/i&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a7d3946813753b22d61f3d9f94a56a7aab71deec/68747470733a2f2f692e6962622e636f2f386746316e38462f6e65737465726f7661312e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/a7d3946813753b22d61f3d9f94a56a7aab71deec/68747470733a2f2f692e6962622e636f2f386746316e38462f6e65737465726f7661312e706e67" alt="Елизавета Нестерова" border="0" width="100" height="100" data-canonical-src="https://i.ibb.co/8gF1n8F/nesterova1.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align="center"&gt;&lt;b&gt;Елизавета Нестерова&lt;/b&gt;&lt;br&gt;
&lt;i&gt;Корреспондент «Настоящего Времени»&lt;br&gt;Координатор чата «Передачи.Москва»&lt;/i&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fd514d3bf3d0522d07061a871623de7e840c1d84/68747470733a2f2f692e6962622e636f2f4d31334c5473742f766f6c6b6f76312e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/fd514d3bf3d0522d07061a871623de7e840c1d84/68747470733a2f2f692e6962622e636f2f4d31334c5473742f766f6c6b6f76312e706e67" alt="Леонид Волков" border="0" width="100" height="100" data-canonical-src="https://i.ibb.co/M13LTst/volkov1.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;&lt;p align="center"&gt;&lt;b&gt;Леонид Волков&lt;/b&gt;&lt;br&gt;
  &lt;i&gt;IT-специалист, основатель «Общества защиты интернета»&lt;br&gt;Руководитель штаба Навального&lt;/i&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/9bc18eec95ca4ef4ba0ca7e8d642e3c47ece0e56/68747470733a2f2f692e6962622e636f2f4a5243386e33472f696d676f6e6c696e652d636f6d2d75612d53686170652d396a612d4c672d46372d4e456b6b6a2d452e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/9bc18eec95ca4ef4ba0ca7e8d642e3c47ece0e56/68747470733a2f2f692e6962622e636f2f4a5243386e33472f696d676f6e6c696e652d636f6d2d75612d53686170652d396a612d4c672d46372d4e456b6b6a2d452e706e67" alt="Павел Чиков" border="0" width="100" height="100" data-canonical-src="https://i.ibb.co/JRC8n3G/imgonline-com-ua-Shape-9ja-Lg-F7-NEkkj-E.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;&lt;p align="center"&gt;&lt;b&gt;Павел Чиков&lt;/b&gt;&lt;br&gt;
  &lt;i&gt;Руководитель международной правозащитной организации «Агора»&lt;/i&gt;
&lt;/p&gt;
&lt;br&gt; 
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2f73702c2c5f99f415957dcb3e20ee54d0aee987/68747470733a2f2f692e6962622e636f2f56597432314c782f736d69726e6f762d726f756e642e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/2f73702c2c5f99f415957dcb3e20ee54d0aee987/68747470733a2f2f692e6962622e636f2f56597432314c782f736d69726e6f762d726f756e642e706e67" alt="Сергей Смирнов" border="0" width="100" height="100" data-canonical-src="https://i.ibb.co/VYt21Lx/smirnov-round.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align="center"&gt;&lt;b&gt;Сергей Смирнов&lt;/b&gt;&lt;br&gt;
&lt;i&gt;Главный редактор издания «Медиазона»&lt;/i&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/31ff59a8b13f0476485d37882dbf640c005781ec/68747470733a2f2f692e6962622e636f2f47514c7963664d2f696d676f6e6c696e652d636f6d2d75612d53686170652d6b66302d53616e65726e2d5a4f2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/31ff59a8b13f0476485d37882dbf640c005781ec/68747470733a2f2f692e6962622e636f2f47514c7963664d2f696d676f6e6c696e652d636f6d2d75612d53686170652d6b66302d53616e65726e2d5a4f2e706e67" alt="Юлия Яковлева" border="0" width="100" height="100" data-canonical-src="https://i.ibb.co/GQLycfM/imgonline-com-ua-Shape-kf0-Sanern-ZO.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align="center"&gt;&lt;b&gt;Юлия Яковлева&lt;/b&gt;&lt;br&gt;
&lt;i&gt;Выпускница МФТИ&lt;br&gt;Разработчица в Яндексе&lt;/i&gt;&lt;/p&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-проекты" class="anchor" aria-hidden="true" href="#проекты"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Проекты&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Команда&lt;/th&gt;
&lt;th&gt;Описание проекта&lt;/th&gt;
&lt;th&gt;Ссылка на репозиторий&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;foss-gov&lt;/td&gt;
&lt;td&gt;Free and open-source governance&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/linvain/foss-gov"&gt;https://github.com/linvain/foss-gov&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;doxa&lt;/td&gt;
&lt;td&gt;hansel - platform/physdev for alarming in the situations like police arrest&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/destabilizer/hansel"&gt;https://github.com/destabilizer/hansel&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MadIdea&lt;/td&gt;
&lt;td&gt;Однокнопочный диктофон со стриминговым сохранением в облако и публикацией по принципу "мертвой руки"&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Pitovsky/StreamingMic"&gt;https://github.com/Pitovsky/StreamingMic&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Police State&lt;/td&gt;
&lt;td&gt;Карта полицейского насилия. Инфографика по работе ОВД Москвы во время акций протеста&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ivan-hilckov/police-arbitrariness-map"&gt;https://github.com/ivan-hilckov/police-arbitrariness-map&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;#VA&lt;/td&gt;
&lt;td&gt;Единый информационно-просветительный ресурс о политических репрессиях в России&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/valeryalexeev/repressions"&gt;https://github.com/valeryalexeev/repressions&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mcclane&lt;/td&gt;
&lt;td&gt;не знаешь есть впереди толпы менты или нет? Маклейн оповестит если что&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/xelaj/mcclane"&gt;https://github.com/xelaj/mcclane&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;//никнейм&lt;/td&gt;
&lt;td&gt;Бот афиши судов Медиазоны в Telegram&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/asolovyov03/Afisha_mediazona_bot"&gt;https://github.com/asolovyov03/Afisha_mediazona_bot&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pokement&lt;/td&gt;
&lt;td&gt;Игра про полицию и покемонов&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/KlonD90/Pokement"&gt;https://github.com/KlonD90/Pokement&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;42&lt;/td&gt;
&lt;td&gt;визуализированный таймлайн по политическим делам&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/agricolamz/2019.12.13-15_dev_against_the_machine"&gt;https://github.com/agricolamz/2019.12.13-15_dev_against_the_machine&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ROS&lt;/td&gt;
&lt;td&gt;Игра про журналиста&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/rosdvp/newsmaker"&gt;https://github.com/rosdvp/newsmaker&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Electro.212&lt;/td&gt;
&lt;td&gt;Телеграм-бот для фиксация нарушений на различных мероприятиях: незаконное задержание полицейскими или вбросы на выборах.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/prvmsky/rus-report-bot"&gt;https://github.com/prvmsky/rus-report-bot&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Last Word Team&lt;/td&gt;
&lt;td&gt;Сайт с публикациями последних слов политзаключённых&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/CORRUPTOR2037/last-word-project/"&gt;https://github.com/CORRUPTOR2037/last-word-project/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Peace Data&lt;/td&gt;
&lt;td&gt;Бот, зарегистрировавшись в котором, можно участвовать в заседаниях/ездить в овд/писать документы. Соединяет правозащитников и политзаков&lt;/td&gt;
&lt;td&gt;&lt;a href="https://gitlab.com/pavertomato/lapp" rel="nofollow"&gt;https://gitlab.com/pavertomato/lapp&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Snatchmap&lt;/td&gt;
&lt;td&gt;Карта имущества, купленного на деньги налогоплательщиков без их ведома&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Fxlr8/snatchmap"&gt;https://github.com/Fxlr8/snatchmap&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Bypass Engine&lt;/td&gt;
&lt;td&gt;Бот для создания прокси без кода и консоли&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Bypass-Engine/TGOpen"&gt;https://github.com/Bypass-Engine/TGOpen&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Стоп отписки&lt;/td&gt;
&lt;td&gt;Сервис, который структурирует переписки с властями и делает им публичным&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/HackSpb/stop_otpiski"&gt;https://github.com/HackSpb/stop_otpiski&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Assembly team&lt;/td&gt;
&lt;td&gt;Игра про нелёгкие будни депутатов Госдумы&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/CORRUPTOR2037/real-politikz-game"&gt;https://github.com/CORRUPTOR2037/real-politikz-game&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;people_in_ovd_search_bot&lt;/td&gt;
&lt;td&gt;Телеграм-бот, обеспечивающий координацию поиска людей, увезенных в неизвестное ОВД, путем обзвона ОВД в определенном регионе.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://gitlab.com/ogarokpeter/people_in_ovd_search_bot" rel="nofollow"&gt;https://gitlab.com/ogarokpeter/people_in_ovd_search_bot&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;IATM Studio&lt;/td&gt;
&lt;td&gt;Игра о ситуации в России&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/iatm-studio/sovereign-democracy"&gt;https://github.com/iatm-studio/sovereign-democracy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lyubish&lt;/td&gt;
&lt;td&gt;Игра - кликер на актуальную тематику&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/damaskes/time-of-dark-side"&gt;https://github.com/damaskes/time-of-dark-side&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;spirit&lt;/td&gt;
&lt;td&gt;Умная поддержка - веб приложение для объединения сил по поддержке политзеков&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/taigabrew/spirit"&gt;https://github.com/taigabrew/spirit&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Boogieman Team&lt;/td&gt;
&lt;td&gt;Бот-помошник связывающий волонтеров и заключенных&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/EvilSocks/avtozak_help"&gt;https://github.com/EvilSocks/avtozak_help&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Institute Jujment&lt;/td&gt;
&lt;td&gt;Система для поиска студентов настроенных против сущесвтующего правительства&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/herber-beep/literate-memory"&gt;https://github.com/herber-beep/literate-memory&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;newsificator3000&lt;/td&gt;
&lt;td&gt;Elaborate news&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/nekotik1/newsificator3000"&gt;https://github.com/nekotik1/newsificator3000&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Holistic Code&lt;/td&gt;
&lt;td&gt;Сервис для создания аватарок поддержки политических заключенных&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/igorkamyshev/avatar-vs-repression"&gt;https://github.com/igorkamyshev/avatar-vs-repression&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;anonimus&lt;/td&gt;
&lt;td&gt;скрипт для анонимизации людей на видео&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/belskikh/anonimus"&gt;https://github.com/belskikh/anonimus&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;He was right, I was wrong.&lt;/td&gt;
&lt;td&gt;Некоторые смеются над колонкой Голубицкого, а я согласна с каждым словом.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/nekotik2/golubitsky-was-right"&gt;https://github.com/nekotik2/golubitsky-was-right&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ястоюза.рф&lt;/td&gt;
&lt;td&gt;Система прямого финансирования фондов и волонтеров &lt;a href="https://github.com/developers-against-repressions/devs-against-the-machine/issues/21"&gt;#21&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/stouza/stouza.ru"&gt;https://github.com/stouza/stouza.ru&lt;/a&gt; &lt;a href="https://github.com/stouza/stouza-android"&gt;https://github.com/stouza/stouza-android&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Free 212&lt;/td&gt;
&lt;td&gt;Stop Lie&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/0x5A35A3h/stop-lie"&gt;https://github.com/0x5A35A3h/stop-lie&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BlueLemon Chat&lt;/td&gt;
&lt;td&gt;collaborative arts video game&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/twelveseas/bluemen-the-game"&gt;https://github.com/twelveseas/bluemen-the-game&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Badges-team&lt;/td&gt;
&lt;td&gt;Сервис для добавления на любой сайт бейджа "Мы против политических репрессий"&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/okonst/badge-stop-repressions"&gt;https://github.com/okonst/badge-stop-repressions&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;theycanbesaved&lt;/td&gt;
&lt;td&gt;Дзен-дашборд иллюстрирующий насколько малая часть средств, украденных нашими крупнейшими коррупционерами, могла бы спасти жизнь.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/taranoff/theycanbesaved"&gt;https://github.com/taranoff/theycanbesaved&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Refugee Stories&lt;/td&gt;
&lt;td&gt;Raising awareness of the refugee crisis&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/nezlobnaya/refugee-stories"&gt;https://github.com/nezlobnaya/refugee-stories&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Nginx Community&lt;/td&gt;
&lt;td&gt;Веб-сайт кампании в поддержку разработчиков Nginx&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/komachi/poweredbynginx"&gt;https://github.com/komachi/poweredbynginx&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;after_hope&lt;/td&gt;
&lt;td&gt;Бот/сайт со всем необходимым для организации вечеров политзаключенных&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/KichiginaTatiana/after_hope"&gt;https://github.com/KichiginaTatiana/after_hope&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>developers-against-repressions</author><guid isPermaLink="false">https://github.com/developers-against-repressions/devs-against-the-machine</guid><pubDate>Fri, 20 Dec 2019 00:17:00 GMT</pubDate></item><item><title>apache/airflow #18 in Python, This week</title><link>https://github.com/apache/airflow</link><description>&lt;p&gt;&lt;i&gt;Apache Airflow - A platform to programmatically author, schedule, and monitor workflows&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;
&lt;h1&gt;&lt;a id="user-content-apache-airflow" class="anchor" aria-hidden="true" href="#apache-airflow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Apache Airflow&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://badge.fury.io/py/apache-airflow" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0f108ec654c883218585d0045e654bc2d49b2bed/68747470733a2f2f62616467652e667572792e696f2f70792f6170616368652d616972666c6f772e737667" alt="PyPI version" data-canonical-src="https://badge.fury.io/py/apache-airflow.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.org/apache/airflow" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f22f5d352f57d42fa86e959568d637b135d3a675/68747470733a2f2f7472617669732d63692e6f72672f6170616368652f616972666c6f772e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/apache/airflow.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/github/apache/airflow?branch=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8c5b43138631718758fa0e91b9db270daf51b147/68747470733a2f2f696d672e736869656c64732e696f2f636f6465636f762f632f6769746875622f6170616368652f616972666c6f772f6d61737465722e737667" alt="Coverage Status" data-canonical-src="https://img.shields.io/codecov/c/github/apache/airflow/master.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://airflow.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/003c5318f36a13626071e12fc699dabf1fd8f11d/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f616972666c6f772f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/airflow/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://www.apache.org/licenses/LICENSE-2.0.txt" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a0f8662456135c05bf3117cb70a1aaa55c0d3604/687474703a2f2f696d672e736869656c64732e696f2f3a6c6963656e73652d417061636865253230322d626c75652e737667" alt="License" data-canonical-src="http://img.shields.io/:license-Apache%202-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/apache-airflow/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/80cdb6efdf45ca775e10a1e923dacf3b72b67ee5/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6170616368652d616972666c6f772e737667" alt="PyPI - Python Version" data-canonical-src="https://img.shields.io/pypi/pyversions/apache-airflow.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://twitter.com/ApacheAirflow" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a6c2ad238bbc98ffa12bdd2b6aef6ab265125827/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f417061636865416972666c6f772e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f77" alt="Twitter Follow" data-canonical-src="https://img.shields.io/twitter/follow/ApacheAirflow.svg?style=social&amp;amp;label=Follow" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://apache-airflow-slack.herokuapp.com/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/260d99509084c1d8d8ddacdd14978003a0847a26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f736c61636b2d6a6f696e5f636861742d77686974652e7376673f6c6f676f3d736c61636b267374796c653d736f6369616c" alt="Slack Status" data-canonical-src="https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&amp;amp;style=social" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Apache Airflow (or simply Airflow) is a platform to programmatically author, schedule, and monitor workflows.&lt;/p&gt;
&lt;p&gt;When workflows are defined as code, they become more maintainable,
versionable, testable, and collaborative.&lt;/p&gt;
&lt;p&gt;Use Airflow to author workflows as directed acyclic graphs (DAGs) of tasks. The Airflow scheduler executes your tasks on an array of workers while following the specified dependencies. Rich command line utilities make performing complex surgeries on DAGs a snap. The rich user interface makes it easy to visualize pipelines running in production, monitor progress, and troubleshoot issues when needed.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;Table of contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#getting-started"&gt;Getting started&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#beyond-the-horizon"&gt;Beyond the Horizon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#principles"&gt;Principles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#user-interface"&gt;User Interface&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#who-uses-apache-airflow"&gt;Who uses Apache Airflow?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#who-maintains-apache-airflow"&gt;Who Maintains Apache Airflow?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#can-i-use-the-apache-airflow-logo-in-my-presentation"&gt;Can I use the Apache Airflow logo in my presentation?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#links"&gt;Links&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting started&lt;/h2&gt;
&lt;p&gt;Please visit the Airflow Platform documentation (latest &lt;strong&gt;stable&lt;/strong&gt; release) for help with &lt;a href="https://airflow.apache.org/installation.html" rel="nofollow"&gt;installing Airflow&lt;/a&gt;, getting a &lt;a href="https://airflow.apache.org/start.html" rel="nofollow"&gt;quick start&lt;/a&gt;, or a more complete &lt;a href="https://airflow.apache.org/tutorial.html" rel="nofollow"&gt;tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Documentation of GitHub master (latest development branch): &lt;a href="https://airflow.readthedocs.io/en/latest/" rel="nofollow"&gt;ReadTheDocs Documentation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For further information, please visit the &lt;a href="https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Home" rel="nofollow"&gt;Airflow Wiki&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-beyond-the-horizon" class="anchor" aria-hidden="true" href="#beyond-the-horizon"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Beyond the Horizon&lt;/h2&gt;
&lt;p&gt;Airflow &lt;strong&gt;is not&lt;/strong&gt; a data streaming solution. Tasks do not move data from
one to the other (though tasks can exchange metadata!). Airflow is not
in the &lt;a href="http://spark.apache.org/streaming/" rel="nofollow"&gt;Spark Streaming&lt;/a&gt;
or &lt;a href="https://storm.apache.org/" rel="nofollow"&gt;Storm&lt;/a&gt; space, it is more comparable to
&lt;a href="http://oozie.apache.org/" rel="nofollow"&gt;Oozie&lt;/a&gt; or
&lt;a href="https://azkaban.github.io/" rel="nofollow"&gt;Azkaban&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Workflows are expected to be mostly static or slowly changing. You can think
of the structure of the tasks in your workflow as slightly more dynamic
than a database structure would be. Airflow workflows are expected to look
similar from a run to the next, this allows for clarity around
unit of work and continuity.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-principles" class="anchor" aria-hidden="true" href="#principles"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Principles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Dynamic&lt;/strong&gt;:  Airflow pipelines are configuration as code (Python), allowing for dynamic pipeline generation. This allows for writing code that instantiates pipelines dynamically.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt;:  Easily define your own operators, executors and extend the library so that it fits the level of abstraction that suits your environment.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Elegant&lt;/strong&gt;:  Airflow pipelines are lean and explicit. Parameterizing your scripts is built into the core of Airflow using the powerful &lt;strong&gt;Jinja&lt;/strong&gt; templating engine.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scalable&lt;/strong&gt;:  Airflow has a modular architecture and uses a message queue to orchestrate an arbitrary number of workers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-user-interface" class="anchor" aria-hidden="true" href="#user-interface"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;User Interface&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DAGs&lt;/strong&gt;: Overview of all DAGs in your environment.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/docs/img/dags.png"&gt;&lt;img src="/docs/img/dags.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tree View&lt;/strong&gt;: Tree representation of a DAG that spans across time.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/docs/img/tree.png"&gt;&lt;img src="/docs/img/tree.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph View&lt;/strong&gt;: Visualization of a DAG's dependencies and their current status for a specific run.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/docs/img/graph.png"&gt;&lt;img src="/docs/img/graph.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Task Duration&lt;/strong&gt;: Total time spent on different tasks over time.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/docs/img/duration.png"&gt;&lt;img src="/docs/img/duration.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Gantt View&lt;/strong&gt;: Duration and overlap of a DAG.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/docs/img/gantt.png"&gt;&lt;img src="/docs/img/gantt.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Code View&lt;/strong&gt;:  Quick way to view source code of a DAG.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/docs/img/code.png"&gt;&lt;img src="/docs/img/code.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;Want to help build Apache Airflow? Check out our &lt;a href="https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst"&gt;contributing documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-who-uses-apache-airflow" class="anchor" aria-hidden="true" href="#who-uses-apache-airflow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Who uses Apache Airflow?&lt;/h2&gt;
&lt;p&gt;As the Apache Airflow community grows, we'd like to keep track of who is using
the platform. Please send a PR with your company name and @githubhandle
if you may.&lt;/p&gt;
&lt;p&gt;Currently &lt;strong&gt;officially&lt;/strong&gt; using Airflow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://www.4g-capital.com/" rel="nofollow"&gt;4G Capital&lt;/a&gt; [&lt;a href="https://github.com/posei"&gt;@posei&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.6play.fr" rel="nofollow"&gt;6play&lt;/a&gt; [&lt;a href="https://github.com/lemoura"&gt;@lemourA&lt;/a&gt;, &lt;a href="https://github.com/achaussende"&gt;@achaussende&lt;/a&gt;, &lt;a href="https://github.com/d-nguyen"&gt;@d-nguyen&lt;/a&gt;, &lt;a href="https://github.com/julien-gm"&gt;@julien-gm&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://8fit.com/" rel="nofollow"&gt;8fit&lt;/a&gt; [&lt;a href="https://github.com/nicor88"&gt;@nicor88&lt;/a&gt;, &lt;a href="https://github.com/frnzska"&gt;@frnzska&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://90seconds.tv/" rel="nofollow"&gt;90 Seconds&lt;/a&gt; [&lt;a href="https://github.com/aaronmak"&gt;@aaronmak&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://99taxis.com" rel="nofollow"&gt;99&lt;/a&gt; [&lt;a href="https://github.com/fbenevides"&gt;@fbenevides&lt;/a&gt;, &lt;a href="https://github.com/gustavoamigo"&gt;@gustavoamigo&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/mmmaia"&gt;@mmmaia&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.adboost.sk" rel="nofollow"&gt;AdBOOST&lt;/a&gt; [&lt;a href="https://github.com/AdBOOST"&gt;AdBOOST&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.adobe.com/" rel="nofollow"&gt;Adobe&lt;/a&gt; [&lt;a href="https://github.com/mishikaSingh"&gt;@mishikaSingh&lt;/a&gt;, &lt;a href="https://github.com/ramandumcs"&gt;@ramandumcs&lt;/a&gt;, &lt;a href="https://github.com/vardancse"&gt;@vardancse&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/agaridata"&gt;Agari&lt;/a&gt; [&lt;a href="https://github.com/r39132"&gt;@r39132&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://agoda.com" rel="nofollow"&gt;Agoda&lt;/a&gt; [&lt;a href="https://github.com/akki"&gt;@akki&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://airbnb.io/" rel="nofollow"&gt;Airbnb&lt;/a&gt; [&lt;a href="https://github.com/mistercrunch"&gt;@mistercrunch&lt;/a&gt;, &lt;a href="https://github.com/artwr"&gt;@artwr&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.airdna.co" rel="nofollow"&gt;AirDNA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.airfinity.com" rel="nofollow"&gt;Airfinity&lt;/a&gt; [&lt;a href="https://github.com/sibowyer"&gt;@sibowyer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.airtel.in/" rel="nofollow"&gt;Airtel&lt;/a&gt; [&lt;a href="https://github.com/harishbisht"&gt;@harishbisht&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://alan.eu" rel="nofollow"&gt;Alan&lt;/a&gt; [&lt;a href="https://github.com/charles-go"&gt;@charles-go&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://allegro.tech/" rel="nofollow"&gt;allegro.pl&lt;/a&gt; [&lt;a href="https://github.com/kretes"&gt;@kretes&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://alopeyk.com" rel="nofollow"&gt;AloPeyk&lt;/a&gt; [&lt;a href="https://github.com/blcksrx"&gt;@blcksrx&lt;/a&gt;, &lt;a href="https://github.com/AloPeyk"&gt;@AloPeyk&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.getaltx.com/about" rel="nofollow"&gt;AltX&lt;/a&gt; [&lt;a href="https://github.com/pedromduarte"&gt;@pedromduarte&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ampathkenya.org/" rel="nofollow"&gt;AMPATH&lt;/a&gt;[&lt;a href="https://github.com/AMPATH"&gt;@AMPATH&lt;/a&gt;, &lt;a href="https://github.com/fatmali"&gt;@fatmali&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://apigee.com" rel="nofollow"&gt;Apigee&lt;/a&gt; [&lt;a href="https://github.com/btallman"&gt;@btallman&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.argolabs.org" rel="nofollow"&gt;ARGO Labs&lt;/a&gt; [&lt;a href="https://github.com/California-Data-Collaborative"&gt;@California Data Collaborative&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.armedangels.de" rel="nofollow"&gt;ARMEDANGELS&lt;/a&gt; [&lt;a href="https://github.com/swiffer"&gt;@swiffer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.arquivei.com.br/" rel="nofollow"&gt;Arquivei&lt;/a&gt; [&lt;a href="https://github.com/arquivei"&gt;@arquivei&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.arrive.com/" rel="nofollow"&gt;Arrive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://asana.com/" rel="nofollow"&gt;Asana&lt;/a&gt; [&lt;a href="https://github.com/chang"&gt;@chang&lt;/a&gt;, &lt;a href="https://github.com/dima-asana"&gt;@dima-asana&lt;/a&gt;, &lt;a href="https://github.com/jdavidheiser"&gt;@jdavidheiser&lt;/a&gt;, &lt;a href="https://github.com/ricardoandresrojas"&gt;@ricardoandresrojas&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.astronomer.io" rel="nofollow"&gt;Astronomer&lt;/a&gt; [&lt;a href="https://github.com/schnie"&gt;@schnie&lt;/a&gt;, &lt;a href="https://github.com/ashb"&gt;@ashb&lt;/a&gt;, &lt;a href="https://github.com/kaxil"&gt;@kaxil&lt;/a&gt;, &lt;a href="https://github.com/dimberman"&gt;@dimberman&lt;/a&gt;, &lt;a href="https://github.com/andriisoldatenko"&gt;@andriisoldatenko&lt;/a&gt;, &lt;a href="https://github.com/ryw"&gt;@ryw&lt;/a&gt;, &lt;a href="https://github.com/andrewhharmon"&gt;@andrewhharmon&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://auth0.com" rel="nofollow"&gt;Auth0&lt;/a&gt; [&lt;a href="https://github.com/sicarul"&gt;@sicarul&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://automattic.com/" rel="nofollow"&gt;Automattic&lt;/a&gt; [&lt;a href="https://github.com/anandnalya"&gt;@anandnalya&lt;/a&gt;, &lt;a href="https://github.com/bperson"&gt;@bperson&lt;/a&gt;, &lt;a href="https://github.com/Khrol"&gt;@khrol&lt;/a&gt;, &lt;a href="https://github.com/xyu"&gt;@xyu&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://awaytravel.com" rel="nofollow"&gt;Away&lt;/a&gt; [&lt;a href="https://github.com/trunsky"&gt;@trunsky&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.azrisolutions.com/" rel="nofollow"&gt;Azri Solutions&lt;/a&gt; [&lt;a href="https://github.com/userimack"&gt;@userimack&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://site.bagelcode.com/" rel="nofollow"&gt;Bagelcode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://truebalance.io/" rel="nofollow"&gt;BalanceHero&lt;/a&gt; [&lt;a href="https://github.com/swalloow"&gt;@swalloow&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.bancodeformaturas.com.br" rel="nofollow"&gt;Banco de Formaturas&lt;/a&gt; [&lt;a href="https://github.com/guiligan"&gt;@guiligan&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.bandwidthx.com" rel="nofollow"&gt;BandwidthX&lt;/a&gt; [&lt;a href="https://github.com/dineshdsharma"&gt;@dineshdsharma&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.basetis.com" rel="nofollow"&gt;Basetis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.bbm.com/" rel="nofollow"&gt;BBM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.beamly.com/" rel="nofollow"&gt;Beamly&lt;/a&gt; [&lt;a href="https://github.com/christopheralcock"&gt;@christopheralcock&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://beeswax.com/" rel="nofollow"&gt;Beeswax&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bellhops"&gt;Bellhops&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://belugadb.com" rel="nofollow"&gt;BelugaDB&lt;/a&gt; [&lt;a href="https://github.com/fabio-nukui"&gt;@fabio-nukui&lt;/a&gt; &amp;amp; &lt;a href="http://github.com/joao-sallaberry"&gt;@joao-sallaberry&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/lucianoviola"&gt;@lucianoviola&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/tmatuki"&gt;@tmatuki&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.betterment.com/" rel="nofollow"&gt;Betterment&lt;/a&gt; [&lt;a href="https://github.com/Betterment"&gt;@betterment&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.bexs.com.br/en" rel="nofollow"&gt;Bexs Bank&lt;/a&gt; [&lt;a href="https://github.com/felipefb"&gt;@felipefb&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/ishvann"&gt;@ilarsen&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bigquant.com/" rel="nofollow"&gt;BigQuant&lt;/a&gt; [&lt;a href="https://github.com/bigquant"&gt;@bigquant&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.birdz.com/en/" rel="nofollow"&gt;Birdz by Veolia&lt;/a&gt; [&lt;a href="https://github.com/benjamingrenier"&gt;@benjamingrenier&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.blablacar.com" rel="nofollow"&gt;BlaBlaCar&lt;/a&gt; [&lt;a href="https://github.com/puckel"&gt;@puckel&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/wmorin"&gt;@wmorin&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.blacklane.com" rel="nofollow"&gt;Blacklane&lt;/a&gt; [&lt;a href="https://github.com/serkef"&gt;@serkef&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.bloc.io" rel="nofollow"&gt;Bloc&lt;/a&gt; [&lt;a href="https://github.com/dpaola2"&gt;@dpaola2&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.techatbloomberg.com" rel="nofollow"&gt;Bloomberg&lt;/a&gt; [&lt;a href="https://github.com/dimberman"&gt;@dimberman&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.blue-yonder.com" rel="nofollow"&gt;Blue Yonder&lt;/a&gt; [&lt;a href="https://github.com/blue-yonder"&gt;@blue-yonder&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.blueapron.com" rel="nofollow"&gt;BlueApron&lt;/a&gt; [&lt;a href="https://github.com/jasonjho"&gt;@jasonjho&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/matthewdavidhauser"&gt;@matthewdavidhauser&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.bluecore.com" rel="nofollow"&gt;Bluecore&lt;/a&gt; [&lt;a href="https://github.com/JLDLaughlin"&gt;@JLDLaughlin&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bluekiri.com" rel="nofollow"&gt;Bluekiri&lt;/a&gt; [&lt;a href="https://github.com/bluekiri"&gt;@Bluekiri&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bodastage/bts-ce"&gt;Boda Telecom Suite - CE&lt;/a&gt; [&lt;a href="https://github.com/erssebaggala"&gt;@erssebaggala&lt;/a&gt;, &lt;a href="https://github.com/bodastage"&gt;@bodastage&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://bodastage.com" rel="nofollow"&gt;Bodastage Solutions&lt;/a&gt; [&lt;a href="https://github.com/erssebaggala"&gt;@erssebaggala&lt;/a&gt;, &lt;a href="https://github.com/bodastage"&gt;@bodastage&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bombora.com/" rel="nofollow"&gt;Bombora Inc&lt;/a&gt; [&lt;a href="https://github.com/jeffkpayne"&gt;@jeffkpayne&lt;/a&gt;, &lt;a href="https://github.com/pakelley"&gt;@pakelley&lt;/a&gt;, &lt;a href="https://github.com/dNavalta"&gt;@dNavalta&lt;/a&gt;, &lt;a href="https://github.com/austynh"&gt;@austynh&lt;/a&gt;, &lt;a href="https://github.com/TheOriginalAlex"&gt;@TheOriginalAlex&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.bonial.com/" rel="nofollow"&gt;Bonial International GmbH&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.bonnierbroadcasting.com" rel="nofollow"&gt;Bonnier Broadcasting&lt;/a&gt; [&lt;a href="https://github.com/wileeam"&gt;@wileeam&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.bouncex.com" rel="nofollow"&gt;BounceX&lt;/a&gt; [&lt;a href="https://github.com/JoshFerge"&gt;@JoshFerge&lt;/a&gt;, &lt;a href="https://github.com/hudsonrio"&gt;@hudsonrio&lt;/a&gt;, &lt;a href="https://github.com/ronniekritou"&gt;@ronniekritou&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.braintreepayments.com" rel="nofollow"&gt;Braintree&lt;/a&gt; [&lt;a href="https://github.com/coopergillan"&gt;@coopergillan&lt;/a&gt;, &lt;a href="https://github.com/curiousjazz77"&gt;@curiousjazz77&lt;/a&gt;, &lt;a href="https://github.com/raymondberg"&gt;@raymondberg&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://branch.io" rel="nofollow"&gt;Branch&lt;/a&gt; [&lt;a href="https://github.com/sdebarshi"&gt;@sdebarshi&lt;/a&gt;, &lt;a href="https://github.com/dmitrig01"&gt;@dmitrig01&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.caesars.com" rel="nofollow"&gt;Caesars Entertainment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/California-Data-Collaborative"&gt;California Data Collaborative&lt;/a&gt; powered by &lt;a href="http://www.argolabs.org" rel="nofollow"&gt;ARGO Labs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.capitalone.com" rel="nofollow"&gt;Capital One&lt;/a&gt; [&lt;a href="https://github.com/anoopengineer"&gt;@anoopengineer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.carbonite.com" rel="nofollow"&gt;Carbonite&lt;/a&gt; [&lt;a href="https://github.com/ajbosco"&gt;@ajbosco&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.carlabs.ai/" rel="nofollow"&gt;CarLabs&lt;/a&gt; [&lt;a href="https://github.com/sganz"&gt;@sganz&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/odannyc"&gt;@odannyc&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cava.com" rel="nofollow"&gt;CAVA&lt;/a&gt; [&lt;a href="http://github.com/minh5"&gt;@minh5&lt;/a&gt; &amp;amp; &lt;a href="http://github.com/patchus"&gt;@patchus&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.celect.com" rel="nofollow"&gt;Celect&lt;/a&gt; [&lt;a href="https://github.com/superdosh"&gt;@superdosh&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/chadcelect"&gt;@chadcelect&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://censys.io" rel="nofollow"&gt;Censys&lt;/a&gt; [&lt;a href="https://github.com/zakird"&gt;@zakird&lt;/a&gt;, &lt;a href="https://github.com/dadrian"&gt;@dadrian&lt;/a&gt;, &amp;amp; &lt;a href="https://github.com/andrewsardone"&gt;@andrewsardone&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.change.org" rel="nofollow"&gt;Change.org&lt;/a&gt; [&lt;a href="https://github.com/change"&gt;@change&lt;/a&gt;, &lt;a href="https://github.com/vijaykramesh"&gt;@vijaykramesh&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.chartboost.com" rel="nofollow"&gt;Chartboost&lt;/a&gt; [&lt;a href="https://github.com/cgelman"&gt;@cgelman&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/dclubb"&gt;@dclubb&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://checkr.com" rel="nofollow"&gt;Checkr&lt;/a&gt; [&lt;a href="https://github.com/tongboh"&gt;@tongboh&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.chop.edu/centers-programs/division-genomic-diagnostics" rel="nofollow"&gt;Children's Hospital of Philadelphia Division of Genomic Diagnostics&lt;/a&gt; [&lt;a href="https://github.com/genomics-geek/"&gt;@genomics-geek&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cinimex.ru" rel="nofollow"&gt;Cinimex DataLab&lt;/a&gt; [&lt;a href="https://github.com/kdubovikov"&gt;@kdubovikov&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://sandiego.gov" rel="nofollow"&gt;City of San Diego&lt;/a&gt; [&lt;a href="https://github.com/mrmaksimize"&gt;@MrMaksimize&lt;/a&gt;, &lt;a href="https://github.com/andrell81"&gt;@andrell81&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/arnaudvedy"&gt;@arnaudvedy&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.toronto.ca/" rel="nofollow"&gt;City of Toronto&lt;/a&gt; [&lt;a href="https://github.com/CityofToronto"&gt;@CityofToronto&lt;/a&gt;, &lt;a href="https://github.com/radumas"&gt;@radumas&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://civalue.com/" rel="nofollow"&gt;ciValue&lt;/a&gt; [&lt;a href="https://github.com/chencivalue"&gt;@chencivalue&lt;/a&gt;, &lt;a href="https://github.com/YoavGaudin"&gt;@YoavGaudin&lt;/a&gt;, &lt;a href="https://github.com/saleem-boshnak"&gt;@saleem-boshnak&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://civey.com/" rel="nofollow"&gt;Civey&lt;/a&gt; [&lt;a href="https://github.com/WesleyBatista"&gt;@WesleyBatista&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://clairvoyantsoft.com" rel="nofollow"&gt;Clairvoyant&lt;/a&gt; [&lt;a href="https://github.com/shekharv"&gt;@shekharv&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://classmethod.jp/" rel="nofollow"&gt;Classmethod, Inc.&lt;/a&gt; [&lt;a href="https://github.com/shoito"&gt;@shoito&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cleartax.in/" rel="nofollow"&gt;Cleartax&lt;/a&gt; [&lt;a href="https://github.com/anks"&gt;@anks&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/codebuff"&gt;@codebuff&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cloverhealth.com" rel="nofollow"&gt;Clover Health&lt;/a&gt; [&lt;a href="https://github.com/gwax"&gt;@gwax&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/vansivallab"&gt;@vansivallab&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.collectivehealth.com" rel="nofollow"&gt;Collectivehealth Inc.&lt;/a&gt; [&lt;a href="https://github.com/retornam"&gt;@retornam&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.compass.com" rel="nofollow"&gt;Compass&lt;/a&gt; [&lt;a href="https://github.com/wdhorton"&gt;@wdhorton&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.connectwise.com/" rel="nofollow"&gt;ConnectWise&lt;/a&gt; [&lt;a href="https://github.com/jacobeturpin"&gt;@jacobeturpin&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.contaazul.com" rel="nofollow"&gt;ContaAzul&lt;/a&gt; [&lt;a href="https://github.com/bern4rdelli"&gt;@bern4rdelli&lt;/a&gt;, &lt;a href="https://github.com/renanleme"&gt;@renanleme&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/sabino"&gt;@sabino&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cotap/"&gt;Cotap&lt;/a&gt; [&lt;a href="https://github.com/maraca"&gt;@maraca&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/richardchew"&gt;@richardchew&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.craigatwork.com" rel="nofollow"&gt;Craig@Work&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://crealytics.com" rel="nofollow"&gt;Crealytics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.creditkarma.com/" rel="nofollow"&gt;Credit Karma&lt;/a&gt; [&lt;a href="https://github.com/preete-dixit-ck"&gt;@preete-dixit-ck&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/harish-gaggar-ck"&gt;@harish-gaggar-ck&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/greg-finley-ck"&gt;@greg-finley-ck&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.creditas.com.br" rel="nofollow"&gt;Creditas&lt;/a&gt; [&lt;a href="https://github.com/dcassiano"&gt;@dcassiano&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.creditcards.com/" rel="nofollow"&gt;CreditCards.com&lt;/a&gt;[&lt;a href="https://github.com/vmAggies"&gt;@vmAggies&lt;/a&gt; &amp;amp;  &lt;a href="https://github.com/jay-wallaby"&gt;@jay-wallaby&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cryptalizer.com/" rel="nofollow"&gt;Cryptalizer.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.customink.com/" rel="nofollow"&gt;Custom Ink&lt;/a&gt; [&lt;a href="https://github.com/david-dalisay"&gt;@david-dalisay&lt;/a&gt;, &lt;a href="https://github.com/dmartin11"&gt;@dmartin11&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/mpeteuil"&gt;@mpeteuil&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cyscale.com" rel="nofollow"&gt;Cyscale&lt;/a&gt; [&lt;a href="https://github.com/ocical"&gt;@ocical&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.dailymotion.com/fr" rel="nofollow"&gt;Dailymotion&lt;/a&gt; [&lt;a href="https://github.com/germaintanguy"&gt;@germaintanguy&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/hc"&gt;@hc&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.danamica.dk" rel="nofollow"&gt;Danamica&lt;/a&gt; [&lt;a href="https://github.com/testvinder"&gt;@testvinder&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.datareply.co.uk/" rel="nofollow"&gt;Data Reply&lt;/a&gt; [&lt;a href="https://github.com/kaxil"&gt;@kaxil&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://datacamp.com/" rel="nofollow"&gt;DataCamp&lt;/a&gt; [&lt;a href="https://github.com/dgrtwo"&gt;@dgrtwo&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.datafox.com/" rel="nofollow"&gt;DataFox&lt;/a&gt; [&lt;a href="https://github.com/sudowork"&gt;@sudowork&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.dentsu.com/" rel="nofollow"&gt;Dentsu Inc.&lt;/a&gt; [&lt;a href="https://github.com/bryan831"&gt;@bryan831&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/loozhengyuan"&gt;@loozhengyuan&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.digitalfirstmedia.com/" rel="nofollow"&gt;Digital First Media&lt;/a&gt; [&lt;a href="https://github.com/duffn"&gt;@duffn&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/mschmo"&gt;@mschmo&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/seanmuth"&gt;@seanmuth&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://digitalocean.com/" rel="nofollow"&gt;DigitalOcean&lt;/a&gt; [&lt;a href="https://github.com/ajbosco"&gt;@ajbosco&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.doordash.com/" rel="nofollow"&gt;DoorDash&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dotmodus.com" rel="nofollow"&gt;Dotmodus&lt;/a&gt; [&lt;a href="https://github.com/dannylee12"&gt;@dannylee12&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.drivy.com" rel="nofollow"&gt;Drivy&lt;/a&gt; [&lt;a href="https://github.com/AntoineAugusti"&gt;@AntoineAugusti&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.easytaxi.com/" rel="nofollow"&gt;Easy Taxi&lt;/a&gt; [&lt;a href="https://github.com/caique-lima"&gt;@caique-lima&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/diraol"&gt;@diraol&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ellisdon.com/" rel="nofollow"&gt;EllisDon&lt;/a&gt; [&lt;a href="https://github.com/d2kalra"&gt;@d2kalra&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/zbasama"&gt;@zbasama&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.endesa.com" rel="nofollow"&gt;Endesa&lt;/a&gt; [&lt;a href="https://github.com/drexpp"&gt;@drexpp&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.enigma.com" rel="nofollow"&gt;Enigma&lt;/a&gt; [&lt;a href="https://github.com/hydrosquall"&gt;@hydrosquall&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.datamaran.com" rel="nofollow"&gt;Datamaran&lt;/a&gt; [&lt;a href="https://github.com/valexharo"&gt;@valexharo&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.etsy.com" rel="nofollow"&gt;Etsy&lt;/a&gt; [&lt;a href="https://github.com/mchalek"&gt;@mchalek&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://evo.company/" rel="nofollow"&gt;evo.company&lt;/a&gt; [&lt;a href="https://github.com/orhideous"&gt;@orhideous&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.experityhealth.com/" rel="nofollow"&gt;Experity (formerly DocuTAP)&lt;/a&gt; [&lt;a href="https://github.com/cloneluke"&gt;@cloneluke&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/tobyjoliver"&gt;@tobyjoliver&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.fathomhealth.co/" rel="nofollow"&gt;Fathom Health&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.hsmap.com/" rel="nofollow"&gt;Firestone Inventing&lt;/a&gt; [&lt;a href="https://github.com/zihengCat"&gt;@zihengCat&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.flipp.com" rel="nofollow"&gt;Flipp&lt;/a&gt; [&lt;a href="https://github.com/sethwilsonwishabi"&gt;@sethwilsonwishabi&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.format.com" rel="nofollow"&gt;Format&lt;/a&gt; [&lt;a href="https://github.com/4ormat"&gt;@format&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/jasonicarter"&gt;@jasonicarter&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/freshbooks"&gt;FreshBooks&lt;/a&gt; [&lt;a href="https://github.com/DinoCow"&gt;@DinoCow&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.freshworks.com/" rel="nofollow"&gt;Freshworks&lt;/a&gt; [&lt;a href="https://github.com/shaikshakeel"&gt;@shaikshakeel&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fullcontact"&gt;FullContact&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.fuller-inc.com/" rel="nofollow"&gt;Fuller, Inc.&lt;/a&gt; [&lt;a href="https://github.com/wutali"&gt;@wutali&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/sh-tech"&gt;@sh-tech&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://fundera.com" rel="nofollow"&gt;Fundera&lt;/a&gt; [&lt;a href="https://github.com/andyxhadji"&gt;@andyxhadji&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gadventures.com" rel="nofollow"&gt;G Adventures&lt;/a&gt; [&lt;a href="https://github.com/chchtv11"&gt;@chchtv11&lt;/a&gt;, &lt;a href="https://github.com/tgumbley"&gt;@tgumbley&lt;/a&gt;, &lt;a href="https://github.com/tomwross"&gt;@tomwross&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gamewisp.com" rel="nofollow"&gt;GameWisp&lt;/a&gt; [&lt;a href="https://github.com/TJBIII"&gt;@tjbiii&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/theryanwalls"&gt;@theryanwalls&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.genecards.org" rel="nofollow"&gt;GeneCards&lt;/a&gt; [&lt;a href="https://github.com/oferze"&gt;@oferze&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://github.com/gentnerlab"&gt;Gentner Lab&lt;/a&gt; [&lt;a href="https://github.com/neuromusic"&gt;@neuromusic&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://getsimpl.com/" rel="nofollow"&gt;Get Simpl&lt;/a&gt; [&lt;a href="https://github.com/rootcss"&gt;@rootcss&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://about.gitlab.com/" rel="nofollow"&gt;GitLab&lt;/a&gt; [&lt;a href="https://gitlab.com/tlapiana" rel="nofollow"&gt;@tlapiana&lt;/a&gt; &amp;amp; &lt;a href="https://gitlab.com/tayloramurphy" rel="nofollow"&gt;@tayloramurphy&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Glassdoor"&gt;Glassdoor&lt;/a&gt; [&lt;a href="https://github.com/syvineckruyk"&gt;@syvineckruyk&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/sid88in"&gt;@sid88in&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://global-fashion-group.com" rel="nofollow"&gt;Global Fashion Group&lt;/a&gt; [&lt;a href="https://github.com/GFG"&gt;@GFG&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://godatadriven.com/" rel="nofollow"&gt;GoDataDriven&lt;/a&gt; [&lt;a href="https://github.com/basph"&gt;@BasPH&lt;/a&gt;, &lt;a href="https://github.com/danielvdende"&gt;@danielvdende&lt;/a&gt;, &lt;a href="https://github.com/ffinfo"&gt;@ffinfo&lt;/a&gt;, &lt;a href="https://github.com/Fokko"&gt;@Fokko&lt;/a&gt;, &lt;a href="https://github.com/gglanzani"&gt;@gglanzani&lt;/a&gt;, &lt;a href="https://github.com/hgrif"&gt;@hgrif&lt;/a&gt;, &lt;a href="https://github.com/jrderuiter"&gt;@jrderuiter&lt;/a&gt;, &lt;a href="https://github.com/NielsZeilemaker"&gt;@NielsZeilemaker&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gds-gov.tech" rel="nofollow"&gt;GovTech GDS&lt;/a&gt; [&lt;a href="https://github.com/chrissng"&gt;@chrissng&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/datagovsg"&gt;@datagovsg&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.grab.com/sg/" rel="nofollow"&gt;Grab&lt;/a&gt; [&lt;a href="https://github.com/canhtran"&gt;@calvintran&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gradeup.co" rel="nofollow"&gt;Gradeup&lt;/a&gt; [&lt;a href="https://github.com/gradeup"&gt;@gradeup&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.grandrounds.com/" rel="nofollow"&gt;Grand Rounds&lt;/a&gt; [&lt;a href="https://github.com/richddr"&gt;@richddr&lt;/a&gt;, &lt;a href="https://github.com/timz1290"&gt;@timz1290&lt;/a&gt;, &lt;a href="https://github.com/@wenever"&gt;@wenever&lt;/a&gt;, &amp;amp; &lt;a href="https://github.com/runongirlrunon"&gt;@runongirlrunon&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://es.groupalia.com" rel="nofollow"&gt;Groupalia&lt;/a&gt; [&lt;a href="https://github.com/jesusfcr"&gt;@jesusfcr&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://groupon.com" rel="nofollow"&gt;Groupon&lt;/a&gt; [&lt;a href="https://github.com/stevencasey"&gt;@stevencasey&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.growbots.com/" rel="nofollow"&gt;Growbots&lt;/a&gt;[&lt;a href="https://github.com/exploy"&gt;@exploy&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.gsngames.com" rel="nofollow"&gt;GSN Games&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gusto.com" rel="nofollow"&gt;Gusto&lt;/a&gt; [&lt;a href="https://github.com/frankhsu"&gt;@frankhsu&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://joinhandshake.com/" rel="nofollow"&gt;Handshake&lt;/a&gt; [&lt;a href="https://github.com/mhickman"&gt;@mhickman&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.handy.com/careers/73115?gh_jid=73115&amp;amp;gh_src=o5qcxn" rel="nofollow"&gt;Handy&lt;/a&gt; [&lt;a href="https://github.com/marcintustin"&gt;@marcintustin&lt;/a&gt; / &lt;a href="https://github.com/mtustin-handy"&gt;@mtustin-handy&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.happn.com" rel="nofollow"&gt;happn&lt;/a&gt; [&lt;a href="https://github.com/pcorbel"&gt;@pcorbel&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.havan.com.br" rel="nofollow"&gt;HAVAN&lt;/a&gt; [&lt;a href="https://github.com/botbiz"&gt;@botbiz&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://tech.hbc.com" rel="nofollow"&gt;HBC Digital&lt;/a&gt; [&lt;a href="https://github.com/tmccartan"&gt;@tmccartan&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/dmateusp"&gt;@dmateusp&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.hbo.com/" rel="nofollow"&gt;HBO&lt;/a&gt;[&lt;a href="https://github.com/yiwang"&gt;@yiwang&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.healthjump.com/" rel="nofollow"&gt;Healthjump&lt;/a&gt; [&lt;a href="https://github.com/miscbits"&gt;@miscbits&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.hellofresh.com" rel="nofollow"&gt;HelloFresh&lt;/a&gt; [&lt;a href="https://github.com/tammymendt"&gt;@tammymendt&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/davidsbatista"&gt;@davidsbatista&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/iuriinedostup"&gt;@iuriinedostup&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.hipages.com.au/" rel="nofollow"&gt;Hipages&lt;/a&gt; [&lt;a href="https://github.com/arihantsurana"&gt;@arihantsurana&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://holimetrix.com/" rel="nofollow"&gt;Holimetrix&lt;/a&gt; [&lt;a href="https://github.com/thibault-ketterer"&gt;@thibault-ketterer&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/hootsuite"&gt;Hootsuite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.hostnfly.com/" rel="nofollow"&gt;Hostnfly&lt;/a&gt; [&lt;a href="https://github.com/CyrilLeMat"&gt;@CyrilLeMat&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/pierrechopin"&gt;@pierrechopin&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/alexisrosuel"&gt;@alexisrosuel&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/HotelQuickly"&gt;HotelQuickly&lt;/a&gt; [&lt;a href="https://github.com/zinuzoid"&gt;@zinuzoid&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://huq.io" rel="nofollow"&gt;Huq Industries&lt;/a&gt; [&lt;a href="https://github.com/huq-industries"&gt;@huqindustries&lt;/a&gt;, &lt;a href="https://github.com/alepuccetti"&gt;@alepuccetti&lt;/a&gt;, &lt;a href="https://github.com/turbomerl"&gt;@turbomerl&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://piay.iflix.com" rel="nofollow"&gt;Iflix&lt;/a&gt; [&lt;a href="https://github.com/ChaturvediSulabh"&gt;@ChaturvediSulabh&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ifttt.com/" rel="nofollow"&gt;IFTTT&lt;/a&gt; [&lt;a href="https://github.com/apurvajoshi"&gt;@apurvajoshi&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.iheart.com/" rel="nofollow"&gt;iHeartRadio&lt;/a&gt;[&lt;a href="https://github.com/yiwang"&gt;@yiwang&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.imgix.com/" rel="nofollow"&gt;imgix&lt;/a&gt; [&lt;a href="https://github.com/dclubb"&gt;@dclubb&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ing.com/" rel="nofollow"&gt;ING&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.instacart.com/" rel="nofollow"&gt;Instacart &lt;g-emoji class="g-emoji" alias="carrot" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f955.png"&gt;🥕&lt;/g-emoji&gt;&lt;/a&gt; [&lt;a href="https://github.com/arp1t"&gt;@arp1t&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/code-sauce"&gt;@code-sauce&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/jasonlew"&gt;@jasonlew&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/j4p3"&gt;@j4p3&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/lubert"&gt;@lubert&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/mmontagna"&gt;@mmontagna&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/RyanAD"&gt;@RyanAD&lt;/a&gt; &amp;amp;&lt;a href="https://github.com/zzadeh"&gt;@zzadeh&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.intercom.com/" rel="nofollow"&gt;Intercom&lt;/a&gt; [&lt;a href="https://github.com/fox"&gt;@fox&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/paulvic"&gt;@paulvic&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.interia.pl" rel="nofollow"&gt;Interia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://investorise.com/" rel="nofollow"&gt;Investorise&lt;/a&gt; [&lt;a href="https://github.com/svenvarkel"&gt;@svenvarkel&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.is2.co" rel="nofollow"&gt;iS2.co&lt;/a&gt; [&lt;a href="https://github.com/iS2co"&gt;@iS2co&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jampp"&gt;Jampp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jeitto.com.br" rel="nofollow"&gt;Jeitto&lt;/a&gt; [&lt;a href="https://github.com/BrennerPablo"&gt;@BrennerPablo&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/ds-mauri"&gt;@ds-mauri&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.jetlore.com/" rel="nofollow"&gt;Jetlore&lt;/a&gt; [&lt;a href="https://github.com/bderose"&gt;@bderose&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jobteaser.com" rel="nofollow"&gt;JobTeaser&lt;/a&gt; [&lt;a href="https://github.com/stefani75"&gt;@stefani75&lt;/a&gt; &amp;amp;  &lt;a href="https://github.com/knil-sama"&gt;@knil-sama&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.julo.co.id/" rel="nofollow"&gt;JULO&lt;/a&gt; [&lt;a href="https://github.com/sepam"&gt;@sepam&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/tenapril"&gt;@tenapril&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/verzqy"&gt;@verzqy&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kalibrr.com/" rel="nofollow"&gt;Kalibrr&lt;/a&gt; [&lt;a href="https://github.com/charlesverdad"&gt;@charlesverdad&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://kargo.com" rel="nofollow"&gt;Kargo&lt;/a&gt; [&lt;a href="https://github.com/chaithra-yenikapati"&gt;@chaithra-yenikapati&lt;/a&gt;, &lt;a href="https://github.com/akarsh3007"&gt;@akarsh3007&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/dineshanchan"&gt;@dineshanchan&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://karmiclabs.com" rel="nofollow"&gt;Karmic&lt;/a&gt; [&lt;a href="https://github.com/hyw"&gt;@hyw&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://king.com" rel="nofollow"&gt;King&lt;/a&gt; [&lt;a href="https://github.com/nathadfield"&gt;@nathadfield&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kapsarc"&gt;King Abdullah Petroleum Studies and Research Center(KAPSARC)&lt;/a&gt; [&lt;a href="https://github.com/saianupkumarp"&gt;@saianupkumarp&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://kiwi.com/" rel="nofollow"&gt;Kiwi.com&lt;/a&gt; [&lt;a href="https://github.com/underyx"&gt;@underyx&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kogan"&gt;Kogan.com&lt;/a&gt; [&lt;a href="https://github.com/geeknam"&gt;@geeknam&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.korbit.co.kr/" rel="nofollow"&gt;Korbit&lt;/a&gt; [&lt;a href="https://github.com/jensenity"&gt;@jensenity&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kpn.com/" rel="nofollow"&gt;KPN B.V.&lt;/a&gt; [&lt;a href="https://github.com/biyanisuraj"&gt;@biyanisuraj&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/gmic"&gt;@gmic&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.kroton.com.br/" rel="nofollow"&gt;Kroton Educacional&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://fundacaolemann.org.br" rel="nofollow"&gt;Lemann Foundation&lt;/a&gt; [&lt;a href="https://github.com/fernandosjp"&gt;@fernandosjp&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.parts-unlimited.com/" rel="nofollow"&gt;LeMans Corporation&lt;/a&gt; [&lt;a href="https://github.com/alloydwhitlock"&gt;@alloydwhitlock&lt;/a&gt;] &amp;amp; [&lt;a href="https://github.com/tinyrye"&gt;@tinyrye&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.lendup.com/" rel="nofollow"&gt;LendUp&lt;/a&gt; [&lt;a href="https://github.com/lendup"&gt;@lendup&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.letsbonus.com" rel="nofollow"&gt;LetsBonus&lt;/a&gt; [&lt;a href="https://github.com/jesusfcr"&gt;@jesusfcr&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/OpringaoDoTurno"&gt;@OpringaoDoTurno&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.libertyglobal.com/" rel="nofollow"&gt;Liberty Global&lt;/a&gt; [&lt;a href="https://github.com/LibertyGlobal/"&gt;@LibertyGlobal&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://liligo.com/" rel="nofollow"&gt;liligo&lt;/a&gt; [&lt;a href="https://github.com/tromika"&gt;@tromika&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.liulishuo.com/" rel="nofollow"&gt;LingoChamp&lt;/a&gt; [&lt;a href="https://github.com/haitaoyao"&gt;@haitaoyao&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.logitravel.com/" rel="nofollow"&gt;Logitravel Group&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.latimes.com/" rel="nofollow"&gt;Los Angeles Times&lt;/a&gt; [&lt;a href="https://github.com/standyro"&gt;@standyro&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://loksuvidha.com/" rel="nofollow"&gt;LokSuvidha&lt;/a&gt; [&lt;a href="https://github.com/saurabhwahile"&gt;@saurabhwahile&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://luc.id" rel="nofollow"&gt;Lucid&lt;/a&gt; [&lt;a href="https://github.com/jbrownlucid"&gt;@jbrownlucid&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/kkourtchikov"&gt;@kkourtchikov&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.lumosity.com/" rel="nofollow"&gt;Lumos Labs&lt;/a&gt; [&lt;a href="https://github.com/rfroetscher/"&gt;@rfroetscher&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/zzztimbo/"&gt;@zzztimbo&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.lyft.com/" rel="nofollow"&gt;Lyft&lt;/a&gt; [&lt;a href="https://github.com/feng-tao"&gt;@feng-tao&lt;/a&gt;, &lt;a href="https://github.com/milton0825"&gt;@milton0825&lt;/a&gt;, &lt;a href="https://github.com/astahlman"&gt;@astahlman&lt;/a&gt;,
&lt;a href="https://github.com/youngyjd"&gt;@youngyjd&lt;/a&gt;, &lt;a href="https://github.com/ArgentFalcon"&gt;@ArgentFalcon&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.m4u.com.br/" rel="nofollow"&gt;M4U&lt;/a&gt; [&lt;a href="https://github.com/msantino"&gt;@msantino&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://madroneco.com/" rel="nofollow"&gt;Madrone&lt;/a&gt; [&lt;a href="https://github.com/mbreining"&gt;@mbreining&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/scotthb"&gt;@scotthb&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://markovian.com/" rel="nofollow"&gt;Markovian&lt;/a&gt; [&lt;a href="https://github.com/al-xv"&gt;@al-xv&lt;/a&gt;, &lt;a href="https://github.com/skogsbaeck"&gt;@skogsbaeck&lt;/a&gt;, &lt;a href="https://github.com/waltherg"&gt;@waltherg&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mercadoni.com.co" rel="nofollow"&gt;Mercadoni&lt;/a&gt; [&lt;a href="https://github.com/demorenoc"&gt;@demorenoc&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.mercari.com/" rel="nofollow"&gt;Mercari&lt;/a&gt; [&lt;a href="https://github.com/yu-iskw"&gt;@yu-iskw&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MfgLabs"&gt;MFG Labs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.minodes.com" rel="nofollow"&gt;MiNODES&lt;/a&gt; [&lt;a href="https://github.com/dice89"&gt;@dice89&lt;/a&gt;, &lt;a href="https://github.com/diazcelsa"&gt;@diazcelsa&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.modmed.com/" rel="nofollow"&gt;Modernizing Medicine&lt;/a&gt;[&lt;a href="https://github.com/kehv1n"&gt;@kehv1n&lt;/a&gt;, &lt;a href="https://github.com/dalupus"&gt;@dalupus&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.multiply.com" rel="nofollow"&gt;Multiply&lt;/a&gt; [&lt;a href="https://github.com/nrhvyc"&gt;@nrhvyc&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mytaxi.com" rel="nofollow"&gt;mytaxi&lt;/a&gt; [&lt;a href="https://github.com/mytaxi"&gt;@mytaxi&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://nbc.ca" rel="nofollow"&gt;National Bank of Canada&lt;/a&gt; [&lt;a href="https://github.com/brilhana"&gt;@brilhana&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.neoway.com.br/" rel="nofollow"&gt;Neoway&lt;/a&gt; [&lt;a href="https://github.com/orgs/NeowayLabs/people"&gt;@neowaylabs&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nerdwallet.com" rel="nofollow"&gt;Nerdwallet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.newrelic.com" rel="nofollow"&gt;New Relic&lt;/a&gt; [&lt;a href="https://github.com/marcweil"&gt;@marcweil&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.newzoo.com" rel="nofollow"&gt;Newzoo&lt;/a&gt; [&lt;a href="https://github.com/newzoo-nexus"&gt;@newzoo-nexus&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nexttrucking.com/" rel="nofollow"&gt;NEXT Trucking&lt;/a&gt; [&lt;a href="https://github.com/earthmancash2"&gt;@earthmancash2&lt;/a&gt;, &lt;a href="https://github.com/kppullin"&gt;@kppullin&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://nextdoor.com" rel="nofollow"&gt;Nextdoor&lt;/a&gt; [&lt;a href="https://github.com/SivaPandeti"&gt;@SivaPandeti&lt;/a&gt;, &lt;a href="https://github.com/zshapiro"&gt;@zshapiro&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/jthomas123"&gt;@jthomas123&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://nine.com.au" rel="nofollow"&gt;Nine&lt;/a&gt; [&lt;a href="https://github.com/TheZepto"&gt;@TheZepto&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.goprime.io/" rel="nofollow"&gt;OdysseyPrime&lt;/a&gt; [&lt;a href="https://github.com/davideberdin"&gt;@davideberdin&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://offerupnow.com" rel="nofollow"&gt;OfferUp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.onefinestay.com" rel="nofollow"&gt;OneFineStay&lt;/a&gt; [&lt;a href="https://github.com/slangwald"&gt;@slangwald&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://okfn.org" rel="nofollow"&gt;Open Knowledge International&lt;/a&gt; &lt;a href="https://github.com/vitorbaptista"&gt;@vitorbaptista&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.optum.com/" rel="nofollow"&gt;Optum&lt;/a&gt; - &lt;a href="https://www.unitedhealthgroup.com/" rel="nofollow"&gt;UnitedHealthGroup&lt;/a&gt; [&lt;a href="https://github.com/hiteshrd"&gt;@hiteshrd&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.outcomehealth.com/" rel="nofollow"&gt;Outcome Health&lt;/a&gt; [&lt;a href="https://github.com/mikethoun"&gt;@mikethoun&lt;/a&gt;, &lt;a href="https://github.com/rolandotribo"&gt;@rolandotribo&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.github.com/overstock"&gt;Overstock&lt;/a&gt; [&lt;a href="https://github.com/mhousley"&gt;@mhousley&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/mct0006"&gt;@mct0006&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ovh.com" rel="nofollow"&gt;OVH&lt;/a&gt; [&lt;a href="https://github.com/ncrocfer"&gt;@ncrocfer&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/anthonyolea"&gt;@anthonyolea&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pagar.me/" rel="nofollow"&gt;Pagar.me&lt;/a&gt; [&lt;a href="https://github.com/pagarme"&gt;@pagarme&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.paloaltonetworks.com/" rel="nofollow"&gt;Palo Alto Networks&lt;/a&gt; [&lt;a href="https://github.com/PaloAltoNetworks"&gt;@PaloAltoNetworks&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.pandora.com/" rel="nofollow"&gt;Pandora Media&lt;/a&gt; [&lt;a href="https://github.com/Acehaidrey"&gt;@Acehaidrey&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/wolfier"&gt;@wolfier&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://payfit.com" rel="nofollow"&gt;PayFit&lt;/a&gt; [&lt;a href="https://github.com/pcorbel"&gt;@pcorbel&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.paymill.com/" rel="nofollow"&gt;PAYMILL&lt;/a&gt; [&lt;a href="https://github.com/paymill"&gt;@paymill&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/matthiashuschle"&gt;@matthiashuschle&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.paypal.com/" rel="nofollow"&gt;PayPal&lt;/a&gt; [&lt;a href="https://github.com/r39132"&gt;@r39132&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/jhsenjaliya"&gt;@jhsenjaliya&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.pecan.ai" rel="nofollow"&gt;Pecan&lt;/a&gt; [&lt;a href="https://github.com/ohadmata"&gt;@ohadmata&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.pernod-ricard.com/" rel="nofollow"&gt;Pernod-Ricard&lt;/a&gt; [&lt;a href="https://github.com/romain-nio"&gt;@romain-nio&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.plaid.com/" rel="nofollow"&gt;Plaid&lt;/a&gt; [&lt;a href="https://github.com/plaid"&gt;@plaid&lt;/a&gt;, &lt;a href="https://github.com/AustinBGibbons"&gt;@AustinBGibbons&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/jeeyoungk"&gt;@jeeyoungk&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.playbuzz.com/" rel="nofollow"&gt;Playbuzz&lt;/a&gt; [&lt;a href="https://github.com/clintonboys"&gt;@clintonboys&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/dbn"&gt;@dbn&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pmc.com/" rel="nofollow"&gt;PMC&lt;/a&gt; [&lt;a href="https://github.com/andrewm4894"&gt;@andrewm4894&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.poshmark.com" rel="nofollow"&gt;Poshmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.postmates.com" rel="nofollow"&gt;Postmates&lt;/a&gt; [&lt;a href="https://github.com/syeoryn"&gt;@syeoryn&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.premise.com" rel="nofollow"&gt;Premise&lt;/a&gt; [&lt;a href="https://github.com/jmccallum-premise"&gt;@jmccallum-premise&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.prontotools.io/" rel="nofollow"&gt;Pronto Tools&lt;/a&gt; [&lt;a href="https://github.com/zkan"&gt;@zkan&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/mesodiar"&gt;@mesodiar&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://proton.ai/" rel="nofollow"&gt;proton.ai&lt;/a&gt; [&lt;a href="https://github.com/prmsolutions"&gt;@prmsolutions&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.publicispixelpark.de/" rel="nofollow"&gt;Publicis Pixelpark&lt;/a&gt; [&lt;a href="https://github.com/feluelle"&gt;@feluelle&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pubnub.com" rel="nofollow"&gt;PubNub&lt;/a&gt; [&lt;a href="https://github.com/jzucker2"&gt;@jzucker2&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.pxydata.com" rel="nofollow"&gt;PXYData&lt;/a&gt; [&lt;a href="http://github.com/patchus"&gt;@patchus&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://qplum.co" rel="nofollow"&gt;Qplum&lt;/a&gt; [&lt;a href="https://github.com/manti"&gt;@manti&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quantopian.com/" rel="nofollow"&gt;Quantopian&lt;/a&gt; [&lt;a href="http://github.com/eronarn"&gt;@eronarn&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://qubole.com" rel="nofollow"&gt;Qubole&lt;/a&gt; [&lt;a href="https://github.com/msumit"&gt;@msumit&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://quizlet.com" rel="nofollow"&gt;Quizlet&lt;/a&gt; [&lt;a href="https://github.com/quizlet"&gt;@quizlet&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/" rel="nofollow"&gt;Quora&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.raizen.com.br/" rel="nofollow"&gt;Raízen&lt;/a&gt; [&lt;a href="https://github.com/rudlac"&gt;@rudlac&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/guifneves"&gt;@guifneves&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.rea-group.com/" rel="nofollow"&gt;REA Group&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/" rel="nofollow"&gt;Reddit&lt;/a&gt; [&lt;a href="https://github.com/reddit/"&gt;@reddit&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://reverb.com" rel="nofollow"&gt;Reverb&lt;/a&gt;[&lt;a href="https://github.com/reverbdotcom"&gt;@reverbdotcom&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.revolut.com/" rel="nofollow"&gt;Revolut&lt;/a&gt; [&lt;a href="https://github.com/sztanko"&gt;@sztanko&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/nautilus28"&gt;@nautilus28&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://robinhood.com" rel="nofollow"&gt;Robinhood&lt;/a&gt; [&lt;a href="https://github.com/vineet-rh"&gt;@vineet-rh&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://scaleway.com" rel="nofollow"&gt;Scaleway&lt;/a&gt; [&lt;a href="https://github.com/kdeldycke"&gt;@kdeldycke&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.seasoned.co/" rel="nofollow"&gt;Seasoned&lt;/a&gt; [&lt;a href="https://github.com/joshuacano"&gt;@joshuacano&lt;/a&gt;] &amp;amp; [&lt;a href="https://github.com/mmyers5"&gt;@mmyers&lt;/a&gt;] &amp;amp; [&lt;a href="https://github.com/tjward"&gt;@tjward&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.secretescapes.com" rel="nofollow"&gt;Secret Escapes&lt;/a&gt; [&lt;a href="https://github.com/secretescapes"&gt;@secretescapes&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.semantics3.com" rel="nofollow"&gt;Semantics3&lt;/a&gt; [&lt;a href="https://github.com/abishekk92"&gt;@abishekk92&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Sense360"&gt;Sense360&lt;/a&gt; [&lt;a href="https://github.com/KamilMroczek"&gt;@kamilmroczek&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sentry.io" rel="nofollow"&gt;Sentry.io&lt;/a&gt; [&lt;a href="https://github.com/tiopi"&gt;@tiopi&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://shopkick.com/" rel="nofollow"&gt;Shopkick&lt;/a&gt; [&lt;a href="https://github.com/shopkick"&gt;@shopkick&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://hello.getsidecar.com/" rel="nofollow"&gt;Sidecar&lt;/a&gt; [&lt;a href="https://github.com/getsidecar"&gt;@getsidecar&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.similarweb.com/" rel="nofollow"&gt;SimilarWeb&lt;/a&gt; [&lt;a href="https://github.com/similarweb"&gt;@similarweb&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.skyscanner.net/" rel="nofollow"&gt;Skyscanner&lt;/a&gt; [&lt;a href="https://github.com/Skyscanner"&gt;@skyscanner&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.smartnews.com/" rel="nofollow"&gt;SmartNews&lt;/a&gt; [&lt;a href="https://github.com/takus"&gt;@takus&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.snaptravel.com/" rel="nofollow"&gt;SnapTravel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.socialcops.com/" rel="nofollow"&gt;SocialCops&lt;/a&gt; [&lt;a href="https://github.com/vinayak-mehta"&gt;@vinayak-mehta&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/sharky93"&gt;@sharky93&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.societegenerale.fr/" rel="nofollow"&gt;Société générale&lt;/a&gt; [&lt;a href="https://github.com/medmrgh"&gt;@medmrgh&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/s83"&gt;@s83&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.spotahome.com/" rel="nofollow"&gt;Spotahome&lt;/a&gt; [&lt;a href="https://github.com/spotahome"&gt;@spotahome&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/spothero"&gt;SpotHero&lt;/a&gt; [&lt;a href="https://github.com/benjigoldberg"&gt;@benjigoldberg&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/spotify"&gt;Spotify&lt;/a&gt; [&lt;a href="https://github.com/znichols"&gt;@znichols&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://squareup.com/" rel="nofollow"&gt;Square&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://beta.stackspace.io/" rel="nofollow"&gt;Stackspace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.stone.co" rel="nofollow"&gt;StoneCo&lt;/a&gt; [&lt;a href="https://github.com/lgwacker"&gt;@lgwacker&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://strava.com" rel="nofollow"&gt;Strava&lt;/a&gt; [&lt;a href="https://github.com/strava"&gt;@strava&lt;/a&gt;, &lt;a href="https://github.com/dhuang"&gt;@dhuang&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/liamstewart"&gt;@liamstewart&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://stripe.com" rel="nofollow"&gt;Stripe&lt;/a&gt; [&lt;a href="https://github.com/jbalogh"&gt;@jbalogh&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.strongmind.com" rel="nofollow"&gt;Strongmind&lt;/a&gt; [&lt;a href="https://github.com/tomchapin"&gt;@tomchapin&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/wongstein"&gt;@wongstein&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.surfline.com/" rel="nofollow"&gt;Surfline&lt;/a&gt; [&lt;a href="https://github.com/jawang35"&gt;@jawang35&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t2systems.com" rel="nofollow"&gt;T2 Systems&lt;/a&gt; [&lt;a href="https://github.com/unclaimedpants"&gt;@unclaimedpants&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tails.com/" rel="nofollow"&gt;Tails.com&lt;/a&gt; [&lt;a href="https://github.com/alanmcruickshank"&gt;@alanmcruickshank&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.tek.fi/en" rel="nofollow"&gt;TEK&lt;/a&gt; [&lt;a href="https://github.com/telac"&gt;@telac&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.alpha.company/" rel="nofollow"&gt;Telefonica Innovation Alpha&lt;/a&gt; [&lt;a href="https://github.com/Alpha-health"&gt;@Alpha-Health&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.teliacompany.com/en" rel="nofollow"&gt;Telia Company&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.tesla.com/" rel="nofollow"&gt;Tesla&lt;/a&gt; [&lt;a href="https://github.com/thoralf-gutierrez"&gt;@thoralf-gutierrez&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.homedepot.com/" rel="nofollow"&gt;The Home Depot&lt;/a&gt;[&lt;a href="https://github.com/apekshithr"&gt;@apekshithr&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.theiconic.com.au/" rel="nofollow"&gt;THE ICONIC&lt;/a&gt; [&lt;a href="https://github.com/revathijay"&gt;@revathijay&lt;/a&gt;] [&lt;a href="https://github.com/ilikedata"&gt;@ilikedata&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://thinkingmachin.es" rel="nofollow"&gt;Thinking Machines&lt;/a&gt; [&lt;a href="https://github.com/marksteve"&gt;@marksteve&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.thinknear.com/" rel="nofollow"&gt;Thinknear&lt;/a&gt; [&lt;a href="https://github.com/d3cay1"&gt;@d3cay1&lt;/a&gt;, &lt;a href="https://github.com/ccson"&gt;@ccson&lt;/a&gt;, &amp;amp; &lt;a href="https://github.com/ababian"&gt;@ababian&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.thoughtworks.com/" rel="nofollow"&gt;ThoughtWorks&lt;/a&gt; [&lt;a href="https://github.com/sann3"&gt;@sann3&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.thumbtack.com/" rel="nofollow"&gt;Thumbtack&lt;/a&gt; [&lt;a href="https://github.com/natekupp"&gt;@natekupp&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tictail.com/" rel="nofollow"&gt;Tictail&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tile.com/" rel="nofollow"&gt;Tile&lt;/a&gt; [&lt;a href="https://github.com/ranjanmanish"&gt;@ranjanmanish&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tinder.com/" rel="nofollow"&gt;Tinder&lt;/a&gt; [&lt;a href="https://github.com/kbendick"&gt;@kbendick&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tokenanalyst"&gt;TokenAnalyst&lt;/a&gt; [&lt;a href="https://github.com/simonohanlon101"&gt;@simonohanlon101&lt;/a&gt;, &lt;a href="https://github.com/ankitchiplunkar"&gt;@ankitchiplunkar&lt;/a&gt;, &lt;a href="https://github.com/sidshekhar"&gt;@sidshekhar&lt;/a&gt;, &lt;a href="https://github.com/sp6pe"&gt;@sp6pe&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.tokopedia.com/" rel="nofollow"&gt;Tokopedia&lt;/a&gt; [&lt;a href="https://github.com/topedmaria"&gt;@topedmaria&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.trocafone.com/" rel="nofollow"&gt;Trocafone&lt;/a&gt; [&lt;a href="https://github.com/idontdomath"&gt;@idontdomath&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/gseva"&gt;@gseva&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/ordonezf"&gt;@ordonezf&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/PalmaLeandro"&gt;@PalmaLeandro&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.twinelabs.com/" rel="nofollow"&gt;Twine Labs&lt;/a&gt; [&lt;a href="https://github.com/ivorpeles"&gt;@ivorpeles&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.twitter.com/" rel="nofollow"&gt;Twitter&lt;/a&gt; [&lt;a href="https://github.com/aoen"&gt;@aoen&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ubisoft.com/" rel="nofollow"&gt;Ubisoft&lt;/a&gt; [&lt;a href="https://github.com/Walkoss"&gt;@Walkoss&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.udacity.com/" rel="nofollow"&gt;Udacity&lt;/a&gt; [&lt;a href="https://github.com/DandikUnited"&gt;@dandikunited&lt;/a&gt;, &lt;a href="https://github.com/simon-uc"&gt;@simon-uc&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.united.com/" rel="nofollow"&gt;United Airlines&lt;/a&gt; [&lt;a href="https://github.com/ilopezfr"&gt;@ilopezfr&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.upsight.com" rel="nofollow"&gt;Upsight&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://veer.tv" rel="nofollow"&gt;VeeR VR&lt;/a&gt; [&lt;a href="https://github.com/pishilong"&gt;@pishilong&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.veikkaus.fi" rel="nofollow"&gt;Veikkaus&lt;/a&gt; [&lt;a href="https://github.com/hixus"&gt;@hixus&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.vente-exclusive.com/" rel="nofollow"&gt;Vente-Exclusive.com&lt;/a&gt; [&lt;a href="https://github.com/alexvanboxel"&gt;@alexvanboxel&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.vevo.com/" rel="nofollow"&gt;Vevo&lt;/a&gt; [&lt;a href="https://github.com/csetiawan"&gt;@csetiawan&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/jerrygillespie"&gt;@jerrygillespie&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.vidio.com/" rel="nofollow"&gt;Vidio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ville.montreal.qc.ca/" rel="nofollow"&gt;Ville de Montréal&lt;/a&gt;&lt;a href="https://github.com/VilledeMontreal/"&gt;@VilledeMontreal&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/vnomics"&gt;Vnomics&lt;/a&gt; [&lt;a href="https://github.com/lpalum"&gt;@lpalum&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.walmartlabs.com" rel="nofollow"&gt;Walmart Labs&lt;/a&gt; [&lt;a href="https://github.com/bharathpalaksha"&gt;@bharathpalaksha&lt;/a&gt;, &lt;a href="https://github.com/vipul007ravi"&gt;@vipul007ravi&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.waze.com" rel="nofollow"&gt;Waze&lt;/a&gt; [&lt;a href="https://github.com/wazeHQ"&gt;@waze&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.wepay.com" rel="nofollow"&gt;WePay&lt;/a&gt; [&lt;a href="https://github.com/criccomini"&gt;@criccomini&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/mtagle"&gt;@mtagle&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/WeTransfer"&gt;WeTransfer&lt;/a&gt; [&lt;a href="https://github.com/coredipper"&gt;@coredipper&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/higee"&gt;@higee&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/azclub"&gt;@azclub&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.whistle.com" rel="nofollow"&gt;Whistle Labs&lt;/a&gt; [&lt;a href="https://github.com/ananya77041"&gt;@ananya77041&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wisebanyan.com/" rel="nofollow"&gt;WiseBanyan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.wooga.com/" rel="nofollow"&gt;Wooga&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.wrike.com" rel="nofollow"&gt;Wrike&lt;/a&gt; [&lt;a href="https://github.com/eliseealex"&gt;@eliseealex&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/Teoretic6"&gt;teoretic6&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.xero.com/" rel="nofollow"&gt;Xero&lt;/a&gt; [&lt;a href="https://github.com/yan9yu"&gt;@yan9yu&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/adamantnz/"&gt;adamantnz&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.xoom.com/" rel="nofollow"&gt;Xoom&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.yahoo.com/" rel="nofollow"&gt;Yahoo!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.yieldr.com/" rel="nofollow"&gt;Yieldr&lt;/a&gt; [&lt;a href="https://github.com/ggeorgiadis"&gt;@ggeorgiadis&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zapier.com" rel="nofollow"&gt;Zapier&lt;/a&gt; [&lt;a href="https://github.com/drknexus"&gt;@drknexus&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/statwonk"&gt;@statwonk&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zego.com/" rel="nofollow"&gt;Zego&lt;/a&gt; [&lt;a href="https://github.com/ruimffl"&gt;@ruimffl&lt;/a&gt;, &lt;a href="https://github.com/james-welly"&gt;@james-welly&lt;/a&gt;, &lt;a href="https://github.com/ken-payne"&gt;@ken-payne&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.github.com/zendesk"&gt;Zendesk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zen.ly" rel="nofollow"&gt;Zenly&lt;/a&gt; [&lt;a href="https://github.com/cerisier"&gt;@cerisier&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/jbdalido"&gt;@jbdalido&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zymergen.com/" rel="nofollow"&gt;Zymergen&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zynga.com" rel="nofollow"&gt;Zynga&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-who-maintains-apache-airflow" class="anchor" aria-hidden="true" href="#who-maintains-apache-airflow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Who Maintains Apache Airflow?&lt;/h2&gt;
&lt;p&gt;Airflow is the work of the &lt;a href="https://github.com/apache/airflow/graphs/contributors"&gt;community&lt;/a&gt;,
but the &lt;a href="https://people.apache.org/committers-by-project.html#airflow" rel="nofollow"&gt;core committers/maintainers&lt;/a&gt;
are responsible for reviewing and merging PRs as well as steering conversation around new feature requests.
If you would like to become a maintainer, please review the Apache Airflow
&lt;a href="https://cwiki.apache.org/confluence/display/AIRFLOW/Committers" rel="nofollow"&gt;committer requirements&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-can-i-use-the-apache-airflow-logo-in-my-presentation" class="anchor" aria-hidden="true" href="#can-i-use-the-apache-airflow-logo-in-my-presentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Can I use the Apache Airflow logo in my presentation?&lt;/h2&gt;
&lt;p&gt;Yes! Be sure to abide by the Apache Foundation &lt;a href="https://www.apache.org/foundation/marks/#books" rel="nofollow"&gt;trademark policies&lt;/a&gt; and the Apache Airflow &lt;a href="https://cwiki.apache.org/confluence/display/AIRFLOW/Brandbook" rel="nofollow"&gt;Brandbook&lt;/a&gt;. The most up to date logos are found in &lt;a href="/docs/img/logos"&gt;this repo&lt;/a&gt; and on the Apache Software Foundation &lt;a href="https://www.apache.org/logos/about.html" rel="nofollow"&gt;website&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-links" class="anchor" aria-hidden="true" href="#links"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://airflow.apache.org/" rel="nofollow"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://apache-airflow-slack.herokuapp.com/" rel="nofollow"&gt;Chat&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Links" rel="nofollow"&gt;More&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>apache</author><guid isPermaLink="false">https://github.com/apache/airflow</guid><pubDate>Fri, 20 Dec 2019 00:18:00 GMT</pubDate></item><item><title>RomelTorres/alpha_vantage #19 in Python, This week</title><link>https://github.com/RomelTorres/alpha_vantage</link><description>&lt;p&gt;&lt;i&gt;A python wrapper for Alpha Vantage API for financial data.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-alpha_vantage" class="anchor" aria-hidden="true" href="#alpha_vantage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;alpha_vantage&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/RomelTorres/alpha_vantage" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/67bfa058f51d35e3e40f347c92ae9c03e01f216e/68747470733a2f2f7472617669732d63692e6f72672f526f6d656c546f727265732f616c7068615f76616e746167652e706e673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/RomelTorres/alpha_vantage.png?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://badge.fury.io/py/alpha-vantage" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d06b9957ccdff75c902fe56ff6f826bfa80ab567/68747470733a2f2f62616467652e667572792e696f2f70792f616c7068612d76616e746167652e737667" alt="PyPI version" data-canonical-src="https://badge.fury.io/py/alpha-vantage.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://alpha-vantage.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/70e4c2dc4bfb40284d422ac09f20aab73a946554/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f616c7068612d76616e746167652f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/alpha-vantage/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://isitmaintained.com/project/RomelTorres/alpha_vantage" title="Average time to resolve an issue" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2bf84db47b696851f82c7915ef16a22744458ed9/687474703a2f2f697369746d61696e7461696e65642e636f6d2f62616467652f7265736f6c7574696f6e2f526f6d656c546f727265732f616c7068615f76616e746167652e737667" alt="Average time to resolve an issue" data-canonical-src="http://isitmaintained.com/badge/resolution/RomelTorres/alpha_vantage.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://isitmaintained.com/project/RomelTorres/alpha_vantage" title="Percentage of issues still open" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/19aac18cbc7f43a8011709c42221c680580a7c74/687474703a2f2f697369746d61696e7461696e65642e636f6d2f62616467652f6f70656e2f526f6d656c546f727265732f616c7068615f76616e746167652e737667" alt="Percentage of issues still open" data-canonical-src="http://isitmaintained.com/badge/open/RomelTorres/alpha_vantage.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Python module to get stock data/cryptocurrencies from the Alpha Vantage API&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Alpha Vantage delivers a free API for real time financial data and most used finance indicators in a simple json or pandas format. This module implements a python interface to the free API provided by Alpha
Vantage (&lt;a href="http://www.alphavantage.co/" rel="nofollow"&gt;http://www.alphavantage.co/&lt;/a&gt;). It requires a free API key, that can be requested on &lt;a href="http://www.alphavantage.co/support/#api-key" rel="nofollow"&gt;http://www.alphavantage.co/support/#api-key&lt;/a&gt;. You can have a look at all the API calls available in their documentation &lt;a href="http://www.alphavantage.co/documentation" rel="nofollow"&gt;http://www.alphavantage.co/documentation&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-news" class="anchor" aria-hidden="true" href="#news"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;News&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;From version 1.9.0 onwards, the urllib was substituted by pythons request library that is thread safe. If you have any error, post an issue.&lt;/li&gt;
&lt;li&gt;From version 1.8.0 onwards, the column names of the data frames have changed, they are now exactly what alphavantage gives back in their json response. You can see the examples in better detail in the following git repo:  &lt;a href="https://github.com/RomelTorres/av_example"&gt;https://github.com/RomelTorres/av_example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;From version 1.6.0, pandas was taken out as a hard dependency.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-install" class="anchor" aria-hidden="true" href="#install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install&lt;/h2&gt;
&lt;p&gt;To install the package use:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install alpha_vantage&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or install with pandas support, simply install pandas too:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install alpha_vantage pandas&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you want to install from source, then use:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/RomelTorres/alpha_vantage.git
pip install -e alpha_vantage&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;p&gt;To get data from the API, simply import the library and call the object with your API key. Next, get ready for some awesome, free, realtime finance data. Your API key may also be stored in the environment variable &lt;code&gt;ALPHAVANTAGE_API_KEY&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; alpha_vantage.timeseries &lt;span class="pl-k"&gt;import&lt;/span&gt; TimeSeries
ts &lt;span class="pl-k"&gt;=&lt;/span&gt; TimeSeries(&lt;span class="pl-v"&gt;key&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YOUR_API_KEY&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Get json object with the intraday data and another with  the call's metadata&lt;/span&gt;
data, meta_data &lt;span class="pl-k"&gt;=&lt;/span&gt; ts.get_intraday(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;GOOGL&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Internally there is a retries counter, that can be used to minimize connection errors (in case that the API is not able to respond in time), the default is set to
5 but can be increased or decreased whenever needed.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;ts &lt;span class="pl-k"&gt;=&lt;/span&gt; TimeSeries(&lt;span class="pl-v"&gt;key&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YOUR_API_KEY&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-v"&gt;retries&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YOUR_RETRIES&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The library supports giving its results as json dictionaries (default), pandas dataframe (if installed) or csv, simply pass the parameter output_format='pandas' to change the format of the output for all the API calls in the given class. Please note that some API calls do not support the csv format (namely &lt;code&gt;ForeignExchange, SectorPerformances and TechIndicators&lt;/code&gt;) because the API endpoint does not support the format on their calls either.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;ts &lt;span class="pl-k"&gt;=&lt;/span&gt; TimeSeries(&lt;span class="pl-v"&gt;key&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YOUR_API_KEY&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-v"&gt;output_format&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pandas&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The pandas data frame given by the call, can have either a date string indexing or an integer indexing (by default the indexing is 'date'),
depending on your needs, you can use both.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt; &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; For the default date string index behavior&lt;/span&gt;
ts &lt;span class="pl-k"&gt;=&lt;/span&gt; TimeSeries(&lt;span class="pl-v"&gt;key&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YOUR_API_KEY&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-v"&gt;output_format&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pandas&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;indexing_type&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;date&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; For the default integer index behavior&lt;/span&gt;
ts &lt;span class="pl-k"&gt;=&lt;/span&gt; TimeSeries(&lt;span class="pl-v"&gt;key&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YOUR_API_KEY&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-v"&gt;output_format&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pandas&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;indexing_type&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;integer&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-data-frame-structure" class="anchor" aria-hidden="true" href="#data-frame-structure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data frame structure&lt;/h2&gt;
&lt;p&gt;The data frame structure is given by the call on alpha vantage rest API. The column names of the data frames
are the ones given by their data structure. For example, the following call:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; alpha_vantage.timeseries &lt;span class="pl-k"&gt;import&lt;/span&gt; TimeSeries
&lt;span class="pl-k"&gt;from&lt;/span&gt; pprint &lt;span class="pl-k"&gt;import&lt;/span&gt; pprint
ts &lt;span class="pl-k"&gt;=&lt;/span&gt; TimeSeries(&lt;span class="pl-v"&gt;key&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YOUR_API_KEY&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;output_format&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pandas&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
data, meta_data &lt;span class="pl-k"&gt;=&lt;/span&gt; ts.get_intraday(&lt;span class="pl-v"&gt;symbol&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;MSFT&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-v"&gt;interval&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;1min&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;outputsize&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;full&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
pprint(data.head(&lt;span class="pl-c1"&gt;2&lt;/span&gt;))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Would result on:
&lt;a target="_blank" rel="noopener noreferrer" href="images/docs_data_frame_header.png?raw=True"&gt;&lt;img src="images/docs_data_frame_header.png?raw=True" alt="alt text" title="Data Header format." style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The headers from the data are specified from Alpha Vantage (in previous versions, the numbers in the headers were removed, but long term is better to have the data exactly as Alpha Vantage produces it.)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-plotting" class="anchor" aria-hidden="true" href="#plotting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Plotting&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-time-series" class="anchor" aria-hidden="true" href="#time-series"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Time Series&lt;/h3&gt;
&lt;p&gt;Using pandas support we can plot the intra-minute value for 'MSFT' stock quite easily:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; alpha_vantage.timeseries &lt;span class="pl-k"&gt;import&lt;/span&gt; TimeSeries
&lt;span class="pl-k"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class="pl-k"&gt;as&lt;/span&gt; plt

ts &lt;span class="pl-k"&gt;=&lt;/span&gt; TimeSeries(&lt;span class="pl-v"&gt;key&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YOUR_API_KEY&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;output_format&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pandas&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
data, meta_data &lt;span class="pl-k"&gt;=&lt;/span&gt; ts.get_intraday(&lt;span class="pl-v"&gt;symbol&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;MSFT&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-v"&gt;interval&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;1min&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;outputsize&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;full&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
data[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;4. close&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;].plot()
plt.title(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Intraday Times Series for the MSFT stock (1 min)&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
plt.show()&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Giving us as output:
&lt;a target="_blank" rel="noopener noreferrer" href="images/docs_ts_msft_example.png?raw=True"&gt;&lt;img src="images/docs_ts_msft_example.png?raw=True" alt="alt text" title="MSFT minute value plot example" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-technical-indicators" class="anchor" aria-hidden="true" href="#technical-indicators"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Technical indicators&lt;/h3&gt;
&lt;p&gt;The same way we can get pandas to plot technical indicators like Bollinger Bands®&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; alpha_vantage.techindicators &lt;span class="pl-k"&gt;import&lt;/span&gt; TechIndicators
&lt;span class="pl-k"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class="pl-k"&gt;as&lt;/span&gt; plt

ti &lt;span class="pl-k"&gt;=&lt;/span&gt; TechIndicators(&lt;span class="pl-v"&gt;key&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YOUR_API_KEY&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;output_format&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pandas&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
data, meta_data &lt;span class="pl-k"&gt;=&lt;/span&gt; ti.get_bbands(&lt;span class="pl-v"&gt;symbol&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;MSFT&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;interval&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;60min&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;time_period&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;60&lt;/span&gt;)
data.plot()
plt.title(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;BBbands indicator for  MSFT stock (60 min)&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
plt.show()&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Giving us as output:
&lt;a target="_blank" rel="noopener noreferrer" href="images/docs_ti_msft_example.png?raw=True"&gt;&lt;img src="images/docs_ti_msft_example.png?raw=True" alt="alt text" title="MSFT minute value plot example" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-sector-performance" class="anchor" aria-hidden="true" href="#sector-performance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sector Performance&lt;/h3&gt;
&lt;p&gt;We can also plot sector performance just as easy:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; alpha_vantage.sectorperformance &lt;span class="pl-k"&gt;import&lt;/span&gt; SectorPerformances
&lt;span class="pl-k"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class="pl-k"&gt;as&lt;/span&gt; plt

sp &lt;span class="pl-k"&gt;=&lt;/span&gt; SectorPerformances(&lt;span class="pl-v"&gt;key&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YOUR_API_KEY&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;output_format&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pandas&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
data, meta_data &lt;span class="pl-k"&gt;=&lt;/span&gt; sp.get_sector()
data[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Rank A: Real-Time Performance&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;].plot(&lt;span class="pl-v"&gt;kind&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bar&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
plt.title(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Real Time Performance (%) per Sector&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
plt.tight_layout()
plt.grid()
plt.show()&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Giving us as output:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/docs_sp_rt_example.png?raw=True"&gt;&lt;img src="images/docs_sp_rt_example.png?raw=True" alt="alt text" title="Real Time Sector Performance" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-crypto-currencies" class="anchor" aria-hidden="true" href="#crypto-currencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Crypto currencies.&lt;/h3&gt;
&lt;p&gt;We can also plot crypto currencies prices like BTC:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; alpha_vantage.cryptocurrencies &lt;span class="pl-k"&gt;import&lt;/span&gt; CryptoCurrencies
&lt;span class="pl-k"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class="pl-k"&gt;as&lt;/span&gt; plt

cc &lt;span class="pl-k"&gt;=&lt;/span&gt; CryptoCurrencies(&lt;span class="pl-v"&gt;key&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YOUR_API_KEY&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;output_format&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pandas&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
data, meta_data &lt;span class="pl-k"&gt;=&lt;/span&gt; cc.get_digital_currency_daily(&lt;span class="pl-v"&gt;symbol&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;BTC&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;market&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;CNY&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
data[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;4b. close (USD)&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;].plot()
plt.tight_layout()
plt.title(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Daily close value for bitcoin (BTC)&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
plt.grid()
plt.show()&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Giving us as output:
&lt;a target="_blank" rel="noopener noreferrer" href="images/docs_cripto_btc.png?raw=True"&gt;&lt;img src="images/docs_cripto_btc.png?raw=True" alt="alt text" title="Crypto Currenci daily (BTC)" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-foreign-exchange-fx" class="anchor" aria-hidden="true" href="#foreign-exchange-fx"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Foreign Exchange (FX)&lt;/h3&gt;
&lt;p&gt;The foreign exchange is just metadata, thus only available as json format (using the 'csv' or 'pandas' format will raise an Error)&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; alpha_vantage.foreignexchange &lt;span class="pl-k"&gt;import&lt;/span&gt; ForeignExchange
&lt;span class="pl-k"&gt;from&lt;/span&gt; pprint &lt;span class="pl-k"&gt;import&lt;/span&gt; pprint
cc &lt;span class="pl-k"&gt;=&lt;/span&gt; ForeignExchange(&lt;span class="pl-v"&gt;key&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YOUR_API_KEY&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; There is no metadata in this call&lt;/span&gt;
data, _ &lt;span class="pl-k"&gt;=&lt;/span&gt; cc.get_currency_exchange_rate(&lt;span class="pl-v"&gt;from_currency&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;BTC&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-v"&gt;to_currency&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;USD&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
pprint(data)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Giving us as output:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
    '1. From_Currency Code': 'BTC',
    '2. From_Currency Name': 'Bitcoin',
    '3. To_Currency Code': 'USD',
    '4. To_Currency Name': 'United States Dollar',
    '5. Exchange Rate': '5566.80500105',
    '6. Last Refreshed': '2017-10-15 15:13:08',
    '7. Time Zone': 'UTC'
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;p&gt;I have added a repository with examples in a python notebook to better see the
usage of the library: &lt;a href="https://github.com/RomelTorres/av_example"&gt;https://github.com/RomelTorres/av_example&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tests" class="anchor" aria-hidden="true" href="#tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tests&lt;/h2&gt;
&lt;p&gt;In order to run the tests you have to first export your API key so that the test can use it to run, also the tests require pandas, mock and nose.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; API_KEY=YOUR_API_KEY
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; alpha_vantage
nosetests&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;The code documentation can be found at &lt;a href="https://alpha-vantage.readthedocs.io/en/latest/" rel="nofollow"&gt;https://alpha-vantage.readthedocs.io/en/latest/&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;Contributing is always welcome, since sometimes I am busy. Just contact me on how best you can contribute.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-todos" class="anchor" aria-hidden="true" href="#todos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TODOs:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The integration tests are not being run at the moment within travis, gotta fix them to run.&lt;/li&gt;
&lt;li&gt;Add test for csv calls as well.&lt;/li&gt;
&lt;li&gt;Add tests for incompatible parameter raise errors.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact:&lt;/h2&gt;
&lt;p&gt;You can reach the Alpha Vantage team on any of the following platforms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://alphavantage.herokuapp.com/" rel="nofollow"&gt;Slack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/alpha_vantage" rel="nofollow"&gt;Twitter: @alpha_vantage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Email: &lt;a href="mailto:support@alphavantage.co"&gt;support@alphavantage.co&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-star-if-you-like-it" class="anchor" aria-hidden="true" href="#star-if-you-like-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Star if you like it.&lt;/h2&gt;
&lt;p&gt;If you like or use this project, consider showing your support by starring it.&lt;/p&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="venezuela" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f1fb-1f1ea.png"&gt;🇻🇪&lt;/g-emoji&gt;-&lt;g-emoji class="g-emoji" alias="de" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f1e9-1f1ea.png"&gt;🇩🇪&lt;/g-emoji&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>RomelTorres</author><guid isPermaLink="false">https://github.com/RomelTorres/alpha_vantage</guid><pubDate>Fri, 20 Dec 2019 00:19:00 GMT</pubDate></item><item><title>toandaominh1997/EfficientDet.Pytorch #20 in Python, This week</title><link>https://github.com/toandaominh1997/EfficientDet.Pytorch</link><description>&lt;p&gt;&lt;i&gt;Implementation EfficientDet: Scalable and Efficient Object Detection in PyTorch&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-efficientdet-scalable-and-efficient-object-detection-in-pytorch" class="anchor" aria-hidden="true" href="#efficientdet-scalable-and-efficient-object-detection-in-pytorch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;EfficientDet: Scalable and Efficient Object Detection, in PyTorch&lt;/h1&gt;
&lt;p&gt;A &lt;a href="http://pytorch.org/" rel="nofollow"&gt;PyTorch&lt;/a&gt; implementation of &lt;a href="https://arxiv.org/abs/1911.09070" rel="nofollow"&gt;EfficientDet&lt;/a&gt; from the 2019 paper by Mingxing Tan Ruoming Pang Quoc V. Le
Google Research, Brain Team.  The official and original: comming soon.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/arch.png"&gt;&lt;img src="./docs/arch.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-fun-with-demo" class="anchor" aria-hidden="true" href="#fun-with-demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fun with Demo:&lt;/h1&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python demo.py --weight ./checkpoint_VOC_efficientdet-d1_97.pth --threshold 0.6 --iou_threshold 0.5 --cam --score&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="docs/pytoan.gif"&gt;&lt;img src="docs/pytoan.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#recent-update"&gt;Recent Update&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#benchmarking"&gt;Benchmarking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#datasets"&gt;Datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#training-efficientdet"&gt;Train&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#evaluation"&gt;Evaluate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#performance"&gt;Performance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#demo"&gt;Demo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#todo"&gt;Future Work&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#references"&gt;Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; 
 
 
 &lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-recent-update" class="anchor" aria-hidden="true" href="#recent-update"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Recent Update&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;[17/12/2019] Add Fast normalized fusion, Augmentation with Ratio, Change RetinaHead, Fix Support EfficientDet-D0-&amp;gt;D7&lt;/li&gt;
&lt;li&gt;[7/12/2019] Support EfficientDet-D0, EfficientDet-D1, EfficientDet-D2, EfficientDet-D3, EfficientDet-D4,... . Support change gradient accumulation steps, AdamW.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-benchmarking" class="anchor" aria-hidden="true" href="#benchmarking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Benchmarking&lt;/h2&gt;
&lt;p&gt;We benchmark our code thoroughly on three datasets: pascal voc and coco, using family efficientnet different network architectures: EfficientDet-D0-&amp;gt;7. Below are the results:&lt;/p&gt;
&lt;p&gt;1). PASCAL VOC 2007 (Train/Test: 07trainval/07test, scale=600, ROI Align)&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;model  &lt;/th&gt;
&lt;th&gt;#GPUs&lt;/th&gt;
&lt;th&gt;batch size&lt;/th&gt;
&lt;th&gt;lr      &lt;/th&gt;
&lt;th&gt;lr_decay&lt;/th&gt;
&lt;th&gt;max_epoch    &lt;/th&gt;
&lt;th&gt;time/epoch&lt;/th&gt;
&lt;th&gt;mem/GPU&lt;/th&gt;
&lt;th&gt;mAP&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://drive.google.com/open?id=1evKg_s2kTYG-AUeVvlq9cliEEHlJ9TQQ" rel="nofollow"&gt;EfficientDet-D1(with Weight)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;1e-4&lt;/td&gt;
&lt;td&gt;30  &lt;/td&gt;
&lt;td&gt;100  &lt;/td&gt;
&lt;td&gt;20.min&lt;/td&gt;
&lt;td&gt;20100 MB  &lt;/td&gt;
&lt;td&gt;updating&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Install &lt;a href="http://pytorch.org/" rel="nofollow"&gt;PyTorch&lt;/a&gt; by selecting your environment on the website and running the appropriate command.&lt;/li&gt;
&lt;li&gt;Clone this repository and install package &lt;a href="#prerequisites"&gt;prerequisites&lt;/a&gt; below.&lt;/li&gt;
&lt;li&gt;Then download the dataset by following the &lt;a href="#datasets"&gt;instructions&lt;/a&gt; below.&lt;/li&gt;
&lt;li&gt;Note: For training, we currently support &lt;a href="http://host.robots.ox.ac.uk/pascal/VOC/" rel="nofollow"&gt;VOC&lt;/a&gt; and &lt;a href="http://mscoco.org/" rel="nofollow"&gt;COCO&lt;/a&gt;, and aim to add &lt;a href="http://www.image-net.org/" rel="nofollow"&gt;ImageNet&lt;/a&gt; support soon.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Python 3.6+&lt;/li&gt;
&lt;li&gt;PyTorch 1.3+&lt;/li&gt;
&lt;li&gt;Torchvision 0.4.0+ (&lt;strong&gt;We need high version because Torchvision support nms now.&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;requirements.txt&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-datasets" class="anchor" aria-hidden="true" href="#datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Datasets&lt;/h2&gt;
&lt;p&gt;To make things easy, we provide bash scripts to handle the dataset downloads and setup for you.  We also provide simple dataset loaders that inherit &lt;code&gt;torch.utils.data.Dataset&lt;/code&gt;, making them fully compatible with the &lt;code&gt;torchvision.datasets&lt;/code&gt; &lt;a href="http://pytorch.org/docs/torchvision/datasets.html" rel="nofollow"&gt;API&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-voc-dataset" class="anchor" aria-hidden="true" href="#voc-dataset"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;VOC Dataset&lt;/h3&gt;
&lt;p&gt;PASCAL VOC: Visual Object Classes&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-download-voc2007--voc2012-trainval--test" class="anchor" aria-hidden="true" href="#download-voc2007--voc2012-trainval--test"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Download VOC2007 + VOC2012 trainval &amp;amp; test&lt;/h5&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; specify a directory for dataset to be downloaded into, else default is ~/data/&lt;/span&gt;
sh datasets/scripts/VOC2007.sh
sh datasets/scripts/VOC2012.sh&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-coco" class="anchor" aria-hidden="true" href="#coco"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;COCO&lt;/h3&gt;
&lt;p&gt;Microsoft COCO: Common Objects in Context&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-download-coco-2014" class="anchor" aria-hidden="true" href="#download-coco-2014"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Download COCO 2014&lt;/h5&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; specify a directory for dataset to be downloaded into, else default is ~/data/&lt;/span&gt;
sh datasets/scripts/COCO2014.sh&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Read dataset COCO will support soon.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-training-efficientdet" class="anchor" aria-hidden="true" href="#training-efficientdet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training EfficientDet&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;To train EfficientDet using the train script simply specify the parameters listed in &lt;code&gt;train.py&lt;/code&gt; as a flag or manually change them.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python train.py --network effcientdet-d0  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Example&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;With VOC Dataset:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python train.py --dataset VOC --dataset_root /root/data/VOCdevkit/ --network effcientdet-d0 --batch_size 32 &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Example&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;With COCO Dataset:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python train.py --dataset COCO --dataset_root /root/data/coco/ --network effcientdet-d0 --batch_size 32 &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Example&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-evaluation" class="anchor" aria-hidden="true" href="#evaluation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;To evaluate a trained network:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python eval.py&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-demo" class="anchor" aria-hidden="true" href="#demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Demo&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python demo.py --threshold 0.5 --iou_threshold 0.5 --score --weight checkpoint_VOC_efficientdet-d1_34.pth --file_name demo.png&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Output:&lt;/p&gt;
&lt;p align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="./docs/demo.png"&gt;&lt;img src="./docs/demo.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-webcam-demo" class="anchor" aria-hidden="true" href="#webcam-demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Webcam Demo&lt;/h2&gt;
&lt;p&gt;You can use a webcam in a real-time demo by running:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python demo.py --threshold 0.5 --iou_threshold 0.5 --cam --score --weight checkpoint_VOC_efficientdet-d1_34.pth&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-performance" class="anchor" aria-hidden="true" href="#performance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Performance&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/compare.png"&gt;&lt;img src="./docs/compare.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-todo" class="anchor" aria-hidden="true" href="#todo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TODO&lt;/h2&gt;
&lt;p&gt;We have accumulated the following to-do list, which we hope to complete in the near future&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Still to come:
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; EfficientDet-[D0-7]&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; GPU-Parallel&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; NMS&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Soft-NMS&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; Pretrained model&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; Demo&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Model zoo&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; TorchScript&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Mobile&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; C++ Onnx&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/toandaominh1997"&gt;&lt;strong&gt;Toan Dao Minh&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/em&gt; Unfortunately, this is just a hobby of ours and not a full-time job, so we'll do our best to keep things up to date, but no guarantees.  That being said, thanks to everyone for your continued help and feedback as it is really appreciated. We will try to address everything as soon as possible.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-references" class="anchor" aria-hidden="true" href="#references"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;tanmingxing, rpang, qvl, et al. "EfficientDet: Scalable and Efficient Object Detection." &lt;a href="https://arxiv.org/abs/1911.09070" rel="nofollow"&gt;EfficientDet&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;A list of other great EfficientDet ports that were sources of inspiration:
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/lukemelas/EfficientNet-PyTorch"&gt;EfficientNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/amdegroot/ssd.pytorch"&gt;SSD.Pytorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/open-mmlab/mmdetection"&gt;mmdetection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/yhenon/pytorch-retinanet"&gt;RetinaNet.Pytorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pytorch.org/docs/stable/torchvision/ops.html" rel="nofollow"&gt;NMS.Torchvision&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;@article{efficientdetpytoan,
    Author = {Toan Dao Minh},
    Title = {A Pytorch Implementation of EfficientDet Object Detection},
    Journal = {github.com/toandaominh1997/EfficientDet.Pytorch},
    Year = {2019}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>toandaominh1997</author><guid isPermaLink="false">https://github.com/toandaominh1997/EfficientDet.Pytorch</guid><pubDate>Fri, 20 Dec 2019 00:20:00 GMT</pubDate></item><item><title>facebookresearch/detectron2 #21 in Python, This week</title><link>https://github.com/facebookresearch/detectron2</link><description>&lt;p&gt;&lt;i&gt;Detectron2 is FAIR's next-generation research platform for object detection and segmentation.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/Detectron2-Logo-Horz.svg"&gt;&lt;img src=".github/Detectron2-Logo-Horz.svg" width="300" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Detectron2 is Facebook AI Research's next generation software system
that implements state-of-the-art object detection algorithms.
It is a ground-up rewrite of the previous version,
&lt;a href="https://github.com/facebookresearch/Detectron/"&gt;Detectron&lt;/a&gt;,
and it originates from &lt;a href="https://github.com/facebookresearch/maskrcnn-benchmark/"&gt;maskrcnn-benchmark&lt;/a&gt;.&lt;/p&gt;
&lt;div align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1381301/66535560-d3422200-eace-11e9-9123-5535d469db19.png"&gt;&lt;img src="https://user-images.githubusercontent.com/1381301/66535560-d3422200-eace-11e9-9123-5535d469db19.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-whats-new" class="anchor" aria-hidden="true" href="#whats-new"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What's New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;It is powered by the &lt;a href="https://pytorch.org" rel="nofollow"&gt;PyTorch&lt;/a&gt; deep learning framework.&lt;/li&gt;
&lt;li&gt;Includes more features such as panoptic segmentation, densepose, Cascade R-CNN, rotated bounding boxes, etc.&lt;/li&gt;
&lt;li&gt;Can be used as a library to support &lt;a href="projects/"&gt;different projects&lt;/a&gt; on top of it.
We'll open source more research projects in this way.&lt;/li&gt;
&lt;li&gt;It &lt;a href="https://detectron2.readthedocs.io/notes/benchmarks.html" rel="nofollow"&gt;trains much faster&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See our &lt;a href="https://ai.facebook.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/" rel="nofollow"&gt;blog post&lt;/a&gt;
to see more demos and learn about detectron2.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;See &lt;a href="INSTALL.md"&gt;INSTALL.md&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;
&lt;p&gt;See &lt;a href="GETTING_STARTED.md"&gt;GETTING_STARTED.md&lt;/a&gt;,
or the &lt;a href="https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5" rel="nofollow"&gt;Colab Notebook&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Learn more at our &lt;a href="https://detectron2.readthedocs.org" rel="nofollow"&gt;documentation&lt;/a&gt;.
And see &lt;a href="projects/"&gt;projects/&lt;/a&gt; for some projects that are built on top of detectron2.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-model-zoo-and-baselines" class="anchor" aria-hidden="true" href="#model-zoo-and-baselines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model Zoo and Baselines&lt;/h2&gt;
&lt;p&gt;We provide a large set of baseline results and trained models available for download in the &lt;a href="MODEL_ZOO.md"&gt;Detectron2 Model Zoo&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Detectron2 is released under the &lt;a href="LICENSE"&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citing-detectron" class="anchor" aria-hidden="true" href="#citing-detectron"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citing Detectron&lt;/h2&gt;
&lt;p&gt;If you use Detectron2 in your research or wish to refer to the baseline results published in the &lt;a href="MODEL_ZOO.md"&gt;Model Zoo&lt;/a&gt;, please use the following BibTeX entry.&lt;/p&gt;
&lt;div class="highlight highlight-text-bibtex"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;@misc&lt;/span&gt;{&lt;span class="pl-en"&gt;wu2019detectron2&lt;/span&gt;,
  &lt;span class="pl-s"&gt;author&lt;/span&gt; =       &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;{&lt;/span&gt;Yuxin Wu and Alexander Kirillov and Francisco Massa and&lt;/span&gt;
&lt;span class="pl-s"&gt;                  Wan-Yen Lo and Ross Girshick&lt;span class="pl-pds"&gt;}&lt;/span&gt;&lt;/span&gt;,
  &lt;span class="pl-s"&gt;title&lt;/span&gt; =        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;{&lt;/span&gt;Detectron2&lt;span class="pl-pds"&gt;}&lt;/span&gt;&lt;/span&gt;,
  &lt;span class="pl-s"&gt;howpublished&lt;/span&gt; = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;{&lt;/span&gt;\url{https://github.com/facebookresearch/detectron2}&lt;span class="pl-pds"&gt;}&lt;/span&gt;&lt;/span&gt;,
  &lt;span class="pl-s"&gt;year&lt;/span&gt; =         &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;{&lt;/span&gt;2019&lt;span class="pl-pds"&gt;}&lt;/span&gt;&lt;/span&gt;
}&lt;/pre&gt;&lt;/div&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>facebookresearch</author><guid isPermaLink="false">https://github.com/facebookresearch/detectron2</guid><pubDate>Fri, 20 Dec 2019 00:21:00 GMT</pubDate></item><item><title>zhaipro/easy12306 #22 in Python, This week</title><link>https://github.com/zhaipro/easy12306</link><description>&lt;p&gt;&lt;i&gt;使用机器学习算法完成对12306验证码的自动识别&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-easy12306" class="anchor" aria-hidden="true" href="#easy12306"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;easy12306&lt;/h1&gt;
&lt;p&gt;两个必要的数据集：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;文字识别，model.h5&lt;/li&gt;
&lt;li&gt;图片识别，12306.image.model.h5&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;识别器数据的下载地址：&lt;/p&gt;
&lt;p&gt;&lt;a href="https://pan.baidu.com/s/1OsBIBM4rl8EnpZt7VYiD9g" rel="nofollow"&gt;https://pan.baidu.com/s/1OsBIBM4rl8EnpZt7VYiD9g&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python3 main.py &amp;lt;img.jpg&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;我把设计思路写在维基中了：&lt;a href="https://github.com/zhaipro/easy12306/wiki"&gt;https://github.com/zhaipro/easy12306/wiki&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-如何" class="anchor" aria-hidden="true" href="#如何"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;如何？&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/8620842/51320752-d6f2cc00-1a9b-11e9-9d2d-7d1e25ddadc5.jpg"&gt;&lt;img src="https://user-images.githubusercontent.com/8620842/51320752-d6f2cc00-1a9b-11e9-9d2d-7d1e25ddadc5.jpg" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~$ python3 main.py 2.jpg 2&amp;gt; /dev/null
电子秤
风铃        # 要找的是以上两样东西
0 0 电子秤  # 第一行第一列就是电子秤
0 1 绿豆
0 2 蒸笼
0 3 蒸笼
1 0 风铃
1 1 电子秤
1 2 网球拍
1 3 网球拍
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;识别前所未见的图片&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/8620842/51799645-a01c7300-225e-11e9-8214-296773112484.jpg"&gt;&lt;img src="https://user-images.githubusercontent.com/8620842/51799645-a01c7300-225e-11e9-8214-296773112484.jpg" alt="8" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;具体的编号：&lt;a href="./texts.txt"&gt;texts.txt&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~$ python3 mlearn_for_image.py 8.jpg
[0.8991613]  # 可信度
[0]          # 0 表示的就是打字机
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-在线体验" class="anchor" aria-hidden="true" href="#在线体验"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;在线体验&lt;/h3&gt;
&lt;p&gt;识别验证码，暂不识别多标签。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://shell.teachx.cn:12306/" rel="nofollow"&gt;http://shell.teachx.cn:12306/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/8620842/51885312-e809da00-23c5-11e9-93a3-78d5e8b4ac18.png"&gt;&lt;img src="https://user-images.githubusercontent.com/8620842/51885312-e809da00-23c5-11e9-93a3-78d5e8b4ac18.png" alt="a" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;识别单个图片，可任意尺寸（总之由cv2简单的将其转为指定尺寸）。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://shell.teachx.cn:5000/" rel="nofollow"&gt;http://shell.teachx.cn:5000/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/8620842/51879603-21831b00-23af-11e9-8d16-9ae64866ca4c.jpg"&gt;&lt;img src="https://user-images.githubusercontent.com/8620842/51879603-21831b00-23af-11e9-8d16-9ae64866ca4c.jpg" alt="a" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>zhaipro</author><guid isPermaLink="false">https://github.com/zhaipro/easy12306</guid><pubDate>Fri, 20 Dec 2019 00:22:00 GMT</pubDate></item><item><title>NVlabs/few-shot-vid2vid #23 in Python, This week</title><link>https://github.com/NVlabs/few-shot-vid2vid</link><description>&lt;p&gt;&lt;i&gt;Pytorch implementation for few-shot photorealistic video-to-video translation.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="imgs/illustration.gif"&gt;&lt;img src="imgs/illustration.gif" align="right" width="200" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-few-shot-vid2vid" class="anchor" aria-hidden="true" href="#few-shot-vid2vid"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Few-shot vid2vid&lt;/h1&gt;
&lt;h3&gt;&lt;a id="user-content-project--youtube--arxiv" class="anchor" aria-hidden="true" href="#project--youtube--arxiv"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://nvlabs.github.io/few-shot-vid2vid/" rel="nofollow"&gt;Project&lt;/a&gt; | &lt;a href="https://youtu.be/8AZBuyEuDqc" rel="nofollow"&gt;YouTube&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/1910.12713" rel="nofollow"&gt;arXiv&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Pytorch implementation for few-shot photorealistic video-to-video translation. It can be used for generating human motions from poses, synthesizing people talking from edge maps, or turning semantic label maps into photo-realistic videos. The core of video-to-video translation is image-to-image translation. Some of our work in that space can be found in &lt;a href="https://github.com/NVIDIA/pix2pixHD"&gt;pix2pixHD&lt;/a&gt; and &lt;a href="https://github.com/NVlabs/SPADE"&gt;SPADE&lt;/a&gt;. &lt;br&gt;&lt;br&gt;
&lt;a href="https://nvlabs.github.io/few-shot-vid2vid/" rel="nofollow"&gt;Few-shot Video-to-Video Synthesis&lt;/a&gt;&lt;br&gt;
&lt;a href="https://tcwang0509.github.io/" rel="nofollow"&gt;Ting-Chun Wang&lt;/a&gt;, &lt;a href="http://mingyuliu.net/" rel="nofollow"&gt;Ming-Yu Liu&lt;/a&gt;, Andrew Tao, &lt;a href="https://liuguilin1225.github.io/" rel="nofollow"&gt;Guilin Liu&lt;/a&gt;, &lt;a href="http://jankautz.com/" rel="nofollow"&gt;Jan Kautz&lt;/a&gt;, &lt;a href="http://catanzaro.name/" rel="nofollow"&gt;Bryan Catanzaro&lt;/a&gt;&lt;br&gt;
NVIDIA Corporation&lt;br&gt;
In Neural Information Processing Systems (&lt;strong&gt;NeurIPS&lt;/strong&gt;) 2019&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-example-results" class="anchor" aria-hidden="true" href="#example-results"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Results&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Dance Videos&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="imgs/dance.gif"&gt;&lt;img src="imgs/dance.gif" width="400" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="imgs/statue.gif"&gt;&lt;img src="imgs/statue.gif" width="400" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Talking Head Videos&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="imgs/face.gif"&gt;&lt;img src="imgs/face.gif" width="400" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="imgs/mona_lisa.gif"&gt;&lt;img src="imgs/mona_lisa.gif" width="400" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Street View Videos&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="imgs/street.gif"&gt;&lt;img src="imgs/street.gif" width="400" style="max-width:100%;"&gt;&lt;/a&gt;  
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Linux or macOS&lt;/li&gt;
&lt;li&gt;Python 3&lt;/li&gt;
&lt;li&gt;NVIDIA GPU + CUDA cuDNN&lt;/li&gt;
&lt;li&gt;PyTorch 1.2&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Install python libraries &lt;a href="https://github.com/Knio/dominate"&gt;dominate&lt;/a&gt; and requests.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install dominate requests&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;If you plan to train with face datasets, please install dlib.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install dlib&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;If you plan to train with pose datasets, please install &lt;a href="https://github.com/facebookresearch/DensePose"&gt;DensePose&lt;/a&gt; and/or &lt;a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose"&gt;OpenPose&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Clone this repo:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/NVlabs/few-shot-vid2vid
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; few-shot-vid2vid&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-dataset" class="anchor" aria-hidden="true" href="#dataset"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dataset&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Pose
&lt;ul&gt;
&lt;li&gt;We use random dancing videos found on YouTube. We then apply DensePose / OpenPose to estimate the poses for each frame.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Face
&lt;ul&gt;
&lt;li&gt;We use the &lt;a href="http://niessnerlab.org/projects/roessler2018faceforensics.html" rel="nofollow"&gt;FaceForensics&lt;/a&gt; dataset. We then use landmark detection to estimate the face keypoints, and interpolate them to get face edges.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Street
&lt;ul&gt;
&lt;li&gt;We use a mix of sequences from different cities, which include Cityscapes &lt;a href="https://www.cityscapes-dataset.com/" rel="nofollow"&gt;official website&lt;/a&gt; and other cities found on YouTube.&lt;/li&gt;
&lt;li&gt;We apply a pre-trained segmentation algorithm to get the corresponding semantic maps.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Please add the obtained images to the &lt;code&gt;datasets&lt;/code&gt; folder in the same way the example images are provided.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-training" class="anchor" aria-hidden="true" href="#training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;First, compile a snapshot of &lt;a href="https://github.com/NVIDIA/flownet2-pytorch"&gt;FlowNet2&lt;/a&gt; by running &lt;code&gt;python scripts/download_flownet2.py&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Please first download example datasets by running &lt;code&gt;python scripts/download_datasets.py&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The following scripts are examples of using one GPU. For multi-GPU training, simply increase the batch sizes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-training-with-pose-datasets" class="anchor" aria-hidden="true" href="#training-with-pose-datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training with pose datasets&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Example DensePose and OpenPose results are included. If you plan to use your own dataset, please generate these results and put them in the same way the example dataset is provided.&lt;/li&gt;
&lt;li&gt;Run the example script (&lt;code&gt;bash ./scripts/pose/train_g1.sh&lt;/code&gt;)
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python train.py --name pose --dataset_mode fewshot_pose --adaptive_spade --warp_ref --spade_combine --remove_face_labels --add_face_D --niter_single 100 --niter 200 --batchSize 2&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;Please refer to &lt;a href="https://github.com/NVlabs/few-shot-vid2vid#more-trainingtest-details"&gt;More Training/Test Details&lt;/a&gt; for more explanations about training flags.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-training-with-face-datasets" class="anchor" aria-hidden="true" href="#training-with-face-datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training with face datasets&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the example script (&lt;code&gt;bash ./scripts/face/train_g1.sh&lt;/code&gt;)
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python train.py --name face --dataset_mode fewshot_face --adaptive_spade --warp_ref --spade_combine --batchSize 8&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-training-with-street-dataset" class="anchor" aria-hidden="true" href="#training-with-street-dataset"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training with street dataset&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the example script (&lt;code&gt;bash ./scripts/street/train_g1.sh&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python train.py --name street --dataset_mode fewshot_street --adaptive_spade --loadSize 512 --fineSize 512 --batchSize 6&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-training-with-your-own-dataset" class="anchor" aria-hidden="true" href="#training-with-your-own-dataset"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training with your own dataset&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;If your input is a label map, please generate label maps which are one-channel whose pixel values correspond to the object labels (i.e. 0,1,...,N-1, where N is the number of labels). This is because we need to generate one-hot vectors from the label maps. Please use &lt;code&gt;--label_nc N&lt;/code&gt; during both training and testing.&lt;/li&gt;
&lt;li&gt;If your input is not a label map, please specify &lt;code&gt;--input_nc N&lt;/code&gt; where N is the number of input channels (The default is 3 for RGB images).&lt;/li&gt;
&lt;li&gt;The default setting for preprocessing is &lt;code&gt;scale_width&lt;/code&gt;, which will scale the width of all training images to &lt;code&gt;opt.loadSize&lt;/code&gt; while keeping the aspect ratio. If you want a different setting, please change it by using the &lt;code&gt;--resize_or_crop&lt;/code&gt; option.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-testing" class="anchor" aria-hidden="true" href="#testing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Testing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;After training, you can run inference by using the following scripts. The test results will be saved in: &lt;code&gt;./results/&lt;/code&gt;. Due to privacy concerns, the pretrained models are not released.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Poses&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To test the trained model (&lt;code&gt;bash ./scripts/pose/test.sh&lt;/code&gt;):
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python test.py --name pose --dataset_mode fewshot_pose --adaptive_spade --warp_ref --spade_combine --remove_face_labels --finetune --seq_path [PATH_TO_SEQ] --ref_img_path [PATH_TO_REF_IMG]&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Faces&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To test the model (&lt;code&gt;bash ./scripts/face/test.sh&lt;/code&gt;):
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python test.py --name face --dataset_mode fewshot_face --adaptive_spade --warp_ref --spade_combine --seq_path [PATH_TO_SEQ] --ref_img_path [PATH_TO_REF_IMG]&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Street&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To test the model (&lt;code&gt;bash ./scripts/street/test.sh&lt;/code&gt;):
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python test.py --name street --dataset_mode fewshot_street --adaptive_spade --loadSize 512 --fineSize 512 --seq_path [PATH_TO_SEQ]--ref_img_path [PATH_TO_REF_IMG]&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-more-trainingtest-details" class="anchor" aria-hidden="true" href="#more-trainingtest-details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More Training/Test Details&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Difference of training methodology vs. vid2vid: instead of copying frames from one GPU to another, each GPU now handles separate batches. To fit into memory, the network only generates one frame at a time (n_frames_per_gpu = 1), and keep this frame fixed when generating the next frame in the sequence. We found this is usually sufficient to modify the current frame only, and is more efficient and easier to maintain.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Training schedule: after switching to using SPADE, the network now consists of two sub-networks: one for single image generation (the SPADE generator) and the flow estimation network. By default, the training will start with training the single frame generator only (i.e. n_frames_total = 1) for &lt;code&gt;niter_single&lt;/code&gt; epochs. After that, the network will start to train the flow network to generate videos, and temporal losses are introduced. Similar to vid2vid, we double the training sequence length for every &lt;code&gt;niter_step&lt;/code&gt; epochs after starting training videos.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Important flags regarding network arch:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;adaptive_spade&lt;/code&gt;: adaptively generate network weights for SPADE modules.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;no_adaptive_embed&lt;/code&gt;: do not dynamically generate weights for the label embedding network.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n_adaptive_layers&lt;/code&gt;: number of adaptive layers in the generator.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;warp_ref&lt;/code&gt;: add an additional flow network to warp the reference image to the current frame and combine with it.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;spade_combine&lt;/code&gt;: instead of linearly blending hallucinated and warped frames to generate the final frame, use warped frame as a guidance image in an additional SPADE module during the synthesis process.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Important flags regarding training:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;n_frames_G&lt;/code&gt;: the number of input frames to feed into the generator network; i.e., &lt;code&gt;n_frames_G - 1&lt;/code&gt; is the number of frames we look into the past.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n_frames_total&lt;/code&gt;: the total number of frames in a sequence we want to train with. We gradually increase this number during training.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;niter_single&lt;/code&gt;: the number of epochs we train the single frame generator before starting training videos.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;niter_step&lt;/code&gt;: for how many epochs do we double &lt;code&gt;n_frames_total&lt;/code&gt;. The default is 10.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;batchSize&lt;/code&gt;: the number of training batches. If it is not divisible by number of GPUs, the first GPU (which is usually more memory heavy) will do fewer batches.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For other flags, please see &lt;code&gt;options/train_options.py&lt;/code&gt; and &lt;code&gt;options/base_options.py&lt;/code&gt; for all the training flags; see &lt;code&gt;options/test_options.py&lt;/code&gt; and &lt;code&gt;options/base_options.py&lt;/code&gt; for all the test flags.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Additional flags for pose examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;remove_face_labels&lt;/code&gt;: remove densepose results for face, so the network can get more robust during inference on different subjects.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;basic_point_only&lt;/code&gt;: if specified, only use basic joint keypoints for OpenPose output, without using any hand or face keypoints.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;add_face_D&lt;/code&gt;: add an additional discriminator that only works on the face region.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;refine_face&lt;/code&gt;: add an additional network to refine the face region.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Additional flags for face examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;no_upper_face&lt;/code&gt;: by default, we add artificial edges for the upper part of face by symmetry. This flag disables it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you find this useful for your research, please cite the following paper.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@inproceedings{wang2019fewshotvid2vid,
   author    = {Ting-Chun Wang and Ming-Yu Liu and Andrew Tao 
                and Guilin Liu and Jan Kautz and Bryan Catanzaro},
   title     = {Few-shot Video-to-Video Synthesis},
   booktitle = {Conference on Neural Information Processing Systems (NeurIPS)},   
   year      = {2019},
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;We thank Karan Sapra for generating the segmentation maps for us.&lt;br&gt;
This code borrows heavily from &lt;a href="https://github.com/NVIDIA/pix2pixHD"&gt;pix2pixHD&lt;/a&gt; and &lt;a href="https://github.com/NVIDIA/vid2vid"&gt;vid2vid&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>NVlabs</author><guid isPermaLink="false">https://github.com/NVlabs/few-shot-vid2vid</guid><pubDate>Fri, 20 Dec 2019 00:23:00 GMT</pubDate></item><item><title>dbolya/yolact #24 in Python, This week</title><link>https://github.com/dbolya/yolact</link><description>&lt;p&gt;&lt;i&gt;A simple, fully convolutional model for real-time instance segmentation.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-you-only-look-at-coefficients" class="anchor" aria-hidden="true" href="#you-only-look-at-coefficients"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Y&lt;/strong&gt;ou &lt;strong&gt;O&lt;/strong&gt;nly &lt;strong&gt;L&lt;/strong&gt;ook &lt;strong&gt;A&lt;/strong&gt;t &lt;strong&gt;C&lt;/strong&gt;oefficien&lt;strong&gt;T&lt;/strong&gt;s&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;    ██╗   ██╗ ██████╗ ██╗      █████╗  ██████╗████████╗
    ╚██╗ ██╔╝██╔═══██╗██║     ██╔══██╗██╔════╝╚══██╔══╝
     ╚████╔╝ ██║   ██║██║     ███████║██║        ██║   
      ╚██╔╝  ██║   ██║██║     ██╔══██║██║        ██║   
       ██║   ╚██████╔╝███████╗██║  ██║╚██████╗   ██║   
       ╚═╝    ╚═════╝ ╚══════╝╚═╝  ╚═╝ ╚═════╝   ╚═╝ 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A simple, fully convolutional model for real-time instance segmentation. This is the code for our papers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1904.02689" rel="nofollow"&gt;YOLACT: Real-time Instance Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1912.06218" rel="nofollow"&gt;YOLACT++: Better Real-time Instance Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-yolact-v12-released-changelog" class="anchor" aria-hidden="true" href="#yolact-v12-released-changelog"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;YOLACT++ (v1.2) released! (&lt;a href="CHANGELOG.md"&gt;Changelog&lt;/a&gt;)&lt;/h4&gt;
&lt;p&gt;YOLACT++'s resnet50 model runs at 33.5 fps on a Titan Xp and achieves 34.1 mAP on COCO's &lt;code&gt;test-dev&lt;/code&gt; (check out our journal paper &lt;a href="https://arxiv.org/abs/1912.06218" rel="nofollow"&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In order to use YOLACT++, make sure you compile the DCNv2 code. (See &lt;a href="https://github.com/dbolya/yolact#installation"&gt;Installation&lt;/a&gt;)&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-for-a-real-time-demo-check-out-our-iccv-video" class="anchor" aria-hidden="true" href="#for-a-real-time-demo-check-out-our-iccv-video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;For a real-time demo, check out our ICCV video:&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=0pMfmo8qfpQ" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c9f0f1403e25276c0beea78732b5cec6c9b610ab/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f30704d666d6f38716670512f302e6a7067" alt="IMAGE ALT TEXT HERE" data-canonical-src="https://img.youtube.com/vi/0pMfmo8qfpQ/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Some examples from our YOLACT base model (33.5 fps on a Titan Xp and 29.8 mAP on COCO's &lt;code&gt;test-dev&lt;/code&gt;):&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="data/yolact_example_0.png"&gt;&lt;img src="data/yolact_example_0.png" alt="Example 0" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="data/yolact_example_1.png"&gt;&lt;img src="data/yolact_example_1.png" alt="Example 1" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="data/yolact_example_2.png"&gt;&lt;img src="data/yolact_example_2.png" alt="Example 2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Set up a Python3 environment.&lt;/li&gt;
&lt;li&gt;Install &lt;a href="http://pytorch.org/" rel="nofollow"&gt;Pytorch&lt;/a&gt; 1.0.1 (or higher) and TorchVision.&lt;/li&gt;
&lt;li&gt;Install some other packages:
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Cython needs to be installed before pycocotools&lt;/span&gt;
pip install cython
pip install opencv-python pillow pycocotools matplotlib &lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;Clone this repository and enter it:
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/dbolya/yolact.git
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; yolact&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;If you'd like to train YOLACT, download the COCO dataset and the 2014/2017 annotations. Note that this script will take a while and dump 21gb of files into &lt;code&gt;./data/coco&lt;/code&gt;.
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sh data/scripts/COCO.sh&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;If you'd like to evaluate YOLACT on &lt;code&gt;test-dev&lt;/code&gt;, download &lt;code&gt;test-dev&lt;/code&gt; with this script.
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sh data/scripts/COCO_test.sh&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;If you want to use YOLACT++, compile deformable convolutional layers (from &lt;a href="https://github.com/CharlesShang/DCNv2/tree/pytorch_1.0"&gt;DCNv2&lt;/a&gt;).
Make sure you have the latest CUDA toolkit installed from &lt;a href="https://developer.nvidia.com/cuda-toolkit" rel="nofollow"&gt;NVidia's Website&lt;/a&gt;.
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;cd&lt;/span&gt; external/DCNv2
python setup.py build develop&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-evaluation" class="anchor" aria-hidden="true" href="#evaluation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Evaluation&lt;/h1&gt;
&lt;p&gt;Here are our YOLACT models (released on April 5th, 2019) along with their FPS on a Titan Xp and mAP on &lt;code&gt;test-dev&lt;/code&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Image Size&lt;/th&gt;
&lt;th align="center"&gt;Backbone&lt;/th&gt;
&lt;th align="center"&gt;FPS&lt;/th&gt;
&lt;th align="center"&gt;mAP&lt;/th&gt;
&lt;th&gt;Weights&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;550&lt;/td&gt;
&lt;td align="center"&gt;Resnet50-FPN&lt;/td&gt;
&lt;td align="center"&gt;42.5&lt;/td&gt;
&lt;td align="center"&gt;28.2&lt;/td&gt;
&lt;td&gt;&lt;a href="https://drive.google.com/file/d/1yp7ZbbDwvMiFJEq4ptVKTYTI2VeRDXl0/view?usp=sharing" rel="nofollow"&gt;yolact_resnet50_54_800000.pth&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://ucdavis365-my.sharepoint.com/:u:/g/personal/yongjaelee_ucdavis_edu/EUVpxoSXaqNIlssoLKOEoCcB1m0RpzGq_Khp5n1VX3zcUw" rel="nofollow"&gt;Mirror&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;550&lt;/td&gt;
&lt;td align="center"&gt;Darknet53-FPN&lt;/td&gt;
&lt;td align="center"&gt;40.0&lt;/td&gt;
&lt;td align="center"&gt;28.7&lt;/td&gt;
&lt;td&gt;&lt;a href="https://drive.google.com/file/d/1dukLrTzZQEuhzitGkHaGjphlmRJOjVnP/view?usp=sharing" rel="nofollow"&gt;yolact_darknet53_54_800000.pth&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://ucdavis365-my.sharepoint.com/:u:/g/personal/yongjaelee_ucdavis_edu/ERrao26c8llJn25dIyZPhwMBxUp2GdZTKIMUQA3t0djHLw" rel="nofollow"&gt;Mirror&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;550&lt;/td&gt;
&lt;td align="center"&gt;Resnet101-FPN&lt;/td&gt;
&lt;td align="center"&gt;33.5&lt;/td&gt;
&lt;td align="center"&gt;29.8&lt;/td&gt;
&lt;td&gt;&lt;a href="https://drive.google.com/file/d/1UYy3dMapbH1BnmtZU4WH1zbYgOzzHHf_/view?usp=sharing" rel="nofollow"&gt;yolact_base_54_800000.pth&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://ucdavis365-my.sharepoint.com/:u:/g/personal/yongjaelee_ucdavis_edu/EYRWxBEoKU9DiblrWx2M89MBGFkVVB_drlRd_v5sdT3Hgg" rel="nofollow"&gt;Mirror&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;700&lt;/td&gt;
&lt;td align="center"&gt;Resnet101-FPN&lt;/td&gt;
&lt;td align="center"&gt;23.6&lt;/td&gt;
&lt;td align="center"&gt;31.2&lt;/td&gt;
&lt;td&gt;&lt;a href="https://drive.google.com/file/d/1lE4Lz5p25teiXV-6HdTiOJSnS7u7GBzg/view?usp=sharing" rel="nofollow"&gt;yolact_im700_54_800000.pth&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://ucdavis365-my.sharepoint.com/:u:/g/personal/yongjaelee_ucdavis_edu/Eagg5RSc5hFEhp7sPtvLNyoBjhlf2feog7t8OQzHKKphjw" rel="nofollow"&gt;Mirror&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;YOLACT++ models (released on December 16th, 2019):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Image Size&lt;/th&gt;
&lt;th align="center"&gt;Backbone&lt;/th&gt;
&lt;th align="center"&gt;FPS&lt;/th&gt;
&lt;th align="center"&gt;mAP&lt;/th&gt;
&lt;th&gt;Weights&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;550&lt;/td&gt;
&lt;td align="center"&gt;Resnet50-FPN&lt;/td&gt;
&lt;td align="center"&gt;33.5&lt;/td&gt;
&lt;td align="center"&gt;34.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://drive.google.com/file/d/1ZPu1YR2UzGHQD0o1rEqy-j5bmEm3lbyP/view?usp=sharing" rel="nofollow"&gt;yolact_plus_resnet50_54_800000.pth&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://ucdavis365-my.sharepoint.com/:u:/g/personal/yongjaelee_ucdavis_edu/EcJAtMiEFlhAnVsDf00yWRIBUC4m8iE9NEEiV05XwtEoGw" rel="nofollow"&gt;Mirror&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;550&lt;/td&gt;
&lt;td align="center"&gt;Resnet101-FPN&lt;/td&gt;
&lt;td align="center"&gt;27.3&lt;/td&gt;
&lt;td align="center"&gt;34.6&lt;/td&gt;
&lt;td&gt;&lt;a href="https://drive.google.com/file/d/15id0Qq5eqRbkD-N3ZjDZXdCvRyIaHpFB/view?usp=sharing" rel="nofollow"&gt;yolact_plus_base_54_800000.pth&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://ucdavis365-my.sharepoint.com/:u:/g/personal/yongjaelee_ucdavis_edu/EVQ62sF0SrJPrl_68onyHF8BpG7c05A8PavV4a849sZgEA" rel="nofollow"&gt;Mirror&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;To evalute the model, put the corresponding weights file in the &lt;code&gt;./weights&lt;/code&gt; directory and run one of the following commands. The name of each config is everything before the numbers in the file name (e.g., &lt;code&gt;yolact_base&lt;/code&gt; for &lt;code&gt;yolact_base_54_800000.pth&lt;/code&gt;).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-quantitative-results-on-coco" class="anchor" aria-hidden="true" href="#quantitative-results-on-coco"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quantitative Results on COCO&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Quantitatively evaluate a trained model on the entire validation set. Make sure you have COCO downloaded as above.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; This should get 29.92 validation mask mAP last time I checked.&lt;/span&gt;
python eval.py --trained_model=weights/yolact_base_54_800000.pth

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Output a COCOEval json to submit to the website or to use the run_coco_eval.py script.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; This command will create './results/bbox_detections.json' and './results/mask_detections.json' for detection and instance segmentation respectively.&lt;/span&gt;
python eval.py --trained_model=weights/yolact_base_54_800000.pth --output_coco_json

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; You can run COCOEval on the files created in the previous command. The performance should match my implementation in eval.py.&lt;/span&gt;
python run_coco_eval.py

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; To output a coco json file for test-dev, make sure you have test-dev downloaded from above and go&lt;/span&gt;
python eval.py --trained_model=weights/yolact_base_54_800000.pth --output_coco_json --dataset=coco2017_testdev_dataset&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-qualitative-results-on-coco" class="anchor" aria-hidden="true" href="#qualitative-results-on-coco"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Qualitative Results on COCO&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Display qualitative results on COCO. From here on I'll use a confidence threshold of 0.15.&lt;/span&gt;
python eval.py --trained_model=weights/yolact_base_54_800000.pth --score_threshold=0.15 --top_k=15 --display&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-benchmarking-on-coco" class="anchor" aria-hidden="true" href="#benchmarking-on-coco"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Benchmarking on COCO&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Run just the raw model on the first 1k images of the validation set&lt;/span&gt;
python eval.py --trained_model=weights/yolact_base_54_800000.pth --benchmark --max_images=1000&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-images" class="anchor" aria-hidden="true" href="#images"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Images&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Display qualitative results on the specified image.&lt;/span&gt;
python eval.py --trained_model=weights/yolact_base_54_800000.pth --score_threshold=0.15 --top_k=15 --image=my_image.png

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Process an image and save it to another file.&lt;/span&gt;
python eval.py --trained_model=weights/yolact_base_54_800000.pth --score_threshold=0.15 --top_k=15 --image=input_image.png:output_image.png

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Process a whole folder of images.&lt;/span&gt;
python eval.py --trained_model=weights/yolact_base_54_800000.pth --score_threshold=0.15 --top_k=15 --images=path/to/input/folder:path/to/output/folder&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-video" class="anchor" aria-hidden="true" href="#video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Video&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Display a video in real-time. "--video_multiframe" will process that many frames at once for improved performance.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; If you want, use "--display_fps" to draw the FPS directly on the frame.&lt;/span&gt;
python eval.py --trained_model=weights/yolact_base_54_800000.pth --score_threshold=0.15 --top_k=15 --video_multiframe=4 --video=my_video.mp4

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Display a webcam feed in real-time. If you have multiple webcams pass the index of the webcam you want instead of 0.&lt;/span&gt;
python eval.py --trained_model=weights/yolact_base_54_800000.pth --score_threshold=0.15 --top_k=15 --video_multiframe=4 --video=0

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Process a video and save it to another file. This uses the same pipeline as the ones above now, so it's fast!&lt;/span&gt;
python eval.py --trained_model=weights/yolact_base_54_800000.pth --score_threshold=0.15 --top_k=15 --video_multiframe=4 --video=input_video.mp4:output_video.mp4&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can tell, &lt;code&gt;eval.py&lt;/code&gt; can do a ton of stuff. Run the &lt;code&gt;--help&lt;/code&gt; command to see everything it can do.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python eval.py --help&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-training" class="anchor" aria-hidden="true" href="#training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training&lt;/h1&gt;
&lt;p&gt;By default, we train on COCO. Make sure to download the entire dataset using the commands above.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To train, grab an imagenet-pretrained model and put it in &lt;code&gt;./weights&lt;/code&gt;.
&lt;ul&gt;
&lt;li&gt;For Resnet101, download &lt;code&gt;resnet101_reducedfc.pth&lt;/code&gt; from &lt;a href="https://drive.google.com/file/d/1tvqFPd4bJtakOlmn-uIA492g2qurRChj/view?usp=sharing" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For Resnet50, download &lt;code&gt;resnet50-19c8e357.pth&lt;/code&gt; from &lt;a href="https://drive.google.com/file/d/1Jy3yCdbatgXa5YYIdTCRrSV0S9V5g1rn/view?usp=sharing" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For Darknet53, download &lt;code&gt;darknet53.pth&lt;/code&gt; from &lt;a href="https://drive.google.com/file/d/17Y431j4sagFpSReuPNoFcj9h7azDTZFf/view?usp=sharing" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Run one of the training commands below.
&lt;ul&gt;
&lt;li&gt;Note that you can press ctrl+c while training and it will save an &lt;code&gt;*_interrupt.pth&lt;/code&gt; file at the current iteration.&lt;/li&gt;
&lt;li&gt;All weights are saved in the &lt;code&gt;./weights&lt;/code&gt; directory by default with the file name &lt;code&gt;&amp;lt;config&amp;gt;_&amp;lt;epoch&amp;gt;_&amp;lt;iter&amp;gt;.pth&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Trains using the base config with a batch size of 8 (the default).&lt;/span&gt;
python train.py --config=yolact_base_config

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Trains yolact_base_config with a batch_size of 5. For the 550px models, 1 batch takes up around 1.5 gigs of VRAM, so specify accordingly.&lt;/span&gt;
python train.py --config=yolact_base_config --batch_size=5

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Resume training yolact_base with a specific weight file and start from the iteration specified in the weight file's name.&lt;/span&gt;
python train.py --config=yolact_base_config --resume=weights/yolact_base_10_32100.pth --start_iter=-1

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Use the help option to see a description of all available command line arguments&lt;/span&gt;
python train.py --help&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-multi-gpu-support" class="anchor" aria-hidden="true" href="#multi-gpu-support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Multi-GPU Support&lt;/h2&gt;
&lt;p&gt;YOLACT now supports multiple GPUs seamlessly during training:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Before running any of the scripts, run: &lt;code&gt;export CUDA_VISIBLE_DEVICES=[gpus]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Where you should replace [gpus] with a comma separated list of the index of each GPU you want to use (e.g., 0,1,2,3).&lt;/li&gt;
&lt;li&gt;You should still do this if only using 1 GPU.&lt;/li&gt;
&lt;li&gt;You can check the indices of your GPUs with &lt;code&gt;nvidia-smi&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Then, simply set the batch size to &lt;code&gt;8*num_gpus&lt;/code&gt; with the training commands above. The training script will automatically scale the hyperparameters to the right values.
&lt;ul&gt;
&lt;li&gt;If you have memory to spare you can increase the batch size further, but keep it a multiple of the number of GPUs you're using.&lt;/li&gt;
&lt;li&gt;If you want to allocate the images per GPU specific for different GPUs, you can use &lt;code&gt;--batch_alloc=[alloc]&lt;/code&gt; where [alloc] is a comma seprated list containing the number of images on each GPU. This must sum to &lt;code&gt;batch_size&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-logging" class="anchor" aria-hidden="true" href="#logging"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Logging&lt;/h2&gt;
&lt;p&gt;YOLACT now logs training and validation information by default. You can disable this with &lt;code&gt;--no_log&lt;/code&gt;. A guide on how to visualize these logs is coming soon, but now you can look at &lt;code&gt;LogVizualizer&lt;/code&gt; in &lt;code&gt;utils/logger.py&lt;/code&gt; for help.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pascal-sbd" class="anchor" aria-hidden="true" href="#pascal-sbd"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pascal SBD&lt;/h2&gt;
&lt;p&gt;We also include a config for training on Pascal SBD annotations (for rapid experimentation or comparing with other methods). To train on Pascal SBD, proceed with the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Download the dataset from &lt;a href="http://home.bharathh.info/pubs/codes/SBD/download.html" rel="nofollow"&gt;here&lt;/a&gt;. It's the first link in the top "Overview" section (and the file is called &lt;code&gt;benchmark.tgz&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Extract the dataset somewhere. In the dataset there should be a folder called &lt;code&gt;dataset/img&lt;/code&gt;. Create the directory &lt;code&gt;./data/sbd&lt;/code&gt; (where &lt;code&gt;.&lt;/code&gt; is YOLACT's root) and copy &lt;code&gt;dataset/img&lt;/code&gt; to &lt;code&gt;./data/sbd/img&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Download the COCO-style annotations from &lt;a href="https://drive.google.com/open?id=1ExrRSPVctHW8Nxrn0SofU1lVhK5Wn0_S" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Extract the annotations into &lt;code&gt;./data/sbd/&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Now you can train using &lt;code&gt;--config=yolact_resnet50_pascal_config&lt;/code&gt;. Check that config to see how to extend it to other models.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will automate this all with a script soon, don't worry. Also, if you want the script I used to convert the annotations, I put it in &lt;code&gt;./scripts/convert_sbd.py&lt;/code&gt;, but you'll have to check how it works to be able to use it because I don't actually remember at this point.&lt;/p&gt;
&lt;p&gt;If you want to verify our results, you can download our &lt;code&gt;yolact_resnet50_pascal_config&lt;/code&gt; weights from &lt;a href="https://drive.google.com/open?id=1yLVwtkRtNxyl0kxeMCtPXJsXFFyc_FHe" rel="nofollow"&gt;here&lt;/a&gt;. This model should get 72.3 mask AP_50 and 56.2 mask AP_70. Note that the "all" AP isn't the same as the "vol" AP reported in others papers for pascal (they use an averages of the thresholds from &lt;code&gt;0.1 - 0.9&lt;/code&gt; in increments of &lt;code&gt;0.1&lt;/code&gt; instead of what COCO uses).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-custom-datasets" class="anchor" aria-hidden="true" href="#custom-datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Custom Datasets&lt;/h2&gt;
&lt;p&gt;You can also train on your own dataset by following these steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a COCO-style Object Detection JSON annotation file for your dataset. The specification for this can be found &lt;a href="http://cocodataset.org/#format-data" rel="nofollow"&gt;here&lt;/a&gt;. Note that we don't use some fields, so the following may be omitted:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;info&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;liscense&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Under &lt;code&gt;image&lt;/code&gt;: &lt;code&gt;license, flickr_url, coco_url, date_captured&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (we use our own format for categories, see below)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Create a definition for your dataset under &lt;code&gt;dataset_base&lt;/code&gt; in &lt;code&gt;data/config.py&lt;/code&gt; (see the comments in &lt;code&gt;dataset_base&lt;/code&gt; for an explanation of each field):&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;my_custom_dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; dataset_base.copy({
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;name&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;My Dataset&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,

    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;train_images&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;path_to_training_images&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;train_info&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;:   &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;path_to_training_annotation&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,

    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;valid_images&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;path_to_validation_images&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;valid_info&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;:   &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;path_to_validation_annotation&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,

    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;has_gt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;True&lt;/span&gt;,
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;class_names&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: (&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;my_class_id_1&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;my_class_id_2&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;my_class_id_3&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;...&lt;/span&gt;)
})&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;A couple things to note:
&lt;ul&gt;
&lt;li&gt;Class IDs in the annotation file should start at 1 and increase sequentially on the order of &lt;code&gt;class_names&lt;/code&gt;. If this isn't the case for your annotation file (like in COCO), see the field &lt;code&gt;label_map&lt;/code&gt; in &lt;code&gt;dataset_base&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If you do not want to create a validation split, use the same image path and annotations file for validation. By default (see &lt;code&gt;python train.py --help&lt;/code&gt;), &lt;code&gt;train.py&lt;/code&gt; will output validation mAP for the first 5000 images in the dataset every 2 epochs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Finally, in &lt;code&gt;yolact_base_config&lt;/code&gt; in the same file, change the value for &lt;code&gt;'dataset'&lt;/code&gt; to &lt;code&gt;'my_custom_dataset'&lt;/code&gt; or whatever you named the config object above. Then you can use any of the training commands in the previous section.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-creating-a-custom-dataset-from-scratch" class="anchor" aria-hidden="true" href="#creating-a-custom-dataset-from-scratch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Creating a Custom Dataset from Scratch&lt;/h4&gt;
&lt;p&gt;See &lt;a href="https://github.com/dbolya/yolact/issues/70#issuecomment-504283008"&gt;this nice post by @Amit12690&lt;/a&gt; for tips on how to annotate a custom dataset and prepare it for use with YOLACT.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h1&gt;
&lt;p&gt;If you use YOLACT or this code base in your work, please cite&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@inproceedings{yolact-iccv2019,
  author    = {Daniel Bolya and Chong Zhou and Fanyi Xiao and Yong Jae Lee},
  title     = {YOLACT: {Real-time} Instance Segmentation},
  booktitle = {ICCV},
  year      = {2019},
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For YOLACT++, please cite&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@misc{yolact-plus-arxiv2019,
  title         = {YOLACT++: Better Real-time Instance Segmentation},
  author        = {Daniel Bolya and Chong Zhou and Fanyi Xiao and Yong Jae Lee},
  year          = {2019},
  eprint        = {1912.06218},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CV}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h1&gt;
&lt;p&gt;For questions about our paper or code, please contact &lt;a href="mailto:dbolya@ucdavis.edu"&gt;Daniel Bolya&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dbolya</author><guid isPermaLink="false">https://github.com/dbolya/yolact</guid><pubDate>Fri, 20 Dec 2019 00:24:00 GMT</pubDate></item><item><title>CharlesPikachu/Games #25 in Python, This week</title><link>https://github.com/CharlesPikachu/Games</link><description>&lt;p&gt;&lt;i&gt;Some games created by python code.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-games" class="anchor" aria-hidden="true" href="#games"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Games&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;Some games created by python code.
You can star this repository to keep track of the project if it's helpful for you, thank you for your support.
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;&lt;a id="user-content-statement" class="anchor" aria-hidden="true" href="#statement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Statement&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;Most of the game materals(including music, fonts and pictures) in this repository are collected from the web, copyright belongs to the original author.
This repository is created just for learning python(Commercial prohibition).
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Game1: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game1"&gt;Bunnies and Badgers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game2: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game2"&gt;Pikachu Go Go Go~~~&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game3: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game3"&gt;Puzzle pieces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game4: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game4"&gt;Skier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game5: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game5"&gt;Tank War&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game6: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game6"&gt;FlappyBird&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game7: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game7"&gt;T-Rex Rush&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game8: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game8"&gt;Tower Defense&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game9: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game9"&gt;Catch apples and coins&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game10: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game10"&gt;Aircraft war&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game11: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game11"&gt;Tetris&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game12: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game12"&gt;Sokoban&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game13: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game13"&gt;Alien Invasion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game14: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game14"&gt;Pacman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game15: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game15"&gt;GemGem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game16: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game16"&gt;24 point&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game17: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game17"&gt;Pingpong&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game18: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game18"&gt;Breakout clone&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game19: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game19"&gt;Bomber Man&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game20: &lt;a href="https://github.com/CharlesPikachu/Games/tree/master/Game20"&gt;Maze&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-record" class="anchor" aria-hidden="true" href="#record"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Record&lt;/h1&gt;
&lt;p&gt;see RECORD dir please → &lt;a href="./RECORD"&gt;click&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-more" class="anchor" aria-hidden="true" href="#more"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More&lt;/h1&gt;
&lt;h4&gt;&lt;a id="user-content-wechat-official-accounts" class="anchor" aria-hidden="true" href="#wechat-official-accounts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WeChat Official Accounts&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Charles_pikachu&lt;/em&gt;&lt;br&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="pikachu.jpg"&gt;&lt;img src="pikachu.jpg" alt="img" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>CharlesPikachu</author><guid isPermaLink="false">https://github.com/CharlesPikachu/Games</guid><pubDate>Fri, 20 Dec 2019 00:25:00 GMT</pubDate></item></channel></rss>