<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Python, This week</title><link>https://github.com/trending/python?since=weekly</link><description>The top repositories on GitHub for python, measured weekly</description><pubDate>Tue, 29 Oct 2019 03:38:10 GMT</pubDate><lastBuildDate>Tue, 29 Oct 2019 03:38:10 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>1400</ttl><item><title>google-research/google-research #1 in Python, This week</title><link>https://github.com/google-research/google-research</link><description>&lt;p&gt;&lt;i&gt;Google AI Research&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-google-ai-research" class="anchor" aria-hidden="true" href="#google-ai-research"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Google AI Research&lt;/h1&gt;
&lt;p&gt;This repository contains code released by
&lt;a href="https://ai.google/research" rel="nofollow"&gt;Google AI Research&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Disclaimer: This is not an official Google product.&lt;/em&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>google-research</author><guid isPermaLink="false">https://github.com/google-research/google-research</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>trailofbits/algo #2 in Python, This week</title><link>https://github.com/trailofbits/algo</link><description>&lt;p&gt;&lt;i&gt;Set up a personal VPN in the cloud&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-algo-vpn" class="anchor" aria-hidden="true" href="#algo-vpn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Algo VPN&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://gitter.im/trailofbits/algo?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0c0e33218aa937f681d5088b670c988adf804264/68747470733a2f2f6261646765732e6769747465722e696d2f747261696c6f66626974732f616c676f2e737667" alt="Join the chat at https://gitter.im/trailofbits/algo" data-canonical-src="https://badges.gitter.im/trailofbits/algo.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://twitter.com/AlgoVPN" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a67add962c4c0beeead2da6dd98552fbce611fdb/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f75726c2f68747470732f747769747465722e636f6d2f666f6c645f6c6566742e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f77253230253430416c676f56504e" alt="Twitter" data-canonical-src="https://img.shields.io/twitter/url/https/twitter.com/fold_left.svg?style=social&amp;amp;label=Follow%20%40AlgoVPN" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.org/trailofbits/algo" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/960c464446296d169c0887c1641336b26bc8672f/68747470733a2f2f6170692e7472617669732d63692e6f72672f747261696c6f66626974732f616c676f2e7376673f6272616e63683d6d6173746572" alt="TravisCI Status" data-canonical-src="https://api.travis-ci.org/trailofbits/algo.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Algo VPN is a set of Ansible scripts that simplify the setup of a personal Wireguard and IPSEC VPN. It uses the most secure defaults available, works with common cloud providers, and does not require client software on most devices. See our &lt;a href="https://blog.trailofbits.com/2016/12/12/meet-algo-the-vpn-that-works/" rel="nofollow"&gt;release announcement&lt;/a&gt; for more information.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Supports only IKEv2 with strong crypto (AES-GCM, SHA2, and P-256) and &lt;a href="https://www.wireguard.com/" rel="nofollow"&gt;WireGuard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Generates Apple profiles to auto-configure iOS and macOS devices&lt;/li&gt;
&lt;li&gt;Includes a helper script to add and remove users&lt;/li&gt;
&lt;li&gt;Blocks ads with a local DNS resolver (optional)&lt;/li&gt;
&lt;li&gt;Sets up limited SSH users for tunneling traffic (optional)&lt;/li&gt;
&lt;li&gt;Based on current versions of Ubuntu and strongSwan&lt;/li&gt;
&lt;li&gt;Installs to DigitalOcean, Amazon Lightsail, Amazon EC2, Vultr, Microsoft Azure, Google Compute Engine, Scaleway, OpenStack, CloudStack, Hetzner Cloud, or &lt;a href="docs/deploy-to-ubuntu.md"&gt;your own Ubuntu server&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-anti-features" class="anchor" aria-hidden="true" href="#anti-features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Anti-features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Does not support legacy cipher suites or protocols like L2TP, IKEv1, or RSA&lt;/li&gt;
&lt;li&gt;Does not install Tor, OpenVPN, or other risky servers&lt;/li&gt;
&lt;li&gt;Does not depend on the security of &lt;a href="https://tools.ietf.org/html/rfc7457" rel="nofollow"&gt;TLS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Does not require client software on most platforms&lt;/li&gt;
&lt;li&gt;Does not claim to provide anonymity or censorship avoidance&lt;/li&gt;
&lt;li&gt;Does not claim to protect you from the &lt;a href="https://en.wikipedia.org/wiki/Federal_Security_Service" rel="nofollow"&gt;FSB&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Ministry_of_State_Security_(China)" rel="nofollow"&gt;MSS&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Directorate-General_for_External_Security" rel="nofollow"&gt;DGSE&lt;/a&gt;, or &lt;a href="https://en.wikipedia.org/wiki/Flying_Spaghetti_Monster" rel="nofollow"&gt;FSM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-deploy-the-algo-server" class="anchor" aria-hidden="true" href="#deploy-the-algo-server"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deploy the Algo Server&lt;/h2&gt;
&lt;p&gt;The easiest way to get an Algo server running is to run it on your local system and let it set up a &lt;em&gt;new&lt;/em&gt; virtual machine in the cloud for you.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Setup an account on a cloud hosting provider.&lt;/strong&gt; Algo supports &lt;a href="https://m.do.co/c/4d7f4ff9cfe4" rel="nofollow"&gt;DigitalOcean&lt;/a&gt; (most user friendly), &lt;a href="https://aws.amazon.com/lightsail/" rel="nofollow"&gt;Amazon Lightsail&lt;/a&gt;, &lt;a href="https://aws.amazon.com/" rel="nofollow"&gt;Amazon EC2&lt;/a&gt;, &lt;a href="https://www.vultr.com/" rel="nofollow"&gt;Vultr&lt;/a&gt;, &lt;a href="https://azure.microsoft.com/" rel="nofollow"&gt;Microsoft Azure&lt;/a&gt;, &lt;a href="https://cloud.google.com/compute/" rel="nofollow"&gt;Google Compute Engine&lt;/a&gt;, &lt;a href="https://www.scaleway.com/" rel="nofollow"&gt;Scaleway&lt;/a&gt;, &lt;a href="https://www.dreamhost.com/cloud/computing/" rel="nofollow"&gt;DreamCompute&lt;/a&gt; or other OpenStack-based cloud hosting, &lt;a href="https://www.exoscale.com" rel="nofollow"&gt;Exoscale&lt;/a&gt; or other CloudStack-based cloud hosting,  or &lt;a href="https://www.hetzner.com/" rel="nofollow"&gt;Hetzner Cloud&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Get a copy of Algo.&lt;/strong&gt; The Algo scripts will be installed on your local system. There are two ways to get a copy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Download the &lt;a href="https://github.com/trailofbits/algo/archive/master.zip"&gt;ZIP file&lt;/a&gt;. Unzip the file to create a directory named &lt;code&gt;algo-master&lt;/code&gt; containing the Algo scripts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the command &lt;code&gt;git clone https://github.com/trailofbits/algo.git&lt;/code&gt; to create a directory named &lt;code&gt;algo&lt;/code&gt; containing the Algo scripts.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Install Algo's core dependencies.&lt;/strong&gt; Algo requires that &lt;strong&gt;Python 3&lt;/strong&gt; and at least one supporting package are installed on your system.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt; Apple does not provide Python 3 with macOS. There are two ways to obtain it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use the &lt;a href="https://brew.sh" rel="nofollow"&gt;Homebrew&lt;/a&gt; package manager. After installing Homebrew install Python 3 by running &lt;code&gt;brew install python3&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download and install the latest stable &lt;a href="https://www.python.org/downloads/mac-osx/" rel="nofollow"&gt;Python 3 package&lt;/a&gt;. Be sure to run the included &lt;em&gt;Install Certificates&lt;/em&gt; command from Finder.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once Python 3 is installed on your Mac, from Terminal run:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python3 -m pip install --upgrade virtualenv&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Linux:&lt;/strong&gt; Recent releases of Ubuntu, Debian, and Fedora come with Python 3 already installed. Make sure your system is up-to-date and install the supporting package(s):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu and Debian:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo apt install -y python3-virtualenv&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Fedora:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo dnf install -y python3-virtualenv&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Red Hat and CentOS 7 and later (for earlier versions see this &lt;a href="docs/deploy-from-redhat-centos6.md"&gt;documentation&lt;/a&gt;):&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo yum -y install epel-release
sudo yum install -y python36-virtualenv&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Windows:&lt;/strong&gt; Use the Windows Subsystem for Linux (WSL) to create your own copy of Ubuntu running under Windows from which to install and run Algo. See the &lt;a href="docs/deploy-from-windows.md"&gt;Windows documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Install Algo's remaining dependencies.&lt;/strong&gt; You'll need to run these commands from the Algo directory each time you download a new copy of Algo. In a Terminal window &lt;code&gt;cd&lt;/code&gt; into the &lt;code&gt;algo-master&lt;/code&gt; (ZIP file) or &lt;code&gt;algo&lt;/code&gt; (&lt;code&gt;git clone&lt;/code&gt;) directory and run:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python3 -m virtualenv --python=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;command -v python3&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; .env &lt;span class="pl-k"&gt;&amp;amp;&amp;amp;&lt;/span&gt;
  &lt;span class="pl-c1"&gt;source&lt;/span&gt; .env/bin/activate &lt;span class="pl-k"&gt;&amp;amp;&amp;amp;&lt;/span&gt;
  python3 -m pip install -U pip virtualenv &lt;span class="pl-k"&gt;&amp;amp;&amp;amp;&lt;/span&gt;
  python3 -m pip install -r requirements.txt&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On Fedora add the option &lt;code&gt;--system-site-packages&lt;/code&gt; to the first command above. On macOS install the C compiler if prompted.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;List the users to create.&lt;/strong&gt; Open the file &lt;code&gt;config.cfg&lt;/code&gt; in your favorite text editor. Specify the users you wish to create in the &lt;code&gt;users&lt;/code&gt; list. Create a unique user for each device you plan to connect to your VPN. If you want to be able to add or delete users later, you &lt;strong&gt;must&lt;/strong&gt; select &lt;code&gt;yes&lt;/code&gt; at the &lt;code&gt;Do you want to retain the keys (PKI)?&lt;/code&gt; prompt during the deployment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Start the deployment.&lt;/strong&gt; Return to your terminal. In the Algo directory, run &lt;code&gt;./algo&lt;/code&gt; and follow the instructions. There are several optional features available. None are required for a fully functional VPN server. These optional features are described in greater detail in &lt;a href="docs/deploy-from-ansible.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That's it! You will get the message below when the server deployment process completes. Take note of the p12 (user certificate) password and the CA key in case you need them later, &lt;strong&gt;they will only be displayed this time&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;You can now set up clients to connect to your VPN. Proceed to &lt;a href="#configure-the-vpn-clients"&gt;Configure the VPN Clients&lt;/a&gt; below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    "#                          Congratulations!                            #"
    "#                     Your Algo server is running.                     #"
    "#    Config files and certificates are in the ./configs/ directory.    #"
    "#              Go to https://whoer.net/ after connecting               #"
    "#        and ensure that all your traffic passes through the VPN.      #"
    "#                     Local DNS resolver 172.16.0.1                    #"
    "#        The p12 and SSH keys password for new users is XXXXXXXX       #"
    "#        The CA key password is XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX       #"
    "#      Shell access: ssh -i configs/algo.pem root@xxx.xxx.xx.xx        #"
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-configure-the-vpn-clients" class="anchor" aria-hidden="true" href="#configure-the-vpn-clients"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configure the VPN Clients&lt;/h2&gt;
&lt;p&gt;Certificates and configuration files that users will need are placed in the &lt;code&gt;configs&lt;/code&gt; directory. Make sure to secure these files since many contain private keys. All files are saved under a subdirectory named with the IP address of your new Algo VPN server.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-apple-devices" class="anchor" aria-hidden="true" href="#apple-devices"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Apple Devices&lt;/h3&gt;
&lt;p&gt;WireGuard is used to provide VPN services on Apple devices. Algo generates a WireGuard configuration file, &lt;code&gt;wireguard/&amp;lt;username&amp;gt;.conf&lt;/code&gt;, and a QR code, &lt;code&gt;wireguard/&amp;lt;username&amp;gt;.png&lt;/code&gt;, for each user defined in &lt;code&gt;config.cfg&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;On iOS, install the &lt;a href="https://itunes.apple.com/us/app/wireguard/id1441195209?mt=8" rel="nofollow"&gt;WireGuard&lt;/a&gt; app from the iOS App Store. Then, use the WireGuard app to scan the QR code or AirDrop the configuration file to the device.&lt;/p&gt;
&lt;p&gt;On macOS Mojave or later, install the &lt;a href="https://itunes.apple.com/us/app/wireguard/id1451685025?mt=12" rel="nofollow"&gt;WireGuard&lt;/a&gt; app from the Mac App Store. WireGuard will appear in the menu bar once you run the app. Click on the WireGuard icon, choose &lt;strong&gt;Import tunnel(s) from file...&lt;/strong&gt;, then select the appropriate WireGuard configuration file.&lt;/p&gt;
&lt;p&gt;On either iOS or macOS, you can enable "Connect on Demand" and/or exclude certain trusted Wi-Fi networks (such as your home or work) by editing the tunnel configuration in the WireGuard app. (Algo can't do this automatically for you.)&lt;/p&gt;
&lt;p&gt;Installing WireGuard is a little more complicated on older version of macOS. See &lt;a href="docs/client-macos-wireguard.md"&gt;Using macOS as a Client with WireGuard&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you prefer to use the built-in IPSEC VPN on Apple devices, or need "Connect on Demand" or excluded Wi-Fi networks automatically configured, then see &lt;a href="docs/client-apple-ipsec.md"&gt;Using Apple Devices as a Client with IPSEC&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-android-devices" class="anchor" aria-hidden="true" href="#android-devices"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Android Devices&lt;/h3&gt;
&lt;p&gt;WireGuard is used to provide VPN services on Android. Install the &lt;a href="https://play.google.com/store/apps/details?id=com.wireguard.android" rel="nofollow"&gt;WireGuard VPN Client&lt;/a&gt;. Import the corresponding &lt;code&gt;wireguard/&amp;lt;name&amp;gt;.conf&lt;/code&gt; file to your device, then setup a new connection with it. See the &lt;a href="/docs/client-android.md"&gt;Android setup instructions&lt;/a&gt; for more detailed walkthrough.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-windows" class="anchor" aria-hidden="true" href="#windows"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Windows&lt;/h3&gt;
&lt;p&gt;WireGuard is used to provide VPN services on Windows. Algo generates a WireGuard configuration file, &lt;code&gt;wireguard/&amp;lt;username&amp;gt;.conf&lt;/code&gt;, for each user defined in &lt;code&gt;config.cfg&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Install the &lt;a href="https://www.wireguard.com/install/#windows-7-8-81-10-2012-2016-2019" rel="nofollow"&gt;WireGuard VPN Client&lt;/a&gt;. Import the generated &lt;code&gt;wireguard/&amp;lt;username&amp;gt;.conf&lt;/code&gt; file to your device, then setup a new connection with it.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-linux-wireguard-clients" class="anchor" aria-hidden="true" href="#linux-wireguard-clients"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linux WireGuard Clients&lt;/h3&gt;
&lt;p&gt;WireGuard works great with Linux clients. See &lt;a href="docs/client-linux-wireguard.md"&gt;this page&lt;/a&gt; for an example of how to configure WireGuard on Ubuntu.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-linux-strongswan-ipsec-clients-eg-openwrt-ubuntu-server-etc" class="anchor" aria-hidden="true" href="#linux-strongswan-ipsec-clients-eg-openwrt-ubuntu-server-etc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linux strongSwan IPsec Clients (e.g., OpenWRT, Ubuntu Server, etc.)&lt;/h3&gt;
&lt;p&gt;Please see &lt;a href="docs/client-linux-ipsec.md"&gt;this page&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-other-devices" class="anchor" aria-hidden="true" href="#other-devices"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other Devices&lt;/h3&gt;
&lt;p&gt;Depending on the platform, you may need one or multiple of the following files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ipsec/manual/cacert.pem: CA Certificate&lt;/li&gt;
&lt;li&gt;ipsec/manual/.p12: User Certificate and Private Key (in PKCS#12 format)&lt;/li&gt;
&lt;li&gt;ipsec/manual/.conf: strongSwan client configuration&lt;/li&gt;
&lt;li&gt;ipsec/manual/.secrets: strongSwan client configuration&lt;/li&gt;
&lt;li&gt;ipsec/apple/.mobileconfig: Apple Profile&lt;/li&gt;
&lt;li&gt;wireguard/.conf: WireGuard configuration profile&lt;/li&gt;
&lt;li&gt;wireguard/.png: WireGuard configuration QR code&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-setup-an-ssh-tunnel" class="anchor" aria-hidden="true" href="#setup-an-ssh-tunnel"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup an SSH Tunnel&lt;/h2&gt;
&lt;p&gt;If you turned on the optional SSH tunneling role, then local user accounts will be created for each user in &lt;code&gt;config.cfg&lt;/code&gt; and SSH authorized_key files for them will be in the &lt;code&gt;configs&lt;/code&gt; directory (user.ssh.pem). SSH user accounts do not have shell access, cannot authenticate with a password, and only have limited tunneling options (e.g., &lt;code&gt;ssh -N&lt;/code&gt; is required). This ensures that SSH users have the least access required to setup a tunnel and can perform no other actions on the Algo server.&lt;/p&gt;
&lt;p&gt;Use the example command below to start an SSH tunnel by replacing &lt;code&gt;user&lt;/code&gt; and &lt;code&gt;ip&lt;/code&gt; with your own. Once the tunnel is setup, you can configure a browser or other application to use 127.0.0.1:1080 as a SOCKS proxy to route traffic through the Algo server.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ssh -D 127.0.0.1:1080 -f -q -C -N user@ip -i configs/&amp;lt;server_ip&amp;gt;/ssh-tunnel/&amp;lt;user&amp;gt;.pem&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ssh-into-algo-server" class="anchor" aria-hidden="true" href="#ssh-into-algo-server"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SSH into Algo Server&lt;/h2&gt;
&lt;p&gt;Your Algo server is configured for key-only SSH access for administrative purposes. Open the Terminal app, &lt;code&gt;cd&lt;/code&gt; into the &lt;code&gt;algo-master&lt;/code&gt; directory where you originally downloaded Algo, and then use the command listed on the success message:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ssh -i configs/algo.pem user@ip&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;where &lt;code&gt;user&lt;/code&gt; is either &lt;code&gt;root&lt;/code&gt; or &lt;code&gt;ubuntu&lt;/code&gt; as listed on the success message, and &lt;code&gt;ip&lt;/code&gt; is the IP address of your Algo server. If you find yourself regularly logging into the server then it will be useful to load your Algo ssh key automatically. Add the following snippet to the bottom of &lt;code&gt;~/.bash_profile&lt;/code&gt; to add it to your shell environment permanently.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ssh-add ~/.ssh/algo &amp;gt; /dev/null 2&amp;gt;&amp;amp;1&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-adding-or-removing-users" class="anchor" aria-hidden="true" href="#adding-or-removing-users"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Adding or Removing Users&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;If you chose to save the CA key during the deploy process,&lt;/em&gt; then Algo's own scripts can easily add and remove users from the VPN server.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Update the &lt;code&gt;users&lt;/code&gt; list in your &lt;code&gt;config.cfg&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Open a terminal, &lt;code&gt;cd&lt;/code&gt; to the algo directory, and activate the virtual environment with &lt;code&gt;source .env/bin/activate&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Run the command: &lt;code&gt;./algo update-users&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After this process completes, the Algo VPN server will contain only the users listed in the &lt;code&gt;config.cfg&lt;/code&gt; file.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-additional-documentation" class="anchor" aria-hidden="true" href="#additional-documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Additional Documentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/index.md"&gt;Deployment instructions, cloud provider setup instructions, and further client setup instructions available here.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/faq.md"&gt;FAQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/troubleshooting.md"&gt;Troubleshooting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you read all the documentation and have further questions, &lt;a href="https://gitter.im/trailofbits/algo" rel="nofollow"&gt;join the chat on Gitter&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-endorsements" class="anchor" aria-hidden="true" href="#endorsements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Endorsements&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;I've been ranting about the sorry state of VPN svcs for so long, probably about
time to give a proper talk on the subject. TL;DR: use Algo.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;-- &lt;a href="https://twitter.com/kennwhite/status/814166603587788800" rel="nofollow"&gt;Kenn White&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Before picking a VPN provider/app, make sure you do some research
&lt;a href="https://research.csiro.au/ng/wp-content/uploads/sites/106/2016/08/paper-1.pdf" rel="nofollow"&gt;https://research.csiro.au/ng/wp-content/uploads/sites/106/2016/08/paper-1.pdf&lt;/a&gt; ... – or consider Algo&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;-- &lt;a href="https://twitter.com/TheRegister/status/825076303657177088" rel="nofollow"&gt;The Register&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Algo is really easy and secure.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;-- &lt;a href="https://twitter.com/thegrugq/status/786249040228786176" rel="nofollow"&gt;the grugq&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I played around with Algo VPN, a set of scripts that let you set up a VPN in the cloud in very little time, even if you don’t know much about development. I’ve got to say that I was quite impressed with Trail of Bits’ approach.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;-- &lt;a href="https://twitter.com/romaindillet/status/851037243728965632" rel="nofollow"&gt;Romain Dillet&lt;/a&gt; for &lt;a href="https://techcrunch.com/2017/04/09/how-i-made-my-own-vpn-server-in-15-minutes/" rel="nofollow"&gt;TechCrunch&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you’re uncomfortable shelling out the cash to an anonymous, random VPN provider, this is the best solution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;-- &lt;a href="https://twitter.com/kingthor" rel="nofollow"&gt;Thorin Klosowski&lt;/a&gt; for &lt;a href="http://lifehacker.com/how-to-set-up-your-own-completely-free-vpn-in-the-cloud-1794302432" rel="nofollow"&gt;Lifehacker&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-support-algo-vpn" class="anchor" aria-hidden="true" href="#support-algo-vpn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support Algo VPN&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://flattr.com/submit/auto?fid=kxw60j&amp;amp;url=https%3A%2F%2Fgithub.com%2Ftrailofbits%2Falgo" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6b27c2d051d09e13f4009938f0b67aedd4ffd280/68747470733a2f2f627574746f6e2e666c617474722e636f6d2f666c617474722d62616467652d6c617267652e706e67" alt="Flattr" data-canonical-src="https://button.flattr.com/flattr-badge-large.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=CYZZD39GXUJ3E" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e14c85b542e06215f7e56c0763333ef1e9b9f9b7/68747470733a2f2f7777772e70617970616c6f626a656374732e636f6d2f656e5f55532f692f62746e2f62746e5f646f6e6174655f534d2e676966" alt="PayPal" data-canonical-src="https://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.patreon.com/algovpn" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/bf653361a158f7645497bf9490a97b697ec18f41/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6261636b5f6f6e2d70617472656f6e2d7265642e737667" alt="Patreon" data-canonical-src="https://img.shields.io/badge/back_on-patreon-red.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.bountysource.com/teams/trailofbits" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/79be76c663eb96142ff6f8d38ec10443107ffe97/68747470733a2f2f696d672e736869656c64732e696f2f626f756e7479736f757263652f7465616d2f747261696c6f66626974732f61637469766974792e737667" alt="Bountysource" data-canonical-src="https://img.shields.io/bountysource/team/trailofbits/activity.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All donations support continued development. Thanks!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We accept donations via &lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=CYZZD39GXUJ3E" rel="nofollow"&gt;PayPal&lt;/a&gt;, &lt;a href="https://www.patreon.com/algovpn" rel="nofollow"&gt;Patreon&lt;/a&gt;, and &lt;a href="https://flattr.com/submit/auto?fid=kxw60j&amp;amp;url=https%3A%2F%2Fgithub.com%2Ftrailofbits%2Falgo" rel="nofollow"&gt;Flattr&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Use our &lt;a href="https://m.do.co/c/4d7f4ff9cfe4" rel="nofollow"&gt;referral code&lt;/a&gt; when you sign up to Digital Ocean for a $10 credit.&lt;/li&gt;
&lt;li&gt;We also accept and appreciate contributions of new code and bugfixes via Github Pull Requests.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Algo is licensed and distributed under the AGPLv3. If you want to distribute a closed-source modification or service based on Algo, then please consider &lt;a href="mailto:opensource@trailofbits.com"&gt;purchasing an exception&lt;/a&gt; . As with the methods above, this will help support continued development.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>trailofbits</author><guid isPermaLink="false">https://github.com/trailofbits/algo</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>evilsocket/pwnagotchi #3 in Python, This week</title><link>https://github.com/evilsocket/pwnagotchi</link><description>&lt;p&gt;&lt;i&gt;(⌐■_■) - Deep Reinforcement Learning instrumenting bettercap for WiFi pwning.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pwnagotchi" class="anchor" aria-hidden="true" href="#pwnagotchi"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pwnagotchi&lt;/h1&gt;
&lt;p align="center"&gt;
  &lt;/p&gt;&lt;p align="center"&gt;
    &lt;a href="https://github.com/evilsocket/pwnagotchi/releases/latest"&gt;&lt;img alt="Release" src="https://camo.githubusercontent.com/9ae707a55ead5a1e951d8504ebc47fe6f2259198/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f6576696c736f636b65742f70776e61676f746368692e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/github/release/evilsocket/pwnagotchi.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://github.com/evilsocket/pwnagotchi/blob/master/LICENSE.md"&gt;&lt;img alt="Software License" src="https://camo.githubusercontent.com/268d96c6dd81f1fff98b19675ef5867412a2a223/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d47504c332d627269676874677265656e2e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/badge/license-GPL3-brightgreen.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://github.com/evilsocket/pwnagotchi/graphs/contributors"&gt;&lt;img alt="Contributors" src="https://camo.githubusercontent.com/929754fc02f162895d1d3ac191ff93d5f0deefb2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6e7472696275746f72732f6576696c736f636b65742f70776e61676f74636869" data-canonical-src="https://img.shields.io/github/contributors/evilsocket/pwnagotchi" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://travis-ci.org/evilsocket/pwnagotchi" rel="nofollow"&gt;&lt;img alt="Travis" src="https://camo.githubusercontent.com/bb71ac99b3141520709ab3799968d900a4e7d193/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f6576696c736f636b65742f70776e61676f746368692f6d61737465722e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/travis/evilsocket/pwnagotchi/master.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://pwnagotchi.herokuapp.com/" rel="nofollow"&gt;&lt;img alt="Slack" src="https://camo.githubusercontent.com/41e1c12ae01495bfa5d5fd35c1e7060bf886ac25/68747470733a2f2f70776e61676f746368692e6865726f6b756170702e636f6d2f62616467652e737667" data-canonical-src="https://pwnagotchi.herokuapp.com/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://twitter.com/intent/follow?screen_name=pwnagotchi" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/342b3854fb5df1b53672e419d06fbd99da5a4eb6/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f70776e61676f746368693f7374796c653d736f6369616c266c6f676f3d74776974746572" alt="follow on Twitter" data-canonical-src="https://img.shields.io/twitter/follow/pwnagotchi?style=social&amp;amp;logo=twitter" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://pwnagotchi.ai/" rel="nofollow"&gt;Pwnagotchi&lt;/a&gt; is an &lt;a href="https://hackernoon.com/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752" rel="nofollow"&gt;A2C&lt;/a&gt;-based "AI" leveraging &lt;a href="https://www.bettercap.org/" rel="nofollow"&gt;bettercap&lt;/a&gt; that learns from its surrounding WiFi environment to maximize the crackable WPA key material it captures (either passively, or by performing authentication and association attacks). This material is collected as PCAP files containing any form of handshake supported by &lt;a href="https://hashcat.net/hashcat/" rel="nofollow"&gt;hashcat&lt;/a&gt;, including &lt;a href="https://www.evilsocket.net/2019/02/13/Pwning-WiFi-networks-with-bettercap-and-the-PMKID-client-less-attack/" rel="nofollow"&gt;PMKIDs&lt;/a&gt;,
full and half WPA handshakes.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e8bbbda8fbeb4da294be75c896026fc777c1a199/68747470733a2f2f692e696d6775722e636f6d2f5836384758726e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e8bbbda8fbeb4da294be75c896026fc777c1a199/68747470733a2f2f692e696d6775722e636f6d2f5836384758726e2e706e67" alt="ui" data-canonical-src="https://i.imgur.com/X68GXrn.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Instead of merely playing &lt;a href="https://becominghuman.ai/getting-mario-back-into-the-gym-setting-up-super-mario-bros-in-openais-gym-8e39a96c1e41?gi=c4b66c3d5ced" rel="nofollow"&gt;Super Mario or Atari games&lt;/a&gt; like most reinforcement learning-based "AI" &lt;em&gt;(yawn)&lt;/em&gt;, Pwnagotchi tunes &lt;a href="https://github.com/evilsocket/pwnagotchi/blob/master/pwnagotchi/defaults.yml#L73"&gt;its parameters&lt;/a&gt; over time to &lt;strong&gt;get better at pwning WiFi things to&lt;/strong&gt; in the environments you expose it to.&lt;/p&gt;
&lt;p&gt;More specifically, Pwnagotchi is using an &lt;a href="https://stable-baselines.readthedocs.io/en/master/modules/policies.html#stable_baselines.common.policies.MlpLstmPolicy" rel="nofollow"&gt;LSTM with MLP feature extractor&lt;/a&gt; as its policy network for the &lt;a href="https://stable-baselines.readthedocs.io/en/master/modules/a2c.html" rel="nofollow"&gt;A2C agent&lt;/a&gt;. If you're unfamiliar with A2C, here is &lt;a href="https://hackernoon.com/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752" rel="nofollow"&gt;a very good introductory explanation&lt;/a&gt; (in comic form!) of the basic principles behind how Pwnagotchi learns. (You can read more about how Pwnagotchi learns in the &lt;a href="https://www.pwnagotchi.ai/usage/#training-the-ai" rel="nofollow"&gt;Usage&lt;/a&gt; doc.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Keep in mind:&lt;/strong&gt; Unlike the usual RL simulations, Pwnagotchi learns over time. Time for a Pwnagotchi is measured in epochs; a single epoch can last from a few seconds to minutes, depending on how many access points and client stations are visible. Do not expect your Pwnagotchi to perform amazingly well at the very beginning, as it will be &lt;a href="https://hackernoon.com/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752" rel="nofollow"&gt;exploring&lt;/a&gt; several combinations of &lt;a href="https://www.pwnagotchi.ai/usage/#training-the-ai" rel="nofollow"&gt;key parameters&lt;/a&gt; to determine ideal adjustments for pwning the particular environment you are exposing it to during its beginning epochs ... but ** listen to your Pwnagotchi when it tells you it's boring!** Bring it into novel WiFi environments with you and have it observe new networks and capture new handshakes—and you'll see. :)&lt;/p&gt;
&lt;p&gt;Multiple units within close physical proximity can "talk" to each other, advertising their presence to each other by broadcasting custom information elements using a parasite protocol I've built on top of the existing dot11 standard. Over time, two or more units trained together will learn to cooperate upon detecting each other's presence by dividing the available channels among them for optimal pwnage.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.pwnagotchi.ai" rel="nofollow"&gt;https://www.pwnagotchi.ai&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-links" class="anchor" aria-hidden="true" href="#links"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Links&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt; &lt;/th&gt;
&lt;th&gt;Official Links&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Slack&lt;/td&gt;
&lt;td&gt;&lt;a href="https://pwnagotchi.herokuapp.com" rel="nofollow"&gt;pwnagotchi.slack.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Twitter&lt;/td&gt;
&lt;td&gt;&lt;a href="https://twitter.com/pwnagotchi" rel="nofollow"&gt;@pwnagotchi&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Subreddit&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.reddit.com/r/pwnagotchi/" rel="nofollow"&gt;r/pwnagotchi&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Website&lt;/td&gt;
&lt;td&gt;&lt;a href="https://pwnagotchi.ai/" rel="nofollow"&gt;pwnagotchi.ai&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;pwnagotchi&lt;/code&gt; is made with ♥  by &lt;a href="https://twitter.com/evilsocket" rel="nofollow"&gt;@evilsocket&lt;/a&gt; and the &lt;a href="https://github.com/evilsocket/pwnagotchi/graphs/contributors"&gt;amazing dev team&lt;/a&gt;. It is released under the GPL3 license.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>evilsocket</author><guid isPermaLink="false">https://github.com/evilsocket/pwnagotchi</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>apachecn/AiLearning #4 in Python, This week</title><link>https://github.com/apachecn/AiLearning</link><description>&lt;p&gt;&lt;i&gt;AiLearning: 机器学习 - MachineLearning - ML、深度学习 - DeepLearning - DL、自然语言处理 NLP&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
    &lt;a href="https://www.apachecn.org" rel="nofollow"&gt;
        &lt;img width="200" src="https://camo.githubusercontent.com/9d35c24a9d070c56093b5598ef22afae12a2f45b/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f6c6f676f2e6a7067" data-canonical-src="http://data.apachecn.org/img/logo.jpg" style="max-width:100%;"&gt;
    &lt;/a&gt;
    &lt;br&gt;
    &lt;a href="https://www.apachecn.org/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/63fa00e49cf2df161cf6022c501b145d225bc335/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2533452d484f4d452d677265656e2e737667" data-canonical-src="https://img.shields.io/badge/%3E-HOME-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="http://home.apachecn.org/about/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/971440c5a29c84e984688b2ebe165dc27aa8cf61/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2533452d41424f55542d677265656e2e737667" data-canonical-src="https://img.shields.io/badge/%3E-ABOUT-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="mailto:apache@163.com"&gt;&lt;img src="https://camo.githubusercontent.com/f1fab6e562c98b86b95a7c44eae041e04022ec3e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2533452d456d61696c2d677265656e2e737667" data-canonical-src="https://img.shields.io/badge/%3E-Email-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h1 align="center"&gt;&lt;a id="user-content-ai-learning" class="anchor" aria-hidden="true" href="#ai-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/apachecn/AiLearning"&gt;AI learning&lt;/a&gt;&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-组织介绍" class="anchor" aria-hidden="true" href="#组织介绍"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;组织介绍&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;合作or侵权，请联系: &lt;code&gt;apachecn@163.com&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;我们不是 Apache 的官方组织/机构/团体，只是 Apache 技术栈（以及 AI）的爱好者！&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ApacheCN - 学习机器学习群【629470233】&lt;a href="//shang.qq.com/wpa/qunwpa?idkey=30e5f1123a79867570f665aa3a483ca404b1c3f77737bc01ec520ed5f078ddef" rel="nofollow"&gt;&lt;img border="0" src="https://camo.githubusercontent.com/6ef3c468024fa0a3ac83d0084d8d0847c6f57769/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f6c6f676f2f417061636865434e2d67726f75702e706e67" alt="ApacheCN - 学习机器学习群[629470233]" title="ApacheCN - 学习机器学习群[629470233]" data-canonical-src="http://data.apachecn.org/img/logo/ApacheCN-group.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;欢迎任何人参与和完善：一个人可以走的很快，但是一群人却可以走的更远&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;&lt;a id="user-content-路线图" class="anchor" aria-hidden="true" href="#路线图"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;路线图&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;入门只看: 步骤 1 =&amp;gt; 2 =&amp;gt; 3，你可以当大牛！&lt;/li&gt;
&lt;li&gt;中级补充 - 资料库: &lt;a href="https://github.com/apachecn/ai-roadmap"&gt;https://github.com/apachecn/ai-roadmap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-1机器学习---基础" class="anchor" aria-hidden="true" href="#1机器学习---基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.机器学习 - 基础&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-基本介绍" class="anchor" aria-hidden="true" href="#基本介绍"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;基本介绍&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;资料来源: Machine Learning in Action(机器学习实战-个人笔记)&lt;/li&gt;
&lt;li&gt;统一数据地址: &lt;a href="https://github.com/apachecn/data"&gt;https://github.com/apachecn/data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;书籍下载地址: &lt;a href="https://github.com/apachecn/data/tree/master/book"&gt;https://github.com/apachecn/data/tree/master/book&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;机器学习下载地址: &lt;a href="https://github.com/apachecn/data/tree/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"&gt;https://github.com/apachecn/data/tree/master/机器学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;深度学习数据地址: &lt;a href="https://github.com/apachecn/data/tree/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;https://github.com/apachecn/data/tree/master/深度学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;推荐系统数据地址: &lt;a href="https://github.com/apachecn/data/tree/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"&gt;https://github.com/apachecn/data/tree/master/推荐系统&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;视频网站：优酷 ／bilibili / Acfun / 网易云课堂，可直接在线播放。（最下方有相应链接）&lt;/li&gt;
&lt;li&gt;-- 推荐 &lt;a href="https://github.com/RedstoneWill"&gt;红色石头&lt;/a&gt;: &lt;a href="https://github.com/apachecn/ntu-hsuantienlin-ml"&gt;台湾大学林轩田机器学习笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;-- 推荐 &lt;a href="https://feisky.xyz/machine-learning" rel="nofollow"&gt;机器学习笔记&lt;/a&gt;: &lt;a href="https://feisky.xyz/machine-learning" rel="nofollow"&gt;https://feisky.xyz/machine-learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-学习文档" class="anchor" aria-hidden="true" href="#学习文档"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;学习文档&lt;/h3&gt;
&lt;table&gt;
  &lt;tbody&gt;&lt;tr&gt;
    &lt;th&gt;模块&lt;/th&gt;
    &lt;th&gt;章节&lt;/th&gt;
    &lt;th&gt;类型&lt;/th&gt;
    &lt;th&gt;负责人(GitHub)&lt;/th&gt;
    &lt;th&gt;QQ&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/1.机器学习基础.md"&gt; 第 1 章: 机器学习基础&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;介绍&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/ElmaDavies"&gt;@毛红动&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;1306014226&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/2.k-近邻算法.md"&gt;第 2 章: KNN 近邻算法&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;分类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/youyj521"&gt;@尤永江&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;279393323&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/3.决策树.md"&gt;第 3 章: 决策树&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;分类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/jingwangfei"&gt;@景涛&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;844300439&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/4.朴素贝叶斯.md"&gt;第 4 章: 朴素贝叶斯&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;分类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/wnma3mz"&gt;@wnma3mz&lt;/a&gt;&lt;br&gt;&lt;a href="https://github.com/kailian"&gt;@分析&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;1003324213&lt;br&gt;244970749&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/5.Logistic回归.md"&gt;第 5 章: Logistic回归&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;分类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/DataMonk2017"&gt;@微光同尘&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;529925688&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/6.支持向量机.md"&gt;第 6 章: SVM 支持向量机&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;分类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/VPrincekin"&gt;@王德红&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;934969547&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;网上组合内容&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/7.集成方法-随机森林和AdaBoost.md"&gt;第 7 章: 集成方法（随机森林和 AdaBoost）&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;分类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/jiangzhonglian"&gt;@片刻&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;529815144&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/8.回归.md"&gt;第 8 章: 回归&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;回归&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/DataMonk2017"&gt;@微光同尘&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;529925688&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/9.树回归.md"&gt;第 9 章: 树回归&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;回归&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/DataMonk2017"&gt;@微光同尘&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;529925688&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/10.k-means聚类.md"&gt;第 10 章: K-Means 聚类&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;聚类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/xuzhaoqing"&gt;@徐昭清&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;827106588&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/11.使用Apriori算法进行关联分析.md"&gt;第 11 章: 利用 Apriori 算法进行关联分析&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;频繁项集&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/WindZQ"&gt;@刘海飞&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;1049498972&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/12.使用FP-growth算法来高效发现频繁项集.md"&gt;第 12 章: FP-growth 高效发现频繁项集&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;频繁项集&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/mikechengwei"&gt;@程威&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;842725815&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/13.利用PCA来简化数据.md"&gt;第 13 章: 利用 PCA 来简化数据&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;工具&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/lljuan330"&gt;@廖立娟&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;835670618&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/14.利用SVD简化数据.md"&gt;第 14 章: 利用 SVD 来简化数据&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;工具&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/marsjhao"&gt;@张俊皓&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;714974242&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/15.大数据与MapReduce.md"&gt;第 15 章: 大数据与 MapReduce&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;工具&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/wnma3mz"&gt;@wnma3mz&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;1003324213&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Ml项目实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/16.推荐系统.md"&gt;第 16 章: 推荐系统（已迁移）&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;项目&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/apachecn/RecommenderSystems"&gt;推荐系统（迁移后地址）&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;第一期的总结&lt;/td&gt;
    &lt;td&gt;&lt;a href="report/2017-04-08_第一期的总结.md"&gt;2017-04-08: 第一期的总结&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;总结&lt;/td&gt;
    &lt;td&gt;总结&lt;/td&gt;
    &lt;td&gt;529815144&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-网站视频" class="anchor" aria-hidden="true" href="#网站视频"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;网站视频&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://www.zhihu.com/question/20691338/answer/248678328" rel="nofollow"&gt;知乎问答-爆炸啦-机器学习该怎么入门？&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当然我知道，第一句就会被吐槽，因为科班出身的人，不屑的吐了一口唾沫，说傻X，还评论 Andrew Ng 的视频。。&lt;/p&gt;
&lt;p&gt;我还知道还有一部分人，看 Andrew Ng 的视频就是看不懂，那神秘的数学推导，那迷之微笑的英文版的教学，我何尝又不是这样走过来的？？ 我的心可能比你们都痛，因为我在网上收藏过上10部《机器学习》相关视频，外加国内本土风格的教程：7月+小象 等等，我都很难去听懂，直到有一天，被一个百度的高级算法分析师推荐说：《机器学习实战》还不错，通俗易懂，你去试试？？&lt;/p&gt;
&lt;p&gt;我试了试，还好我的Python基础和调试能力还不错，基本上代码都调试过一遍，很多高大上的 "理论+推导"，在我眼中变成了几个 "加减乘除+循环"，我想这不就是像我这样的程序员想要的入门教程么？&lt;/p&gt;
&lt;p&gt;很多程序员说机器学习 TM 太难学了，是的，真 TM 难学，我想最难的是：没有一本像《机器学习实战》那样的作者愿意以程序员 Coding 角度去给大家讲解！！&lt;/p&gt;
&lt;p&gt;最近几天，GitHub 涨了 300颗 star，加群的200人， 现在还在不断的增加++，我想大家可能都是感同身受吧！&lt;/p&gt;
&lt;p&gt;很多想入门新手就是被忽悠着收藏收藏再收藏，但是最后还是什么都没有学到，也就是"资源收藏家"，也许新手要的就是 &lt;a href="https://docs.apachecn.org/map" rel="nofollow"&gt;MachineLearning(机器学习) 学习路线图&lt;/a&gt;。没错，我可以给你们的一份，因为我们还通过视频记录下来我们的学习过程。水平当然也有限，不过对于新手入门，绝对没问题，如果你还不会，那算我输！！&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;视频怎么看？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/4aeb51811bbc73e4715ced3ebc64ab26670bdc67/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f4d61696e506167652f417061636865434e2d4d4c2d62696c6962696c692d636f6d706172652e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/4aeb51811bbc73e4715ced3ebc64ab26670bdc67/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f4d61696e506167652f417061636865434e2d4d4c2d62696c6962696c692d636f6d706172652e6a7067" alt="" data-canonical-src="http://data.apachecn.org/img/AiLearning/MainPage/ApacheCN-ML-bilibili-compare.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;理论科班出身-建议去学习 Andrew Ng 的视频（Ng 的视频绝对是权威，这个毋庸置疑）&lt;/li&gt;
&lt;li&gt;编码能力强 - 建议看我们的&lt;a href="https://space.bilibili.com/97678687/#!/channel/detail?cid=22486" rel="nofollow"&gt;《机器学习实战-教学版》&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;编码能力弱 - 建议看我们的&lt;a href="https://space.bilibili.com/97678687/#!/channel/detail?cid=13045" rel="nofollow"&gt;《机器学习实战-讨论版》&lt;/a&gt;，不过在看理论的时候，看 教学版-理论部分；讨论版的废话太多，不过在讲解代码的时候是一行一行讲解的；所以，根据自己的需求，自由的组合。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;【免费】数学教学视频 - 可汗学院 入门篇&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=""&gt;@于振梓&lt;/a&gt; 推荐: 可汗学院-网易公开课&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;概率&lt;/th&gt;
&lt;th&gt;统计&lt;/th&gt;
&lt;th&gt;线性代数&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://open.163.com/special/Khan/probability.html" rel="nofollow"&gt;可汗学院(概率)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://open.163.com/special/Khan/khstatistics.html" rel="nofollow"&gt;可汗学院(统计学)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://open.163.com/special/Khan/linearalgebra.html" rel="nofollow"&gt;可汗学院(线性代数)&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;机器学习视频 - ApacheCN 教学版&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;AcFun&lt;/td&gt;
&lt;td&gt;B站&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a title="AcFun（机器学习视频）" href="http://www.acfun.cn/u/12540256.aspx#page=1" rel="nofollow"&gt;&lt;img width="290" src="https://camo.githubusercontent.com/122aa82278121b78486f6cc20b3813851832d1b0/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f4d61696e506167652f417061636865434e2d4d4c2d416346756e2e6a7067" data-canonical-src="http://data.apachecn.org/img/AiLearning/MainPage/ApacheCN-ML-AcFun.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a title="bilibili（机器学习视频）" href="https://space.bilibili.com/97678687/#!/channel/index" rel="nofollow"&gt;&lt;img width="290" src="https://camo.githubusercontent.com/c04107f0478a7e3e15b5103004d534af8ec36afd/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f4d61696e506167652f417061636865434e2d4d4c2d62696c6962696c692e6a7067" data-canonical-src="http://data.apachecn.org/img/AiLearning/MainPage/ApacheCN-ML-bilibili.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;优酷&lt;/td&gt;
&lt;td&gt;网易云课堂&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a title="YouKu（机器学习视频）" href="http://i.youku.com/apachecn" rel="nofollow"&gt;&lt;img width="290" src="https://camo.githubusercontent.com/ff306cb8a0eac3f6a9a59f01e73b538b0be8588e/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f4d61696e506167652f417061636865434d2d4d4c2d796f756b752e6a7067" data-canonical-src="http://data.apachecn.org/img/AiLearning/MainPage/ApacheCM-ML-youku.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a title="WangYiYunKeTang（机器学习视频）" href="http://study.163.com/course/courseMain.htm?courseId=1004582003" rel="nofollow"&gt;&lt;img width="290" src="https://camo.githubusercontent.com/615d94638b0fefc25253ca5a4147a5153e35379f/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f4d61696e506167652f417061636865434d2d4d4c2d57616e67596959756e4b6554616e672e706e67" data-canonical-src="http://data.apachecn.org/img/AiLearning/MainPage/ApacheCM-ML-WangYiYunKeTang.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;【免费】机器/深度学习视频 - 吴恩达&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;机器学习&lt;/th&gt;
&lt;th&gt;深度学习&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://study.163.com/course/courseMain.htm?courseId=1004570029" rel="nofollow"&gt;吴恩达机器学习&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://mooc.study.163.com/course/2001281002?tid=2001392029" rel="nofollow"&gt;神经网络和深度学习&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-2深度学习" class="anchor" aria-hidden="true" href="#2深度学习"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2.深度学习&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-入门基础" class="anchor" aria-hidden="true" href="#入门基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;入门基础&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="/docs/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92.md"&gt;反向传递&lt;/a&gt;: &lt;a href="https://www.cnblogs.com/charlotte77/p/5629865.html" rel="nofollow"&gt;https://www.cnblogs.com/charlotte77/p/5629865.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/docs/dl/CNN%E5%8E%9F%E7%90%86.md"&gt;CNN原理&lt;/a&gt;: &lt;a href="http://www.cnblogs.com/charlotte77/p/7759802.html" rel="nofollow"&gt;http://www.cnblogs.com/charlotte77/p/7759802.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/docs/dl/RNN%E5%8E%9F%E7%90%86.md"&gt;RNN原理&lt;/a&gt;: &lt;a href="https://blog.csdn.net/qq_39422642/article/details/78676567" rel="nofollow"&gt;https://blog.csdn.net/qq_39422642/article/details/78676567&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/docs/dl/LSTM%E5%8E%9F%E7%90%86.md"&gt;LSTM原理&lt;/a&gt;: &lt;a href="https://blog.csdn.net/weixin_42111770/article/details/80900575" rel="nofollow"&gt;https://blog.csdn.net/weixin_42111770/article/details/80900575&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-pytorch---教程" class="anchor" aria-hidden="true" href="#pytorch---教程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pytorch - 教程&lt;/h3&gt;
&lt;p&gt;-- 待更新&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-tensorflow-20---教程" class="anchor" aria-hidden="true" href="#tensorflow-20---教程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow 2.0 - 教程&lt;/h3&gt;
&lt;p&gt;-- 待更新&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;目录结构:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/TensorFlow2.x/%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97.md"&gt;安装指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/TensorFlow2.x/Keras%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8.md"&gt;Kears 快速入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/TensorFlow2.x/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE_1_%E7%94%B5%E5%BD%B1%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB.md"&gt;实战项目 1 电影情感分类&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/TensorFlow2.x/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE_2_%E6%B1%BD%E8%BD%A6%E7%87%83%E6%B2%B9%E6%95%88%E7%8E%87.md"&gt;实战项目 2 汽车燃油效率&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/TensorFlow2.x/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE%E4%BC%98%E5%8C%96_%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88.md"&gt;实战项目 优化: 过拟合，欠拟合&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-3自然语言处理" class="anchor" aria-hidden="true" href="#3自然语言处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3.自然语言处理&lt;/h2&gt;
&lt;p&gt;学习过程中-内心复杂的变化！！！&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;自从学习&lt;span class="pl-c1"&gt;NLP&lt;/span&gt;以后，才发现国内与国外的典型区别:
&lt;span class="pl-c1"&gt;1&lt;/span&gt;. 对资源的态度是完全相反的:
  &lt;span class="pl-c1"&gt;1&lt;/span&gt;) 国内：就好像为了名气，举办工作装逼的会议，就是没有干货，全部都是象征性的&lt;span class="pl-c1"&gt;PPT&lt;/span&gt;介绍，不是针对在做的各位
  &lt;span class="pl-c1"&gt;2&lt;/span&gt;）国外：就好像是为了推动nlp进步一样，分享者各种干货资料和具体的实现。（特别是: python自然语言处理）
&lt;span class="pl-c1"&gt;2&lt;/span&gt;. 论文的实现：
  &lt;span class="pl-c1"&gt;1&lt;/span&gt;) 各种高大上的论文实现，却还是没看到一个像样的GitHub项目！（可能我的搜索能力差了点，一直没找到）
  &lt;span class="pl-c1"&gt;2&lt;/span&gt;）国外就不举例了，我看不懂！
&lt;span class="pl-c1"&gt;3&lt;/span&gt;. 开源的框架
  &lt;span class="pl-c1"&gt;1&lt;/span&gt;）国外的开源框架： tensorflow&lt;span class="pl-k"&gt;/&lt;/span&gt;pytorch 文档&lt;span class="pl-k"&gt;+&lt;/span&gt;教程&lt;span class="pl-k"&gt;+&lt;/span&gt;视频（官方提供）
  &lt;span class="pl-c1"&gt;2&lt;/span&gt;) 国内的开源框架: 额额，还真举例不出来！但是牛逼吹得不比国外差！（MXNet虽然有众多国人参与开发，但不能算是国内开源框架。基于MXNet的动手学深度学习(http:&lt;span class="pl-k"&gt;//&lt;/span&gt;zh.d2l.ai &lt;span class="pl-k"&gt;&amp;amp;&lt;/span&gt; https:&lt;span class="pl-k"&gt;//&lt;/span&gt;discuss.gluon.ai&lt;span class="pl-k"&gt;/&lt;/span&gt;t&lt;span class="pl-k"&gt;/&lt;/span&gt;topic&lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-c1"&gt;753&lt;/span&gt;)中文教程,已经由沐神(李沐)以及阿斯顿·张讲授录制，公开发布(文档&lt;span class="pl-k"&gt;+&lt;/span&gt;第一季教程&lt;span class="pl-k"&gt;+&lt;/span&gt;视频）。)
每一次深入都要去翻墙，每一次深入都要Google，每一次看着国内的说：哈工大、讯飞、中科大、百度、阿里多牛逼，但是资料还是得国外去找！
有时候真的挺恨的！真的有点瞧不起自己国内的技术环境！

当然谢谢国内很多博客大佬，特别是一些入门的Demo和基本概念。【深入的水平有限，没看懂】&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6535fd936f9a2b1db5392b626320ce725854f675/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f6e6c702f46393435383146363443323141313039344134373333393744464134324639432e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/6535fd936f9a2b1db5392b626320ce725854f675/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f6e6c702f46393435383146363443323141313039344134373333393744464134324639432e6a7067" alt="" data-canonical-src="http://data.apachecn.org/img/AiLearning/nlp/F94581F64C21A1094A473397DFA42F9C.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;【入门须知】必须了解&lt;/strong&gt;: &lt;a href="https://github.com/apachecn/AiLearning/tree/master/docs/nlp"&gt;https://github.com/apachecn/AiLearning/tree/master/docs/nlp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;【入门教程】强烈推荐: PyTorch 自然语言处理&lt;/strong&gt;: &lt;a href="https://github.com/apachecn/NLP-with-PyTorch"&gt;https://github.com/apachecn/NLP-with-PyTorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Python 自然语言处理 第二版: &lt;a href="https://usyiyi.github.io/nlp-py-2e-zh" rel="nofollow"&gt;https://usyiyi.github.io/nlp-py-2e-zh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;推荐一个&lt;a href="https://github.com/liuhuanyong"&gt;liuhuanyong大佬&lt;/a&gt;整理的nlp全面知识体系: &lt;a href="https://liuhuanyong.github.io" rel="nofollow"&gt;https://liuhuanyong.github.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;开源 - 词向量库集合:
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Embedding/Chinese-Word-Vectors"&gt;https://github.com/Embedding/Chinese-Word-Vectors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/brightmart/nlp_chinese_corpus"&gt;https://github.com/brightmart/nlp_chinese_corpus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/codemayq/chinese_chatbot_corpus"&gt;https://github.com/codemayq/chinese_chatbot_corpus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/candlewill/Dialog_Corpus"&gt;https://github.com/candlewill/Dialog_Corpus&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-1使用场景-百度公开课" class="anchor" aria-hidden="true" href="#1使用场景-百度公开课"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.使用场景 （百度公开课）&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;第一部分 入门介绍&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;1.) &lt;a href="/docs/nlp/1.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D.md"&gt;自然语言处理入门介绍&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;第二部分 机器翻译&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;2.) &lt;a href="/docs/nlp/2.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md"&gt;机器翻译&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;第三部分 篇章分析&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;3.1.) &lt;a href="/docs/nlp/3.1.%E7%AF%87%E7%AB%A0%E5%88%86%E6%9E%90-%E5%86%85%E5%AE%B9%E6%A6%82%E8%BF%B0.md"&gt;篇章分析-内容概述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3.2.) &lt;a href="/docs/nlp/3.2.%E7%AF%87%E7%AB%A0%E5%88%86%E6%9E%90-%E5%86%85%E5%AE%B9%E6%A0%87%E7%AD%BE.md"&gt;篇章分析-内容标签&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3.3.) &lt;a href="/docs/nlp/3.3.%E7%AF%87%E7%AB%A0%E5%88%86%E6%9E%90-%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90.md"&gt;篇章分析-情感分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3.4.) &lt;a href="/docs/nlp/3.4.%E7%AF%87%E7%AB%A0%E5%88%86%E6%9E%90-%E8%87%AA%E5%8A%A8%E6%91%98%E8%A6%81.md"&gt;篇章分析-自动摘要&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;第四部分 UNIT-语言理解与交互技术&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;4.) &lt;a href="/docs/nlp/4.UNIT-%E8%AF%AD%E8%A8%80%E7%90%86%E8%A7%A3%E4%B8%8E%E4%BA%A4%E4%BA%92%E6%8A%80%E6%9C%AF.md"&gt;UNIT-语言理解与交互技术&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-应用领域" class="anchor" aria-hidden="true" href="#应用领域"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;应用领域&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-中文分词" class="anchor" aria-hidden="true" href="#中文分词"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;中文分词：&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;构建DAG图&lt;/li&gt;
&lt;li&gt;动态规划查找，综合正反向（正向加权反向输出）求得DAG最大概率路径&lt;/li&gt;
&lt;li&gt;使用了SBME语料训练了一套 HMM + Viterbi 模型，解决未登录词问题&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-1文本分类text-classification" class="anchor" aria-hidden="true" href="#1文本分类text-classification"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.文本分类（Text Classification）&lt;/h4&gt;
&lt;p&gt;文本分类是指标记句子或文档，例如电子邮件垃圾邮件分类和情感分析。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者文本分类数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html" rel="nofollow"&gt;路透社Newswire主题分类&lt;/a&gt;（路透社-21578）。1987年路透社出现的一系列新闻文件，按类别编制索引。&lt;a href="http://trec.nist.gov/data/reuters/reuters.html" rel="nofollow"&gt;另见RCV1，RCV2和TRC2&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ai.stanford.edu/~amaas/data/sentiment" rel="nofollow"&gt;IMDB电影评论情感分类（斯坦福）&lt;/a&gt;。来自网站imdb.com的一系列电影评论及其积极或消极的情绪。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.cornell.edu/people/pabo/movie-review-data/" rel="nofollow"&gt;新闻组电影评论情感分类（康奈尔）&lt;/a&gt;。来自网站imdb.com的一系列电影评论及其积极或消极的情绪。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有关更多信息，请参阅帖子：
&lt;a href="http://ana.cachopo.org/datasets-for-single-label-text-categorization" rel="nofollow"&gt;单标签文本分类的数据集&lt;/a&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;情感分析&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;比赛地址: &lt;a href="https://www.kaggle.com/c/word2vec-nlp-tutorial" rel="nofollow"&gt;https://www.kaggle.com/c/word2vec-nlp-tutorial&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;方案一(0.86)：WordCount + 朴素 Bayes&lt;/li&gt;
&lt;li&gt;方案二(0.94)：LDA + 分类模型（knn/决策树/逻辑回归/svm/xgboost/随机森林）
&lt;ul&gt;
&lt;li&gt;a) 决策树效果不是很好，这种连续特征不太适合的&lt;/li&gt;
&lt;li&gt;b) 通过参数调整 200 个topic，信息量保存效果较优（计算主题）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;方案三(0.72)：word2vec + CNN
&lt;ul&gt;
&lt;li&gt;说实话：没有一个好的机器，是调不出来一个好的结果 (: 逃&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;通过AUC 来评估模型的效果&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-2语言模型language-modeling" class="anchor" aria-hidden="true" href="#2语言模型language-modeling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2.语言模型（Language Modeling）&lt;/h4&gt;
&lt;p&gt;语言建模涉及开发一种统计模型，用于预测句子中的下一个单词或一个单词中的下一个单词。它是语音识别和机器翻译等任务中的前置任务。&lt;/p&gt;
&lt;p&gt;它是语音识别和机器翻译等任务中的前置任务。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者语言建模数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.gutenberg.org/" rel="nofollow"&gt;古腾堡项目&lt;/a&gt;，一系列免费书籍，可以用纯文本检索各种语言。&lt;/li&gt;
&lt;li&gt;还有更多正式的语料库得到了很好的研究; 例如：
&lt;a href="https://en.wikipedia.org/wiki/Brown_Corpus" rel="nofollow"&gt;布朗大学现代美国英语标准语料库&lt;/a&gt;。大量英语单词样本。
&lt;a href="https://github.com/ciprian-chelba/1-billion-word-language-modeling-benchmark"&gt;谷歌10亿字语料库&lt;/a&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;新词发现&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;中文分词新词发现&lt;/li&gt;
&lt;li&gt;python3利用互信息和左右信息熵的中文分词新词发现&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanzecheng/Chinese_segment_augment"&gt;https://github.com/zhanzecheng/Chinese_segment_augment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;句子相似度识别&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;项目地址: &lt;a href="https://www.kaggle.com/c/quora-question-pairs" rel="nofollow"&gt;https://www.kaggle.com/c/quora-question-pairs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;解决方案: word2vec + Bi-GRU&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;文本纠错&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;bi-gram + levenshtein&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-3图像字幕image-captioning" class="anchor" aria-hidden="true" href="#3图像字幕image-captioning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3.图像字幕（Image Captioning）&lt;/h4&gt;
&lt;p&gt;mage字幕是为给定图像生成文本描述的任务。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者图像字幕数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://mscoco.org/dataset/#overview" rel="nofollow"&gt;上下文中的公共对象（COCO）&lt;/a&gt;。包含超过12万张带描述的图像的集合&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nlp.cs.illinois.edu/HockenmaierGroup/8k-pictures.html" rel="nofollow"&gt;Flickr 8K&lt;/a&gt;。从flickr.com获取的8千个描述图像的集合。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://shannon.cs.illinois.edu/DenotationGraph/" rel="nofollow"&gt;Flickr 30K&lt;/a&gt;。从flickr.com获取的3万个描述图像的集合。
欲了解更多，请看帖子：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="http://sidgan.me/technical/2016/01/09/Exploring-Datasets" rel="nofollow"&gt;探索图像字幕数据集，2016年&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-4机器翻译machine-translation" class="anchor" aria-hidden="true" href="#4机器翻译machine-translation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4.机器翻译（Machine Translation）&lt;/h4&gt;
&lt;p&gt;机器翻译是将文本从一种语言翻译成另一种语言的任务。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者机器翻译数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.isi.edu/natural-language/download/hansard/" rel="nofollow"&gt;加拿大第36届议会的协调国会议员&lt;/a&gt;。成对的英语和法语句子。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.statmt.org/europarl/" rel="nofollow"&gt;欧洲议会诉讼平行语料库1996-2011&lt;/a&gt;。句子对一套欧洲语言。
有大量标准数据集用于年度机器翻译挑战; 看到：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="http://www.statmt.org/" rel="nofollow"&gt;统计机器翻译&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;机器翻译&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Encoder + Decoder(Attention)&lt;/li&gt;
&lt;li&gt;参考案例: &lt;a href="http://pytorch.apachecn.org/cn/tutorials/intermediate/seq2seq_translation_tutorial.html" rel="nofollow"&gt;http://pytorch.apachecn.org/cn/tutorials/intermediate/seq2seq_translation_tutorial.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-5问答系统question-answering" class="anchor" aria-hidden="true" href="#5问答系统question-answering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;5.问答系统（Question Answering）&lt;/h4&gt;
&lt;p&gt;问答是一项任务，其中提供了一个句子或文本样本，从中提出问题并且必须回答问题。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者问题回答数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/" rel="nofollow"&gt;斯坦福问题回答数据集（SQuAD）&lt;/a&gt;。回答有关维基百科文章的问题。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/deepmind/rc-data"&gt;Deepmind问题回答语料库&lt;/a&gt;。从每日邮报回答有关新闻文章的问题。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmcauley.ucsd.edu/data/amazon/qa/" rel="nofollow"&gt;亚马逊问答数据&lt;/a&gt;。回答有关亚马逊产品的问题。
有关更多信息，请参阅帖子：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="https://www.quora.com/Datasets-How-can-I-get-corpus-of-a-question-answering-website-like-Quora-or-Yahoo-Answers-or-Stack-Overflow-for-analyzing-answer-quality" rel="nofollow"&gt;数据集：我如何获得问答网站的语料库，如Quora或Yahoo Answers或Stack Overflow来分析答案质量？&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-6语音识别speech-recognition" class="anchor" aria-hidden="true" href="#6语音识别speech-recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;6.语音识别（Speech Recognition）&lt;/h4&gt;
&lt;p&gt;语音识别是将口语的音频转换为人类可读文本的任务。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者语音识别数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://catalog.ldc.upenn.edu/LDC93S1" rel="nofollow"&gt;TIMIT声学 - 语音连续语音语料库&lt;/a&gt;。不是免费的，但因其广泛使用而上市。口语美国英语和相关的转录。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://voxforge.org/" rel="nofollow"&gt;VoxForge&lt;/a&gt;。用于构建用于语音识别的开源数据库的项目。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.openslr.org/12/" rel="nofollow"&gt;LibriSpeech ASR语料库&lt;/a&gt;。从LibriVox收集的大量英语有声读物。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-7自动文摘document-summarization" class="anchor" aria-hidden="true" href="#7自动文摘document-summarization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;7.自动文摘（Document Summarization）&lt;/h4&gt;
&lt;p&gt;文档摘要是创建较大文档的简短有意义描述的任务。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者文档摘要数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://archive.ics.uci.edu/ml/datasets/Legal+Case+Reports" rel="nofollow"&gt;法律案例报告数据集&lt;/a&gt;。收集了4000份法律案件及其摘要。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www-nlpir.nist.gov/related_projects/tipster_summac/cmp_lg.html" rel="nofollow"&gt;TIPSTER文本摘要评估会议语料库&lt;/a&gt;。收集了近200份文件及其摘要。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://catalog.ldc.upenn.edu/LDC2002T31" rel="nofollow"&gt;英语新闻文本的AQUAINT语料库&lt;/a&gt;。不是免费的，而是广泛使用的。新闻文章的语料库。
欲了解更多信息：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="http://www-nlpir.nist.gov/projects/duc/data.html" rel="nofollow"&gt;文档理解会议（DUC）任务&lt;/a&gt;。
&lt;a href="https://www.quora.com/Where-can-I-find-good-data-sets-for-text-summarization" rel="nofollow"&gt;在哪里可以找到用于文本摘要的良好数据集？&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;命名实体识别&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Bi-LSTM CRF&lt;/li&gt;
&lt;li&gt;参考案例: &lt;a href="http://pytorch.apachecn.org/cn/tutorials/beginner/nlp/advanced_tutorial.html" rel="nofollow"&gt;http://pytorch.apachecn.org/cn/tutorials/beginner/nlp/advanced_tutorial.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CRF推荐文档: &lt;a href="https://www.jianshu.com/p/55755fc649b1" rel="nofollow"&gt;https://www.jianshu.com/p/55755fc649b1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;文本摘要&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;抽取式&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;word2vec + textrank&lt;/li&gt;
&lt;li&gt;word2vec推荐文档: &lt;a href="https://www.zhihu.com/question/44832436/answer/266068967" rel="nofollow"&gt;https://www.zhihu.com/question/44832436/answer/266068967&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;textrank推荐文档: &lt;a href="https://blog.csdn.net/BaiHuaXiu123/article/details/77847232" rel="nofollow"&gt;https://blog.csdn.net/BaiHuaXiu123/article/details/77847232&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-graph图计算慢慢更新" class="anchor" aria-hidden="true" href="#graph图计算慢慢更新"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Graph图计算【慢慢更新】&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;数据集: &lt;a href="data/nlp/graph"&gt;data/nlp/graph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;学习资料: spark graphX实战.pdf 【文件太大不方便提供，自己百度】&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-知识图谱" class="anchor" aria-hidden="true" href="#知识图谱"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;知识图谱&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;知识图谱，我只认 &lt;a href="https://www.zhihu.com/people/simmerchan" rel="nofollow"&gt;SimmerChan&lt;/a&gt;: &lt;a href="https://zhuanlan.zhihu.com/knowledgegraph" rel="nofollow"&gt;【知识图谱-给AI装个大脑】&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;说实话，我是看这博主老哥写的博客长大的，写的真的是深入浅出。我很喜欢，所以就分享给大家，希望你们也喜欢。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-进一步阅读" class="anchor" aria-hidden="true" href="#进一步阅读"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;进一步阅读&lt;/h3&gt;
&lt;p&gt;如果您希望更深入，本节提供了其他数据集列表。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#Text_data" rel="nofollow"&gt;维基百科研究中使用的文本数据集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/Datasets-What-are-the-major-text-corpora-used-by-computational-linguists-and-natural-language-processing-researchers-and-what-are-the-characteristics-biases-of-each-corpus" rel="nofollow"&gt;数据集：计算语言学家和自然语言处理研究人员使用的主要文本语料库是什么？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://nlp.stanford.edu/links/statnlp.html#Corpora" rel="nofollow"&gt;斯坦福统计自然语言处理语料库&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/niderhoff/nlp-datasets"&gt;按字母顺序排列的NLP数据集列表&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nltk.org/nltk_data/" rel="nofollow"&gt;该机构NLTK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://deeplearning4j.org/opendata" rel="nofollow"&gt;在DL4J上打开深度学习数据&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/caesar0301/awesome-public-datasets#natural-language"&gt;NLP数据集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;国内开放数据集: &lt;a href="https://bosonnlp.com/dev/resource" rel="nofollow"&gt;https://bosonnlp.com/dev/resource&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-项目负责人" class="anchor" aria-hidden="true" href="#项目负责人"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目负责人&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第一期 (2017-02-27)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jiangzhonglian"&gt;@片刻&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wangyangting"&gt;@那伊抹微笑&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chenyyx"&gt;@瑶妹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/report/2017-04-08_%E7%AC%AC%E4%B8%80%E6%9C%9F%E7%9A%84%E6%80%BB%E7%BB%93.md"&gt;2017-04-08_第一期的总结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第二期 (2017-08-14)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jiangzhonglian"&gt;@片刻&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wangyangting"&gt;@那伊抹微笑&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chenyyx"&gt;@瑶妹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mikechengwei"&gt;@Mike&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第三期 (2018-04-16)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-项目贡献者" class="anchor" aria-hidden="true" href="#项目贡献者"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目贡献者&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第一期 (2017-02-27)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/geekidentity"&gt;@侯法超&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/hello19883"&gt;@hello19883&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sheepmen"&gt;@徐鑫&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/highfei2011"&gt;@ibe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第二期 (2017-08-14)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/LeeMoonCh"&gt;@Arithmetic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/caopeirui"&gt;@Veyron C&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Cugtyt"&gt;@Cugtyt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/hey-bruce"&gt;@BBruceyuan&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第三期 (2018-04-16)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-群管理员换届" class="anchor" aria-hidden="true" href="#群管理员换届"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;群管理员换届&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/chenyyx"&gt;@瑶妹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wizardforcel"&gt;@飞龙&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jiangzhonglian"&gt;@片刻&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Watermelon233"&gt;@伪文艺.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wangyangting"&gt;@那伊抹微笑&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@LAMDA-健忘症&lt;/a&gt; 永久留任-非常感谢对群的贡献&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第一届 (2017-09-01)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=""&gt;@易漠&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mikechengwei"&gt;@Mike&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@Books&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@李孟禹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@张假飞&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@Glassy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@红色石头&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@微光同尘&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第二届 (2018-07-04)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=""&gt;@张假飞&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@李孟禹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@小明教主&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@平淡的天&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@凌少skierゞ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@じ☆νЁ坐看云起&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;古柳-DesertsX&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;woodchuck&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;自由精灵&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;楚盟&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;99杆清台&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;时空守望者@&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;只想发论文的渣渣&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;目标: ml劝退专家&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第三届 (2019-01-01)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=""&gt;只会喊666的存在&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;codefun007.xyz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;荼靡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;大鱼&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;青鸟&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;古柳-DesertsX&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Edge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Alluka&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;不发篇paper不改名片&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;FontTian&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Bigjing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;仁 礼 智 爱&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;可啪的小乖受&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;老古董&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;时空守望者&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;我好菜啊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Messi 19&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;萌Jay小公举&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第四届 (2019-06-01)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=""&gt;佛学爱好者&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;楚盟&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;codefun007.xyz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;大鱼-群花-声优&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;大海&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Edge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;if only&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;李孟禹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;平静&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;任务做不完&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;仁礼智爱&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;园时空守望者@&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;坐看云起&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;阿花君霸占路人&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;烦焖鸡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;古柳-DesertsX&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;青鸟(服务员)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;小明教主&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;zhiqing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;SrL.z&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;欢迎贡献者不断的追加&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-免责声明---只供学习参考" class="anchor" aria-hidden="true" href="#免责声明---只供学习参考"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;免责声明 - 【只供学习参考】&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ApacheCN 纯粹出于学习目的与个人兴趣翻译本书&lt;/li&gt;
&lt;li&gt;ApacheCN 保留对此版本译文的署名权及其它相关权利&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-协议" class="anchor" aria-hidden="true" href="#协议"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;协议&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;以各项目协议为准。&lt;/li&gt;
&lt;li&gt;ApacheCN 账号下没有协议的项目，一律视为 &lt;a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="nofollow"&gt;CC BY-NC-SA 4.0&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-资料来源" class="anchor" aria-hidden="true" href="#资料来源"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;资料来源:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;【比赛收集平台】: &lt;a href="https://github.com/iphysresearch/DataSciComp"&gt;https://github.com/iphysresearch/DataSciComp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pbharrin/machinelearninginaction"&gt;https://github.com/pbharrin/machinelearninginaction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://machinelearningmastery.com/datasets-natural-language-processing" rel="nofollow"&gt;https://machinelearningmastery.com/datasets-natural-language-processing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-感谢信" class="anchor" aria-hidden="true" href="#感谢信"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;感谢信&lt;/h2&gt;
&lt;p&gt;最近无意收到群友推送的链接，发现得到大佬高度的认可，并在热心的推广&lt;/p&gt;
&lt;p&gt;在此感谢:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/org/liang-zi-wei-48" rel="nofollow"&gt;量子位&lt;/a&gt;: &lt;a href="https://www.zhihu.com/question/20472776/answer/691646493" rel="nofollow"&gt;https://www.zhihu.com/question/20472776/answer/691646493&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;人工智能前沿讲习: &lt;a href="https://mp.weixin.qq.com/s/f2dqulxOPkt7k5hqPsydyQ" rel="nofollow"&gt;https://mp.weixin.qq.com/s/f2dqulxOPkt7k5hqPsydyQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-赞助我们" class="anchor" aria-hidden="true" href="#赞助我们"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;赞助我们&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2814efae28977e977f631af3a30acfe4e9089dd9/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f61626f75742f646f6e6174652e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/2814efae28977e977f631af3a30acfe4e9089dd9/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f61626f75742f646f6e6174652e6a7067" alt="微信&amp;amp;支付宝" data-canonical-src="http://data.apachecn.org/img/about/donate.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;特别赞助商(欢迎“私聊”赞助)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td align="center" valign="middle"&gt;
            &lt;a href="https://coding.net/?utm_source=ApacheCN&amp;amp;utm_medium=banner&amp;amp;utm_campaign=march2019" rel="nofollow"&gt;
              &lt;img width="1080" src="https://camo.githubusercontent.com/8d33a9d36a6822434ce78147cdb7cb41aba56a02/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f5370656369616c53706f6e736f72732f436f64696e674e65742e706e67" data-canonical-src="http://data.apachecn.org/img/SpecialSponsors/CodingNet.png" style="max-width:100%;"&gt;
            &lt;/a&gt;
          &lt;/td&gt;
      &lt;/tr&gt;&lt;/tbody&gt;
&lt;/table&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>apachecn</author><guid isPermaLink="false">https://github.com/apachecn/AiLearning</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>notadamking/tensortrade #5 in Python, This week</title><link>https://github.com/notadamking/tensortrade</link><description>&lt;p&gt;&lt;i&gt;An open source reinforcement learning framework for training, evaluating, and deploying robust trading agents.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensortrade-trade-efficiently-with-reinforcement-learning" class="anchor" aria-hidden="true" href="#tensortrade-trade-efficiently-with-reinforcement-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://towardsdatascience.com/trade-smarter-w-reinforcement-learning-a5e91163f315?source=friends_link&amp;amp;sk=ea3afd0a305141eb9147be4718826dfb" rel="nofollow"&gt;TensorTrade: Trade Efficiently with Reinforcement Learning&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/notadamking/tensortrade" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/41e140102a87bca237e00545bde70be469f5494f/68747470733a2f2f7472617669732d63692e636f6d2f6e6f746164616d6b696e672f74656e736f7274726164652e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/notadamking/tensortrade.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://tensortrade.org" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1507bfd72bf32b8fc46754503d5d8dc464c023fe/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f74656e736f7274726164652f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/tensortrade/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/25504145e91ed8726d8ce49c5ab2ad2a4bdfb098/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6e6f746164616d6b696e672f74656e736f7274726164652e7376673f636f6c6f723d627269676874677265656e" alt="Apache License" data-canonical-src="https://img.shields.io/github/license/notadamking/tensortrade.svg?color=brightgreen" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://discord.gg/ZZ7BGWh" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/11bef0bdfed0a6d99ad8c933cfa835cef46a755b/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3539323434363632343838323439313430322e7376673f636f6c6f723d627269676874677265656e" alt="Discord" data-canonical-src="https://img.shields.io/discord/592446624882491402.svg?color=brightgreen" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.python.org/downloads/release/python-360/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c2ed0c1d8ac1a5ebbe7281923d42b50b7962912c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d626c75652e737667" alt="Python 3.6" data-canonical-src="https://img.shields.io/badge/python-3.6-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;div align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/notadamking/tensortrade/blob/master/docs/source/_static/logo.jpg"&gt;&lt;img src="https://github.com/notadamking/tensortrade/raw/master/docs/source/_static/logo.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;TensorTrade is still in Alpha, meaning it should not be used in production systems yet, and it may contain bugs.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;TensorTrade is an open source Python framework for building, training, evaluating, and deploying robust trading algorithms using reinforcement learning. The framework focuses on being highly composable and extensible, to allow the system to scale from simple trading strategies on a single CPU, to complex investment strategies run on a distribution of HPC machines.&lt;/p&gt;
&lt;p&gt;Under the hood, the framework uses many of the APIs from existing machine learning libraries to maintain high quality data pipelines and learning models. One of the main goals of TensorTrade is to enable fast experimentation with algorithmic trading strategies, by leveraging the existing tools and pipelines provided by &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;, &lt;code&gt;gym&lt;/code&gt;, &lt;code&gt;keras&lt;/code&gt;, and &lt;code&gt;tensorflow&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Every piece of the framework is split up into re-usable components, allowing you to take advantage of the general use components built by the community, while keeping your proprietary features private. The aim is to simplify the process of testing and deploying robust trading agents using deep reinforcement learning, to allow you and I to focus on creating profitable strategies.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The goal of this framework is to enable fast experimentation, while maintaining production-quality data pipelines.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Read &lt;a href="http://tensortrade.org" rel="nofollow"&gt;the documentation&lt;/a&gt; or walk through &lt;a href="https://towardsdatascience.com/trade-smarter-w-reinforcement-learning-a5e91163f315?source=friends_link&amp;amp;sk=ea3afd0a305141eb9147be4718826dfb" rel="nofollow"&gt;the tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-guiding-principles" class="anchor" aria-hidden="true" href="#guiding-principles"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Guiding principles&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Inspired by &lt;a href="https://github.com/keras-team/keras"&gt;Keras' guiding principles&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;User friendliness.&lt;/strong&gt; TensorTrade is an API designed for human beings, not machines. It puts user experience front and center. TensorTrade follows best practices for reducing cognitive load: it offers consistent &amp;amp; simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear and actionable feedback upon user error.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Modularity.&lt;/strong&gt; A trading environment is a conglomeration of fully configurable modules that can be plugged together with as few restrictions as possible. In particular, instrument exchanges, feature pipelines, action strategies, reward strategies, trading agents, and performance reports are all standalone modules that you can combine to create new trading environments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Easy extensibility.&lt;/strong&gt; New modules are simple to add (as new classes and functions), and existing modules provide ample examples. To be able to easily create new modules allows for total expressiveness, making TensorTrade suitable for advanced research and production use.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-tensortrade-hall-of-fame" class="anchor" aria-hidden="true" href="#tensortrade-hall-of-fame"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorTrade Hall of Fame&lt;/h2&gt;
&lt;p&gt;TensorTrade is entirely community funded. We appreciate all of our great sponsors! If you would like to be featured on our Hall of Fame, or sponsor the framework in any other way, visit the &lt;a href="#sponsorship"&gt;Sponsorship section below&lt;/a&gt;.&lt;/p&gt;
&lt;a href="https://capfol.io" rel="nofollow"&gt;
  &lt;img alt="Capfolio" src="https://user-images.githubusercontent.com/14098106/67627791-fc291d80-f817-11e9-8fc5-0f0a3d72c646.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;You can get started testing on Google Colab or your local machine, by viewing our &lt;a href="https://github.com/notadamking/tensortrade/tree/master/examples"&gt;many examples&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;TensorTrade requires Python &amp;gt;= 3.6 for all functionality to work as expected.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install -r requirements.txt&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h2&gt;
&lt;p&gt;To run the commands below, ensure Docker is installed. Visit &lt;a href="https://docs.docker.com/install/" rel="nofollow"&gt;https://docs.docker.com/install/&lt;/a&gt; for more information.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-run-jupyter-notebooks" class="anchor" aria-hidden="true" href="#run-jupyter-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Run Jupyter Notebooks&lt;/h3&gt;
&lt;p&gt;To run a jupyter notebook in your browser, execute the following command and visit the &lt;code&gt;http://127.0.0.1:8888/?token=...&lt;/code&gt; link printed to the command line.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;make run-notebook&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-build-documentation" class="anchor" aria-hidden="true" href="#build-documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Build Documentation&lt;/h3&gt;
&lt;p&gt;To build the HTML documentation, execute the following command.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;make run-docs&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-run-test-suite" class="anchor" aria-hidden="true" href="#run-test-suite"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Run Test Suite&lt;/h3&gt;
&lt;p&gt;To run the test suite, execute the following command.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;make run-tests&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-support" class="anchor" aria-hidden="true" href="#support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support&lt;/h2&gt;
&lt;p&gt;You can ask questions and join the development discussion:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On the &lt;a href="https://discord.gg/ZZ7BGWh" rel="nofollow"&gt;TensorTrade Discord server&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;On the &lt;a href="https://gitter.im/tensortrade-framework/community" rel="nofollow"&gt;TensorTrade Gitter&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can also post &lt;strong&gt;bug reports and feature requests&lt;/strong&gt; in &lt;a href="https://github.com/notadamking/tensortrade/issues"&gt;GitHub issues&lt;/a&gt;. Make sure to read &lt;a href="https://github.com/notadamking/tensortrade/blob/master/CONTRIBUTING.md"&gt;our guidelines&lt;/a&gt; first.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sponsorship" class="anchor" aria-hidden="true" href="#sponsorship"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sponsorship&lt;/h2&gt;
&lt;p&gt;If you would like to support this project financially, there are a few ways you can contribute. Your contributions are greatly appreciated and help to keep TensorTrade maintained and always improving.&lt;/p&gt;
&lt;p&gt;Github Sponsors: &lt;a href="https://github.com/sponsors/notadamking"&gt;https://github.com/sponsors/notadamking&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;All Github Sponsors donations are matched 1:1 by Github up to $5,000!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;BTC Address: &lt;code&gt;1Lc47bhYvdyKGk1qN8oBHdYQTkbFLL3PFw&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;ETH Address: &lt;code&gt;0x9907A0cF64Ec9Fbf6Ed8FD4971090DE88222a9aC&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributors&lt;/h2&gt;
&lt;p&gt;Contributions are encouraged and welcomed. This project is meant to grow as the community around it grows. Let me know on Discord in the #suggestions channel if there is anything that you would like to see in the future, or if there is anything you feel is missing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Working on your first Pull Request?&lt;/strong&gt; You can learn how from this &lt;em&gt;free&lt;/em&gt; series &lt;a href="https://egghead.io/series/how-to-contribute-to-an-open-source-project-on-github" rel="nofollow"&gt;How to Contribute to an Open Source Project on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/11e0e3968f7aad0c841cdab9a5d746dd02b9c394/68747470733a2f2f636f6e7472696275746f72732d696d672e66697265626173656170702e636f6d2f696d6167653f7265706f3d6e6f746164616d6b696e672f74656e736f727472616465"&gt;&lt;img src="https://camo.githubusercontent.com/11e0e3968f7aad0c841cdab9a5d746dd02b9c394/68747470733a2f2f636f6e7472696275746f72732d696d672e66697265626173656170702e636f6d2f696d6167653f7265706f3d6e6f746164616d6b696e672f74656e736f727472616465" alt="https://github.com/notadamking/tensortrade/graphs/contributors" data-canonical-src="https://contributors-img.firebaseapp.com/image?repo=notadamking/tensortrade" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>notadamking</author><guid isPermaLink="false">https://github.com/notadamking/tensortrade</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>eriklindernoren/ML-From-Scratch #6 in Python, This week</title><link>https://github.com/eriklindernoren/ML-From-Scratch</link><description>&lt;p&gt;&lt;i&gt;Machine Learning From Scratch. Bare bones NumPy implementations of machine learning models and algorithms with a focus on accessibility. Aims to cover everything from linear regression to deep learning.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-from-scratch" class="anchor" aria-hidden="true" href="#machine-learning-from-scratch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning From Scratch&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-about" class="anchor" aria-hidden="true" href="#about"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About&lt;/h2&gt;
&lt;p&gt;Python implementations of some of the fundamental Machine Learning models and algorithms from scratch.&lt;/p&gt;
&lt;p&gt;The purpose of this project is not to produce as optimized and computationally efficient algorithms as possible
but rather to present the inner workings of them in a transparent and accessible way.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#machine-learning-from-scratch"&gt;Machine Learning From Scratch&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#about"&gt;About&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#examples"&gt;Examples&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#polynomial-regression"&gt;Polynomial Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#classification-with-cnn"&gt;Classification With CNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#density-based-clustering"&gt;Density-Based Clustering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#generating-handwritten-digits"&gt;Generating Handwritten Digits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#deep-reinforcement-learning"&gt;Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#image-reconstruction-with-rbm"&gt;Image Reconstruction With RBM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#evolutionary-evolved-neural-network"&gt;Evolutionary Evolved Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#genetic-algorithm"&gt;Genetic Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#association-analysis"&gt;Association Analysis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#implementations"&gt;Implementations&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#supervised-learning"&gt;Supervised Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#unsupervised-learning"&gt;Unsupervised Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#reinforcement-learning"&gt;Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#deep-learning"&gt;Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#contact"&gt;Contact&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/eriklindernoren/ML-From-Scratch
$ cd ML-From-Scratch
$ python setup.py install
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-polynomial-regression" class="anchor" aria-hidden="true" href="#polynomial-regression"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Polynomial Regression&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/polynomial_regression.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/d82416364e7916546886f94027e2652d3247e8ab/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f705f7265672e676966"&gt;&lt;img src="https://camo.githubusercontent.com/d82416364e7916546886f94027e2652d3247e8ab/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f705f7265672e676966" width="640" data-canonical-src="http://eriklindernoren.se/images/p_reg.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Training progress of a regularized polynomial regression model fitting &lt;br&gt;
    temperature data measured in Linköping, Sweden 2016.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-classification-with-cnn" class="anchor" aria-hidden="true" href="#classification-with-cnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Classification With CNN&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/convolutional_neural_network.py

+---------+
| ConvNet |
+---------+
Input Shape: (1, 8, 8)
+----------------------+------------+--------------+
| Layer Type           | Parameters | Output Shape |
+----------------------+------------+--------------+
| Conv2D               | 160        | (16, 8, 8)   |
| Activation (ReLU)    | 0          | (16, 8, 8)   |
| Dropout              | 0          | (16, 8, 8)   |
| BatchNormalization   | 2048       | (16, 8, 8)   |
| Conv2D               | 4640       | (32, 8, 8)   |
| Activation (ReLU)    | 0          | (32, 8, 8)   |
| Dropout              | 0          | (32, 8, 8)   |
| BatchNormalization   | 4096       | (32, 8, 8)   |
| Flatten              | 0          | (2048,)      |
| Dense                | 524544     | (256,)       |
| Activation (ReLU)    | 0          | (256,)       |
| Dropout              | 0          | (256,)       |
| BatchNormalization   | 512        | (256,)       |
| Dense                | 2570       | (10,)        |
| Activation (Softmax) | 0          | (10,)        |
+----------------------+------------+--------------+
Total Parameters: 538570

Training: 100% [------------------------------------------------------------------------] Time: 0:01:55
Accuracy: 0.987465181058
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/c2bca09f5d1ce2b72f33fe61464408607797caa3/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f6d6c66735f636e6e312e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/c2bca09f5d1ce2b72f33fe61464408607797caa3/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f6d6c66735f636e6e312e706e67" width="640" data-canonical-src="http://eriklindernoren.se/images/mlfs_cnn1.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Classification of the digit dataset using CNN.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-density-based-clustering" class="anchor" aria-hidden="true" href="#density-based-clustering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Density-Based Clustering&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/dbscan.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/eaf413b6e8cbf3f8fd048f3a63984482ffd7350e/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f6d6c66735f64627363616e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/eaf413b6e8cbf3f8fd048f3a63984482ffd7350e/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f6d6c66735f64627363616e2e706e67" width="640" data-canonical-src="http://eriklindernoren.se/images/mlfs_dbscan.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Clustering of the moons dataset using DBSCAN.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-generating-handwritten-digits" class="anchor" aria-hidden="true" href="#generating-handwritten-digits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generating Handwritten Digits&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/unsupervised_learning/generative_adversarial_network.py

+-----------+
| Generator |
+-----------+
Input Shape: (100,)
+------------------------+------------+--------------+
| Layer Type             | Parameters | Output Shape |
+------------------------+------------+--------------+
| Dense                  | 25856      | (256,)       |
| Activation (LeakyReLU) | 0          | (256,)       |
| BatchNormalization     | 512        | (256,)       |
| Dense                  | 131584     | (512,)       |
| Activation (LeakyReLU) | 0          | (512,)       |
| BatchNormalization     | 1024       | (512,)       |
| Dense                  | 525312     | (1024,)      |
| Activation (LeakyReLU) | 0          | (1024,)      |
| BatchNormalization     | 2048       | (1024,)      |
| Dense                  | 803600     | (784,)       |
| Activation (TanH)      | 0          | (784,)       |
+------------------------+------------+--------------+
Total Parameters: 1489936

+---------------+
| Discriminator |
+---------------+
Input Shape: (784,)
+------------------------+------------+--------------+
| Layer Type             | Parameters | Output Shape |
+------------------------+------------+--------------+
| Dense                  | 401920     | (512,)       |
| Activation (LeakyReLU) | 0          | (512,)       |
| Dropout                | 0          | (512,)       |
| Dense                  | 131328     | (256,)       |
| Activation (LeakyReLU) | 0          | (256,)       |
| Dropout                | 0          | (256,)       |
| Dense                  | 514        | (2,)         |
| Activation (Softmax)   | 0          | (2,)         |
+------------------------+------------+--------------+
Total Parameters: 533762
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/15ad5010011227a7ab8c6c77d19b7cc625cced30/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f67616e5f6d6e697374352e676966"&gt;&lt;img src="https://camo.githubusercontent.com/15ad5010011227a7ab8c6c77d19b7cc625cced30/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f67616e5f6d6e697374352e676966" width="640" data-canonical-src="http://eriklindernoren.se/images/gan_mnist5.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Training progress of a Generative Adversarial Network generating &lt;br&gt;
    handwritten digits.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-deep-reinforcement-learning" class="anchor" aria-hidden="true" href="#deep-reinforcement-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Reinforcement Learning&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/deep_q_network.py

+----------------+
| Deep Q-Network |
+----------------+
Input Shape: (4,)
+-------------------+------------+--------------+
| Layer Type        | Parameters | Output Shape |
+-------------------+------------+--------------+
| Dense             | 320        | (64,)        |
| Activation (ReLU) | 0          | (64,)        |
| Dense             | 130        | (2,)         |
+-------------------+------------+--------------+
Total Parameters: 450
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/c605134f41b739121c4710f3d5c6e8370a592e0c/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f6d6c66735f64716c312e676966"&gt;&lt;img src="https://camo.githubusercontent.com/c605134f41b739121c4710f3d5c6e8370a592e0c/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f6d6c66735f64716c312e676966" width="640" data-canonical-src="http://eriklindernoren.se/images/mlfs_dql1.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Deep Q-Network solution to the CartPole-v1 environment in OpenAI gym.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-image-reconstruction-with-rbm" class="anchor" aria-hidden="true" href="#image-reconstruction-with-rbm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image Reconstruction With RBM&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/restricted_boltzmann_machine.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/d209d42aed9e8e32a10eaec9b76f141319a2b0d7/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f72626d5f646967697473312e676966"&gt;&lt;img src="https://camo.githubusercontent.com/d209d42aed9e8e32a10eaec9b76f141319a2b0d7/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f72626d5f646967697473312e676966" width="640" data-canonical-src="http://eriklindernoren.se/images/rbm_digits1.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Shows how the network gets better during training at reconstructing &lt;br&gt;
    the digit 2 in the MNIST dataset.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-evolutionary-evolved-neural-network" class="anchor" aria-hidden="true" href="#evolutionary-evolved-neural-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Evolutionary Evolved Neural Network&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/neuroevolution.py

+---------------+
| Model Summary |
+---------------+
Input Shape: (64,)
+----------------------+------------+--------------+
| Layer Type           | Parameters | Output Shape |
+----------------------+------------+--------------+
| Dense                | 1040       | (16,)        |
| Activation (ReLU)    | 0          | (16,)        |
| Dense                | 170        | (10,)        |
| Activation (Softmax) | 0          | (10,)        |
+----------------------+------------+--------------+
Total Parameters: 1210

Population Size: 100
Generations: 3000
Mutation Rate: 0.01

[0 Best Individual - Fitness: 3.08301, Accuracy: 10.5%]
[1 Best Individual - Fitness: 3.08746, Accuracy: 12.0%]
...
[2999 Best Individual - Fitness: 94.08513, Accuracy: 98.5%]
Test set accuracy: 96.7%
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1a8abe4882d0195b8f8bd4c6f24caab639291e6e/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f65766f5f6e6e342e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/1a8abe4882d0195b8f8bd4c6f24caab639291e6e/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f65766f5f6e6e342e706e67" width="640" data-canonical-src="http://eriklindernoren.se/images/evo_nn4.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Classification of the digit dataset by a neural network which has&lt;br&gt;
    been evolutionary evolved.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-genetic-algorithm" class="anchor" aria-hidden="true" href="#genetic-algorithm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Genetic Algorithm&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/genetic_algorithm.py

+--------+
|   GA   |
+--------+
Description: Implementation of a Genetic Algorithm which aims to produce
the user specified target string. This implementation calculates each
candidate's fitness based on the alphabetical distance between the candidate
and the target. A candidate is selected as a parent with probabilities proportional
to the candidate's fitness. Reproduction is implemented as a single-point
crossover between pairs of parents. Mutation is done by randomly assigning
new characters with uniform probability.

Parameters
----------
Target String: 'Genetic Algorithm'
Population Size: 100
Mutation Rate: 0.05

[0 Closest Candidate: 'CJqlJguPlqzvpoJmb', Fitness: 0.00]
[1 Closest Candidate: 'MCxZxdr nlfiwwGEk', Fitness: 0.01]
[2 Closest Candidate: 'MCxZxdm nlfiwwGcx', Fitness: 0.01]
[3 Closest Candidate: 'SmdsAklMHn kBIwKn', Fitness: 0.01]
[4 Closest Candidate: '  lotneaJOasWfu Z', Fitness: 0.01]
...
[292 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]
[293 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]
[294 Answer: 'Genetic Algorithm']
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-association-analysis" class="anchor" aria-hidden="true" href="#association-analysis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Association Analysis&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/apriori.py
+-------------+
|   Apriori   |
+-------------+
Minimum Support: 0.25
Minimum Confidence: 0.8
Transactions:
    [1, 2, 3, 4]
    [1, 2, 4]
    [1, 2]
    [2, 3, 4]
    [2, 3]
    [3, 4]
    [2, 4]
Frequent Itemsets:
    [1, 2, 3, 4, [1, 2], [1, 4], [2, 3], [2, 4], [3, 4], [1, 2, 4], [2, 3, 4]]
Rules:
    1 -&amp;gt; 2 (support: 0.43, confidence: 1.0)
    4 -&amp;gt; 2 (support: 0.57, confidence: 0.8)
    [1, 4] -&amp;gt; 2 (support: 0.29, confidence: 1.0)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-implementations" class="anchor" aria-hidden="true" href="#implementations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Implementations&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-supervised-learning" class="anchor" aria-hidden="true" href="#supervised-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Supervised Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/adaboost.py"&gt;Adaboost&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/bayesian_regression.py"&gt;Bayesian Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/decision_tree.py"&gt;Decision Tree&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/regression.py"&gt;Elastic Net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/gradient_boosting.py"&gt;Gradient Boosting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/k_nearest_neighbors.py"&gt;K Nearest Neighbors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/regression.py"&gt;Lasso Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/linear_discriminant_analysis.py"&gt;Linear Discriminant Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/regression.py"&gt;Linear Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/logistic_regression.py"&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/multi_class_lda.py"&gt;Multi-class Linear Discriminant Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/multilayer_perceptron.py"&gt;Multilayer Perceptron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/naive_bayes.py"&gt;Naive Bayes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/neuroevolution.py"&gt;Neuroevolution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/particle_swarm_optimization.py"&gt;Particle Swarm Optimization of Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/perceptron.py"&gt;Perceptron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/regression.py"&gt;Polynomial Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/random_forest.py"&gt;Random Forest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/regression.py"&gt;Ridge Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/support_vector_machine.py"&gt;Support Vector Machine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/xgboost.py"&gt;XGBoost&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-unsupervised-learning" class="anchor" aria-hidden="true" href="#unsupervised-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Unsupervised Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/apriori.py"&gt;Apriori&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/autoencoder.py"&gt;Autoencoder&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/dbscan.py"&gt;DBSCAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/fp_growth.py"&gt;FP-Growth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/gaussian_mixture_model.py"&gt;Gaussian Mixture Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/generative_adversarial_network.py"&gt;Generative Adversarial Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/genetic_algorithm.py"&gt;Genetic Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/k_means.py"&gt;K-Means&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/partitioning_around_medoids.py"&gt;Partitioning Around Medoids&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/principal_component_analysis.py"&gt;Principal Component Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py"&gt;Restricted Boltzmann Machine&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-reinforcement-learning" class="anchor" aria-hidden="true" href="#reinforcement-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reinforcement Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="mlfromscratch/reinforcement_learning/deep_q_network.py"&gt;Deep Q-Network&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-deep-learning" class="anchor" aria-hidden="true" href="#deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="mlfromscratch/deep_learning/neural_network.py"&gt;Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/deep_learning/layers.py"&gt;Layers&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Activation Layer&lt;/li&gt;
&lt;li&gt;Average Pooling Layer&lt;/li&gt;
&lt;li&gt;Batch Normalization Layer&lt;/li&gt;
&lt;li&gt;Constant Padding Layer&lt;/li&gt;
&lt;li&gt;Convolutional Layer&lt;/li&gt;
&lt;li&gt;Dropout Layer&lt;/li&gt;
&lt;li&gt;Flatten Layer&lt;/li&gt;
&lt;li&gt;Fully-Connected (Dense) Layer&lt;/li&gt;
&lt;li&gt;Fully-Connected RNN Layer&lt;/li&gt;
&lt;li&gt;Max Pooling Layer&lt;/li&gt;
&lt;li&gt;Reshape Layer&lt;/li&gt;
&lt;li&gt;Up Sampling Layer&lt;/li&gt;
&lt;li&gt;Zero Padding Layer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Model Types
&lt;ul&gt;
&lt;li&gt;&lt;a href="mlfromscratch/examples/convolutional_neural_network.py"&gt;Convolutional Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/examples/multilayer_perceptron.py"&gt;Multilayer Perceptron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/examples/recurrent_neural_network.py"&gt;Recurrent Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h2&gt;
&lt;p&gt;If there's some implementation you would like to see here or if you're just feeling social,
feel free to &lt;a href="mailto:eriklindernoren@gmail.com"&gt;email&lt;/a&gt; me or connect with me on &lt;a href="https://www.linkedin.com/in/eriklindernoren/" rel="nofollow"&gt;LinkedIn&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>eriklindernoren</author><guid isPermaLink="false">https://github.com/eriklindernoren/ML-From-Scratch</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>OUCMachineLearning/OUCML #7 in Python, This week</title><link>https://github.com/OUCMachineLearning/OUCML</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-oucml" class="anchor" aria-hidden="true" href="#oucml"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;OUCML&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/OUCMachineLearning/OUCML/tree/master/One%20Day%20One%20GAN"&gt;ODOG&lt;/a&gt;一天一GAN&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/OUCMachineLearning/OUCML/tree/master/GAN"&gt;GAN&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/OUCMachineLearning/OUCML/tree/master/AutoML"&gt;AUTOML&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;大家编写README.MD文件的时候，可以参考&lt;a href="https://blog.csdn.net/liu537192/article/details/45693529" rel="nofollow"&gt;github上README.md文件如何编写&lt;/a&gt;。&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>OUCMachineLearning</author><guid isPermaLink="false">https://github.com/OUCMachineLearning/OUCML</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>aivivn/Machine-Learning-Yearning-Vietnamese-Translation #8 in Python, This week</title><link>https://github.com/aivivn/Machine-Learning-Yearning-Vietnamese-Translation</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-dự-án-dịch-sách-machine-learning-yearning-andrew-ng-ra-tiếng-việt" class="anchor" aria-hidden="true" href="#dự-án-dịch-sách-machine-learning-yearning-andrew-ng-ra-tiếng-việt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dự án dịch sách &lt;a href="https://www.deeplearning.ai/machine-learning-yearning/" rel="nofollow"&gt;Machine Learning Yearning&lt;/a&gt;, Andrew Ng ra tiếng Việt&lt;/h1&gt;
&lt;p&gt;Nguồn để dịch &lt;a href="https://github.com/ajaymache/machine-learning-yearning"&gt;https://github.com/ajaymache/machine-learning-yearning&lt;/a&gt;. Mặc dù là bản Draft, nội dung bản này cũng đã khá đầy đủ.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-bảng-thuật-ngữ" class="anchor" aria-hidden="true" href="#bảng-thuật-ngữ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bảng thuật ngữ&lt;/h2&gt;
&lt;p&gt;Tất cả các thuật ngữ cần được dịch theo chuẩn trong file &lt;a href="glossary.md"&gt;glossary&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-bản-song-ngữ-tổng-hợp-các-chương-đã-dịch-xong" class="anchor" aria-hidden="true" href="#bản-song-ngữ-tổng-hợp-các-chương-đã-dịch-xong"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bản song ngữ tổng hợp các chương đã dịch xong&lt;/h2&gt;
&lt;p&gt;Các chương đã dịch xong được tổng hợp dưới dạng song ngữ Anh-Việt trong &lt;a href="chapters/all_chapters.md"&gt;file này&lt;/a&gt;. Hầu hết các chương mới qua giai đoạn một -- đảm bảo nghĩa chính xác. Việc trau chuốt ngôn từ sẽ được thực hiện ở giai đoạn hai của mỗi chương.&lt;/p&gt;
&lt;p&gt;Bạn có thể đóng góp bằng cách dịch một chương mới hoặc sửa văn phong trong các chương đã dịch xong giai đoạn một. Hướng dẫn về việc đóng góp có thể được tìm thấy tại &lt;a href="contribution.md"&gt;Làm thế nào để đóng góp vào dự án&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tiến-độ-từng-chương" class="anchor" aria-hidden="true" href="#tiến-độ-từng-chương"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tiến độ từng chương&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Chương&lt;/th&gt;
&lt;th&gt;Tên chương&lt;/th&gt;
&lt;th&gt;Dịch giai đoạn 1&lt;/th&gt;
&lt;th&gt;Giai đoạn 1&lt;/th&gt;
&lt;th&gt;Dịch giai đoạn 2&lt;/th&gt;
&lt;th&gt;Giai đoạn 2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch01.md"&gt;Tại sao cần chiến lược Machine Learning&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2qt2j5I" rel="nofollow"&gt;#40&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2paL9t5" rel="nofollow"&gt;#143&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch02.md"&gt;Cách sử dụng cuốn sách khi làm việc nhóm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2P3wMRW" rel="nofollow"&gt;#54&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch03.md"&gt;Điều kiện tiên quyết và Ký hiệu&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2pG1Yfi" rel="nofollow"&gt;#90&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch04.md"&gt;Quy mô quyết định mô hình machine learning&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2Bqursa" rel="nofollow"&gt;#83&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch05.md"&gt;Tập phát triển và tập kiểm tra&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2Mt4jmV" rel="nofollow"&gt;#82&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch06.md"&gt;Tập phát triển và tập kiểm tra nên có cùng phân phối&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2MxIAKE" rel="nofollow"&gt;#91&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch07.md"&gt;Tập phát triển/kiểm tra cần lớn đến mức nào?&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/35Jetrj" rel="nofollow"&gt;#70&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch08.md"&gt;Thiết lập một phép đo đơn trị làm mục tiêu tối ưu&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2pGMCqX" rel="nofollow"&gt;#80&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch09.md"&gt;Phép đo tối ưu và phép đo thỏa mãn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2VVgJXM" rel="nofollow"&gt;#77&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch10.md"&gt;Xây dựng một tập phát triển và một phép đo sẽ tăng tốc quá trình làm việc&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2WdLYxp" rel="nofollow"&gt;#117&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch11.md"&gt; Khi nào cần thay đổi tập phát triển/kiểm tra và các phép đo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/361NZkJ" rel="nofollow"&gt;#150&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch12.md"&gt;Điều cần nhớ: Thiết lập các tập phát triển và kiểm tra&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2Pe9d9a" rel="nofollow"&gt;#113&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch13.md"&gt;Bạn mong muốn xây dựng một hệ thống phòng chống email rác mới. Nhóm của bạn có rất nhiều ý tưởng:&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2PprDnG" rel="nofollow"&gt;#160&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch14.md"&gt;Phân tích lỗi: đánh giá ý tưởng dựa trên tập phát triển&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2W6QbDa" rel="nofollow"&gt;#140&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch15.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/36g8aMf" rel="nofollow"&gt;#161&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch16.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2MRrGqB" rel="nofollow"&gt;#164&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch17.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2JoQ5RZ" rel="nofollow"&gt;#168&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch18.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/348mZhW" rel="nofollow"&gt;#156&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch19.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2WhQkUc" rel="nofollow"&gt;#169&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch20.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2MSAigt" rel="nofollow"&gt;#172&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch21.md"&gt;Những ví dụ về Độ chệch và Phương sai&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2MSzFn7" rel="nofollow"&gt;#173&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;hoàn thành&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;22&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch22.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bit.ly/2BNdPeH" rel="nofollow"&gt;#175&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;23&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch23.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch24.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch25.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;26&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch26.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;27&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch27.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch28.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;29&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch29.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch30.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch31.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch32.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;33&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch33.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;34&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch34.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;35&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch35.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;36&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch36.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;37&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch37.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;38&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch38.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;39&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch39.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch40.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;41&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch41.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;42&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch42.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;43&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch43.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;44&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch44.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;45&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch45.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;46&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch46.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;47&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch47.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;48&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch48.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;49&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch49.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;50&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch50.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;51&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch51.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;52&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch52.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;53&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch53.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;54&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch54.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;55&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch55.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;56&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch56.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;57&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch57.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;58&lt;/td&gt;
&lt;td&gt;&lt;a href="chapters/ch58.md"&gt;chưa có tên&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>aivivn</author><guid isPermaLink="false">https://github.com/aivivn/Machine-Learning-Yearning-Vietnamese-Translation</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>ownthink/KnowledgeGraphData #9 in Python, This week</title><link>https://github.com/ownthink/KnowledgeGraphData</link><description>&lt;p&gt;&lt;i&gt;史上最大规模1.4亿中文知识图谱开源下载&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1 align="center"&gt;&lt;a id="user-content-史上最大规模14亿中文知识图谱开源下载" class="anchor" aria-hidden="true" href="#史上最大规模14亿中文知识图谱开源下载"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;史上最大规模1.4亿中文知识图谱开源下载&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/kg.png"&gt;&lt;img src="img/kg.png" alt="知识图谱" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;知识就是力量，知识图谱是人工智能新时代的产物，简单地说知识图谱就是通过关联关系将知识组成网状的结构，然后我们的人工智能可以通过这个图谱来认识其代表的这一个现实事件，这个事件可以是现实，也可以是虚构的。&lt;/p&gt;
&lt;p&gt;知识图谱可以应用于机器人问答系统，知识推荐等等，下图为知识图谱在机器人上的应用。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/bot.png"&gt;&lt;img src="img/bot.png" alt="机器人" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本次ownthink开源了史上最大规模的中文知识图谱，数据是以（实体、属性、值），（实体、关系、实体）混合的形式组织，数据格式采用csv格式，下载链接见文末。&lt;/p&gt;
&lt;p&gt;解压后查看知识图谱规模：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ wc -l ownthink_v2.csv
140919781 ownthink_v2.csv&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;查看知识图谱数据：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ head ownthink_v2.csv
实体,属性,值
胶饴,描述,别名: 饴糖、畅糖、畅、软糖。
词条,描述,词条（拼音：cí tiáo）也叫词目，是辞书学用语，指收列的词语及其释文。
词条,标签,文化
红色食品,描述,红色食品是指食品为红色、橙红色或棕红色的食品。
红色食品,中文名,红色食品
红色食品,是否含防腐剂,否
红色食品,主要食用功效,预防感冒，缓解疲劳
红色食品,适宜人群,全部人群
红色食品,用途,增强表皮细胞再生和防止皮肤衰老&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;使用python进行读取测试：&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; sys
&lt;span class="pl-k"&gt;import&lt;/span&gt; csv

&lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-c1"&gt;open&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ownthink_v2.csv&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;r&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;encoding&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;utf8&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-k"&gt;as&lt;/span&gt; fin:
  reader &lt;span class="pl-k"&gt;=&lt;/span&gt; csv.reader(fin)
  &lt;span class="pl-k"&gt;for&lt;/span&gt; index, read &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;enumerate&lt;/span&gt;(reader):
    &lt;span class="pl-c1"&gt;print&lt;/span&gt;(read)
    
    &lt;span class="pl-k"&gt;if&lt;/span&gt; index &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;:
      sys.exit(&lt;span class="pl-c1"&gt;0&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;运行以上脚本输出结果：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;实体&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;属性&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;值&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;胶饴&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;描述&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;别名: 饴糖、畅糖、畅、软糖。&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;词条&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;描述&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;词条（拼音：cí tiáo）也叫词目，是辞书学用语，指收列的词语及其释文。&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;词条&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;标签&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;文化&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;描述&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品是指食品为红色、橙红色或棕红色的食品。&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;中文名&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;是否含防腐剂&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;否&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;主要食用功效&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;预防感冒，缓解疲劳&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;适宜人群&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;全部人群&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;用途&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;增强表皮细胞再生和防止皮肤衰老&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;标签&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;非科学&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;标签&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;生活&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;数据下载方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;关注思知机器人回复【数据下载】获取下载链接&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;百度网盘（链接: &lt;a href="https://pan.baidu.com/s/1LZjs9Dsta0yD9NH-1y0sAw" rel="nofollow"&gt;https://pan.baidu.com/s/1LZjs9Dsta0yD9NH-1y0sAw&lt;/a&gt; 提取码: 3hpp ）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注：解压密码是：&lt;a href="https://www.ownthink.com/" rel="nofollow"&gt;https://www.ownthink.com/&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ownthink</author><guid isPermaLink="false">https://github.com/ownthink/KnowledgeGraphData</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>vinta/awesome-python #10 in Python, This week</title><link>https://github.com/vinta/awesome-python</link><description>&lt;p&gt;&lt;i&gt;A curated list of awesome Python frameworks, libraries, software and resources&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-awesome-python-" class="anchor" aria-hidden="true" href="#awesome-python-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Awesome Python &lt;a href="https://github.com/sindresorhus/awesome"&gt;&lt;img src="https://camo.githubusercontent.com/13c4e50d88df7178ae1882a203ed57b641674f94/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667" alt="Awesome" data-canonical-src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;A curated list of awesome Python frameworks, libraries, software and resources.&lt;/p&gt;
&lt;p&gt;Inspired by &lt;a href="https://github.com/ziadoz/awesome-php"&gt;awesome-php&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#awesome-python"&gt;Awesome Python&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#admin-panels"&gt;Admin Panels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#algorithms-and-design-patterns"&gt;Algorithms and Design Patterns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#audio"&gt;Audio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#authentication"&gt;Authentication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#build-tools"&gt;Build Tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#built-in-classes-enhancement"&gt;Built-in Classes Enhancement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#caching"&gt;Caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#chatops-tools"&gt;ChatOps Tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cms"&gt;CMS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#code-analysis"&gt;Code Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#command-line-interface-development"&gt;Command-line Interface Development&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#command-line-tools"&gt;Command-line Tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#compatibility"&gt;Compatibility&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#computer-vision"&gt;Computer Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#concurrency-and-parallelism"&gt;Concurrency and Parallelism&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cryptography"&gt;Cryptography&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data-analysis"&gt;Data Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data-validation"&gt;Data Validation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data-visualization"&gt;Data Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#database"&gt;Database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#database-drivers"&gt;Database Drivers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#date-and-time"&gt;Date and Time&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#debugging-tools"&gt;Debugging Tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#deep-learning"&gt;Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#devops-tools"&gt;DevOps Tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#distributed-computing"&gt;Distributed Computing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#distribution"&gt;Distribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#downloader"&gt;Downloader&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#e-commerce"&gt;E-commerce&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#editor-plugins-and-ides"&gt;Editor Plugins and IDEs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#email"&gt;Email&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#environment-management"&gt;Environment Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#files"&gt;Files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#foreign-function-interface"&gt;Foreign Function Interface&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#forms"&gt;Forms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#functional-programming"&gt;Functional Programming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#game-development"&gt;Game Development&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#geolocation"&gt;Geolocation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#gui-development"&gt;GUI Development&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#hardware"&gt;Hardware&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#html-manipulation"&gt;HTML Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#http-clients"&gt;HTTP Clients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#image-processing"&gt;Image Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#implementations"&gt;Implementations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#interactive-interpreter"&gt;Interactive Interpreter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#internationalization"&gt;Internationalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#job-scheduler"&gt;Job Scheduler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#logging"&gt;Logging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#machine-learning"&gt;Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#miscellaneous"&gt;Miscellaneous&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#natural-language-processing"&gt;Natural Language Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#network-virtualization"&gt;Network Virtualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#networking"&gt;Networking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#news-feed"&gt;News Feed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#orm"&gt;ORM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#package-management"&gt;Package Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#package-repositories"&gt;Package Repositories&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#permissions"&gt;Permissions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#processes"&gt;Processes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#queue"&gt;Queue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#recommender-systems"&gt;Recommender Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#restful-api"&gt;RESTful API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#robotics"&gt;Robotics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rpc-servers"&gt;RPC Servers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#science"&gt;Science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#search"&gt;Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#serialization"&gt;Serialization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#serverless-frameworks"&gt;Serverless Frameworks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#specific-formats-processing"&gt;Specific Formats Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#static-site-generator"&gt;Static Site Generator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tagging"&gt;Tagging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#template-engine"&gt;Template Engine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#testing"&gt;Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#text-processing"&gt;Text Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#third-party-apis"&gt;Third-party APIs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#url-manipulation"&gt;URL Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#video"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#web-asset-management"&gt;Web Asset Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#web-content-extracting"&gt;Web Content Extracting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#web-crawling"&gt;Web Crawling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#web-frameworks"&gt;Web Frameworks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#websocket"&gt;WebSocket&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wsgi-servers"&gt;WSGI Servers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#services"&gt;Services&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#code-quality"&gt;Code Quality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#continuous-integration"&gt;Continuous Integration&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#resources"&gt;Resources&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#podcasts"&gt;Podcasts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#twitter"&gt;Twitter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#websites"&gt;Websites&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#weekly"&gt;Weekly&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-admin-panels" class="anchor" aria-hidden="true" href="#admin-panels"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Admin Panels&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for administrative interfaces.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ajenti/ajenti"&gt;ajenti&lt;/a&gt; - The admin panel your servers deserve.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://grappelliproject.com/" rel="nofollow"&gt;django-grappelli&lt;/a&gt; - A jazzy skin for the Django Admin-Interface.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/geex-arts/django-jet"&gt;django-jet&lt;/a&gt; - Modern responsive template for the Django admin interface with improved functionality.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://djangosuit.com/" rel="nofollow"&gt;django-suit&lt;/a&gt; - Alternative Django Admin-Interface (free only for Non-commercial use).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sshwsfc/xadmin"&gt;django-xadmin&lt;/a&gt; - Drop-in replacement of Django admin comes with lots of goodies.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jet-admin/jet-bridge"&gt;jet-bridge&lt;/a&gt; - Admin panel framework for any application with nice UI (ex Jet Django)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/flask-admin/flask-admin"&gt;flask-admin&lt;/a&gt; - Simple and extensible administrative interface framework for Flask.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mher/flower"&gt;flower&lt;/a&gt; - Real-time monitor and web admin for Celery.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wooey/wooey"&gt;wooey&lt;/a&gt; - A Django app which creates automatic web UIs for Python scripts.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-algorithms-and-design-patterns" class="anchor" aria-hidden="true" href="#algorithms-and-design-patterns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Algorithms and Design Patterns&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Python implementation of algorithms and design patterns.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/keon/algorithms"&gt;algorithms&lt;/a&gt; - Minimal examples of data structures and algorithms in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tylerlaberge/PyPattyrn"&gt;PyPattyrn&lt;/a&gt; - A simple yet effective library for implementing common design patterns.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/faif/python-patterns"&gt;python-patterns&lt;/a&gt; - A collection of design patterns in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/grantjenks/python-sortedcontainers"&gt;sortedcontainers&lt;/a&gt; - Fast, pure-Python implementation of SortedList, SortedDict, and SortedSet types.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-audio" class="anchor" aria-hidden="true" href="#audio"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Audio&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for manipulating audio and its metadata.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Audio
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/beetbox/audioread"&gt;audioread&lt;/a&gt; - Cross-library (GStreamer + Core Audio + MAD + FFmpeg) audio decoding.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/worldveil/dejavu"&gt;dejavu&lt;/a&gt; - Audio fingerprinting and recognition.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://bspaans.github.io/python-mingus/" rel="nofollow"&gt;mingus&lt;/a&gt; - An advanced music theory and notation package with MIDI file and playback support.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tyiannak/pyAudioAnalysis"&gt;pyAudioAnalysis&lt;/a&gt; - Audio feature extraction, classification, segmentation and applications.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jiaaro/pydub"&gt;pydub&lt;/a&gt; - Manipulate audio with a simple and easy high level interface.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Parisson/TimeSide"&gt;TimeSide&lt;/a&gt; - Open web audio processing framework.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Metadata
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/beetbox/beets"&gt;beets&lt;/a&gt; - A music library manager and &lt;a href="https://musicbrainz.org/" rel="nofollow"&gt;MusicBrainz&lt;/a&gt; tagger.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nicfit/eyeD3"&gt;eyeD3&lt;/a&gt; - A tool for working with audio files, specifically MP3 files containing ID3 metadata.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/quodlibet/mutagen"&gt;mutagen&lt;/a&gt; - A Python module to handle audio metadata.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/devsnd/tinytag"&gt;tinytag&lt;/a&gt; - A library for reading music meta data of MP3, OGG, FLAC and Wave files.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-authentication" class="anchor" aria-hidden="true" href="#authentication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authentication&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for implementing authentications schemes.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OAuth
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/lepture/authlib"&gt;authlib&lt;/a&gt; - JavaScript Object Signing and Encryption draft implementation.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pennersr/django-allauth"&gt;django-allauth&lt;/a&gt; - Authentication app for Django that "just works."&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/evonove/django-oauth-toolkit"&gt;django-oauth-toolkit&lt;/a&gt; - OAuth 2 goodies for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/idan/oauthlib"&gt;oauthlib&lt;/a&gt; - A generic and thorough implementation of the OAuth request-signing logic.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/joestump/python-oauth2"&gt;python-oauth2&lt;/a&gt; - A fully tested, abstract interface to creating OAuth clients and servers.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/omab/python-social-auth"&gt;python-social-auth&lt;/a&gt; - An easy-to-setup social authentication mechanism.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;JWT
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jpadilla/pyjwt"&gt;pyjwt&lt;/a&gt; - JSON Web Token implementation in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mpdavis/python-jose/"&gt;python-jose&lt;/a&gt; - A JOSE implementation in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/davedoesdev/python-jwt"&gt;python-jwt&lt;/a&gt; - A module for generating and verifying JSON Web Tokens.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-build-tools" class="anchor" aria-hidden="true" href="#build-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Build Tools&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Compile software from source code.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.yoctoproject.org/docs/1.6/bitbake-user-manual/bitbake-user-manual.html" rel="nofollow"&gt;BitBake&lt;/a&gt; - A make-like build tool for embedded Linux.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.buildout.org/en/latest/" rel="nofollow"&gt;buildout&lt;/a&gt; - A build system for creating, assembling and deploying applications from multiple parts.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/platformio/platformio-core"&gt;PlatformIO&lt;/a&gt; - A console tool to build code with different development platforms.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pybuilder/pybuilder"&gt;pybuilder&lt;/a&gt; - A continuous build tool written in pure Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.scons.org/" rel="nofollow"&gt;SCons&lt;/a&gt; - A software construction tool.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-built-in-classes-enhancement" class="anchor" aria-hidden="true" href="#built-in-classes-enhancement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Built-in Classes Enhancement&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for enhancing Python built-in classes.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/dataclasses.html" rel="nofollow"&gt;dataclasses&lt;/a&gt; - (Python standard library) Data classes.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/python-attrs/attrs"&gt;attrs&lt;/a&gt; - Replacement for &lt;code&gt;__init__&lt;/code&gt;, &lt;code&gt;__eq__&lt;/code&gt;, &lt;code&gt;__repr__&lt;/code&gt;, etc. boilerplate in class definitions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jab/bidict"&gt;bidict&lt;/a&gt; - Efficient, Pythonic bidirectional map data structures and related functionality..&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cdgriffith/Box"&gt;Box&lt;/a&gt; - Python dictionaries with advanced dot notation access.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/carlosescri/DottedDict"&gt;DottedDict&lt;/a&gt; - A library that provides a method of accessing lists and dicts with a dotted path notation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-cms" class="anchor" aria-hidden="true" href="#cms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CMS&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Content Management Systems.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://wagtail.io/" rel="nofollow"&gt;wagtail&lt;/a&gt; - A Django content management system.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.django-cms.org/en/" rel="nofollow"&gt;django-cms&lt;/a&gt; - An Open source enterprise CMS based on the Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/feincms/feincms"&gt;feincms&lt;/a&gt; - One of the most advanced Content Management Systems built on Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kotti/Kotti"&gt;Kotti&lt;/a&gt; - A high-level, Pythonic web application framework built on Pyramid.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/stephenmcd/mezzanine"&gt;mezzanine&lt;/a&gt; - A powerful, consistent, and flexible content management platform.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://plone.org/" rel="nofollow"&gt;plone&lt;/a&gt; - A CMS built on top of the open source application server Zope.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rochacbruno/quokka"&gt;quokka&lt;/a&gt; - Flexible, extensible, small CMS powered by Flask and MongoDB.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-caching" class="anchor" aria-hidden="true" href="#caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Caching&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for caching data.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/bbangert/beaker"&gt;beaker&lt;/a&gt; - A WSGI middleware for sessions and caching.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/django-cache-machine/django-cache-machine"&gt;django-cache-machine&lt;/a&gt; - Automatic caching and invalidation for Django models.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Suor/django-cacheops"&gt;django-cacheops&lt;/a&gt; - A slick ORM cache with automatic granular event-driven invalidation.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dogpilecache.readthedocs.io/en/latest/" rel="nofollow"&gt;dogpile.cache&lt;/a&gt; - dogpile.cache is next generation replacement for Beaker made by same authors.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/HermesCache/" rel="nofollow"&gt;HermesCache&lt;/a&gt; - Python caching library with tag-based invalidation and dogpile effect prevention.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lericson/pylibmc"&gt;pylibmc&lt;/a&gt; - A Python wrapper around the &lt;a href="https://libmemcached.org/libMemcached.html" rel="nofollow"&gt;libmemcached&lt;/a&gt; interface.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.grantjenks.com/docs/diskcache/" rel="nofollow"&gt;python-diskcache&lt;/a&gt; - SQLite and file backed cache backend with faster lookups than memcached and redis.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-chatops-tools" class="anchor" aria-hidden="true" href="#chatops-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ChatOps Tools&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for chatbot development.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/errbotio/errbot/"&gt;errbot&lt;/a&gt; - The easiest and most popular chatbot to implement ChatOps.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-code-analysis" class="anchor" aria-hidden="true" href="#code-analysis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code Analysis&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Tools of static analysis, linters and code quality checkers. Also see &lt;a href="https://github.com/mre/awesome-static-analysis"&gt;awesome-static-analysis&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Code Analysis
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/coala/coala/"&gt;coala&lt;/a&gt; - Language independent and easily extendable code analysis application.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/scottrogowski/code2flow"&gt;code2flow&lt;/a&gt; - Turn your Python and JavaScript code into DOT flowcharts.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PyCQA/prospector"&gt;prospector&lt;/a&gt; - A tool to analyse Python code.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gak/pycallgraph"&gt;pycallgraph&lt;/a&gt; - A library that visualises the flow (call graph) of your Python application.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Code Linters
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/flake8/" rel="nofollow"&gt;flake8&lt;/a&gt; - A wrapper around &lt;code&gt;pycodestyle&lt;/code&gt;, &lt;code&gt;pyflakes&lt;/code&gt; and McCabe.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/DmytroLitvinov/awesome-flake8-extensions"&gt;awesome-flake8-extensions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.pylint.org/" rel="nofollow"&gt;pylint&lt;/a&gt; - A fully customizable source code analyzer.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/klen/pylama"&gt;pylama&lt;/a&gt; - A code audit tool for Python and JavaScript.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wemake-services/wemake-python-styleguide"&gt;wemake-python-styleguide&lt;/a&gt; - The strictest and most opinionated python linter ever.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Code Formatters
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/python/black"&gt;black&lt;/a&gt; - The uncompromising Python code formatter.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/yapf"&gt;yapf&lt;/a&gt; - Yet another Python code formatter from Google.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Static Type Checkers, also see &lt;a href="https://github.com/typeddjango/awesome-python-typing"&gt;awesome-python-typing&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mypy-lang.org/" rel="nofollow"&gt;mypy&lt;/a&gt; - Check variable types during compile time.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebook/pyre-check"&gt;pyre-check&lt;/a&gt; - Performant type checking.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Static Type Annotations Generators
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Instagram/MonkeyType"&gt;MonkeyType&lt;/a&gt; - A system for Python that generates static type annotations by collecting runtime types&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-command-line-interface-development" class="anchor" aria-hidden="true" href="#command-line-interface-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Command-line Interface Development&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for building command-line applications.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Command-line Application Development
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://builtoncement.com/" rel="nofollow"&gt;cement&lt;/a&gt; - CLI Application Framework for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://click.pocoo.org/dev/" rel="nofollow"&gt;click&lt;/a&gt; - A package for creating beautiful command line interfaces in a composable way.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.openstack.org/developer/cliff/" rel="nofollow"&gt;cliff&lt;/a&gt; - A framework for creating command-line programs with multi-level commands.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/clint"&gt;clint&lt;/a&gt; - Python Command-line Application Tools.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docopt.org/" rel="nofollow"&gt;docopt&lt;/a&gt; - Pythonic command line arguments parser.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/python-fire"&gt;python-fire&lt;/a&gt; - A library for creating command line interfaces from absolutely any Python object.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jonathanslenders/python-prompt-toolkit"&gt;python-prompt-toolkit&lt;/a&gt; - A library for building powerful interactive command lines.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Terminal Rendering
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/peterbrittain/asciimatics"&gt;asciimatics&lt;/a&gt; - A package to create full-screen text UIs (from interactive forms to ASCII animations).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/glamp/bashplotlib"&gt;bashplotlib&lt;/a&gt; - Making basic plots in the terminal.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/colorama/" rel="nofollow"&gt;colorama&lt;/a&gt; - Cross-platform colored terminal text.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tqdm/tqdm"&gt;tqdm&lt;/a&gt; - Fast, extensible progress bar for loops and CLI.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-command-line-tools" class="anchor" aria-hidden="true" href="#command-line-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Command-line Tools&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Useful CLI-based tools for productivity.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Productivity Tools
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/audreyr/cookiecutter"&gt;cookiecutter&lt;/a&gt; - A command-line utility that creates projects from cookiecutters (project templates).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sloria/doitlive"&gt;doitlive&lt;/a&gt; - A tool for live presentations in the terminal.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gleitz/howdoi"&gt;howdoi&lt;/a&gt; - Instant coding answers via the command line.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebook/PathPicker"&gt;PathPicker&lt;/a&gt; - Select files out of bash output.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mooz/percol"&gt;percol&lt;/a&gt; - Adds flavor of interactive selection to the traditional pipe concept on UNIX.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nvbn/thefuck"&gt;thefuck&lt;/a&gt; - Correcting your previous console command.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tony/tmuxp"&gt;tmuxp&lt;/a&gt; - A &lt;a href="https://github.com/tmux/tmux"&gt;tmux&lt;/a&gt; session manager.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/timofurrer/try"&gt;try&lt;/a&gt; - A dead simple CLI to try out python packages - it's never been easier.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CLI Enhancements
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jakubroztocil/httpie"&gt;httpie&lt;/a&gt; - A command line HTTP client, a user-friendly cURL replacement.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cloudnativelabs/kube-shell"&gt;kube-shell&lt;/a&gt; - An integrated shell for working with the Kubernetes CLI.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dbcli/mycli"&gt;mycli&lt;/a&gt; - A Terminal Client for MySQL with AutoCompletion and Syntax Highlighting.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dbcli/pgcli"&gt;pgcli&lt;/a&gt; - Postgres CLI with autocompletion and syntax highlighting.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/saws"&gt;saws&lt;/a&gt; - A Supercharged &lt;a href="https://github.com/aws/aws-cli"&gt;aws-cli&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-compatibility" class="anchor" aria-hidden="true" href="#compatibility"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Compatibility&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for migrating from Python 2 to 3.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://python-future.org/index.html" rel="nofollow"&gt;python-future&lt;/a&gt; - The missing compatibility layer between Python 2 and Python 3.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mitsuhiko/python-modernize"&gt;python-modernize&lt;/a&gt; - Modernizes Python code for eventual Python 3 migration.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/six/" rel="nofollow"&gt;six&lt;/a&gt; - Python 2 and 3 compatibility utilities.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-computer-vision" class="anchor" aria-hidden="true" href="#computer-vision"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Computer Vision&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for computer vision.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://opencv.org/" rel="nofollow"&gt;OpenCV&lt;/a&gt; - Open Source Computer Vision Library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/madmaze/pytesseract"&gt;pytesseract&lt;/a&gt; - Another wrapper for &lt;a href="https://github.com/tesseract-ocr"&gt;Google Tesseract OCR&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://simplecv.org/" rel="nofollow"&gt;SimpleCV&lt;/a&gt; - An open source framework for building computer vision applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-concurrency-and-parallelism" class="anchor" aria-hidden="true" href="#concurrency-and-parallelism"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Concurrency and Parallelism&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for concurrent and parallel execution. Also see &lt;a href="https://github.com/timofurrer/awesome-asyncio"&gt;awesome-asyncio&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow"&gt;concurrent.futures&lt;/a&gt; - (Python standard library) A high-level interface for asynchronously executing callables.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow"&gt;multiprocessing&lt;/a&gt; - (Python standard library) Process-based parallelism.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://eventlet.net/" rel="nofollow"&gt;eventlet&lt;/a&gt; - Asynchronous framework with WSGI support.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.gevent.org/" rel="nofollow"&gt;gevent&lt;/a&gt; - A coroutine-based Python networking library that uses &lt;a href="https://github.com/python-greenlet/greenlet"&gt;greenlet&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MagicStack/uvloop"&gt;uvloop&lt;/a&gt; - Ultra fast implementation of &lt;code&gt;asyncio&lt;/code&gt; event loop on top of &lt;code&gt;libuv&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/soravux/scoop"&gt;scoop&lt;/a&gt; - Scalable Concurrent Operations in Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-configuration" class="anchor" aria-hidden="true" href="#configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuration&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for storing and parsing configuration options.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/DiffSK/configobj"&gt;configobj&lt;/a&gt; - INI file parser with validation.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/configparser.html" rel="nofollow"&gt;configparser&lt;/a&gt; - (Python standard library) INI file parser.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://profig.readthedocs.io/en/default/" rel="nofollow"&gt;profig&lt;/a&gt; - Config from multiple formats with value conversion.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/henriquebastos/python-decouple"&gt;python-decouple&lt;/a&gt; - Strict separation of settings from code.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-cryptography" class="anchor" aria-hidden="true" href="#cryptography"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cryptography&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cryptography.io/en/latest/" rel="nofollow"&gt;cryptography&lt;/a&gt; - A package designed to expose cryptographic primitives and recipes to Python developers.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/paramiko/paramiko"&gt;paramiko&lt;/a&gt; - The leading native Python SSHv2 protocol library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://passlib.readthedocs.io/en/stable/" rel="nofollow"&gt;passlib&lt;/a&gt; - Secure password storage/hashing library, very high level.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pyca/pynacl"&gt;pynacl&lt;/a&gt; - Python binding to the Networking and Cryptography (NaCl) library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-data-analysis" class="anchor" aria-hidden="true" href="#data-analysis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Analysis&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for data analyzing.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/blaze/blaze"&gt;Blaze&lt;/a&gt; - NumPy and Pandas interface to Big Data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mining/mining"&gt;Open Mining&lt;/a&gt; - Business Intelligence (BI) in Pandas interface.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://orange.biolab.si/" rel="nofollow"&gt;Orange&lt;/a&gt; - Data mining, data visualization, analysis and machine learning through visual programming or scripts.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pandas.pydata.org/" rel="nofollow"&gt;Pandas&lt;/a&gt; - A library providing high-performance, easy-to-use data structures and data analysis tools.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ironmussa/Optimus"&gt;Optimus&lt;/a&gt; - Agile Data Science Workflows made easy with PySpark.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-data-validation" class="anchor" aria-hidden="true" href="#data-validation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Validation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for validating data. Used for forms in many cases.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pyeve/cerberus"&gt;Cerberus&lt;/a&gt; - A lightweight and extensible data validation library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.pylonsproject.org/projects/colander/en/latest/" rel="nofollow"&gt;colander&lt;/a&gt; - Validating and deserializing data obtained via XML, JSON, an HTML form post.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Julian/jsonschema"&gt;jsonschema&lt;/a&gt; - An implementation of &lt;a href="http://json-schema.org/" rel="nofollow"&gt;JSON Schema&lt;/a&gt; for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/keleshev/schema"&gt;schema&lt;/a&gt; - A library for validating Python data structures.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/schematics/schematics"&gt;Schematics&lt;/a&gt; - Data Structure Validation.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/podio/valideer"&gt;valideer&lt;/a&gt; - Lightweight extensible data validation and adaptation library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/alecthomas/voluptuous"&gt;voluptuous&lt;/a&gt; - A Python data validation library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-data-visualization" class="anchor" aria-hidden="true" href="#data-visualization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Visualization&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for visualizing data. Also see &lt;a href="https://github.com/sorrycc/awesome-javascript#data-visualization"&gt;awesome-javascript&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/altair-viz/altair"&gt;Altair&lt;/a&gt; - Declarative statistical visualization library for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bokeh/bokeh"&gt;Bokeh&lt;/a&gt; - Interactive Web Plotting for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bloomberg/bqplot"&gt;bqplot&lt;/a&gt; - Interactive Plotting Library for the Jupyter Notebook&lt;/li&gt;
&lt;li&gt;&lt;a href="https://plot.ly/products/dash/" rel="nofollow"&gt;Dash&lt;/a&gt; - Built on top of Flask, React and Plotly aimed at analytical web applications.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Acrotrend/awesome-dash"&gt;awesome-dash&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/has2k1/plotnine"&gt;plotnine&lt;/a&gt; - A grammar of graphics for Python based on ggplot2.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://matplotlib.org/" rel="nofollow"&gt;Matplotlib&lt;/a&gt; - A Python 2D plotting library.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pygal.org/en/latest/" rel="nofollow"&gt;Pygal&lt;/a&gt; - A Python SVG Charts Creator.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/pygraphviz/" rel="nofollow"&gt;PyGraphviz&lt;/a&gt; - Python interface to &lt;a href="http://www.graphviz.org/" rel="nofollow"&gt;Graphviz&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pyqtgraph.org/" rel="nofollow"&gt;PyQtGraph&lt;/a&gt; - Interactive and realtime 2D/3D/Image plotting and science/engineering widgets.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mwaskom/seaborn"&gt;Seaborn&lt;/a&gt; - Statistical data visualization using Matplotlib.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/vispy/vispy"&gt;VisPy&lt;/a&gt; - High-performance scientific visualization based on OpenGL.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-database" class="anchor" aria-hidden="true" href="#database"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Databases implemented in Python.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/patx/pickledb"&gt;pickleDB&lt;/a&gt; - A simple and lightweight key-value store for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/msiemens/tinydb"&gt;tinydb&lt;/a&gt; - A tiny, document-oriented database.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zopefoundation/ZODB"&gt;ZODB&lt;/a&gt; - A native object database for Python. A key-value and object graph database.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-database-drivers" class="anchor" aria-hidden="true" href="#database-drivers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database Drivers&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for connecting and operating databases.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MySQL - &lt;a href="http://shlomi-noach.github.io/awesome-mysql/" rel="nofollow"&gt;awesome-mysql&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/PyMySQL/mysqlclient-python"&gt;mysqlclient&lt;/a&gt; - MySQL connector with Python 3 support (&lt;a href="https://sourceforge.net/projects/mysql-python/" rel="nofollow"&gt;mysql-python&lt;/a&gt; fork).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PyMySQL/PyMySQL"&gt;PyMySQL&lt;/a&gt; - A pure Python MySQL driver compatible to mysql-python.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PostgreSQL - &lt;a href="https://github.com/dhamaniasad/awesome-postgres"&gt;awesome-postgres&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://initd.org/psycopg/" rel="nofollow"&gt;psycopg2&lt;/a&gt; - The most popular PostgreSQL adapter for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gmr/queries"&gt;queries&lt;/a&gt; - A wrapper of the psycopg2 library for interacting with PostgreSQL.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Other Relational Databases
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.pymssql.org/en/latest/" rel="nofollow"&gt;pymssql&lt;/a&gt; - A simple database interface to Microsoft SQL Server.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NoSQL Databases
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/datastax/python-driver"&gt;cassandra-driver&lt;/a&gt; - The Python Driver for Apache Cassandra.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wbolster/happybase"&gt;happybase&lt;/a&gt; - A developer-friendly library for Apache HBase.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dpkp/kafka-python"&gt;kafka-python&lt;/a&gt; - The Python client for Apache Kafka.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://py2neo.org/" rel="nofollow"&gt;py2neo&lt;/a&gt; - Python wrapper client for Neo4j's restful interface.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mongodb/mongo-python-driver"&gt;pymongo&lt;/a&gt; - The official Python client for MongoDB.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/andymccurdy/redis-py"&gt;redis-py&lt;/a&gt; - The Python client for Redis.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Asynchronous Clients
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/mongodb/motor"&gt;motor&lt;/a&gt; - The async Python driver for MongoDB.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/driftx/Telephus"&gt;Telephus&lt;/a&gt; - Twisted based client for Cassandra.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wulczer/txpostgres"&gt;txpostgres&lt;/a&gt; - Twisted based asynchronous driver for PostgreSQL.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/deldotdr/txRedis"&gt;txRedis&lt;/a&gt; - Twisted based client for Redis.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-date-and-time" class="anchor" aria-hidden="true" href="#date-and-time"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Date and Time&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with dates and times.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/KoffeinFlummi/Chronyk"&gt;Chronyk&lt;/a&gt; - A Python 3 library for parsing human-written times and dates.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dateutil/dateutil"&gt;dateutil&lt;/a&gt; - Extensions to the standard Python &lt;a href="https://docs.python.org/3/library/datetime.html" rel="nofollow"&gt;datetime&lt;/a&gt; module.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/myusuf3/delorean/"&gt;delorean&lt;/a&gt; - A library for clearing up the inconvenient truths that arise dealing with datetimes.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zachwill/moment"&gt;moment&lt;/a&gt; - A Python library for dealing with dates/times. Inspired by &lt;a href="http://momentjs.com/" rel="nofollow"&gt;Moment.js&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sdispater/pendulum"&gt;Pendulum&lt;/a&gt; - Python datetimes made easy.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/shinux/PyTime"&gt;PyTime&lt;/a&gt; - An easy-to-use Python module which aims to operate date/time/datetime by string.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://launchpad.net/pytz" rel="nofollow"&gt;pytz&lt;/a&gt; - World timezone definitions, modern and historical. Brings the &lt;a href="https://en.wikipedia.org/wiki/Tz_database" rel="nofollow"&gt;tz database&lt;/a&gt; into Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dirn/When.py"&gt;when.py&lt;/a&gt; - Providing user-friendly functions to help perform common date and time actions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/maya"&gt;maya&lt;/a&gt; - Datetimes for Humans.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-debugging-tools" class="anchor" aria-hidden="true" href="#debugging-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Debugging Tools&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for debugging code.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pdb-like Debugger
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/gotcha/ipdb"&gt;ipdb&lt;/a&gt; - IPython-enabled &lt;a href="https://docs.python.org/3/library/pdb.html" rel="nofollow"&gt;pdb&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/antocuni/pdb"&gt;pdb++&lt;/a&gt; - Another drop-in replacement for pdb.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/inducer/pudb"&gt;pudb&lt;/a&gt; - A full-screen, console-based Python debugger.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kozea/wdb"&gt;wdb&lt;/a&gt; - An improbable web debugger through WebSockets.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tracing
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/khamidou/lptrace"&gt;lptrace&lt;/a&gt; - &lt;a href="http://man7.org/linux/man-pages/man1/strace.1.html" rel="nofollow"&gt;strace&lt;/a&gt; for Python programs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ionelmc/python-manhole"&gt;manhole&lt;/a&gt; - Debugging UNIX socket connections and present the stacktraces for all threads and an interactive prompt.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/pyringe"&gt;pyringe&lt;/a&gt; - Debugger capable of attaching to and injecting code into Python processes.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ionelmc/python-hunter"&gt;python-hunter&lt;/a&gt; - A flexible code tracing toolkit.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Profiler
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/rkern/line_profiler"&gt;line_profiler&lt;/a&gt; - Line-by-line profiling.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fabianp/memory_profiler"&gt;memory_profiler&lt;/a&gt; - Monitor Memory usage of Python code.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/what-studio/profiling"&gt;profiling&lt;/a&gt; - An interactive Python profiler.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/benfred/py-spy"&gt;py-spy&lt;/a&gt; - A sampling profiler for Python programs. Written in Rust.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/uber/pyflame"&gt;pyflame&lt;/a&gt; - A ptracing profiler For Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nvdv/vprof"&gt;vprof&lt;/a&gt; - Visual Python profiler.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Others
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/gruns/icecream"&gt;icecream&lt;/a&gt; - Inspect variables, expressions, and program execution with a single, simple function call.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jazzband/django-debug-toolbar"&gt;django-debug-toolbar&lt;/a&gt; - Display various debug information for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dcramer/django-devserver"&gt;django-devserver&lt;/a&gt; - A drop-in replacement for Django's runserver.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mgood/flask-debugtoolbar"&gt;flask-debugtoolbar&lt;/a&gt; - A port of the django-debug-toolbar to flask.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/eliben/pyelftools"&gt;pyelftools&lt;/a&gt; - Parsing and analyzing ELF files and DWARF debugging information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-deep-learning" class="anchor" aria-hidden="true" href="#deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Frameworks for Neural Networks and Deep Learning. Also see &lt;a href="https://github.com/ChristosChristofidis/awesome-deep-learning"&gt;awesome-deep-learning&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/BVLC/caffe"&gt;caffe&lt;/a&gt; - A fast open framework for deep learning..&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/keras-team/keras"&gt;keras&lt;/a&gt; - A high-level neural networks library and capable of running on top of either TensorFlow or Theano.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dmlc/mxnet"&gt;mxnet&lt;/a&gt; - A deep learning framework designed for both efficiency and flexibility.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pytorch/pytorch"&gt;pytorch&lt;/a&gt; - Tensors and Dynamic neural networks in Python with strong GPU acceleration.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/SerpentAI/SerpentAI"&gt;SerpentAI&lt;/a&gt; - Game agent framework. Use any video game as a deep learning sandbox.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tensorflow"&gt;tensorflow&lt;/a&gt; - The most popular Deep Learning framework created by Google.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Theano/Theano"&gt;Theano&lt;/a&gt; - A library for fast numerical computation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-devops-tools" class="anchor" aria-hidden="true" href="#devops-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DevOps Tools&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Software and libraries for DevOps.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ansible/ansible"&gt;ansible&lt;/a&gt; - A radically simple IT automation platform.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cloudinit.readthedocs.io/en/latest/" rel="nofollow"&gt;cloudinit&lt;/a&gt; - A multi-distribution package that handles early initialization of a cloud instance.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sebastien/cuisine"&gt;cuisine&lt;/a&gt; - Chef-like functionality for Fabric.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.docker.com/compose/" rel="nofollow"&gt;docker-compose&lt;/a&gt; - Fast, isolated development environments using &lt;a href="https://www.docker.com/" rel="nofollow"&gt;Docker&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fabric/fabric"&gt;fabric&lt;/a&gt; - A simple, Pythonic tool for remote execution and deployment.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fabtools/fabtools"&gt;fabtools&lt;/a&gt; - Tools for writing awesome Fabric files.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nickstenning/honcho"&gt;honcho&lt;/a&gt; - A Python clone of &lt;a href="https://github.com/ddollar/foreman"&gt;Foreman&lt;/a&gt;, for managing Procfile-based applications.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.openstack.org/" rel="nofollow"&gt;OpenStack&lt;/a&gt; - Open source software for building private and public clouds.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pexpect/pexpect"&gt;pexpect&lt;/a&gt; - Controlling interactive programs in a pseudo-terminal like GNU expect.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giampaolo/psutil"&gt;psutil&lt;/a&gt; - A cross-platform process and system utilities module.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/saltstack/salt"&gt;saltstack&lt;/a&gt; - Infrastructure automation and management system.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Supervisor/supervisor"&gt;supervisor&lt;/a&gt; - Supervisor process control system for UNIX.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-distributed-computing" class="anchor" aria-hidden="true" href="#distributed-computing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Distributed Computing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Frameworks and libraries for Distributed Computing.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Batch Processing
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/pyspark/" rel="nofollow"&gt;PySpark&lt;/a&gt; - &lt;a href="https://spark.apache.org/" rel="nofollow"&gt;Apache Spark&lt;/a&gt; Python API.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dask/dask"&gt;dask&lt;/a&gt; - A flexible parallel computing library for analytic computing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/spotify/luigi"&gt;luigi&lt;/a&gt; - A module that helps you build complex pipelines of batch jobs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Yelp/mrjob"&gt;mrjob&lt;/a&gt; - Run MapReduce jobs on Hadoop or Amazon Web Services.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ray-project/ray/"&gt;Ray&lt;/a&gt; - A system for parallel and distributed Python that unifies the machine learning ecosystem.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stream Processing
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/robinhood/faust"&gt;faust&lt;/a&gt; - A stream processing library, porting the ideas from &lt;a href="https://kafka.apache.org/documentation/streams/" rel="nofollow"&gt;Kafka Streams&lt;/a&gt; to Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Parsely/streamparse"&gt;streamparse&lt;/a&gt; - Run Python code against real-time streams of data via &lt;a href="http://storm.apache.org/" rel="nofollow"&gt;Apache Storm&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-distribution" class="anchor" aria-hidden="true" href="#distribution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Distribution&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries to create packaged executables for release distribution.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/spotify/dh-virtualenv"&gt;dh-virtualenv&lt;/a&gt; - Build and distribute a virtualenv as a Debian package.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nuitka.net/" rel="nofollow"&gt;Nuitka&lt;/a&gt; - Compile scripts, modules, packages to an executable or extension module.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pythonhosted.org/py2app/" rel="nofollow"&gt;py2app&lt;/a&gt; - Freezes Python scripts (Mac OS X).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.py2exe.org/" rel="nofollow"&gt;py2exe&lt;/a&gt; - Freezes Python scripts (Windows).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pyinstaller/pyinstaller"&gt;PyInstaller&lt;/a&gt; - Converts Python programs into stand-alone executables (cross-platform).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pynsist.readthedocs.io/en/latest/" rel="nofollow"&gt;pynsist&lt;/a&gt; - A tool to build Windows installers, installers bundle Python itself.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for generating project documentation.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/sphinx-doc/sphinx/"&gt;sphinx&lt;/a&gt; - Python Documentation generator.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/yoloseem/awesome-sphinxdoc"&gt;awesome-sphinxdoc&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mitmproxy/pdoc"&gt;pdoc&lt;/a&gt; - Epydoc replacement to auto generate API documentation for Python libraries.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pycco-docs/pycco"&gt;pycco&lt;/a&gt; - The literate-programming-style documentation generator.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-downloader" class="anchor" aria-hidden="true" href="#downloader"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Downloader&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for downloading.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/s3tools/s3cmd"&gt;s3cmd&lt;/a&gt; - A command line tool for managing Amazon S3 and CloudFront.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bloomreach/s4cmd"&gt;s4cmd&lt;/a&gt; - Super S3 command line tool, good for higher performance.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://you-get.org/" rel="nofollow"&gt;you-get&lt;/a&gt; - A YouTube/Youku/Niconico video downloader written in Python 3.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://rg3.github.io/youtube-dl/" rel="nofollow"&gt;youtube-dl&lt;/a&gt; - A small command-line program to download videos from YouTube.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-e-commerce" class="anchor" aria-hidden="true" href="#e-commerce"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;E-commerce&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Frameworks and libraries for e-commerce and payments.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/lxneng/alipay"&gt;alipay&lt;/a&gt; - Unofficial Alipay API for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/stephenmcd/cartridge"&gt;Cartridge&lt;/a&gt; - A shopping cart app built using the Mezzanine.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://oscarcommerce.com/" rel="nofollow"&gt;django-oscar&lt;/a&gt; - An open-source e-commerce framework for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/awesto/django-shop"&gt;django-shop&lt;/a&gt; - A Django based shop system.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/agiliq/merchant"&gt;merchant&lt;/a&gt; - A Django app to accept payments from various payment processors.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/carlospalol/money"&gt;money&lt;/a&gt; - &lt;code&gt;Money&lt;/code&gt; class with optional CLDR-backed locale-aware formatting and an extensible currency exchange.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Alir3z4/python-currencies"&gt;python-currencies&lt;/a&gt; - Display money format and its filthy currencies.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MicroPyramid/forex-python"&gt;forex-python&lt;/a&gt; - Foreign exchange rates, Bitcoin price index and currency conversion.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://getsaleor.com/" rel="nofollow"&gt;saleor&lt;/a&gt; - An e-commerce storefront for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.shuup.com/en/" rel="nofollow"&gt;shoop&lt;/a&gt; - An open source E-Commerce platform based on Django.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-editor-plugins-and-ides" class="anchor" aria-hidden="true" href="#editor-plugins-and-ides"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Editor Plugins and IDEs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Emacs
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jorgenschaefer/elpy"&gt;elpy&lt;/a&gt; - Emacs Python Development Environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sublime Text
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/DamnWidget/anaconda"&gt;anaconda&lt;/a&gt; - Anaconda turns your Sublime Text 3 in a full featured Python development IDE.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/srusskih/SublimeJEDI"&gt;SublimeJEDI&lt;/a&gt; - A Sublime Text plugin to the awesome auto-complete library Jedi.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Vim
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/davidhalter/jedi-vim"&gt;jedi-vim&lt;/a&gt; - Vim bindings for the Jedi auto-completion library for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/python-mode/python-mode"&gt;python-mode&lt;/a&gt; - An all in one plugin for turning Vim into a Python IDE.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Valloric/YouCompleteMe"&gt;YouCompleteMe&lt;/a&gt; - Includes &lt;a href="https://github.com/davidhalter/jedi"&gt;Jedi&lt;/a&gt;-based completion engine for Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Visual Studio
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Microsoft/PTVS"&gt;PTVS&lt;/a&gt; - Python Tools for Visual Studio.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Visual Studio Code
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-python.python" rel="nofollow"&gt;Python&lt;/a&gt; - The official VSCode extension with rich support for Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;IDE
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.jetbrains.com/pycharm/" rel="nofollow"&gt;PyCharm&lt;/a&gt; - Commercial Python IDE by JetBrains. Has free community edition available.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/spyder-ide/spyder"&gt;spyder&lt;/a&gt; - Open Source Python IDE.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-email" class="anchor" aria-hidden="true" href="#email"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Email&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for sending and parsing email.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://tomekwojcik.github.io/envelopes/" rel="nofollow"&gt;envelopes&lt;/a&gt; - Mailing for human beings.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mailgun/flanker"&gt;flanker&lt;/a&gt; - An email address and Mime parsing library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/martinrusev/imbox"&gt;imbox&lt;/a&gt; - Python IMAP for Humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/inbox.py"&gt;inbox.py&lt;/a&gt; - Python SMTP Server for Humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zedshaw/lamson"&gt;lamson&lt;/a&gt; - Pythonic SMTP Application Server.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/marrow/mailer"&gt;Marrow Mailer&lt;/a&gt; - High-performance extensible mail delivery framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/modoboa/modoboa"&gt;modoboa&lt;/a&gt; - A mail hosting and management platform including a modern and simplified Web UI.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nylas/sync-engine"&gt;Nylas Sync Engine&lt;/a&gt; - Providing a RESTful API on top of a powerful email sync platform.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kootenpv/yagmail"&gt;yagmail&lt;/a&gt; - Yet another Gmail/SMTP client.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-environment-management" class="anchor" aria-hidden="true" href="#environment-management"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Environment Management&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for Python version and virtual environment management.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pyenv/pyenv"&gt;pyenv&lt;/a&gt; - Simple Python version management.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pypa/pipenv"&gt;pipenv&lt;/a&gt; - Python Development Workflow for Humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sdispater/poetry"&gt;poetry&lt;/a&gt; - Python dependency management and packaging made easy.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pypa/virtualenv"&gt;virtualenv&lt;/a&gt; - A tool to create isolated Python environments.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-files" class="anchor" aria-hidden="true" href="#files"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Files&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for file manipulation and MIME type detection.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/mimetypes.html" rel="nofollow"&gt;mimetypes&lt;/a&gt; - (Python standard library) Map filenames to MIME types.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jaraco/path.py"&gt;path.py&lt;/a&gt; - A module wrapper for &lt;a href="https://docs.python.org/3/library/os.path.html" rel="nofollow"&gt;os.path&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/pathlib.html" rel="nofollow"&gt;pathlib&lt;/a&gt; - (Python standard library) An cross-platform, object-oriented path library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pyfilesystem/pyfilesystem2"&gt;PyFilesystem2&lt;/a&gt; - Python's filesystem abstraction layer.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ahupp/python-magic"&gt;python-magic&lt;/a&gt; - A Python interface to the libmagic file type identification library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mikeorr/Unipath"&gt;Unipath&lt;/a&gt; - An object-oriented approach to file/directory operations.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gorakhargosh/watchdog"&gt;watchdog&lt;/a&gt; - API and shell utilities to monitor file system events.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-foreign-function-interface" class="anchor" aria-hidden="true" href="#foreign-function-interface"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Foreign Function Interface&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for providing foreign function interface.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/cffi/" rel="nofollow"&gt;cffi&lt;/a&gt; - Foreign Function Interface for Python calling C code.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/ctypes.html" rel="nofollow"&gt;ctypes&lt;/a&gt; - (Python standard library) Foreign Function Interface for Python calling C code.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mathema.tician.de/software/pycuda/" rel="nofollow"&gt;PyCUDA&lt;/a&gt; - A Python wrapper for Nvidia's CUDA API.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.swig.org/Doc1.3/Python.html" rel="nofollow"&gt;SWIG&lt;/a&gt; - Simplified Wrapper and Interface Generator.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-forms" class="anchor" aria-hidden="true" href="#forms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Forms&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with forms.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Pylons/deform"&gt;Deform&lt;/a&gt; - Python HTML form generation library influenced by the formish form generation library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dyve/django-bootstrap3"&gt;django-bootstrap3&lt;/a&gt; - Bootstrap 3 integration with Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zostera/django-bootstrap4"&gt;django-bootstrap4&lt;/a&gt; - Bootstrap 4 integration with Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/django-crispy-forms/django-crispy-forms"&gt;django-crispy-forms&lt;/a&gt; - A Django app which lets you create beautiful forms in a very elegant and DRY way.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/WiserTogether/django-remote-forms"&gt;django-remote-forms&lt;/a&gt; - A platform independent Django form serializer.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wtforms/wtforms"&gt;WTForms&lt;/a&gt; - A flexible forms validation and rendering library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-functional-programming" class="anchor" aria-hidden="true" href="#functional-programming"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Functional Programming&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Functional Programming with Python.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://coconut-lang.org/" rel="nofollow"&gt;Coconut&lt;/a&gt; - Coconut is a variant of Python built for simple, elegant, Pythonic functional programming.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pytoolz/cytoolz/"&gt;CyToolz&lt;/a&gt; - Cython implementation of Toolz: High performance functional utilities.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kachayev/fn.py"&gt;fn.py&lt;/a&gt; - Functional programming in Python: implementation of missing features to enjoy FP.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Suor/funcy"&gt;funcy&lt;/a&gt; - A fancy and practical functional tools.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pytoolz/toolz"&gt;Toolz&lt;/a&gt; - A collection of functional utilities for iterators, functions, and dictionaries.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-gui-development" class="anchor" aria-hidden="true" href="#gui-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GUI Development&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with graphical user interface applications.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/curses.html" rel="nofollow"&gt;curses&lt;/a&gt; - Built-in wrapper for &lt;a href="http://www.gnu.org/software/ncurses/" rel="nofollow"&gt;ncurses&lt;/a&gt; used to create terminal GUI applications.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ChrisKnott/Eel"&gt;Eel&lt;/a&gt; - A library for making simple Electron-like offline HTML/JS GUI apps.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nucleic/enaml"&gt;enaml&lt;/a&gt; - Creating beautiful user-interfaces with Declarative Syntax like QML.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zoofIO/flexx"&gt;Flexx&lt;/a&gt; - Flexx is a pure Python toolkit for creating GUI's, that uses web technology for its rendering.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chriskiehl/Gooey"&gt;Gooey&lt;/a&gt; - Turn command line programs into a full GUI application with one line.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://kivy.org/" rel="nofollow"&gt;kivy&lt;/a&gt; - A library for creating NUI applications, running on Windows, Linux, Mac OS X, Android and iOS.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bitbucket.org/pyglet/pyglet/wiki/Home" rel="nofollow"&gt;pyglet&lt;/a&gt; - A cross-platform windowing and multimedia library for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.gnome.org/Projects/PyGObject" rel="nofollow"&gt;PyGObject&lt;/a&gt; - Python Bindings for GLib/GObject/GIO/GTK+ (GTK+3).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://riverbankcomputing.com/software/pyqt/intro" rel="nofollow"&gt;PyQt&lt;/a&gt; - Python bindings for the &lt;a href="https://www.qt.io/" rel="nofollow"&gt;Qt&lt;/a&gt; cross-platform application and UI framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PySimpleGUI/PySimpleGUI"&gt;PySimpleGUI&lt;/a&gt; - Wrapper for tkinter, Qt, WxPython and Remi.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/r0x0r/pywebview/"&gt;pywebview&lt;/a&gt; - A lightweight cross-platform native wrapper around a webview component.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.python.org/moin/TkInter" rel="nofollow"&gt;Tkinter&lt;/a&gt; - Tkinter is Python's de-facto standard GUI package.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pybee/toga"&gt;Toga&lt;/a&gt; - A Python native, OS native GUI toolkit.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://urwid.org/" rel="nofollow"&gt;urwid&lt;/a&gt; - A library for creating terminal GUI applications with strong support for widgets, events, rich colors, etc.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wxpython.org/" rel="nofollow"&gt;wxPython&lt;/a&gt; - A blending of the wxWidgets C++ class library with the Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-game-development" class="anchor" aria-hidden="true" href="#game-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Game Development&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Awesome game development libraries.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://cocos2d.org/" rel="nofollow"&gt;Cocos2d&lt;/a&gt; - cocos2d is a framework for building 2D games, demos, and other graphical/interactive applications.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.harfang3d.com" rel="nofollow"&gt;Harfang3D&lt;/a&gt; - Python framework for 3D, VR and game development.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.panda3d.org/" rel="nofollow"&gt;Panda3D&lt;/a&gt; - 3D game engine developed by Disney.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pygame.org/news.html" rel="nofollow"&gt;Pygame&lt;/a&gt; - Pygame is a set of Python modules designed for writing games.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ogre3d.org/tikiwiki/PyOgre" rel="nofollow"&gt;PyOgre&lt;/a&gt; - Python bindings for the Ogre 3D render engine, can be used for games, simulations, anything 3D.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pyopengl.sourceforge.net/" rel="nofollow"&gt;PyOpenGL&lt;/a&gt; - Python ctypes bindings for OpenGL and it's related APIs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pysdl2.readthedocs.io" rel="nofollow"&gt;PySDL2&lt;/a&gt; - A ctypes based wrapper for the SDL2 library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.renpy.org/" rel="nofollow"&gt;RenPy&lt;/a&gt; - A Visual Novel engine.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-geolocation" class="anchor" aria-hidden="true" href="#geolocation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Geolocation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for geocoding addresses and working with latitudes and longitudes.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/SmileyChris/django-countries"&gt;django-countries&lt;/a&gt; - A Django app that provides a country field for models and forms.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.djangoproject.com/en/dev/ref/contrib/gis/" rel="nofollow"&gt;GeoDjango&lt;/a&gt; - A world-class geographic web framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/maxmind/geoip-api-python"&gt;GeoIP&lt;/a&gt; - Python API for MaxMind GeoIP Legacy Database.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/frewsxcv/python-geojson"&gt;geojson&lt;/a&gt; - Python bindings and utilities for GeoJSON.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/geopy/geopy"&gt;geopy&lt;/a&gt; - Python Geocoding Toolbox.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/appliedsec/pygeoip"&gt;pygeoip&lt;/a&gt; - Pure Python GeoIP API.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-html-manipulation" class="anchor" aria-hidden="true" href="#html-manipulation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;HTML Manipulation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with HTML and XML.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="nofollow"&gt;BeautifulSoup&lt;/a&gt; - Providing Pythonic idioms for iterating, searching, and modifying HTML or XML.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mozilla/bleach"&gt;bleach&lt;/a&gt; - A whitelist-based HTML sanitization and text linkification library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/cssutils/" rel="nofollow"&gt;cssutils&lt;/a&gt; - A CSS library for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/html5lib/html5lib-python"&gt;html5lib&lt;/a&gt; - A standards-compliant library for parsing and serializing HTML documents and fragments.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lxml.de/" rel="nofollow"&gt;lxml&lt;/a&gt; - A very fast, easy-to-use and versatile library for handling HTML and XML.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pallets/markupsafe"&gt;MarkupSafe&lt;/a&gt; - Implements a XML/HTML/XHTML Markup safe string for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gawel/pyquery"&gt;pyquery&lt;/a&gt; - A jQuery-like library for parsing HTML.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/stchris/untangle"&gt;untangle&lt;/a&gt; - Converts XML documents to Python objects for easy access.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://weasyprint.org" rel="nofollow"&gt;WeasyPrint&lt;/a&gt; - A visual rendering engine for HTML and CSS that can export to PDF.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://xmldataset.readthedocs.io/en/latest/" rel="nofollow"&gt;xmldataset&lt;/a&gt; - Simple XML Parsing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/martinblech/xmltodict"&gt;xmltodict&lt;/a&gt; - Working with XML feel like you are working with JSON.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-http-clients" class="anchor" aria-hidden="true" href="#http-clients"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;HTTP Clients&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with HTTP.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/grequests"&gt;grequests&lt;/a&gt; - requests + gevent for asynchronous HTTP requests.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/httplib2/httplib2"&gt;httplib2&lt;/a&gt; - Comprehensive HTTP client library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://requests.kennethreitz.org/en/master/" rel="nofollow"&gt;requests&lt;/a&gt; - HTTP Requests for Humans™.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/twisted/treq"&gt;treq&lt;/a&gt; - Python requests like API built on top of Twisted's HTTP client.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/shazow/urllib3"&gt;urllib3&lt;/a&gt; - A HTTP library with thread-safe connection pooling, file post support, sanity friendly.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-hardware" class="anchor" aria-hidden="true" href="#hardware"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hardware&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for programming with hardware.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://inotool.org/" rel="nofollow"&gt;ino&lt;/a&gt; - Command line toolkit for working with &lt;a href="https://www.arduino.cc/" rel="nofollow"&gt;Arduino&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/boppreh/keyboard"&gt;keyboard&lt;/a&gt; - Hook and simulate global keyboard events on Windows and Linux.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/boppreh/mouse"&gt;mouse&lt;/a&gt; - Hook and simulate global mouse events on Windows and Linux.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pingo.io/" rel="nofollow"&gt;Pingo&lt;/a&gt; - Pingo provides a uniform API to program devices like the Raspberry Pi, pcDuino, Intel Galileo, etc.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/SavinaRoja/PyUserInput"&gt;PyUserInput&lt;/a&gt; - A module for cross-platform control of the mouse and keyboard.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/secdev/scapy"&gt;scapy&lt;/a&gt; - A brilliant packet manipulation library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rockymeza/wifi"&gt;wifi&lt;/a&gt; - A Python library and command line tool for working with WiFi on Linux.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-image-processing" class="anchor" aria-hidden="true" href="#image-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image Processing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for manipulating images.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/rossgoodwin/hmap"&gt;hmap&lt;/a&gt; - Image histogram remapping.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sourceforge.net/projects/imgseek/" rel="nofollow"&gt;imgSeek&lt;/a&gt; - A project for searching a collection of images using visual similarity.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/hhatto/nude.py"&gt;nude.py&lt;/a&gt; - Nudity detection.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/daboth/pagan"&gt;pagan&lt;/a&gt; - Retro identicon (Avatar) generation based on input string and hash.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/python-pillow/Pillow"&gt;pillow&lt;/a&gt; - Pillow is the friendly &lt;a href="http://www.pythonware.com/products/pil/" rel="nofollow"&gt;PIL&lt;/a&gt; fork.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pythonhosted.org/pyBarcode/" rel="nofollow"&gt;pyBarcode&lt;/a&gt; - Create barcodes in Python without needing PIL.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ajkumar25/pygram"&gt;pygram&lt;/a&gt; - Instagram-like image filters.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lincolnloop/python-qrcode"&gt;python-qrcode&lt;/a&gt; - A pure Python QR Code generator.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fogleman/Quads"&gt;Quads&lt;/a&gt; - Computer art based on quadtrees.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-image.org/" rel="nofollow"&gt;scikit-image&lt;/a&gt; - A Python library for (scientific) image processing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/thumbor/thumbor"&gt;thumbor&lt;/a&gt; - A smart imaging service. It enables on-demand crop, re-sizing and flipping of images.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dahlia/wand"&gt;wand&lt;/a&gt; - Python bindings for &lt;a href="http://www.imagemagick.org/script/magick-wand.php" rel="nofollow"&gt;MagickWand&lt;/a&gt;, C API for ImageMagick.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-implementations" class="anchor" aria-hidden="true" href="#implementations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Implementations&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Implementations of Python.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/python/cpython"&gt;CPython&lt;/a&gt; - &lt;strong&gt;Default, most widely used implementation of the Python programming language written in C.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cython.org/" rel="nofollow"&gt;Cython&lt;/a&gt; - Optimizing Static Compiler for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/metawilm/cl-python"&gt;CLPython&lt;/a&gt; - Implementation of the Python programming language written in Common Lisp.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/grumpy"&gt;Grumpy&lt;/a&gt; - More compiler than interpreter as more powerful CPython2.7 replacement (alpha).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/IronLanguages/ironpython3"&gt;IronPython&lt;/a&gt; - Implementation of the Python programming language written in C#.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://hg.python.org/jython" rel="nofollow"&gt;Jython&lt;/a&gt; - Implementation of Python programming language written in Java for the JVM.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/micropython/micropython"&gt;MicroPython&lt;/a&gt; - A lean and efficient Python programming language implementation.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://numba.pydata.org/" rel="nofollow"&gt;Numba&lt;/a&gt; - Python JIT compiler to LLVM aimed at scientific Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Maratyszcza/PeachPy"&gt;PeachPy&lt;/a&gt; - x86-64 assembler embedded in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Microsoft/Pyjion"&gt;Pyjion&lt;/a&gt; - A JIT for Python based upon CoreCLR.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bitbucket.org/pypy/pypy" rel="nofollow"&gt;PyPy&lt;/a&gt; - A very fast and compliant implementation of the Python language.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dropbox/pyston"&gt;Pyston&lt;/a&gt; - A Python implementation using JIT techniques.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/stackless-dev/stackless"&gt;Stackless Python&lt;/a&gt; - An enhanced version of the Python programming language.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-interactive-interpreter" class="anchor" aria-hidden="true" href="#interactive-interpreter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive Interpreter&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Interactive Python interpreters (REPL).&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/bpython/bpython"&gt;bpython&lt;/a&gt; - A fancy interface to the Python interpreter.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jupyter.org" rel="nofollow"&gt;Jupyter Notebook (IPython)&lt;/a&gt; - A rich toolkit to help you make the most out of using Python interactively.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/markusschanta/awesome-jupyter"&gt;awesome-jupyter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jonathanslenders/ptpython"&gt;ptpython&lt;/a&gt; - Advanced Python REPL built on top of the &lt;a href="https://github.com/jonathanslenders/python-prompt-toolkit"&gt;python-prompt-toolkit&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-internationalization" class="anchor" aria-hidden="true" href="#internationalization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Internationalization&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with i18n.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://babel.pocoo.org/en/latest/" rel="nofollow"&gt;Babel&lt;/a&gt; - An internationalization library for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ovalhub/pyicu"&gt;PyICU&lt;/a&gt; - A wrapper of International Components for Unicode C++ library (&lt;a href="http://site.icu-project.org/" rel="nofollow"&gt;ICU&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-job-scheduler" class="anchor" aria-hidden="true" href="#job-scheduler"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Job Scheduler&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for scheduling jobs.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://apscheduler.readthedocs.io/en/latest/" rel="nofollow"&gt;APScheduler&lt;/a&gt; - A light but powerful in-process task scheduler that lets you schedule functions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/thauber/django-schedule"&gt;django-schedule&lt;/a&gt; - A calendaring app for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pydoit.org/" rel="nofollow"&gt;doit&lt;/a&gt; - A task runner and build tool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gunnery/gunnery"&gt;gunnery&lt;/a&gt; - Multipurpose task execution tool for distributed systems with web-based interface.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://joblib.readthedocs.io/" rel="nofollow"&gt;Joblib&lt;/a&gt; - A set of tools to provide lightweight pipelining in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fengsp/plan"&gt;Plan&lt;/a&gt; - Writing crontab file in Python like a charm.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dbader/schedule"&gt;schedule&lt;/a&gt; - Python job scheduling for humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/knipknap/SpiffWorkflow"&gt;Spiff&lt;/a&gt; - A powerful workflow engine implemented in pure Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.openstack.org/developer/taskflow/" rel="nofollow"&gt;TaskFlow&lt;/a&gt; - A Python library that helps to make task execution easy, consistent and reliable.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://airflow.apache.org/" rel="nofollow"&gt;Airflow&lt;/a&gt; - Airflow is a platform to programmatically author, schedule and monitor workflows.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-logging" class="anchor" aria-hidden="true" href="#logging"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Logging&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for generating and working with logs.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ScatterHQ/eliot"&gt;Eliot&lt;/a&gt; - Logging for complex &amp;amp; distributed systems.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://logbook.readthedocs.io/en/stable/" rel="nofollow"&gt;logbook&lt;/a&gt; - Logging replacement for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/logging.html" rel="nofollow"&gt;logging&lt;/a&gt; - (Python standard library) Logging facility for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/raven-python"&gt;raven&lt;/a&gt; - Python client for Sentry, a log/error tracking, crash reporting and aggregation platform for web applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-machine-learning" class="anchor" aria-hidden="true" href="#machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for Machine Learning. Also see &lt;a href="https://github.com/josephmisiti/awesome-machine-learning#python"&gt;awesome-machine-learning&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/h2oai/h2o-3"&gt;H2O&lt;/a&gt; - Open Source Fast Scalable Machine Learning Platform.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/benhamner/Metrics"&gt;Metrics&lt;/a&gt; - Machine learning evaluation metrics.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/numenta/nupic"&gt;NuPIC&lt;/a&gt; - Numenta Platform for Intelligent Computing.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/" rel="nofollow"&gt;scikit-learn&lt;/a&gt; - The most popular Python library for Machine Learning.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://spark.apache.org/docs/latest/ml-guide.html" rel="nofollow"&gt;Spark ML&lt;/a&gt; - &lt;a href="http://spark.apache.org/" rel="nofollow"&gt;Apache Spark&lt;/a&gt;'s scalable Machine Learning library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/josephreisinger/vowpal_porpoise"&gt;vowpal_porpoise&lt;/a&gt; - A lightweight Python wrapper for &lt;a href="https://github.com/JohnLangford/vowpal_wabbit/"&gt;Vowpal Wabbit&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dmlc/xgboost"&gt;xgboost&lt;/a&gt; - A scalable, portable, and distributed gradient boosting library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-microsoft-windows" class="anchor" aria-hidden="true" href="#microsoft-windows"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Microsoft Windows&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Python programming on Microsoft Windows.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://python-xy.github.io/" rel="nofollow"&gt;Python(x,y)&lt;/a&gt; - Scientific-applications-oriented Python Distribution based on Qt and Spyder.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/" rel="nofollow"&gt;pythonlibs&lt;/a&gt; - Unofficial Windows binaries for Python extension packages.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pythonnet/pythonnet"&gt;PythonNet&lt;/a&gt; - Python Integration with the .NET Common Language Runtime (CLR).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sourceforge.net/projects/pywin32/" rel="nofollow"&gt;PyWin32&lt;/a&gt; - Python Extensions for Windows.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://winpython.github.io/" rel="nofollow"&gt;WinPython&lt;/a&gt; - Portable development environment for Windows 7/8.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-miscellaneous" class="anchor" aria-hidden="true" href="#miscellaneous"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Miscellaneous&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Useful libraries or tools that don't fit in the categories above.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jek/blinker"&gt;blinker&lt;/a&gt; - A fast Python in-process signal/event dispatching system.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mahmoud/boltons"&gt;boltons&lt;/a&gt; - A set of pure-Python utilities.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pallets/itsdangerous"&gt;itsdangerous&lt;/a&gt; - Various helpers to pass trusted data to untrusted environments.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mitsuhiko/pluginbase"&gt;pluginbase&lt;/a&gt; - A simple but flexible plugin system for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.tryton.org/" rel="nofollow"&gt;tryton&lt;/a&gt; - A general purpose business framework.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-natural-language-processing" class="anchor" aria-hidden="true" href="#natural-language-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Natural Language Processing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with human languages.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;General
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/RaRe-Technologies/gensim"&gt;gensim&lt;/a&gt; - Topic Modeling for Humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/saffsd/langid.py"&gt;langid.py&lt;/a&gt; - Stand-alone language identification system.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nltk.org/" rel="nofollow"&gt;nltk&lt;/a&gt; - A leading platform for building Python programs to work with human language data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/clips/pattern"&gt;pattern&lt;/a&gt; - A web mining module for the Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/aboSamoor/polyglot"&gt;polyglot&lt;/a&gt; - Natural language pipeline supporting hundreds of languages.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/pytext"&gt;pytext&lt;/a&gt; - A natural language modeling framework based on PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PetrochukM/PyTorch-NLP"&gt;PyTorch-NLP&lt;/a&gt; - A toolkit enabling rapid deep learning NLP prototyping for research.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://spacy.io/" rel="nofollow"&gt;spacy&lt;/a&gt; - A library for industrial-strength natural language processing in Python and Cython.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/stanfordnlp/stanfordnlp"&gt;stanfordnlp&lt;/a&gt; - The Stanford NLP Group's official Python library, supporting 50+ languages.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Chinese
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/fxsjy/jieba"&gt;jieba&lt;/a&gt; - The most popular Chinese text segmentation library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lancopku/pkuseg-python"&gt;pkuseg-python&lt;/a&gt; - A toolkit for Chinese word segmentation in various domains.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/isnowfy/snownlp"&gt;snownlp&lt;/a&gt; - A library for processing Chinese text.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fighting41love/funNLP"&gt;funNLP&lt;/a&gt; - A collection of tools and datasets for Chinese NLP.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-network-virtualization" class="anchor" aria-hidden="true" href="#network-virtualization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Network Virtualization&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Tools and libraries for Virtual Networking and SDN (Software Defined Networking).&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/mininet/mininet"&gt;mininet&lt;/a&gt; - A popular network emulator and API written in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/noxrepo/pox"&gt;pox&lt;/a&gt; - A Python-based SDN control applications, such as OpenFlow SDN controllers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-networking" class="anchor" aria-hidden="true" href="#networking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Networking&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for networking programming.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow"&gt;asyncio&lt;/a&gt; - (Python standard library) Asynchronous I/O, event loop, coroutines and tasks.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/timofurrer/awesome-asyncio"&gt;awesome-asyncio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/quantmind/pulsar"&gt;pulsar&lt;/a&gt; - Event-driven concurrent framework for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zeromq/pyzmq"&gt;pyzmq&lt;/a&gt; - A Python wrapper for the ZeroMQ message library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twistedmatrix.com/trac/" rel="nofollow"&gt;Twisted&lt;/a&gt; - An event-driven networking engine.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/napalm-automation/napalm"&gt;napalm&lt;/a&gt; - Cross-vendor API to manipulate network devices.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-news-feed" class="anchor" aria-hidden="true" href="#news-feed"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;News Feed&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for building user's activities.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/justquick/django-activity-stream"&gt;django-activity-stream&lt;/a&gt; - Generating generic activity streams from the actions on your site.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tschellenbach/Stream-Framework"&gt;Stream Framework&lt;/a&gt; - Building news feed and notification systems using Cassandra and Redis.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-orm" class="anchor" aria-hidden="true" href="#orm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ORM&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries that implement Object-Relational Mapping or data mapping techniques.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Relational Databases
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.djangoproject.com/en/dev/topics/db/models/" rel="nofollow"&gt;Django Models&lt;/a&gt; - A part of Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sqlalchemy.org/" rel="nofollow"&gt;SQLAlchemy&lt;/a&gt; - The Python SQL Toolkit and Object Relational Mapper.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/dahlia/awesome-sqlalchemy"&gt;awesome-sqlalchemy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pudo/dataset"&gt;dataset&lt;/a&gt; - Store Python dicts in a database - works with SQLite, MySQL, and PostgreSQL.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sdispater/orator"&gt;orator&lt;/a&gt; -  The Orator ORM provides a simple yet beautiful ActiveRecord implementation.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/coleifer/peewee"&gt;peewee&lt;/a&gt; - A small, expressive ORM.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ponyorm/pony/"&gt;pony&lt;/a&gt; - ORM that provides a generator-oriented interface to SQL.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/web2py/pydal/"&gt;pydal&lt;/a&gt; - A pure Python Database Abstraction Layer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NoSQL Databases
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/stephenmcd/hot-redis"&gt;hot-redis&lt;/a&gt; - Rich Python data types for Redis.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MongoEngine/mongoengine"&gt;mongoengine&lt;/a&gt; - A Python Object-Document-Mapper for working with MongoDB.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pynamodb/PynamoDB"&gt;PynamoDB&lt;/a&gt; - A Pythonic interface for &lt;a href="https://aws.amazon.com/dynamodb/" rel="nofollow"&gt;Amazon DynamoDB&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kiddouk/redisco"&gt;redisco&lt;/a&gt; - A Python Library for Simple Models and Containers Persisted in Redis.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-package-management" class="anchor" aria-hidden="true" href="#package-management"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Package Management&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for package and dependency management.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pip.pypa.io/en/stable/" rel="nofollow"&gt;pip&lt;/a&gt; - The Python package and dependency manager.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.org/" rel="nofollow"&gt;PyPI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jazzband/pip-tools"&gt;pip-tools&lt;/a&gt; - A set of tools to keep your pinned Python dependencies fresh.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/conda/conda/"&gt;conda&lt;/a&gt; - Cross-platform, Python-agnostic binary package manager.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-package-repositories" class="anchor" aria-hidden="true" href="#package-repositories"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Package Repositories&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Local PyPI repository server and proxies.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pypa/warehouse"&gt;warehouse&lt;/a&gt; - Next generation Python Package Repository (PyPI).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pypa/bandersnatch/"&gt;bandersnatch&lt;/a&gt; - PyPI mirroring tool provided by Python Packaging Authority (PyPA).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/devpi/devpi"&gt;devpi&lt;/a&gt; - PyPI server and packaging/testing/release tool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jazzband/localshop"&gt;localshop&lt;/a&gt; - Local PyPI server (custom packages and auto-mirroring of pypi).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-permissions" class="anchor" aria-hidden="true" href="#permissions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Permissions&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries that allow or deny users access to data or functionality.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/django-guardian/django-guardian"&gt;django-guardian&lt;/a&gt; - Implementation of per object permissions for Django 1.2+&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dfunckt/django-rules"&gt;django-rules&lt;/a&gt; - A tiny but powerful app providing object-level permissions to Django, without requiring a database.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-processes" class="anchor" aria-hidden="true" href="#processes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Processes&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for starting and communicating with OS processes.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/delegator.py"&gt;delegator.py&lt;/a&gt; - &lt;a href="https://docs.python.org/3.6/library/subprocess.html" rel="nofollow"&gt;Subprocesses&lt;/a&gt; for Humans™ 2.0.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sarge.readthedocs.io/en/latest/" rel="nofollow"&gt;sarge&lt;/a&gt; - Yet another wrapper for subprocess.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/amoffat/sh"&gt;sh&lt;/a&gt; - A full-fledged subprocess replacement for Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-queue" class="anchor" aria-hidden="true" href="#queue"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Queue&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with event and task queues.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.celeryproject.org/" rel="nofollow"&gt;celery&lt;/a&gt; - An asynchronous task queue/job queue based on distributed message passing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/coleifer/huey"&gt;huey&lt;/a&gt; - Little multi-threaded task queue.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pricingassistant/mrq"&gt;mrq&lt;/a&gt; - Mr. Queue - A distributed worker task queue in Python using Redis &amp;amp; gevent.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rq/rq"&gt;rq&lt;/a&gt; - Simple job queues for Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-recommender-systems" class="anchor" aria-hidden="true" href="#recommender-systems"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Recommender Systems&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for building recommender systems.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/spotify/annoy"&gt;annoy&lt;/a&gt; - Approximate Nearest Neighbors in C++/Python optimized for memory usage.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ibayer/fastFM"&gt;fastFM&lt;/a&gt; - A library for Factorization Machines.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/benfred/implicit"&gt;implicit&lt;/a&gt; - A fast Python implementation of collaborative filtering for implicit datasets.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/guestwalk/libffm"&gt;libffm&lt;/a&gt; - A library for Field-aware Factorization Machine (FFM).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lyst/lightfm"&gt;lightfm&lt;/a&gt; - A Python implementation of a number of popular recommendation algorithms.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/maciejkula/spotlight"&gt;spotlight&lt;/a&gt; - Deep recommender models using PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/NicolasHug/Surprise"&gt;Surprise&lt;/a&gt; - A scikit for building and analyzing recommender systems.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jfkirk/tensorrec"&gt;tensorrec&lt;/a&gt; - A Recommendation Engine Framework in TensorFlow.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-restful-api" class="anchor" aria-hidden="true" href="#restful-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RESTful API&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for developing RESTful APIs.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Django
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.django-rest-framework.org/" rel="nofollow"&gt;django-rest-framework&lt;/a&gt; - A powerful and flexible toolkit to build web APIs.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://tastypieapi.org/" rel="nofollow"&gt;django-tastypie&lt;/a&gt; - Creating delicious APIs for Django apps.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Flask
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pyeve/eve"&gt;eve&lt;/a&gt; - REST API framework powered by Flask, MongoDB and good intentions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/marselester/flask-api-utils"&gt;flask-api-utils&lt;/a&gt; - Taking care of API representation and authentication for Flask.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.flaskapi.org/" rel="nofollow"&gt;flask-api&lt;/a&gt; - Browsable Web APIs for Flask.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/flask-restful/flask-restful"&gt;flask-restful&lt;/a&gt; - Quickly building REST APIs for Flask.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jfinkels/flask-restless"&gt;flask-restless&lt;/a&gt; - Generating RESTful APIs for database models defined with SQLAlchemy.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pyramid
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Cornices/cornice"&gt;cornice&lt;/a&gt; - A RESTful framework for Pyramid.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Framework agnostic
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/encode/apistar"&gt;apistar&lt;/a&gt; - A smart Web API framework, designed for Python 3.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://falconframework.org/" rel="nofollow"&gt;falcon&lt;/a&gt; - A high-performance framework for building cloud APIs and web app backends.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/timothycrosley/hug"&gt;hug&lt;/a&gt; - A Python 3 framework for cleanly exposing APIs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/toastdriven/restless"&gt;restless&lt;/a&gt; - Framework agnostic REST framework based on lessons learned from Tastypie.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/vertical-knowledge/ripozo"&gt;ripozo&lt;/a&gt; - Quickly creating REST/HATEOAS/Hypermedia APIs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jeffknupp/sandman"&gt;sandman&lt;/a&gt; - Automated REST APIs for existing database-driven systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-robotics" class="anchor" aria-hidden="true" href="#robotics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Robotics&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for robotics.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics"&gt;PythonRobotics&lt;/a&gt; - This is a compilation of various robotics algorithms with visualizations.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://wiki.ros.org/rospy" rel="nofollow"&gt;rospy&lt;/a&gt; - This is a library for ROS (Robot Operating System).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-rpc-servers" class="anchor" aria-hidden="true" href="#rpc-servers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RPC Servers&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;RPC-compatible servers.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/joshmarshall/jsonrpclib/"&gt;SimpleJSONRPCServer&lt;/a&gt; - This library is an implementation of the JSON-RPC specification.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/xmlrpc.server.html" rel="nofollow"&gt;SimpleXMLRPCServer&lt;/a&gt; - (Python standard library) Simple XML-RPC server implementation, single-threaded.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/0rpc/zerorpc-python"&gt;zeroRPC&lt;/a&gt; - zerorpc is a flexible RPC implementation based on &lt;a href="http://zeromq.org/" rel="nofollow"&gt;ZeroMQ&lt;/a&gt; and &lt;a href="http://msgpack.org/" rel="nofollow"&gt;MessagePack&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-science" class="anchor" aria-hidden="true" href="#science"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Science&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for scientific computing. Also see &lt;a href="https://github.com/TomNicholas/Python-for-Scientists"&gt;Python-for-Scientists&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.astropy.org/" rel="nofollow"&gt;astropy&lt;/a&gt; - A community Python library for Astronomy.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chapmanb/bcbio-nextgen"&gt;bcbio-nextgen&lt;/a&gt; - Providing best-practice pipelines for fully automated high throughput sequencing analysis.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chapmanb/bcbb"&gt;bccb&lt;/a&gt; - Collection of useful code related to biological analysis.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://biopython.org/wiki/Main_Page" rel="nofollow"&gt;Biopython&lt;/a&gt; - Biopython is a set of freely available tools for biological computation.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cclib.github.io/" rel="nofollow"&gt;cclib&lt;/a&gt; - A library for parsing and interpreting the results of computational chemistry packages.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://colour-science.org/" rel="nofollow"&gt;Colour&lt;/a&gt; - Implementing a comprehensive number of colour theory transformations and algorithms.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://networkx.github.io/" rel="nofollow"&gt;NetworkX&lt;/a&gt; - A high-productivity software for complex networks.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nipy.org" rel="nofollow"&gt;NIPY&lt;/a&gt; - A collection of neuroimaging toolkits.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.numpy.org/" rel="nofollow"&gt;NumPy&lt;/a&gt; - A fundamental package for scientific computing with Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://openbabel.org/wiki/Main_Page" rel="nofollow"&gt;Open Babel&lt;/a&gt; - A chemical toolbox designed to speak the many languages of chemical data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/obspy/obspy/wiki/"&gt;ObsPy&lt;/a&gt; - A Python toolbox for seismology.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pydy.org/" rel="nofollow"&gt;PyDy&lt;/a&gt; - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pymc-devs/pymc3"&gt;PyMC&lt;/a&gt; - Markov Chain Monte Carlo sampling toolkit.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://qutip.org/" rel="nofollow"&gt;QuTiP&lt;/a&gt; - Quantum Toolbox in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.rdkit.org/" rel="nofollow"&gt;RDKit&lt;/a&gt; - Cheminformatics and Machine Learning Software.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.scipy.org/" rel="nofollow"&gt;SciPy&lt;/a&gt; - A Python-based ecosystem of open-source software for mathematics, science, and engineering.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/statsmodels/statsmodels"&gt;statsmodels&lt;/a&gt; - Statistical modeling and econometrics in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sympy/sympy"&gt;SymPy&lt;/a&gt; - A Python library for symbolic mathematics.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/quantopian/zipline"&gt;Zipline&lt;/a&gt; - A Pythonic algorithmic trading library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bitbucket.org/simpy/simpy" rel="nofollow"&gt;SimPy&lt;/a&gt; -  A process-based discrete-event simulation framework.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-search" class="anchor" aria-hidden="true" href="#search"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Search&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries and software for indexing and performing search queries on data.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/index.html" rel="nofollow"&gt;elasticsearch-py&lt;/a&gt; - The official low-level Python client for &lt;a href="https://www.elastic.co/products/elasticsearch" rel="nofollow"&gt;Elasticsearch&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/elasticsearch-dsl-py"&gt;elasticsearch-dsl-py&lt;/a&gt; - The official high-level Python client for Elasticsearch.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/django-haystack/django-haystack"&gt;django-haystack&lt;/a&gt; - Modular search for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/django-haystack/pysolr"&gt;pysolr&lt;/a&gt; - A lightweight Python wrapper for &lt;a href="https://lucene.apache.org/solr/" rel="nofollow"&gt;Apache Solr&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://whoosh.readthedocs.io/en/latest/" rel="nofollow"&gt;whoosh&lt;/a&gt; - A fast, pure Python search engine library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-serialization" class="anchor" aria-hidden="true" href="#serialization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Serialization&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for serializing complex data types&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/marshmallow-code/marshmallow"&gt;marshmallow&lt;/a&gt; - A lightweight library for converting complex objects to and from simple Python datatypes.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TkTech/pysimdjson"&gt;pysimdjson&lt;/a&gt; - A Python bindings for &lt;a href="https://github.com/lemire/simdjson"&gt;simdjson&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/python-rapidjson/python-rapidjson"&gt;python-rapidjson&lt;/a&gt; - A Python wrapper around &lt;a href="https://github.com/Tencent/rapidjson"&gt;RapidJSON&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-serverless-frameworks" class="anchor" aria-hidden="true" href="#serverless-frameworks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Serverless Frameworks&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Frameworks for developing serverless Python code.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/nficano/python-lambda"&gt;python-lambda&lt;/a&gt; - A toolkit for developing and deploying Python code in AWS Lambda.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Miserlou/Zappa"&gt;Zappa&lt;/a&gt; - A tool for deploying WSGI applications on AWS Lambda and API Gateway.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-specific-formats-processing" class="anchor" aria-hidden="true" href="#specific-formats-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Specific Formats Processing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for parsing and manipulating specific text formats.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;General
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/tablib"&gt;tablib&lt;/a&gt; - A module for Tabular Datasets in XLS, CSV, JSON, YAML.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Office
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://openpyxl.readthedocs.io/en/stable/" rel="nofollow"&gt;openpyxl&lt;/a&gt; - A library for reading and writing Excel 2010 xlsx/xlsm/xltx/xltm files.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pyexcel/pyexcel"&gt;pyexcel&lt;/a&gt; - Providing one API for reading, manipulating and writing csv, ods, xls, xlsx and xlsm files.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/python-openxml/python-docx"&gt;python-docx&lt;/a&gt; - Reads, queries and modifies Microsoft Word 2007/2008 docx files.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/scanny/python-pptx"&gt;python-pptx&lt;/a&gt; - Python library for creating and updating PowerPoint (.pptx) files.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/unoconv/unoconv"&gt;unoconv&lt;/a&gt; - Convert between any document format supported by LibreOffice/OpenOffice.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jmcnamara/XlsxWriter"&gt;XlsxWriter&lt;/a&gt; - A Python module for creating Excel .xlsx files.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ZoomerAnalytics/xlwings"&gt;xlwings&lt;/a&gt; - A BSD-licensed library that makes it easy to call Python from Excel and vice versa.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/python-excel/xlwt"&gt;xlwt&lt;/a&gt; / &lt;a href="https://github.com/python-excel/xlrd"&gt;xlrd&lt;/a&gt; - Writing and reading data and formatting information from Excel files.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PDF
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/euske/pdfminer"&gt;PDFMiner&lt;/a&gt; - A tool for extracting information from PDF documents.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mstamy2/PyPDF2"&gt;PyPDF2&lt;/a&gt; - A library capable of splitting, merging and transforming PDF pages.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reportlab.com/opensource/" rel="nofollow"&gt;ReportLab&lt;/a&gt; - Allowing Rapid creation of rich PDF documents.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Markdown
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/lepture/mistune"&gt;Mistune&lt;/a&gt; - Fastest and full featured pure Python parsers of Markdown.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/waylan/Python-Markdown"&gt;Python-Markdown&lt;/a&gt; - A Python implementation of John Gruber’s Markdown.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;YAML
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://pyyaml.org/" rel="nofollow"&gt;PyYAML&lt;/a&gt; - YAML implementations for Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CSV
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/wireservice/csvkit"&gt;csvkit&lt;/a&gt; - Utilities for converting to and working with CSV.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Archive
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/mitsuhiko/unp"&gt;unp&lt;/a&gt; - A command line tool that can unpack archives easily.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-static-site-generator" class="anchor" aria-hidden="true" href="#static-site-generator"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Static Site Generator&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Static site generator is a software that takes some text + templates as input and produces HTML files on the output.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/mkdocs/mkdocs/"&gt;mkdocs&lt;/a&gt; - Markdown friendly documentation generator.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getpelican/pelican"&gt;pelican&lt;/a&gt; - Static site generator that supports Markdown and reST syntax.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lektor/lektor"&gt;lektor&lt;/a&gt; - An easy to use static CMS and blog engine.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getnikola/nikola"&gt;nikola&lt;/a&gt; - A static website and blog generator.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-tagging" class="anchor" aria-hidden="true" href="#tagging"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tagging&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for tagging items.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jazzband/django-taggit"&gt;django-taggit&lt;/a&gt; - Simple tagging for Django.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-template-engine" class="anchor" aria-hidden="true" href="#template-engine"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Template Engine&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries and tools for templating and lexing.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pallets/jinja"&gt;Jinja2&lt;/a&gt; - A modern and designer friendly templating language.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://genshi.edgewall.org/" rel="nofollow"&gt;Genshi&lt;/a&gt; - Python templating toolkit for generation of web-aware output.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.makotemplates.org/" rel="nofollow"&gt;Mako&lt;/a&gt; - Hyperfast and lightweight templating for the Python platform.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-testing" class="anchor" aria-hidden="true" href="#testing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Testing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for testing codebases and generating test data.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Testing Frameworks
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.pytest.org/en/latest/" rel="nofollow"&gt;pytest&lt;/a&gt; - A mature full-featured Python testing tool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/HypothesisWorks/hypothesis"&gt;hypothesis&lt;/a&gt; - Hypothesis is an advanced Quickcheck style property based testing library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nose-devs/nose2"&gt;nose2&lt;/a&gt; - The successor to &lt;code&gt;nose&lt;/code&gt;, based on `unittest2.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/robotframework/robotframework"&gt;Robot Framework&lt;/a&gt; - A generic test automation framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/unittest.html" rel="nofollow"&gt;unittest&lt;/a&gt; - (Python standard library) Unit testing framework.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Test Runners
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/CleanCut/green"&gt;green&lt;/a&gt; - A clean, colorful test runner.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nestorsalceda.github.io/mamba/" rel="nofollow"&gt;mamba&lt;/a&gt; - The definitive testing tool for Python. Born under the banner of BDD.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tox.readthedocs.io/en/latest/" rel="nofollow"&gt;tox&lt;/a&gt; - Auto builds and tests distributions in multiple Python versions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GUI / Web Testing
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/locustio/locust"&gt;locust&lt;/a&gt; - Scalable user load testing tool written in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/asweigart/pyautogui"&gt;PyAutoGUI&lt;/a&gt; - PyAutoGUI is a cross-platform GUI automation Python module for human beings.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/selenium/" rel="nofollow"&gt;Selenium&lt;/a&gt; - Python bindings for &lt;a href="http://www.seleniumhq.org/" rel="nofollow"&gt;Selenium&lt;/a&gt; WebDriver.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/seatgeek/sixpack"&gt;sixpack&lt;/a&gt; - A language-agnostic A/B Testing framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cobrateam/splinter"&gt;splinter&lt;/a&gt; - Open source tool for testing web applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mock
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/unittest.mock.html" rel="nofollow"&gt;mock&lt;/a&gt; - (Python standard library) A mocking and patching library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/doublex/" rel="nofollow"&gt;doublex&lt;/a&gt; - Powerful test doubles framework for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/spulec/freezegun"&gt;freezegun&lt;/a&gt; - Travel through time by mocking the datetime module.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/patrys/httmock"&gt;httmock&lt;/a&gt; - A mocking library for requests for Python 2.6+ and 3.2+.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gabrielfalcao/HTTPretty"&gt;httpretty&lt;/a&gt; - HTTP request mock tool for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mindflayer/python-mocket"&gt;mocket&lt;/a&gt; - A socket mock framework with gevent/asyncio/SSL support.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/responses"&gt;responses&lt;/a&gt; - A utility library for mocking out the requests Python library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kevin1024/vcrpy"&gt;VCR.py&lt;/a&gt; - Record and replay HTTP interactions on your tests.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Object Factories
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/FactoryBoy/factory_boy"&gt;factory_boy&lt;/a&gt; - A test fixtures replacement for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/klen/mixer"&gt;mixer&lt;/a&gt; - Another fixtures replacement. Supported Django, Flask, SQLAlchemy, Peewee and etc.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/vandersonmota/model_mommy"&gt;model_mommy&lt;/a&gt; - Creating random fixtures for testing in Django.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Code Coverage
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/coverage/" rel="nofollow"&gt;coverage&lt;/a&gt; - Code coverage measurement.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fake Data
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/lk-geimfari/mimesis"&gt;mimesis&lt;/a&gt; - is a Python library that help you generate fake data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/emirozer/fake2db"&gt;fake2db&lt;/a&gt; - Fake database generator.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/joke2k/faker"&gt;faker&lt;/a&gt; - A Python package that generates fake data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/radar/" rel="nofollow"&gt;radar&lt;/a&gt; - Generate random datetime / time.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-text-processing" class="anchor" aria-hidden="true" href="#text-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Text Processing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for parsing and manipulating plain texts.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;General
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/chardet/chardet"&gt;chardet&lt;/a&gt; - Python 2/3 compatible character encoding detector.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/difflib.html" rel="nofollow"&gt;difflib&lt;/a&gt; - (Python standard library) Helpers for computing deltas.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/LuminosoInsight/python-ftfy"&gt;ftfy&lt;/a&gt; - Makes Unicode text less broken and more consistent automagically.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/seatgeek/fuzzywuzzy"&gt;fuzzywuzzy&lt;/a&gt; - Fuzzy String Matching.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ztane/python-Levenshtein/"&gt;Levenshtein&lt;/a&gt; - Fast computation of Levenshtein distance and string similarity.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/vinta/pangu.py"&gt;pangu.py&lt;/a&gt; - Paranoid text spacing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pwaller/pyfiglet"&gt;pyfiglet&lt;/a&gt; - An implementation of figlet written in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mozillazg/python-pinyin"&gt;pypinyin&lt;/a&gt; - Convert Chinese hanzi (漢字) to pinyin (拼音).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/orsinium/textdistance"&gt;textdistance&lt;/a&gt; - Compute distance between sequences with 30+ algorithms.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/Unidecode/" rel="nofollow"&gt;unidecode&lt;/a&gt; - ASCII transliterations of Unicode text.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Slugify
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/dimka665/awesome-slugify"&gt;awesome-slugify&lt;/a&gt; - A Python slugify library that can preserve unicode.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/un33k/python-slugify"&gt;python-slugify&lt;/a&gt; - A Python slugify library that translates unicode to ASCII.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mozilla/unicode-slugify"&gt;unicode-slugify&lt;/a&gt; - A slugifier that generates unicode slugs with Django as a dependency.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Unique identifiers
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/davidaurelio/hashids-python"&gt;hashids&lt;/a&gt; - Implementation of &lt;a href="http://hashids.org" rel="nofollow"&gt;hashids&lt;/a&gt; in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/skorokithakis/shortuuid"&gt;shortuuid&lt;/a&gt; - A generator library for concise, unambiguous and URL-safe UUIDs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Parser
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/dabeaz/ply"&gt;ply&lt;/a&gt; - Implementation of lex and yacc parsing tools for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pygments.org/" rel="nofollow"&gt;pygments&lt;/a&gt; - A generic syntax highlighter.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pyparsing/pyparsing"&gt;pyparsing&lt;/a&gt; - A general purpose framework for generating parsers.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/derek73/python-nameparser"&gt;python-nameparser&lt;/a&gt; - Parsing human names into their individual components.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/daviddrysdale/python-phonenumbers"&gt;python-phonenumbers&lt;/a&gt; - Parsing, formatting, storing and validating international phone numbers.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/selwin/python-user-agents"&gt;python-user-agents&lt;/a&gt; - Browser user agent parser.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/andialbrecht/sqlparse"&gt;sqlparse&lt;/a&gt; - A non-validating SQL parser.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-third-party-apis" class="anchor" aria-hidden="true" href="#third-party-apis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Third-party APIs&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for accessing third party services APIs. Also see &lt;a href="https://github.com/realpython/list-of-python-api-wrappers"&gt;List of Python API Wrappers and Libraries&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://libcloud.apache.org/" rel="nofollow"&gt;apache-libcloud&lt;/a&gt; - One Python library for all clouds.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/boto/boto3"&gt;boto3&lt;/a&gt; - Python interface to Amazon Web Services.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/istrategylabs/django-wordpress"&gt;django-wordpress&lt;/a&gt; - WordPress models and views for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mobolic/facebook-sdk"&gt;facebook-sdk&lt;/a&gt; - Facebook Platform Python SDK.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/google-api-python-client"&gt;google-api-python-client&lt;/a&gt; - Google APIs Client Library for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/burnash/gspread"&gt;gspread&lt;/a&gt; - Google Spreadsheets Python API.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ryanmcgrath/twython"&gt;twython&lt;/a&gt; - A Python wrapper for the Twitter API.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-url-manipulation" class="anchor" aria-hidden="true" href="#url-manipulation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;URL Manipulation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for parsing URLs.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/gruns/furl"&gt;furl&lt;/a&gt; - A small Python library that makes parsing and manipulating URLs easy.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/codeinthehole/purl"&gt;purl&lt;/a&gt; - A simple, immutable URL class with a clean API for interrogation and manipulation.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ellisonleao/pyshorteners"&gt;pyshorteners&lt;/a&gt; - A pure Python URL shortening lib.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/marshmallow-code/webargs"&gt;webargs&lt;/a&gt; - A friendly library for parsing HTTP request arguments with built-in support for popular web frameworks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-video" class="anchor" aria-hidden="true" href="#video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Video&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for manipulating video and GIFs.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zulko.github.io/moviepy/" rel="nofollow"&gt;moviepy&lt;/a&gt; - A module for script-based movie editing with many formats, including animated GIFs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/aizvorski/scikit-video"&gt;scikit-video&lt;/a&gt; - Video processing routines for SciPy.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-wsgi-servers" class="anchor" aria-hidden="true" href="#wsgi-servers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WSGI Servers&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;WSGI-compatible web servers.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jonashaag/bjoern"&gt;bjoern&lt;/a&gt; - Asynchronous, very fast and written in C.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/benoitc/gunicorn"&gt;gunicorn&lt;/a&gt; - Pre-forked, partly written in C.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://uwsgi-docs.readthedocs.io/en/latest/" rel="nofollow"&gt;uWSGI&lt;/a&gt; - A project aims at developing a full stack for building hosting services, written in C.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Pylons/waitress"&gt;waitress&lt;/a&gt; - Multi-threaded, powers Pyramid.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pallets/werkzeug"&gt;werkzeug&lt;/a&gt; - A WSGI utility library for Python that powers Flask and can easily be embedded into your own projects.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-web-asset-management" class="anchor" aria-hidden="true" href="#web-asset-management"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web Asset Management&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Tools for managing, compressing and minifying website assets.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/django-compressor/django-compressor"&gt;django-compressor&lt;/a&gt; - Compresses linked and inline JavaScript or CSS into a single cached file.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jazzband/django-pipeline"&gt;django-pipeline&lt;/a&gt; - An asset packaging library for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jschneier/django-storages"&gt;django-storages&lt;/a&gt; - A collection of custom storage back ends for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.fanstatic.org/en/latest/" rel="nofollow"&gt;fanstatic&lt;/a&gt; - Packages, optimizes, and serves static file dependencies as Python packages.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://wimleers.com/fileconveyor" rel="nofollow"&gt;fileconveyor&lt;/a&gt; - A daemon to detect and sync files to CDNs, S3 and FTP.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/miracle2k/flask-assets"&gt;flask-assets&lt;/a&gt; - Helps you integrate webassets into your Flask app.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/miracle2k/webassets"&gt;webassets&lt;/a&gt; - Bundles, optimizes, and manages unique cache-busting URLs for static resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-web-content-extracting" class="anchor" aria-hidden="true" href="#web-content-extracting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web Content Extracting&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for extracting web contents.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Alir3z4/html2text"&gt;html2text&lt;/a&gt; - Convert HTML to Markdown-formatted text.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/michaelhelmick/lassie"&gt;lassie&lt;/a&gt; - Web Content Retrieval for Humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/coleifer/micawber"&gt;micawber&lt;/a&gt; - A small library for extracting rich content from URLs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/codelucas/newspaper"&gt;newspaper&lt;/a&gt; - News extraction, article extraction and content curation in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/buriy/python-readability"&gt;python-readability&lt;/a&gt; - Fast Python port of arc90's readability tool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/requests-html"&gt;requests-html&lt;/a&gt; - Pythonic HTML Parsing for Humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/miso-belica/sumy"&gt;sumy&lt;/a&gt; - A module for automatic summarization of text documents and HTML pages.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/deanmalmgren/textract"&gt;textract&lt;/a&gt; - Extract text from any document, Word, PowerPoint, PDFs, etc.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gaojiuli/toapi"&gt;toapi&lt;/a&gt; - Every web site provides APIs.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-web-crawling" class="anchor" aria-hidden="true" href="#web-crawling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web Crawling&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries to automate web scraping.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/chineking/cola"&gt;cola&lt;/a&gt; - A distributed crawling framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pythonhosted.org/feedparser/" rel="nofollow"&gt;feedparser&lt;/a&gt; - Universal feed parser.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lorien/grab"&gt;grab&lt;/a&gt; - Site scraping framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MechanicalSoup/MechanicalSoup"&gt;MechanicalSoup&lt;/a&gt; - A Python library for automating interaction with websites.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/binux/pyspider"&gt;pyspider&lt;/a&gt; - A powerful spider system.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jmcarp/robobrowser"&gt;robobrowser&lt;/a&gt; - A simple, Pythonic library for browsing the web without a standalone web browser.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://scrapy.org/" rel="nofollow"&gt;scrapy&lt;/a&gt; - A fast high-level screen scraping and web crawling framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/scrapinghub/portia"&gt;portia&lt;/a&gt; - Visual scraping for Scrapy.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-web-frameworks" class="anchor" aria-hidden="true" href="#web-frameworks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web Frameworks&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Full stack web frameworks.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.djangoproject.com/" rel="nofollow"&gt;Django&lt;/a&gt; - The most popular web framework in Python.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/shahraizali/awesome-django"&gt;awesome-django&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://flask.pocoo.org/" rel="nofollow"&gt;Flask&lt;/a&gt; - A microframework for Python.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/humiaozuzu/awesome-flask"&gt;awesome-flask&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MasoniteFramework/masonite"&gt;Masonite&lt;/a&gt; - The modern and developer centric Python web framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pylonsproject.org/" rel="nofollow"&gt;Pyramid&lt;/a&gt; - A small, fast, down-to-earth, open source Python web framework.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/uralbash/awesome-pyramid"&gt;awesome-pyramid&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/channelcat/sanic"&gt;Sanic&lt;/a&gt; - Web server that's written to go fast.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://vibora.io/" rel="nofollow"&gt;Vibora&lt;/a&gt; - Fast, efficient and asynchronous Web framework inspired by Flask.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.tornadoweb.org/en/latest/" rel="nofollow"&gt;Tornado&lt;/a&gt; - A Web framework and asynchronous networking library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-websocket" class="anchor" aria-hidden="true" href="#websocket"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WebSocket&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with WebSocket.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/crossbario/autobahn-python"&gt;autobahn-python&lt;/a&gt; - WebSocket &amp;amp; WAMP for Python on Twisted and &lt;a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow"&gt;asyncio&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/crossbario/crossbar/"&gt;crossbar&lt;/a&gt; - Open-source Unified Application Router (Websocket &amp;amp; WAMP for Python on Autobahn).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/django/channels"&gt;django-channels&lt;/a&gt; - Developer-friendly asynchrony for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/stephenmcd/django-socketio"&gt;django-socketio&lt;/a&gt; - WebSockets for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Lawouach/WebSocket-for-Python"&gt;WebSocket-for-Python&lt;/a&gt; - WebSocket client and server library for Python 2 and 3 as well as PyPy.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-services" class="anchor" aria-hidden="true" href="#services"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Services&lt;/h1&gt;
&lt;p&gt;Online tools and APIs to simplify development.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-continuous-integration" class="anchor" aria-hidden="true" href="#continuous-integration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Continuous Integration&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Also see &lt;a href="https://github.com/ciandcd/awesome-ciandcd#online-build-system"&gt;awesome-CIandCD&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://circleci.com/" rel="nofollow"&gt;CircleCI&lt;/a&gt; - A CI service that can run very fast parallel testing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://travis-ci.org" rel="nofollow"&gt;Travis CI&lt;/a&gt; - A popular CI service for your open source and &lt;a href="https://travis-ci.com" rel="nofollow"&gt;private&lt;/a&gt; projects. (GitHub only)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://vexor.io" rel="nofollow"&gt;Vexor CI&lt;/a&gt; - A continuous integration tool for private apps with pay-per-minute billing model.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.wercker.com/" rel="nofollow"&gt;Wercker&lt;/a&gt; - A Docker-based platform for building and deploying applications and microservices.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-code-quality" class="anchor" aria-hidden="true" href="#code-quality"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code Quality&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.codacy.com/" rel="nofollow"&gt;Codacy&lt;/a&gt; - Automated Code Review to ship better code, faster.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://codecov.io/" rel="nofollow"&gt;Codecov&lt;/a&gt; - Code coverage dashboard.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.codefactor.io/" rel="nofollow"&gt;CodeFactor&lt;/a&gt; - Automated Code Review for Git.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://landscape.io/" rel="nofollow"&gt;Landscape&lt;/a&gt; - Hosted continuous Python code metrics.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pep8speaks.com/" rel="nofollow"&gt;PEP 8 Speaks&lt;/a&gt; - GitHub integration to review code style.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h1&gt;
&lt;p&gt;Where to discover new Python libraries.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-podcasts" class="anchor" aria-hidden="true" href="#podcasts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Podcasts&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://frompythonimportpodcast.com/" rel="nofollow"&gt;From Python Import Podcast&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://podcastinit.com/" rel="nofollow"&gt;Podcast.init&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pythonbytes.fm" rel="nofollow"&gt;Python Bytes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pythontesting.net" rel="nofollow"&gt;Python Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://radiofreepython.com/" rel="nofollow"&gt;Radio Free Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://talkpython.fm/" rel="nofollow"&gt;Talk Python To Me&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://testandcode.com/" rel="nofollow"&gt;Test and Code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-twitter" class="anchor" aria-hidden="true" href="#twitter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Twitter&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://twitter.com/codetengu" rel="nofollow"&gt;@codetengu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/getpy" rel="nofollow"&gt;@getpy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/importpython" rel="nofollow"&gt;@importpython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/planetpython" rel="nofollow"&gt;@planetpython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/pycoders" rel="nofollow"&gt;@pycoders&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/pypi" rel="nofollow"&gt;@pypi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/pythontrending" rel="nofollow"&gt;@pythontrending&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/PythonWeekly" rel="nofollow"&gt;@PythonWeekly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/talkpython" rel="nofollow"&gt;@TalkPython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/realpython" rel="nofollow"&gt;@realpython&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-websites" class="anchor" aria-hidden="true" href="#websites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Websites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/coolgithubprojects/" rel="nofollow"&gt;/r/CoolGithubProjects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/python" rel="nofollow"&gt;/r/Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://python.libhunt.com/" rel="nofollow"&gt;Awesome Python @LibHunt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://djangopackages.org/" rel="nofollow"&gt;Django Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.fullstackpython.com/" rel="nofollow"&gt;Full Stack Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.pythoncheatsheet.org/" rel="nofollow"&gt;Python Cheatsheet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://python.zeef.com/alan.richmond" rel="nofollow"&gt;Python ZEEF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ctolib.com/python/" rel="nofollow"&gt;Python 开发社区&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://realpython.com" rel="nofollow"&gt;Real Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/trending?l=python"&gt;Trending Python repositories on GitHub today&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://python-scripts.com/" rel="nofollow"&gt;Сообщество Python Программистов&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-weekly" class="anchor" aria-hidden="true" href="#weekly"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Weekly&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://weekly.codetengu.com/" rel="nofollow"&gt;CodeTengu Weekly 碼天狗週刊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://importpython.com/newsletter/" rel="nofollow"&gt;Import Python Newsletter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pycoders.com/" rel="nofollow"&gt;Pycoder's Weekly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pythonweekly.com/" rel="nofollow"&gt;Python Weekly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://realpython.com/python-tricks/" rel="nofollow"&gt;Python Tricks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h1&gt;
&lt;p&gt;Your contributions are always welcome! Please take a look at the &lt;a href="https://github.com/vinta/awesome-python/blob/master/CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt; first.&lt;/p&gt;
&lt;p&gt;I will keep some pull requests open if I'm not sure whether those libraries are awesome, you could &lt;a href="https://github.com/vinta/awesome-python/pulls"&gt;vote for them&lt;/a&gt; by adding &lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt; to them. Pull requests will be merged when their votes reach &lt;strong&gt;20&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;If you have any question about this opinionated list, do not hesitate to contact me &lt;a href="https://twitter.com/vinta" rel="nofollow"&gt;@vinta&lt;/a&gt; on Twitter or open an issue on GitHub.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>vinta</author><guid isPermaLink="false">https://github.com/vinta/awesome-python</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>nvbn/thefuck #11 in Python, This week</title><link>https://github.com/nvbn/thefuck</link><description>&lt;p&gt;&lt;i&gt;Magnificent app which corrects your previous console command.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-the-fuck-----" class="anchor" aria-hidden="true" href="#the-fuck-----"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Fuck &lt;a href="https://pypi.python.org/pypi/thefuck/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1354b987be5b712a696ce297c86f3b8bf75fc718/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7468656675636b2e7376673f6c6162656c3d76657273696f6e" alt="Version" data-canonical-src="https://img.shields.io/pypi/v/thefuck.svg?label=version" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://travis-ci.org/nvbn/thefuck" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/420a5527201a2037e3452204bc5f3a24e873e131/68747470733a2f2f7472617669732d63692e6f72672f6e76626e2f7468656675636b2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/nvbn/thefuck.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://ci.appveyor.com/project/nvbn/thefuck" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/148742d6f0fc1e93fda3d900f83e250b8c57eb8c/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f3173736b6a34696d6a3032756d3067752f6272616e63682f6d61737465723f7376673d74727565" alt="Windows Build Status" data-canonical-src="https://ci.appveyor.com/api/projects/status/1sskj4imj02um0gu/branch/master?svg=true" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/github/nvbn/thefuck" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/b31627a753c4602df5a3ae332331f19217285467/68747470733a2f2f696d672e736869656c64732e696f2f636f766572616c6c732f6e76626e2f7468656675636b2e737667" alt="Coverage" data-canonical-src="https://img.shields.io/coveralls/nvbn/thefuck.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="LICENSE.md"&gt;&lt;img src="https://camo.githubusercontent.com/a4a2b602f35a6fb803d4c7b56d9b2bf1bebb7748/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d3030374543372e737667" alt="MIT License" data-canonical-src="https://img.shields.io/badge/license-MIT-007EC7.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;The Fuck&lt;/em&gt; is a magnificent app, inspired by a &lt;a href="https://twitter.com/liamosaur/" rel="nofollow"&gt;@liamosaur&lt;/a&gt;
&lt;a href="https://twitter.com/liamosaur/status/506975850596536320" rel="nofollow"&gt;tweet&lt;/a&gt;,
that corrects errors in previous console commands.&lt;/p&gt;
&lt;p&gt;Is &lt;em&gt;The Fuck&lt;/em&gt; too slow? &lt;a href="#experimental-instant-mode"&gt;Try the experimental instant mode!&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/nvbn/thefuck/master/example.gif" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/nvbn/thefuck/master/example.gif" alt="gif with examples" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More examples:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;➜ apt-get install vim
E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)
E: Unable to lock the administration directory (/var/lib/dpkg/), are you root&lt;span class="pl-k"&gt;?&lt;/span&gt;

➜ fuck
sudo apt-get install vim [enter/↑/↓/ctrl+c]
[sudo] password &lt;span class="pl-k"&gt;for&lt;/span&gt; nvbn:
Reading package lists... Done
...&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;➜ git push
fatal: The current branch master has no upstream branch.
To push the current branch and &lt;span class="pl-c1"&gt;set&lt;/span&gt; the remote as upstream, use

    git push --set-upstream origin master


➜ fuck
git push --set-upstream origin master [enter/↑/↓/ctrl+c]
Counting objects: 9, done.
...&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;➜ puthon
No &lt;span class="pl-c1"&gt;command&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;puthon&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; found, did you mean:
 Command &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;python&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; from package &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;python-minimal&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; (main)
 Command &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;python&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; from package &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;python3&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; (main)
zsh: &lt;span class="pl-c1"&gt;command&lt;/span&gt; not found: puthon

➜ fuck
python [enter/↑/↓/ctrl+c]
Python 3.4.2 (default, Oct  8 2014, 13:08:17)
...&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;➜ git brnch
git: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;brnch&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; is not a git command. See &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;git --help&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.

Did you mean this&lt;span class="pl-k"&gt;?&lt;/span&gt;
    branch

➜ fuck
git branch [enter/↑/↓/ctrl+c]
&lt;span class="pl-k"&gt;*&lt;/span&gt; master&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;➜ lein rpl
&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;rpl&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; is not a task. See &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;lein help&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.

Did you mean this&lt;span class="pl-k"&gt;?&lt;/span&gt;
         repl

➜ fuck
lein repl [enter/↑/↓/ctrl+c]
nREPL server started on port 54848 on host 127.0.0.1 - nrepl://127.0.0.1:54848
REPL-y 0.3.1
...&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you're not afraid of blindly running corrected commands, the
&lt;code&gt;require_confirmation&lt;/code&gt; &lt;a href="#settings"&gt;settings&lt;/a&gt; option can be disabled:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;➜ apt-get install vim
E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)
E: Unable to lock the administration directory (/var/lib/dpkg/), are you root&lt;span class="pl-k"&gt;?&lt;/span&gt;

➜ fuck
sudo apt-get install vim
[sudo] password &lt;span class="pl-k"&gt;for&lt;/span&gt; nvbn:
Reading package lists... Done
...&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;python (3.4+)&lt;/li&gt;
&lt;li&gt;pip&lt;/li&gt;
&lt;li&gt;python-dev&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;On OS X, you can install &lt;em&gt;The Fuck&lt;/em&gt; via &lt;a href="https://brew.sh/" rel="nofollow"&gt;Homebrew&lt;/a&gt; (or via &lt;a href="https://linuxbrew.sh/" rel="nofollow"&gt;Linuxbrew&lt;/a&gt; on Linux):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;brew install thefuck&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On Ubuntu / Mint, install &lt;em&gt;The Fuck&lt;/em&gt; with the following commands:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo apt update
sudo apt install python3-dev python3-pip python3-setuptools
sudo pip3 install thefuck&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On FreeBSD, install &lt;em&gt;The Fuck&lt;/em&gt; with the following commands:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pkg install thefuck&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On ChromeOS, install &lt;em&gt;The Fuck&lt;/em&gt; using &lt;a href="https://github.com/skycocker/chromebrew"&gt;chromebrew&lt;/a&gt; with the following command:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;crew install thefuck&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On other systems, install &lt;em&gt;The Fuck&lt;/em&gt;  by using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install thefuck&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://github.com/nvbn/thefuck/wiki/Installation"&gt;Alternatively, you may use an OS package manager (OS X, Ubuntu, Arch).&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="#manual-installation" name="user-content-manual-installation"&gt;#&lt;/a&gt;
It is recommended that you place this command in your &lt;code&gt;.bash_profile&lt;/code&gt;,
&lt;code&gt;.bashrc&lt;/code&gt;, &lt;code&gt;.zshrc&lt;/code&gt; or other startup script:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;eval&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;thefuck --alias&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; You can use whatever you want as an alias, like for Mondays:&lt;/span&gt;
&lt;span class="pl-c1"&gt;eval&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;thefuck --alias FUCK&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://github.com/nvbn/thefuck/wiki/Shell-aliases"&gt;Or in your shell config (Bash, Zsh, Fish, Powershell, tcsh).&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Changes are only available in a new shell session. To make changes immediately
available, run &lt;code&gt;source ~/.bashrc&lt;/code&gt; (or your shell config file like &lt;code&gt;.zshrc&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;To run fixed commands without confirmation, use the &lt;code&gt;--yeah&lt;/code&gt; option (or just &lt;code&gt;-y&lt;/code&gt; for short, or &lt;code&gt;--hard&lt;/code&gt; if you're especially frustrated):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;fuck --yeah&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To fix commands recursively until succeeding, use the &lt;code&gt;-r&lt;/code&gt; option:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;fuck -r&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-updating" class="anchor" aria-hidden="true" href="#updating"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Updating&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip3 install thefuck --upgrade&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Note: Alias functionality was changed in v1.34 of &lt;em&gt;The Fuck&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-it-works" class="anchor" aria-hidden="true" href="#how-it-works"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How it works&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;The Fuck&lt;/em&gt; attempts to match the previous command with a rule. If a match is
found, a new command is created using the matched rule and executed. The
following rules are enabled by default:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;adb_unknown_command&lt;/code&gt; – fixes misspelled commands like &lt;code&gt;adb logcta&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ag_literal&lt;/code&gt; – adds &lt;code&gt;-Q&lt;/code&gt; to &lt;code&gt;ag&lt;/code&gt; when suggested;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;aws_cli&lt;/code&gt; – fixes misspelled commands like &lt;code&gt;aws dynamdb scan&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;az_cli&lt;/code&gt; – fixes misspelled commands like &lt;code&gt;az providers&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cargo&lt;/code&gt; – runs &lt;code&gt;cargo build&lt;/code&gt; instead of &lt;code&gt;cargo&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cargo_no_command&lt;/code&gt; – fixes wrongs commands like &lt;code&gt;cargo buid&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cat_dir&lt;/code&gt; – replaces &lt;code&gt;cat&lt;/code&gt; with &lt;code&gt;ls&lt;/code&gt; when you try to &lt;code&gt;cat&lt;/code&gt; a directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd_correction&lt;/code&gt; – spellchecks and correct failed cd commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd_mkdir&lt;/code&gt; – creates directories before cd'ing into them;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd_parent&lt;/code&gt; – changes &lt;code&gt;cd..&lt;/code&gt; to &lt;code&gt;cd ..&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;chmod_x&lt;/code&gt; – add execution bit;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;composer_not_command&lt;/code&gt; – fixes composer command name;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cp_omitting_directory&lt;/code&gt; – adds &lt;code&gt;-a&lt;/code&gt; when you &lt;code&gt;cp&lt;/code&gt; directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cpp11&lt;/code&gt; – adds missing &lt;code&gt;-std=c++11&lt;/code&gt; to &lt;code&gt;g++&lt;/code&gt; or &lt;code&gt;clang++&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dirty_untar&lt;/code&gt; – fixes &lt;code&gt;tar x&lt;/code&gt; command that untarred in the current directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dirty_unzip&lt;/code&gt; – fixes &lt;code&gt;unzip&lt;/code&gt; command that unzipped in the current directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;django_south_ghost&lt;/code&gt; – adds &lt;code&gt;--delete-ghost-migrations&lt;/code&gt; to failed because ghosts django south migration;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;django_south_merge&lt;/code&gt; – adds &lt;code&gt;--merge&lt;/code&gt; to inconsistent django south migration;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker_login&lt;/code&gt; – executes a &lt;code&gt;docker login&lt;/code&gt; and repeats the previous command;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker_not_command&lt;/code&gt; – fixes wrong docker commands like &lt;code&gt;docker tags&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker_image_being_used_by_container&lt;/code&gt; ‐ removes the container that is using the image before removing the image;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dry&lt;/code&gt; – fixes repetitions like &lt;code&gt;git git push&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fab_command_not_found&lt;/code&gt; – fix misspelled fabric commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fix_alt_space&lt;/code&gt; – replaces Alt+Space with Space character;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fix_file&lt;/code&gt; – opens a file with an error in your &lt;code&gt;$EDITOR&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gem_unknown_command&lt;/code&gt; – fixes wrong &lt;code&gt;gem&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_add&lt;/code&gt; – fixes &lt;em&gt;"pathspec 'foo' did not match any file(s) known to git."&lt;/em&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_add_force&lt;/code&gt; – adds &lt;code&gt;--force&lt;/code&gt; to &lt;code&gt;git add &amp;lt;pathspec&amp;gt;...&lt;/code&gt; when paths are .gitignore'd;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_bisect_usage&lt;/code&gt; – fixes &lt;code&gt;git bisect strt&lt;/code&gt;, &lt;code&gt;git bisect goood&lt;/code&gt;, &lt;code&gt;git bisect rset&lt;/code&gt;, etc. when bisecting;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_branch_delete&lt;/code&gt; – changes &lt;code&gt;git branch -d&lt;/code&gt; to &lt;code&gt;git branch -D&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_branch_delete_checked_out&lt;/code&gt; – changes &lt;code&gt;git branch -d&lt;/code&gt; to &lt;code&gt;git checkout master &amp;amp;&amp;amp; git branch -D&lt;/code&gt; when trying to delete a checked out branch;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_branch_exists&lt;/code&gt; – offers &lt;code&gt;git branch -d foo&lt;/code&gt;, &lt;code&gt;git branch -D foo&lt;/code&gt; or &lt;code&gt;git checkout foo&lt;/code&gt; when creating a branch that already exists;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_branch_list&lt;/code&gt; – catches &lt;code&gt;git branch list&lt;/code&gt; in place of &lt;code&gt;git branch&lt;/code&gt; and removes created branch;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_checkout&lt;/code&gt; – fixes branch name or creates new branch;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_commit_amend&lt;/code&gt; – offers &lt;code&gt;git commit --amend&lt;/code&gt; after previous commit;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_commit_reset&lt;/code&gt; – offers &lt;code&gt;git reset HEAD~&lt;/code&gt; after previous commit;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_diff_no_index&lt;/code&gt; – adds &lt;code&gt;--no-index&lt;/code&gt; to previous &lt;code&gt;git diff&lt;/code&gt; on untracked files;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_diff_staged&lt;/code&gt; – adds &lt;code&gt;--staged&lt;/code&gt; to previous &lt;code&gt;git diff&lt;/code&gt; with unexpected output;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_fix_stash&lt;/code&gt; – fixes &lt;code&gt;git stash&lt;/code&gt; commands (misspelled subcommand and missing &lt;code&gt;save&lt;/code&gt;);&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_flag_after_filename&lt;/code&gt; – fixes &lt;code&gt;fatal: bad flag '...' after filename&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_help_aliased&lt;/code&gt; – fixes &lt;code&gt;git help &amp;lt;alias&amp;gt;&lt;/code&gt; commands replacing  with the aliased command;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_merge&lt;/code&gt; – adds remote to branch names;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_merge_unrelated&lt;/code&gt; – adds &lt;code&gt;--allow-unrelated-histories&lt;/code&gt; when required&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_not_command&lt;/code&gt; – fixes wrong git commands like &lt;code&gt;git brnch&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_pull&lt;/code&gt; – sets upstream before executing previous &lt;code&gt;git pull&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_pull_clone&lt;/code&gt; – clones instead of pulling when the repo does not exist;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_pull_uncommitted_changes&lt;/code&gt; – stashes changes before pulling and pops them afterwards;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_push&lt;/code&gt; – adds &lt;code&gt;--set-upstream origin $branch&lt;/code&gt; to previous failed &lt;code&gt;git push&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_push_different_branch_names&lt;/code&gt; – fixes pushes when local brach name does not match remote branch name;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_push_pull&lt;/code&gt; – runs &lt;code&gt;git pull&lt;/code&gt; when &lt;code&gt;push&lt;/code&gt; was rejected;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_push_without_commits&lt;/code&gt; – Creates an initial commit if you forget and only &lt;code&gt;git add .&lt;/code&gt;, when setting up a new project;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_rebase_no_changes&lt;/code&gt; – runs &lt;code&gt;git rebase --skip&lt;/code&gt; instead of &lt;code&gt;git rebase --continue&lt;/code&gt; when there are no changes;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_remote_delete&lt;/code&gt; – replaces &lt;code&gt;git remote delete remote_name&lt;/code&gt; with &lt;code&gt;git remote remove remote_name&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_rm_local_modifications&lt;/code&gt; –  adds &lt;code&gt;-f&lt;/code&gt; or &lt;code&gt;--cached&lt;/code&gt; when you try to &lt;code&gt;rm&lt;/code&gt; a locally modified file;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_rm_recursive&lt;/code&gt; – adds &lt;code&gt;-r&lt;/code&gt; when you try to &lt;code&gt;rm&lt;/code&gt; a directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_rm_staged&lt;/code&gt; –  adds &lt;code&gt;-f&lt;/code&gt; or &lt;code&gt;--cached&lt;/code&gt; when you try to &lt;code&gt;rm&lt;/code&gt; a file with staged changes&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_rebase_merge_dir&lt;/code&gt; – offers &lt;code&gt;git rebase (--continue | --abort | --skip)&lt;/code&gt; or removing the &lt;code&gt;.git/rebase-merge&lt;/code&gt; dir when a rebase is in progress;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_remote_seturl_add&lt;/code&gt; – runs &lt;code&gt;git remote add&lt;/code&gt; when &lt;code&gt;git remote set_url&lt;/code&gt; on nonexistant remote;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_stash&lt;/code&gt; – stashes your local modifications before rebasing or switching branch;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_stash_pop&lt;/code&gt; – adds your local modifications before popping stash, then resets;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_tag_force&lt;/code&gt; – adds &lt;code&gt;--force&lt;/code&gt; to &lt;code&gt;git tag &amp;lt;tagname&amp;gt;&lt;/code&gt; when the tag already exists;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_two_dashes&lt;/code&gt; – adds a missing dash to commands like &lt;code&gt;git commit -amend&lt;/code&gt; or &lt;code&gt;git rebase -continue&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;go_run&lt;/code&gt; – appends &lt;code&gt;.go&lt;/code&gt; extension when compiling/running Go programs;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;go_unknown_command&lt;/code&gt; – fixes wrong &lt;code&gt;go&lt;/code&gt; commands, for example &lt;code&gt;go bulid&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gradle_no_task&lt;/code&gt; – fixes not found or ambiguous &lt;code&gt;gradle&lt;/code&gt; task;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gradle_wrapper&lt;/code&gt; – replaces &lt;code&gt;gradle&lt;/code&gt; with &lt;code&gt;./gradlew&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;grep_arguments_order&lt;/code&gt; – fixes &lt;code&gt;grep&lt;/code&gt; arguments order for situations like &lt;code&gt;grep -lir . test&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;grep_recursive&lt;/code&gt; – adds &lt;code&gt;-r&lt;/code&gt; when you try to &lt;code&gt;grep&lt;/code&gt; directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;grunt_task_not_found&lt;/code&gt; – fixes misspelled &lt;code&gt;grunt&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gulp_not_task&lt;/code&gt; – fixes misspelled &lt;code&gt;gulp&lt;/code&gt; tasks;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;has_exists_script&lt;/code&gt; – prepends &lt;code&gt;./&lt;/code&gt; when script/binary exists;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;heroku_multiple_apps&lt;/code&gt; – add &lt;code&gt;--app &amp;lt;app&amp;gt;&lt;/code&gt; to &lt;code&gt;heroku&lt;/code&gt; commands like &lt;code&gt;heroku pg&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;heroku_not_command&lt;/code&gt; – fixes wrong &lt;code&gt;heroku&lt;/code&gt; commands like &lt;code&gt;heroku log&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;history&lt;/code&gt; – tries to replace command with most similar command from history;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hostscli&lt;/code&gt; – tries to fix &lt;code&gt;hostscli&lt;/code&gt; usage;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ifconfig_device_not_found&lt;/code&gt; – fixes wrong device names like &lt;code&gt;wlan0&lt;/code&gt; to &lt;code&gt;wlp2s0&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;java&lt;/code&gt; – removes &lt;code&gt;.java&lt;/code&gt; extension when running Java programs;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;javac&lt;/code&gt; – appends missing &lt;code&gt;.java&lt;/code&gt; when compiling Java files;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lein_not_task&lt;/code&gt; – fixes wrong &lt;code&gt;lein&lt;/code&gt; tasks like &lt;code&gt;lein rpl&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;long_form_help&lt;/code&gt; – changes &lt;code&gt;-h&lt;/code&gt; to &lt;code&gt;--help&lt;/code&gt; when the short form version is not supported&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ln_no_hard_link&lt;/code&gt; – catches hard link creation on directories, suggest symbolic link;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ln_s_order&lt;/code&gt; – fixes &lt;code&gt;ln -s&lt;/code&gt; arguments order;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ls_all&lt;/code&gt; – adds &lt;code&gt;-A&lt;/code&gt; to &lt;code&gt;ls&lt;/code&gt; when output is empty;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ls_lah&lt;/code&gt; – adds &lt;code&gt;-lah&lt;/code&gt; to &lt;code&gt;ls&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;man&lt;/code&gt; – changes manual section;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;man_no_space&lt;/code&gt; – fixes man commands without spaces, for example &lt;code&gt;mandiff&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mercurial&lt;/code&gt; – fixes wrong &lt;code&gt;hg&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;missing_space_before_subcommand&lt;/code&gt; – fixes command with missing space like &lt;code&gt;npminstall&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mkdir_p&lt;/code&gt; – adds &lt;code&gt;-p&lt;/code&gt; when you try to create a directory without parent;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn_no_command&lt;/code&gt; – adds &lt;code&gt;clean package&lt;/code&gt; to &lt;code&gt;mvn&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn_unknown_lifecycle_phase&lt;/code&gt; – fixes misspelled lifecycle phases with &lt;code&gt;mvn&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;npm_missing_script&lt;/code&gt; – fixes &lt;code&gt;npm&lt;/code&gt; custom script name in &lt;code&gt;npm run-script &amp;lt;script&amp;gt;&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;npm_run_script&lt;/code&gt; – adds missing &lt;code&gt;run-script&lt;/code&gt; for custom &lt;code&gt;npm&lt;/code&gt; scripts;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;npm_wrong_command&lt;/code&gt; – fixes wrong npm commands like &lt;code&gt;npm urgrade&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;no_command&lt;/code&gt; – fixes wrong console commands, for example &lt;code&gt;vom/vim&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;no_such_file&lt;/code&gt; – creates missing directories with &lt;code&gt;mv&lt;/code&gt; and &lt;code&gt;cp&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;open&lt;/code&gt; – either prepends &lt;code&gt;http://&lt;/code&gt; to address passed to &lt;code&gt;open&lt;/code&gt; or create a new file or directory and passes it to &lt;code&gt;open&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pip_install&lt;/code&gt; – fixes permission issues with &lt;code&gt;pip install&lt;/code&gt; commands by adding &lt;code&gt;--user&lt;/code&gt; or prepending &lt;code&gt;sudo&lt;/code&gt; if necessary;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pip_unknown_command&lt;/code&gt; – fixes wrong &lt;code&gt;pip&lt;/code&gt; commands, for example &lt;code&gt;pip instatl/pip install&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;php_s&lt;/code&gt; – replaces &lt;code&gt;-s&lt;/code&gt; by &lt;code&gt;-S&lt;/code&gt; when trying to run a local php server;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;port_already_in_use&lt;/code&gt; – kills process that bound port;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;prove_recursively&lt;/code&gt; – adds &lt;code&gt;-r&lt;/code&gt; when called with directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pyenv_no_such_command&lt;/code&gt; – fixes wrong pyenv commands like &lt;code&gt;pyenv isntall&lt;/code&gt; or &lt;code&gt;pyenv list&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;python_command&lt;/code&gt; – prepends &lt;code&gt;python&lt;/code&gt; when you try to run non-executable/without &lt;code&gt;./&lt;/code&gt; python script;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;python_execute&lt;/code&gt; – appends missing &lt;code&gt;.py&lt;/code&gt; when executing Python files;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;quotation_marks&lt;/code&gt; – fixes uneven usage of &lt;code&gt;'&lt;/code&gt; and &lt;code&gt;"&lt;/code&gt; when containing args';&lt;/li&gt;
&lt;li&gt;&lt;code&gt;path_from_history&lt;/code&gt; – replaces not found path with similar absolute path from history;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;react_native_command_unrecognized&lt;/code&gt; – fixes unrecognized &lt;code&gt;react-native&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;remove_trailing_cedilla&lt;/code&gt; – remove trailling cedillas &lt;code&gt;ç&lt;/code&gt;, a common typo for european keyboard layouts;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rm_dir&lt;/code&gt; – adds &lt;code&gt;-rf&lt;/code&gt; when you try to remove a directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;scm_correction&lt;/code&gt; – corrects wrong scm like &lt;code&gt;hg log&lt;/code&gt; to &lt;code&gt;git log&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sed_unterminated_s&lt;/code&gt; – adds missing '/' to &lt;code&gt;sed&lt;/code&gt;'s &lt;code&gt;s&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sl_ls&lt;/code&gt; – changes &lt;code&gt;sl&lt;/code&gt; to &lt;code&gt;ls&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ssh_known_hosts&lt;/code&gt; – removes host from &lt;code&gt;known_hosts&lt;/code&gt; on warning;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sudo&lt;/code&gt; – prepends &lt;code&gt;sudo&lt;/code&gt; to previous command if it failed because of permissions;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sudo_command_from_user_path&lt;/code&gt; – runs commands from users &lt;code&gt;$PATH&lt;/code&gt; with &lt;code&gt;sudo&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;switch_lang&lt;/code&gt; – switches command from your local layout to en;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;systemctl&lt;/code&gt; – correctly orders parameters of confusing &lt;code&gt;systemctl&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;terraform_init.py&lt;/code&gt; – run &lt;code&gt;terraform init&lt;/code&gt; before plan or apply;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;test.py&lt;/code&gt; – runs &lt;code&gt;py.test&lt;/code&gt; instead of &lt;code&gt;test.py&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;touch&lt;/code&gt; – creates missing directories before "touching";&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tsuru_login&lt;/code&gt; – runs &lt;code&gt;tsuru login&lt;/code&gt; if not authenticated or session expired;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tsuru_not_command&lt;/code&gt; – fixes wrong &lt;code&gt;tsuru&lt;/code&gt; commands like &lt;code&gt;tsuru shell&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tmux&lt;/code&gt; – fixes &lt;code&gt;tmux&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;unknown_command&lt;/code&gt; – fixes hadoop hdfs-style "unknown command", for example adds missing '-' to the command on &lt;code&gt;hdfs dfs ls&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;unsudo&lt;/code&gt; – removes &lt;code&gt;sudo&lt;/code&gt; from previous command if a process refuses to run on super user privilege.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vagrant_up&lt;/code&gt; – starts up the vagrant instance;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;whois&lt;/code&gt; – fixes &lt;code&gt;whois&lt;/code&gt; command;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;workon_doesnt_exists&lt;/code&gt; – fixes &lt;code&gt;virtualenvwrapper&lt;/code&gt; env name os suggests to create new.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn_alias&lt;/code&gt; – fixes aliased &lt;code&gt;yarn&lt;/code&gt; commands like &lt;code&gt;yarn ls&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn_command_not_found&lt;/code&gt; – fixes misspelled &lt;code&gt;yarn&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn_command_replaced&lt;/code&gt; – fixes replaced &lt;code&gt;yarn&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn_help&lt;/code&gt; – makes it easier to open &lt;code&gt;yarn&lt;/code&gt; documentation;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following rules are enabled by default on specific platforms only:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;apt_get&lt;/code&gt; – installs app from apt if it not installed (requires &lt;code&gt;python-commandnotfound&lt;/code&gt; / &lt;code&gt;python3-commandnotfound&lt;/code&gt;);&lt;/li&gt;
&lt;li&gt;&lt;code&gt;apt_get_search&lt;/code&gt; – changes trying to search using &lt;code&gt;apt-get&lt;/code&gt; with searching using &lt;code&gt;apt-cache&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;apt_invalid_operation&lt;/code&gt; – fixes invalid &lt;code&gt;apt&lt;/code&gt; and &lt;code&gt;apt-get&lt;/code&gt; calls, like &lt;code&gt;apt-get isntall vim&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;apt_list_upgradable&lt;/code&gt; – helps you run &lt;code&gt;apt list --upgradable&lt;/code&gt; after &lt;code&gt;apt update&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;apt_upgrade&lt;/code&gt; – helps you run &lt;code&gt;apt upgrade&lt;/code&gt; after &lt;code&gt;apt list --upgradable&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_cask_dependency&lt;/code&gt; – installs cask dependencies;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_install&lt;/code&gt; – fixes formula name for &lt;code&gt;brew install&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_reinstall&lt;/code&gt; – turns &lt;code&gt;brew install &amp;lt;formula&amp;gt;&lt;/code&gt; into &lt;code&gt;brew reinstall &amp;lt;formula&amp;gt;&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_link&lt;/code&gt; – adds &lt;code&gt;--overwrite --dry-run&lt;/code&gt; if linking fails;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_uninstall&lt;/code&gt; – adds &lt;code&gt;--force&lt;/code&gt; to &lt;code&gt;brew uninstall&lt;/code&gt; if multiple versions were installed;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_unknown_command&lt;/code&gt; – fixes wrong brew commands, for example &lt;code&gt;brew docto/brew doctor&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_update_formula&lt;/code&gt; – turns &lt;code&gt;brew update &amp;lt;formula&amp;gt;&lt;/code&gt; into &lt;code&gt;brew upgrade &amp;lt;formula&amp;gt;&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dnf_no_such_command&lt;/code&gt; – fixes mistyped DNF commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nixos_cmd_not_found&lt;/code&gt; – installs apps on NixOS;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pacman&lt;/code&gt; – installs app with &lt;code&gt;pacman&lt;/code&gt; if it is not installed (uses &lt;code&gt;yay&lt;/code&gt; or &lt;code&gt;yaourt&lt;/code&gt; if available);&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pacman_not_found&lt;/code&gt; – fixes package name with &lt;code&gt;pacman&lt;/code&gt;, &lt;code&gt;yay&lt;/code&gt; or &lt;code&gt;yaourt&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yum_invalid_operation&lt;/code&gt; – fixes invalid &lt;code&gt;yum&lt;/code&gt; calls, like &lt;code&gt;yum isntall vim&lt;/code&gt;;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following commands are bundled with &lt;em&gt;The Fuck&lt;/em&gt;, but are not enabled by
default:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;git_push_force&lt;/code&gt; – adds &lt;code&gt;--force-with-lease&lt;/code&gt; to a &lt;code&gt;git push&lt;/code&gt; (may conflict with &lt;code&gt;git_push_pull&lt;/code&gt;);&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rm_root&lt;/code&gt; – adds &lt;code&gt;--no-preserve-root&lt;/code&gt; to &lt;code&gt;rm -rf /&lt;/code&gt; command.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-creating-your-own-rules" class="anchor" aria-hidden="true" href="#creating-your-own-rules"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Creating your own rules&lt;/h2&gt;
&lt;p&gt;To add your own rule, create a file named &lt;code&gt;your-rule-name.py&lt;/code&gt;
in &lt;code&gt;~/.config/thefuck/rules&lt;/code&gt;. The rule file must contain two functions:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;match(command: Command) &lt;span class="pl-ii"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;bool&lt;/span&gt;
get_new_command(command: Command) &lt;span class="pl-ii"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;str&lt;/span&gt; &lt;span class="pl-k"&gt;|&lt;/span&gt; list[&lt;span class="pl-c1"&gt;str&lt;/span&gt;]&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Additionally, rules can contain optional functions:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;side_effect(old_command: Command, fixed_command: &lt;span class="pl-c1"&gt;str&lt;/span&gt;) &lt;span class="pl-ii"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Rules can also contain the optional variables &lt;code&gt;enabled_by_default&lt;/code&gt;, &lt;code&gt;requires_output&lt;/code&gt; and &lt;code&gt;priority&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Command&lt;/code&gt; has three attributes: &lt;code&gt;script&lt;/code&gt;, &lt;code&gt;output&lt;/code&gt; and &lt;code&gt;script_parts&lt;/code&gt;.
Your rule should not change &lt;code&gt;Command&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rules api changed in 3.0:&lt;/strong&gt; To access a rule's settings, import it with
&lt;code&gt;from thefuck.conf import settings&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;settings&lt;/code&gt; is a special object assembled from &lt;code&gt;~/.config/thefuck/settings.py&lt;/code&gt;,
and values from env (&lt;a href="#settings"&gt;see more below&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;A simple example rule for running a script with &lt;code&gt;sudo&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;match&lt;/span&gt;(&lt;span class="pl-smi"&gt;command&lt;/span&gt;):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; (&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;permission denied&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;in&lt;/span&gt; command.output.lower()
            &lt;span class="pl-k"&gt;or&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;EACCES&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;in&lt;/span&gt; command.output)


&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;get_new_command&lt;/span&gt;(&lt;span class="pl-smi"&gt;command&lt;/span&gt;):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sudo &lt;span class="pl-c1"&gt;{}&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.format(command.script)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Optional:&lt;/span&gt;
enabled_by_default &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;True&lt;/span&gt;

&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;side_effect&lt;/span&gt;(&lt;span class="pl-smi"&gt;command&lt;/span&gt;, &lt;span class="pl-smi"&gt;fixed_command&lt;/span&gt;):
    subprocess.call(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;chmod 777 .&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;shell&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)

priority &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1000&lt;/span&gt;  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Lower first, default is 1000&lt;/span&gt;

requires_output &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;True&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://github.com/nvbn/thefuck/tree/master/thefuck/rules"&gt;More examples of rules&lt;/a&gt;,
&lt;a href="https://github.com/nvbn/thefuck/tree/master/thefuck/utils.py"&gt;utility functions for rules&lt;/a&gt;,
&lt;a href="https://github.com/nvbn/thefuck/tree/master/thefuck/specific/"&gt;app/os-specific helpers&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-settings" class="anchor" aria-hidden="true" href="#settings"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Settings&lt;/h2&gt;
&lt;p&gt;Several &lt;em&gt;The Fuck&lt;/em&gt; parameters can be changed in the file &lt;code&gt;$XDG_CONFIG_HOME/thefuck/settings.py&lt;/code&gt;
(&lt;code&gt;$XDG_CONFIG_HOME&lt;/code&gt; defaults to &lt;code&gt;~/.config&lt;/code&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rules&lt;/code&gt; – list of enabled rules, by default &lt;code&gt;thefuck.conf.DEFAULT_RULES&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;exclude_rules&lt;/code&gt; – list of disabled rules, by default &lt;code&gt;[]&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;require_confirmation&lt;/code&gt; – requires confirmation before running new command, by default &lt;code&gt;True&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wait_command&lt;/code&gt; – max amount of time in seconds for getting previous command output;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;no_colors&lt;/code&gt; – disable colored output;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;priority&lt;/code&gt; – dict with rules priorities, rule with lower &lt;code&gt;priority&lt;/code&gt; will be matched first;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;debug&lt;/code&gt; – enables debug output, by default &lt;code&gt;False&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;history_limit&lt;/code&gt; – numeric value of how many history commands will be scanned, like &lt;code&gt;2000&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;alter_history&lt;/code&gt; – push fixed command to history, by default &lt;code&gt;True&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wait_slow_command&lt;/code&gt; – max amount of time in seconds for getting previous command output if it in &lt;code&gt;slow_commands&lt;/code&gt; list;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;slow_commands&lt;/code&gt; – list of slow commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num_close_matches&lt;/code&gt; – maximum number of close matches to suggest, by default &lt;code&gt;3&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An example of &lt;code&gt;settings.py&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;rules &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sudo&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;no_command&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
exclude_rules &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;git_push&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
require_confirmation &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;True&lt;/span&gt;
wait_command &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;
no_colors &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;False&lt;/span&gt;
priority &lt;span class="pl-k"&gt;=&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sudo&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;no_command&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;9999&lt;/span&gt;}
debug &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;False&lt;/span&gt;
history_limit &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;9999&lt;/span&gt;
wait_slow_command &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;20&lt;/span&gt;
slow_commands &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;react-native&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;gradle&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
num_close_matches &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;5&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or via environment variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_RULES&lt;/code&gt; – list of enabled rules, like &lt;code&gt;DEFAULT_RULES:rm_root&lt;/code&gt; or &lt;code&gt;sudo:no_command&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_EXCLUDE_RULES&lt;/code&gt; – list of disabled rules, like &lt;code&gt;git_pull:git_push&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_REQUIRE_CONFIRMATION&lt;/code&gt; – require confirmation before running new command, &lt;code&gt;true/false&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_WAIT_COMMAND&lt;/code&gt; – max amount of time in seconds for getting previous command output;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_NO_COLORS&lt;/code&gt; – disable colored output, &lt;code&gt;true/false&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_PRIORITY&lt;/code&gt; – priority of the rules, like &lt;code&gt;no_command=9999:apt_get=100&lt;/code&gt;,
rule with lower &lt;code&gt;priority&lt;/code&gt; will be matched first;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_DEBUG&lt;/code&gt; – enables debug output, &lt;code&gt;true/false&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_HISTORY_LIMIT&lt;/code&gt; – how many history commands will be scanned, like &lt;code&gt;2000&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_ALTER_HISTORY&lt;/code&gt; – push fixed command to history &lt;code&gt;true/false&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_WAIT_SLOW_COMMAND&lt;/code&gt; – max amount of time in seconds for getting previous command output if it in &lt;code&gt;slow_commands&lt;/code&gt; list;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_SLOW_COMMANDS&lt;/code&gt; – list of slow commands, like &lt;code&gt;lein:gradle&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_NUM_CLOSE_MATCHES&lt;/code&gt; – maximum number of close matches to suggest, like &lt;code&gt;5&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_RULES=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sudo:no_command&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_EXCLUDE_RULES=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;git_pull:git_push&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_REQUIRE_CONFIRMATION=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;true&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_WAIT_COMMAND=10
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_NO_COLORS=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;false&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_PRIORITY=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;no_command=9999:apt_get=100&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_HISTORY_LIMIT=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;2000&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_NUM_CLOSE_MATCHES=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-third-party-packages-with-rules" class="anchor" aria-hidden="true" href="#third-party-packages-with-rules"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Third-party packages with rules&lt;/h2&gt;
&lt;p&gt;If you'd like to make a specific set of non-public rules, but would still like
to share them with others, create a package named &lt;code&gt;thefuck_contrib_*&lt;/code&gt; with
the following structure:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;thefuck_contrib_foo
  thefuck_contrib_foo
    rules
      __init__.py
      *third-party rules*
    __init__.py
    *third-party-utils*
  setup.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;The Fuck&lt;/em&gt; will find rules located in the &lt;code&gt;rules&lt;/code&gt; module.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-experimental-instant-mode" class="anchor" aria-hidden="true" href="#experimental-instant-mode"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Experimental instant mode&lt;/h2&gt;
&lt;p&gt;The default behavior of &lt;em&gt;The Fuck&lt;/em&gt; requires time to re-run previous commands.
When in instant mode, &lt;em&gt;The Fuck&lt;/em&gt; saves time by logging output with &lt;a href="https://en.wikipedia.org/wiki/Script_(Unix)" rel="nofollow"&gt;script&lt;/a&gt;,
then reading the log.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/nvbn/thefuck/master/example_instant_mode.gif" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/nvbn/thefuck/master/example_instant_mode.gif" alt="gif with instant mode" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Currently, instant mode only supports Python 3 with bash or zsh. zsh's autocorrect function also needs to be disabled in order for thefuck to work properly.&lt;/p&gt;
&lt;p&gt;To enable instant mode, add &lt;code&gt;--enable-experimental-instant-mode&lt;/code&gt;
to the alias initialization in &lt;code&gt;.bashrc&lt;/code&gt;, &lt;code&gt;.bash_profile&lt;/code&gt; or &lt;code&gt;.zshrc&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;eval&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;thefuck --alias --enable-experimental-instant-mode&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-developing" class="anchor" aria-hidden="true" href="#developing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Developing&lt;/h2&gt;
&lt;p&gt;See &lt;a href="CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license-mit" class="anchor" aria-hidden="true" href="#license-mit"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License MIT&lt;/h2&gt;
&lt;p&gt;Project License can be found &lt;a href="LICENSE.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>nvbn</author><guid isPermaLink="false">https://github.com/nvbn/thefuck</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>donnemartin/data-science-ipython-notebooks #12 in Python, This week</title><link>https://github.com/donnemartin/data-science-ipython-notebooks</link><description>&lt;p&gt;&lt;i&gt;Data science Python notebooks: Deep learning (TensorFlow, Theano, Caffe, Keras), scikit-learn, Kaggle, big data (Spark, Hadoop MapReduce, HDFS), matplotlib, pandas, NumPy, SciPy, Python essentials, AWS, and various command lines.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/README_1200x800.gif"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/README_1200x800.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/coversmall_alt.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/coversmall_alt.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-data-science-ipython-notebooks" class="anchor" aria-hidden="true" href="#data-science-ipython-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;data-science-ipython-notebooks&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-index" class="anchor" aria-hidden="true" href="#index"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Index&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#deep-learning"&gt;deep-learning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#tensor-flow-tutorials"&gt;tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#theano-tutorials"&gt;theano&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#keras-tutorials"&gt;keras&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#deep-learning-misc"&gt;caffe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#scikit-learn"&gt;scikit-learn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#statistical-inference-scipy"&gt;statistical-inference-scipy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pandas"&gt;pandas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#matplotlib"&gt;matplotlib&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#numpy"&gt;numpy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#python-data"&gt;python-data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#kaggle-and-business-analyses"&gt;kaggle-and-business-analyses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#spark"&gt;spark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mapreduce-python"&gt;mapreduce-python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#aws"&gt;amazon web services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#commands"&gt;command lines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#misc"&gt;misc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#notebook-installation"&gt;notebook-installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#credits"&gt;credits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing"&gt;contributing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contact-info"&gt;contact-info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;license&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ee94aabdb3e1fc49fad71ea1ac9801c82095001d/687474703a2f2f692e696d6775722e636f6d2f5a684b58724b5a2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/ee94aabdb3e1fc49fad71ea1ac9801c82095001d/687474703a2f2f692e696d6775722e636f6d2f5a684b58724b5a2e706e67" data-canonical-src="http://i.imgur.com/ZhKXrKZ.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-deep-learning" class="anchor" aria-hidden="true" href="#deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;deep-learning&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating deep learning functionality.&lt;/p&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://avatars0.githubusercontent.com/u/15658638?v=3&amp;amp;s=100"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/15658638?v=3&amp;amp;s=100" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-tensor-flow-tutorials" class="anchor" aria-hidden="true" href="#tensor-flow-tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;tensor-flow-tutorials&lt;/h3&gt;
&lt;p&gt;Additional TensorFlow tutorials:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pkmital/tensorflow_tutorials"&gt;pkmital/tensorflow_tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nlintz/TensorFlow-Tutorials"&gt;nlintz/TensorFlow-Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/alrojo/tensorflow-tutorial"&gt;alrojo/tensorflow-tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/BinRoot/TensorFlow-Book"&gt;BinRoot/TensorFlow-Book&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tuanavu/tensorflow-basic-tutorials"&gt;tuanavu/tensorflow-basic-tutorials&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/1_intro/basic_operations.ipynb" rel="nofollow"&gt;tsf-basics&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/linear_regression.ipynb" rel="nofollow"&gt;tsf-linear&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement linear regression in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/logistic_regression.ipynb" rel="nofollow"&gt;tsf-logistic&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement logistic regression in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/nearest_neighbor.ipynb" rel="nofollow"&gt;tsf-nn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement nearest neighboars in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/alexnet.ipynb" rel="nofollow"&gt;tsf-alex&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement AlexNet in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/convolutional_network.ipynb" rel="nofollow"&gt;tsf-cnn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement convolutional neural networks in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/multilayer_perceptron.ipynb" rel="nofollow"&gt;tsf-mlp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement multilayer perceptrons in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/recurrent_network.ipynb" rel="nofollow"&gt;tsf-rnn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement recurrent neural networks in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/4_multi_gpu/multigpu_basics.ipynb" rel="nofollow"&gt;tsf-gpu&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about basic multi-GPU computation in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/graph_visualization.ipynb" rel="nofollow"&gt;tsf-gviz&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about graph visualization in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/loss_visualization.ipynb" rel="nofollow"&gt;tsf-lviz&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about loss visualization in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-tensor-flow-exercises" class="anchor" aria-hidden="true" href="#tensor-flow-exercises"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;tensor-flow-exercises&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/1_notmnist.ipynb" rel="nofollow"&gt;tsf-not-mnist&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/2_fullyconnected.ipynb" rel="nofollow"&gt;tsf-fully-connected&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Progressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/3_regularization.ipynb" rel="nofollow"&gt;tsf-regularization&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Explore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/4_convolutions.ipynb" rel="nofollow"&gt;tsf-convolutions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Create convolutional neural networks in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/5_word2vec.ipynb" rel="nofollow"&gt;tsf-word2vec&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Train a skip-gram model over Text8 data in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/6_lstm.ipynb" rel="nofollow"&gt;tsf-lstm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Train a LSTM character model over Text8 data in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/f3f9ed69fc2544e3d53d866e01783a0f4facd3d8/687474703a2f2f7777772e646565706c6561726e696e672e6e65742f736f6674776172652f746865616e6f2f5f7374617469632f746865616e6f5f6c6f676f5f616c6c626c75655f3230307834362e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/f3f9ed69fc2544e3d53d866e01783a0f4facd3d8/687474703a2f2f7777772e646565706c6561726e696e672e6e65742f736f6674776172652f746865616e6f2f5f7374617469632f746865616e6f5f6c6f676f5f616c6c626c75655f3230307834362e706e67" data-canonical-src="http://www.deeplearning.net/software/theano/_static/theano_logo_allblue_200x46.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-theano-tutorials" class="anchor" aria-hidden="true" href="#theano-tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;theano-tutorials&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/intro_theano/intro_theano.ipynb" rel="nofollow"&gt;theano-intro&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Intro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/scan_tutorial/scan_tutorial.ipynb" rel="nofollow"&gt;theano-scan&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn scans, a mechanism to perform loops in a Theano graph.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/intro_theano/logistic_regression.ipynb" rel="nofollow"&gt;theano-logistic&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement logistic regression in Theano.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/rnn_tutorial/simple_rnn.ipynb" rel="nofollow"&gt;theano-rnn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement recurrent neural networks in Theano.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/theano_mlp/theano_mlp.ipynb" rel="nofollow"&gt;theano-mlp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement multilayer perceptrons in Theano.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/46a7861f9fd3f8b141c64dd3d01145874bf3546e/687474703a2f2f692e696d6775722e636f6d2f4c3435513863322e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/46a7861f9fd3f8b141c64dd3d01145874bf3546e/687474703a2f2f692e696d6775722e636f6d2f4c3435513863322e6a7067" data-canonical-src="http://i.imgur.com/L45Q8c2.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-keras-tutorials" class="anchor" aria-hidden="true" href="#keras-tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;keras-tutorials&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;keras&lt;/td&gt;
&lt;td&gt;Keras is an open source neural network library written in Python. It is capable of running on top of either Tensorflow or Theano.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/0.%20Preamble.ipynb" rel="nofollow"&gt;setup&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about the tutorial goals and how to set up your Keras environment.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.1%20Introduction%20-%20Deep%20Learning%20and%20ANN.ipynb" rel="nofollow"&gt;intro-deep-learning-ann&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Get an intro to deep learning with Keras and Artificial Neural Networks (ANN).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.2%20Introduction%20-%20Theano.ipynb" rel="nofollow"&gt;theano&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Theano by working with weights matrices and gradients.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.3%20Introduction%20-%20Keras.ipynb" rel="nofollow"&gt;keras-otto&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Keras by looking at the Kaggle Otto challenge.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.4%20%28Extra%29%20A%20Simple%20Implementation%20of%20ANN%20for%20MNIST.ipynb" rel="nofollow"&gt;ann-mnist&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Review a simple implementation of ANN for MNIST using Keras.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.1%20Supervised%20Learning%20-%20ConvNets.ipynb" rel="nofollow"&gt;conv-nets&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Convolutional Neural Networks (CNNs) with Keras.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.2.1%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20I.ipynb" rel="nofollow"&gt;conv-net-1&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Recognize handwritten digits from MNIST using Keras - Part 1.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.2.2%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20II.ipynb" rel="nofollow"&gt;conv-net-2&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Recognize handwritten digits from MNIST using Keras - Part 2.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.3%20Supervised%20Learning%20-%20Famous%20Models%20with%20Keras.ipynb" rel="nofollow"&gt;keras-models&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Use pre-trained models such as VGG16, VGG19, ResNet50, and Inception v3 with Keras.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.1%20Unsupervised%20Learning%20-%20AutoEncoders%20and%20Embeddings.ipynb" rel="nofollow"&gt;auto-encoders&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Autoencoders with Keras.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.2%20RNN%20and%20LSTM.ipynb" rel="nofollow"&gt;rnn-lstm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Recurrent Neural Networks (RNNs) with Keras.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.3%20%28Extra%29%20LSTM%20for%20Sentence%20Generation.ipynb" rel="nofollow"&gt;lstm-sentence-gen&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about RNNs using Long Short Term Memory (LSTM) networks with Keras.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-deep-learning-misc" class="anchor" aria-hidden="true" href="#deep-learning-misc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;deep-learning-misc&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/deep-dream/dream.ipynb" rel="nofollow"&gt;deep-dream&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Caffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scikitlearn.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scikitlearn.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-scikit-learn" class="anchor" aria-hidden="true" href="#scikit-learn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;scikit-learn&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating scikit-learn functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-intro.ipynb" rel="nofollow"&gt;intro&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Intro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-intro.ipynb#K-Nearest-Neighbors-Classifier" rel="nofollow"&gt;knn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement k-nearest neighbors in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-linear-reg.ipynb" rel="nofollow"&gt;linear-reg&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement linear regression in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-svm.ipynb" rel="nofollow"&gt;svm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement support vector machine classifiers with and without kernels in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-random-forest.ipynb" rel="nofollow"&gt;random-forest&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement random forest classifiers and regressors in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-k-means.ipynb" rel="nofollow"&gt;k-means&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement k-means clustering in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-pca.ipynb" rel="nofollow"&gt;pca&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement principal component analysis in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-gmm.ipynb" rel="nofollow"&gt;gmm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement Gaussian mixture models in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-validation.ipynb" rel="nofollow"&gt;validation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement validation and model selection in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scipy.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scipy.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-statistical-inference-scipy" class="anchor" aria-hidden="true" href="#statistical-inference-scipy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;statistical-inference-scipy&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating statistical inference with SciPy functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;scipy&lt;/td&gt;
&lt;td&gt;SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/effect_size.ipynb" rel="nofollow"&gt;effect-size&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Explore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/sampling.ipynb" rel="nofollow"&gt;sampling&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Explore random sampling by analyzing the average weight of men and women in the United States using BRFSS data.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/hypothesis.ipynb" rel="nofollow"&gt;hypothesis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Explore hypothesis testing by analyzing the difference of first-born babies compared with others.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/pandas.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/pandas.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pandas" class="anchor" aria-hidden="true" href="#pandas"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;pandas&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating pandas functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/pandas.ipynb" rel="nofollow"&gt;pandas&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Software library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/donnemartin/viz/blob/master/githubstats/data_wrangling.ipynb"&gt;github-data-wrangling&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn how to load, clean, merge, and feature engineer by analyzing GitHub data from the &lt;a href="https://github.com/donnemartin/viz"&gt;&lt;code&gt;Viz&lt;/code&gt;&lt;/a&gt; repo.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.00-Introduction-to-Pandas.ipynb" rel="nofollow"&gt;Introduction-to-Pandas&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Introduction to Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.01-Introducing-Pandas-Objects.ipynb" rel="nofollow"&gt;Introducing-Pandas-Objects&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Pandas objects.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.02-Data-Indexing-and-Selection.ipynb" rel="nofollow"&gt;Data Indexing and Selection&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about data indexing and selection in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.03-Operations-in-Pandas.ipynb" rel="nofollow"&gt;Operations-in-Pandas&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about operating on data in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.04-Missing-Values.ipynb" rel="nofollow"&gt;Missing-Values&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about handling missing data in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.05-Hierarchical-Indexing.ipynb" rel="nofollow"&gt;Hierarchical-Indexing&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about hierarchical indexing in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.06-Concat-And-Append.ipynb" rel="nofollow"&gt;Concat-And-Append&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about combining datasets: concat and append in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.07-Merge-and-Join.ipynb" rel="nofollow"&gt;Merge-and-Join&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about combining datasets: merge and join in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.08-Aggregation-and-Grouping.ipynb" rel="nofollow"&gt;Aggregation-and-Grouping&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about aggregation and grouping in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.09-Pivot-Tables.ipynb" rel="nofollow"&gt;Pivot-Tables&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about pivot tables in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.10-Working-With-Strings.ipynb" rel="nofollow"&gt;Working-With-Strings&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about vectorized string operations in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.11-Working-with-Time-Series.ipynb" rel="nofollow"&gt;Working-with-Time-Series&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about working with time series in pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.12-Performance-Eval-and-Query.ipynb" rel="nofollow"&gt;Performance-Eval-and-Query&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about high-performance Pandas: eval() and query() in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/matplotlib.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/matplotlib.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-matplotlib" class="anchor" aria-hidden="true" href="#matplotlib"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;matplotlib&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating matplotlib functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/matplotlib.ipynb" rel="nofollow"&gt;matplotlib&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/matplotlib-applied.ipynb" rel="nofollow"&gt;matplotlib-applied&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Apply matplotlib visualizations to Kaggle competitions for exploratory data analysis.  Learn how to create bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.00-Introduction-To-Matplotlib.ipynb" rel="nofollow"&gt;Introduction-To-Matplotlib&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Introduction to Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.01-Simple-Line-Plots.ipynb" rel="nofollow"&gt;Simple-Line-Plots&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about simple line plots in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.02-Simple-Scatter-Plots.ipynb" rel="nofollow"&gt;Simple-Scatter-Plots&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about simple scatter plots in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.03-Errorbars.ipynb" rel="nofollow"&gt;Errorbars.ipynb&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about visualizing errors in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.04-Density-and-Contour-Plots.ipynb" rel="nofollow"&gt;Density-and-Contour-Plots&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about density and contour plots in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.05-Histograms-and-Binnings.ipynb" rel="nofollow"&gt;Histograms-and-Binnings&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about histograms, binnings, and density in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.06-Customizing-Legends.ipynb" rel="nofollow"&gt;Customizing-Legends&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about customizing plot legends in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.07-Customizing-Colorbars.ipynb" rel="nofollow"&gt;Customizing-Colorbars&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about customizing colorbars in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.08-Multiple-Subplots.ipynb" rel="nofollow"&gt;Multiple-Subplots&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about multiple subplots in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.09-Text-and-Annotation.ipynb" rel="nofollow"&gt;Text-and-Annotation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about text and annotation in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.10-Customizing-Ticks.ipynb" rel="nofollow"&gt;Customizing-Ticks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about customizing ticks in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.11-Settings-and-Stylesheets.ipynb" rel="nofollow"&gt;Settings-and-Stylesheets&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about customizing Matplotlib: configurations and stylesheets.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.12-Three-Dimensional-Plotting.ipynb" rel="nofollow"&gt;Three-Dimensional-Plotting&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about three-dimensional plotting in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.13-Geographic-Data-With-Basemap.ipynb" rel="nofollow"&gt;Geographic-Data-With-Basemap&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about geographic data with basemap in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.14-Visualization-With-Seaborn.ipynb" rel="nofollow"&gt;Visualization-With-Seaborn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about visualization with Seaborn.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-numpy" class="anchor" aria-hidden="true" href="#numpy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;numpy&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating NumPy functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/numpy.ipynb" rel="nofollow"&gt;numpy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.00-Introduction-to-NumPy.ipynb" rel="nofollow"&gt;Introduction-to-NumPy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Introduction to NumPy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.01-Understanding-Data-Types.ipynb" rel="nofollow"&gt;Understanding-Data-Types&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about data types in Python.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.02-The-Basics-Of-NumPy-Arrays.ipynb" rel="nofollow"&gt;The-Basics-Of-NumPy-Arrays&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about the basics of NumPy arrays.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.03-Computation-on-arrays-ufuncs.ipynb" rel="nofollow"&gt;Computation-on-arrays-ufuncs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about computations on NumPy arrays: universal functions.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.04-Computation-on-arrays-aggregates.ipynb" rel="nofollow"&gt;Computation-on-arrays-aggregates&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about aggregations: min, max, and everything in between in NumPy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.05-Computation-on-arrays-broadcasting.ipynb" rel="nofollow"&gt;Computation-on-arrays-broadcasting&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about computation on arrays: broadcasting in NumPy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.06-Boolean-Arrays-and-Masks.ipynb" rel="nofollow"&gt;Boolean-Arrays-and-Masks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about comparisons, masks, and boolean logic in NumPy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.07-Fancy-Indexing.ipynb" rel="nofollow"&gt;Fancy-Indexing&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about fancy indexing in NumPy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.08-Sorting.ipynb" rel="nofollow"&gt;Sorting&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about sorting arrays in NumPy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.09-Structured-Data-NumPy.ipynb" rel="nofollow"&gt;Structured-Data-NumPy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about structured data: NumPy's structured arrays.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/python.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/python.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-python-data" class="anchor" aria-hidden="true" href="#python-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;python-data&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating Python functionality geared towards data analysis.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/structs.ipynb" rel="nofollow"&gt;data structures&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn Python basics with tuples, lists, dicts, sets.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/structs_utils.ipynb" rel="nofollow"&gt;data structure utilities&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/functions.ipynb" rel="nofollow"&gt;functions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about more advanced Python features: Functions as objects, lambda functions, closures, *args, **kwargs currying, generators, generator expressions, itertools.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/datetime.ipynb" rel="nofollow"&gt;datetime&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn how to work with Python dates and times: datetime, strftime, strptime, timedelta.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/logs.ipynb" rel="nofollow"&gt;logging&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Python logging with RotatingFileHandler and TimedRotatingFileHandler.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/pdb.ipynb" rel="nofollow"&gt;pdb&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn how to debug in Python with the interactive source code debugger.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/unit_tests.ipynb" rel="nofollow"&gt;unit tests&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn how to test in Python with Nose unit tests.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/kaggle.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/kaggle.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-kaggle-and-business-analyses" class="anchor" aria-hidden="true" href="#kaggle-and-business-analyses"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;kaggle-and-business-analyses&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) used in &lt;a href="https://www.kaggle.com/" rel="nofollow"&gt;kaggle&lt;/a&gt; competitions and business analyses.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb" rel="nofollow"&gt;titanic&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Predict survival on the Titanic.  Learn data cleaning, exploratory data analysis, and machine learning.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/analyses/churn.ipynb" rel="nofollow"&gt;churn-analysis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Predict customer churn.  Exercise logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Includes discussions of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/spark.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/spark.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-spark" class="anchor" aria-hidden="true" href="#spark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;spark&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating spark and HDFS functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/spark/spark.ipynb" rel="nofollow"&gt;spark&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;In-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/spark/hdfs.ipynb" rel="nofollow"&gt;hdfs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Reliably stores very large files across machines in a large cluster.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/mrjob.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/mrjob.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-mapreduce-python" class="anchor" aria-hidden="true" href="#mapreduce-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;mapreduce-python&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/mapreduce/mapreduce-python.ipynb" rel="nofollow"&gt;mapreduce-python&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Runs MapReduce jobs in Python, executing jobs locally or on Hadoop clusters. Demonstrates Hadoop Streaming in Python code with unit test and &lt;a href="https://github.com/Yelp/mrjob"&gt;mrjob&lt;/a&gt; config file to analyze Amazon S3 bucket logs on Elastic MapReduce.  &lt;a href="https://github.com/discoproject/disco/"&gt;Disco&lt;/a&gt; is another python-based alternative.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/aws.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/aws.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-aws" class="anchor" aria-hidden="true" href="#aws"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;aws&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating Amazon Web Services (AWS) and AWS tools functionality.&lt;/p&gt;
&lt;p&gt;Also check out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/saws"&gt;SAWS&lt;/a&gt;: A Supercharged AWS command line interface (CLI).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/awesome-aws"&gt;Awesome AWS&lt;/a&gt;: A curated list of libraries, open source repos, guides, blogs, and other resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#Boto" rel="nofollow"&gt;boto&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Official AWS SDK for Python.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3cmd" rel="nofollow"&gt;s3cmd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Interacts with S3 through the command line.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3distcp" rel="nofollow"&gt;s3distcp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Combines smaller files and aggregates them together by taking in a pattern and target file.  S3DistCp can also be used to transfer large volumes of data from S3 to your Hadoop cluster.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3-parallel-put" rel="nofollow"&gt;s3-parallel-put&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Uploads multiple files to S3 in parallel.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#redshift" rel="nofollow"&gt;redshift&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Acts as a fast data warehouse built on top of technology from massive parallel processing (MPP).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#kinesis" rel="nofollow"&gt;kinesis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Streams data in real time with the ability to process thousands of data streams per second.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#lambda" rel="nofollow"&gt;lambda&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Runs code in response to events, automatically managing compute resources.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/commands.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/commands.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-commands" class="anchor" aria-hidden="true" href="#commands"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;commands&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating various command lines for Linux, Git, etc.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/linux.ipynb" rel="nofollow"&gt;linux&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Unix-like and mostly POSIX-compliant computer operating system.  Disk usage, splitting files, grep, sed, curl, viewing running processes, terminal syntax highlighting, and Vim.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#anaconda" rel="nofollow"&gt;anaconda&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing, that aims to simplify package management and deployment.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#ipython-notebook" rel="nofollow"&gt;ipython notebook&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Web-based interactive computational environment where you can combine code execution, text, mathematics, plots and rich media into a single document.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#git" rel="nofollow"&gt;git&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Distributed revision control system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#ruby" rel="nofollow"&gt;ruby&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Used to interact with the AWS command line and for Jekyll, a blog framework that can be hosted on GitHub Pages.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#jekyll" rel="nofollow"&gt;jekyll&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Simple, blog-aware, static site generator for personal, project, or organization sites.  Renders Markdown or Textile and Liquid templates, and produces a complete, static website ready to be served by Apache HTTP Server, Nginx or another web server.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#pelican" rel="nofollow"&gt;pelican&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Python-based alternative to Jekyll.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#django" rel="nofollow"&gt;django&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;High-level Python Web framework that encourages rapid development and clean, pragmatic design. It can be useful to share reports/analyses and for blogging. Lighter-weight alternatives include &lt;a href="https://github.com/Pylons/pyramid"&gt;Pyramid&lt;/a&gt;, &lt;a href="https://github.com/pallets/flask"&gt;Flask&lt;/a&gt;, &lt;a href="https://github.com/tornadoweb/tornado"&gt;Tornado&lt;/a&gt;, and &lt;a href="https://github.com/bottlepy/bottle"&gt;Bottle&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-misc" class="anchor" aria-hidden="true" href="#misc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;misc&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating miscellaneous functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/misc/regex.ipynb" rel="nofollow"&gt;regex&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Regular expression cheat sheet useful in data wrangling.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/misc/Algorithmia.ipynb" rel="nofollow"&gt;algorithmia&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Algorithmia is a marketplace for algorithms. This notebook showcases 4 different algorithms: Face Detection, Content Summarizer, Latent Dirichlet Allocation and Optical Character Recognition.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-notebook-installation" class="anchor" aria-hidden="true" href="#notebook-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;notebook-installation&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-anaconda" class="anchor" aria-hidden="true" href="#anaconda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;anaconda&lt;/h3&gt;
&lt;p&gt;Anaconda is a free distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing that aims to simplify package management and deployment.&lt;/p&gt;
&lt;p&gt;Follow instructions to install &lt;a href="https://docs.continuum.io/anaconda/install" rel="nofollow"&gt;Anaconda&lt;/a&gt; or the more lightweight &lt;a href="http://conda.pydata.org/miniconda.html" rel="nofollow"&gt;miniconda&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-dev-setup" class="anchor" aria-hidden="true" href="#dev-setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;dev-setup&lt;/h3&gt;
&lt;p&gt;For detailed instructions, scripts, and tools to set up your development environment for data analysis, check out the &lt;a href="https://github.com/donnemartin/dev-setup"&gt;dev-setup&lt;/a&gt; repo.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-running-notebooks" class="anchor" aria-hidden="true" href="#running-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;running-notebooks&lt;/h3&gt;
&lt;p&gt;To view interactive content or to modify elements within the IPython notebooks, you must first clone or download the repository then run the notebook.  More information on IPython Notebooks can be found &lt;a href="http://ipython.org/notebook.html" rel="nofollow"&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/donnemartin/data-science-ipython-notebooks.git
$ cd data-science-ipython-notebooks
$ jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notebooks tested with Python 2.7.x.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;credits&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793" rel="nofollow"&gt;Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython&lt;/a&gt; by Wes McKinney&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jakevdp/sklearn_pycon2015"&gt;PyCon 2015 Scikit-learn Tutorial&lt;/a&gt; by Jake VanderPlas&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jakevdp/PythonDataScienceHandbook"&gt;Python Data Science Handbook&lt;/a&gt; by Jake VanderPlas&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ogrisel/parallel_ml_tutorial"&gt;Parallel Machine Learning with scikit-learn and IPython&lt;/a&gt; by Olivier Grisel&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/AllenDowney/CompStats"&gt;Statistical Interference Using Computational Methods in Python&lt;/a&gt; by Allen Downey&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/aymericdamien/TensorFlow-Examples"&gt;TensorFlow Examples&lt;/a&gt; by Aymeric Damien&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pkmital/tensorflow_tutorials"&gt;TensorFlow Tutorials&lt;/a&gt; by Parag K Mital&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nlintz/TensorFlow-Tutorials"&gt;TensorFlow Tutorials&lt;/a&gt; by Nathan Lintz&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/alrojo/tensorflow-tutorial"&gt;TensorFlow Tutorials&lt;/a&gt; by Alexander R Johansen&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/BinRoot/TensorFlow-Book"&gt;TensorFlow Book&lt;/a&gt; by Nishant Shukla&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mila-udem/summerschool2015"&gt;Summer School 2015&lt;/a&gt; by mila-udem&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/leriomaggio/deep-learning-keras-tensorflow"&gt;Keras tutorials&lt;/a&gt; by Valerio Maggio&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/" rel="nofollow"&gt;Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.yhat.com/" rel="nofollow"&gt;Yhat Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;contributing&lt;/h2&gt;
&lt;p&gt;Contributions are welcome!  For bug reports or requests please &lt;a href="https://github.com/donnemartin/data-science-ipython-notebooks/issues"&gt;submit an issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contact-info" class="anchor" aria-hidden="true" href="#contact-info"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;contact-info&lt;/h2&gt;
&lt;p&gt;Feel free to contact me to discuss any issues, questions, or comments.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Email: &lt;a href="mailto:donne.martin@gmail.com"&gt;donne.martin@gmail.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Twitter: &lt;a href="https://twitter.com/donne_martin" rel="nofollow"&gt;@donne_martin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href="https://github.com/donnemartin"&gt;donnemartin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;LinkedIn: &lt;a href="https://www.linkedin.com/in/donnemartin" rel="nofollow"&gt;donnemartin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Website: &lt;a href="http://donnemartin.com" rel="nofollow"&gt;donnemartin.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;license&lt;/h2&gt;
&lt;p&gt;This repository contains a variety of content; some developed by Donne Martin, and some from third-parties.  The third-party content is distributed under the license provided by those parties.&lt;/p&gt;
&lt;p&gt;The content developed by Donne Martin is distributed under the following license:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Copyright 2015 Donne Martin

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>donnemartin</author><guid isPermaLink="false">https://github.com/donnemartin/data-science-ipython-notebooks</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>quantopian/zipline #13 in Python, This week</title><link>https://github.com/quantopian/zipline</link><description>&lt;p&gt;&lt;i&gt;Zipline, a Pythonic Algorithmic Trading Library&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body rst" data-path="README.rst"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;a href="https://www.zipline.io" rel="nofollow"&gt;&lt;img alt="Zipline" src="https://camo.githubusercontent.com/887b8228aa4b569b2a519ef711c7da7e5d6b40cd/68747470733a2f2f6d656469612e7175616e746f7069616e2e636f6d2f6c6f676f732f6f70656e5f736f757263652f7a69706c696e652d6c6f676f2d30335f2e706e67" data-canonical-src="https://media.quantopian.com/logos/open_source/zipline-logo-03_.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href="https://gitter.im/quantopian/zipline?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img alt="Gitter" src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://pypi.python.org/pypi/zipline" rel="nofollow"&gt;&lt;img alt="version status" src="https://camo.githubusercontent.com/3eb069ec0b3e276829eb1f88f7c594f33fe1e3d8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f7a69706c696e652e737667" data-canonical-src="https://img.shields.io/pypi/pyversions/zipline.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://travis-ci.org/quantopian/zipline" rel="nofollow"&gt;&lt;img alt="travis status" src="https://camo.githubusercontent.com/29e70eddded2efd56e32b7fc5c150b90820099a1/68747470733a2f2f7472617669732d63692e6f72672f7175616e746f7069616e2f7a69706c696e652e706e673f6272616e63683d6d6173746572" data-canonical-src="https://travis-ci.org/quantopian/zipline.png?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/quantopian/zipline/branch/master" rel="nofollow"&gt;&lt;img alt="appveyor status" src="https://camo.githubusercontent.com/b0eef78a2d89bc9ea40ea6cfeafb438444705605/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f336467313865363232376476737477362f6272616e63682f6d61737465723f7376673d74727565" data-canonical-src="https://ci.appveyor.com/api/projects/status/3dg18e6227dvstw6/branch/master?svg=true" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://coveralls.io/r/quantopian/zipline" rel="nofollow"&gt;&lt;img alt="Coverage Status" src="https://camo.githubusercontent.com/1a7165b07669cce4c6c69f92ca68d7e3e374bffc/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f7175616e746f7069616e2f7a69706c696e652f62616467652e706e67" data-canonical-src="https://coveralls.io/repos/quantopian/zipline/badge.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zipline is a Pythonic algorithmic trading library. It is an event-driven
system for backtesting. Zipline is currently used in production as the backtesting and live-trading
engine powering &lt;a href="https://www.quantopian.com" rel="nofollow"&gt;Quantopian&lt;/a&gt; -- a free,
community-centered, hosted platform for building and executing trading
strategies.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://groups.google.com/forum/#!forum/zipline" rel="nofollow"&gt;Join our Community!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zipline.io" rel="nofollow"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Want to Contribute? See our &lt;a href="https://www.zipline.io/development-guidelines" rel="nofollow"&gt;Development Guidelines&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-features"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ease of Use:&lt;/strong&gt; Zipline tries to get out of your way so that you can
focus on algorithm development. See below for a code example.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;"Batteries Included":&lt;/strong&gt; many common statistics like
moving average and linear regression can be readily accessed from
within a user-written algorithm.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyData Integration:&lt;/strong&gt; Input of historical data and output of performance statistics are
based on Pandas DataFrames to integrate nicely into the existing
PyData ecosystem.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Statistics and Machine Learning Libraries:&lt;/strong&gt; You can use libraries like matplotlib, scipy,
statsmodels, and sklearn to support development, analysis, and
visualization of state-of-the-art trading systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-installation"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;a name="user-content-installing-with-pip"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-installing-with-pip" class="anchor" aria-hidden="true" href="#installing-with-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing With &lt;code&gt;pip&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Assuming you have all required (see note below) non-Python dependencies, you
can install Zipline with &lt;code&gt;pip&lt;/code&gt; via:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ pip install zipline&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Installing Zipline via &lt;code&gt;pip&lt;/code&gt; is slightly more involved than the
average Python package.  Simply running &lt;code&gt;pip install zipline&lt;/code&gt; will likely
fail if you've never installed any scientific Python packages before.&lt;/p&gt;
&lt;p&gt;There are two reasons for the additional complexity:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Zipline ships several C extensions that require access to the CPython C API.
In order to build the C extensions, &lt;code&gt;pip&lt;/code&gt; needs access to the CPython
header files for your Python installation.&lt;/li&gt;
&lt;li&gt;Zipline depends on &lt;a href="https://www.numpy.org/" rel="nofollow"&gt;numpy&lt;/a&gt;, the core library for
numerical array computing in Python.  Numpy depends on having the &lt;a href="https://www.netlib.org/lapack/" rel="nofollow"&gt;LAPACK&lt;/a&gt; linear algebra routines available.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Because LAPACK and the CPython headers are binary dependencies, the correct way
to install them varies from platform to platform.  On Linux, users generally
acquire these dependencies via a package manager like &lt;code&gt;apt&lt;/code&gt;, &lt;code&gt;yum&lt;/code&gt;, or
&lt;code&gt;pacman&lt;/code&gt;.  On OSX, &lt;a href="https://brew.sh/" rel="nofollow"&gt;Homebrew&lt;/a&gt; is a popular choice
providing similar functionality.&lt;/p&gt;
&lt;p&gt;See the full &lt;a href="https://www.zipline.io/install" rel="nofollow"&gt;Zipline Install Documentation&lt;/a&gt; for more information on acquiring
binary dependencies for your specific platform.&lt;/p&gt;
&lt;a name="user-content-conda"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-conda" class="anchor" aria-hidden="true" href="#conda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;conda&lt;/h3&gt;
&lt;p&gt;Another way to install Zipline is via the &lt;code&gt;conda&lt;/code&gt; package manager, which
comes as part of &lt;a href="https://www.anaconda.com/distribution/" rel="nofollow"&gt;Anaconda&lt;/a&gt; or can be
installed via &lt;code&gt;pip install conda&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once set up, you can install Zipline from our &lt;code&gt;Quantopian&lt;/code&gt; channel:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ conda install -c Quantopian zipline&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Currently supported platforms include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GNU/Linux 64-bit&lt;/li&gt;
&lt;li&gt;OSX 64-bit&lt;/li&gt;
&lt;li&gt;Windows 64-bit&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
&lt;p&gt;Note&lt;/p&gt;
&lt;p&gt;Windows 32-bit may work; however, it is not currently included in
continuous integration tests.&lt;/p&gt;
&lt;/div&gt;
&lt;a name="user-content-quickstart"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-quickstart" class="anchor" aria-hidden="true" href="#quickstart"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quickstart&lt;/h2&gt;
&lt;p&gt;See our &lt;a href="https://www.zipline.io/beginner-tutorial" rel="nofollow"&gt;getting started tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following code implements a simple dual moving average algorithm.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; zipline.api &lt;span class="pl-k"&gt;import&lt;/span&gt; order_target, record, symbol

&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;initialize&lt;/span&gt;(&lt;span class="pl-smi"&gt;context&lt;/span&gt;):
    context.i &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;
    context.asset &lt;span class="pl-k"&gt;=&lt;/span&gt; symbol(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;AAPL&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)


&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;handle_data&lt;/span&gt;(&lt;span class="pl-smi"&gt;context&lt;/span&gt;, &lt;span class="pl-smi"&gt;data&lt;/span&gt;):
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Skip first 300 days to get full windows&lt;/span&gt;
    context.i &lt;span class="pl-k"&gt;+=&lt;/span&gt; &lt;span class="pl-c1"&gt;1&lt;/span&gt;
    &lt;span class="pl-k"&gt;if&lt;/span&gt; context.i &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;300&lt;/span&gt;:
        &lt;span class="pl-k"&gt;return&lt;/span&gt;

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Compute averages&lt;/span&gt;
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; data.history() has to be called with the same params&lt;/span&gt;
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; from above and returns a pandas dataframe.&lt;/span&gt;
    short_mavg &lt;span class="pl-k"&gt;=&lt;/span&gt; data.history(context.asset, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;price&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;bar_count&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;frequency&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;1d&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;).mean()
    long_mavg &lt;span class="pl-k"&gt;=&lt;/span&gt; data.history(context.asset, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;price&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;bar_count&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;300&lt;/span&gt;, &lt;span class="pl-v"&gt;frequency&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;1d&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;).mean()

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Trading logic&lt;/span&gt;
    &lt;span class="pl-k"&gt;if&lt;/span&gt; short_mavg &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; long_mavg:
        &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; order_target orders as many shares as needed to&lt;/span&gt;
        &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; achieve the desired number of shares.&lt;/span&gt;
        order_target(context.asset, &lt;span class="pl-c1"&gt;100&lt;/span&gt;)
    &lt;span class="pl-k"&gt;elif&lt;/span&gt; short_mavg &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; long_mavg:
        order_target(context.asset, &lt;span class="pl-c1"&gt;0&lt;/span&gt;)

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Save values for later inspection&lt;/span&gt;
    record(&lt;span class="pl-v"&gt;AAPL&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;data.current(context.asset, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;price&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
           &lt;span class="pl-v"&gt;short_mavg&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;short_mavg,
           &lt;span class="pl-v"&gt;long_mavg&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;long_mavg)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can then run this algorithm using the Zipline CLI; you'll need a &lt;a href="https://docs.quandl.com/docs#section-authentication" rel="nofollow"&gt;Quandl&lt;/a&gt; API key to ingest the default data bundle.
Once you have your key, run the following from the command line:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ QUANDL_API_KEY=&lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;yourkey&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; zipline ingest -b quandl
$ zipline run -f dual_moving_average.py --start 2014-1-1 --end 2018-1-1 -o dma.pickle&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will download asset pricing data data from quandl, and stream it through the algorithm
over the specified time range. Then, the resulting performance DataFrame is saved in dma.pickle, which you
can load and analyze from within Python.&lt;/p&gt;
&lt;p&gt;You can find other examples in the &lt;code&gt;zipline/examples&lt;/code&gt; directory.&lt;/p&gt;
&lt;a name="user-content-questions"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-questions" class="anchor" aria-hidden="true" href="#questions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Questions?&lt;/h2&gt;
&lt;p&gt;If you find a bug, feel free to &lt;a href="https://github.com/quantopian/zipline/issues/new"&gt;open an issue&lt;/a&gt; and fill out the issue template.&lt;/p&gt;
&lt;a name="user-content-contributing"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;All contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome. Details on how to set up a development environment can be found in our &lt;a href="https://www.zipline.io/development-guidelines" rel="nofollow"&gt;development guidelines&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are looking to start working with the Zipline codebase, navigate to the GitHub issues tab and start looking through interesting issues. Sometimes there are issues labeled as &lt;a href="https://github.com/quantopian/zipline/issues?q=is%3Aissue+is%3Aopen+label%3A%22Beginner+Friendly%22"&gt;Beginner Friendly&lt;/a&gt; or &lt;a href="https://github.com/quantopian/zipline/issues?q=is%3Aissue+is%3Aopen+label%3A%22Help+Wanted%22"&gt;Help Wanted&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Feel free to ask questions on the &lt;a href="https://groups.google.com/forum/#!forum/zipline" rel="nofollow"&gt;mailing list&lt;/a&gt; or on &lt;a href="https://gitter.im/quantopian/zipline" rel="nofollow"&gt;Gitter&lt;/a&gt;.&lt;/p&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>quantopian</author><guid isPermaLink="false">https://github.com/quantopian/zipline</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>mlflow/mlflow #14 in Python, This week</title><link>https://github.com/mlflow/mlflow</link><description>&lt;p&gt;&lt;i&gt;Open source platform for the machine learning lifecycle&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body rst" data-path="README.rst"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-mlflow-a-machine-learning-lifecycle-platform" class="anchor" aria-hidden="true" href="#mlflow-a-machine-learning-lifecycle-platform"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MLflow: A Machine Learning Lifecycle Platform&lt;/h1&gt;
&lt;p&gt;MLflow is a platform to streamline machine learning development, including tracking experiments, packaging code
into reproducible runs, and sharing and deploying models. MLflow offers a set of lightweight APIs in that can
used with any existing machine learning application or library (TensorFlow, PyTorch, XGBoost, etc), wherever you
currently run ML code (e.g. in notebooks, standalone applications or the cloud). MLflow's current components are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://mlflow.org/docs/latest/tracking.html" rel="nofollow"&gt;MLflow Tracking&lt;/a&gt;: An API to log parameters, code, and
results in machine learning experiments and compare them using an interactive UI.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mlflow.org/docs/latest/projects.html" rel="nofollow"&gt;MLflow Projects&lt;/a&gt;: A code packaging format for reproducible
runs using Conda and Docker, so you can share your ML code with others.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mlflow.org/docs/latest/models.html" rel="nofollow"&gt;MLflow Models&lt;/a&gt;: A model packaging format and tools that let
you easily deploy the same model (from any ML library) to batch and real-time scoring on platforms such as
Docker, Apache Spark, Azure ML and AWS SageMaker.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://mlflow.org/docs/latest/index.html" rel="nofollow"&gt;&lt;img alt="Latest Docs" src="https://camo.githubusercontent.com/8897346570974d9343daaa3d0028f05fba3b2c96/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d737563636573732e737667" data-canonical-src="https://img.shields.io/badge/docs-latest-success.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://travis-ci.org/mlflow/mlflow" rel="nofollow"&gt;&lt;img alt="Build Status" src="https://camo.githubusercontent.com/cc7d1ba99188e8b7c1840ccc124e52dec84524e5/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f6d6c666c6f772f6d6c666c6f772e737667" data-canonical-src="https://img.shields.io/travis/mlflow/mlflow.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://pypi.org/project/mlflow/" rel="nofollow"&gt;&lt;img alt="Latest Python Release" src="https://camo.githubusercontent.com/64da7a7404b91748bf7f828013025ed864ad035c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6d6c666c6f772e737667" data-canonical-src="https://img.shields.io/pypi/v/mlflow.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://anaconda.org/conda-forge/mlflow" rel="nofollow"&gt;&lt;img alt="Latest Conda Release" src="https://camo.githubusercontent.com/433a5d0f4ed3fe6cfa7bc3501c05cb3b68fb149c/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f6d6c666c6f772e737667" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/mlflow.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://cran.r-project.org/package=mlflow" rel="nofollow"&gt;&lt;img alt="Latest CRAN Release" src="https://camo.githubusercontent.com/a0f2cb7d1126f71f1fa04d6d585a800e55c9ec6e/68747470733a2f2f696d672e736869656c64732e696f2f6372616e2f762f6d6c666c6f772e737667" data-canonical-src="https://img.shields.io/cran/v/mlflow.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://mvnrepository.com/artifact/org.mlflow" rel="nofollow"&gt;&lt;img alt="Maven Central" src="https://camo.githubusercontent.com/f65e7489205a7fb500ea5771c6176da3afb74162/68747470733a2f2f696d672e736869656c64732e696f2f6d6176656e2d63656e7472616c2f762f6f72672e6d6c666c6f772f6d6c666c6f772d706172656e742e737667" data-canonical-src="https://img.shields.io/maven-central/v/org.mlflow/mlflow-parent.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://github.com/mlflow/mlflow/blob/master/LICENSE.txt"&gt;&lt;img alt="Apache 2 License" src="https://camo.githubusercontent.com/34c5905ad22fdcb15a03e47e463e8773c815c2fd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d417061636865253230322d627269676874677265656e2e737667" data-canonical-src="https://img.shields.io/badge/license-Apache%202-brightgreen.svg" style="max-width:100%;"&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;a name="user-content-installing"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing&lt;/h2&gt;
&lt;p&gt;Install MLflow from PyPi via &lt;code&gt;pip install mlflow&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;MLflow requires &lt;code&gt;conda&lt;/code&gt; to be on the &lt;code&gt;PATH&lt;/code&gt; for the projects feature.&lt;/p&gt;
&lt;p&gt;Nightly snapshots of MLflow master are also available &lt;a href="https://mlflow-snapshots.s3-us-west-2.amazonaws.com/" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-documentation"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;Official documentation for MLflow can be found at &lt;a href="https://mlflow.org/docs/latest/index.html" rel="nofollow"&gt;https://mlflow.org/docs/latest/index.html&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-community"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-community" class="anchor" aria-hidden="true" href="#community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community&lt;/h2&gt;
&lt;p&gt;For help or questions about MLflow usage (e.g. "how do I do X?") see the &lt;a href="https://mlflow.org/docs/latest/index.html" rel="nofollow"&gt;docs&lt;/a&gt;
or &lt;a href="https://stackoverflow.com/questions/tagged/mlflow" rel="nofollow"&gt;Stack Overflow&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To report a bug, file a documentation issue, or submit a feature request, please open a GitHub issue.&lt;/p&gt;
&lt;p&gt;For release announcements and other discussions, please subscribe to our mailing list (&lt;a href="mailto:mlflow-users@googlegroups.com"&gt;mlflow-users@googlegroups.com&lt;/a&gt;)
or join us on Slack at &lt;a href="https://tinyurl.com/mlflow-slack" rel="nofollow"&gt;https://tinyurl.com/mlflow-slack&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-running-a-sample-app-with-the-tracking-api"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-running-a-sample-app-with-the-tracking-api" class="anchor" aria-hidden="true" href="#running-a-sample-app-with-the-tracking-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running a Sample App With the Tracking API&lt;/h2&gt;
&lt;p&gt;The programs in &lt;code&gt;examples&lt;/code&gt; use the MLflow Tracking API. For instance, run:&lt;/p&gt;
&lt;pre&gt;python examples/quickstart/mlflow_tracking.py
&lt;/pre&gt;
&lt;p&gt;This program will use &lt;a href="https://mlflow.org/docs/latest/tracking.html" rel="nofollow"&gt;MLflow Tracking API&lt;/a&gt;,
which logs tracking data in &lt;code&gt;./mlruns&lt;/code&gt;. This can then be viewed with the Tracking UI.&lt;/p&gt;
&lt;a name="user-content-launching-the-tracking-ui"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-launching-the-tracking-ui" class="anchor" aria-hidden="true" href="#launching-the-tracking-ui"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Launching the Tracking UI&lt;/h2&gt;
&lt;p&gt;The MLflow Tracking UI will show runs logged in &lt;code&gt;./mlruns&lt;/code&gt; at &lt;a href="http://localhost:5000" rel="nofollow"&gt;http://localhost:5000&lt;/a&gt;.
Start it with:&lt;/p&gt;
&lt;pre&gt;mlflow ui
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Running &lt;code&gt;mlflow ui&lt;/code&gt; from within a clone of MLflow is not recommended - doing so will
run the dev UI from source. We recommend running the UI from a different working directory,
specifying a backend store via the &lt;code&gt;--backend-store-uri&lt;/code&gt; option. Alternatively, see
instructions for running the dev UI in the &lt;a href="CONTRIBUTING.rst"&gt;contributor guide&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-running-a-project-from-a-uri"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-running-a-project-from-a-uri" class="anchor" aria-hidden="true" href="#running-a-project-from-a-uri"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running a Project from a URI&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;mlflow run&lt;/code&gt; command lets you run a project packaged with a MLproject file from a local path
or a Git URI:&lt;/p&gt;
&lt;pre&gt;mlflow run examples/sklearn_elasticnet_wine -P alpha=0.4

mlflow run https://github.com/mlflow/mlflow-example.git -P alpha=0.4
&lt;/pre&gt;
&lt;p&gt;See &lt;code&gt;examples/sklearn_elasticnet_wine&lt;/code&gt; for a sample project with an MLproject file.&lt;/p&gt;
&lt;a name="user-content-saving-and-serving-models"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-saving-and-serving-models" class="anchor" aria-hidden="true" href="#saving-and-serving-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Saving and Serving Models&lt;/h2&gt;
&lt;p&gt;To illustrate managing models, the &lt;code&gt;mlflow.sklearn&lt;/code&gt; package can log scikit-learn models as
MLflow artifacts and then load them again for serving. There is an example training application in
&lt;code&gt;examples/sklearn_logistic_regression/train.py&lt;/code&gt; that you can run as follows:&lt;/p&gt;
&lt;pre&gt;$ python examples/sklearn_logistic_regression/train.py
Score: 0.666
Model saved in run &amp;lt;run-id&amp;gt;

$ mlflow models serve --model-uri runs:/&amp;lt;run-id&amp;gt;/model

$ curl -d '{"columns":[0],"index":[0,1],"data":[[1],[-1]]}' -H 'Content-Type: application/json'  localhost:5000/invocations
&lt;/pre&gt;
&lt;a name="user-content-contributing"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;We happily welcome contributions to MLflow. Please see our &lt;a href="CONTRIBUTING.rst"&gt;contribution guide&lt;/a&gt;
for details.&lt;/p&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>mlflow</author><guid isPermaLink="false">https://github.com/mlflow/mlflow</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>tiangolo/fastapi #15 in Python, This week</title><link>https://github.com/tiangolo/fastapi</link><description>&lt;p&gt;&lt;i&gt;FastAPI framework, high performance, easy to learn, fast to code, ready for production&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
  &lt;a href="https://fastapi.tiangolo.com" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/86dafd728b94c0e3c8f19a7295e87df678ed6751/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f6c6f676f2d6d617267696e2f6c6f676f2d7465616c2e706e67" alt="FastAPI" data-canonical-src="https://fastapi.tiangolo.com/img/logo-margin/logo-teal.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;em&gt;FastAPI framework, high performance, easy to learn, fast to code, ready for production&lt;/em&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
&lt;a href="https://travis-ci.org/tiangolo/fastapi" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/a063500cd90b05f7713e4e8a1d8425d56117ab54/68747470733a2f2f7472617669732d63692e6f72672f7469616e676f6c6f2f666173746170692e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/tiangolo/fastapi.svg?branch=master" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://codecov.io/gh/tiangolo/fastapi" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/f5a1eba9c0d4b5b01c08287fe78a467cc0b07512/68747470733a2f2f636f6465636f762e696f2f67682f7469616e676f6c6f2f666173746170692f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/tiangolo/fastapi/branch/master/graph/badge.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://pypi.org/project/fastapi" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/42b9100f882ee4300fe2372e7f1d4e65f95b1f4c/68747470733a2f2f62616467652e667572792e696f2f70792f666173746170692e737667" alt="Package version" data-canonical-src="https://badge.fury.io/py/fastapi.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://gitter.im/tiangolo/fastapi?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/2cc5eb2b608263a42d3938f63f69e0dcc697eaad/68747470733a2f2f6261646765732e6769747465722e696d2f7469616e676f6c6f2f666173746170692e737667" alt="Join the chat at https://gitter.im/tiangolo/fastapi" data-canonical-src="https://badges.gitter.im/tiangolo/fastapi.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href="https://fastapi.tiangolo.com" rel="nofollow"&gt;&lt;/a&gt;&lt;a href="https://fastapi.tiangolo.com" rel="nofollow"&gt;https://fastapi.tiangolo.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source Code&lt;/strong&gt;: &lt;a href="https://github.com/tiangolo/fastapi"&gt;&lt;/a&gt;&lt;a href="https://github.com/tiangolo/fastapi"&gt;https://github.com/tiangolo/fastapi&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints.&lt;/p&gt;
&lt;p&gt;The key features are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fast&lt;/strong&gt;: Very high performance, on par with &lt;strong&gt;NodeJS&lt;/strong&gt; and &lt;strong&gt;Go&lt;/strong&gt; (thanks to Starlette and Pydantic). &lt;a href="#performance"&gt;One of the fastest Python frameworks available&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fast to code&lt;/strong&gt;: Increase the speed to develop features by about 200% to 300% *.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fewer bugs&lt;/strong&gt;: Reduce about 40% of human (developer) induced errors. *&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Intuitive&lt;/strong&gt;: Great editor support. Completion everywhere. Less time debugging.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Easy&lt;/strong&gt;: Designed to be easy to use and learn. Less time reading docs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Short&lt;/strong&gt;: Minimize code duplication. Multiple features from each parameter declaration. Fewer bugs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Robust&lt;/strong&gt;: Get production-ready code. With automatic interactive documentation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Standards-based&lt;/strong&gt;: Based on (and fully compatible with) the open standards for APIs: &lt;a href="https://github.com/OAI/OpenAPI-Specification"&gt;OpenAPI&lt;/a&gt; (previously known as Swagger) and &lt;a href="http://json-schema.org/" rel="nofollow"&gt;JSON Schema&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;* estimation based on tests on an internal development team, building production applications.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-opinions" class="anchor" aria-hidden="true" href="#opinions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Opinions&lt;/h2&gt;
&lt;p&gt;"&lt;em&gt;[...] I'm using &lt;strong&gt;FastAPI&lt;/strong&gt; a ton these days. [...] I'm actually planning to use it for all of my team's &lt;strong&gt;ML services at Microsoft&lt;/strong&gt;. Some of them are getting integrated into the core &lt;strong&gt;Windows&lt;/strong&gt; product and some &lt;strong&gt;Office&lt;/strong&gt; products.&lt;/em&gt;"&lt;/p&gt;
&lt;div&gt;Kabir Khan - &lt;strong&gt;Microsoft&lt;/strong&gt; &lt;a href="https://github.com/tiangolo/fastapi/pull/26"&gt;(ref)&lt;/a&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;"&lt;em&gt;I’m over the moon excited about &lt;strong&gt;FastAPI&lt;/strong&gt;. It’s so fun!&lt;/em&gt;"&lt;/p&gt;
&lt;div&gt;Brian Okken - &lt;strong&gt;&lt;a href="https://pythonbytes.fm/episodes/show/123/time-to-right-the-py-wrongs?time_in_sec=855" rel="nofollow"&gt;Python Bytes&lt;/a&gt; podcast host&lt;/strong&gt; &lt;a href="https://twitter.com/brianokken/status/1112220079972728832" rel="nofollow"&gt;(ref)&lt;/a&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;"&lt;em&gt;Honestly, what you've built looks super solid and polished. In many ways, it's what I wanted &lt;strong&gt;Hug&lt;/strong&gt; to be - it's really inspiring to see someone build that.&lt;/em&gt;"&lt;/p&gt;
&lt;div&gt;Timothy Crosley - &lt;strong&gt;&lt;a href="http://www.hug.rest/" rel="nofollow"&gt;Hug&lt;/a&gt; creator&lt;/strong&gt; &lt;a href="https://news.ycombinator.com/item?id=19455465" rel="nofollow"&gt;(ref)&lt;/a&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;"&lt;em&gt;If you're looking to learn one &lt;strong&gt;modern framework&lt;/strong&gt; for building REST APIs, check out &lt;strong&gt;FastAPI&lt;/strong&gt; [...] It's fast, easy to use and easy to learn [...]&lt;/em&gt;"&lt;/p&gt;
&lt;p&gt;"&lt;em&gt;We've switched over to &lt;strong&gt;FastAPI&lt;/strong&gt; for our &lt;strong&gt;APIs&lt;/strong&gt; [...] I think you'll like it [...]&lt;/em&gt;"&lt;/p&gt;
&lt;div&gt;Ines Montani - Matthew Honnibal - &lt;strong&gt;&lt;a href="https://explosion.ai" rel="nofollow"&gt;Explosion AI&lt;/a&gt; founders - &lt;a href="https://spacy.io" rel="nofollow"&gt;spaCy&lt;/a&gt; creators&lt;/strong&gt; &lt;a href="https://twitter.com/_inesmontani/status/1144173225322143744" rel="nofollow"&gt;(ref)&lt;/a&gt; - &lt;a href="https://twitter.com/honnibal/status/1144031421859655680" rel="nofollow"&gt;(ref)&lt;/a&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;"&lt;em&gt;We adopted the &lt;strong&gt;FastAPI&lt;/strong&gt; library to spawn a &lt;strong&gt;REST&lt;/strong&gt; server that can be queried to obtain &lt;strong&gt;predictions&lt;/strong&gt;. [for Ludwig]&lt;/em&gt;"&lt;/p&gt;
&lt;div&gt;Piero Molino, Yaroslav Dudin, and Sai Sumanth Miryala - &lt;strong&gt;Uber&lt;/strong&gt; &lt;a href="https://eng.uber.com/ludwig-v0-2/" rel="nofollow"&gt;(ref)&lt;/a&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h2&gt;
&lt;p&gt;Python 3.6+&lt;/p&gt;
&lt;p&gt;FastAPI stands on the shoulders of giants:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.starlette.io/" rel="nofollow"&gt;Starlette&lt;/a&gt; for the web parts.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pydantic-docs.helpmanual.io/" rel="nofollow"&gt;Pydantic&lt;/a&gt; for the data parts.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ pip install fastapi&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You will also need an ASGI server, for production such as &lt;a href="http://www.uvicorn.org" rel="nofollow"&gt;Uvicorn&lt;/a&gt; or &lt;a href="https://gitlab.com/pgjones/hypercorn" rel="nofollow"&gt;Hypercorn&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ pip install uvicorn&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-example" class="anchor" aria-hidden="true" href="#example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-create-it" class="anchor" aria-hidden="true" href="#create-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Create it&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Create a file &lt;code&gt;main.py&lt;/code&gt; with:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; fastapi &lt;span class="pl-k"&gt;import&lt;/span&gt; FastAPI

app &lt;span class="pl-k"&gt;=&lt;/span&gt; FastAPI()


&lt;span class="pl-en"&gt;@app.get&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;read_root&lt;/span&gt;():
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Hello&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;World&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;}


&lt;span class="pl-en"&gt;@app.get&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/items/&lt;span class="pl-c1"&gt;{item_id}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;read_item&lt;/span&gt;(&lt;span class="pl-smi"&gt;item_id&lt;/span&gt;: &lt;span class="pl-c1"&gt;int&lt;/span&gt;, &lt;span class="pl-smi"&gt;q&lt;/span&gt;: &lt;span class="pl-c1"&gt;str&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item_id, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;q&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: q}&lt;/pre&gt;&lt;/div&gt;
&lt;details&gt;
&lt;summary&gt;Or use &lt;code&gt;async def&lt;/code&gt;...&lt;/summary&gt;
&lt;p&gt;If your code uses &lt;code&gt;async&lt;/code&gt; / &lt;code&gt;await&lt;/code&gt;, use &lt;code&gt;async def&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; fastapi &lt;span class="pl-k"&gt;import&lt;/span&gt; FastAPI

app &lt;span class="pl-k"&gt;=&lt;/span&gt; FastAPI()


&lt;span class="pl-en"&gt;@app.get&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;async&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;read_root&lt;/span&gt;():
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Hello&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;World&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;}


&lt;span class="pl-en"&gt;@app.get&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/items/&lt;span class="pl-c1"&gt;{item_id}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;async&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;read_item&lt;/span&gt;(&lt;span class="pl-smi"&gt;item_id&lt;/span&gt;: &lt;span class="pl-c1"&gt;int&lt;/span&gt;, &lt;span class="pl-smi"&gt;q&lt;/span&gt;: &lt;span class="pl-c1"&gt;str&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item_id, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;q&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: q}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;If you don't know, check the &lt;em&gt;"In a hurry?"&lt;/em&gt; section about &lt;a href="https://fastapi.tiangolo.com/async/#in-a-hurry" rel="nofollow"&gt;&lt;code&gt;async&lt;/code&gt; and &lt;code&gt;await&lt;/code&gt; in the docs&lt;/a&gt;.&lt;/p&gt;
&lt;/details&gt;
&lt;h3&gt;&lt;a id="user-content-run-it" class="anchor" aria-hidden="true" href="#run-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Run it&lt;/h3&gt;
&lt;p&gt;Run the server with:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;uvicorn main:app --reload&lt;/pre&gt;&lt;/div&gt;
&lt;details&gt;
&lt;summary&gt;About the command &lt;code&gt;uvicorn main:app --reload&lt;/code&gt;...&lt;/summary&gt;
&lt;p&gt;The command &lt;code&gt;uvicorn main:app&lt;/code&gt; refers to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;main&lt;/code&gt;: the file &lt;code&gt;main.py&lt;/code&gt; (the Python "module").&lt;/li&gt;
&lt;li&gt;&lt;code&gt;app&lt;/code&gt;: the object created inside of &lt;code&gt;main.py&lt;/code&gt; with the line &lt;code&gt;app = FastAPI()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--reload&lt;/code&gt;: make the server restart after code changes. Only do this for development.&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;
&lt;h3&gt;&lt;a id="user-content-check-it" class="anchor" aria-hidden="true" href="#check-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Check it&lt;/h3&gt;
&lt;p&gt;Open your browser at &lt;a href="http://127.0.0.1:8000/items/5?q=somequery" rel="nofollow"&gt;&lt;/a&gt;&lt;a href="http://127.0.0.1:8000/items/5?q=somequery" rel="nofollow"&gt;http://127.0.0.1:8000/items/5?q=somequery&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You will see the JSON response as:&lt;/p&gt;
&lt;div class="highlight highlight-source-json"&gt;&lt;pre&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;5&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;q&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;somequery&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You already created an API that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Receives HTTP requests in the &lt;em&gt;paths&lt;/em&gt; &lt;code&gt;/&lt;/code&gt; and &lt;code&gt;/items/{item_id}&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Both &lt;em&gt;paths&lt;/em&gt; take &lt;code&gt;GET&lt;/code&gt; &lt;em&gt;operations&lt;/em&gt; (also known as HTTP &lt;em&gt;methods&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;path&lt;/em&gt; &lt;code&gt;/items/{item_id}&lt;/code&gt; has a &lt;em&gt;path parameter&lt;/em&gt; &lt;code&gt;item_id&lt;/code&gt; that should be an &lt;code&gt;int&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;path&lt;/em&gt; &lt;code&gt;/items/{item_id}&lt;/code&gt; has an optional &lt;code&gt;str&lt;/code&gt; &lt;em&gt;query parameter&lt;/em&gt; &lt;code&gt;q&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-interactive-api-docs" class="anchor" aria-hidden="true" href="#interactive-api-docs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive API docs&lt;/h3&gt;
&lt;p&gt;Now go to &lt;a href="http://127.0.0.1:8000/docs" rel="nofollow"&gt;&lt;/a&gt;&lt;a href="http://127.0.0.1:8000/docs" rel="nofollow"&gt;http://127.0.0.1:8000/docs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You will see the automatic interactive API documentation (provided by &lt;a href="https://github.com/swagger-api/swagger-ui"&gt;Swagger UI&lt;/a&gt;):&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/4695ec8d41da6a358a4faa882c61bbac9951b026/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30312d737761676765722d75692d73696d706c652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/4695ec8d41da6a358a4faa882c61bbac9951b026/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30312d737761676765722d75692d73696d706c652e706e67" alt="Swagger UI" data-canonical-src="https://fastapi.tiangolo.com/img/index/index-01-swagger-ui-simple.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-alternative-api-docs" class="anchor" aria-hidden="true" href="#alternative-api-docs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Alternative API docs&lt;/h3&gt;
&lt;p&gt;And now, go to &lt;a href="http://127.0.0.1:8000/redoc" rel="nofollow"&gt;&lt;/a&gt;&lt;a href="http://127.0.0.1:8000/redoc" rel="nofollow"&gt;http://127.0.0.1:8000/redoc&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You will see the alternative automatic documentation (provided by &lt;a href="https://github.com/Rebilly/ReDoc"&gt;ReDoc&lt;/a&gt;):&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/3a6ac8a74ecc2fca49f1e731ddd66cc5172d8c35/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30322d7265646f632d73696d706c652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/3a6ac8a74ecc2fca49f1e731ddd66cc5172d8c35/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30322d7265646f632d73696d706c652e706e67" alt="ReDoc" data-canonical-src="https://fastapi.tiangolo.com/img/index/index-02-redoc-simple.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-example-upgrade" class="anchor" aria-hidden="true" href="#example-upgrade"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example upgrade&lt;/h2&gt;
&lt;p&gt;Now modify the file &lt;code&gt;main.py&lt;/code&gt; to receive a body from a &lt;code&gt;PUT&lt;/code&gt; request.&lt;/p&gt;
&lt;p&gt;Declare the body using standard Python types, thanks to Pydantic.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; fastapi &lt;span class="pl-k"&gt;import&lt;/span&gt; FastAPI
&lt;span class="pl-k"&gt;from&lt;/span&gt; pydantic &lt;span class="pl-k"&gt;import&lt;/span&gt; BaseModel

app &lt;span class="pl-k"&gt;=&lt;/span&gt; FastAPI()


&lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;Item&lt;/span&gt;(&lt;span class="pl-e"&gt;BaseModel&lt;/span&gt;):
    name: &lt;span class="pl-c1"&gt;str&lt;/span&gt;
    price: &lt;span class="pl-c1"&gt;float&lt;/span&gt;
    is_offer: &lt;span class="pl-c1"&gt;bool&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;


&lt;span class="pl-en"&gt;@app.get&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;read_root&lt;/span&gt;():
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Hello&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;World&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;}


&lt;span class="pl-en"&gt;@app.get&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/items/&lt;span class="pl-c1"&gt;{item_id}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;read_item&lt;/span&gt;(&lt;span class="pl-smi"&gt;item_id&lt;/span&gt;: &lt;span class="pl-c1"&gt;int&lt;/span&gt;, &lt;span class="pl-smi"&gt;q&lt;/span&gt;: &lt;span class="pl-c1"&gt;str&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item_id, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;q&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: q}


&lt;span class="pl-en"&gt;@app.put&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/items/&lt;span class="pl-c1"&gt;{item_id}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;update_item&lt;/span&gt;(&lt;span class="pl-smi"&gt;item_id&lt;/span&gt;: &lt;span class="pl-c1"&gt;int&lt;/span&gt;, &lt;span class="pl-smi"&gt;item&lt;/span&gt;: Item):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_name&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item.name, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item_id}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The server should reload automatically (because you added &lt;code&gt;--reload&lt;/code&gt; to the &lt;code&gt;uvicorn&lt;/code&gt; command above).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-interactive-api-docs-upgrade" class="anchor" aria-hidden="true" href="#interactive-api-docs-upgrade"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive API docs upgrade&lt;/h3&gt;
&lt;p&gt;Now go to &lt;a href="http://127.0.0.1:8000/docs" rel="nofollow"&gt;&lt;/a&gt;&lt;a href="http://127.0.0.1:8000/docs" rel="nofollow"&gt;http://127.0.0.1:8000/docs&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The interactive API documentation will be automatically updated, including the new body:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/f0019a9c9b37044a50e6cff6d8750b426e7e0944/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30332d737761676765722d30322e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/f0019a9c9b37044a50e6cff6d8750b426e7e0944/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30332d737761676765722d30322e706e67" alt="Swagger UI" data-canonical-src="https://fastapi.tiangolo.com/img/index/index-03-swagger-02.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Click on the button "Try it out", it allows you to fill the parameters and directly interact with the API:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1be49d95361f60e81305eb315dd90fc197af3def/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30342d737761676765722d30332e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/1be49d95361f60e81305eb315dd90fc197af3def/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30342d737761676765722d30332e706e67" alt="Swagger UI interaction" data-canonical-src="https://fastapi.tiangolo.com/img/index/index-04-swagger-03.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Then click on the "Execute" button, the user interface will communicate with your API, send the parameters, get the results and show them on the screen:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/3a631804039f0a0cb0cf603689fac91b08628a7f/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30352d737761676765722d30342e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/3a631804039f0a0cb0cf603689fac91b08628a7f/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30352d737761676765722d30342e706e67" alt="Swagger UI interaction" data-canonical-src="https://fastapi.tiangolo.com/img/index/index-05-swagger-04.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-alternative-api-docs-upgrade" class="anchor" aria-hidden="true" href="#alternative-api-docs-upgrade"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Alternative API docs upgrade&lt;/h3&gt;
&lt;p&gt;And now, go to &lt;a href="http://127.0.0.1:8000/redoc" rel="nofollow"&gt;&lt;/a&gt;&lt;a href="http://127.0.0.1:8000/redoc" rel="nofollow"&gt;http://127.0.0.1:8000/redoc&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The alternative documentation will also reflect the new query parameter and body:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/8145a3ba1236551d039aca21225d3ef348f04ccf/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30362d7265646f632d30322e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/8145a3ba1236551d039aca21225d3ef348f04ccf/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30362d7265646f632d30322e706e67" alt="ReDoc" data-canonical-src="https://fastapi.tiangolo.com/img/index/index-06-redoc-02.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-recap" class="anchor" aria-hidden="true" href="#recap"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Recap&lt;/h3&gt;
&lt;p&gt;In summary, you declare &lt;strong&gt;once&lt;/strong&gt; the types of parameters, body, etc. as function parameters.&lt;/p&gt;
&lt;p&gt;You do that with standard modern Python types.&lt;/p&gt;
&lt;p&gt;You don't have to learn a new syntax, the methods or classes of a specific library, etc.&lt;/p&gt;
&lt;p&gt;Just standard &lt;strong&gt;Python 3.6+&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;For example, for an &lt;code&gt;int&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;item_id: &lt;span class="pl-c1"&gt;int&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or for a more complex &lt;code&gt;Item&lt;/code&gt; model:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;item: Item&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;...and with that single declaration you get:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Editor support, including:
&lt;ul&gt;
&lt;li&gt;Completion.&lt;/li&gt;
&lt;li&gt;Type checks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Validation of data:
&lt;ul&gt;
&lt;li&gt;Automatic and clear errors when the data is invalid.&lt;/li&gt;
&lt;li&gt;Validation even for deeply nested JSON objects.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Conversion of input data: coming from the network to Python data and types. Reading from:
&lt;ul&gt;
&lt;li&gt;JSON.&lt;/li&gt;
&lt;li&gt;Path parameters.&lt;/li&gt;
&lt;li&gt;Query parameters.&lt;/li&gt;
&lt;li&gt;Cookies.&lt;/li&gt;
&lt;li&gt;Headers.&lt;/li&gt;
&lt;li&gt;Forms.&lt;/li&gt;
&lt;li&gt;Files.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Conversion of output data: converting from Python data and types to network data (as JSON):
&lt;ul&gt;
&lt;li&gt;Convert Python types (&lt;code&gt;str&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;, &lt;code&gt;float&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;, &lt;code&gt;list&lt;/code&gt;, etc).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;datetime&lt;/code&gt; objects.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;UUID&lt;/code&gt; objects.&lt;/li&gt;
&lt;li&gt;Database models.&lt;/li&gt;
&lt;li&gt;...and many more.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Automatic interactive API documentation, including 2 alternative user interfaces:
&lt;ul&gt;
&lt;li&gt;Swagger UI.&lt;/li&gt;
&lt;li&gt;ReDoc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Coming back to the previous code example, &lt;strong&gt;FastAPI&lt;/strong&gt; will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Validate that there is an &lt;code&gt;item_id&lt;/code&gt; in the path for &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;PUT&lt;/code&gt; requests.&lt;/li&gt;
&lt;li&gt;Validate that the &lt;code&gt;item_id&lt;/code&gt; is of type &lt;code&gt;int&lt;/code&gt; for &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;PUT&lt;/code&gt; requests.
&lt;ul&gt;
&lt;li&gt;If it is not, the client will see a useful, clear error.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Check if there is an optional query parameter named &lt;code&gt;q&lt;/code&gt; (as in &lt;code&gt;http://127.0.0.1:8000/items/foo?q=somequery&lt;/code&gt;) for &lt;code&gt;GET&lt;/code&gt; requests.
&lt;ul&gt;
&lt;li&gt;As the &lt;code&gt;q&lt;/code&gt; parameter is declared with &lt;code&gt;= None&lt;/code&gt;, it is optional.&lt;/li&gt;
&lt;li&gt;Without the &lt;code&gt;None&lt;/code&gt; it would be required (as is the body in the case with &lt;code&gt;PUT&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For &lt;code&gt;PUT&lt;/code&gt; requests to &lt;code&gt;/items/{item_id}&lt;/code&gt;, Read the body as JSON:
&lt;ul&gt;
&lt;li&gt;Check that it has a required attribute &lt;code&gt;name&lt;/code&gt; that should be a &lt;code&gt;str&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Check that is has a required attribute &lt;code&gt;price&lt;/code&gt; that has to be a &lt;code&gt;float&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Check that it has an optional attribute &lt;code&gt;is_offer&lt;/code&gt;, that should be a &lt;code&gt;bool&lt;/code&gt;, if present.&lt;/li&gt;
&lt;li&gt;All this would also work for deeply nested JSON objects.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Convert from and to JSON automatically.&lt;/li&gt;
&lt;li&gt;Document everything with OpenAPI, that can be used by:
&lt;ul&gt;
&lt;li&gt;Interactive documentation systems.&lt;/li&gt;
&lt;li&gt;Automatic client code generation systems, for many languages.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Provide 2 interactive documentation web interfaces directly.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;We just scratched the surface, but you already get the idea of how it all works.&lt;/p&gt;
&lt;p&gt;Try changing the line with:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_name&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item.name, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item_id}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;...from:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;        &lt;span class="pl-c1"&gt;...&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_name&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item.name &lt;span class="pl-c1"&gt;...&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;...to:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;        &lt;span class="pl-c1"&gt;...&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_price&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item.price &lt;span class="pl-c1"&gt;...&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;...and see how your editor will auto-complete the attributes and know their types:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b65e9d0dfe805713562159d8b226bc85acdd4c21/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f7673636f64652d636f6d706c6574696f6e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/b65e9d0dfe805713562159d8b226bc85acdd4c21/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f7673636f64652d636f6d706c6574696f6e2e706e67" alt="editor support" data-canonical-src="https://fastapi.tiangolo.com/img/vscode-completion.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For a more complete example including more features, see the &lt;a href="https://fastapi.tiangolo.com/tutorial/intro/" rel="nofollow"&gt;Tutorial - User Guide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Spoiler alert&lt;/strong&gt;: the tutorial - user guide includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Declaration of &lt;strong&gt;parameters&lt;/strong&gt; from other different places as: &lt;strong&gt;headers&lt;/strong&gt;, &lt;strong&gt;cookies&lt;/strong&gt;, &lt;strong&gt;form fields&lt;/strong&gt; and &lt;strong&gt;files&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;How to set &lt;strong&gt;validation constraints&lt;/strong&gt; as &lt;code&gt;maximum_length&lt;/code&gt; or &lt;code&gt;regex&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;A very powerful and easy to use &lt;strong&gt;Dependency Injection&lt;/strong&gt; system.&lt;/li&gt;
&lt;li&gt;Security and authentication, including support for &lt;strong&gt;OAuth2&lt;/strong&gt; with &lt;strong&gt;JWT tokens&lt;/strong&gt; and &lt;strong&gt;HTTP Basic&lt;/strong&gt; auth.&lt;/li&gt;
&lt;li&gt;More advanced (but equally easy) techniques for declaring &lt;strong&gt;deeply nested JSON models&lt;/strong&gt; (thanks to Pydantic).&lt;/li&gt;
&lt;li&gt;Many extra features (thanks to Starlette) as:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;WebSockets&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GraphQL&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;extremely easy tests based on &lt;code&gt;requests&lt;/code&gt; and &lt;code&gt;pytest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CORS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cookie Sessions&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;...and more.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-performance" class="anchor" aria-hidden="true" href="#performance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Performance&lt;/h2&gt;
&lt;p&gt;Independent TechEmpower benchmarks show &lt;strong&gt;FastAPI&lt;/strong&gt; applications running under Uvicorn as &lt;a href="https://www.techempower.com/benchmarks/#section=test&amp;amp;runid=7464e520-0dc2-473d-bd34-dbdfd7e85911&amp;amp;hw=ph&amp;amp;test=query&amp;amp;l=zijzen-7" rel="nofollow"&gt;one of the fastest Python frameworks available&lt;/a&gt;, only below Starlette and Uvicorn themselves (used internally by FastAPI). (*)&lt;/p&gt;
&lt;p&gt;To understand more about it, see the section &lt;a href="https://fastapi.tiangolo.com/benchmarks/" rel="nofollow"&gt;Benchmarks&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-optional-dependencies" class="anchor" aria-hidden="true" href="#optional-dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Optional Dependencies&lt;/h2&gt;
&lt;p&gt;Used by Pydantic:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/esnme/ultrajson"&gt;&lt;code&gt;ujson&lt;/code&gt;&lt;/a&gt; - for faster JSON "parsing".&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/JoshData/python-email-validator"&gt;&lt;code&gt;email_validator&lt;/code&gt;&lt;/a&gt; - for email validation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Used by Starlette:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://docs.python-requests.org" rel="nofollow"&gt;&lt;code&gt;requests&lt;/code&gt;&lt;/a&gt; - Required if you want to use the &lt;code&gt;TestClient&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Tinche/aiofiles"&gt;&lt;code&gt;aiofiles&lt;/code&gt;&lt;/a&gt; - Required if you want to use &lt;code&gt;FileResponse&lt;/code&gt; or &lt;code&gt;StaticFiles&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jinja.pocoo.org" rel="nofollow"&gt;&lt;code&gt;jinja2&lt;/code&gt;&lt;/a&gt; - Required if you want to use the default template configuration.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://andrew-d.github.io/python-multipart/" rel="nofollow"&gt;&lt;code&gt;python-multipart&lt;/code&gt;&lt;/a&gt; - Required if you want to support form "parsing", with &lt;code&gt;request.form()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pythonhosted.org/itsdangerous/" rel="nofollow"&gt;&lt;code&gt;itsdangerous&lt;/code&gt;&lt;/a&gt; - Required for &lt;code&gt;SessionMiddleware&lt;/code&gt; support.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pyyaml.org/wiki/PyYAMLDocumentation" rel="nofollow"&gt;&lt;code&gt;pyyaml&lt;/code&gt;&lt;/a&gt; - Required for &lt;code&gt;SchemaGenerator&lt;/code&gt; support.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://graphene-python.org/" rel="nofollow"&gt;&lt;code&gt;graphene&lt;/code&gt;&lt;/a&gt; - Required for &lt;code&gt;GraphQLApp&lt;/code&gt; support.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/esnme/ultrajson"&gt;&lt;code&gt;ujson&lt;/code&gt;&lt;/a&gt; - Required if you want to use &lt;code&gt;UJSONResponse&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Used by FastAPI / Starlette:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.uvicorn.org" rel="nofollow"&gt;&lt;code&gt;uvicorn&lt;/code&gt;&lt;/a&gt; - for the server that loads and serves your application.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can install all of these with &lt;code&gt;pip3 install fastapi[all]&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is licensed under the terms of the MIT license.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>tiangolo</author><guid isPermaLink="false">https://github.com/tiangolo/fastapi</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>google-research/bert #16 in Python, This week</title><link>https://github.com/google-research/bert</link><description>&lt;p&gt;&lt;i&gt;TensorFlow code and pre-trained models for BERT&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-bert" class="anchor" aria-hidden="true" href="#bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;BERT&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;***** New May 31st, 2019: Whole Word Masking Models *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is a release of several new models which were the result of an improvement
the pre-processing code.&lt;/p&gt;
&lt;p&gt;In the original pre-processing code, we randomly select WordPiece tokens to
mask. For example:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Input Text: the man jumped up , put his basket on phil ##am ##mon ' s head&lt;/code&gt;
&lt;code&gt;Original Masked Input: [MASK] man [MASK] up , put his [MASK] on phil [MASK] ##mon ' s head&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The new technique is called Whole Word Masking. In this case, we always mask
&lt;em&gt;all&lt;/em&gt; of the the tokens corresponding to a word at once. The overall masking
rate remains the same.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Whole Word Masked Input: the man [MASK] up , put his basket on [MASK] [MASK] [MASK] ' s head&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The training is identical -- we still predict each masked WordPiece token
independently. The improvement comes from the fact that the original prediction
task was too 'easy' for words that had been split into multiple WordPieces.&lt;/p&gt;
&lt;p&gt;This can be enabled during data generation by passing the flag
&lt;code&gt;--do_whole_word_mask=True&lt;/code&gt; to &lt;code&gt;create_pretraining_data.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Pre-trained models with Whole Word Masking are linked below. The data and
training were otherwise identical, and the models have identical structure and
vocab to the original models. We only include BERT-Large models. When using
these models, please make it clear in the paper that you are using the Whole
Word Masking variant of BERT-Large.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Uncased (Whole Word Masking)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2019_05_30/wwm_cased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Cased (Whole Word Masking)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th align="center"&gt;SQUAD 1.1 F1/EM&lt;/th&gt;
&lt;th align="center"&gt;Multi NLI Accuracy&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;BERT-Large, Uncased (Original)&lt;/td&gt;
&lt;td align="center"&gt;91.0/84.3&lt;/td&gt;
&lt;td align="center"&gt;86.05&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BERT-Large, Uncased (Whole Word Masking)&lt;/td&gt;
&lt;td align="center"&gt;92.8/86.7&lt;/td&gt;
&lt;td align="center"&gt;87.07&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BERT-Large, Cased (Original)&lt;/td&gt;
&lt;td align="center"&gt;91.5/84.8&lt;/td&gt;
&lt;td align="center"&gt;86.09&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BERT-Large, Cased (Whole Word Masking)&lt;/td&gt;
&lt;td align="center"&gt;92.9/86.7&lt;/td&gt;
&lt;td align="center"&gt;86.46&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;***** New February 7th, 2019: TfHub Module *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;BERT has been uploaded to &lt;a href="https://tfhub.dev" rel="nofollow"&gt;TensorFlow Hub&lt;/a&gt;. See
&lt;code&gt;run_classifier_with_tfhub.py&lt;/code&gt; for an example of how to use the TF Hub module,
or run an example in the browser on
&lt;a href="https://colab.sandbox.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb" rel="nofollow"&gt;Colab&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;***** New November 23rd, 2018: Un-normalized multilingual model + Thai +
Mongolian *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We uploaded a new multilingual model which does &lt;em&gt;not&lt;/em&gt; perform any normalization
on the input (no lower casing, accent stripping, or Unicode normalization), and
additionally inclues Thai and Mongolian.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It is recommended to use this version for developing multilingual models,
especially on languages with non-Latin alphabets.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This does not require any code changes, and can be downloaded here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Multilingual Cased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
104 languages, 12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;***** New November 15th, 2018: SOTA SQuAD 2.0 System *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We released code changes to reproduce our 83% F1 SQuAD 2.0 system, which is
currently 1st place on the leaderboard by 3%. See the SQuAD 2.0 section of the
README for details.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;***** New November 5th, 2018: Third-party PyTorch and Chainer versions of
BERT available *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;NLP researchers from HuggingFace made a
&lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT"&gt;PyTorch version of BERT available&lt;/a&gt;
which is compatible with our pre-trained checkpoints and is able to reproduce
our results. Sosuke Kobayashi also made a
&lt;a href="https://github.com/soskek/bert-chainer"&gt;Chainer version of BERT available&lt;/a&gt;
(Thanks!) We were not involved in the creation or maintenance of the PyTorch
implementation so please direct any questions towards the authors of that
repository.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;***** New November 3rd, 2018: Multilingual and Chinese models available
*****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We have made two new BERT models available:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/multilingual_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Multilingual&lt;/code&gt;&lt;/a&gt;
(Not recommended, use &lt;code&gt;Multilingual Cased&lt;/code&gt; instead)&lt;/strong&gt;: 102 languages,
12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Chinese&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M
parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We use character-based tokenization for Chinese, and WordPiece tokenization for
all other languages. Both models should work out-of-the-box without any code
changes. We did update the implementation of &lt;code&gt;BasicTokenizer&lt;/code&gt; in
&lt;code&gt;tokenization.py&lt;/code&gt; to support Chinese character tokenization, so please update if
you forked it. However, we did not change the tokenization API.&lt;/p&gt;
&lt;p&gt;For more, see the
&lt;a href="https://github.com/google-research/bert/blob/master/multilingual.md"&gt;Multilingual README&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;***** End new information *****&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;BERT&lt;/strong&gt;, or &lt;strong&gt;B&lt;/strong&gt;idirectional &lt;strong&gt;E&lt;/strong&gt;ncoder &lt;strong&gt;R&lt;/strong&gt;epresentations from
&lt;strong&gt;T&lt;/strong&gt;ransformers, is a new method of pre-training language representations which
obtains state-of-the-art results on a wide array of Natural Language Processing
(NLP) tasks.&lt;/p&gt;
&lt;p&gt;Our academic paper which describes BERT in detail and provides full results on a
number of tasks can be found here:
&lt;a href="https://arxiv.org/abs/1810.04805" rel="nofollow"&gt;https://arxiv.org/abs/1810.04805&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To give a few numbers, here are the results on the
&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/" rel="nofollow"&gt;SQuAD v1.1&lt;/a&gt; question answering
task:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SQuAD v1.1 Leaderboard (Oct 8th 2018)&lt;/th&gt;
&lt;th align="center"&gt;Test EM&lt;/th&gt;
&lt;th align="center"&gt;Test F1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1st Place Ensemble - BERT&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;87.4&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;93.2&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2nd Place Ensemble - nlnet&lt;/td&gt;
&lt;td align="center"&gt;86.0&lt;/td&gt;
&lt;td align="center"&gt;91.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1st Place Single Model - BERT&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;85.1&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;91.8&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2nd Place Single Model - nlnet&lt;/td&gt;
&lt;td align="center"&gt;83.5&lt;/td&gt;
&lt;td align="center"&gt;90.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;And several natural language inference tasks:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;System&lt;/th&gt;
&lt;th align="center"&gt;MultiNLI&lt;/th&gt;
&lt;th align="center"&gt;Question NLI&lt;/th&gt;
&lt;th align="center"&gt;SWAG&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;BERT&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;86.7&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;91.1&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;86.3&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OpenAI GPT (Prev. SOTA)&lt;/td&gt;
&lt;td align="center"&gt;82.2&lt;/td&gt;
&lt;td align="center"&gt;88.1&lt;/td&gt;
&lt;td align="center"&gt;75.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Plus many other tasks.&lt;/p&gt;
&lt;p&gt;Moreover, these results were all obtained with almost no task-specific neural
network architecture design.&lt;/p&gt;
&lt;p&gt;If you already know what BERT is and you just want to get started, you can
&lt;a href="#pre-trained-models"&gt;download the pre-trained models&lt;/a&gt; and
&lt;a href="#fine-tuning-with-bert"&gt;run a state-of-the-art fine-tuning&lt;/a&gt; in only a few
minutes.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-what-is-bert" class="anchor" aria-hidden="true" href="#what-is-bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is BERT?&lt;/h2&gt;
&lt;p&gt;BERT is a method of pre-training language representations, meaning that we train
a general-purpose "language understanding" model on a large text corpus (like
Wikipedia), and then use that model for downstream NLP tasks that we care about
(like question answering). BERT outperforms previous methods because it is the
first &lt;em&gt;unsupervised&lt;/em&gt;, &lt;em&gt;deeply bidirectional&lt;/em&gt; system for pre-training NLP.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Unsupervised&lt;/em&gt; means that BERT was trained using only a plain text corpus, which
is important because an enormous amount of plain text data is publicly available
on the web in many languages.&lt;/p&gt;
&lt;p&gt;Pre-trained representations can also either be &lt;em&gt;context-free&lt;/em&gt; or &lt;em&gt;contextual&lt;/em&gt;,
and contextual representations can further be &lt;em&gt;unidirectional&lt;/em&gt; or
&lt;em&gt;bidirectional&lt;/em&gt;. Context-free models such as
&lt;a href="https://www.tensorflow.org/tutorials/representation/word2vec" rel="nofollow"&gt;word2vec&lt;/a&gt; or
&lt;a href="https://nlp.stanford.edu/projects/glove/" rel="nofollow"&gt;GloVe&lt;/a&gt; generate a single "word
embedding" representation for each word in the vocabulary, so &lt;code&gt;bank&lt;/code&gt; would have
the same representation in &lt;code&gt;bank deposit&lt;/code&gt; and &lt;code&gt;river bank&lt;/code&gt;. Contextual models
instead generate a representation of each word that is based on the other words
in the sentence.&lt;/p&gt;
&lt;p&gt;BERT was built upon recent work in pre-training contextual representations —
including &lt;a href="https://arxiv.org/abs/1511.01432" rel="nofollow"&gt;Semi-supervised Sequence Learning&lt;/a&gt;,
&lt;a href="https://blog.openai.com/language-unsupervised/" rel="nofollow"&gt;Generative Pre-Training&lt;/a&gt;,
&lt;a href="https://allennlp.org/elmo" rel="nofollow"&gt;ELMo&lt;/a&gt;, and
&lt;a href="http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html" rel="nofollow"&gt;ULMFit&lt;/a&gt;
— but crucially these models are all &lt;em&gt;unidirectional&lt;/em&gt; or &lt;em&gt;shallowly
bidirectional&lt;/em&gt;. This means that each word is only contextualized using the words
to its left (or right). For example, in the sentence &lt;code&gt;I made a bank deposit&lt;/code&gt; the
unidirectional representation of &lt;code&gt;bank&lt;/code&gt; is only based on &lt;code&gt;I made a&lt;/code&gt; but not
&lt;code&gt;deposit&lt;/code&gt;. Some previous work does combine the representations from separate
left-context and right-context models, but only in a "shallow" manner. BERT
represents "bank" using both its left and right context — &lt;code&gt;I made a ... deposit&lt;/code&gt;
— starting from the very bottom of a deep neural network, so it is &lt;em&gt;deeply
bidirectional&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;BERT uses a simple approach for this: We mask out 15% of the words in the input,
run the entire sequence through a deep bidirectional
&lt;a href="https://arxiv.org/abs/1706.03762" rel="nofollow"&gt;Transformer&lt;/a&gt; encoder, and then predict only
the masked words. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Input: the man went to the [MASK1] . he bought a [MASK2] of milk.
Labels: [MASK1] = store; [MASK2] = gallon
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to learn relationships between sentences, we also train on a simple
task which can be generated from any monolingual corpus: Given two sentences &lt;code&gt;A&lt;/code&gt;
and &lt;code&gt;B&lt;/code&gt;, is &lt;code&gt;B&lt;/code&gt; the actual next sentence that comes after &lt;code&gt;A&lt;/code&gt;, or just a random
sentence from the corpus?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Sentence A: the man went to the store .
Sentence B: he bought a gallon of milk .
Label: IsNextSentence
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Sentence A: the man went to the store .
Sentence B: penguins are flightless .
Label: NotNextSentence
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We then train a large model (12-layer to 24-layer Transformer) on a large corpus
(Wikipedia + &lt;a href="http://yknzhu.wixsite.com/mbweb" rel="nofollow"&gt;BookCorpus&lt;/a&gt;) for a long time (1M
update steps), and that's BERT.&lt;/p&gt;
&lt;p&gt;Using BERT has two stages: &lt;em&gt;Pre-training&lt;/em&gt; and &lt;em&gt;fine-tuning&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pre-training&lt;/strong&gt; is fairly expensive (four days on 4 to 16 Cloud TPUs), but is a
one-time procedure for each language (current models are English-only, but
multilingual models will be released in the near future). We are releasing a
number of pre-trained models from the paper which were pre-trained at Google.
Most NLP researchers will never need to pre-train their own model from scratch.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fine-tuning&lt;/strong&gt; is inexpensive. All of the results in the paper can be
replicated in at most 1 hour on a single Cloud TPU, or a few hours on a GPU,
starting from the exact same pre-trained model. SQuAD, for example, can be
trained in around 30 minutes on a single Cloud TPU to achieve a Dev F1 score of
91.0%, which is the single system state-of-the-art.&lt;/p&gt;
&lt;p&gt;The other important aspect of BERT is that it can be adapted to many types of
NLP tasks very easily. In the paper, we demonstrate state-of-the-art results on
sentence-level (e.g., SST-2), sentence-pair-level (e.g., MultiNLI), word-level
(e.g., NER), and span-level (e.g., SQuAD) tasks with almost no task-specific
modifications.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-what-has-been-released-in-this-repository" class="anchor" aria-hidden="true" href="#what-has-been-released-in-this-repository"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What has been released in this repository?&lt;/h2&gt;
&lt;p&gt;We are releasing the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TensorFlow code for the BERT model architecture (which is mostly a standard
&lt;a href="https://arxiv.org/abs/1706.03762" rel="nofollow"&gt;Transformer&lt;/a&gt; architecture).&lt;/li&gt;
&lt;li&gt;Pre-trained checkpoints for both the lowercase and cased version of
&lt;code&gt;BERT-Base&lt;/code&gt; and &lt;code&gt;BERT-Large&lt;/code&gt; from the paper.&lt;/li&gt;
&lt;li&gt;TensorFlow code for push-button replication of the most important
fine-tuning experiments from the paper, including SQuAD, MultiNLI, and MRPC.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of the code in this repository works out-of-the-box with CPU, GPU, and Cloud
TPU.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pre-trained-models" class="anchor" aria-hidden="true" href="#pre-trained-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-trained models&lt;/h2&gt;
&lt;p&gt;We are releasing the &lt;code&gt;BERT-Base&lt;/code&gt; and &lt;code&gt;BERT-Large&lt;/code&gt; models from the paper.
&lt;code&gt;Uncased&lt;/code&gt; means that the text has been lowercased before WordPiece tokenization,
e.g., &lt;code&gt;John Smith&lt;/code&gt; becomes &lt;code&gt;john smith&lt;/code&gt;. The &lt;code&gt;Uncased&lt;/code&gt; model also strips out any
accent markers. &lt;code&gt;Cased&lt;/code&gt; means that the true case and accent markers are
preserved. Typically, the &lt;code&gt;Uncased&lt;/code&gt; model is better unless you know that case
information is important for your task (e.g., Named Entity Recognition or
Part-of-Speech tagging).&lt;/p&gt;
&lt;p&gt;These models are all released under the same license as the source code (Apache
2.0).&lt;/p&gt;
&lt;p&gt;For information about the Multilingual and Chinese model, see the
&lt;a href="https://github.com/google-research/bert/blob/master/multilingual.md"&gt;Multilingual README&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When using a cased model, make sure to pass &lt;code&gt;--do_lower=False&lt;/code&gt; to the training
scripts. (Or pass &lt;code&gt;do_lower_case=False&lt;/code&gt; directly to &lt;code&gt;FullTokenizer&lt;/code&gt; if you're
using your own script.)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The links to the models are here (right-click, 'Save link as...' on the name):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Uncased (Whole Word Masking)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2019_05_30/wwm_cased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Cased (Whole Word Masking)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Uncased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Uncased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Cased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
12-layer, 768-hidden, 12-heads , 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Cased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Multilingual Cased (New, recommended)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
104 languages, 12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/multilingual_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Multilingual Uncased (Orig, not recommended)&lt;/code&gt;&lt;/a&gt;
(Not recommended, use &lt;code&gt;Multilingual Cased&lt;/code&gt; instead)&lt;/strong&gt;: 102 languages,
12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Chinese&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M
parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each .zip file contains three items:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A TensorFlow checkpoint (&lt;code&gt;bert_model.ckpt&lt;/code&gt;) containing the pre-trained
weights (which is actually 3 files).&lt;/li&gt;
&lt;li&gt;A vocab file (&lt;code&gt;vocab.txt&lt;/code&gt;) to map WordPiece to word id.&lt;/li&gt;
&lt;li&gt;A config file (&lt;code&gt;bert_config.json&lt;/code&gt;) which specifies the hyperparameters of
the model.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-fine-tuning-with-bert" class="anchor" aria-hidden="true" href="#fine-tuning-with-bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning with BERT&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: All results on the paper were fine-tuned on a single Cloud TPU,
which has 64GB of RAM. It is currently not possible to re-produce most of the
&lt;code&gt;BERT-Large&lt;/code&gt; results on the paper using a GPU with 12GB - 16GB of RAM, because
the maximum batch size that can fit in memory is too small. We are working on
adding code to this repository which allows for much larger effective batch size
on the GPU. See the section on &lt;a href="#out-of-memory-issues"&gt;out-of-memory issues&lt;/a&gt; for
more details.&lt;/p&gt;
&lt;p&gt;This code was tested with TensorFlow 1.11.0. It was tested with Python2 and
Python3 (but more thoroughly with Python2, since this is what's used internally
in Google).&lt;/p&gt;
&lt;p&gt;The fine-tuning examples which use &lt;code&gt;BERT-Base&lt;/code&gt; should be able to run on a GPU
that has at least 12GB of RAM using the hyperparameters given.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-fine-tuning-with-cloud-tpus" class="anchor" aria-hidden="true" href="#fine-tuning-with-cloud-tpus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning with Cloud TPUs&lt;/h3&gt;
&lt;p&gt;Most of the examples below assumes that you will be running training/evaluation
on your local machine, using a GPU like a Titan X or GTX 1080.&lt;/p&gt;
&lt;p&gt;However, if you have access to a Cloud TPU that you want to train on, just add
the following flags to &lt;code&gt;run_classifier.py&lt;/code&gt; or &lt;code&gt;run_squad.py&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  --use_tpu=True \
  --tpu_name=$TPU_NAME
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please see the
&lt;a href="https://cloud.google.com/tpu/docs/tutorials/mnist" rel="nofollow"&gt;Google Cloud TPU tutorial&lt;/a&gt;
for how to use Cloud TPUs. Alternatively, you can use the Google Colab notebook
"&lt;a href="https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb" rel="nofollow"&gt;BERT FineTuning with Cloud TPUs&lt;/a&gt;".&lt;/p&gt;
&lt;p&gt;On Cloud TPUs, the pretrained model and the output directory will need to be on
Google Cloud Storage. For example, if you have a bucket named &lt;code&gt;some_bucket&lt;/code&gt;, you
might use the following flags instead:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  --output_dir=gs://some_bucket/my_output_dir/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The unzipped pre-trained model files can also be found in the Google Cloud
Storage folder &lt;code&gt;gs://bert_models/2018_10_18&lt;/code&gt;. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export BERT_BASE_DIR=gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-sentence-and-sentence-pair-classification-tasks" class="anchor" aria-hidden="true" href="#sentence-and-sentence-pair-classification-tasks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sentence (and sentence-pair) classification tasks&lt;/h3&gt;
&lt;p&gt;Before running this example you must download the
&lt;a href="https://gluebenchmark.com/tasks" rel="nofollow"&gt;GLUE data&lt;/a&gt; by running
&lt;a href="https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e"&gt;this script&lt;/a&gt;
and unpack it to some directory &lt;code&gt;$GLUE_DIR&lt;/code&gt;. Next, download the &lt;code&gt;BERT-Base&lt;/code&gt;
checkpoint and unzip it to some directory &lt;code&gt;$BERT_BASE_DIR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This example code fine-tunes &lt;code&gt;BERT-Base&lt;/code&gt; on the Microsoft Research Paraphrase
Corpus (MRPC) corpus, which only contains 3,600 examples and can fine-tune in a
few minutes on most GPUs.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12
&lt;span class="pl-k"&gt;export&lt;/span&gt; GLUE_DIR=/path/to/glue

python run_classifier.py \
  --task_name=MRPC \
  --do_train=true \
  --do_eval=true \
  --data_dir=&lt;span class="pl-smi"&gt;$GLUE_DIR&lt;/span&gt;/MRPC \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_model.ckpt \
  --max_seq_length=128 \
  --train_batch_size=32 \
  --learning_rate=2e-5 \
  --num_train_epochs=3.0 \
  --output_dir=/tmp/mrpc_output/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You should see output like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;***** Eval results *****
  eval_accuracy = 0.845588
  eval_loss = 0.505248
  global_step = 343
  loss = 0.505248
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This means that the Dev set accuracy was 84.55%. Small sets like MRPC have a
high variance in the Dev set accuracy, even when starting from the same
pre-training checkpoint. If you re-run multiple times (making sure to point to
different &lt;code&gt;output_dir&lt;/code&gt;), you should see results between 84% and 88%.&lt;/p&gt;
&lt;p&gt;A few other pre-trained models are implemented off-the-shelf in
&lt;code&gt;run_classifier.py&lt;/code&gt;, so it should be straightforward to follow those examples to
use BERT for any single-sentence or sentence-pair classification task.&lt;/p&gt;
&lt;p&gt;Note: You might see a message &lt;code&gt;Running train on CPU&lt;/code&gt;. This really just means
that it's running on something other than a Cloud TPU, which includes a GPU.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-prediction-from-classifier" class="anchor" aria-hidden="true" href="#prediction-from-classifier"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prediction from classifier&lt;/h4&gt;
&lt;p&gt;Once you have trained your classifier you can use it in inference mode by using
the --do_predict=true command. You need to have a file named test.tsv in the
input folder. Output will be created in file called test_results.tsv in the
output folder. Each line will contain output for each sample, columns are the
class probabilities.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12
&lt;span class="pl-k"&gt;export&lt;/span&gt; GLUE_DIR=/path/to/glue
&lt;span class="pl-k"&gt;export&lt;/span&gt; TRAINED_CLASSIFIER=/path/to/fine/tuned/classifier

python run_classifier.py \
  --task_name=MRPC \
  --do_predict=true \
  --data_dir=&lt;span class="pl-smi"&gt;$GLUE_DIR&lt;/span&gt;/MRPC \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$TRAINED_CLASSIFIER&lt;/span&gt; \
  --max_seq_length=128 \
  --output_dir=/tmp/mrpc_output/&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-squad-11" class="anchor" aria-hidden="true" href="#squad-11"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SQuAD 1.1&lt;/h3&gt;
&lt;p&gt;The Stanford Question Answering Dataset (SQuAD) is a popular question answering
benchmark dataset. BERT (at the time of the release) obtains state-of-the-art
results on SQuAD with almost no task-specific network architecture modifications
or data augmentation. However, it does require semi-complex data pre-processing
and post-processing to deal with (a) the variable-length nature of SQuAD context
paragraphs, and (b) the character-level answer annotations which are used for
SQuAD training. This processing is implemented and documented in &lt;code&gt;run_squad.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To run on SQuAD, you will first need to download the dataset. The
&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/" rel="nofollow"&gt;SQuAD website&lt;/a&gt; does not seem to
link to the v1.1 datasets any longer, but the necessary files can be found here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json" rel="nofollow"&gt;train-v1.1.json&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json" rel="nofollow"&gt;dev-v1.1.json&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/allenai/bi-att-flow/blob/master/squad/evaluate-v1.1.py"&gt;evaluate-v1.1.py&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Download these to some directory &lt;code&gt;$SQUAD_DIR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The state-of-the-art SQuAD results from the paper currently cannot be reproduced
on a 12GB-16GB GPU due to memory constraints (in fact, even batch size 1 does
not seem to fit on a 12GB GPU using &lt;code&gt;BERT-Large&lt;/code&gt;). However, a reasonably strong
&lt;code&gt;BERT-Base&lt;/code&gt; model can be trained on the GPU with these hyperparameters:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_squad.py \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_model.ckpt \
  --do_train=True \
  --train_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v1.1.json \
  --do_predict=True \
  --predict_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json \
  --train_batch_size=12 \
  --learning_rate=3e-5 \
  --num_train_epochs=2.0 \
  --max_seq_length=384 \
  --doc_stride=128 \
  --output_dir=/tmp/squad_base/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The dev set predictions will be saved into a file called &lt;code&gt;predictions.json&lt;/code&gt; in
the &lt;code&gt;output_dir&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/evaluate-v1.1.py &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json ./squad/predictions.json&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Which should produce an output like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;f1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 88.41249612335034, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;exact_match&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 81.2488174077578}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You should see a result similar to the 88.5% reported in the paper for
&lt;code&gt;BERT-Base&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you have access to a Cloud TPU, you can train with &lt;code&gt;BERT-Large&lt;/code&gt;. Here is a
set of hyperparameters (slightly different than the paper) which consistently
obtain around 90.5%-91.0% F1 single-system trained only on SQuAD:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_squad.py \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_model.ckpt \
  --do_train=True \
  --train_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v1.1.json \
  --do_predict=True \
  --predict_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json \
  --train_batch_size=24 \
  --learning_rate=3e-5 \
  --num_train_epochs=2.0 \
  --max_seq_length=384 \
  --doc_stride=128 \
  --output_dir=gs://some_bucket/squad_large/ \
  --use_tpu=True \
  --tpu_name=&lt;span class="pl-smi"&gt;$TPU_NAME&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For example, one random run with these parameters produces the following Dev
scores:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;f1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 90.87081895814865, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;exact_match&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 84.38978240302744}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you fine-tune for one epoch on
&lt;a href="http://nlp.cs.washington.edu/triviaqa/" rel="nofollow"&gt;TriviaQA&lt;/a&gt; before this the results will
be even better, but you will need to convert TriviaQA into the SQuAD json
format.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-squad-20" class="anchor" aria-hidden="true" href="#squad-20"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SQuAD 2.0&lt;/h3&gt;
&lt;p&gt;This model is also implemented and documented in &lt;code&gt;run_squad.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To run on SQuAD 2.0, you will first need to download the dataset. The necessary
files can be found here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json" rel="nofollow"&gt;train-v2.0.json&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json" rel="nofollow"&gt;dev-v2.0.json&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/" rel="nofollow"&gt;evaluate-v2.0.py&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Download these to some directory &lt;code&gt;$SQUAD_DIR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;On Cloud TPU you can run with BERT-Large as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_squad.py \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_model.ckpt \
  --do_train=True \
  --train_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v2.0.json \
  --do_predict=True \
  --predict_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v2.0.json \
  --train_batch_size=24 \
  --learning_rate=3e-5 \
  --num_train_epochs=2.0 \
  --max_seq_length=384 \
  --doc_stride=128 \
  --output_dir=gs://some_bucket/squad_large/ \
  --use_tpu=True \
  --tpu_name=&lt;span class="pl-smi"&gt;$TPU_NAME&lt;/span&gt; \
  --version_2_with_negative=True&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We assume you have copied everything from the output directory to a local
directory called ./squad/. The initial dev set predictions will be at
./squad/predictions.json and the differences between the score of no answer ("")
and the best non-null answer for each question will be in the file
./squad/null_odds.json&lt;/p&gt;
&lt;p&gt;Run this script to tune a threshold for predicting null versus non-null answers:&lt;/p&gt;
&lt;p&gt;python $SQUAD_DIR/evaluate-v2.0.py $SQUAD_DIR/dev-v2.0.json
./squad/predictions.json --na-prob-file ./squad/null_odds.json&lt;/p&gt;
&lt;p&gt;Assume the script outputs "best_f1_thresh" THRESH. (Typical values are between
-1.0 and -5.0). You can now re-run the model to generate predictions with the
derived threshold or alternatively you can extract the appropriate answers from
./squad/nbest_predictions.json.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_squad.py \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_model.ckpt \
  --do_train=False \
  --train_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v2.0.json \
  --do_predict=True \
  --predict_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v2.0.json \
  --train_batch_size=24 \
  --learning_rate=3e-5 \
  --num_train_epochs=2.0 \
  --max_seq_length=384 \
  --doc_stride=128 \
  --output_dir=gs://some_bucket/squad_large/ \
  --use_tpu=True \
  --tpu_name=&lt;span class="pl-smi"&gt;$TPU_NAME&lt;/span&gt; \
  --version_2_with_negative=True \
  --null_score_diff_threshold=&lt;span class="pl-smi"&gt;$THRESH&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-out-of-memory-issues" class="anchor" aria-hidden="true" href="#out-of-memory-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Out-of-memory issues&lt;/h3&gt;
&lt;p&gt;All experiments in the paper were fine-tuned on a Cloud TPU, which has 64GB of
device RAM. Therefore, when using a GPU with 12GB - 16GB of RAM, you are likely
to encounter out-of-memory issues if you use the same hyperparameters described
in the paper.&lt;/p&gt;
&lt;p&gt;The factors that affect memory usage are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;max_seq_length&lt;/code&gt;&lt;/strong&gt;: The released models were trained with sequence lengths
up to 512, but you can fine-tune with a shorter max sequence length to save
substantial memory. This is controlled by the &lt;code&gt;max_seq_length&lt;/code&gt; flag in our
example code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;train_batch_size&lt;/code&gt;&lt;/strong&gt;: The memory usage is also directly proportional to
the batch size.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model type, &lt;code&gt;BERT-Base&lt;/code&gt; vs. &lt;code&gt;BERT-Large&lt;/code&gt;&lt;/strong&gt;: The &lt;code&gt;BERT-Large&lt;/code&gt; model
requires significantly more memory than &lt;code&gt;BERT-Base&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Optimizer&lt;/strong&gt;: The default optimizer for BERT is Adam, which requires a lot
of extra memory to store the &lt;code&gt;m&lt;/code&gt; and &lt;code&gt;v&lt;/code&gt; vectors. Switching to a more memory
efficient optimizer can reduce memory usage, but can also affect the
results. We have not experimented with other optimizers for fine-tuning.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Using the default training scripts (&lt;code&gt;run_classifier.py&lt;/code&gt; and &lt;code&gt;run_squad.py&lt;/code&gt;), we
benchmarked the maximum batch size on single Titan X GPU (12GB RAM) with
TensorFlow 1.11.0:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;System&lt;/th&gt;
&lt;th&gt;Seq Length&lt;/th&gt;
&lt;th&gt;Max Batch Size&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;BERT-Base&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;128&lt;/td&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;320&lt;/td&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;384&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;512&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;BERT-Large&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;128&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;320&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;384&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;512&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Unfortunately, these max batch sizes for &lt;code&gt;BERT-Large&lt;/code&gt; are so small that they
will actually harm the model accuracy, regardless of the learning rate used. We
are working on adding code to this repository which will allow much larger
effective batch sizes to be used on the GPU. The code will be based on one (or
both) of the following techniques:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Gradient accumulation&lt;/strong&gt;: The samples in a minibatch are typically
independent with respect to gradient computation (excluding batch
normalization, which is not used here). This means that the gradients of
multiple smaller minibatches can be accumulated before performing the weight
update, and this will be exactly equivalent to a single larger update.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/openai/gradient-checkpointing"&gt;&lt;strong&gt;Gradient checkpointing&lt;/strong&gt;&lt;/a&gt;:
The major use of GPU/TPU memory during DNN training is caching the
intermediate activations in the forward pass that are necessary for
efficient computation in the backward pass. "Gradient checkpointing" trades
memory for compute time by re-computing the activations in an intelligent
way.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;However, this is not implemented in the current release.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-bert-to-extract-fixed-feature-vectors-like-elmo" class="anchor" aria-hidden="true" href="#using-bert-to-extract-fixed-feature-vectors-like-elmo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using BERT to extract fixed feature vectors (like ELMo)&lt;/h2&gt;
&lt;p&gt;In certain cases, rather than fine-tuning the entire pre-trained model
end-to-end, it can be beneficial to obtained &lt;em&gt;pre-trained contextual
embeddings&lt;/em&gt;, which are fixed contextual representations of each input token
generated from the hidden layers of the pre-trained model. This should also
mitigate most of the out-of-memory issues.&lt;/p&gt;
&lt;p&gt;As an example, we include the script &lt;code&gt;extract_features.py&lt;/code&gt; which can be used
like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Sentence A and Sentence B are separated by the ||| delimiter for sentence&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; pair tasks like question answering and entailment.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; For single sentence inputs, put one sentence per line and DON'T use the&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; delimiter.&lt;/span&gt;
&lt;span class="pl-c1"&gt;echo&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Who was Jim Henson ? ||| Jim Henson was a puppeteer&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; /tmp/input.txt

python extract_features.py \
  --input_file=/tmp/input.txt \
  --output_file=/tmp/output.jsonl \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_model.ckpt \
  --layers=-1,-2,-3,-4 \
  --max_seq_length=128 \
  --batch_size=8&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will create a JSON file (one line per line of input) containing the BERT
activations from each Transformer layer specified by &lt;code&gt;layers&lt;/code&gt; (-1 is the final
hidden layer of the Transformer, etc.)&lt;/p&gt;
&lt;p&gt;Note that this script will produce very large output files (by default, around
15kb for every input token).&lt;/p&gt;
&lt;p&gt;If you need to maintain alignment between the original and tokenized words (for
projecting training labels), see the &lt;a href="#tokenization"&gt;Tokenization&lt;/a&gt; section
below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You may see a message like &lt;code&gt;Could not find trained model in model_dir: /tmp/tmpuB5g5c, running initialization to predict.&lt;/code&gt; This message is expected, it
just means that we are using the &lt;code&gt;init_from_checkpoint()&lt;/code&gt; API rather than the
saved model API. If you don't specify a checkpoint or specify an invalid
checkpoint, this script will complain.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tokenization" class="anchor" aria-hidden="true" href="#tokenization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tokenization&lt;/h2&gt;
&lt;p&gt;For sentence-level tasks (or sentence-pair) tasks, tokenization is very simple.
Just follow the example code in &lt;code&gt;run_classifier.py&lt;/code&gt; and &lt;code&gt;extract_features.py&lt;/code&gt;.
The basic procedure for sentence-level tasks is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Instantiate an instance of &lt;code&gt;tokenizer = tokenization.FullTokenizer&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tokenize the raw text with &lt;code&gt;tokens = tokenizer.tokenize(raw_text)&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Truncate to the maximum sequence length. (You can use up to 512, but you
probably want to use shorter if possible for memory and speed reasons.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add the &lt;code&gt;[CLS]&lt;/code&gt; and &lt;code&gt;[SEP]&lt;/code&gt; tokens in the right place.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Word-level and span-level tasks (e.g., SQuAD and NER) are more complex, since
you need to maintain alignment between your input text and output text so that
you can project your training labels. SQuAD is a particularly complex example
because the input labels are &lt;em&gt;character&lt;/em&gt;-based, and SQuAD paragraphs are often
longer than our maximum sequence length. See the code in &lt;code&gt;run_squad.py&lt;/code&gt; to show
how we handle this.&lt;/p&gt;
&lt;p&gt;Before we describe the general recipe for handling word-level tasks, it's
important to understand what exactly our tokenizer is doing. It has three main
steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Text normalization&lt;/strong&gt;: Convert all whitespace characters to spaces, and
(for the &lt;code&gt;Uncased&lt;/code&gt; model) lowercase the input and strip out accent markers.
E.g., &lt;code&gt;John Johanson's, → john johanson's,&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Punctuation splitting&lt;/strong&gt;: Split &lt;em&gt;all&lt;/em&gt; punctuation characters on both sides
(i.e., add whitespace around all punctuation characters). Punctuation
characters are defined as (a) Anything with a &lt;code&gt;P*&lt;/code&gt; Unicode class, (b) any
non-letter/number/space ASCII character (e.g., characters like &lt;code&gt;$&lt;/code&gt; which are
technically not punctuation). E.g., &lt;code&gt;john johanson's, → john johanson ' s ,&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;WordPiece tokenization&lt;/strong&gt;: Apply whitespace tokenization to the output of
the above procedure, and apply
&lt;a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/text_encoder.py"&gt;WordPiece&lt;/a&gt;
tokenization to each token separately. (Our implementation is directly based
on the one from &lt;code&gt;tensor2tensor&lt;/code&gt;, which is linked). E.g., &lt;code&gt;john johanson ' s , → john johan ##son ' s ,&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The advantage of this scheme is that it is "compatible" with most existing
English tokenizers. For example, imagine that you have a part-of-speech tagging
task which looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Input:  John Johanson 's   house
Labels: NNP  NNP      POS NN
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The tokenized output will look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Tokens: john johan ##son ' s house
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Crucially, this would be the same output as if the raw text were &lt;code&gt;John Johanson's house&lt;/code&gt; (with no space before the &lt;code&gt;'s&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;If you have a pre-tokenized representation with word-level annotations, you can
simply tokenize each input word independently, and deterministically maintain an
original-to-tokenized alignment:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Input&lt;/span&gt;
orig_tokens &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;John&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Johanson&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;'s&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,  &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;house&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;]
labels      &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;NNP&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,  &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;NNP&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,      &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;POS&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;NN&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Output&lt;/span&gt;
bert_tokens &lt;span class="pl-k"&gt;=&lt;/span&gt; []

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Token map will be an int -&amp;gt; int mapping between the `orig_tokens` index and&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; the `bert_tokens` index.&lt;/span&gt;
orig_to_tok_map &lt;span class="pl-k"&gt;=&lt;/span&gt; []

tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; tokenization.FullTokenizer(
    &lt;span class="pl-v"&gt;vocab_file&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;vocab_file, &lt;span class="pl-v"&gt;do_lower_case&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)

bert_tokens.append(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;[CLS]&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;for&lt;/span&gt; orig_token &lt;span class="pl-k"&gt;in&lt;/span&gt; orig_tokens:
  orig_to_tok_map.append(&lt;span class="pl-c1"&gt;len&lt;/span&gt;(bert_tokens))
  bert_tokens.extend(tokenizer.tokenize(orig_token))
bert_tokens.append(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;[SEP]&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; bert_tokens == ["[CLS]", "john", "johan", "##son", "'", "s", "house", "[SEP]"]&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; orig_to_tok_map == [1, 2, 4, 6]&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now &lt;code&gt;orig_to_tok_map&lt;/code&gt; can be used to project &lt;code&gt;labels&lt;/code&gt; to the tokenized
representation.&lt;/p&gt;
&lt;p&gt;There are common English tokenization schemes which will cause a slight mismatch
between how BERT was pre-trained. For example, if your input tokenization splits
off contractions like &lt;code&gt;do n't&lt;/code&gt;, this will cause a mismatch. If it is possible to
do so, you should pre-process your data to convert these back to raw-looking
text, but if it's not possible, this mismatch is likely not a big deal.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pre-training-with-bert" class="anchor" aria-hidden="true" href="#pre-training-with-bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-training with BERT&lt;/h2&gt;
&lt;p&gt;We are releasing code to do "masked LM" and "next sentence prediction" on an
arbitrary text corpus. Note that this is &lt;em&gt;not&lt;/em&gt; the exact code that was used for
the paper (the original code was written in C++, and had some additional
complexity), but this code does generate pre-training data as described in the
paper.&lt;/p&gt;
&lt;p&gt;Here's how to run the data generation. The input is a plain text file, with one
sentence per line. (It is important that these be actual sentences for the "next
sentence prediction" task). Documents are delimited by empty lines. The output
is a set of &lt;code&gt;tf.train.Example&lt;/code&gt;s serialized into &lt;code&gt;TFRecord&lt;/code&gt; file format.&lt;/p&gt;
&lt;p&gt;You can perform sentence segmentation with an off-the-shelf NLP toolkit such as
&lt;a href="https://spacy.io/" rel="nofollow"&gt;spaCy&lt;/a&gt;. The &lt;code&gt;create_pretraining_data.py&lt;/code&gt; script will
concatenate segments until they reach the maximum sequence length to minimize
computational waste from padding (see the script for more details). However, you
may want to intentionally add a slight amount of noise to your input data (e.g.,
randomly truncate 2% of input segments) to make it more robust to non-sentential
input during fine-tuning.&lt;/p&gt;
&lt;p&gt;This script stores all of the examples for the entire input file in memory, so
for large data files you should shard the input file and call the script
multiple times. (You can pass in a file glob to &lt;code&gt;run_pretraining.py&lt;/code&gt;, e.g.,
&lt;code&gt;tf_examples.tf_record*&lt;/code&gt;.)&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;max_predictions_per_seq&lt;/code&gt; is the maximum number of masked LM predictions per
sequence. You should set this to around &lt;code&gt;max_seq_length&lt;/code&gt; * &lt;code&gt;masked_lm_prob&lt;/code&gt; (the
script doesn't do that automatically because the exact value needs to be passed
to both scripts).&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python create_pretraining_data.py \
  --input_file=./sample_text.txt \
  --output_file=/tmp/tf_examples.tfrecord \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --do_lower_case=True \
  --max_seq_length=128 \
  --max_predictions_per_seq=20 \
  --masked_lm_prob=0.15 \
  --random_seed=12345 \
  --dupe_factor=5&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here's how to run the pre-training. Do not include &lt;code&gt;init_checkpoint&lt;/code&gt; if you are
pre-training from scratch. The model configuration (including vocab size) is
specified in &lt;code&gt;bert_config_file&lt;/code&gt;. This demo code only pre-trains for a small
number of steps (20), but in practice you will probably want to set
&lt;code&gt;num_train_steps&lt;/code&gt; to 10000 steps or more. The &lt;code&gt;max_seq_length&lt;/code&gt; and
&lt;code&gt;max_predictions_per_seq&lt;/code&gt; parameters passed to &lt;code&gt;run_pretraining.py&lt;/code&gt; must be the
same as &lt;code&gt;create_pretraining_data.py&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_pretraining.py \
  --input_file=/tmp/tf_examples.tfrecord \
  --output_dir=/tmp/pretraining_output \
  --do_train=True \
  --do_eval=True \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_model.ckpt \
  --train_batch_size=32 \
  --max_seq_length=128 \
  --max_predictions_per_seq=20 \
  --num_train_steps=20 \
  --num_warmup_steps=10 \
  --learning_rate=2e-5&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will produce an output like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;***** Eval results *****
  global_step = 20
  loss = 0.0979674
  masked_lm_accuracy = 0.985479
  masked_lm_loss = 0.0979328
  next_sentence_accuracy = 1.0
  next_sentence_loss = 3.45724e-05
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that since our &lt;code&gt;sample_text.txt&lt;/code&gt; file is very small, this example training
will overfit that data in only a few steps and produce unrealistically high
accuracy numbers.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-pre-training-tips-and-caveats" class="anchor" aria-hidden="true" href="#pre-training-tips-and-caveats"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-training tips and caveats&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;If using your own vocabulary, make sure to change &lt;code&gt;vocab_size&lt;/code&gt; in
&lt;code&gt;bert_config.json&lt;/code&gt;. If you use a larger vocabulary without changing this,
you will likely get NaNs when training on GPU or TPU due to unchecked
out-of-bounds access.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;If your task has a large domain-specific corpus available (e.g., "movie
reviews" or "scientific papers"), it will likely be beneficial to run
additional steps of pre-training on your corpus, starting from the BERT
checkpoint.&lt;/li&gt;
&lt;li&gt;The learning rate we used in the paper was 1e-4. However, if you are doing
additional steps of pre-training starting from an existing BERT checkpoint,
you should use a smaller learning rate (e.g., 2e-5).&lt;/li&gt;
&lt;li&gt;Current BERT models are English-only, but we do plan to release a
multilingual model which has been pre-trained on a lot of languages in the
near future (hopefully by the end of November 2018).&lt;/li&gt;
&lt;li&gt;Longer sequences are disproportionately expensive because attention is
quadratic to the sequence length. In other words, a batch of 64 sequences of
length 512 is much more expensive than a batch of 256 sequences of
length 128. The fully-connected/convolutional cost is the same, but the
attention cost is far greater for the 512-length sequences. Therefore, one
good recipe is to pre-train for, say, 90,000 steps with a sequence length of
128 and then for 10,000 additional steps with a sequence length of 512. The
very long sequences are mostly needed to learn positional embeddings, which
can be learned fairly quickly. Note that this does require generating the
data twice with different values of &lt;code&gt;max_seq_length&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If you are pre-training from scratch, be prepared that pre-training is
computationally expensive, especially on GPUs. If you are pre-training from
scratch, our recommended recipe is to pre-train a &lt;code&gt;BERT-Base&lt;/code&gt; on a single
&lt;a href="https://cloud.google.com/tpu/docs/pricing" rel="nofollow"&gt;preemptible Cloud TPU v2&lt;/a&gt;, which
takes about 2 weeks at a cost of about $500 USD (based on the pricing in
October 2018). You will have to scale down the batch size when only training
on a single Cloud TPU, compared to what was used in the paper. It is
recommended to use the largest batch size that fits into TPU memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pre-training-data" class="anchor" aria-hidden="true" href="#pre-training-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-training data&lt;/h3&gt;
&lt;p&gt;We will &lt;strong&gt;not&lt;/strong&gt; be able to release the pre-processed datasets used in the paper.
For Wikipedia, the recommended pre-processing is to download
&lt;a href="https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2" rel="nofollow"&gt;the latest dump&lt;/a&gt;,
extract the text with
&lt;a href="https://github.com/attardi/wikiextractor"&gt;&lt;code&gt;WikiExtractor.py&lt;/code&gt;&lt;/a&gt;, and then apply
any necessary cleanup to convert it into plain text.&lt;/p&gt;
&lt;p&gt;Unfortunately the researchers who collected the
&lt;a href="http://yknzhu.wixsite.com/mbweb" rel="nofollow"&gt;BookCorpus&lt;/a&gt; no longer have it available for
public download. The
&lt;a href="https://web.eecs.umich.edu/~lahiri/gutenberg_dataset.html" rel="nofollow"&gt;Project Guttenberg Dataset&lt;/a&gt;
is a somewhat smaller (200M word) collection of older books that are public
domain.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://commoncrawl.org/" rel="nofollow"&gt;Common Crawl&lt;/a&gt; is another very large collection of
text, but you will likely have to do substantial pre-processing and cleanup to
extract a usable corpus for pre-training BERT.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-learning-a-new-wordpiece-vocabulary" class="anchor" aria-hidden="true" href="#learning-a-new-wordpiece-vocabulary"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learning a new WordPiece vocabulary&lt;/h3&gt;
&lt;p&gt;This repository does not include code for &lt;em&gt;learning&lt;/em&gt; a new WordPiece vocabulary.
The reason is that the code used in the paper was implemented in C++ with
dependencies on Google's internal libraries. For English, it is almost always
better to just start with our vocabulary and pre-trained models. For learning
vocabularies of other languages, there are a number of open source options
available. However, keep in mind that these are not compatible with our
&lt;code&gt;tokenization.py&lt;/code&gt; library:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/google/sentencepiece"&gt;Google's SentencePiece library&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/text_encoder_build_subword.py"&gt;tensor2tensor's WordPiece generation script&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/rsennrich/subword-nmt"&gt;Rico Sennrich's Byte Pair Encoding library&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-using-bert-in-colab" class="anchor" aria-hidden="true" href="#using-bert-in-colab"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using BERT in Colab&lt;/h2&gt;
&lt;p&gt;If you want to use BERT with &lt;a href="https://colab.research.google.com" rel="nofollow"&gt;Colab&lt;/a&gt;, you can
get started with the notebook
"&lt;a href="https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb" rel="nofollow"&gt;BERT FineTuning with Cloud TPUs&lt;/a&gt;".
&lt;strong&gt;At the time of this writing (October 31st, 2018), Colab users can access a
Cloud TPU completely for free.&lt;/strong&gt; Note: One per user, availability limited,
requires a Google Cloud Platform account with storage (although storage may be
purchased with free credit for signing up with GCP), and this capability may not
longer be available in the future. Click on the BERT Colab that was just linked
for more information.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-faq" class="anchor" aria-hidden="true" href="#faq"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FAQ&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-is-this-code-compatible-with-cloud-tpus-what-about-gpus" class="anchor" aria-hidden="true" href="#is-this-code-compatible-with-cloud-tpus-what-about-gpus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Is this code compatible with Cloud TPUs? What about GPUs?&lt;/h4&gt;
&lt;p&gt;Yes, all of the code in this repository works out-of-the-box with CPU, GPU, and
Cloud TPU. However, GPU training is single-GPU only.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-i-am-getting-out-of-memory-errors-what-is-wrong" class="anchor" aria-hidden="true" href="#i-am-getting-out-of-memory-errors-what-is-wrong"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;I am getting out-of-memory errors, what is wrong?&lt;/h4&gt;
&lt;p&gt;See the section on &lt;a href="#out-of-memory-issues"&gt;out-of-memory issues&lt;/a&gt; for more
information.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-is-there-a-pytorch-version-available" class="anchor" aria-hidden="true" href="#is-there-a-pytorch-version-available"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Is there a PyTorch version available?&lt;/h4&gt;
&lt;p&gt;There is no official PyTorch implementation. However, NLP researchers from
HuggingFace made a
&lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT"&gt;PyTorch version of BERT available&lt;/a&gt;
which is compatible with our pre-trained checkpoints and is able to reproduce
our results. We were not involved in the creation or maintenance of the PyTorch
implementation so please direct any questions towards the authors of that
repository.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-is-there-a-chainer-version-available" class="anchor" aria-hidden="true" href="#is-there-a-chainer-version-available"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Is there a Chainer version available?&lt;/h4&gt;
&lt;p&gt;There is no official Chainer implementation. However, Sosuke Kobayashi made a
&lt;a href="https://github.com/soskek/bert-chainer"&gt;Chainer version of BERT available&lt;/a&gt;
which is compatible with our pre-trained checkpoints and is able to reproduce
our results. We were not involved in the creation or maintenance of the Chainer
implementation so please direct any questions towards the authors of that
repository.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-will-models-in-other-languages-be-released" class="anchor" aria-hidden="true" href="#will-models-in-other-languages-be-released"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Will models in other languages be released?&lt;/h4&gt;
&lt;p&gt;Yes, we plan to release a multi-lingual BERT model in the near future. We cannot
make promises about exactly which languages will be included, but it will likely
be a single model which includes &lt;em&gt;most&lt;/em&gt; of the languages which have a
significantly-sized Wikipedia.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-will-models-larger-than-bert-large-be-released" class="anchor" aria-hidden="true" href="#will-models-larger-than-bert-large-be-released"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Will models larger than &lt;code&gt;BERT-Large&lt;/code&gt; be released?&lt;/h4&gt;
&lt;p&gt;So far we have not attempted to train anything larger than &lt;code&gt;BERT-Large&lt;/code&gt;. It is
possible that we will release larger models if we are able to obtain significant
improvements.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-what-license-is-this-library-released-under" class="anchor" aria-hidden="true" href="#what-license-is-this-library-released-under"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What license is this library released under?&lt;/h4&gt;
&lt;p&gt;All code &lt;em&gt;and&lt;/em&gt; models are released under the Apache 2.0 license. See the
&lt;code&gt;LICENSE&lt;/code&gt; file for more information.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-how-do-i-cite-bert" class="anchor" aria-hidden="true" href="#how-do-i-cite-bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How do I cite BERT?&lt;/h4&gt;
&lt;p&gt;For now, cite &lt;a href="https://arxiv.org/abs/1810.04805" rel="nofollow"&gt;the Arxiv paper&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we submit the paper to a conference or journal, we will update the BibTeX.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;This is not an official Google product.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contact-information" class="anchor" aria-hidden="true" href="#contact-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact information&lt;/h2&gt;
&lt;p&gt;For help or issues using BERT, please submit a GitHub issue.&lt;/p&gt;
&lt;p&gt;For personal communication related to BERT, please contact Jacob Devlin
(&lt;code&gt;jacobdevlin@google.com&lt;/code&gt;), Ming-Wei Chang (&lt;code&gt;mingweichang@google.com&lt;/code&gt;), or
Kenton Lee (&lt;code&gt;kentonl@google.com&lt;/code&gt;).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>google-research</author><guid isPermaLink="false">https://github.com/google-research/bert</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>KubeOperator/KubeOperator #17 in Python, This week</title><link>https://github.com/KubeOperator/KubeOperator</link><description>&lt;p&gt;&lt;i&gt;KubeOperator 是一个开源项目，通过 Web UI 在 VMware、OpenStack、物理机上一键部署和管理生产级别的 Kubernetes 集群。&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-kubeoperator---从这里开启您的-kubernetes-之旅" class="anchor" aria-hidden="true" href="#kubeoperator---从这里开启您的-kubernetes-之旅"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;KubeOperator - 从这里开启您的 Kubernetes 之旅&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/KubeOperatpr/KubeOperatpr/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/7197a397ba1baf73679f3cf0edf68d821c35ae52/687474703a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d61706163686525323076322d626c75652e737667" alt="License" data-canonical-src="http://img.shields.io/badge/license-apache%20v2-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.python.org/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d4c11ac2b538cba463dfd1e43d05fe4f30f2d33d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d677265656e2e7376673f7374796c653d706c6173746963" alt="Python3" data-canonical-src="https://img.shields.io/badge/python-3.6-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.djangoproject.com/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/35798c7a6bb116ad2e8d420db49766bce91239b1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646a616e676f2d322e312d627269676874677265656e2e7376673f7374796c653d706c6173746963" alt="Django" data-canonical-src="https://img.shields.io/badge/django-2.1-brightgreen.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.ansible.com/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/dbfb9037d993ab109b0dd41252b2aabcd703e4a5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616e7369626c652d322e362e352d626c75652e7376673f7374796c653d706c6173746963" alt="Ansible" data-canonical-src="https://img.shields.io/badge/ansible-2.6.5-blue.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.angular.cn/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9829fdfaae3736e19d738b29efaeec4aaf21c61c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616e67756c61722d372e302e342d7265642e7376673f7374796c653d706c6173746963" alt="Angular" data-canonical-src="https://img.shields.io/badge/angular-7.0.4-red.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;KubeOperator 是一个开源项目，在离线网络环境下，通过可视化 Web UI 在 VMware、Openstack 或者物理机上规划、部署和管理生产级别的 Kubernetes 集群。KubeOperator 是 &lt;a href="https://github.com/jumpserver/jumpserver"&gt;Jumpserver&lt;/a&gt; 明星开源团队在 Kubernetes 领域的的又一全新力作。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/KubeOperator/docs/blob/master/website/static/img/overview.png?raw=true"&gt;&lt;img src="https://github.com/KubeOperator/docs/raw/master/website/static/img/overview.png?raw=true" alt="overview" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-web-ui-展示" class="anchor" aria-hidden="true" href="#web-ui-展示"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web UI 展示&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/KubeOperator/website/master/images/kubeoperator-ui.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/KubeOperator/website/master/images/kubeoperator-ui.jpg" alt="overview" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;更多功能截屏请查看：&lt;a href="https://docs.kubeoperator.io/kubeoperator-v2.1/screenshot" rel="nofollow"&gt;https://docs.kubeoperator.io/kubeoperator-v2.1/screenshot&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-整体架构" class="anchor" aria-hidden="true" href="#整体架构"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;整体架构&lt;/h2&gt;
&lt;p&gt;KubeOperator 使用 Terraform 在 IaaS 平台上自动创建主机（用户也可以自行准备主机，比如物理机或者虚机），通过 Ansible 完成自动化部署和变更操作，支持 Kubernetes 集群 从 Day 0 规划，到 Day 1 部署，到 Day 2 运维及变更的全生命周期管理。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/KubeOperator/docs/blob/master/website/static/img/KubeOperator.jpeg?raw=true"&gt;&lt;img src="https://github.com/KubeOperator/docs/raw/master/website/static/img/KubeOperator.jpeg?raw=true" alt="overview" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-技术优势" class="anchor" aria-hidden="true" href="#技术优势"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;技术优势&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;按需创建：调用云平台 API，一键快速创建和部署 Kubernetes 集群 (即 Kubernetes as a Service)；&lt;/li&gt;
&lt;li&gt;按需伸缩：快速伸缩 Kubernetes 集群，优化资源使用效率；&lt;/li&gt;
&lt;li&gt;按需修补：快速升级和修补 Kubernetes 集群，并与社区最新版本同步，保证安全性；&lt;/li&gt;
&lt;li&gt;自我修复：通过重建故障节点确保集群可用性；&lt;/li&gt;
&lt;li&gt;离线部署：持续更新包括 Kubernetes 及常用组件的离线包；&lt;/li&gt;
&lt;li&gt;Multi-AZ 支持：通过把 Kubernetes 集群 Master 节点分布在不同的故障域上确保的高可用；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-demo-视频使用文档" class="anchor" aria-hidden="true" href="#demo-视频使用文档"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Demo 视频、使用文档&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://kubeoperator-1256577600.file.myqcloud.com/video/KubeOperator2.1.mp4" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="tv" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4fa.png"&gt;📺&lt;/g-emoji&gt;8 分钟演示视频&lt;/a&gt;：详细演示 KubeOperator 的功能。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.kubeoperator.io/" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="books" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4da.png"&gt;📚&lt;/g-emoji&gt;安装及使用文档&lt;/a&gt;：包括 KubeOperator 安装文档、使用文档、功能截屏、常见问题等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-kubernetes-离线安装包" class="anchor" aria-hidden="true" href="#kubernetes-离线安装包"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Kubernetes 离线安装包&lt;/h2&gt;
&lt;p&gt;KubeOperator 提供完整的离线 Kubernetes 安装包（包括 Kubernetes、Docker、etcd、Dashboard、Promethus、OS 补丁等），每个安装包会被构建成一个独立容器镜像供 KubeOperator 使用，具体信息请参考：&lt;a href="https://github.com/KubeOperator/k8s-package"&gt;k8s-package&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-版本规划" class="anchor" aria-hidden="true" href="#版本规划"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;版本规划&lt;/h2&gt;
&lt;p&gt;v1.0 （已发布）&lt;/p&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 提供原生 Kubernetes 的离线包仓库；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持一主多节点部署模式；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持离线环境下的一键自动化部署，可视化展示集群部署进展和结果；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 内置 Kubernetes 常用系统应用的安装，包括 Registry、Promethus、Dashboard、Traefik Ingress、Helm 等；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 提供简易明了的 Kubernetes 集群运行状况面板；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 NFS 作为持久化存储；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Flannel 网络插件；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Kubernetes 集群手动部署模式（自行准备主机和 NFS）；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;v2.0 （已发布）&lt;/p&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持调用 VMware vCenter API 自动创建集群主机；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 VMware vSAN 、VMFS/NFS 作为持久化存储；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Multi AZ，支持多主多节点部署模式；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Calico 网络插件；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 内置 Weave Scope；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持通过 F5 BIG-IP Controller 对外暴露服务（Nodeport mode, 七层和四层服务都支持）；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;v2.1 （已发布）&lt;/p&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Openstack 云平台；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Openstack Cinder 作为持久化存储；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Kubernetes 集群升级 （Day 2）；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Kubernetes 集群扩缩容（Day 2）；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Kubernetes 集群备份与恢复（Day 2）；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Kubernetes 集群健康检查与诊断（Day 2）；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 &lt;a href="https://github.com/webkubectl/webkubectl"&gt;webkubectl&lt;/a&gt; ；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;v2.2 （计划中，预计 2019.12.31 发布）&lt;/p&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 国际化支持；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 集成 KubeApps 应用商店；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 支持 VMware NSX-T；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 日志收集及管理方案；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-沟通交流" class="anchor" aria-hidden="true" href="#沟通交流"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;沟通交流&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;技术交流 QQ 群：825046920；&lt;/li&gt;
&lt;li&gt;技术支持邮箱：&lt;a href="mailto:support@fit2cloud.com"&gt;support@fit2cloud.com&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;微信群： 搜索微信号 wh_it0224，添加好友，备注（城市-github用户名）, 验证通过会加入群聊；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-致谢" class="anchor" aria-hidden="true" href="#致谢"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;致谢&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/hashicorp/terraform"&gt;Terraform&lt;/a&gt;: KubeOperator 采用 Terraform 来自动创建虚机；&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/vmware/clarity/"&gt;Clarity&lt;/a&gt;: KubeOperator 采用 Clarity 作为前端 Web 框架；&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ansible/ansible"&gt;Ansible&lt;/a&gt;: KubeOperator 采用 Ansible 作为自动化部署工具；&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/easzlab/kubeasz"&gt;kubeasz&lt;/a&gt;: 提供各种 Kubernetes Ansible 脚本；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright (c) 2014-2019 FIT2CLOUD 飞致云&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.fit2cloud.com" rel="nofollow"&gt;https://www.fit2cloud.com&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;KubeOperator is licensed under the Apache License, Version 2.0.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>KubeOperator</author><guid isPermaLink="false">https://github.com/KubeOperator/KubeOperator</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>ageitgey/face_recognition #18 in Python, This week</title><link>https://github.com/ageitgey/face_recognition</link><description>&lt;p&gt;&lt;i&gt;The world's simplest facial recognition api for Python and the command line&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-face-recognition" class="anchor" aria-hidden="true" href="#face-recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Face Recognition&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;You can also read a translated version of this file &lt;a href="https://github.com/ageitgey/face_recognition/blob/master/README_Simplified_Chinese.md"&gt;in Chinese 简体中文版&lt;/a&gt; or &lt;a href="https://github.com/ageitgey/face_recognition/blob/master/README_Korean.md"&gt;in Korean 한국어&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Recognize and manipulate faces from Python or from the command line with
the world's simplest face recognition library.&lt;/p&gt;
&lt;p&gt;Built using &lt;a href="http://dlib.net/" rel="nofollow"&gt;dlib&lt;/a&gt;'s state-of-the-art face recognition
built with deep learning. The model has an accuracy of 99.38% on the
&lt;a href="http://vis-www.cs.umass.edu/lfw/" rel="nofollow"&gt;Labeled Faces in the Wild&lt;/a&gt; benchmark.&lt;/p&gt;
&lt;p&gt;This also provides a simple &lt;code&gt;face_recognition&lt;/code&gt; command line tool that lets
you do face recognition on a folder of images from the command line!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://pypi.python.org/pypi/face_recognition" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/b90732359d1ebc3af2493af54da46ce19145d14b/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f666163655f7265636f676e6974696f6e2e737667" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/face_recognition.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.org/ageitgey/face_recognition" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0a50211fff9fc1cd53666133a389a0b100e78239/68747470733a2f2f7472617669732d63692e6f72672f61676569746765792f666163655f7265636f676e6974696f6e2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/ageitgey/face_recognition.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://face-recognition.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e82fac09ba8a6a356d28ce74a3bf874790bc82b7/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f666163652d7265636f676e6974696f6e2f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/face-recognition/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-find-faces-in-pictures" class="anchor" aria-hidden="true" href="#find-faces-in-pictures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Find faces in pictures&lt;/h4&gt;
&lt;p&gt;Find all the faces that appear in a picture:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://cloud.githubusercontent.com/assets/896692/23625227/42c65360-025d-11e7-94ea-b12f28cb34b4.png"&gt;&lt;img src="https://cloud.githubusercontent.com/assets/896692/23625227/42c65360-025d-11e7-94ea-b12f28cb34b4.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; face_recognition
image &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.load_image_file(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;your_file.jpg&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
face_locations &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.face_locations(image)&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-find-and-manipulate-facial-features-in-pictures" class="anchor" aria-hidden="true" href="#find-and-manipulate-facial-features-in-pictures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Find and manipulate facial features in pictures&lt;/h4&gt;
&lt;p&gt;Get the locations and outlines of each person's eyes, nose, mouth and chin.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://cloud.githubusercontent.com/assets/896692/23625282/7f2d79dc-025d-11e7-8728-d8924596f8fa.png"&gt;&lt;img src="https://cloud.githubusercontent.com/assets/896692/23625282/7f2d79dc-025d-11e7-8728-d8924596f8fa.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; face_recognition
image &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.load_image_file(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;your_file.jpg&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
face_landmarks_list &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.face_landmarks(image)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finding facial features is super useful for lots of important stuff. But you can also use it for really stupid stuff
like applying &lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/digital_makeup.py"&gt;digital make-up&lt;/a&gt; (think 'Meitu'):&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://cloud.githubusercontent.com/assets/896692/23625283/80638760-025d-11e7-80a2-1d2779f7ccab.png"&gt;&lt;img src="https://cloud.githubusercontent.com/assets/896692/23625283/80638760-025d-11e7-80a2-1d2779f7ccab.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-identify-faces-in-pictures" class="anchor" aria-hidden="true" href="#identify-faces-in-pictures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Identify faces in pictures&lt;/h4&gt;
&lt;p&gt;Recognize who appears in each photo.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://cloud.githubusercontent.com/assets/896692/23625229/45e049b6-025d-11e7-89cc-8a71cf89e713.png"&gt;&lt;img src="https://cloud.githubusercontent.com/assets/896692/23625229/45e049b6-025d-11e7-89cc-8a71cf89e713.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; face_recognition
known_image &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.load_image_file(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;biden.jpg&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
unknown_image &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.load_image_file(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;unknown.jpg&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)

biden_encoding &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.face_encodings(known_image)[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
unknown_encoding &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.face_encodings(unknown_image)[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]

results &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.compare_faces([biden_encoding], unknown_encoding)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can even use this library with other Python libraries to do real-time face recognition:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://cloud.githubusercontent.com/assets/896692/24430398/36f0e3f0-13cb-11e7-8258-4d0c9ce1e419.gif"&gt;&lt;img src="https://cloud.githubusercontent.com/assets/896692/24430398/36f0e3f0-13cb-11e7-8258-4d0c9ce1e419.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam_faster.py"&gt;this example&lt;/a&gt; for the code.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-online-demos" class="anchor" aria-hidden="true" href="#online-demos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Online Demos&lt;/h2&gt;
&lt;p&gt;User-contributed shared Jupyter notebook demo (not officially supported): &lt;a href="https://beta.deepnote.org/launch?template=face_recognition" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0713c03de1d17e6bc2a9d78fedcc40415afcd517/68747470733a2f2f626574612e646565706e6f74652e6f72672f627574746f6e732f7472792d696e2d612d6a7570797465722d6e6f7465626f6f6b2e737667" alt="Deepnote" data-canonical-src="https://beta.deepnote.org/buttons/try-in-a-jupyter-notebook.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Python 3.3+ or Python 2.7&lt;/li&gt;
&lt;li&gt;macOS or Linux (Windows not officially supported, but might work)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-installation-options" class="anchor" aria-hidden="true" href="#installation-options"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation Options:&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-installing-on-mac-or-linux" class="anchor" aria-hidden="true" href="#installing-on-mac-or-linux"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing on Mac or Linux&lt;/h4&gt;
&lt;p&gt;First, make sure you have dlib already installed with Python bindings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/ageitgey/629d75c1baac34dfa5ca2a1928a7aeaf"&gt;How to install dlib from source on macOS or Ubuntu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then, install this module from pypi using &lt;code&gt;pip3&lt;/code&gt; (or &lt;code&gt;pip2&lt;/code&gt; for Python 2):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip3 install face_recognition&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Alternatively, you can try this library with &lt;a href="https://www.docker.com/" rel="nofollow"&gt;Docker&lt;/a&gt;, see &lt;a href="#deployment"&gt;this section&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are having trouble with installation, you can also try out a
&lt;a href="https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b" rel="nofollow"&gt;pre-configured VM&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-installing-on-an-nvidia-jetson-nano-board" class="anchor" aria-hidden="true" href="#installing-on-an-nvidia-jetson-nano-board"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing on an Nvidia Jetson Nano board&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://medium.com/@ageitgey/build-a-hardware-based-face-recognition-system-for-150-with-the-nvidia-jetson-nano-and-python-a25cb8c891fd" rel="nofollow"&gt;Jetson Nano installation instructions&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Please follow the instructions in the article carefully. There is current a bug in the CUDA libraries on the Jetson Nano that will cause this library to fail silently if you don't follow the instructions in the article to comment out a line in dlib and recompile it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-installing-on-raspberry-pi-2" class="anchor" aria-hidden="true" href="#installing-on-raspberry-pi-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing on Raspberry Pi 2+&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/ageitgey/1ac8dbe8572f3f533df6269dab35df65"&gt;Raspberry Pi 2+ installation instructions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-installing-on-windows" class="anchor" aria-hidden="true" href="#installing-on-windows"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing on Windows&lt;/h4&gt;
&lt;p&gt;While Windows isn't officially supported, helpful users have posted instructions on how to install this library:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/issues/175#issue-257710508"&gt;@masoudr's Windows 10 installation guide (dlib + face_recognition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-installing-a-pre-configured-virtual-machine-image" class="anchor" aria-hidden="true" href="#installing-a-pre-configured-virtual-machine-image"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing a pre-configured Virtual Machine image&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b" rel="nofollow"&gt;Download the pre-configured VM image&lt;/a&gt; (for VMware Player or VirtualBox).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-command-line-interface" class="anchor" aria-hidden="true" href="#command-line-interface"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Command-Line Interface&lt;/h3&gt;
&lt;p&gt;When you install &lt;code&gt;face_recognition&lt;/code&gt;, you get two simple command-line
programs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;face_recognition&lt;/code&gt; - Recognize faces in a photograph or folder full for
photographs.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;face_detection&lt;/code&gt; - Find faces in a photograph or folder full for photographs.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-face_recognition-command-line-tool" class="anchor" aria-hidden="true" href="#face_recognition-command-line-tool"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;face_recognition&lt;/code&gt; command line tool&lt;/h4&gt;
&lt;p&gt;The &lt;code&gt;face_recognition&lt;/code&gt; command lets you recognize faces in a photograph or
folder full  for photographs.&lt;/p&gt;
&lt;p&gt;First, you need to provide a folder with one picture of each person you
already know. There should be one image file for each person with the
files named according to who is in the picture:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://cloud.githubusercontent.com/assets/896692/23582466/8324810e-00df-11e7-82cf-41515eba704d.png"&gt;&lt;img src="https://cloud.githubusercontent.com/assets/896692/23582466/8324810e-00df-11e7-82cf-41515eba704d.png" alt="known" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Next, you need a second folder with the files you want to identify:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://cloud.githubusercontent.com/assets/896692/23582465/81f422f8-00df-11e7-8b0d-75364f641f58.png"&gt;&lt;img src="https://cloud.githubusercontent.com/assets/896692/23582465/81f422f8-00df-11e7-8b0d-75364f641f58.png" alt="unknown" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Then in you simply run the command &lt;code&gt;face_recognition&lt;/code&gt;, passing in
the folder of known people and the folder (or single image) with unknown
people and it tells you who is in each image:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/

/unknown_pictures/unknown.jpg,Barack Obama
/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There's one line in the output for each face. The data is comma-separated
with the filename and the name of the person found.&lt;/p&gt;
&lt;p&gt;An &lt;code&gt;unknown_person&lt;/code&gt; is a face in the image that didn't match anyone in
your folder of known people.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-face_detection-command-line-tool" class="anchor" aria-hidden="true" href="#face_detection-command-line-tool"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;face_detection&lt;/code&gt; command line tool&lt;/h4&gt;
&lt;p&gt;The &lt;code&gt;face_detection&lt;/code&gt; command lets you find the location (pixel coordinatates)
of any faces in an image.&lt;/p&gt;
&lt;p&gt;Just run the command &lt;code&gt;face_detection&lt;/code&gt;, passing in a folder of images
to check (or a single image):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ face_detection  ./folder_with_pictures/

examples/image1.jpg,65,215,169,112
examples/image2.jpg,62,394,211,244
examples/image2.jpg,95,941,244,792&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It prints one line for each face that was detected. The coordinates
reported are the top, right, bottom and left coordinates of the face (in pixels).&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-adjusting-tolerance--sensitivity" class="anchor" aria-hidden="true" href="#adjusting-tolerance--sensitivity"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Adjusting Tolerance / Sensitivity&lt;/h5&gt;
&lt;p&gt;If you are getting multiple matches for the same person, it might be that
the people in your photos look very similar and a lower tolerance value
is needed to make face comparisons more strict.&lt;/p&gt;
&lt;p&gt;You can do that with the &lt;code&gt;--tolerance&lt;/code&gt; parameter. The default tolerance
value is 0.6 and lower numbers make face comparisons more strict:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ face_recognition --tolerance 0.54 ./pictures_of_people_i_know/ ./unknown_pictures/

/unknown_pictures/unknown.jpg,Barack Obama
/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you want to see the face distance calculated for each match in order
to adjust the tolerance setting, you can use &lt;code&gt;--show-distance true&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ face_recognition --show-distance &lt;span class="pl-c1"&gt;true&lt;/span&gt; ./pictures_of_people_i_know/ ./unknown_pictures/

/unknown_pictures/unknown.jpg,Barack Obama,0.378542298956785
/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person,None&lt;/pre&gt;&lt;/div&gt;
&lt;h5&gt;&lt;a id="user-content-more-examples" class="anchor" aria-hidden="true" href="#more-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More Examples&lt;/h5&gt;
&lt;p&gt;If you simply want to know the names of the people in each photograph but don't
care about file names, you could do this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/ &lt;span class="pl-k"&gt;|&lt;/span&gt; cut -d &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;,&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; -f2

Barack Obama
unknown_person&lt;/pre&gt;&lt;/div&gt;
&lt;h5&gt;&lt;a id="user-content-speeding-up-face-recognition" class="anchor" aria-hidden="true" href="#speeding-up-face-recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speeding up Face Recognition&lt;/h5&gt;
&lt;p&gt;Face recognition can be done in parallel if you have a computer with
multiple CPU cores. For example, if your system has 4 CPU cores, you can
process about 4 times as many images in the same amount of time by using
all your CPU cores in parallel.&lt;/p&gt;
&lt;p&gt;If you are using Python 3.4 or newer, pass in a &lt;code&gt;--cpus &amp;lt;number_of_cpu_cores_to_use&amp;gt;&lt;/code&gt; parameter:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ face_recognition --cpus 4 ./pictures_of_people_i_know/ ./unknown_pictures/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can also pass in &lt;code&gt;--cpus -1&lt;/code&gt; to use all CPU cores in your system.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-python-module" class="anchor" aria-hidden="true" href="#python-module"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python Module&lt;/h4&gt;
&lt;p&gt;You can import the &lt;code&gt;face_recognition&lt;/code&gt; module and then easily manipulate
faces with just a couple of lines of code. It's super easy!&lt;/p&gt;
&lt;p&gt;API Docs: &lt;a href="https://face-recognition.readthedocs.io/en/latest/face_recognition.html" rel="nofollow"&gt;https://face-recognition.readthedocs.io&lt;/a&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-automatically-find-all-the-faces-in-an-image" class="anchor" aria-hidden="true" href="#automatically-find-all-the-faces-in-an-image"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Automatically find all the faces in an image&lt;/h5&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; face_recognition

image &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.load_image_file(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;my_picture.jpg&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
face_locations &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.face_locations(image)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; face_locations is now an array listing the co-ordinates of each face!&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See &lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture.py"&gt;this example&lt;/a&gt;
to try it out.&lt;/p&gt;
&lt;p&gt;You can also opt-in to a somewhat more accurate deep-learning-based face detection model.&lt;/p&gt;
&lt;p&gt;Note: GPU acceleration (via NVidia's CUDA library) is required for good
performance with this model. You'll also want to enable CUDA support
when compliling &lt;code&gt;dlib&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; face_recognition

image &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.load_image_file(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;my_picture.jpg&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
face_locations &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.face_locations(image, &lt;span class="pl-v"&gt;model&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;cnn&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; face_locations is now an array listing the co-ordinates of each face!&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See &lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture_cnn.py"&gt;this example&lt;/a&gt;
to try it out.&lt;/p&gt;
&lt;p&gt;If you have a lot of images and a GPU, you can also
&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_batches.py"&gt;find faces in batches&lt;/a&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-automatically-locate-the-facial-features-of-a-person-in-an-image" class="anchor" aria-hidden="true" href="#automatically-locate-the-facial-features-of-a-person-in-an-image"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Automatically locate the facial features of a person in an image&lt;/h5&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; face_recognition

image &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.load_image_file(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;my_picture.jpg&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
face_landmarks_list &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.face_landmarks(image)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; face_landmarks_list is now an array with the locations of each facial feature in each face.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; face_landmarks_list[0]['left_eye'] would be the location and outline of the first person's left eye.&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See &lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/find_facial_features_in_picture.py"&gt;this example&lt;/a&gt;
to try it out.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-recognize-faces-in-images-and-identify-who-they-are" class="anchor" aria-hidden="true" href="#recognize-faces-in-images-and-identify-who-they-are"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Recognize faces in images and identify who they are&lt;/h5&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; face_recognition

picture_of_me &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.load_image_file(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;me.jpg&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
my_face_encoding &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.face_encodings(picture_of_me)[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; my_face_encoding now contains a universal 'encoding' of my facial features that can be compared to any other picture of a face!&lt;/span&gt;

unknown_picture &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.load_image_file(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;unknown.jpg&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
unknown_face_encoding &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.face_encodings(unknown_picture)[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Now we can see the two face encodings are of the same person with `compare_faces`!&lt;/span&gt;

results &lt;span class="pl-k"&gt;=&lt;/span&gt; face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)

&lt;span class="pl-k"&gt;if&lt;/span&gt; results[&lt;span class="pl-c1"&gt;0&lt;/span&gt;] &lt;span class="pl-k"&gt;==&lt;/span&gt; &lt;span class="pl-c1"&gt;True&lt;/span&gt;:
    &lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;It's a picture of me!&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;else&lt;/span&gt;:
    &lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;It's not a picture of me!&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See &lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/recognize_faces_in_pictures.py"&gt;this example&lt;/a&gt;
to try it out.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-python-code-examples" class="anchor" aria-hidden="true" href="#python-code-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python Code Examples&lt;/h2&gt;
&lt;p&gt;All the examples are available &lt;a href="https://github.com/ageitgey/face_recognition/tree/master/examples"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-face-detection" class="anchor" aria-hidden="true" href="#face-detection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Face Detection&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture.py"&gt;Find faces in a photograph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture_cnn.py"&gt;Find faces in a photograph (using deep learning)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_batches.py"&gt;Find faces in batches of images w/ GPU (using deep learning)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/blur_faces_on_webcam.py"&gt;Blur all the faces in a live video using your webcam (Requires OpenCV to be installed)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-facial-features" class="anchor" aria-hidden="true" href="#facial-features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Facial Features&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/find_facial_features_in_picture.py"&gt;Identify specific facial features in a photograph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/digital_makeup.py"&gt;Apply (horribly ugly) digital make-up&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-facial-recognition" class="anchor" aria-hidden="true" href="#facial-recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Facial Recognition&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/recognize_faces_in_pictures.py"&gt;Find and recognize unknown faces in a photograph based on photographs of known people&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/identify_and_draw_boxes_on_faces.py"&gt;Identify and draw boxes around each person in a photo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/face_distance.py"&gt;Compare faces by numeric face distance instead of only True/False matches&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam.py"&gt;Recognize faces in live video using your webcam - Simple / Slower Version (Requires OpenCV to be installed)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam_faster.py"&gt;Recognize faces in live video using your webcam - Faster Version (Requires OpenCV to be installed)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_video_file.py"&gt;Recognize faces in a video file and write out new video file (Requires OpenCV to be installed)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_on_raspberry_pi.py"&gt;Recognize faces on a Raspberry Pi w/ camera&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/web_service_example.py"&gt;Run a web service to recognize faces via HTTP (Requires Flask to be installed)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/face_recognition_knn.py"&gt;Recognize faces with a K-nearest neighbors classifier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ageitgey/face_recognition/blob/master/examples/face_recognition_svm.py"&gt;Train multiple images per person then recognize faces using a SVM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-creating-a-standalone-executable" class="anchor" aria-hidden="true" href="#creating-a-standalone-executable"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Creating a Standalone Executable&lt;/h2&gt;
&lt;p&gt;If you want to create a standalone executable that can run without the need to install &lt;code&gt;python&lt;/code&gt; or &lt;code&gt;face_recognition&lt;/code&gt;, you can use &lt;a href="https://github.com/pyinstaller/pyinstaller"&gt;PyInstaller&lt;/a&gt;. However, it requires some custom configuration to work with this library. See &lt;a href="https://github.com/ageitgey/face_recognition/issues/357"&gt;this issue&lt;/a&gt; for how to do it.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-articles-and-guides-that-cover-face_recognition" class="anchor" aria-hidden="true" href="#articles-and-guides-that-cover-face_recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Articles and Guides that cover &lt;code&gt;face_recognition&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;My article on how Face Recognition works: &lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78" rel="nofollow"&gt;Modern Face Recognition with Deep Learning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Covers the algorithms and how they generally work&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.pyimagesearch.com/2018/06/18/face-recognition-with-opencv-python-and-deep-learning/" rel="nofollow"&gt;Face recognition with OpenCV, Python, and deep learning&lt;/a&gt; by Adrian Rosebrock
&lt;ul&gt;
&lt;li&gt;Covers how to use face recognition in practice&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.pyimagesearch.com/2018/06/25/raspberry-pi-face-recognition/" rel="nofollow"&gt;Raspberry Pi Face Recognition&lt;/a&gt; by Adrian Rosebrock
&lt;ul&gt;
&lt;li&gt;Covers how to use this on a Raspberry Pi&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.pyimagesearch.com/2018/07/09/face-clustering-with-python/" rel="nofollow"&gt;Face clustering with Python&lt;/a&gt; by Adrian Rosebrock
&lt;ul&gt;
&lt;li&gt;Covers how to automatically cluster photos based on who appears in each photo using unsupervised learning&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-how-face-recognition-works" class="anchor" aria-hidden="true" href="#how-face-recognition-works"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How Face Recognition Works&lt;/h2&gt;
&lt;p&gt;If you want to learn how face location and recognition work instead of
depending on a black box library, &lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78" rel="nofollow"&gt;read my article&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-caveats" class="anchor" aria-hidden="true" href="#caveats"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Caveats&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The face recognition model is trained on adults and does not work very well on children. It tends to mix
up children quite easy using the default comparison threshold of 0.6.&lt;/li&gt;
&lt;li&gt;Accuracy may vary between ethnic groups. Please see &lt;a href="https://github.com/ageitgey/face_recognition/wiki/Face-Recognition-Accuracy-Problems#question-face-recognition-works-well-with-european-individuals-but-overall-accuracy-is-lower-with-asian-individuals"&gt;this wiki page&lt;/a&gt; for more details.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-deployment-to-cloud-hosts-heroku-aws-etc" class="anchor" aria-hidden="true" href="#deployment-to-cloud-hosts-heroku-aws-etc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-deployment"&gt;Deployment to Cloud Hosts (Heroku, AWS, etc)&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Since &lt;code&gt;face_recognition&lt;/code&gt; depends on &lt;code&gt;dlib&lt;/code&gt; which is written in C++, it can be tricky to deploy an app
using it to a cloud hosting provider like Heroku or AWS.&lt;/p&gt;
&lt;p&gt;To make things easier, there's an example Dockerfile in this repo that shows how to run an app built with
&lt;code&gt;face_recognition&lt;/code&gt; in a &lt;a href="https://www.docker.com/" rel="nofollow"&gt;Docker&lt;/a&gt; container. With that, you should be able to deploy
to any service that supports Docker images.&lt;/p&gt;
&lt;p&gt;You can try the Docker image locally by running: &lt;code&gt;docker-compose up --build&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Linux users with a GPU (drivers &amp;gt;= 384.81) and &lt;a href="https://github.com/NVIDIA/nvidia-docker"&gt;Nvidia-Docker&lt;/a&gt; installed can run the example on the GPU: Open the &lt;a href="docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt; file and uncomment the &lt;code&gt;dockerfile: Dockerfile.gpu&lt;/code&gt; and &lt;code&gt;runtime: nvidia&lt;/code&gt; lines.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-having-problems" class="anchor" aria-hidden="true" href="#having-problems"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Having problems?&lt;/h2&gt;
&lt;p&gt;If you run into problems, please read the &lt;a href="https://github.com/ageitgey/face_recognition/wiki/Common-Errors"&gt;Common Errors&lt;/a&gt; section of the wiki before filing a github issue.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-thanks" class="anchor" aria-hidden="true" href="#thanks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Thanks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Many, many thanks to &lt;a href="https://github.com/davisking"&gt;Davis King&lt;/a&gt; (&lt;a href="https://twitter.com/nulhom" rel="nofollow"&gt;@nulhom&lt;/a&gt;)
for creating dlib and for providing the trained facial feature detection and face encoding models
used in this library. For more information on the ResNet that powers the face encodings, check out
his &lt;a href="http://blog.dlib.net/2017/02/high-quality-face-recognition-with-deep.html" rel="nofollow"&gt;blog post&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Thanks to everyone who works on all the awesome Python data science libraries like numpy, scipy, scikit-image,
pillow, etc, etc that makes this kind of stuff so easy and fun in Python.&lt;/li&gt;
&lt;li&gt;Thanks to &lt;a href="https://github.com/audreyr/cookiecutter"&gt;Cookiecutter&lt;/a&gt; and the
&lt;a href="https://github.com/audreyr/cookiecutter-pypackage"&gt;audreyr/cookiecutter-pypackage&lt;/a&gt; project template
for making Python project packaging way more tolerable.&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ageitgey</author><guid isPermaLink="false">https://github.com/ageitgey/face_recognition</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>sherlock-project/sherlock #19 in Python, This week</title><link>https://github.com/sherlock-project/sherlock</link><description>&lt;p&gt;&lt;i&gt;🔎 Find usernames across social networks&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/27065646/53551960-ae4dff80-3b3a-11e9-9075-cef786c69364.png"&gt;&lt;img src="https://user-images.githubusercontent.com/27065646/53551960-ae4dff80-3b3a-11e9-9075-cef786c69364.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;span&gt;Hunt down social media accounts by username across &lt;a href="https://github.com/theyahya/sherlock/blob/master/sites.md"&gt;social networks&lt;/a&gt;&lt;/span&gt;
  &lt;br&gt;
  &lt;a href="https://www.python.org/downloads/" title="Python version" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/392b343efc8b7ac39cdb7fd56d19a8ca6792c12b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d2533453d5f332e362d677265656e2e737667" data-canonical-src="https://img.shields.io/badge/python-%3E=_3.6-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a href="LICENSE" title="License: MIT"&gt;&lt;img src="https://camo.githubusercontent.com/311762166ef25238116d3cadd22fcb6091edab98/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d626c75652e737667" data-canonical-src="https://img.shields.io/badge/License-MIT-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a href="https://travis-ci.com/TheYahya/sherlock/" title="Build Status" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a93b7b21f175cd07941d299809dbda32764d2cff/68747470733a2f2f7472617669732d63692e636f6d2f54686559616879612f736865726c6f636b2e7376673f6272616e63683d6d6173746572" data-canonical-src="https://travis-ci.com/TheYahya/sherlock.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a href="https://twitter.com/intent/tweet?text=%F0%9F%94%8E%20Find%20usernames%20across%20social%20networks%20&amp;amp;url=https://github.com/TheYahya/sherlock&amp;amp;hashtags=hacking,%20osint,%20bugbounty,%20reconnaissance" title="Share on Tweeter" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/83d4084f7b71558e33b08844da5c773a8657e271/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f75726c2f687474702f736869656c64732e696f2e7376673f7374796c653d736f6369616c" data-canonical-src="https://img.shields.io/twitter/url/http/shields.io.svg?style=social" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a href="http://sherlock-project.github.io/" rel="nofollow"&gt;&lt;img alt="Website" src="https://camo.githubusercontent.com/adc37cc0993bd76eb6e4a6e661146251f8b663af/68747470733a2f2f696d672e736869656c64732e696f2f776562736974652d75702d646f776e2d677265656e2d7265642f687474702f736865726c6f636b2d70726f6a6563742e6769746875622e696f2f2e2e737667" data-canonical-src="https://img.shields.io/website-up-down-green-red/http/sherlock-project.github.io/..svg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a href="https://microbadger.com/images/theyahya/sherlock" rel="nofollow"&gt;&lt;img alt="docker image" src="https://camo.githubusercontent.com/7369ca4d589232865f5ff69b001ba2794474a285/68747470733a2f2f696d616765732e6d6963726f6261646765722e636f6d2f6261646765732f76657273696f6e2f74686579616879612f736865726c6f636b2e737667" data-canonical-src="https://images.microbadger.com/badges/version/theyahya/sherlock.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a href="#demo"&gt;Demo&lt;/a&gt;
     |   
  &lt;a href="#installation"&gt;Installation&lt;/a&gt;
     |   
  &lt;a href="#usage"&gt;Usage&lt;/a&gt;
     |   
  &lt;a href="#docker-notes"&gt;Docker Notes&lt;/a&gt;
     |   
  &lt;a href="#adding-new-sites"&gt;Adding New Sites&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
&lt;a href="https://asciinema.org/a/223115" rel="nofollow"&gt;
&lt;img src="./images/sherlock_preview.gif" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-demo" class="anchor" aria-hidden="true" href="#demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Demo&lt;/h2&gt;
&lt;p&gt;You can use this link to test Sherlock directly in your browser:
&lt;a href="https://elody.com/scenario/plan/16/" rel="nofollow"&gt;https://elody.com/scenario/plan/16/&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Python 3.6 or higher is required.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; clone the repo&lt;/span&gt;
$ git clone https://github.com/sherlock-project/sherlock.git

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; change the working directory to sherlock&lt;/span&gt;
$ &lt;span class="pl-c1"&gt;cd&lt;/span&gt; sherlock

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; install python3 and python3-pip if they are not installed&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; install the requirements&lt;/span&gt;
$ python3 -m pip install -r requirements.txt&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ python3 sherlock.py --help
usage: sherlock.py [-h] [--version] [--verbose] [--rank]
                   [--folderoutput FOLDEROUTPUT] [--output OUTPUT] [--tor]
                   [--unique-tor] [--csv] [--site SITE_NAME]
                   [--proxy PROXY_URL] [--json JSON_FILE]
                   [--proxy_list PROXY_LIST] [--check_proxies CHECK_PROXY]
                   [--print-found]
                   USERNAMES [USERNAMES ...]

Sherlock: Find Usernames Across Social Networks (Version 0.9.1)

positional arguments:
  USERNAMES             One or more usernames to check with social networks.

optional arguments:
  -h, --help            show this &lt;span class="pl-c1"&gt;help&lt;/span&gt; message and &lt;span class="pl-c1"&gt;exit&lt;/span&gt;
  --version             Display version information and dependencies.
  --verbose, -v, -d, --debug
                        Display extra debugging information and metrics.
  --rank, -r            Present websites ordered by their Alexa.com global
                        rank &lt;span class="pl-k"&gt;in&lt;/span&gt; popularity.
  --folderoutput FOLDEROUTPUT, -fo FOLDEROUTPUT
                        If using multiple usernames, the output of the results
                        will be saved at this folder.
  --output OUTPUT, -o OUTPUT
                        If using single username, the output of the result
                        will be saved at this file.
  --tor, -t             Make requests over Tor&lt;span class="pl-k"&gt;;&lt;/span&gt; increases runtime&lt;span class="pl-k"&gt;;&lt;/span&gt; requires
                        Tor to be installed and &lt;span class="pl-k"&gt;in&lt;/span&gt; system path.
  --unique-tor, -u      Make requests over Tor with new Tor circuit after each
                        request&lt;span class="pl-k"&gt;;&lt;/span&gt; increases runtime&lt;span class="pl-k"&gt;;&lt;/span&gt; requires Tor to be
                        installed and &lt;span class="pl-k"&gt;in&lt;/span&gt; system path.
  --csv                 Create Comma-Separated Values (CSV) File.
  --site SITE_NAME      Limit analysis to just the listed sites. Add multiple
                        options to specify more than one site.
  --proxy PROXY_URL, -p PROXY_URL
                        Make requests over a proxy. e.g.
                        socks5://127.0.0.1:1080
  --json JSON_FILE, -j JSON_FILE
                        Load data from a JSON file or an online, valid, JSON
                        file.
  --proxy_list PROXY_LIST, -pl PROXY_LIST
                        Make requests over a proxy randomly chosen from a list
                        generated from a .csv file.
  --check_proxies CHECK_PROXY, -cp CHECK_PROXY
                        To be used with the &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;--proxy_list&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; parameter. The
                        script will check &lt;span class="pl-k"&gt;if&lt;/span&gt; the proxies supplied &lt;span class="pl-k"&gt;in&lt;/span&gt; the .csv
                        file are working and anonymous.Put 0 &lt;span class="pl-k"&gt;for&lt;/span&gt; no limit on
                        successfully checked proxies, or another number to
                        institute a limit.
  --print-found         Do not output sites where the username was not found.
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For example to search for only one user:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python3 sherlock.py user123
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To search for more than one user:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python3 sherlock.py user1 user2 user3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All of the accounts found will be stored in an individual text file with the corresponding username (e.g &lt;code&gt;user123.txt&lt;/code&gt;).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-docker-notes" class="anchor" aria-hidden="true" href="#docker-notes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker Notes&lt;/h2&gt;
&lt;p&gt;If you have docker installed you can build an image and run this as a container.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker build -t mysherlock-image .
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the image is built, sherlock can be invoked by running the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run --rm -t mysherlock-image user123
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The optional &lt;code&gt;--rm&lt;/code&gt; flag removes the container filesystem on completion to prevent cruft build-up. See: &lt;a href="https://docs.docker.com/engine/reference/run/#clean-up---rm" rel="nofollow"&gt;https://docs.docker.com/engine/reference/run/#clean-up---rm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The optional &lt;code&gt;-t&lt;/code&gt; flag allocates a pseudo-TTY which allows colored output. See: &lt;a href="https://docs.docker.com/engine/reference/run/#foreground" rel="nofollow"&gt;https://docs.docker.com/engine/reference/run/#foreground&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It is possible to use the following command to access the saved results:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run --rm -t -v "$PWD/results:/opt/sherlock/results" mysherlock-image -o /opt/sherlock/results/text.txt user123
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;-v "$PWD/results:/opt/sherlock/results"&lt;/code&gt; option tells docker to create (or use) the folder &lt;code&gt;results&lt;/code&gt; in the
present working directory and to mount it at &lt;code&gt;/opt/sherlock/results&lt;/code&gt; on the docker container.
The &lt;code&gt;-o /opt/sherlock/results/text.txt&lt;/code&gt; option tells &lt;code&gt;sherlock&lt;/code&gt; to output the result.&lt;/p&gt;
&lt;p&gt;Or you can simply use "Docker Hub" to run &lt;code&gt;sherlock&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run theyahya/sherlock user123
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-using-docker-compose" class="anchor" aria-hidden="true" href="#using-docker-compose"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using &lt;code&gt;docker-compose&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;You can also use the &lt;code&gt;docker-compose.yml&lt;/code&gt; file from the repository and use this command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-compose run sherlok -o /opt/sherlock/results/text.txt user123
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-adding-new-sites" class="anchor" aria-hidden="true" href="#adding-new-sites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Adding New Sites&lt;/h2&gt;
&lt;p&gt;Please look at the Wiki entry on
&lt;a href="https://github.com/TheYahya/sherlock/wiki/Adding-Sites-To-Sherlock"&gt;adding new sites&lt;/a&gt;
to understand the issues.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Sherlock is not accepting adult sites in the standard list.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tests" class="anchor" aria-hidden="true" href="#tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tests&lt;/h2&gt;
&lt;p&gt;If you are contributing to Sherlock, then Thank You!&lt;/p&gt;
&lt;p&gt;Before creating a pull request with new development, please run the tests
to ensure that everything is working great.  It would also be a good idea to run the tests
before starting development to distinguish problems between your
environment and the Sherlock software.&lt;/p&gt;
&lt;p&gt;The following is an example of the command line to run all the tests for
Sherlock.  This invocation hides the progress text that Sherlock normally
outputs, and instead shows the verbose output of the tests.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 -m unittest tests.all --buffer --verbose
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that we do currently have 100% test coverage.  Unfortunately, some of
the sites that Sherlock checks are not always reliable, so it is common
to get response errors.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-stargazers-over-time" class="anchor" aria-hidden="true" href="#stargazers-over-time"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stargazers over time&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://starcharts.herokuapp.com/TheYahya/sherlock" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9a700fddd7ae13c41a23e7ebd1b5eaa40a1bb549/68747470733a2f2f737461726368617274732e6865726f6b756170702e636f6d2f54686559616879612f736865726c6f636b2e737667" alt="Stargazers over time" data-canonical-src="https://starcharts.herokuapp.com/TheYahya/sherlock.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;MIT © &lt;a href="https://theyahya.com" rel="nofollow"&gt;Yahya SayadArbabi&lt;/a&gt;&lt;br&gt;
Original Creator - &lt;a href="https://github.com/sdushantha"&gt;Siddharth Dushantha&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>sherlock-project</author><guid isPermaLink="false">https://github.com/sherlock-project/sherlock</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>getsentry/sentry #20 in Python, This week</title><link>https://github.com/getsentry/sentry</link><description>&lt;p&gt;&lt;i&gt;Sentry is cross-platform application monitoring, with a focus on error reporting.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body rst" data-path="README.rst"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
  &lt;/p&gt;&lt;p align="center"&gt;
    &lt;a href="https://sentry.io/?utm_source=github&amp;amp;utm_medium=logo" rel="nofollow"&gt;
      &lt;img src="https://camo.githubusercontent.com/2dfeafbee0904d6df16ddf7200993dace1629e60/68747470733a2f2f73656e7472792d6272616e642e73746f726167652e676f6f676c65617069732e636f6d2f73656e7472792d6c6f676f2d626c61636b2e706e67" alt="Sentry" height="72" data-canonical-src="https://sentry-brand.storage.googleapis.com/sentry-logo-black.png" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/p&gt;
  &lt;p align="center"&gt;
    Users and logs provide clues. Sentry provides answers.
  &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;a name="user-content-what-s-sentry"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-whats-sentry" class="anchor" aria-hidden="true" href="#whats-sentry"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What's Sentry?&lt;/h2&gt;
&lt;p&gt;Sentry fundamentally is a service that helps you monitor and fix crashes in realtime.
The server is in Python, but it contains a full API for sending events from any
language, in any application.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/getsentry/sentry/raw/master/src/sentry/static/sentry/images/product/thumb-1.png"&gt;&lt;img src="https://github.com/getsentry/sentry/raw/master/src/sentry/static/sentry/images/product/thumb-1.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/getsentry/sentry/raw/master/src/sentry/static/sentry/images/product/thumb-2.png"&gt;&lt;img src="https://github.com/getsentry/sentry/raw/master/src/sentry/static/sentry/images/product/thumb-2.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/getsentry/sentry/raw/master/src/sentry/static/sentry/images/product/thumb-3.png"&gt;&lt;img src="https://github.com/getsentry/sentry/raw/master/src/sentry/static/sentry/images/product/thumb-3.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;&lt;a name="user-content-official-sentry-sdks"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-official-sentry-sdks" class="anchor" aria-hidden="true" href="#official-sentry-sdks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Official Sentry SDKs&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-javascript"&gt;JavaScript&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/react-native-sentry"&gt;React-Native&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-python"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/raven-ruby"&gt;Ruby&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-php"&gt;PHP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-go"&gt;Go&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-java"&gt;Java&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-cocoa"&gt;Objective-C/Swift&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-dotnet"&gt;C#&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/perl-raven"&gt;Perl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-elixir"&gt;Elixir&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-laravel"&gt;Laravel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-resources"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.sentry.io/" rel="nofollow"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://forum.sentry.io/" rel="nofollow"&gt;Community&lt;/a&gt; (Bugs, feature requests, general questions)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.sentry.io/internal/contributing/" rel="nofollow"&gt;Contributing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/sentry/issues"&gt;Bug Tracker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/sentry"&gt;Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;IRC  (irc.freenode.net, #sentry)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.transifex.com/getsentry/sentry/" rel="nofollow"&gt;Transifex&lt;/a&gt; (Translate Sentry!)&lt;/li&gt;
&lt;/ul&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>getsentry</author><guid isPermaLink="false">https://github.com/getsentry/sentry</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>cornellius-gp/gpytorch #21 in Python, This week</title><link>https://github.com/cornellius-gp/gpytorch</link><description>&lt;p&gt;&lt;i&gt;A highly efficient and modular implementation of Gaussian Processes in PyTorch&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-gpytorch-beta-release" class="anchor" aria-hidden="true" href="#gpytorch-beta-release"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GPyTorch (Beta Release)&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/cornellius-gp/gpytorch" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/086e31820ce909a5325c4529fb5f9ff12a2d4ae1/68747470733a2f2f7472617669732d63692e6f72672f636f726e656c6c6975732d67702f677079746f7263682e7376673f6272616e63683d6d6173746572" alt="Build status" data-canonical-src="https://travis-ci.org/cornellius-gp/gpytorch.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gpytorch.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0658d8fb97af292063f7b818705b541df283c035/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f677079746f7263682f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/gpytorch/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://forthebadge.com" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/eae52829d6125ed81803704fdbcb158c1160e528/68747470733a2f2f666f7274686562616467652e636f6d2f696d616765732f6261646765732f616765732d31322e737667" alt="forthebadge" data-canonical-src="https://forthebadge.com/images/badges/ages-12.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;News!&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Beta release is currently out! Note that it &lt;strong&gt;requires PyTorch &amp;gt;= 1.3&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;If you need to install the alpha release (we recommend you use the latest version though!), check out &lt;a href="https://github.com/cornellius-gp/gpytorch/tree/alpha"&gt;the alpha release&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GPyTorch is a Gaussian process library implemented using PyTorch. GPyTorch is designed for creating scalable, flexible, and modular Gaussian process models with ease.&lt;/p&gt;
&lt;p&gt;Internally, GPyTorch differs from many existing approaches to GP inference by performing all inference operations using modern numerical linear algebra techniques like preconditioned conjugate gradients. Implementing a scalable GP method is as simple as providing a matrix multiplication routine with the kernel matrix and its derivative via our &lt;code&gt;LazyTensor&lt;/code&gt; interface, or by composing many of our already existing &lt;code&gt;LazyTensors&lt;/code&gt;. This allows not only for easy implementation of popular scalable GP techniques, but often also for significantly improved utilization of GPU computing compared to solvers based on the Cholesky decomposition.&lt;/p&gt;
&lt;p&gt;GPyTorch provides (1) significant GPU acceleration (through MVM based inference); (2) state-of-the-art implementations of the latest algorithmic advances for scalability and flexibility (&lt;a href="http://proceedings.mlr.press/v37/wilson15.pdf" rel="nofollow"&gt;SKI/KISS-GP&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1711.03481" rel="nofollow"&gt;stochastic Lanczos expansions&lt;/a&gt;, &lt;a href="https://arxiv.org/pdf/1803.06058.pdf" rel="nofollow"&gt;LOVE&lt;/a&gt;, &lt;a href="https://arxiv.org/pdf/1802.08903.pdf" rel="nofollow"&gt;SKIP&lt;/a&gt;, &lt;a href="https://arxiv.org/pdf/1611.00336.pdf" rel="nofollow"&gt;stochastic variational&lt;/a&gt; &lt;a href="http://proceedings.mlr.press/v51/wilson16.pdf" rel="nofollow"&gt;deep kernel learning&lt;/a&gt;, ...); (3) easy integration with deep learning frameworks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-examples-and-tutorials" class="anchor" aria-hidden="true" href="#examples-and-tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples and Tutorials&lt;/h2&gt;
&lt;p&gt;See our numerous &lt;a href="http://github.com/cornellius-gp/gpytorch/blob/master/examples"&gt;&lt;strong&gt;examples and tutorials&lt;/strong&gt;&lt;/a&gt; on how to construct all sorts of models in GPyTorch. These example notebooks and a walk through of GPyTorch are also available at our &lt;strong&gt;ReadTheDocs page &lt;a href="https://gpytorch.readthedocs.io/en/latest/index.html" rel="nofollow"&gt;here&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Requirements&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python &amp;gt;= 3.6&lt;/li&gt;
&lt;li&gt;PyTorch &amp;gt;= 1.3&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;N.B.&lt;/strong&gt; GPyTorch will not run on PyTorch 0.4.1 or earlier versions.&lt;/p&gt;
&lt;p&gt;First make sure that you have PyTorch (`&amp;gt;= 1.3&lt;/p&gt;
&lt;p&gt;`) installed using the appropriate command from &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Then install GPyTorch using pip or conda:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install gpytorch
conda install gpytorch -c gpytorch&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To use packages globally but install GPyTorch as a user-only package, use &lt;code&gt;pip install --user&lt;/code&gt; above.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-latest-unstable-version" class="anchor" aria-hidden="true" href="#latest-unstable-version"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latest (unstable) version&lt;/h4&gt;
&lt;p&gt;To get the latest (unstable) version, run&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install git+https://github.com/cornellius-gp/gpytorch.git&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-citing-us" class="anchor" aria-hidden="true" href="#citing-us"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citing Us&lt;/h2&gt;
&lt;p&gt;If you use GPyTorch, please cite the following papers:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1809.11165" rel="nofollow"&gt;Gardner, Jacob R., Geoff Pleiss, David Bindel, Kilian Q. Weinberger, and Andrew Gordon Wilson. "GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration." In Advances in Neural Information Processing Systems (2018).&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;@inproceedings{gardner2018gpytorch,
  title={GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration},
  author={Gardner, Jacob R and Pleiss, Geoff and Bindel, David and Weinberger, Kilian Q and Wilson, Andrew Gordon},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;For &lt;strong&gt;tutorials and examples&lt;/strong&gt;, check out &lt;a href="https://github.com/cornellius-gp/gpytorch/tree/master/examples"&gt;the examples folder&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For in-depth &lt;strong&gt;documentation&lt;/strong&gt;, check out our &lt;a href="http://gpytorch.readthedocs.io/" rel="nofollow"&gt;read the docs&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-development" class="anchor" aria-hidden="true" href="#development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development&lt;/h2&gt;
&lt;p&gt;To run the unit tests:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -m unittest&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By default, the random seeds are locked down for some of the tests.
If you want to run the tests without locking down the seed, run&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;UNLOCK_SEED=true python -m unittest&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Please lint the code with &lt;code&gt;flake8&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install flake8  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; if not already installed&lt;/span&gt;
flake8&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-the-team" class="anchor" aria-hidden="true" href="#the-team"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Team&lt;/h2&gt;
&lt;p&gt;GPyTorch is primarily maintained by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://github.com/jacobrgardner"&gt;Jake Gardner&lt;/a&gt; (Uber AI Labs)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://github.com/gpleiss"&gt;Geoff Pleiss&lt;/a&gt; (Cornell University)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://kilian.cs.cornell.edu/" rel="nofollow"&gt;Kilian Weinberger&lt;/a&gt; (Cornell University)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://people.orie.cornell.edu/andrew/" rel="nofollow"&gt;Andrew Gordon Wilson&lt;/a&gt; (Cornell University)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://research.fb.com/people/balandat-max/" rel="nofollow"&gt;Max Balandat&lt;/a&gt; (Facebook)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0c115437df284dad869f6254be0daf42d2d32d9a/68747470733a2f2f6272616e642e636f726e656c6c2e6564752f6173736574732f696d616765732f646f776e6c6f6164732f6c6f676f732f636f726e656c6c5f6c6f676f5f73696d706c652f636f726e656c6c5f6c6f676f5f73696d706c652e737667"&gt;&lt;img width="300" src="https://camo.githubusercontent.com/0c115437df284dad869f6254be0daf42d2d32d9a/68747470733a2f2f6272616e642e636f726e656c6c2e6564752f6173736574732f696d616765732f646f776e6c6f6164732f6c6f676f732f636f726e656c6c5f6c6f676f5f73696d706c652f636f726e656c6c5f6c6f676f5f73696d706c652e737667" alt="Cornell Logo" data-canonical-src="https://brand.cornell.edu/assets/images/downloads/logos/cornell_logo_simple/cornell_logo_simple.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/cornellius-gp/cornellius-gp.github.io/master/static/media/facebook_logo.2835357a.png"&gt;&lt;img width="300" src="https://raw.githubusercontent.com/cornellius-gp/cornellius-gp.github.io/master/static/media/facebook_logo.2835357a.png" alt="Facebook Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/13804bb567d948c1bd440eed09f5ee28ff8cd6c9/68747470733a2f2f677079746f7263682e61692f7374617469632f6d656469612f756265725f61695f686f72697a6f6e74616c2e66653961623635332e706e67"&gt;&lt;img width="300" src="https://camo.githubusercontent.com/13804bb567d948c1bd440eed09f5ee28ff8cd6c9/68747470733a2f2f677079746f7263682e61692f7374617469632f6d656469612f756265725f61695f686f72697a6f6e74616c2e66653961623635332e706e67" alt="Uber AI Logo" data-canonical-src="https://gpytorch.ai/static/media/uber_ai_horizontal.fe9ab653.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
We would like to thank our other contributors including (but not limited to)  David Arbour, Eytan Bakshy, David Eriksson, Jared Frank, Sam Stanton, Bram Wallace, Ke Alexander Wang, Ruihan Wu.
&lt;h2&gt;&lt;a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;Development of GPyTorch is supported by funding from the &lt;a href="https://www.gatesfoundation.org/" rel="nofollow"&gt;Bill and Melinda Gates Foundation&lt;/a&gt;, the &lt;a href="https://www.nsf.gov/" rel="nofollow"&gt;National Science Foundation&lt;/a&gt;, and &lt;a href="https://www.sap.com/index.html" rel="nofollow"&gt;SAP&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>cornellius-gp</author><guid isPermaLink="false">https://github.com/cornellius-gp/gpytorch</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>tensorflow/models #22 in Python, This week</title><link>https://github.com/tensorflow/models</link><description>&lt;p&gt;&lt;i&gt;Models and examples built with TensorFlow&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-models" class="anchor" aria-hidden="true" href="#tensorflow-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow Models&lt;/h1&gt;
&lt;p&gt;This repository contains a number of different models implemented in &lt;a href="https://www.tensorflow.org" rel="nofollow"&gt;TensorFlow&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;The &lt;a href="official"&gt;official models&lt;/a&gt; are a collection of example models that use TensorFlow's high-level APIs. They are intended to be well-maintained, tested, and kept up to date with the latest stable TensorFlow API. They should also be reasonably optimized for fast performance while still being easy to read. We especially recommend newer TensorFlow users to start here.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/tensorflow/models/tree/master/research"&gt;research models&lt;/a&gt; are a large collection of models implemented in TensorFlow by researchers. They are not officially supported or available in release branches; it is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.&lt;/p&gt;
&lt;p&gt;The &lt;a href="samples"&gt;samples folder&lt;/a&gt; contains code snippets and smaller models that demonstrate features of TensorFlow, including code presented in various blog posts.&lt;/p&gt;
&lt;p&gt;The &lt;a href="tutorials"&gt;tutorials folder&lt;/a&gt; is a collection of models described in the &lt;a href="https://www.tensorflow.org/tutorials/" rel="nofollow"&gt;TensorFlow tutorials&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-guidelines" class="anchor" aria-hidden="true" href="#contribution-guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution guidelines&lt;/h2&gt;
&lt;p&gt;If you want to contribute to models, be sure to review the &lt;a href="CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a href="LICENSE"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>tensorflow</author><guid isPermaLink="false">https://github.com/tensorflow/models</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>hanxiao/bert-as-service #23 in Python, This week</title><link>https://github.com/hanxiao/bert-as-service</link><description>&lt;p&gt;&lt;i&gt;Mapping a variable-length sentence to a fixed-length vector using BERT model&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1 align="center"&gt;&lt;a id="user-content-bert-as-service" class="anchor" aria-hidden="true" href="#bert-as-service"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;bert-as-service&lt;/h1&gt;
&lt;p align="center"&gt;Using BERT model as a sentence encoding service, i.e. mapping a variable-length sentence to a fixed-length vector.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a href="https://github.com/hanxiao/bert-as-service/stargazers"&gt;
    &lt;img src="https://camo.githubusercontent.com/827fc64cf3b84a82a3057b15bd67bd110c3f094f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616e7869616f2f626572742d61732d736572766963652e7376673f636f6c6f72413d6f72616e676526636f6c6f72423d6f72616e6765266c6f676f3d676974687562" alt="GitHub stars" data-canonical-src="https://img.shields.io/github/stars/hanxiao/bert-as-service.svg?colorA=orange&amp;amp;colorB=orange&amp;amp;logo=github" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://pypi.org/search/?q=bert-serving" rel="nofollow"&gt;
      &lt;img src="https://camo.githubusercontent.com/17c79028fcd99fcb6ffd09d9078a9e90ca72dabe/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f626572742d73657276696e672d7365727665722e7376673f636f6c6f72423d627269676874677265656e" alt="Pypi package" data-canonical-src="https://img.shields.io/pypi/v/bert-serving-server.svg?colorB=brightgreen" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;a href="https://bert-as-service.readthedocs.io/" rel="nofollow"&gt;
      &lt;img src="https://camo.githubusercontent.com/97f0af3aadd65722bd4510764170eb12e26c20a2/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f626572742d61732d736572766963652f62616467652f3f76657273696f6e3d6c6174657374" alt="ReadTheDoc" data-canonical-src="https://readthedocs.org/projects/bert-as-service/badge/?version=latest" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;a href="https://pypi.org/search/?q=bert-serving" rel="nofollow"&gt;
      &lt;img alt="PyPI - Downloads" src="https://camo.githubusercontent.com/f0c139454d4564bf4abdcf294e009d886e53e1f5/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f626572742d73657276696e672d736572766572" data-canonical-src="https://img.shields.io/pypi/dm/bert-serving-server" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://github.com/hanxiao/bert-as-service/issues"&gt;
        &lt;img src="https://camo.githubusercontent.com/37c917311b11a54f44462c0271a9e62fbd82dc03/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f68616e7869616f2f626572742d61732d736572766963652e737667" alt="GitHub issues" data-canonical-src="https://img.shields.io/github/issues/hanxiao/bert-as-service.svg" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://github.com/hanxiao/bert-as-service/blob/master/LICENSE"&gt;
        &lt;img src="https://camo.githubusercontent.com/82e75359cfc65c373073242222565e1d21cd5979/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f68616e7869616f2f626572742d61732d736572766963652e737667" alt="GitHub license" data-canonical-src="https://img.shields.io/github/license/hanxiao/bert-as-service.svg" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://twitter.com/intent/tweet?text=Wow:&amp;amp;url=https%3A%2F%2Fgithub.com%2Fhanxiao%2Fbert-as-service" rel="nofollow"&gt;
  &lt;img src="https://camo.githubusercontent.com/c03e98ee22b873659d1c89f929e35fc8eafbeada/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f75726c2f68747470732f6769746875622e636f6d2f68616e7869616f2f626572742d61732d736572766963652e7376673f7374796c653d736f6369616c" alt="Twitter" data-canonical-src="https://img.shields.io/twitter/url/https/github.com/hanxiao/bert-as-service.svg?style=social" style="max-width:100%;"&gt;
  &lt;/a&gt;      
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a href="#highlights"&gt;Highlights&lt;/a&gt; •
  &lt;a href="#what-is-it"&gt;What is it&lt;/a&gt; •
  &lt;a href="#install"&gt;Install&lt;/a&gt; •
  &lt;a href="#getting-started"&gt;Getting Started&lt;/a&gt; •
  &lt;a href="#server-and-client-api"&gt;API&lt;/a&gt; •
  &lt;a href="#book-tutorial"&gt;Tutorials&lt;/a&gt; •
  &lt;a href="#speech_balloon-faq"&gt;FAQ&lt;/a&gt; •
  &lt;a href="#zap-benchmark"&gt;Benchmark&lt;/a&gt; •
  &lt;a href="https://hanxiao.github.io/2019/01/02/Serving-Google-BERT-in-Production-using-Tensorflow-and-ZeroMQ/" rel="nofollow"&gt;Blog&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href=".github/demo.gif?raw=true"&gt;&lt;img src=".github/demo.gif?raw=true" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h6 align="center"&gt;&lt;a id="user-content-made-by-han-xiao--globe_with_meridians-httpshanxiaogithubio" class="anchor" aria-hidden="true" href="#made-by-han-xiao--globe_with_meridians-httpshanxiaogithubio"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Made by Han Xiao • &lt;g-emoji class="g-emoji" alias="globe_with_meridians" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f310.png"&gt;🌐&lt;/g-emoji&gt; &lt;a href="https://hanxiao.github.io" rel="nofollow"&gt;https://hanxiao.github.io&lt;/a&gt;&lt;/h6&gt;

&lt;table&gt;
  &lt;tbody&gt;&lt;tr&gt;
  &lt;td width="25%"&gt;&lt;a href="https://github.com/gnes-ai/gnes"&gt;
      &lt;img src=".github/gnes-logo-tight.svg" alt="GNES is Generic Neural Elastic Search (logo made by Han Xiao)" style="max-width:100%;"&gt;
      &lt;/a&gt;&lt;/td&gt;
  &lt;td&gt;
  &lt;b&gt;&lt;g-emoji class="g-emoji" alias="sparkles" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png"&gt;✨&lt;/g-emoji&gt;Looking for X-as-service? Or more generic and cloud-native solution?&lt;/b&gt;
  &lt;p&gt;&lt;br&gt;Checkout my new project &lt;a href="https://github.com/gnes-ai/gnes"&gt;GNES&lt;/a&gt;! GNES is Generic Neural Elastic Search, a cloud-native semantic search system based on deep neural network. GNES enables large-scale index and semantic search for text-to-text, image-to-image, video-to-video and any-to-any content form.&lt;/p&gt;
&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2 align="center"&gt;&lt;a id="user-content-what-is-it" class="anchor" aria-hidden="true" href="#what-is-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is it&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;BERT&lt;/strong&gt; is a NLP model &lt;a href="https://github.com/google-research/bert"&gt;developed by Google&lt;/a&gt; for pre-training language representations. It leverages an enormous amount of plain text data publicly available on the web and is trained in an unsupervised manner. Pre-training a BERT model is a fairly expensive yet one-time procedure for each language. Fortunately, Google released several pre-trained models where &lt;a href="https://github.com/google-research/bert#pre-trained-models"&gt;you can download from here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sentence Encoding/Embedding&lt;/strong&gt; is a upstream task required in many NLP applications, e.g. sentiment analysis, text classification. The goal is to represent a variable length sentence into a fixed length vector, e.g. &lt;code&gt;hello world&lt;/code&gt; to &lt;code&gt;[0.1, 0.3, 0.9]&lt;/code&gt;. Each element of the vector should "encode" some semantics of the original sentence.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Finally, &lt;code&gt;bert-as-service&lt;/code&gt;&lt;/strong&gt; uses BERT as a sentence encoder and hosts it as a service via ZeroMQ, allowing you to map sentences into fixed-length representations in just two lines of code.&lt;/p&gt;
&lt;h2 align="center"&gt;&lt;a id="user-content-highlights" class="anchor" aria-hidden="true" href="#highlights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Highlights&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="telescope" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52d.png"&gt;🔭&lt;/g-emoji&gt; &lt;strong&gt;State-of-the-art&lt;/strong&gt;: build on pretrained 12/24-layer BERT models released by Google AI, which is considered as a milestone in the NLP community.&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="hatching_chick" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f423.png"&gt;🐣&lt;/g-emoji&gt; &lt;strong&gt;Easy-to-use&lt;/strong&gt;: require only two lines of code to get sentence/token-level encodes.&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="zap" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a1.png"&gt;⚡️&lt;/g-emoji&gt; &lt;strong&gt;Fast&lt;/strong&gt;: 900 sentences/s on a single Tesla M40 24GB. Low latency, optimized for speed. See &lt;a href="#zap-benchmark"&gt;benchmark&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="octopus" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f419.png"&gt;🐙&lt;/g-emoji&gt; &lt;strong&gt;Scalable&lt;/strong&gt;: scale nicely and smoothly on multiple GPUs and multiple clients without worrying about concurrency. See &lt;a href="#speed-wrt-num_client"&gt;benchmark&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="gem" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f48e.png"&gt;💎&lt;/g-emoji&gt; &lt;strong&gt;Reliable&lt;/strong&gt;: tested on multi-billion sentences; days of running without a break or OOM or any nasty exceptions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More features: &lt;a href="#speed-wrt--fp16-and--xla"&gt;XLA &amp;amp; FP16 support&lt;/a&gt;; mix GPU-CPU workloads; optimized graph; &lt;code&gt;tf.data&lt;/code&gt; friendly; customized tokenizer; flexible pooling strategy; &lt;a href="#using-bert-as-service-to-serve-http-requests-in-json"&gt;build-in HTTP server&lt;/a&gt; and dashboard; &lt;a href="#asynchronous-encoding"&gt;async encoding&lt;/a&gt;; &lt;a href="#broadcasting-to-multiple-clients"&gt;multicasting&lt;/a&gt;; etc.&lt;/p&gt;
&lt;h2 align="center"&gt;&lt;a id="user-content-install" class="anchor" aria-hidden="true" href="#install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install&lt;/h2&gt;
&lt;p&gt;Install the server and client via &lt;code&gt;pip&lt;/code&gt;. They can be installed separately or even on &lt;em&gt;different&lt;/em&gt; machines:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install bert-serving-server  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; server&lt;/span&gt;
pip install bert-serving-client  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; client, independent of `bert-serving-server`&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that the server MUST be running on &lt;strong&gt;Python &amp;gt;= 3.5&lt;/strong&gt; with &lt;strong&gt;Tensorflow &amp;gt;= 1.10&lt;/strong&gt; (&lt;em&gt;one-point-ten&lt;/em&gt;). Again, the server does not support Python 2!&lt;/p&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="point_up" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/261d.png"&gt;☝️&lt;/g-emoji&gt; The client can be running on both Python 2 and 3 &lt;a href="#q-can-i-run-it-in-python-2"&gt;for the following consideration&lt;/a&gt;.&lt;/p&gt;
&lt;h2 align="center"&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-1-download-a-pre-trained-bert-model" class="anchor" aria-hidden="true" href="#1-download-a-pre-trained-bert-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Download a Pre-trained BERT Model&lt;/h4&gt;
&lt;p&gt;Download a model listed below, then uncompress the zip file into some folder, say &lt;code&gt;/tmp/english_L-12_H-768_A-12/&lt;/code&gt;&lt;/p&gt;
&lt;details&gt;
 &lt;summary&gt;List of released pretrained BERT models (click to expand...)&lt;/summary&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip" rel="nofollow"&gt;BERT-Base, Uncased&lt;/a&gt;&lt;/td&gt;&lt;td&gt;12-layer, 768-hidden, 12-heads, 110M parameters&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;BERT-Large, Uncased&lt;/a&gt;&lt;/td&gt;&lt;td&gt;24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip" rel="nofollow"&gt;BERT-Base, Cased&lt;/a&gt;&lt;/td&gt;&lt;td&gt;12-layer, 768-hidden, 12-heads , 110M parameters&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;BERT-Large, Cased&lt;/a&gt;&lt;/td&gt;&lt;td&gt;24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip" rel="nofollow"&gt;BERT-Base, Multilingual Cased (New)&lt;/a&gt;&lt;/td&gt;&lt;td&gt;104 languages, 12-layer, 768-hidden, 12-heads, 110M parameters&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/multilingual_L-12_H-768_A-12.zip" rel="nofollow"&gt;BERT-Base, Multilingual Cased (Old)&lt;/a&gt;&lt;/td&gt;&lt;td&gt;102 languages, 12-layer, 768-hidden, 12-heads, 110M parameters&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip" rel="nofollow"&gt;BERT-Base, Chinese&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M parameters&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/details&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Optional:&lt;/strong&gt; fine-tuning the model on your downstream task. &lt;a href="#q-are-you-suggesting-using-bert-without-fine-tuning"&gt;Why is it optional?&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-2-start-the-bert-service" class="anchor" aria-hidden="true" href="#2-start-the-bert-service"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Start the BERT service&lt;/h4&gt;
&lt;p&gt;After installing the server, you should be able to use &lt;code&gt;bert-serving-start&lt;/code&gt; CLI as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bert-serving-start -model_dir /tmp/english_L-12_H-768_A-12/ -num_worker=4 &lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will start a service with four workers, meaning that it can handle up to four &lt;strong&gt;concurrent&lt;/strong&gt; requests. More concurrent requests will be queued in a load balancer. Details can be found in our &lt;a href="#q-what-is-the-parallel-processing-model-behind-the-scene"&gt;FAQ&lt;/a&gt; and &lt;a href="#speed-wrt-num_client"&gt;the benchmark on number of clients&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Below shows what the server looks like when starting correctly:&lt;/p&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/server-demo.gif?raw=true"&gt;&lt;img src=".github/server-demo.gif?raw=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;details&gt;
 &lt;summary&gt;Alternatively, one can start the BERT Service in a Docker Container (click to expand...)&lt;/summary&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;docker build -t bert-as-service -f ./docker/Dockerfile &lt;span class="pl-c1"&gt;.&lt;/span&gt;
NUM_WORKER=1
PATH_MODEL=/PATH_TO/_YOUR_MODEL/
docker run --runtime nvidia -dit -p 5555:5555 -p 5556:5556 -v &lt;span class="pl-smi"&gt;$PATH_MODEL&lt;/span&gt;:/model -t bert-as-service &lt;span class="pl-smi"&gt;$NUM_WORKER&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/details&gt;
&lt;h4&gt;&lt;a id="user-content-3-use-client-to-get-sentence-encodes" class="anchor" aria-hidden="true" href="#3-use-client-to-get-sentence-encodes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. Use Client to Get Sentence Encodes&lt;/h4&gt;
&lt;p&gt;Now you can encode sentences simply as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; bert_serving.client &lt;span class="pl-k"&gt;import&lt;/span&gt; BertClient
bc &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient()
bc.encode([&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;First do it&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;then do it right&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;then do it better&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It will return a &lt;code&gt;ndarray&lt;/code&gt; (or &lt;code&gt;List[List[float]]&lt;/code&gt; if you wish), in which each row is a fixed-length vector representing a sentence. Having thousands of sentences? Just &lt;code&gt;encode&lt;/code&gt;! &lt;em&gt;Don't even bother to batch&lt;/em&gt;, the server will take care of it.&lt;/p&gt;
&lt;p&gt;As a feature of BERT, you may get encodes of a pair of sentences by concatenating them with &lt;code&gt;|||&lt;/code&gt; (with whitespace before and after), e.g.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;bc.encode([&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;First do it ||| then do it right&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Below shows what the server looks like while encoding:&lt;/p&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/server-run-demo.gif?raw=true"&gt;&lt;img src=".github/server-run-demo.gif?raw=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-use-bert-service-remotely" class="anchor" aria-hidden="true" href="#use-bert-service-remotely"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Use BERT Service Remotely&lt;/h4&gt;
&lt;p&gt;One may also start the service on one (GPU) machine and call it from another (CPU) machine as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; on another CPU machine&lt;/span&gt;
&lt;span class="pl-k"&gt;from&lt;/span&gt; bert_serving.client &lt;span class="pl-k"&gt;import&lt;/span&gt; BertClient
bc &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient(&lt;span class="pl-v"&gt;ip&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;xx.xx.xx.xx&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; ip address of the GPU machine&lt;/span&gt;
bc.encode([&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;First do it&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;then do it right&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;then do it better&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that you only need &lt;code&gt;pip install -U bert-serving-client&lt;/code&gt; in this case, the server side is not required. You may also &lt;a href="#using-bert-as-service-to-serve-http-requests-in-json"&gt;call the service via HTTP requests.&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="bulb" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a1.png"&gt;💡&lt;/g-emoji&gt; &lt;strong&gt;Want to learn more? Checkout our tutorials:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#building-a-qa-semantic-search-engine-in-3-minutes"&gt;Building a QA semantic search engine in 3 min.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#serving-a-fine-tuned-bert-model"&gt;Serving a fine-tuned BERT model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#getting-elmo-like-contextual-word-embedding"&gt;Getting ELMo-like contextual word embedding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-your-own-tokenizer"&gt;Using your own tokenizer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-bertclient-with-tfdata-api"&gt;Using &lt;code&gt;BertClient&lt;/code&gt; with &lt;code&gt;tf.data&lt;/code&gt; API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#training-a-text-classifier-using-bert-features-and-tfestimator-api"&gt;Training a text classifier using BERT features and tf.estimator API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#saving-and-loading-with-tfrecord-data"&gt;Saving and loading with TFRecord data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#asynchronous-encoding"&gt;Asynchronous encoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#broadcasting-to-multiple-clients"&gt;Broadcasting to multiple clients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#monitoring-the-service-status-in-a-dashboard"&gt;Monitoring the service status in a dashboard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-bert-as-service-to-serve-http-requests-in-json"&gt;Using &lt;code&gt;bert-as-service&lt;/code&gt; to serve HTTP requests in JSON&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#starting-bertserver-from-python"&gt;Starting &lt;code&gt;BertServer&lt;/code&gt; from Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 align="center"&gt;&lt;a id="user-content-server-and-client-api" class="anchor" aria-hidden="true" href="#server-and-client-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Server and Client API&lt;/h2&gt;
&lt;p align="right"&gt;&lt;a href="#bert-as-service"&gt;&lt;sup&gt;▴ Back to top&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://bert-as-service.readthedocs.io" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/95c38ab3eb5e58dcd9c3c931c7ef216fe77552d0/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f626572742d61732d736572766963652f62616467652f3f76657273696f6e3d6c6174657374267374796c653d666f722d7468652d6261646765" alt="ReadTheDoc" data-canonical-src="https://readthedocs.org/projects/bert-as-service/badge/?version=latest&amp;amp;style=for-the-badge" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The best way to learn &lt;code&gt;bert-as-service&lt;/code&gt; &lt;strong&gt;latest API&lt;/strong&gt; is &lt;a href="http://bert-as-service.readthedocs.io" rel="nofollow"&gt;reading the documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-server-api" class="anchor" aria-hidden="true" href="#server-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Server API&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://bert-as-service.readthedocs.io/en/latest/source/server.html#server-side-api" rel="nofollow"&gt;Please always refer to the latest server-side API documented here.&lt;/a&gt;, you may get the latest usage via:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bert-serving-start --help
bert-serving-terminate --help
bert-serving-benchmark --help&lt;/pre&gt;&lt;/div&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Argument&lt;/th&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;Default&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;model_dir&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;&lt;em&gt;Required&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;folder path of the pre-trained BERT model.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;tuned_model_dir&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;(Optional)&lt;/td&gt;
&lt;td&gt;folder path of a fine-tuned BERT model.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ckpt_name&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;&lt;code&gt;bert_model.ckpt&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;filename of the checkpoint file.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;config_name&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;&lt;code&gt;bert_config.json&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;filename of the JSON config file for BERT model.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;graph_tmp_dir&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;path to graph temp file&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;max_seq_len&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;&lt;code&gt;25&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;maximum length of sequence, longer sequence will be trimmed on the right side. Set it to NONE for dynamically using the longest sequence in a (mini)batch.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;cased_tokenization&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;False&lt;/td&gt;
&lt;td&gt;Whether tokenizer should skip the default lowercasing and accent removal. Should be used for e.g. the multilingual cased pretrained BERT model.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;mask_cls_sep&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;False&lt;/td&gt;
&lt;td&gt;masking the embedding on [CLS] and [SEP] with zero.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;num_worker&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;number of (GPU/CPU) worker runs BERT model, each works in a separate process.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;max_batch_size&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;&lt;code&gt;256&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;maximum number of sequences handled by each worker, larger batch will be partitioned into small batches.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;priority_batch_size&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;&lt;code&gt;16&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;batch smaller than this size will be labeled as high priority, and jumps forward in the job queue to get result faster&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;port&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;&lt;code&gt;5555&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;port for pushing data from client to server&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;port_out&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;&lt;code&gt;5556&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;port for publishing results from server to client&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;http_port&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;server port for receiving HTTP requests&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;cors&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;&lt;code&gt;*&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;setting "Access-Control-Allow-Origin" for HTTP requests&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;pooling_strategy&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;&lt;code&gt;REDUCE_MEAN&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;the pooling strategy for generating encoding vectors, valid values are &lt;code&gt;NONE&lt;/code&gt;, &lt;code&gt;REDUCE_MEAN&lt;/code&gt;, &lt;code&gt;REDUCE_MAX&lt;/code&gt;, &lt;code&gt;REDUCE_MEAN_MAX&lt;/code&gt;, &lt;code&gt;CLS_TOKEN&lt;/code&gt;, &lt;code&gt;FIRST_TOKEN&lt;/code&gt;, &lt;code&gt;SEP_TOKEN&lt;/code&gt;, &lt;code&gt;LAST_TOKEN&lt;/code&gt;. Explanation of these strategies &lt;a href="#q-what-are-the-available-pooling-strategies"&gt;can be found here&lt;/a&gt;. To get encoding for each token in the sequence, please set this to &lt;code&gt;NONE&lt;/code&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;pooling_layer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;list&lt;/td&gt;
&lt;td&gt;&lt;code&gt;[-2]&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;the encoding layer that pooling operates on, where &lt;code&gt;-1&lt;/code&gt; means the last layer, &lt;code&gt;-2&lt;/code&gt; means the second-to-last, &lt;code&gt;[-1, -2]&lt;/code&gt; means concatenating the result of last two layers, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;gpu_memory_fraction&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;float&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0.5&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;the fraction of the overall amount of memory that each GPU should be allocated per worker&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;cpu&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;False&lt;/td&gt;
&lt;td&gt;run on CPU instead of GPU&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;xla&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;False&lt;/td&gt;
&lt;td&gt;enable &lt;a href="https://www.tensorflow.org/xla/jit" rel="nofollow"&gt;XLA compiler&lt;/a&gt; for graph optimization (&lt;em&gt;experimental!&lt;/em&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;fp16&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;False&lt;/td&gt;
&lt;td&gt;use float16 precision (experimental)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;device_map&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;list&lt;/td&gt;
&lt;td&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;specify the list of GPU device ids that will be used (id starts from 0)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;show_tokens_to_client&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;False&lt;/td&gt;
&lt;td&gt;sending tokenization results to client&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-client-api" class="anchor" aria-hidden="true" href="#client-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Client API&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://bert-as-service.readthedocs.io/en/latest/source/client.html#module-client" rel="nofollow"&gt;Please always refer to the latest client-side API documented here.&lt;/a&gt; Client-side provides a Python class called &lt;code&gt;BertClient&lt;/code&gt;, which accepts arguments as follows:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Argument&lt;/th&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;Default&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ip&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;&lt;code&gt;localhost&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;IP address of the server&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;port&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;&lt;code&gt;5555&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;port for pushing data from client to server, &lt;em&gt;must be consistent with the server side config&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;port_out&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;&lt;code&gt;5556&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;port for publishing results from server to client, &lt;em&gt;must be consistent with the server side config&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;output_fmt&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ndarray&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;the output format of the sentence encodes, either in numpy array or python List[List[float]] (&lt;code&gt;ndarray&lt;/code&gt;/&lt;code&gt;list&lt;/code&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;show_server_config&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;whether to show server configs when first connected&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;check_version&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;whether to force client and server to have the same version&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;identity&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;a UUID that identifies the client, useful in multi-casting&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;timeout&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;&lt;code&gt;-1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;set the timeout (milliseconds) for receive operation on the client&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;A &lt;code&gt;BertClient&lt;/code&gt; implements the following methods and properties:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Method&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;.encode()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Encode a list of strings to a list of vectors&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;.encode_async()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Asynchronous encode batches from a generator&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;.fetch()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fetch all encoded vectors from server and return them in a generator, use it with &lt;code&gt;.encode_async()&lt;/code&gt; or &lt;code&gt;.encode(blocking=False)&lt;/code&gt;. Sending order is NOT preserved.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;.fetch_all()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fetch all encoded vectors from server and return them in a list, use it with &lt;code&gt;.encode_async()&lt;/code&gt; or &lt;code&gt;.encode(blocking=False)&lt;/code&gt;. Sending order is preserved.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;.close()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Gracefully close the connection between the client and the server&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;.status&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Get the client status in JSON format&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;.server_status&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Get the server status in JSON format&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 align="center"&gt;&lt;a id="user-content-book-tutorial" class="anchor" aria-hidden="true" href="#book-tutorial"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png"&gt;📖&lt;/g-emoji&gt; Tutorial&lt;/h2&gt;
&lt;p align="right"&gt;&lt;a href="#bert-as-service"&gt;&lt;sup&gt;▴ Back to top&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://bert-as-service.readthedocs.io/en/latest/section/faq.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/95c38ab3eb5e58dcd9c3c931c7ef216fe77552d0/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f626572742d61732d736572766963652f62616467652f3f76657273696f6e3d6c6174657374267374796c653d666f722d7468652d6261646765" alt="ReadTheDoc" data-canonical-src="https://readthedocs.org/projects/bert-as-service/badge/?version=latest&amp;amp;style=for-the-badge" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The full list of examples can be found in &lt;a href="example"&gt;&lt;code&gt;example/&lt;/code&gt;&lt;/a&gt;. You can run each via &lt;code&gt;python example/example-k.py&lt;/code&gt;. Most of examples require you to start a BertServer first, please follow &lt;a href="#2-start-the-bert-service"&gt;the instruction here&lt;/a&gt;. Note that although &lt;code&gt;BertClient&lt;/code&gt; works universally on both Python 2.x and 3.x, examples are only tested on Python 3.6.&lt;/p&gt;
&lt;details&gt;
 &lt;summary&gt;Table of contents (click to expand...)&lt;/summary&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#building-a-qa-semantic-search-engine-in-3-minutes"&gt;Building a QA semantic search engine in 3 min.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#serving-a-fine-tuned-bert-model"&gt;Serving a fine-tuned BERT model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#getting-elmo-like-contextual-word-embedding"&gt;Getting ELMo-like contextual word embedding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-your-own-tokenizer"&gt;Using your own tokenizer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-bertclient-with-tfdata-api"&gt;Using &lt;code&gt;BertClient&lt;/code&gt; with &lt;code&gt;tf.data&lt;/code&gt; API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#training-a-text-classifier-using-bert-features-and-tfestimator-api"&gt;Training a text classifier using BERT features and tf.estimator API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#saving-and-loading-with-tfrecord-data"&gt;Saving and loading with TFRecord data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#asynchronous-encoding"&gt;Asynchronous encoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#broadcasting-to-multiple-clients"&gt;Broadcasting to multiple clients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#monitoring-the-service-status-in-a-dashboard"&gt;Monitoring the service status in a dashboard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-bert-as-service-to-serve-http-requests-in-json"&gt;Using &lt;code&gt;bert-as-service&lt;/code&gt; to serve HTTP requests in JSON&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#starting-bertserver-from-python"&gt;Starting &lt;code&gt;BertServer&lt;/code&gt; from Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/details&gt;
&lt;h3&gt;&lt;a id="user-content-building-a-qa-semantic-search-engine-in-3-minutes" class="anchor" aria-hidden="true" href="#building-a-qa-semantic-search-engine-in-3-minutes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building a QA semantic search engine in 3 minutes&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;The complete example can &lt;a href="example/example8.py"&gt;be found example8.py&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As the first example, we will implement a simple QA search engine using &lt;code&gt;bert-as-service&lt;/code&gt; in just three minutes. No kidding! The goal is to find similar questions to user's input and return the corresponding answer. To start, we need a list of question-answer pairs. Fortunately, this README file already contains &lt;a href="#speech_balloon-faq"&gt;a list of FAQ&lt;/a&gt;, so I will just use that to make this example perfectly self-contained. Let's first load all questions and show some statistics.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;prefix_q &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;##### **Q:** &lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-c1"&gt;open&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;README.md&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-k"&gt;as&lt;/span&gt; fp:
    questions &lt;span class="pl-k"&gt;=&lt;/span&gt; [v.replace(prefix_q, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;).strip() &lt;span class="pl-k"&gt;for&lt;/span&gt; v &lt;span class="pl-k"&gt;in&lt;/span&gt; fp &lt;span class="pl-k"&gt;if&lt;/span&gt; v.strip() &lt;span class="pl-k"&gt;and&lt;/span&gt; v.startswith(prefix_q)]
    &lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-c1"&gt;%d&lt;/span&gt; questions loaded, avg. len of &lt;span class="pl-c1"&gt;%d&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%&lt;/span&gt; (&lt;span class="pl-c1"&gt;len&lt;/span&gt;(questions), np.mean([&lt;span class="pl-c1"&gt;len&lt;/span&gt;(d.split()) &lt;span class="pl-k"&gt;for&lt;/span&gt; d &lt;span class="pl-k"&gt;in&lt;/span&gt; questions])))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This gives &lt;code&gt;33 questions loaded, avg. len of 9&lt;/code&gt;. So looks like we have enough questions. Now start a BertServer with &lt;code&gt;uncased_L-12_H-768_A-12&lt;/code&gt; pretrained BERT model:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bert-serving-start -num_worker=1 -model_dir=/data/cips/data/lab/data/model/uncased_L-12_H-768_A-12&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, we need to encode our questions into vectors:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;bc &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient(&lt;span class="pl-v"&gt;port&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4000&lt;/span&gt;, &lt;span class="pl-v"&gt;port_out&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4001&lt;/span&gt;)
doc_vecs &lt;span class="pl-k"&gt;=&lt;/span&gt; bc.encode(questions)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, we are ready to receive new query and perform a simple "fuzzy" search against the existing questions. To do that, every time a new query is coming, we encode it as a vector and compute its dot product with &lt;code&gt;doc_vecs&lt;/code&gt;; sort the result descendingly; and return the top-k similar questions as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;while&lt;/span&gt; &lt;span class="pl-c1"&gt;True&lt;/span&gt;:
    query &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;input&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;your question: &lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
    query_vec &lt;span class="pl-k"&gt;=&lt;/span&gt; bc.encode([query])[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; compute normalized dot product as score&lt;/span&gt;
    score &lt;span class="pl-k"&gt;=&lt;/span&gt; np.sum(query_vec &lt;span class="pl-k"&gt;*&lt;/span&gt; doc_vecs, &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;) &lt;span class="pl-k"&gt;/&lt;/span&gt; np.linalg.norm(doc_vecs, &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;)
    topk_idx &lt;span class="pl-k"&gt;=&lt;/span&gt; np.argsort(score)[::&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;][:topk]
    &lt;span class="pl-k"&gt;for&lt;/span&gt; idx &lt;span class="pl-k"&gt;in&lt;/span&gt; topk_idx:
        &lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&amp;gt; &lt;span class="pl-c1"&gt;%s&lt;/span&gt;&lt;span class="pl-cce"&gt;\t&lt;/span&gt;&lt;span class="pl-c1"&gt;%s&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%&lt;/span&gt; (score[idx], questions[idx]))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That's it! Now run the code and type your query, see how this search engine handles fuzzy match:&lt;/p&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/qasearch-demo.gif?raw=true"&gt;&lt;img src=".github/qasearch-demo.gif?raw=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-serving-a-fine-tuned-bert-model" class="anchor" aria-hidden="true" href="#serving-a-fine-tuned-bert-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Serving a fine-tuned BERT model&lt;/h3&gt;
&lt;p&gt;Pretrained BERT models often show quite "okayish" performance on many tasks. However, to release the true power of BERT a fine-tuning on the downstream task (or on domain-specific data) is necessary. In this example, I will show you how to serve a fine-tuned BERT model.&lt;/p&gt;
&lt;p&gt;We follow the instruction in &lt;a href="https://github.com/google-research/bert#sentence-and-sentence-pair-classification-tasks"&gt;"Sentence (and sentence-pair) classification tasks"&lt;/a&gt; and use &lt;code&gt;run_classifier.py&lt;/code&gt; to fine tune &lt;code&gt;uncased_L-12_H-768_A-12&lt;/code&gt; model on MRPC task. The fine-tuned model is stored at &lt;code&gt;/tmp/mrpc_output/&lt;/code&gt;, which can be changed by specifying &lt;code&gt;--output_dir&lt;/code&gt; of &lt;code&gt;run_classifier.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you look into &lt;code&gt;/tmp/mrpc_output/&lt;/code&gt;, it contains something like:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;checkpoint                                        128
&lt;span class="pl-c1"&gt;eval&lt;/span&gt;                                              4.0K
eval_results.txt                                  86
eval.tf_record                                    219K
events.out.tfevents.1545202214.TENCENT64.site     6.1M
events.out.tfevents.1545203242.TENCENT64.site     14M
graph.pbtxt                                       9.0M
model.ckpt-0.data-00000-of-00001                  1.3G
model.ckpt-0.index                                23K
model.ckpt-0.meta                                 3.9M
model.ckpt-343.data-00000-of-00001                1.3G
model.ckpt-343.index                              23K
model.ckpt-343.meta                               3.9M
train.tf_record                                   2.0M&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Don't be afraid of those mysterious files, as the only important one to us is &lt;code&gt;model.ckpt-343.data-00000-of-00001&lt;/code&gt; (looks like my training stops at the 343 step. One may get &lt;code&gt;model.ckpt-123.data-00000-of-00001&lt;/code&gt; or &lt;code&gt;model.ckpt-9876.data-00000-of-00001&lt;/code&gt; depending on the total training steps). Now we have collected all three pieces of information that are needed for serving this fine-tuned model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The pretrained model is downloaded to &lt;code&gt;/path/to/bert/uncased_L-12_H-768_A-12&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Our fine-tuned model is stored at &lt;code&gt;/tmp/mrpc_output/&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;Our fine-tuned model checkpoint is named as &lt;code&gt;model.ckpt-343&lt;/code&gt; something something.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now start a BertServer by putting three pieces together:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bert-serving-start -model_dir=/pretrained/uncased_L-12_H-768_A-12 -tuned_model_dir=/tmp/mrpc_output/ -ckpt_name=model.ckpt-343&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After the server started, you should find this line in the log:&lt;/p&gt;
&lt;pre lang="text"&gt;&lt;code&gt;I:GRAPHOPT:[gra:opt: 50]:checkpoint (override by fine-tuned model): /tmp/mrpc_output/model.ckpt-343
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which means the BERT parameters is overrode and successfully loaded from our fine-tuned &lt;code&gt;/tmp/mrpc_output/model.ckpt-343&lt;/code&gt;. Done!&lt;/p&gt;
&lt;p&gt;In short, find your fine-tuned model path and checkpoint name, then feed them to &lt;code&gt;-tuned_model_dir&lt;/code&gt; and &lt;code&gt;-ckpt_name&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-getting-elmo-like-contextual-word-embedding" class="anchor" aria-hidden="true" href="#getting-elmo-like-contextual-word-embedding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting ELMo-like contextual word embedding&lt;/h3&gt;
&lt;p&gt;Start the server with &lt;code&gt;pooling_strategy&lt;/code&gt; set to NONE.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bert-serving-start -pooling_strategy NONE -model_dir /tmp/english_L-12_H-768_A-12/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To get the word embedding corresponds to every token, you can simply use slice index as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; max_seq_len = 25&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; pooling_strategy = NONE&lt;/span&gt;

bc &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient()
vec &lt;span class="pl-k"&gt;=&lt;/span&gt; bc.encode([&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;hey you&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;whats up?&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])

vec  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; [2, 25, 768]&lt;/span&gt;
vec[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; [1, 25, 768], sentence embeddings for `hey you`&lt;/span&gt;
vec[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;0&lt;/span&gt;]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; [1, 1, 768], word embedding for `[CLS]`&lt;/span&gt;
vec[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;1&lt;/span&gt;]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; [1, 1, 768], word embedding for `hey`&lt;/span&gt;
vec[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;2&lt;/span&gt;]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; [1, 1, 768], word embedding for `you`&lt;/span&gt;
vec[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;3&lt;/span&gt;]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; [1, 1, 768], word embedding for `[SEP]`&lt;/span&gt;
vec[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;4&lt;/span&gt;]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; [1, 1, 768], word embedding for padding symbol&lt;/span&gt;
vec[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;25&lt;/span&gt;]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; error, out of index!&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that no matter how long your original sequence is, the service will always return a &lt;code&gt;[max_seq_len, 768]&lt;/code&gt; matrix for every sequence. When using slice index to get the word embedding, beware of the special tokens padded to the sequence, i.e. &lt;code&gt;[CLS]&lt;/code&gt;, &lt;code&gt;[SEP]&lt;/code&gt;, &lt;code&gt;0_PAD&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-using-your-own-tokenizer" class="anchor" aria-hidden="true" href="#using-your-own-tokenizer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using your own tokenizer&lt;/h3&gt;
&lt;p&gt;Often you want to use your own tokenizer to segment sentences instead of the default one from BERT. Simply call &lt;code&gt;encode(is_tokenized=True)&lt;/code&gt; on the client slide as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;texts &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;hello world!&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;good day&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; a naive whitespace tokenizer&lt;/span&gt;
texts2 &lt;span class="pl-k"&gt;=&lt;/span&gt; [s.split() &lt;span class="pl-k"&gt;for&lt;/span&gt; s &lt;span class="pl-k"&gt;in&lt;/span&gt; texts]

vecs &lt;span class="pl-k"&gt;=&lt;/span&gt; bc.encode(texts2, &lt;span class="pl-v"&gt;is_tokenized&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This gives &lt;code&gt;[2, 25, 768]&lt;/code&gt; tensor where the first &lt;code&gt;[1, 25, 768]&lt;/code&gt; corresponds to the token-level encoding of "hello world!". If you look into its values, you will find that only the first four elements, i.e. &lt;code&gt;[1, 0:3, 768]&lt;/code&gt; have values, all the others are zeros. This is due to the fact that BERT considers "hello world!" as four tokens: &lt;code&gt;[CLS]&lt;/code&gt; &lt;code&gt;hello&lt;/code&gt; &lt;code&gt;world!&lt;/code&gt; &lt;code&gt;[SEP]&lt;/code&gt;, the rest are padding symbols and are masked out before output.&lt;/p&gt;
&lt;p&gt;Note that there is no need to start a separate server for handling tokenized/untokenized sentences. The server can tell and handle both cases automatically.&lt;/p&gt;
&lt;p&gt;Sometimes you want to know explicitly the tokenization performed on the server side to have better understanding of the embedding result. One such case is asking word embedding from the server (with &lt;code&gt;-pooling_strategy NONE&lt;/code&gt;), one wants to tell which word is tokenized and which is unrecognized. You can get such information with the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;enabling &lt;code&gt;-show_tokens_to_client&lt;/code&gt; on the server side;&lt;/li&gt;
&lt;li&gt;calling the server via &lt;code&gt;encode(..., show_tokens=True)&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For example, a basic usage like&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;bc.encode([&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;hello world!&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;thisis it&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], &lt;span class="pl-v"&gt;show_tokens&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;returns a tuple, where the first element is the embedding and the second is the tokenization result from the server:&lt;/p&gt;
&lt;pre lang="text"&gt;&lt;code&gt;(array([[[ 0.        , -0.        ,  0.        , ...,  0.        , -0.        , -0.        ],
        [ 1.1100919 , -0.20474958,  0.9895898 , ...,  0.3873255  , -1.4093989 , -0.47620595],
        ..., -0.        , -0.        ]],

       [[ 0.        , -0.        ,  0.        , ...,  0.        , 0.        ,  0.        ],
        [ 0.6293478 , -0.4088499 ,  0.6022662 , ...,  0.41740108, 1.214456  ,  1.2532915 ],
        ..., 0.        ,  0.        ]]], dtype=float32),
         
          [['[CLS]', 'hello', 'world', '!', '[SEP]'], ['[CLS]', 'this', '##is', 'it', '[SEP]']])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When using your own tokenization, you may still want to check if the server respects your tokens. For example,&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;bc.encode([[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;hello&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;world!&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;thisis&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;it&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]], &lt;span class="pl-v"&gt;show_tokens&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;, &lt;span class="pl-v"&gt;is_tokenized&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;returns:&lt;/p&gt;
&lt;pre lang="text"&gt;&lt;code&gt;(array([[[ 0.        , -0.        ,  0.        , ...,  0.       ,  -0.        ,  0.        ],
        [ 1.1111546 , -0.56572634,  0.37183186, ...,  0.02397121,  -0.5445367 ,  1.1009651 ],
        ..., -0.        ,  0.        ]],

       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,  -0.        ,  0.        ],
        [ 0.39262453,  0.3782491 ,  0.27096173, ...,  0.7122045 ,  -0.9874849 ,  0.9318679 ],
        ..., -0.        ,  0.        ]]], dtype=float32),
         
         [['[CLS]', 'hello', '[UNK]', '[SEP]'], ['[CLS]', '[UNK]', 'it', '[SEP]']])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One can observe that &lt;code&gt;world!&lt;/code&gt; and &lt;code&gt;thisis&lt;/code&gt; are not recognized on the server, hence they are set to &lt;code&gt;[UNK]&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Finally, beware that the pretrained BERT Chinese from Google is character-based, i.e. its vocabulary is made of single Chinese characters. Therefore it makes no sense if you use word-level segmentation algorithm to pre-process the data and feed to such model.&lt;/p&gt;
&lt;p&gt;Extremely curious readers may notice that the first row in the above example is all-zero even though the tokenization result includes &lt;code&gt;[CLS]&lt;/code&gt; (well done, detective!). The reason is that the tokenization result will &lt;strong&gt;always&lt;/strong&gt; includes &lt;code&gt;[CLS]&lt;/code&gt; and &lt;code&gt;[UNK]&lt;/code&gt; regardless the setting of &lt;code&gt;-mask_cls_sep&lt;/code&gt;. This could be useful when you want to align the tokens afterwards. Remember, &lt;code&gt;-mask_cls_sep&lt;/code&gt; only masks &lt;code&gt;[CLS]&lt;/code&gt; and &lt;code&gt;[SEP]&lt;/code&gt; out of the computation. It doesn't affect the tokenization algorithm.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-using-bertclient-with-tfdata-api" class="anchor" aria-hidden="true" href="#using-bertclient-with-tfdata-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using &lt;code&gt;BertClient&lt;/code&gt; with &lt;code&gt;tf.data&lt;/code&gt; API&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;The complete example can &lt;a href="example/example4.py"&gt;be found example4.py&lt;/a&gt;. There is also &lt;a href="https://github.com/hanxiao/bert-as-service/issues/29#issuecomment-442362241"&gt;an example in Keras&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The &lt;a href="https://www.tensorflow.org/guide/datasets" rel="nofollow"&gt;&lt;code&gt;tf.data&lt;/code&gt;&lt;/a&gt; API enables you to build complex input pipelines from simple, reusable pieces. One can also use &lt;code&gt;BertClient&lt;/code&gt; to encode sentences on-the-fly and use the vectors in a downstream model. Here is an example:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;batch_size &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;256&lt;/span&gt;
num_parallel_calls &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;4&lt;/span&gt;
num_clients &lt;span class="pl-k"&gt;=&lt;/span&gt; num_parallel_calls &lt;span class="pl-k"&gt;*&lt;/span&gt; &lt;span class="pl-c1"&gt;2&lt;/span&gt;  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; should be at least greater than `num_parallel_calls`&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; start a pool of clients&lt;/span&gt;
bc_clients &lt;span class="pl-k"&gt;=&lt;/span&gt; [BertClient(&lt;span class="pl-v"&gt;show_server_config&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;False&lt;/span&gt;) &lt;span class="pl-k"&gt;for&lt;/span&gt; _ &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(num_clients)]


&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;get_encodes&lt;/span&gt;(&lt;span class="pl-smi"&gt;x&lt;/span&gt;):
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; x is `batch_size` of lines, each of which is a json object&lt;/span&gt;
    samples &lt;span class="pl-k"&gt;=&lt;/span&gt; [json.loads(l) &lt;span class="pl-k"&gt;for&lt;/span&gt; l &lt;span class="pl-k"&gt;in&lt;/span&gt; x]
    text &lt;span class="pl-k"&gt;=&lt;/span&gt; [s[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;raw_text&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;] &lt;span class="pl-k"&gt;for&lt;/span&gt; s &lt;span class="pl-k"&gt;in&lt;/span&gt; samples]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; List[List[str]]&lt;/span&gt;
    labels &lt;span class="pl-k"&gt;=&lt;/span&gt; [s[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;label&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;] &lt;span class="pl-k"&gt;for&lt;/span&gt; s &lt;span class="pl-k"&gt;in&lt;/span&gt; samples]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; List[str]&lt;/span&gt;
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; get a client from available clients&lt;/span&gt;
    bc_client &lt;span class="pl-k"&gt;=&lt;/span&gt; bc_clients.pop()
    features &lt;span class="pl-k"&gt;=&lt;/span&gt; bc_client.encode(text)
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; after use, put it back&lt;/span&gt;
    bc_clients.append(bc_client)
    &lt;span class="pl-k"&gt;return&lt;/span&gt; features, labels


ds &lt;span class="pl-k"&gt;=&lt;/span&gt; (tf.data.TextLineDataset(train_fp).batch(batch_size)
        .map(&lt;span class="pl-k"&gt;lambda&lt;/span&gt; &lt;span class="pl-smi"&gt;x&lt;/span&gt;: tf.py_func(get_encodes, [x], [tf.float32, tf.string]),  &lt;span class="pl-v"&gt;num_parallel_calls&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;num_parallel_calls)
        .map(&lt;span class="pl-k"&gt;lambda&lt;/span&gt; &lt;span class="pl-smi"&gt;x&lt;/span&gt;, &lt;span class="pl-smi"&gt;y&lt;/span&gt;: {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;feature&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: x, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;label&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: y})
        .make_one_shot_iterator().get_next())&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The trick here is to start a pool of &lt;code&gt;BertClient&lt;/code&gt; and reuse them one by one. In this way, we can fully harness the power of &lt;code&gt;num_parallel_calls&lt;/code&gt; of &lt;code&gt;Dataset.map()&lt;/code&gt; API.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-training-a-text-classifier-using-bert-features-and-tfestimator-api" class="anchor" aria-hidden="true" href="#training-a-text-classifier-using-bert-features-and-tfestimator-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training a text classifier using BERT features and &lt;code&gt;tf.estimator&lt;/code&gt; API&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;The complete example can &lt;a href="example/example5.py"&gt;be found example5.py&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Following the last example, we can easily extend it to a full classifier using &lt;code&gt;tf.estimator&lt;/code&gt; API. One only need minor change on the input function as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;estimator &lt;span class="pl-k"&gt;=&lt;/span&gt; DNNClassifier(
    &lt;span class="pl-v"&gt;hidden_units&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-c1"&gt;512&lt;/span&gt;],
    &lt;span class="pl-v"&gt;feature_columns&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[tf.feature_column.numeric_column(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;feature&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;shape&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(&lt;span class="pl-c1"&gt;768&lt;/span&gt;,))],
    &lt;span class="pl-v"&gt;n_classes&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;len&lt;/span&gt;(laws),
    &lt;span class="pl-v"&gt;config&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;run_config,
    &lt;span class="pl-v"&gt;label_vocabulary&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;laws_str,
    &lt;span class="pl-v"&gt;dropout&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0.1&lt;/span&gt;)

input_fn &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;lambda&lt;/span&gt; &lt;span class="pl-smi"&gt;fp&lt;/span&gt;: (tf.data.TextLineDataset(fp)
                       .apply(tf.contrib.data.shuffle_and_repeat(&lt;span class="pl-v"&gt;buffer_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;10000&lt;/span&gt;))
                       .batch(batch_size)
                       .map(&lt;span class="pl-k"&gt;lambda&lt;/span&gt; &lt;span class="pl-smi"&gt;x&lt;/span&gt;: tf.py_func(get_encodes, [x], [tf.float32, tf.string]), &lt;span class="pl-v"&gt;num_parallel_calls&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;num_parallel_calls)
                       .map(&lt;span class="pl-k"&gt;lambda&lt;/span&gt; &lt;span class="pl-smi"&gt;x&lt;/span&gt;, &lt;span class="pl-smi"&gt;y&lt;/span&gt;: ({&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;feature&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: x}, y))
                       .prefetch(&lt;span class="pl-c1"&gt;20&lt;/span&gt;))

train_spec &lt;span class="pl-k"&gt;=&lt;/span&gt; TrainSpec(&lt;span class="pl-v"&gt;input_fn&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-k"&gt;lambda&lt;/span&gt;: input_fn(train_fp))
eval_spec &lt;span class="pl-k"&gt;=&lt;/span&gt; EvalSpec(&lt;span class="pl-v"&gt;input_fn&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-k"&gt;lambda&lt;/span&gt;: input_fn(eval_fp), &lt;span class="pl-v"&gt;throttle_secs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
train_and_evaluate(estimator, train_spec, eval_spec)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The complete example can &lt;a href="example/example5.py"&gt;be found example5.py&lt;/a&gt;, in which a simple MLP is built on BERT features for predicting the relevant articles according to the fact description in the law documents. The problem is a part of the &lt;a href="https://github.com/thunlp/CAIL/blob/master/README_en.md"&gt;Chinese AI and Law Challenge Competition&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-saving-and-loading-with-tfrecord-data" class="anchor" aria-hidden="true" href="#saving-and-loading-with-tfrecord-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Saving and loading with TFRecord data&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;The complete example can &lt;a href="example/example6.py"&gt;be found example6.py&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The TFRecord file format is a simple record-oriented binary format that many TensorFlow applications use for training data. You can also pre-encode all your sequences and store their encodings to a TFRecord file, then later load it to build a &lt;code&gt;tf.Dataset&lt;/code&gt;. For example, to write encoding into a TFRecord file:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;bc &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient()
list_vec &lt;span class="pl-k"&gt;=&lt;/span&gt; bc.encode(lst_str)
list_label &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-c1"&gt;0&lt;/span&gt; &lt;span class="pl-k"&gt;for&lt;/span&gt; _ &lt;span class="pl-k"&gt;in&lt;/span&gt; lst_str]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; a dummy list of all-zero labels&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; write to tfrecord&lt;/span&gt;
&lt;span class="pl-k"&gt;with&lt;/span&gt; tf.python_io.TFRecordWriter(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;tmp.tfrecord&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-k"&gt;as&lt;/span&gt; writer:
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;create_float_feature&lt;/span&gt;(&lt;span class="pl-smi"&gt;values&lt;/span&gt;):
        &lt;span class="pl-k"&gt;return&lt;/span&gt; tf.train.Feature(&lt;span class="pl-v"&gt;float_list&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;tf.train.FloatList(&lt;span class="pl-v"&gt;value&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;values))

    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;create_int_feature&lt;/span&gt;(&lt;span class="pl-smi"&gt;values&lt;/span&gt;):
        &lt;span class="pl-k"&gt;return&lt;/span&gt; tf.train.Feature(&lt;span class="pl-v"&gt;int64_list&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;tf.train.Int64List(&lt;span class="pl-v"&gt;value&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;list&lt;/span&gt;(values)))

    &lt;span class="pl-k"&gt;for&lt;/span&gt; (vec, label) &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;zip&lt;/span&gt;(list_vec, list_label):
        features &lt;span class="pl-k"&gt;=&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;features&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: create_float_feature(vec), &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;labels&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: create_int_feature([label])}
        tf_example &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.train.Example(&lt;span class="pl-v"&gt;features&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;tf.train.Features(&lt;span class="pl-v"&gt;feature&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;features))
        writer.write(tf_example.SerializeToString())&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we can load from it and build a &lt;code&gt;tf.Dataset&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;_decode_record&lt;/span&gt;(&lt;span class="pl-smi"&gt;record&lt;/span&gt;):
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"""&lt;/span&gt;Decodes a record to a TensorFlow example.&lt;span class="pl-pds"&gt;"""&lt;/span&gt;&lt;/span&gt;
    &lt;span class="pl-k"&gt;return&lt;/span&gt; tf.parse_single_example(record, {
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;features&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: tf.FixedLenFeature([&lt;span class="pl-c1"&gt;768&lt;/span&gt;], tf.float32),
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;labels&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: tf.FixedLenFeature([], tf.int64),
    })

ds &lt;span class="pl-k"&gt;=&lt;/span&gt; (tf.data.TFRecordDataset(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;tmp.tfrecord&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;).repeat().shuffle(&lt;span class="pl-v"&gt;buffer_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;).apply(
    tf.contrib.data.map_and_batch(&lt;span class="pl-k"&gt;lambda&lt;/span&gt; &lt;span class="pl-smi"&gt;record&lt;/span&gt;: _decode_record(record), &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;64&lt;/span&gt;))
      .make_one_shot_iterator().get_next())&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To save word/token-level embedding to TFRecord, one needs to first flatten &lt;code&gt;[max_seq_len, num_hidden]&lt;/code&gt; tensor into an 1D array as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;create_float_feature&lt;/span&gt;(&lt;span class="pl-smi"&gt;values&lt;/span&gt;):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; tf.train.Feature(&lt;span class="pl-v"&gt;float_list&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;tf.train.FloatList(&lt;span class="pl-v"&gt;value&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;values.reshape(&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;)))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And later reconstruct the shape when loading it:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;name_to_features &lt;span class="pl-k"&gt;=&lt;/span&gt; {
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;feature&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: tf.FixedLenFeature([max_seq_length &lt;span class="pl-k"&gt;*&lt;/span&gt; num_hidden], tf.float32),
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;label_ids&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: tf.FixedLenFeature([], tf.int64),
}
    
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;_decode_record&lt;/span&gt;(&lt;span class="pl-smi"&gt;record&lt;/span&gt;, &lt;span class="pl-smi"&gt;name_to_features&lt;/span&gt;):
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"""&lt;/span&gt;Decodes a record to a TensorFlow example.&lt;span class="pl-pds"&gt;"""&lt;/span&gt;&lt;/span&gt;
    example &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.parse_single_example(record, name_to_features)
    example[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;feature&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.reshape(example[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;feature&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], [max_seq_length, &lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;])
    &lt;span class="pl-k"&gt;return&lt;/span&gt; example&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Be careful, this will generate a huge TFRecord file.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-asynchronous-encoding" class="anchor" aria-hidden="true" href="#asynchronous-encoding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Asynchronous encoding&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;The complete example can &lt;a href="example/example2.py"&gt;be found example2.py&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;BertClient.encode()&lt;/code&gt; offers a nice synchronous way to get sentence encodes. However,   sometimes we want to do it in an asynchronous manner by feeding all textual data to the server first, fetching the encoded results later. This can be easily done by:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; an endless data stream, generating data in an extremely fast speed&lt;/span&gt;
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;text_gen&lt;/span&gt;():
    &lt;span class="pl-k"&gt;while&lt;/span&gt; &lt;span class="pl-c1"&gt;True&lt;/span&gt;:
        &lt;span class="pl-k"&gt;yield&lt;/span&gt; lst_str  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; yield a batch of text lines&lt;/span&gt;

bc &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient()

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; get encoded vectors&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; bc.encode_async(text_gen(), &lt;span class="pl-v"&gt;max_num_batch&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;10&lt;/span&gt;):
    &lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;received &lt;span class="pl-c1"&gt;%d&lt;/span&gt; x &lt;span class="pl-c1"&gt;%d&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%&lt;/span&gt; (j.shape[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], j.shape[&lt;span class="pl-c1"&gt;1&lt;/span&gt;]))&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-broadcasting-to-multiple-clients" class="anchor" aria-hidden="true" href="#broadcasting-to-multiple-clients"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Broadcasting to multiple clients&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;The complete example can &lt;a href="example/example3.py"&gt;be found in example3.py&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The encoded result is routed to the client according to its identity. If you have multiple clients with same identity, then they all receive the results! You can use this &lt;em&gt;multicast&lt;/em&gt; feature to do some cool things, e.g. training multiple different models (some using &lt;code&gt;scikit-learn&lt;/code&gt; some using &lt;code&gt;tensorflow&lt;/code&gt;) in multiple separated processes while only call &lt;code&gt;BertServer&lt;/code&gt; once. In the example below, &lt;code&gt;bc&lt;/code&gt; and its two clones will all receive encoded vector.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; clone a client by reusing the identity &lt;/span&gt;
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;client_clone&lt;/span&gt;(&lt;span class="pl-smi"&gt;id&lt;/span&gt;, &lt;span class="pl-smi"&gt;idx&lt;/span&gt;):
    bc &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient(&lt;span class="pl-v"&gt;identity&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;id&lt;/span&gt;)
    &lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; bc.listen():
        &lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;clone-client-&lt;span class="pl-c1"&gt;%d&lt;/span&gt;: received &lt;span class="pl-c1"&gt;%d&lt;/span&gt; x &lt;span class="pl-c1"&gt;%d&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%&lt;/span&gt; (idx, j.shape[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], j.shape[&lt;span class="pl-c1"&gt;1&lt;/span&gt;]))

bc &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient()
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; start two cloned clients sharing the same identity as bc&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;):
    threading.Thread(&lt;span class="pl-v"&gt;target&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;client_clone, &lt;span class="pl-v"&gt;args&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(bc.identity, j)).start()

&lt;span class="pl-k"&gt;for&lt;/span&gt; _ &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;3&lt;/span&gt;):
    bc.encode(lst_str)&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-monitoring-the-service-status-in-a-dashboard" class="anchor" aria-hidden="true" href="#monitoring-the-service-status-in-a-dashboard"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Monitoring the service status in a dashboard&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;The complete example can &lt;a href="plugin/dashboard"&gt;be found in plugin/dashboard/&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As a part of the infrastructure, one may also want to monitor the service status and show it in a dashboard. To do that, we can use:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;bc &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient(&lt;span class="pl-v"&gt;ip&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;server_ip&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

json.dumps(bc.server_status, &lt;span class="pl-v"&gt;ensure_ascii&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;False&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This gives the current status of the server including number of requests, number of clients etc. in JSON format. The only thing remained is to start a HTTP server for returning this JSON to the frontend that renders it.&lt;/p&gt;
&lt;p&gt;Alternatively, one may simply expose an HTTP port when starting a server via:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bert-serving-start -http_port 8001 -model_dir ...&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will allow one to use javascript or &lt;code&gt;curl&lt;/code&gt; to fetch the server status at port 8001.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;plugin/dashboard/index.html&lt;/code&gt; shows a simple dashboard based on Bootstrap and Vue.js.&lt;/p&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/dashboard.png?raw=true"&gt;&lt;img src=".github/dashboard.png?raw=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-using-bert-as-service-to-serve-http-requests-in-json" class="anchor" aria-hidden="true" href="#using-bert-as-service-to-serve-http-requests-in-json"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using &lt;code&gt;bert-as-service&lt;/code&gt; to serve HTTP requests in JSON&lt;/h3&gt;
&lt;p&gt;Besides calling &lt;code&gt;bert-as-service&lt;/code&gt; from Python, one can also call it via HTTP request in JSON. It is quite useful especially when low transport layer is prohibited. Behind the scene, &lt;code&gt;bert-as-service&lt;/code&gt; spawns a Flask server in a separate process and then reuse a &lt;code&gt;BertClient&lt;/code&gt; instance as a proxy to communicate with the ventilator.&lt;/p&gt;
&lt;p&gt;To enable the build-in HTTP server, we need to first (re)install the server with some extra Python dependencies:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install -U bert-serving-server[http]&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then simply start the server with:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bert-serving-start -model_dir=/YOUR_MODEL -http_port 8125&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Done! Your server is now listening HTTP and TCP requests at port &lt;code&gt;8125&lt;/code&gt; simultaneously!&lt;/p&gt;
&lt;p&gt;To send a HTTP request, first prepare the payload in JSON as following:&lt;/p&gt;
&lt;div class="highlight highlight-source-json"&gt;&lt;pre&gt;{
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;123&lt;/span&gt;,
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;texts&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;hello world&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;good day!&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;],
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;is_tokenized&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;false&lt;/span&gt;
}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;, where &lt;code&gt;id&lt;/code&gt; is a unique identifier helping you to synchronize the results; &lt;code&gt;is_tokenized&lt;/code&gt; follows the meaning in &lt;a href="https://bert-as-service.readthedocs.io/en/latest/source/client.html#client.BertClient.encode_async" rel="nofollow"&gt;&lt;code&gt;BertClient&lt;/code&gt; API&lt;/a&gt; and &lt;code&gt;false&lt;/code&gt; by default.&lt;/p&gt;
&lt;p&gt;Then simply call the server at &lt;code&gt;/encode&lt;/code&gt; via HTTP POST request. You can use javascript or whatever, here is an example using &lt;code&gt;curl&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;curl -X POST http://xx.xx.xx.xx:8125/encode \
  -H &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;content-type: application/json&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; \
  -d &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;{"id": 123,"texts": ["hello world"], "is_tokenized": false}&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;, which returns a JSON:&lt;/p&gt;
&lt;div class="highlight highlight-source-json"&gt;&lt;pre&gt;{
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;123&lt;/span&gt;,
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;results&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: [[&lt;span class="pl-c1"&gt;768&lt;/span&gt; &lt;span class="pl-ii"&gt;float-list&lt;/span&gt;], [&lt;span class="pl-c1"&gt;768&lt;/span&gt; &lt;span class="pl-ii"&gt;float-list&lt;/span&gt;]],
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;status&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;200&lt;/span&gt;
}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To get the server's status and client's status, you can send GET requests at &lt;code&gt;/status/server&lt;/code&gt; and &lt;code&gt;/status/client&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;p&gt;Finally, one may also config CORS to restrict the public access of the server by specifying &lt;code&gt;-cors&lt;/code&gt; when starting &lt;code&gt;bert-serving-start&lt;/code&gt;. By default &lt;code&gt;-cors=*&lt;/code&gt;, meaning the server is public accessible.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-starting-bertserver-from-python" class="anchor" aria-hidden="true" href="#starting-bertserver-from-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Starting &lt;code&gt;BertServer&lt;/code&gt; from Python&lt;/h3&gt;
&lt;p&gt;Besides shell, one can also start a &lt;code&gt;BertServer&lt;/code&gt; from python. Simply do&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; bert_serving.server.helper &lt;span class="pl-k"&gt;import&lt;/span&gt; get_args_parser
&lt;span class="pl-k"&gt;from&lt;/span&gt; bert_serving.server &lt;span class="pl-k"&gt;import&lt;/span&gt; BertServer
args &lt;span class="pl-k"&gt;=&lt;/span&gt; get_args_parser().parse_args([&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;-model_dir&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;YOUR_MODEL_PATH_HERE&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
                                     &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;-port&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;5555&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
                                     &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;-port_out&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;5556&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
                                     &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;-max_seq_len&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;NONE&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
                                     &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;-mask_cls_sep&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
                                     &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;-cpu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])
server &lt;span class="pl-k"&gt;=&lt;/span&gt; BertServer(args)
server.start()&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that it's basically mirroring the arg-parsing behavior in CLI, so everything in that &lt;code&gt;.parse_args([])&lt;/code&gt; list should be string, e.g. &lt;code&gt;['-port', '5555']&lt;/code&gt; not &lt;code&gt;['-port', 5555]&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To shutdown the server, you may call the static method in &lt;code&gt;BertServer&lt;/code&gt; class via:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;BertServer.shutdown(&lt;span class="pl-v"&gt;port&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;5555&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or via shell CLI:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bert-serving-terminate -port 5555&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will terminate the server running on localhost at port 5555. You may also use it to terminate a remote server, see &lt;code&gt;bert-serving-terminate --help&lt;/code&gt; for details.&lt;/p&gt;
&lt;h2 align="center"&gt;&lt;a id="user-content-speech_balloon-faq" class="anchor" aria-hidden="true" href="#speech_balloon-faq"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="speech_balloon" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ac.png"&gt;💬&lt;/g-emoji&gt; FAQ&lt;/h2&gt;
&lt;p align="right"&gt;&lt;a href="#bert-as-service"&gt;&lt;sup&gt;▴ Back to top&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://bert-as-service.readthedocs.io/en/latest/section/faq.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/95c38ab3eb5e58dcd9c3c931c7ef216fe77552d0/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f626572742d61732d736572766963652f62616467652f3f76657273696f6e3d6c6174657374267374796c653d666f722d7468652d6261646765" alt="ReadTheDoc" data-canonical-src="https://readthedocs.org/projects/bert-as-service/badge/?version=latest&amp;amp;style=for-the-badge" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-do-you-have-a-paper-or-other-written-explanation-to-introduce-your-models-details" class="anchor" aria-hidden="true" href="#q-do-you-have-a-paper-or-other-written-explanation-to-introduce-your-models-details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Do you have a paper or other written explanation to introduce your model's details?&lt;/h5&gt;
&lt;p&gt;The design philosophy and technical details can be found &lt;a href="https://hanxiao.github.io/2019/01/02/Serving-Google-BERT-in-Production-using-Tensorflow-and-ZeroMQ/" rel="nofollow"&gt;in my blog post&lt;/a&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-where-is-the-bert-code-come-from" class="anchor" aria-hidden="true" href="#q-where-is-the-bert-code-come-from"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Where is the BERT code come from?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; &lt;a href="server/bert_serving/server/bert/"&gt;BERT code of this repo&lt;/a&gt; is forked from the &lt;a href="https://github.com/google-research/bert"&gt;original BERT repo&lt;/a&gt; with necessary modification, &lt;a href="server/bert_serving/server/bert/extract_features.py"&gt;especially in extract_features.py&lt;/a&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-how-large-is-a-sentence-vector" class="anchor" aria-hidden="true" href="#q-how-large-is-a-sentence-vector"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; How large is a sentence vector?&lt;/h5&gt;
&lt;p&gt;In general, each sentence is translated to a 768-dimensional vector. Depending on the pretrained BERT you are using, &lt;code&gt;pooling_strategy&lt;/code&gt; and &lt;code&gt;pooling_layer&lt;/code&gt; the dimensions of the output vector could be different.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-how-do-you-get-the-fixed-representation-did-you-do-pooling-or-something" class="anchor" aria-hidden="true" href="#q-how-do-you-get-the-fixed-representation-did-you-do-pooling-or-something"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; How do you get the fixed representation? Did you do pooling or something?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Yes, pooling is required to get a fixed representation of a sentence. In the default strategy &lt;code&gt;REDUCE_MEAN&lt;/code&gt;, I take the second-to-last hidden layer of all of the tokens in the sentence and do average pooling.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-are-you-suggesting-using-bert-without-fine-tuning" class="anchor" aria-hidden="true" href="#q-are-you-suggesting-using-bert-without-fine-tuning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Are you suggesting using BERT without fine-tuning?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Yes and no. On the one hand, Google pretrained BERT on Wikipedia data, thus should encode enough prior knowledge of the language into the model. Having such feature is not a bad idea. On the other hand, these prior knowledge is not specific to any particular domain. It should be totally reasonable if the performance is not ideal if you are using it on, for example, classifying legal cases. Nonetheless, you can always first fine-tune your own BERT on the downstream task and then use &lt;code&gt;bert-as-service&lt;/code&gt; to extract the feature vectors efficiently. Keep in mind that &lt;code&gt;bert-as-service&lt;/code&gt; is just a feature extraction service based on BERT. Nothing stops you from using a fine-tuned BERT.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-can-i-get-a-concatenation-of-several-layers-instead-of-a-single-layer-" class="anchor" aria-hidden="true" href="#q-can-i-get-a-concatenation-of-several-layers-instead-of-a-single-layer-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Can I get a concatenation of several layers instead of a single layer ?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Sure! Just use a list of the layer you want to concatenate when calling the server. Example:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bert-serving-start -pooling_layer -4 -3 -2 -1 -model_dir /tmp/english_L-12_H-768_A-12/&lt;/pre&gt;&lt;/div&gt;
&lt;h5&gt;&lt;a id="user-content-q-what-are-the-available-pooling-strategies" class="anchor" aria-hidden="true" href="#q-what-are-the-available-pooling-strategies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; What are the available pooling strategies?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Here is a table summarizes all pooling strategies I implemented. Choose your favorite one by specifying &lt;code&gt;bert-serving-start -pooling_strategy&lt;/code&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Strategy&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;NONE&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;no pooling at all, useful when you want to use word embedding instead of sentence embedding. This will results in a &lt;code&gt;[max_seq_len, 768]&lt;/code&gt; encode matrix for a sequence.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;REDUCE_MEAN&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;take the average of the hidden state of encoding layer on the time axis&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;REDUCE_MAX&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;take the maximum of the hidden state of encoding layer on the time axis&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;REDUCE_MEAN_MAX&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;do &lt;code&gt;REDUCE_MEAN&lt;/code&gt; and &lt;code&gt;REDUCE_MAX&lt;/code&gt; separately and then concat them together on the last axis, resulting in 1536-dim sentence encodes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;CLS_TOKEN&lt;/code&gt; or &lt;code&gt;FIRST_TOKEN&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;get the hidden state corresponding to &lt;code&gt;[CLS]&lt;/code&gt;, i.e. the first token&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;SEP_TOKEN&lt;/code&gt; or &lt;code&gt;LAST_TOKEN&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;get the hidden state corresponding to &lt;code&gt;[SEP]&lt;/code&gt;, i.e. the last token&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h5&gt;&lt;a id="user-content-q-why-not-use-the-hidden-state-of-the-first-token-as-default-strategy-ie-the-cls" class="anchor" aria-hidden="true" href="#q-why-not-use-the-hidden-state-of-the-first-token-as-default-strategy-ie-the-cls"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Why not use the hidden state of the first token as default strategy, i.e. the &lt;code&gt;[CLS]&lt;/code&gt;?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Because a pre-trained model is not fine-tuned on any downstream tasks yet. In this case, the hidden state of &lt;code&gt;[CLS]&lt;/code&gt; is not a good sentence representation. If later you fine-tune the model, you may use &lt;code&gt;[CLS]&lt;/code&gt; as well.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-bert-has-1224-layers-so-which-layer-are-you-talking-about" class="anchor" aria-hidden="true" href="#q-bert-has-1224-layers-so-which-layer-are-you-talking-about"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; BERT has 12/24 layers, so which layer are you talking about?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; By default this service works on the second last layer, i.e. &lt;code&gt;pooling_layer=-2&lt;/code&gt;. You can change it by setting &lt;code&gt;pooling_layer&lt;/code&gt; to other negative values, e.g. -1 corresponds to the last layer.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-why-not-the-last-hidden-layer-why-second-to-last" class="anchor" aria-hidden="true" href="#q-why-not-the-last-hidden-layer-why-second-to-last"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Why not the last hidden layer? Why second-to-last?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; The last layer is too closed to the target functions (i.e. masked language model and next sentence prediction) during pre-training, therefore may be biased to those targets. If you question about this argument and want to use the last hidden layer anyway, please feel free to set &lt;code&gt;pooling_layer=-1&lt;/code&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-so-which-layer-and-which-pooling-strategy-is-the-best" class="anchor" aria-hidden="true" href="#q-so-which-layer-and-which-pooling-strategy-is-the-best"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; So which layer and which pooling strategy is the best?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; It depends. Keep in mind that different BERT layers capture different information. To see that more clearly, here is a visualization on &lt;a href="https://www.kaggle.com/uciml/news-aggregator-dataset" rel="nofollow"&gt;UCI-News Aggregator Dataset&lt;/a&gt;, where I randomly sample 20K news titles; get sentence encodes from different layers and with different pooling strategies, finally reduce it to 2D via PCA (one can of course do t-SNE as well, but that's not my point). There are only four classes of the data, illustrated in red, blue, yellow and green. To reproduce the result, please run &lt;a href="example/example7.py"&gt;example7.py&lt;/a&gt;.&lt;/p&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/pool_mean.png?raw=true"&gt;&lt;img src=".github/pool_mean.png?raw=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/pool_max.png?raw=true"&gt;&lt;img src=".github/pool_max.png?raw=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Intuitively, &lt;code&gt;pooling_layer=-1&lt;/code&gt; is close to the training output, so it may be biased to the training targets. If you don't fine tune the model, then this could lead to a bad representation. &lt;code&gt;pooling_layer=-12&lt;/code&gt; is close to the word embedding, may preserve the very original word information (with no fancy self-attention etc.). On the other hand, you may achieve the very same performance by simply using a word-embedding only. That said, anything in-between [-1, -12] is then a trade-off.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-could-i-use-other-pooling-techniques" class="anchor" aria-hidden="true" href="#q-could-i-use-other-pooling-techniques"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Could I use other pooling techniques?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; For sure. But if you introduce new &lt;code&gt;tf.variables&lt;/code&gt; to the graph, then you need to train those variables before using the model. You may also want to check &lt;a href="https://hanxiao.github.io/2018/06/24/4-Encoding-Blocks-You-Need-to-Know-Besides-LSTM-RNN-in-Tensorflow/#pooling-block" rel="nofollow"&gt;some pooling techniques I mentioned in my blog post&lt;/a&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-do-i-need-to-batch-the-data-before-encode" class="anchor" aria-hidden="true" href="#q-do-i-need-to-batch-the-data-before-encode"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Do I need to batch the data before &lt;code&gt;encode()&lt;/code&gt;?&lt;/h5&gt;
&lt;p&gt;No, not at all. Just do &lt;code&gt;encode&lt;/code&gt; and let the server handles the rest. If the batch is too large, the server will do batching automatically and it is more efficient than doing it by yourself. No matter how many sentences you have, 10K or 100K, as long as you can hold it in client's memory, just send it to the server. Please also read &lt;a href="https://github.com/hanxiao/bert-as-service#speed-wrt-client_batch_size"&gt;the benchmark on the client batch size&lt;/a&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-can-i-start-multiple-clients-and-send-requests-to-one-server-simultaneously" class="anchor" aria-hidden="true" href="#q-can-i-start-multiple-clients-and-send-requests-to-one-server-simultaneously"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Can I start multiple clients and send requests to one server simultaneously?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Yes! That's the purpose of this repo. In fact you can start as many clients as you want. One server can handle all of them (given enough time).&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-how-many-requests-can-one-service-handle-concurrently" class="anchor" aria-hidden="true" href="#q-how-many-requests-can-one-service-handle-concurrently"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; How many requests can one service handle concurrently?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; The maximum number of concurrent requests is determined by &lt;code&gt;num_worker&lt;/code&gt; in &lt;code&gt;bert-serving-start&lt;/code&gt;. If you a sending more than &lt;code&gt;num_worker&lt;/code&gt; requests concurrently, the new requests will be temporally stored in a queue until a free worker becomes available.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-so-one-request-means-one-sentence" class="anchor" aria-hidden="true" href="#q-so-one-request-means-one-sentence"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; So one request means one sentence?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; No. One request means a list of sentences sent from a client. Think the size of a request as the batch size. A request may contain 256, 512 or 1024 sentences. The optimal size of a request is often determined empirically. One large request can certainly improve the GPU utilization, yet it also increases the overhead of transmission. You may run &lt;code&gt;python example/example1.py&lt;/code&gt; for a simple benchmark.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-how-about-the-speed-is-it-fast-enough-for-production" class="anchor" aria-hidden="true" href="#q-how-about-the-speed-is-it-fast-enough-for-production"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; How about the speed? Is it fast enough for production?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; It highly depends on the &lt;code&gt;max_seq_len&lt;/code&gt; and the size of a request. On a single Tesla M40 24GB with &lt;code&gt;max_seq_len=40&lt;/code&gt;, you should get about 470 samples per second using a 12-layer BERT. In general, I'd suggest smaller &lt;code&gt;max_seq_len&lt;/code&gt; (25) and larger request size (512/1024).&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-did-you-benchmark-the-efficiency" class="anchor" aria-hidden="true" href="#q-did-you-benchmark-the-efficiency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Did you benchmark the efficiency?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Yes. See &lt;a href="#zap-benchmark"&gt;Benchmark&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To reproduce the results, please run &lt;code&gt;bert-serving-benchmark&lt;/code&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-what-is-backend-based-on" class="anchor" aria-hidden="true" href="#q-what-is-backend-based-on"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; What is backend based on?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; &lt;a href="http://zeromq.org/" rel="nofollow"&gt;ZeroMQ&lt;/a&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-what-is-the-parallel-processing-model-behind-the-scene" class="anchor" aria-hidden="true" href="#q-what-is-the-parallel-processing-model-behind-the-scene"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; What is the parallel processing model behind the scene?&lt;/h5&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/bert-parallel-pipeline.png?raw=true"&gt;&lt;img src=".github/bert-parallel-pipeline.png?raw=true" width="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-why-does-the-server-need-two-ports" class="anchor" aria-hidden="true" href="#q-why-does-the-server-need-two-ports"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Why does the server need two ports?&lt;/h5&gt;
&lt;p&gt;One port is for pushing text data into the server, the other port is for publishing the encoded result to the client(s). In this way, we get rid of back-chatter, meaning that at every level recipients never talk back to senders. The overall message flow is strictly one-way, as depicted in the above figure. Killing back-chatter is essential to real scalability, allowing us to use &lt;code&gt;BertClient&lt;/code&gt; in an asynchronous way.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-do-i-need-tensorflow-on-the-client-side" class="anchor" aria-hidden="true" href="#q-do-i-need-tensorflow-on-the-client-side"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Do I need Tensorflow on the client side?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; No. Think of &lt;code&gt;BertClient&lt;/code&gt; as a general feature extractor, whose output can be fed to &lt;em&gt;any&lt;/em&gt; ML models, e.g. &lt;code&gt;scikit-learn&lt;/code&gt;, &lt;code&gt;pytorch&lt;/code&gt;, &lt;code&gt;tensorflow&lt;/code&gt;. The only file that client need is &lt;a href="service/client.py"&gt;&lt;code&gt;client.py&lt;/code&gt;&lt;/a&gt;. Copy this file to your project and import it, then you are ready to go.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-can-i-use-multilingual-bert-model-provided-by-google" class="anchor" aria-hidden="true" href="#q-can-i-use-multilingual-bert-model-provided-by-google"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Can I use multilingual BERT model provided by Google?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Yes.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-can-i-use-my-own-fine-tuned-bert-model" class="anchor" aria-hidden="true" href="#q-can-i-use-my-own-fine-tuned-bert-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Can I use my own fine-tuned BERT model?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Yes. In fact, this is suggested. Make sure you have the following three items in &lt;code&gt;model_dir&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A TensorFlow checkpoint (&lt;code&gt;bert_model.ckpt&lt;/code&gt;) containing the pre-trained weights (which is actually 3 files).&lt;/li&gt;
&lt;li&gt;A vocab file (&lt;code&gt;vocab.txt&lt;/code&gt;) to map WordPiece to word id.&lt;/li&gt;
&lt;li&gt;A config file (&lt;code&gt;bert_config.json&lt;/code&gt;) which specifies the hyperparameters of the model.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-q-can-i-run-it-in-python-2" class="anchor" aria-hidden="true" href="#q-can-i-run-it-in-python-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Can I run it in python 2?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Server side no, client side yes. This is based on the consideration that python 2.x might still be a major piece in some tech stack. Migrating the whole downstream stack to python 3 for supporting &lt;code&gt;bert-as-service&lt;/code&gt; can take quite some effort. On the other hand, setting up &lt;code&gt;BertServer&lt;/code&gt; is just a one-time thing, which can be even &lt;a href="#run-bert-service-on-nvidia-docker"&gt;run in a docker container&lt;/a&gt;. To ease the integration, we support python 2 on the client side so that you can directly use &lt;code&gt;BertClient&lt;/code&gt; as a part of your python 2 project, whereas the server side should always be hosted with python 3.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-do-i-need-to-do-segmentation-for-chinese" class="anchor" aria-hidden="true" href="#q-do-i-need-to-do-segmentation-for-chinese"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Do I need to do segmentation for Chinese?&lt;/h5&gt;
&lt;p&gt;No, if you are using &lt;a href="https://github.com/google-research/bert#pre-trained-models"&gt;the pretrained Chinese BERT released by Google&lt;/a&gt; you don't need word segmentation. As this Chinese BERT is character-based model. It won't recognize word/phrase even if you intentionally add space in-between. To see that more clearly, this is what the BERT model actually receives after tokenization:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;bc.encode([&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;hey you&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;whats up?&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;你好么？&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;我 还 可以&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;tokens: [CLS] hey you [SEP]
input_ids: 101 13153 8357 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

tokens: [CLS] what ##s up ? [SEP]
input_ids: 101 9100 8118 8644 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

tokens: [CLS] 你 好 么 ？ [SEP]
input_ids: 101 872 1962 720 8043 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

tokens: [CLS] 我 还 可 以 [SEP]
input_ids: 101 2769 6820 1377 809 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That means the word embedding is actually the character embedding for Chinese-BERT.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-why-my-english-word-is-tokenized-to-something" class="anchor" aria-hidden="true" href="#q-why-my-english-word-is-tokenized-to-something"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Why my (English) word is tokenized to &lt;code&gt;##something&lt;/code&gt;?&lt;/h5&gt;
&lt;p&gt;Because your word is out-of-vocabulary (OOV). The tokenizer from Google uses a greedy longest-match-first algorithm to perform tokenization using the given vocabulary.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;input&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;unaffable&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
tokenizer_output &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;un&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;##aff&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;##able&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;]&lt;/pre&gt;&lt;/div&gt;
&lt;h5&gt;&lt;a id="user-content-q-can-i-use-my-own-tokenizer" class="anchor" aria-hidden="true" href="#q-can-i-use-my-own-tokenizer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Can I use my own tokenizer?&lt;/h5&gt;
&lt;p&gt;Yes. If you already tokenize the sentence on your own, simply send use &lt;code&gt;encode&lt;/code&gt; with &lt;code&gt;List[List[Str]]&lt;/code&gt; as input and turn on &lt;code&gt;is_tokenized&lt;/code&gt;, i.e. &lt;code&gt;bc.encode(texts, is_tokenized=True)&lt;/code&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-i-encounter-zmqerrorzmqerror-operation-cannot-be-accomplished-in-current-state-when-using-bertclient-what-should-i-do" class="anchor" aria-hidden="true" href="#q-i-encounter-zmqerrorzmqerror-operation-cannot-be-accomplished-in-current-state-when-using-bertclient-what-should-i-do"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; I encounter &lt;code&gt;zmq.error.ZMQError: Operation cannot be accomplished in current state&lt;/code&gt; when using &lt;code&gt;BertClient&lt;/code&gt;, what should I do?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; This is often due to the misuse of &lt;code&gt;BertClient&lt;/code&gt; in multi-thread/process environment. Note that you can’t reuse one &lt;code&gt;BertClient&lt;/code&gt; among multiple threads/processes, you have to make a separate instance for each thread/process. For example, the following won't work at all:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; BAD example&lt;/span&gt;
bc &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient()

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; in Proc1/Thread1 scope:&lt;/span&gt;
bc.encode(lst_str)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; in Proc2/Thread2 scope:&lt;/span&gt;
bc.encode(lst_str)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Instead, please do:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; in Proc1/Thread1 scope:&lt;/span&gt;
bc1 &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient()
bc1.encode(lst_str)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; in Proc2/Thread2 scope:&lt;/span&gt;
bc2 &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient()
bc2.encode(lst_str)&lt;/pre&gt;&lt;/div&gt;
&lt;h5&gt;&lt;a id="user-content-q-after-running-the-server-i-have-several-garbage-tmpxxxx-folders-how-can-i-change-this-behavior-" class="anchor" aria-hidden="true" href="#q-after-running-the-server-i-have-several-garbage-tmpxxxx-folders-how-can-i-change-this-behavior-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; After running the server, I have several garbage &lt;code&gt;tmpXXXX&lt;/code&gt; folders. How can I change this behavior ?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; These folders are used by ZeroMQ to store sockets. You can choose a different location by setting the environment variable &lt;code&gt;ZEROMQ_SOCK_TMP_DIR&lt;/code&gt; :
&lt;code&gt;export ZEROMQ_SOCK_TMP_DIR=/tmp/&lt;/code&gt;&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-the-cosine-similarity-of-two-sentence-vectors-is-unreasonably-high-eg-always--08-whats-wrong" class="anchor" aria-hidden="true" href="#q-the-cosine-similarity-of-two-sentence-vectors-is-unreasonably-high-eg-always--08-whats-wrong"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; The cosine similarity of two sentence vectors is unreasonably high (e.g. always &amp;gt; 0.8), what's wrong?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; A decent representation for a downstream task doesn't mean that it will be meaningful in terms of cosine distance. Since cosine distance is a linear space where all dimensions are weighted equally. if you want to use cosine distance anyway, then please focus on the rank not the absolute value. Namely, do not use:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if cosine(A, B) &amp;gt; 0.9, then A and B are similar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please consider the following instead:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if cosine(A, B) &amp;gt; cosine(A, C), then A is more similar to B than C.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The graph below illustrates the pairwise similarity of 3000 Chinese sentences randomly sampled from web (char. length &amp;lt; 25). We compute cosine similarity based on the sentence vectors and &lt;a href="https://en.wikipedia.org/wiki/ROUGE_(metric)" rel="nofollow"&gt;Rouge-L&lt;/a&gt; based on the raw text. The diagonal (self-correlation) is removed for the sake of clarity. As one can see, there is some positive correlation between these two metrics.&lt;/p&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/cosine-vs-rougel.png?raw=true"&gt;&lt;img src=".github/cosine-vs-rougel.png?raw=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;   
&lt;h5&gt;&lt;a id="user-content-q-im-getting-bad-performance-what-should-i-do" class="anchor" aria-hidden="true" href="#q-im-getting-bad-performance-what-should-i-do"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; I'm getting bad performance, what should I do?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; This often suggests that the pretrained BERT could not generate a descent representation of your downstream task. Thus, you can fine-tune the model on the downstream task and then use &lt;code&gt;bert-as-service&lt;/code&gt; to serve the fine-tuned BERT. Note that, &lt;code&gt;bert-as-service&lt;/code&gt; is just a feature extraction service based on BERT. Nothing stops you from using a fine-tuned BERT.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-can-i-run-the-server-side-on-cpu-only-machine" class="anchor" aria-hidden="true" href="#q-can-i-run-the-server-side-on-cpu-only-machine"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Can I run the server side on CPU-only machine?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Yes, please run &lt;code&gt;bert-serving-start -cpu -max_batch_size 16&lt;/code&gt;. Note that, CPU does not scale as good as GPU on large batches, therefore the &lt;code&gt;max_batch_size&lt;/code&gt; on the server side needs to be smaller, e.g. 16 or 32.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-how-can-i-choose-num_worker" class="anchor" aria-hidden="true" href="#q-how-can-i-choose-num_worker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; How can I choose &lt;code&gt;num_worker&lt;/code&gt;?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Generally, the number of workers should be less than or equal to the number of GPU/CPU you have. Otherwise, multiple workers will be allocated to one GPU/CPU, which may not scale well (and may cause out-of-memory on GPU).&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-q-can-i-specify-which-gpu-to-use" class="anchor" aria-hidden="true" href="#q-can-i-specify-which-gpu-to-use"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Q:&lt;/strong&gt; Can I specify which GPU to use?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Yes, you can specifying &lt;code&gt;-device_map&lt;/code&gt; as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bert-serving-start -device_map 0 1 4 -num_worker 4 -model_dir ...&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will start four workers and allocate them to GPU0, GPU1, GPU4 and again GPU0, respectively. In general, if &lt;code&gt;num_worker&lt;/code&gt; &amp;gt; &lt;code&gt;device_map&lt;/code&gt;, then devices will be reused and shared by the workers (may scale suboptimally or cause OOM); if &lt;code&gt;num_worker&lt;/code&gt; &amp;lt; &lt;code&gt;device_map&lt;/code&gt;, only &lt;code&gt;device_map[:num_worker]&lt;/code&gt; will be used.&lt;/p&gt;
&lt;p&gt;Note, &lt;code&gt;device_map&lt;/code&gt; is ignored when running on CPU.&lt;/p&gt;
&lt;h2 align="center"&gt;&lt;a id="user-content-zap-benchmark" class="anchor" aria-hidden="true" href="#zap-benchmark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="zap" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a1.png"&gt;⚡️&lt;/g-emoji&gt; Benchmark&lt;/h2&gt;
&lt;p align="right"&gt;&lt;a href="#bert-as-service"&gt;&lt;sup&gt;▴ Back to top&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://bert-as-service.readthedocs.io/en/latest/section/benchmark.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/95c38ab3eb5e58dcd9c3c931c7ef216fe77552d0/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f626572742d61732d736572766963652f62616467652f3f76657273696f6e3d6c6174657374267374796c653d666f722d7468652d6261646765" alt="ReadTheDoc" data-canonical-src="https://readthedocs.org/projects/bert-as-service/badge/?version=latest&amp;amp;style=for-the-badge" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The primary goal of benchmarking is to test the scalability and the speed of this service, which is crucial for using it in a dev/prod environment. Benchmark was done on Tesla M40 24GB, experiments were repeated 10 times and the average value is reported.&lt;/p&gt;
&lt;p&gt;To reproduce the results, please run&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;bert-serving-benchmark --help&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Common arguments across all experiments are:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Parameter&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;num_worker&lt;/td&gt;
&lt;td&gt;1,2,4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_seq_len&lt;/td&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;client_batch_size&lt;/td&gt;
&lt;td&gt;2048&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_batch_size&lt;/td&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;num_client&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-speed-wrt-max_seq_len" class="anchor" aria-hidden="true" href="#speed-wrt-max_seq_len"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speed wrt. &lt;code&gt;max_seq_len&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;max_seq_len&lt;/code&gt; is a parameter on the server side, which controls the maximum length of a sequence that a BERT model can handle. Sequences larger than &lt;code&gt;max_seq_len&lt;/code&gt; will be truncated on the left side. Thus, if your client want to send long sequences to the model, please make sure the server can handle them correctly.&lt;/p&gt;
&lt;p&gt;Performance-wise, longer sequences means slower speed and  more chance of OOM, as the multi-head self-attention (the core unit of BERT) needs to do dot products and matrix multiplications between every two symbols in the sequence.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/max_seq_len.png?raw=true"&gt;&lt;img src=".github/max_seq_len.png?raw=true" width="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;code&gt;max_seq_len&lt;/code&gt;&lt;/th&gt;
&lt;th&gt;1 GPU&lt;/th&gt;
&lt;th&gt;2 GPU&lt;/th&gt;
&lt;th&gt;4 GPU&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;903&lt;/td&gt;
&lt;td&gt;1774&lt;/td&gt;
&lt;td&gt;3254&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;473&lt;/td&gt;
&lt;td&gt;919&lt;/td&gt;
&lt;td&gt;1687&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;80&lt;/td&gt;
&lt;td&gt;231&lt;/td&gt;
&lt;td&gt;435&lt;/td&gt;
&lt;td&gt;768&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;160&lt;/td&gt;
&lt;td&gt;119&lt;/td&gt;
&lt;td&gt;237&lt;/td&gt;
&lt;td&gt;464&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;320&lt;/td&gt;
&lt;td&gt;54&lt;/td&gt;
&lt;td&gt;108&lt;/td&gt;
&lt;td&gt;212&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-speed-wrt-client_batch_size" class="anchor" aria-hidden="true" href="#speed-wrt-client_batch_size"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speed wrt. &lt;code&gt;client_batch_size&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;client_batch_size&lt;/code&gt; is the number of sequences from a client when invoking &lt;code&gt;encode()&lt;/code&gt;. For performance reason, please consider encoding sequences in batch rather than encoding them one by one.&lt;/p&gt;
&lt;p&gt;For example, do:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; prepare your sent in advance&lt;/span&gt;
bc &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient()
my_sentences &lt;span class="pl-k"&gt;=&lt;/span&gt; [s &lt;span class="pl-k"&gt;for&lt;/span&gt; s &lt;span class="pl-k"&gt;in&lt;/span&gt; my_corpus.iter()]
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; doing encoding in one-shot&lt;/span&gt;
vec &lt;span class="pl-k"&gt;=&lt;/span&gt; bc.encode(my_sentences)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;DON'T:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;bc &lt;span class="pl-k"&gt;=&lt;/span&gt; BertClient()
vec &lt;span class="pl-k"&gt;=&lt;/span&gt; []
&lt;span class="pl-k"&gt;for&lt;/span&gt; s &lt;span class="pl-k"&gt;in&lt;/span&gt; my_corpus.iter():
    vec.append(bc.encode(s))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It's even worse if you put &lt;code&gt;BertClient()&lt;/code&gt; inside the loop. Don't do that.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/client_batch_size.png?raw=true"&gt;&lt;img src=".github/client_batch_size.png?raw=true" width="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;code&gt;client_batch_size&lt;/code&gt;&lt;/th&gt;
&lt;th&gt;1 GPU&lt;/th&gt;
&lt;th&gt;2 GPU&lt;/th&gt;
&lt;th&gt;4 GPU&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;75&lt;/td&gt;
&lt;td&gt;74&lt;/td&gt;
&lt;td&gt;72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;206&lt;/td&gt;
&lt;td&gt;205&lt;/td&gt;
&lt;td&gt;201&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;274&lt;/td&gt;
&lt;td&gt;270&lt;/td&gt;
&lt;td&gt;267&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;332&lt;/td&gt;
&lt;td&gt;329&lt;/td&gt;
&lt;td&gt;330&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;td&gt;365&lt;/td&gt;
&lt;td&gt;365&lt;/td&gt;
&lt;td&gt;365&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;382&lt;/td&gt;
&lt;td&gt;383&lt;/td&gt;
&lt;td&gt;383&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;512&lt;/td&gt;
&lt;td&gt;432&lt;/td&gt;
&lt;td&gt;766&lt;/td&gt;
&lt;td&gt;762&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1024&lt;/td&gt;
&lt;td&gt;459&lt;/td&gt;
&lt;td&gt;862&lt;/td&gt;
&lt;td&gt;1517&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2048&lt;/td&gt;
&lt;td&gt;473&lt;/td&gt;
&lt;td&gt;917&lt;/td&gt;
&lt;td&gt;1681&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4096&lt;/td&gt;
&lt;td&gt;481&lt;/td&gt;
&lt;td&gt;943&lt;/td&gt;
&lt;td&gt;1809&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-speed-wrt-num_client" class="anchor" aria-hidden="true" href="#speed-wrt-num_client"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speed wrt. &lt;code&gt;num_client&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;num_client&lt;/code&gt; represents the number of concurrent clients connected to the server at the same time.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/num_clients.png?raw=true"&gt;&lt;img src=".github/num_clients.png?raw=true" width="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;code&gt;num_client&lt;/code&gt;&lt;/th&gt;
&lt;th&gt;1 GPU&lt;/th&gt;
&lt;th&gt;2 GPU&lt;/th&gt;
&lt;th&gt;4 GPU&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;473&lt;/td&gt;
&lt;td&gt;919&lt;/td&gt;
&lt;td&gt;1759&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;261&lt;/td&gt;
&lt;td&gt;512&lt;/td&gt;
&lt;td&gt;1028&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;133&lt;/td&gt;
&lt;td&gt;267&lt;/td&gt;
&lt;td&gt;533&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;67&lt;/td&gt;
&lt;td&gt;136&lt;/td&gt;
&lt;td&gt;270&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;34&lt;/td&gt;
&lt;td&gt;68&lt;/td&gt;
&lt;td&gt;136&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;34&lt;/td&gt;
&lt;td&gt;68&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As one can observe, 1 clients 1 GPU = 381 seqs/s, 2 clients 2 GPU 402 seqs/s, 4 clients 4 GPU 413 seqs/s. This shows the efficiency of our parallel pipeline and job scheduling, as the service can leverage the GPU time  more exhaustively as concurrent requests increase.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-speed-wrt-max_batch_size" class="anchor" aria-hidden="true" href="#speed-wrt-max_batch_size"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speed wrt. &lt;code&gt;max_batch_size&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;max_batch_size&lt;/code&gt; is a parameter on the server side, which controls the maximum number of samples per batch per worker. If a incoming batch from client is larger than &lt;code&gt;max_batch_size&lt;/code&gt;, the server will split it into small batches so that each of them is less or equal than &lt;code&gt;max_batch_size&lt;/code&gt; before sending it to workers.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/max_batch_size.png?raw=true"&gt;&lt;img src=".github/max_batch_size.png?raw=true" width="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;code&gt;max_batch_size&lt;/code&gt;&lt;/th&gt;
&lt;th&gt;1 GPU&lt;/th&gt;
&lt;th&gt;2 GPU&lt;/th&gt;
&lt;th&gt;4 GPU&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;td&gt;450&lt;/td&gt;
&lt;td&gt;887&lt;/td&gt;
&lt;td&gt;1726&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;td&gt;459&lt;/td&gt;
&lt;td&gt;897&lt;/td&gt;
&lt;td&gt;1759&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;128&lt;/td&gt;
&lt;td&gt;473&lt;/td&gt;
&lt;td&gt;931&lt;/td&gt;
&lt;td&gt;1816&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;473&lt;/td&gt;
&lt;td&gt;919&lt;/td&gt;
&lt;td&gt;1688&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;512&lt;/td&gt;
&lt;td&gt;464&lt;/td&gt;
&lt;td&gt;866&lt;/td&gt;
&lt;td&gt;1483&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-speed-wrt-pooling_layer" class="anchor" aria-hidden="true" href="#speed-wrt-pooling_layer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speed wrt. &lt;code&gt;pooling_layer&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;pooling_layer&lt;/code&gt; determines the encoding layer that pooling operates on. For example, in a 12-layer BERT model, &lt;code&gt;-1&lt;/code&gt; represents the layer closed to the output, &lt;code&gt;-12&lt;/code&gt; represents the layer closed to the embedding layer. As one can observe below, the depth of the pooling layer affects the speed.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/pooling_layer.png?raw=true"&gt;&lt;img src=".github/pooling_layer.png?raw=true" width="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;code&gt;pooling_layer&lt;/code&gt;&lt;/th&gt;
&lt;th&gt;1 GPU&lt;/th&gt;
&lt;th&gt;2 GPU&lt;/th&gt;
&lt;th&gt;4 GPU&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;[-1]&lt;/td&gt;
&lt;td&gt;438&lt;/td&gt;
&lt;td&gt;844&lt;/td&gt;
&lt;td&gt;1568&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[-2]&lt;/td&gt;
&lt;td&gt;475&lt;/td&gt;
&lt;td&gt;916&lt;/td&gt;
&lt;td&gt;1686&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[-3]&lt;/td&gt;
&lt;td&gt;516&lt;/td&gt;
&lt;td&gt;995&lt;/td&gt;
&lt;td&gt;1823&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[-4]&lt;/td&gt;
&lt;td&gt;569&lt;/td&gt;
&lt;td&gt;1076&lt;/td&gt;
&lt;td&gt;1986&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[-5]&lt;/td&gt;
&lt;td&gt;633&lt;/td&gt;
&lt;td&gt;1193&lt;/td&gt;
&lt;td&gt;2184&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[-6]&lt;/td&gt;
&lt;td&gt;711&lt;/td&gt;
&lt;td&gt;1340&lt;/td&gt;
&lt;td&gt;2430&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[-7]&lt;/td&gt;
&lt;td&gt;820&lt;/td&gt;
&lt;td&gt;1528&lt;/td&gt;
&lt;td&gt;2729&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[-8]&lt;/td&gt;
&lt;td&gt;945&lt;/td&gt;
&lt;td&gt;1772&lt;/td&gt;
&lt;td&gt;3104&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[-9]&lt;/td&gt;
&lt;td&gt;1128&lt;/td&gt;
&lt;td&gt;2047&lt;/td&gt;
&lt;td&gt;3622&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[-10]&lt;/td&gt;
&lt;td&gt;1392&lt;/td&gt;
&lt;td&gt;2542&lt;/td&gt;
&lt;td&gt;4241&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[-11]&lt;/td&gt;
&lt;td&gt;1523&lt;/td&gt;
&lt;td&gt;2737&lt;/td&gt;
&lt;td&gt;4752&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[-12]&lt;/td&gt;
&lt;td&gt;1568&lt;/td&gt;
&lt;td&gt;2985&lt;/td&gt;
&lt;td&gt;5303&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-speed-wrt--fp16-and--xla" class="anchor" aria-hidden="true" href="#speed-wrt--fp16-and--xla"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speed wrt. &lt;code&gt;-fp16&lt;/code&gt; and &lt;code&gt;-xla&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;bert-as-service&lt;/code&gt; supports two additional optimizations: half-precision and XLA, which can be turned on by adding &lt;code&gt;-fp16&lt;/code&gt; and &lt;code&gt;-xla&lt;/code&gt; to &lt;code&gt;bert-serving-start&lt;/code&gt;, respectively. To enable these two options, you have to meet the following requirements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;your GPU supports FP16 instructions;&lt;/li&gt;
&lt;li&gt;your Tensorflow is self-compiled with XLA and &lt;code&gt;-march=native&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;your CUDA and cudnn are not too old.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On Tesla V100 with &lt;code&gt;tensorflow=1.13.0-rc0&lt;/code&gt; it gives:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href=".github/fp16-xla.svg"&gt;&lt;img src=".github/fp16-xla.svg" width="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;FP16 achieves ~1.4x speedup (round-trip) comparing to the FP32 counterpart. To reproduce the result, please run &lt;code&gt;python example/example1.py&lt;/code&gt;.&lt;/p&gt;
&lt;h2 align="center"&gt;&lt;a id="user-content-citing" class="anchor" aria-hidden="true" href="#citing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citing&lt;/h2&gt;
&lt;p align="right"&gt;&lt;a href="#bert-as-service"&gt;&lt;sup&gt;▴ Back to top&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you use bert-as-service in a scientific publication, we would appreciate references to the following BibTex entry:&lt;/p&gt;
&lt;div class="highlight highlight-text-tex-latex"&gt;&lt;pre&gt;@misc{xiao2018bertservice,
  title={bert-as-service},
  author={Xiao, Han},
  howpublished={&lt;span class="pl-c1"&gt;\url&lt;/span&gt;{https://github.com/hanxiao/bert-as-service}},
  year={2018}
}&lt;/pre&gt;&lt;/div&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>hanxiao</author><guid isPermaLink="false">https://github.com/hanxiao/bert-as-service</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>swisskyrepo/PayloadsAllTheThings #24 in Python, This week</title><link>https://github.com/swisskyrepo/PayloadsAllTheThings</link><description>&lt;p&gt;&lt;i&gt;A list of useful payloads and bypass for Web Application Security and Pentest/CTF&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-payloads-all-the-things" class="anchor" aria-hidden="true" href="#payloads-all-the-things"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Payloads All The Things&lt;/h1&gt;
&lt;p&gt;A list of useful payloads and bypasses for Web Application Security.
Feel free to improve with your payloads and techniques !
I &lt;g-emoji class="g-emoji" alias="heart" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2764.png"&gt;❤️&lt;/g-emoji&gt; pull requests :)&lt;/p&gt;
&lt;p&gt;You can also contribute with a &lt;g-emoji class="g-emoji" alias="beers" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f37b.png"&gt;🍻&lt;/g-emoji&gt; IRL&lt;/p&gt;
&lt;p&gt;Every section contains the following files, you can use the &lt;code&gt;_template_vuln&lt;/code&gt; folder to create a new chapter:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;README.md - vulnerability description and how to exploit it&lt;/li&gt;
&lt;li&gt;Intruder - a set of files to give to Burp Intruder&lt;/li&gt;
&lt;li&gt;Images - pictures for the README.md&lt;/li&gt;
&lt;li&gt;Files - some files referenced in the README.md&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You might also like the &lt;code&gt;Methodology and Resources&lt;/code&gt; folder :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/"&gt;Methodology and Resources&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Active%20Directory%20Attack.md"&gt;Active Directory Attack.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Linux%20-%20Persistence.md"&gt;Linux - Persistence.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Linux%20-%20Privilege%20Escalation.md"&gt;Linux - Privilege Escalation.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Metasploit%20-%20Cheatsheet.md"&gt;Metasploit - Cheatsheet.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Methodology%20and%20enumeration.md"&gt;Methodology and enumeration.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Network%20Pivoting%20Techniques.md"&gt;Network Pivoting Techniques.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Network%20Discovery.md"&gt;Network Discovery.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Reverse%20Shell%20Cheatsheet.md"&gt;Reverse Shell Cheatsheet.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Subdomains%20Enumeration.md"&gt;Subdomains Enumeration.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Download%20and%20Execute.md"&gt;Windows - Download and Execute.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Mimikatz.md"&gt;Windows - Mimikatz.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Persistence.md"&gt;Windows - Persistence.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Post%20Exploitation%20Koadic.md"&gt;Windows - Post Exploitation Koadic.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Privilege%20Escalation.md"&gt;Windows - Privilege Escalation.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Using%20credentials.md"&gt;Windows - Using credentials.md&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/CVE%20Exploits"&gt;CVE Exploits&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apache Struts 2 CVE-2013-2251 CVE-2017-5638 CVE-2018-11776_.py&lt;/li&gt;
&lt;li&gt;Apache Struts 2 CVE-2017-9805.py&lt;/li&gt;
&lt;li&gt;Apache Struts 2 CVE-2018-11776.py&lt;/li&gt;
&lt;li&gt;Docker API RCE.py&lt;/li&gt;
&lt;li&gt;Drupalgeddon2 CVE-2018-7600.rb&lt;/li&gt;
&lt;li&gt;Heartbleed CVE-2014-0160.py&lt;/li&gt;
&lt;li&gt;JBoss CVE-2015-7501.py&lt;/li&gt;
&lt;li&gt;Jenkins CVE-2015-8103.py&lt;/li&gt;
&lt;li&gt;Jenkins CVE-2016-0792.py&lt;/li&gt;
&lt;li&gt;Rails CVE-2019-5420.rb&lt;/li&gt;
&lt;li&gt;Shellshock CVE-2014-6271.py&lt;/li&gt;
&lt;li&gt;Tomcat CVE-2017-12617.py&lt;/li&gt;
&lt;li&gt;WebLogic CVE-2016-3510.py&lt;/li&gt;
&lt;li&gt;WebLogic CVE-2017-10271.py&lt;/li&gt;
&lt;li&gt;WebLogic CVE-2018-2894.py&lt;/li&gt;
&lt;li&gt;WebSphere CVE-2015-7450.py&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You want more ? Check the &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/BOOKS.md"&gt;Books&lt;/a&gt; and &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/YOUTUBE.md"&gt;Youtube videos&lt;/a&gt; selections.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>swisskyrepo</author><guid isPermaLink="false">https://github.com/swisskyrepo/PayloadsAllTheThings</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>bokeh/bokeh #25 in Python, This week</title><link>https://github.com/bokeh/bokeh</link><description>&lt;p&gt;&lt;i&gt;Interactive Data Visualization in the browser, from  Python&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;a href="https://bokeh.org" rel="nofollow"&gt;
  &lt;img src="https://camo.githubusercontent.com/23c4767f9deb6835e161e7bee64eeaa1125f0721/68747470733a2f2f7374617469632e626f6b65682e6f72672f6c6f676f732f6c6f676f747970652e737667" height="60" width="150" alt="Bokeh logotype" data-canonical-src="https://static.bokeh.org/logos/logotype.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;p&gt;&lt;em&gt;Bokeh is a fiscally sponsored project of &lt;a href="https://numfocus.org" rel="nofollow"&gt;NumFOCUS&lt;/a&gt;, a nonprofit dedicated to supporting the open-source scientific computing community. If you like Bokeh and would like to support our mission, please consider &lt;a href="https://numfocus.org/donate-to-bokeh" rel="nofollow"&gt;making a donation&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
  &lt;td&gt;Latest Release&lt;/td&gt;
  &lt;td&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/319e5c4665c805f31c4e03601804b746c5d74925/68747470733a2f2f62616467652e667572792e696f2f67682f626f6b6568253246626f6b65682e737667"&gt;&lt;img src="https://camo.githubusercontent.com/319e5c4665c805f31c4e03601804b746c5d74925/68747470733a2f2f62616467652e667572792e696f2f67682f626f6b6568253246626f6b65682e737667" alt="Latest release version" data-canonical-src="https://badge.fury.io/gh/bokeh%2Fbokeh.svg" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://badge.fury.io/js/bokehjs" rel="nofollow"&gt;
      &lt;img src="https://camo.githubusercontent.com/95363bfe2ac7fb7e5eb9885a50868c1dba3a9a70/68747470733a2f2f62616467652e667572792e696f2f6a732f626f6b65686a732e737667" alt="npm version" data-canonical-src="https://badge.fury.io/js/bokehjs.svg" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;Conda&lt;/td&gt;
  &lt;td&gt;
    &lt;a href="https://docs.bokeh.org/en/latest/docs/installation.html" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/d0117bc93858f82f1a8ea5ebf5c19cabd97df9fd/68747470733a2f2f707976697a2e6f72672f5f7374617469632f63616368652f626f6b65685f636f6e64615f646f776e6c6f6164735f62616467652e737667" alt="Conda downloads per month" data-canonical-src="https://pyviz.org/_static/cache/bokeh_conda_downloads_badge.svg" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;License&lt;/td&gt;
  &lt;td&gt;
    &lt;a href="https://github.com/bokeh/bokeh/blob/master/LICENSE.txt"&gt;
    &lt;img src="https://camo.githubusercontent.com/abf7fceca8e58b3842bfed01c2e3c2ee1612fb09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f626f6b65682f626f6b65682e737667" alt="Bokeh license (BSD 3-clause)" data-canonical-src="https://img.shields.io/github/license/bokeh/bokeh.svg" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;PyPI&lt;/td&gt;
  &lt;td&gt;
    &lt;a href="https://docs.bokeh.org/en/latest/docs/installation.html" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/5ec94c8c7308f7fb219ac302aa09a50b46b18a82/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f626f6b65682e737667" alt="PyPI downloads per month" data-canonical-src="https://img.shields.io/pypi/dm/bokeh.svg" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;Sponsorship&lt;/td&gt;
  &lt;td&gt;
    &lt;a href="http://numfocus.org" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/28d3beb4213a1bfc61313a5b5a0be78b06e96c05/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706f776572656425323062792d4e756d464f4355532d626c61636b2e7376673f7374796c653d666c617426636f6c6f72413d35423542354226636f6c6f72423d303037443841" alt="Powered by NumFOCUS" data-canonical-src="https://img.shields.io/badge/powered%20by-NumFOCUS-black.svg?style=flat&amp;amp;colorA=5B5B5B&amp;amp;colorB=007D8A" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;Live Tutorial&lt;/td&gt;
  &lt;td&gt;
    &lt;a href="https://mybinder.org/v2/gh/bokeh/bokeh-notebooks/master?filepath=tutorial%2F00%20-%20Introduction%20and%20Setup.ipynb" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Live Bokeh tutorial notebooks on MyBinder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;Build Status&lt;/td&gt;
  &lt;td&gt;
    &lt;a href="https://travis-ci.org/bokeh/bokeh" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/8335f2a93fe3e1293a3571623b8d23ba262b1d30/68747470733a2f2f7472617669732d63692e6f72672f626f6b65682f626f6b65682e7376673f6272616e63683d6d6173746572" alt="Current TravisCI build status" data-canonical-src="https://travis-ci.org/bokeh/bokeh.svg?branch=master" style="max-width:100%;"&gt;
    &lt;/a&gt;
    &lt;a href="https://ci.appveyor.com/project/bokeh-integrations/bokeh" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/91e2de256d6ef59085db8d6fa178f4850fbf6cb3/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f753469646632356468703231396d686f3f7376673d74727565" alt="Current Appveyor build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/u4idf25dhp219mho?svg=true" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;Support&lt;/td&gt;
  &lt;td&gt;
    &lt;a href="https://discourse.bokeh.org" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/4bc630e601229d0ec09ce27647039334bede13ed/68747470733a2f2f696d672e736869656c64732e696f2f646973636f757273652f68747470732f646973636f757273652e626f6b65682e6f72672f706f7374732e737667" alt="Community Support on discourse.bokeh.org" data-canonical-src="https://img.shields.io/discourse/https/discourse.bokeh.org/posts.svg" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;Static Analysis&lt;/td&gt;
  &lt;td&gt;
    &lt;a href="https://bettercodehub.com/edge/badge/bokeh/bokeh?branch=master" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/0045ca709534292b0c5d2f8fc628b22ca3cbcf11/68747470733a2f2f626574746572636f64656875622e636f6d2f656467652f62616467652f626f6b65682f626f6b65683f6272616e63683d6d6173746572" alt="BetterCodeHub static analysis" data-canonical-src="https://bettercodehub.com/edge/badge/bokeh/bokeh?branch=master" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;Twitter&lt;/td&gt;
  &lt;td&gt;
    &lt;a href="https://twitter.com/BokehPlots" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/92ffc787e59932d1af96a7126fac375f84816b55/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f626f6b6568706c6f74732e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f77" alt="Follow BokehPlots on Twitter" data-canonical-src="https://img.shields.io/twitter/follow/bokehplots.svg?style=social&amp;amp;label=Follow" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;&lt;a href="https://bokeh.org" rel="nofollow"&gt;Bokeh&lt;/a&gt; is an interactive visualization library for modern web browsers. It provides elegant, concise construction of versatile graphics, and affords high-performance interactivity over large or streaming datasets. Bokeh can help anyone who would like to quickly and easily make interactive plots, dashboards, and data applications.&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;&lt;table cellspacing="10"&gt;
&lt;tbody&gt;&lt;tr&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/image.html" rel="nofollow"&gt;
  &lt;img alt="colormapped image plot thumbnail" src="https://camo.githubusercontent.com/f1f586b237dff8683e0ceaa2bdcb1b7e35f13f93/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f696d6167655f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/image_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/anscombe.html" rel="nofollow"&gt;
  &lt;img alt="anscombe plot thumbnail" src="https://camo.githubusercontent.com/073188ee921204d9f4741a91ab4562ca196711fe/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f616e73636f6d62655f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/anscombe_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/stocks.html" rel="nofollow"&gt;
  &lt;img alt="stocks plot thumbnail" src="https://camo.githubusercontent.com/e616cb26a235f6354269b268ae07eae87bac0c29/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f73746f636b735f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/stocks_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/lorenz.html" rel="nofollow"&gt;
  &lt;img alt="lorenz attractor plot thumbnail" src="https://camo.githubusercontent.com/7dfd551f33c5b51a099938c4e07349b28ba86387/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f6c6f72656e7a5f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/lorenz_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/candlestick.html" rel="nofollow"&gt;
  &lt;img alt="candlestick plot thumbnail" src="https://camo.githubusercontent.com/c44c6fc6939b0db3896efcb4902a68674f9af381/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f63616e646c65737469636b5f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/candlestick_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/color_scatter.html" rel="nofollow"&gt;
  &lt;img alt="scatter plot thumbnail" src="https://camo.githubusercontent.com/c7dce46ac91e2097b13979e697d42f469c3d3b9c/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f736361747465725f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/scatter_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/iris_splom.html" rel="nofollow"&gt;
  &lt;img alt="SPLOM plot thumbnail" src="https://camo.githubusercontent.com/85ebf47ee37f3ea5093426c73b87ef7122435ba0/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f73706c6f6d5f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/splom_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/iris.html" rel="nofollow"&gt;
  &lt;img alt="iris dataset plot thumbnail" src="https://camo.githubusercontent.com/0198838e25d20407fc590705827632199daa32a3/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f697269735f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/iris_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/histogram.html" rel="nofollow"&gt;
  &lt;img alt="histogram plot thumbnail" src="https://camo.githubusercontent.com/5ca5fb847641949daa5da2c3ebb7afec7029eb96/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f686973746f6772616d5f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/histogram_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/periodic.html" rel="nofollow"&gt;
  &lt;img alt="periodic table plot thumbnail" src="https://camo.githubusercontent.com/dc1fa06b214455fd268f67ac0a4ed47a38795b52/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f706572696f6469635f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/periodic_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/texas.html" rel="nofollow"&gt;
  &lt;img alt="choropleth plot thumbnail" src="https://camo.githubusercontent.com/1d1d55f394731332a63780514673c251136f2f63/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f63686f726f706c6574685f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/choropleth_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/burtin.html" rel="nofollow"&gt;
  &lt;img alt="burtin antibiotic data plot thumbnail" src="https://camo.githubusercontent.com/f8329c228dabe62292ae4727cf911d783ebe9371/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f62757274696e5f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/burtin_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/streamline.html" rel="nofollow"&gt;
  &lt;img alt="streamline plot thumbnail" src="https://camo.githubusercontent.com/2a39c0491917ad87e8c1ed266d85af408953152e/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f73747265616d6c696e655f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/streamline_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/image_rgba.html" rel="nofollow"&gt;
  &lt;img alt="RGBA image plot thumbnail" src="https://camo.githubusercontent.com/5a0021bc298920caf8f200c8661df4da2dbb908f/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f696d6167655f726762615f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/image_rgba_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/brewer.html" rel="nofollow"&gt;
  &lt;img alt="stacked bars plot thumbnail" src="https://camo.githubusercontent.com/8f4eef019e452e4e04ae69e54d3a603ae20ce861/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f737461636b65645f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/stacked_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/quiver.html" rel="nofollow"&gt;
  &lt;img alt="quiver plot thumbnail" src="https://camo.githubusercontent.com/4f762bcca73dddb3cc86e60b3d43f1521409a838/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f7175697665725f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/quiver_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/elements.html" rel="nofollow"&gt;
  &lt;img alt="elements data plot thumbnail" src="https://camo.githubusercontent.com/1b46c02fcad9fa523b1194f01b7c61821b68bcae/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f656c656d656e74735f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/elements_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/boxplot.html" rel="nofollow"&gt;
  &lt;img alt="boxplot thumbnail" src="https://camo.githubusercontent.com/aee991248aed1c36ce01afabea75062560915d91/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f626f78706c6f745f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/boxplot_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/categorical.html" rel="nofollow"&gt;
  &lt;img alt="categorical plot thumbnail" src="https://camo.githubusercontent.com/ad3bf9a45ea612ea5fe36c9aebfd61cdd23f82da/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f63617465676f726963616c5f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/categorical_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/unemployment.html" rel="nofollow"&gt;
  &lt;img alt="unemployment data plot thumbnail" src="https://camo.githubusercontent.com/a3b8632276b3f5adedd036d1ad6f9e7a02d6c907/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f756e656d706c6f796d656e745f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/unemployment_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
  &lt;a href="https://docs.bokeh.org/en/latest/docs/gallery/les_mis.html" rel="nofollow"&gt;
  &lt;img alt="Les Mis co-occurrence plot thumbnail" src="https://camo.githubusercontent.com/d50bb70e41286e878e465a38684ace5fb9f8e74e/68747470733a2f2f646f63732e626f6b65682e6f72672f656e2f6c61746573742f5f696d616765732f6c65735f6d69735f742e706e67" data-canonical-src="https://docs.bokeh.org/en/latest/_images/les_mis_t.png" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;The easiest way to install Bokeh is using the &lt;a href="https://www.anaconda.com/what-is-anaconda/" rel="nofollow"&gt;Anaconda Python distribution&lt;/a&gt; and its included &lt;em&gt;Conda&lt;/em&gt; package management system. To install Bokeh and its required dependencies, enter the following command at a Bash or Windows command prompt:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install bokeh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To install using pip, enter the following command at a Bash or Windows command prompt:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install bokeh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more information, refer to the &lt;a href="https://docs.bokeh.org/en/latest/docs/user_guide/quickstart.html#quick-installation" rel="nofollow"&gt;installation documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h2&gt;
&lt;p&gt;Once Bokeh is installed, check out the &lt;a href="https://docs.bokeh.org/en/latest/docs/user_guide/quickstart.html#getting-started" rel="nofollow"&gt;Getting Started&lt;/a&gt; section of the &lt;a href="https://docs.bokeh.org/en/latest/docs/user_guide/quickstart.html" rel="nofollow"&gt;Quickstart guide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Visit the &lt;a href="https://docs.bokeh.org" rel="nofollow"&gt;full documentation site&lt;/a&gt; to view the &lt;a href="https://docs.bokeh.org/en/dev/docs/user_guide.html" rel="nofollow"&gt;User's Guide&lt;/a&gt; or &lt;a href="https://mybinder.org/v2/gh/bokeh/bokeh-notebooks/master?filepath=tutorial%2F00%20-%20Introduction%20and%20Setup.ipynb" rel="nofollow"&gt;launch the Bokeh tutorial&lt;/a&gt; to learn about Bokeh in live Jupyter Notebooks.&lt;/p&gt;
&lt;p&gt;Community support is available on the &lt;a href="https://discourse.bokeh.org" rel="nofollow"&gt;Project Discourse&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you would like to contribute to Bokeh, please review the &lt;a href="https://docs.bokeh.org/en/latest/docs/dev_guide.html" rel="nofollow"&gt;Developer Guide&lt;/a&gt; and say hello on the &lt;a href="https://gitter.im/bokeh/bokeh-dev" rel="nofollow"&gt;bokeh-dev chat channel&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-follow-us" class="anchor" aria-hidden="true" href="#follow-us"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Follow us&lt;/h2&gt;
&lt;p&gt;Follow us on Twitter &lt;a href="https://twitter.com/BokehPlots" rel="nofollow"&gt;@bokehplots&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sponsors" class="anchor" aria-hidden="true" href="#sponsors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sponsors&lt;/h2&gt;
&lt;p&gt;The Bokeh project is grateful for &lt;a href="https://numfocus.org/donate-to-bokeh" rel="nofollow"&gt;individual contributions&lt;/a&gt; as well as sponsorship by the organizations and companies below:&lt;/p&gt;
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
  &lt;td&gt;
    &lt;a href="https://www.numfocus.org/" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/d147c30d8a6d9ca4b5eb060a83c511d7c99e6948/68747470733a2f2f7374617469632e626f6b65682e6f72672f73706f6e736f722f6e756d666f6375732e737667" alt="NumFocus Logo" width="200" data-canonical-src="https://static.bokeh.org/sponsor/numfocus.svg" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
    &lt;a href="https://www.anaconda.com/" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/64a2555013bed95305c66c8c823a419dcb1e2754/68747470733a2f2f7374617469632e626f6b65682e6f72672f73706f6e736f722f616e61636f6e64612e706e67" alt="Anaconda Logo" width="200" data-canonical-src="https://static.bokeh.org/sponsor/anaconda.png" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
    &lt;a href="https://www.nvidia.com" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/d2e3f41f97a9833e323294d46045dc8b0e7fc66a/68747470733a2f2f7374617469632e626f6b65682e6f72672f73706f6e736f722f6e76696469612e706e67" alt="NVidia Logo" width="200" data-canonical-src="https://static.bokeh.org/sponsor/nvidia.png" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
    &lt;a href="https://developer.nvidia.com/rapids" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/16c8825f8ae78640242f57070aab1bf8e664fa9c/68747470733a2f2f7374617469632e626f6b65682e6f72672f73706f6e736f722f7261706964732e706e67" alt="Rapids Logo" width="200" data-canonical-src="https://static.bokeh.org/sponsor/rapids.png" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;table align="center"&gt;
&lt;tbody&gt;&lt;tr&gt;
  &lt;td&gt;
    &lt;a href="https://www.quansight.com" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/8b37ec4276ae3506abd62b93028c9a3b5b86459a/68747470733a2f2f7374617469632e626f6b65682e6f72672f73706f6e736f722f7175616e73696768742e706e67" alt="Quansight Logo" width="100" data-canonical-src="https://static.bokeh.org/sponsor/quansight.png" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
    &lt;a href="https://www.rexhomes.com/" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/723b4a136c3f567e7ee1f9cb71767488eef13a30/68747470733a2f2f7374617469632e626f6b65682e6f72672f73706f6e736f722f7265782e6a7067" alt="Rex Logo" width="100" data-canonical-src="https://static.bokeh.org/sponsor/rex.jpg" style="max-width:100%;"&gt;
    &lt;/a&gt;
  &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;If your company uses Bokeh and is able to sponsor the project, please contact &lt;a href="info@bokeh.org"&gt;&lt;/a&gt;&lt;a href="mailto:info@bokeh.org"&gt;info@bokeh.org&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>bokeh</author><guid isPermaLink="false">https://github.com/bokeh/bokeh</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item></channel></rss>