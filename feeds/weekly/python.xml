<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Python, This week</title><link>https://github.com/trending/python?since=weekly</link><description>The top repositories on GitHub for python, measured weekly</description><pubDate>Mon, 28 Oct 2019 03:42:17 GMT</pubDate><lastBuildDate>Mon, 28 Oct 2019 03:42:17 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>1400</ttl><item><title>google-research/google-research #1 in Python, This week</title><link>https://github.com/google-research/google-research</link><description>&lt;p&gt;&lt;i&gt;Google AI Research&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-google-ai-research" class="anchor" aria-hidden="true" href="#google-ai-research"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Google AI Research&lt;/h1&gt;
&lt;p&gt;This repository contains code released by
&lt;a href="https://ai.google/research" rel="nofollow"&gt;Google AI Research&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Disclaimer: This is not an official Google product.&lt;/em&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>google-research</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>trailofbits/algo #2 in Python, This week</title><link>https://github.com/trailofbits/algo</link><description>&lt;p&gt;&lt;i&gt;Set up a personal VPN in the cloud&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-algo-vpn" class="anchor" aria-hidden="true" href="#algo-vpn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Algo VPN&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://gitter.im/trailofbits/algo?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0c0e33218aa937f681d5088b670c988adf804264/68747470733a2f2f6261646765732e6769747465722e696d2f747261696c6f66626974732f616c676f2e737667" alt="Join the chat at https://gitter.im/trailofbits/algo" data-canonical-src="https://badges.gitter.im/trailofbits/algo.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://twitter.com/AlgoVPN" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a67add962c4c0beeead2da6dd98552fbce611fdb/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f75726c2f68747470732f747769747465722e636f6d2f666f6c645f6c6566742e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f77253230253430416c676f56504e" alt="Twitter" data-canonical-src="https://img.shields.io/twitter/url/https/twitter.com/fold_left.svg?style=social&amp;amp;label=Follow%20%40AlgoVPN" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.org/trailofbits/algo" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/960c464446296d169c0887c1641336b26bc8672f/68747470733a2f2f6170692e7472617669732d63692e6f72672f747261696c6f66626974732f616c676f2e7376673f6272616e63683d6d6173746572" alt="TravisCI Status" data-canonical-src="https://api.travis-ci.org/trailofbits/algo.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Algo VPN is a set of Ansible scripts that simplify the setup of a personal Wireguard and IPSEC VPN. It uses the most secure defaults available, works with common cloud providers, and does not require client software on most devices. See our &lt;a href="https://blog.trailofbits.com/2016/12/12/meet-algo-the-vpn-that-works/" rel="nofollow"&gt;release announcement&lt;/a&gt; for more information.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Supports only IKEv2 with strong crypto (AES-GCM, SHA2, and P-256) and &lt;a href="https://www.wireguard.com/" rel="nofollow"&gt;WireGuard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Generates Apple profiles to auto-configure iOS and macOS devices&lt;/li&gt;
&lt;li&gt;Includes a helper script to add and remove users&lt;/li&gt;
&lt;li&gt;Blocks ads with a local DNS resolver (optional)&lt;/li&gt;
&lt;li&gt;Sets up limited SSH users for tunneling traffic (optional)&lt;/li&gt;
&lt;li&gt;Based on current versions of Ubuntu and strongSwan&lt;/li&gt;
&lt;li&gt;Installs to DigitalOcean, Amazon Lightsail, Amazon EC2, Vultr, Microsoft Azure, Google Compute Engine, Scaleway, OpenStack, CloudStack, Hetzner Cloud, or &lt;a href="docs/deploy-to-ubuntu.md"&gt;your own Ubuntu server&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-anti-features" class="anchor" aria-hidden="true" href="#anti-features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Anti-features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Does not support legacy cipher suites or protocols like L2TP, IKEv1, or RSA&lt;/li&gt;
&lt;li&gt;Does not install Tor, OpenVPN, or other risky servers&lt;/li&gt;
&lt;li&gt;Does not depend on the security of &lt;a href="https://tools.ietf.org/html/rfc7457" rel="nofollow"&gt;TLS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Does not require client software on most platforms&lt;/li&gt;
&lt;li&gt;Does not claim to provide anonymity or censorship avoidance&lt;/li&gt;
&lt;li&gt;Does not claim to protect you from the &lt;a href="https://en.wikipedia.org/wiki/Federal_Security_Service" rel="nofollow"&gt;FSB&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Ministry_of_State_Security_(China)" rel="nofollow"&gt;MSS&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Directorate-General_for_External_Security" rel="nofollow"&gt;DGSE&lt;/a&gt;, or &lt;a href="https://en.wikipedia.org/wiki/Flying_Spaghetti_Monster" rel="nofollow"&gt;FSM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-deploy-the-algo-server" class="anchor" aria-hidden="true" href="#deploy-the-algo-server"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deploy the Algo Server&lt;/h2&gt;
&lt;p&gt;The easiest way to get an Algo server running is to run it on your local system and let it set up a &lt;em&gt;new&lt;/em&gt; virtual machine in the cloud for you.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Setup an account on a cloud hosting provider.&lt;/strong&gt; Algo supports &lt;a href="https://m.do.co/c/4d7f4ff9cfe4" rel="nofollow"&gt;DigitalOcean&lt;/a&gt; (most user friendly), &lt;a href="https://aws.amazon.com/lightsail/" rel="nofollow"&gt;Amazon Lightsail&lt;/a&gt;, &lt;a href="https://aws.amazon.com/" rel="nofollow"&gt;Amazon EC2&lt;/a&gt;, &lt;a href="https://www.vultr.com/" rel="nofollow"&gt;Vultr&lt;/a&gt;, &lt;a href="https://azure.microsoft.com/" rel="nofollow"&gt;Microsoft Azure&lt;/a&gt;, &lt;a href="https://cloud.google.com/compute/" rel="nofollow"&gt;Google Compute Engine&lt;/a&gt;, &lt;a href="https://www.scaleway.com/" rel="nofollow"&gt;Scaleway&lt;/a&gt;, &lt;a href="https://www.dreamhost.com/cloud/computing/" rel="nofollow"&gt;DreamCompute&lt;/a&gt; or other OpenStack-based cloud hosting, &lt;a href="https://www.exoscale.com" rel="nofollow"&gt;Exoscale&lt;/a&gt; or other CloudStack-based cloud hosting,  or &lt;a href="https://www.hetzner.com/" rel="nofollow"&gt;Hetzner Cloud&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Get a copy of Algo.&lt;/strong&gt; The Algo scripts will be installed on your local system. There are two ways to get a copy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Download the &lt;a href="https://github.com/trailofbits/algo/archive/master.zip"&gt;ZIP file&lt;/a&gt;. Unzip the file to create a directory named &lt;code&gt;algo-master&lt;/code&gt; containing the Algo scripts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the command &lt;code&gt;git clone https://github.com/trailofbits/algo.git&lt;/code&gt; to create a directory named &lt;code&gt;algo&lt;/code&gt; containing the Algo scripts.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Install Algo's core dependencies.&lt;/strong&gt; Algo requires that &lt;strong&gt;Python 3&lt;/strong&gt; and at least one supporting package are installed on your system.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt; Apple does not provide Python 3 with macOS. There are two ways to obtain it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use the &lt;a href="https://brew.sh" rel="nofollow"&gt;Homebrew&lt;/a&gt; package manager. After installing Homebrew install Python 3 by running &lt;code&gt;brew install python3&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download and install the latest stable &lt;a href="https://www.python.org/downloads/mac-osx/" rel="nofollow"&gt;Python 3 package&lt;/a&gt;. Be sure to run the included &lt;em&gt;Install Certificates&lt;/em&gt; command from Finder.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once Python 3 is installed on your Mac, from Terminal run:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python3 -m pip install --upgrade virtualenv&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Linux:&lt;/strong&gt; Recent releases of Ubuntu, Debian, and Fedora come with Python 3 already installed. Make sure your system is up-to-date and install the supporting package(s):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu and Debian:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo apt install -y python3-virtualenv&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Fedora:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo dnf install -y python3-virtualenv&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Red Hat and CentOS 7 and later (for earlier versions see this &lt;a href="docs/deploy-from-redhat-centos6.md"&gt;documentation&lt;/a&gt;):&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo yum -y install epel-release
sudo yum install -y python36-virtualenv&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Windows:&lt;/strong&gt; Use the Windows Subsystem for Linux (WSL) to create your own copy of Ubuntu running under Windows from which to install and run Algo. See the &lt;a href="docs/deploy-from-windows.md"&gt;Windows documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Install Algo's remaining dependencies.&lt;/strong&gt; You'll need to run these commands from the Algo directory each time you download a new copy of Algo. In a Terminal window &lt;code&gt;cd&lt;/code&gt; into the &lt;code&gt;algo-master&lt;/code&gt; (ZIP file) or &lt;code&gt;algo&lt;/code&gt; (&lt;code&gt;git clone&lt;/code&gt;) directory and run:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python3 -m virtualenv --python=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;command -v python3&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; .env &lt;span class="pl-k"&gt;&amp;amp;&amp;amp;&lt;/span&gt;
  &lt;span class="pl-c1"&gt;source&lt;/span&gt; .env/bin/activate &lt;span class="pl-k"&gt;&amp;amp;&amp;amp;&lt;/span&gt;
  python3 -m pip install -U pip virtualenv &lt;span class="pl-k"&gt;&amp;amp;&amp;amp;&lt;/span&gt;
  python3 -m pip install -r requirements.txt&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On Fedora add the option &lt;code&gt;--system-site-packages&lt;/code&gt; to the first command above. On macOS install the C compiler if prompted.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;List the users to create.&lt;/strong&gt; Open the file &lt;code&gt;config.cfg&lt;/code&gt; in your favorite text editor. Specify the users you wish to create in the &lt;code&gt;users&lt;/code&gt; list. Create a unique user for each device you plan to connect to your VPN. If you want to be able to add or delete users later, you &lt;strong&gt;must&lt;/strong&gt; select &lt;code&gt;yes&lt;/code&gt; at the &lt;code&gt;Do you want to retain the keys (PKI)?&lt;/code&gt; prompt during the deployment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Start the deployment.&lt;/strong&gt; Return to your terminal. In the Algo directory, run &lt;code&gt;./algo&lt;/code&gt; and follow the instructions. There are several optional features available. None are required for a fully functional VPN server. These optional features are described in greater detail in &lt;a href="docs/deploy-from-ansible.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That's it! You will get the message below when the server deployment process completes. Take note of the p12 (user certificate) password and the CA key in case you need them later, &lt;strong&gt;they will only be displayed this time&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;You can now set up clients to connect to your VPN. Proceed to &lt;a href="#configure-the-vpn-clients"&gt;Configure the VPN Clients&lt;/a&gt; below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    "#                          Congratulations!                            #"
    "#                     Your Algo server is running.                     #"
    "#    Config files and certificates are in the ./configs/ directory.    #"
    "#              Go to https://whoer.net/ after connecting               #"
    "#        and ensure that all your traffic passes through the VPN.      #"
    "#                     Local DNS resolver 172.16.0.1                    #"
    "#        The p12 and SSH keys password for new users is XXXXXXXX       #"
    "#        The CA key password is XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX       #"
    "#      Shell access: ssh -i configs/algo.pem root@xxx.xxx.xx.xx        #"
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-configure-the-vpn-clients" class="anchor" aria-hidden="true" href="#configure-the-vpn-clients"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configure the VPN Clients&lt;/h2&gt;
&lt;p&gt;Certificates and configuration files that users will need are placed in the &lt;code&gt;configs&lt;/code&gt; directory. Make sure to secure these files since many contain private keys. All files are saved under a subdirectory named with the IP address of your new Algo VPN server.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-apple-devices" class="anchor" aria-hidden="true" href="#apple-devices"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Apple Devices&lt;/h3&gt;
&lt;p&gt;WireGuard is used to provide VPN services on Apple devices. Algo generates a WireGuard configuration file, &lt;code&gt;wireguard/&amp;lt;username&amp;gt;.conf&lt;/code&gt;, and a QR code, &lt;code&gt;wireguard/&amp;lt;username&amp;gt;.png&lt;/code&gt;, for each user defined in &lt;code&gt;config.cfg&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;On iOS, install the &lt;a href="https://itunes.apple.com/us/app/wireguard/id1441195209?mt=8" rel="nofollow"&gt;WireGuard&lt;/a&gt; app from the iOS App Store. Then, use the WireGuard app to scan the QR code or AirDrop the configuration file to the device.&lt;/p&gt;
&lt;p&gt;On macOS Mojave or later, install the &lt;a href="https://itunes.apple.com/us/app/wireguard/id1451685025?mt=12" rel="nofollow"&gt;WireGuard&lt;/a&gt; app from the Mac App Store. WireGuard will appear in the menu bar once you run the app. Click on the WireGuard icon, choose &lt;strong&gt;Import tunnel(s) from file...&lt;/strong&gt;, then select the appropriate WireGuard configuration file.&lt;/p&gt;
&lt;p&gt;On either iOS or macOS, you can enable "Connect on Demand" and/or exclude certain trusted Wi-Fi networks (such as your home or work) by editing the tunnel configuration in the WireGuard app. (Algo can't do this automatically for you.)&lt;/p&gt;
&lt;p&gt;Installing WireGuard is a little more complicated on older version of macOS. See &lt;a href="docs/client-macos-wireguard.md"&gt;Using macOS as a Client with WireGuard&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you prefer to use the built-in IPSEC VPN on Apple devices, or need "Connect on Demand" or excluded Wi-Fi networks automatically configured, then see &lt;a href="docs/client-apple-ipsec.md"&gt;Using Apple Devices as a Client with IPSEC&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-android-devices" class="anchor" aria-hidden="true" href="#android-devices"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Android Devices&lt;/h3&gt;
&lt;p&gt;WireGuard is used to provide VPN services on Android. Install the &lt;a href="https://play.google.com/store/apps/details?id=com.wireguard.android" rel="nofollow"&gt;WireGuard VPN Client&lt;/a&gt;. Import the corresponding &lt;code&gt;wireguard/&amp;lt;name&amp;gt;.conf&lt;/code&gt; file to your device, then setup a new connection with it. See the &lt;a href="/docs/client-android.md"&gt;Android setup instructions&lt;/a&gt; for more detailed walkthrough.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-windows" class="anchor" aria-hidden="true" href="#windows"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Windows&lt;/h3&gt;
&lt;p&gt;WireGuard is used to provide VPN services on Windows. Algo generates a WireGuard configuration file, &lt;code&gt;wireguard/&amp;lt;username&amp;gt;.conf&lt;/code&gt;, for each user defined in &lt;code&gt;config.cfg&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Install the &lt;a href="https://www.wireguard.com/install/#windows-7-8-81-10-2012-2016-2019" rel="nofollow"&gt;WireGuard VPN Client&lt;/a&gt;. Import the generated &lt;code&gt;wireguard/&amp;lt;username&amp;gt;.conf&lt;/code&gt; file to your device, then setup a new connection with it.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-linux-wireguard-clients" class="anchor" aria-hidden="true" href="#linux-wireguard-clients"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linux WireGuard Clients&lt;/h3&gt;
&lt;p&gt;WireGuard works great with Linux clients. See &lt;a href="docs/client-linux-wireguard.md"&gt;this page&lt;/a&gt; for an example of how to configure WireGuard on Ubuntu.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-linux-strongswan-ipsec-clients-eg-openwrt-ubuntu-server-etc" class="anchor" aria-hidden="true" href="#linux-strongswan-ipsec-clients-eg-openwrt-ubuntu-server-etc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linux strongSwan IPsec Clients (e.g., OpenWRT, Ubuntu Server, etc.)&lt;/h3&gt;
&lt;p&gt;Please see &lt;a href="docs/client-linux-ipsec.md"&gt;this page&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-other-devices" class="anchor" aria-hidden="true" href="#other-devices"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other Devices&lt;/h3&gt;
&lt;p&gt;Depending on the platform, you may need one or multiple of the following files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ipsec/manual/cacert.pem: CA Certificate&lt;/li&gt;
&lt;li&gt;ipsec/manual/.p12: User Certificate and Private Key (in PKCS#12 format)&lt;/li&gt;
&lt;li&gt;ipsec/manual/.conf: strongSwan client configuration&lt;/li&gt;
&lt;li&gt;ipsec/manual/.secrets: strongSwan client configuration&lt;/li&gt;
&lt;li&gt;ipsec/apple/.mobileconfig: Apple Profile&lt;/li&gt;
&lt;li&gt;wireguard/.conf: WireGuard configuration profile&lt;/li&gt;
&lt;li&gt;wireguard/.png: WireGuard configuration QR code&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-setup-an-ssh-tunnel" class="anchor" aria-hidden="true" href="#setup-an-ssh-tunnel"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup an SSH Tunnel&lt;/h2&gt;
&lt;p&gt;If you turned on the optional SSH tunneling role, then local user accounts will be created for each user in &lt;code&gt;config.cfg&lt;/code&gt; and SSH authorized_key files for them will be in the &lt;code&gt;configs&lt;/code&gt; directory (user.ssh.pem). SSH user accounts do not have shell access, cannot authenticate with a password, and only have limited tunneling options (e.g., &lt;code&gt;ssh -N&lt;/code&gt; is required). This ensures that SSH users have the least access required to setup a tunnel and can perform no other actions on the Algo server.&lt;/p&gt;
&lt;p&gt;Use the example command below to start an SSH tunnel by replacing &lt;code&gt;user&lt;/code&gt; and &lt;code&gt;ip&lt;/code&gt; with your own. Once the tunnel is setup, you can configure a browser or other application to use 127.0.0.1:1080 as a SOCKS proxy to route traffic through the Algo server.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ssh -D 127.0.0.1:1080 -f -q -C -N user@ip -i configs/&amp;lt;server_ip&amp;gt;/ssh-tunnel/&amp;lt;user&amp;gt;.pem&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ssh-into-algo-server" class="anchor" aria-hidden="true" href="#ssh-into-algo-server"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SSH into Algo Server&lt;/h2&gt;
&lt;p&gt;Your Algo server is configured for key-only SSH access for administrative purposes. Open the Terminal app, &lt;code&gt;cd&lt;/code&gt; into the &lt;code&gt;algo-master&lt;/code&gt; directory where you originally downloaded Algo, and then use the command listed on the success message:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ssh -i configs/algo.pem user@ip&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;where &lt;code&gt;user&lt;/code&gt; is either &lt;code&gt;root&lt;/code&gt; or &lt;code&gt;ubuntu&lt;/code&gt; as listed on the success message, and &lt;code&gt;ip&lt;/code&gt; is the IP address of your Algo server. If you find yourself regularly logging into the server then it will be useful to load your Algo ssh key automatically. Add the following snippet to the bottom of &lt;code&gt;~/.bash_profile&lt;/code&gt; to add it to your shell environment permanently.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ssh-add ~/.ssh/algo &amp;gt; /dev/null 2&amp;gt;&amp;amp;1&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-adding-or-removing-users" class="anchor" aria-hidden="true" href="#adding-or-removing-users"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Adding or Removing Users&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;If you chose to save the CA key during the deploy process,&lt;/em&gt; then Algo's own scripts can easily add and remove users from the VPN server.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Update the &lt;code&gt;users&lt;/code&gt; list in your &lt;code&gt;config.cfg&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Open a terminal, &lt;code&gt;cd&lt;/code&gt; to the algo directory, and activate the virtual environment with &lt;code&gt;source .env/bin/activate&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Run the command: &lt;code&gt;./algo update-users&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After this process completes, the Algo VPN server will contain only the users listed in the &lt;code&gt;config.cfg&lt;/code&gt; file.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-additional-documentation" class="anchor" aria-hidden="true" href="#additional-documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Additional Documentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/index.md"&gt;Deployment instructions, cloud provider setup instructions, and further client setup instructions available here.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/faq.md"&gt;FAQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/troubleshooting.md"&gt;Troubleshooting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you read all the documentation and have further questions, &lt;a href="https://gitter.im/trailofbits/algo" rel="nofollow"&gt;join the chat on Gitter&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-endorsements" class="anchor" aria-hidden="true" href="#endorsements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Endorsements&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;I've been ranting about the sorry state of VPN svcs for so long, probably about
time to give a proper talk on the subject. TL;DR: use Algo.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;-- &lt;a href="https://twitter.com/kennwhite/status/814166603587788800" rel="nofollow"&gt;Kenn White&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Before picking a VPN provider/app, make sure you do some research
&lt;a href="https://research.csiro.au/ng/wp-content/uploads/sites/106/2016/08/paper-1.pdf" rel="nofollow"&gt;https://research.csiro.au/ng/wp-content/uploads/sites/106/2016/08/paper-1.pdf&lt;/a&gt; ... – or consider Algo&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;-- &lt;a href="https://twitter.com/TheRegister/status/825076303657177088" rel="nofollow"&gt;The Register&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Algo is really easy and secure.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;-- &lt;a href="https://twitter.com/thegrugq/status/786249040228786176" rel="nofollow"&gt;the grugq&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I played around with Algo VPN, a set of scripts that let you set up a VPN in the cloud in very little time, even if you don’t know much about development. I’ve got to say that I was quite impressed with Trail of Bits’ approach.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;-- &lt;a href="https://twitter.com/romaindillet/status/851037243728965632" rel="nofollow"&gt;Romain Dillet&lt;/a&gt; for &lt;a href="https://techcrunch.com/2017/04/09/how-i-made-my-own-vpn-server-in-15-minutes/" rel="nofollow"&gt;TechCrunch&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you’re uncomfortable shelling out the cash to an anonymous, random VPN provider, this is the best solution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;-- &lt;a href="https://twitter.com/kingthor" rel="nofollow"&gt;Thorin Klosowski&lt;/a&gt; for &lt;a href="http://lifehacker.com/how-to-set-up-your-own-completely-free-vpn-in-the-cloud-1794302432" rel="nofollow"&gt;Lifehacker&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-support-algo-vpn" class="anchor" aria-hidden="true" href="#support-algo-vpn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support Algo VPN&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://flattr.com/submit/auto?fid=kxw60j&amp;amp;url=https%3A%2F%2Fgithub.com%2Ftrailofbits%2Falgo" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6b27c2d051d09e13f4009938f0b67aedd4ffd280/68747470733a2f2f627574746f6e2e666c617474722e636f6d2f666c617474722d62616467652d6c617267652e706e67" alt="Flattr" data-canonical-src="https://button.flattr.com/flattr-badge-large.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=CYZZD39GXUJ3E" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e14c85b542e06215f7e56c0763333ef1e9b9f9b7/68747470733a2f2f7777772e70617970616c6f626a656374732e636f6d2f656e5f55532f692f62746e2f62746e5f646f6e6174655f534d2e676966" alt="PayPal" data-canonical-src="https://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.patreon.com/algovpn" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/bf653361a158f7645497bf9490a97b697ec18f41/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6261636b5f6f6e2d70617472656f6e2d7265642e737667" alt="Patreon" data-canonical-src="https://img.shields.io/badge/back_on-patreon-red.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.bountysource.com/teams/trailofbits" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/79be76c663eb96142ff6f8d38ec10443107ffe97/68747470733a2f2f696d672e736869656c64732e696f2f626f756e7479736f757263652f7465616d2f747261696c6f66626974732f61637469766974792e737667" alt="Bountysource" data-canonical-src="https://img.shields.io/bountysource/team/trailofbits/activity.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All donations support continued development. Thanks!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We accept donations via &lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=CYZZD39GXUJ3E" rel="nofollow"&gt;PayPal&lt;/a&gt;, &lt;a href="https://www.patreon.com/algovpn" rel="nofollow"&gt;Patreon&lt;/a&gt;, and &lt;a href="https://flattr.com/submit/auto?fid=kxw60j&amp;amp;url=https%3A%2F%2Fgithub.com%2Ftrailofbits%2Falgo" rel="nofollow"&gt;Flattr&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Use our &lt;a href="https://m.do.co/c/4d7f4ff9cfe4" rel="nofollow"&gt;referral code&lt;/a&gt; when you sign up to Digital Ocean for a $10 credit.&lt;/li&gt;
&lt;li&gt;We also accept and appreciate contributions of new code and bugfixes via Github Pull Requests.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Algo is licensed and distributed under the AGPLv3. If you want to distribute a closed-source modification or service based on Algo, then please consider &lt;a href="mailto:opensource@trailofbits.com"&gt;purchasing an exception&lt;/a&gt; . As with the methods above, this will help support continued development.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>trailofbits</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>evilsocket/pwnagotchi #3 in Python, This week</title><link>https://github.com/evilsocket/pwnagotchi</link><description>&lt;p&gt;&lt;i&gt;(⌐■_■) - Deep Reinforcement Learning instrumenting bettercap for WiFi pwning.&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pwnagotchi" class="anchor" aria-hidden="true" href="#pwnagotchi"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pwnagotchi&lt;/h1&gt;
&lt;p align="center"&gt;
  &lt;/p&gt;&lt;p align="center"&gt;
    &lt;a href="https://github.com/evilsocket/pwnagotchi/releases/latest"&gt;&lt;img alt="Release" src="https://camo.githubusercontent.com/9ae707a55ead5a1e951d8504ebc47fe6f2259198/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f6576696c736f636b65742f70776e61676f746368692e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/github/release/evilsocket/pwnagotchi.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://github.com/evilsocket/pwnagotchi/blob/master/LICENSE.md"&gt;&lt;img alt="Software License" src="https://camo.githubusercontent.com/268d96c6dd81f1fff98b19675ef5867412a2a223/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d47504c332d627269676874677265656e2e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/badge/license-GPL3-brightgreen.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://github.com/evilsocket/pwnagotchi/graphs/contributors"&gt;&lt;img alt="Contributors" src="https://camo.githubusercontent.com/929754fc02f162895d1d3ac191ff93d5f0deefb2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6e7472696275746f72732f6576696c736f636b65742f70776e61676f74636869" data-canonical-src="https://img.shields.io/github/contributors/evilsocket/pwnagotchi" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://travis-ci.org/evilsocket/pwnagotchi" rel="nofollow"&gt;&lt;img alt="Travis" src="https://camo.githubusercontent.com/bb71ac99b3141520709ab3799968d900a4e7d193/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f6576696c736f636b65742f70776e61676f746368692f6d61737465722e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/travis/evilsocket/pwnagotchi/master.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://pwnagotchi.herokuapp.com/" rel="nofollow"&gt;&lt;img alt="Slack" src="https://camo.githubusercontent.com/41e1c12ae01495bfa5d5fd35c1e7060bf886ac25/68747470733a2f2f70776e61676f746368692e6865726f6b756170702e636f6d2f62616467652e737667" data-canonical-src="https://pwnagotchi.herokuapp.com/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://twitter.com/intent/follow?screen_name=pwnagotchi" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/342b3854fb5df1b53672e419d06fbd99da5a4eb6/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f70776e61676f746368693f7374796c653d736f6369616c266c6f676f3d74776974746572" alt="follow on Twitter" data-canonical-src="https://img.shields.io/twitter/follow/pwnagotchi?style=social&amp;amp;logo=twitter" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://pwnagotchi.ai/" rel="nofollow"&gt;Pwnagotchi&lt;/a&gt; is an &lt;a href="https://hackernoon.com/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752" rel="nofollow"&gt;A2C&lt;/a&gt;-based "AI" leveraging &lt;a href="https://www.bettercap.org/" rel="nofollow"&gt;bettercap&lt;/a&gt; that learns from its surrounding WiFi environment to maximize the crackable WPA key material it captures (either passively, or by performing authentication and association attacks). This material is collected as PCAP files containing any form of handshake supported by &lt;a href="https://hashcat.net/hashcat/" rel="nofollow"&gt;hashcat&lt;/a&gt;, including &lt;a href="https://www.evilsocket.net/2019/02/13/Pwning-WiFi-networks-with-bettercap-and-the-PMKID-client-less-attack/" rel="nofollow"&gt;PMKIDs&lt;/a&gt;,
full and half WPA handshakes.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e8bbbda8fbeb4da294be75c896026fc777c1a199/68747470733a2f2f692e696d6775722e636f6d2f5836384758726e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e8bbbda8fbeb4da294be75c896026fc777c1a199/68747470733a2f2f692e696d6775722e636f6d2f5836384758726e2e706e67" alt="ui" data-canonical-src="https://i.imgur.com/X68GXrn.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Instead of merely playing &lt;a href="https://becominghuman.ai/getting-mario-back-into-the-gym-setting-up-super-mario-bros-in-openais-gym-8e39a96c1e41?gi=c4b66c3d5ced" rel="nofollow"&gt;Super Mario or Atari games&lt;/a&gt; like most reinforcement learning-based "AI" &lt;em&gt;(yawn)&lt;/em&gt;, Pwnagotchi tunes &lt;a href="https://github.com/evilsocket/pwnagotchi/blob/master/pwnagotchi/defaults.yml#L73"&gt;its parameters&lt;/a&gt; over time to &lt;strong&gt;get better at pwning WiFi things to&lt;/strong&gt; in the environments you expose it to.&lt;/p&gt;
&lt;p&gt;More specifically, Pwnagotchi is using an &lt;a href="https://stable-baselines.readthedocs.io/en/master/modules/policies.html#stable_baselines.common.policies.MlpLstmPolicy" rel="nofollow"&gt;LSTM with MLP feature extractor&lt;/a&gt; as its policy network for the &lt;a href="https://stable-baselines.readthedocs.io/en/master/modules/a2c.html" rel="nofollow"&gt;A2C agent&lt;/a&gt;. If you're unfamiliar with A2C, here is &lt;a href="https://hackernoon.com/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752" rel="nofollow"&gt;a very good introductory explanation&lt;/a&gt; (in comic form!) of the basic principles behind how Pwnagotchi learns. (You can read more about how Pwnagotchi learns in the &lt;a href="https://www.pwnagotchi.ai/usage/#training-the-ai" rel="nofollow"&gt;Usage&lt;/a&gt; doc.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Keep in mind:&lt;/strong&gt; Unlike the usual RL simulations, Pwnagotchi learns over time. Time for a Pwnagotchi is measured in epochs; a single epoch can last from a few seconds to minutes, depending on how many access points and client stations are visible. Do not expect your Pwnagotchi to perform amazingly well at the very beginning, as it will be &lt;a href="https://hackernoon.com/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752" rel="nofollow"&gt;exploring&lt;/a&gt; several combinations of &lt;a href="https://www.pwnagotchi.ai/usage/#training-the-ai" rel="nofollow"&gt;key parameters&lt;/a&gt; to determine ideal adjustments for pwning the particular environment you are exposing it to during its beginning epochs ... but ** listen to your Pwnagotchi when it tells you it's boring!** Bring it into novel WiFi environments with you and have it observe new networks and capture new handshakes—and you'll see. :)&lt;/p&gt;
&lt;p&gt;Multiple units within close physical proximity can "talk" to each other, advertising their presence to each other by broadcasting custom information elements using a parasite protocol I've built on top of the existing dot11 standard. Over time, two or more units trained together will learn to cooperate upon detecting each other's presence by dividing the available channels among them for optimal pwnage.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.pwnagotchi.ai" rel="nofollow"&gt;https://www.pwnagotchi.ai&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-links" class="anchor" aria-hidden="true" href="#links"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Links&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt; &lt;/th&gt;
&lt;th&gt;Official Links&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Slack&lt;/td&gt;
&lt;td&gt;&lt;a href="https://pwnagotchi.herokuapp.com" rel="nofollow"&gt;pwnagotchi.slack.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Twitter&lt;/td&gt;
&lt;td&gt;&lt;a href="https://twitter.com/pwnagotchi" rel="nofollow"&gt;@pwnagotchi&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Subreddit&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.reddit.com/r/pwnagotchi/" rel="nofollow"&gt;r/pwnagotchi&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Website&lt;/td&gt;
&lt;td&gt;&lt;a href="https://pwnagotchi.ai/" rel="nofollow"&gt;pwnagotchi.ai&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;pwnagotchi&lt;/code&gt; is made with ♥  by &lt;a href="https://twitter.com/evilsocket" rel="nofollow"&gt;@evilsocket&lt;/a&gt; and the &lt;a href="https://github.com/evilsocket/pwnagotchi/graphs/contributors"&gt;amazing dev team&lt;/a&gt;. It is released under the GPL3 license.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>evilsocket</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>apachecn/AiLearning #4 in Python, This week</title><link>https://github.com/apachecn/AiLearning</link><description>&lt;p&gt;&lt;i&gt;AiLearning: 机器学习 - MachineLearning - ML、深度学习 - DeepLearning - DL、自然语言处理 NLP&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
    &lt;a href="https://www.apachecn.org" rel="nofollow"&gt;
        &lt;img width="200" src="https://camo.githubusercontent.com/9d35c24a9d070c56093b5598ef22afae12a2f45b/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f6c6f676f2e6a7067" data-canonical-src="http://data.apachecn.org/img/logo.jpg" style="max-width:100%;"&gt;
    &lt;/a&gt;
    &lt;br&gt;
    &lt;a href="https://www.apachecn.org/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/63fa00e49cf2df161cf6022c501b145d225bc335/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2533452d484f4d452d677265656e2e737667" data-canonical-src="https://img.shields.io/badge/%3E-HOME-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="http://home.apachecn.org/about/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/971440c5a29c84e984688b2ebe165dc27aa8cf61/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2533452d41424f55542d677265656e2e737667" data-canonical-src="https://img.shields.io/badge/%3E-ABOUT-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="mailto:apache@163.com"&gt;&lt;img src="https://camo.githubusercontent.com/f1fab6e562c98b86b95a7c44eae041e04022ec3e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2533452d456d61696c2d677265656e2e737667" data-canonical-src="https://img.shields.io/badge/%3E-Email-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h1 align="center"&gt;&lt;a id="user-content-ai-learning" class="anchor" aria-hidden="true" href="#ai-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/apachecn/AiLearning"&gt;AI learning&lt;/a&gt;&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-组织介绍" class="anchor" aria-hidden="true" href="#组织介绍"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;组织介绍&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;合作or侵权，请联系: &lt;code&gt;apachecn@163.com&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;我们不是 Apache 的官方组织/机构/团体，只是 Apache 技术栈（以及 AI）的爱好者！&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ApacheCN - 学习机器学习群【629470233】&lt;a href="//shang.qq.com/wpa/qunwpa?idkey=30e5f1123a79867570f665aa3a483ca404b1c3f77737bc01ec520ed5f078ddef" rel="nofollow"&gt;&lt;img border="0" src="https://camo.githubusercontent.com/6ef3c468024fa0a3ac83d0084d8d0847c6f57769/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f6c6f676f2f417061636865434e2d67726f75702e706e67" alt="ApacheCN - 学习机器学习群[629470233]" title="ApacheCN - 学习机器学习群[629470233]" data-canonical-src="http://data.apachecn.org/img/logo/ApacheCN-group.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;欢迎任何人参与和完善：一个人可以走的很快，但是一群人却可以走的更远&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;&lt;a id="user-content-路线图" class="anchor" aria-hidden="true" href="#路线图"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;路线图&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;入门只看: 步骤 1 =&amp;gt; 2 =&amp;gt; 3，你可以当大牛！&lt;/li&gt;
&lt;li&gt;中级补充 - 资料库: &lt;a href="https://github.com/apachecn/ai-roadmap"&gt;https://github.com/apachecn/ai-roadmap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-1机器学习---基础" class="anchor" aria-hidden="true" href="#1机器学习---基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.机器学习 - 基础&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-基本介绍" class="anchor" aria-hidden="true" href="#基本介绍"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;基本介绍&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;资料来源: Machine Learning in Action(机器学习实战-个人笔记)&lt;/li&gt;
&lt;li&gt;统一数据地址: &lt;a href="https://github.com/apachecn/data"&gt;https://github.com/apachecn/data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;书籍下载地址: &lt;a href="https://github.com/apachecn/data/tree/master/book"&gt;https://github.com/apachecn/data/tree/master/book&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;机器学习下载地址: &lt;a href="https://github.com/apachecn/data/tree/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"&gt;https://github.com/apachecn/data/tree/master/机器学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;深度学习数据地址: &lt;a href="https://github.com/apachecn/data/tree/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;https://github.com/apachecn/data/tree/master/深度学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;推荐系统数据地址: &lt;a href="https://github.com/apachecn/data/tree/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"&gt;https://github.com/apachecn/data/tree/master/推荐系统&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;视频网站：优酷 ／bilibili / Acfun / 网易云课堂，可直接在线播放。（最下方有相应链接）&lt;/li&gt;
&lt;li&gt;-- 推荐 &lt;a href="https://github.com/RedstoneWill"&gt;红色石头&lt;/a&gt;: &lt;a href="https://github.com/apachecn/ntu-hsuantienlin-ml"&gt;台湾大学林轩田机器学习笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;-- 推荐 &lt;a href="https://feisky.xyz/machine-learning" rel="nofollow"&gt;机器学习笔记&lt;/a&gt;: &lt;a href="https://feisky.xyz/machine-learning" rel="nofollow"&gt;https://feisky.xyz/machine-learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-学习文档" class="anchor" aria-hidden="true" href="#学习文档"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;学习文档&lt;/h3&gt;
&lt;table&gt;
  &lt;tbody&gt;&lt;tr&gt;
    &lt;th&gt;模块&lt;/th&gt;
    &lt;th&gt;章节&lt;/th&gt;
    &lt;th&gt;类型&lt;/th&gt;
    &lt;th&gt;负责人(GitHub)&lt;/th&gt;
    &lt;th&gt;QQ&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/1.机器学习基础.md"&gt; 第 1 章: 机器学习基础&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;介绍&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/ElmaDavies"&gt;@毛红动&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;1306014226&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/2.k-近邻算法.md"&gt;第 2 章: KNN 近邻算法&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;分类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/youyj521"&gt;@尤永江&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;279393323&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/3.决策树.md"&gt;第 3 章: 决策树&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;分类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/jingwangfei"&gt;@景涛&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;844300439&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/4.朴素贝叶斯.md"&gt;第 4 章: 朴素贝叶斯&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;分类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/wnma3mz"&gt;@wnma3mz&lt;/a&gt;&lt;br&gt;&lt;a href="https://github.com/kailian"&gt;@分析&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;1003324213&lt;br&gt;244970749&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/5.Logistic回归.md"&gt;第 5 章: Logistic回归&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;分类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/DataMonk2017"&gt;@微光同尘&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;529925688&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/6.支持向量机.md"&gt;第 6 章: SVM 支持向量机&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;分类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/VPrincekin"&gt;@王德红&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;934969547&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;网上组合内容&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/7.集成方法-随机森林和AdaBoost.md"&gt;第 7 章: 集成方法（随机森林和 AdaBoost）&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;分类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/jiangzhonglian"&gt;@片刻&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;529815144&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/8.回归.md"&gt;第 8 章: 回归&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;回归&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/DataMonk2017"&gt;@微光同尘&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;529925688&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/9.树回归.md"&gt;第 9 章: 树回归&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;回归&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/DataMonk2017"&gt;@微光同尘&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;529925688&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/10.k-means聚类.md"&gt;第 10 章: K-Means 聚类&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;聚类&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/xuzhaoqing"&gt;@徐昭清&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;827106588&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/11.使用Apriori算法进行关联分析.md"&gt;第 11 章: 利用 Apriori 算法进行关联分析&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;频繁项集&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/WindZQ"&gt;@刘海飞&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;1049498972&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/12.使用FP-growth算法来高效发现频繁项集.md"&gt;第 12 章: FP-growth 高效发现频繁项集&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;频繁项集&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/mikechengwei"&gt;@程威&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;842725815&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/13.利用PCA来简化数据.md"&gt;第 13 章: 利用 PCA 来简化数据&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;工具&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/lljuan330"&gt;@廖立娟&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;835670618&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/14.利用SVD简化数据.md"&gt;第 14 章: 利用 SVD 来简化数据&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;工具&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/marsjhao"&gt;@张俊皓&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;714974242&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;机器学习实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/15.大数据与MapReduce.md"&gt;第 15 章: 大数据与 MapReduce&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;工具&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/wnma3mz"&gt;@wnma3mz&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;1003324213&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Ml项目实战&lt;/td&gt;
    &lt;td&gt;&lt;a href="docs/ml/16.推荐系统.md"&gt;第 16 章: 推荐系统（已迁移）&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;项目&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://github.com/apachecn/RecommenderSystems"&gt;推荐系统（迁移后地址）&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;第一期的总结&lt;/td&gt;
    &lt;td&gt;&lt;a href="report/2017-04-08_第一期的总结.md"&gt;2017-04-08: 第一期的总结&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;总结&lt;/td&gt;
    &lt;td&gt;总结&lt;/td&gt;
    &lt;td&gt;529815144&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-网站视频" class="anchor" aria-hidden="true" href="#网站视频"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;网站视频&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://www.zhihu.com/question/20691338/answer/248678328" rel="nofollow"&gt;知乎问答-爆炸啦-机器学习该怎么入门？&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当然我知道，第一句就会被吐槽，因为科班出身的人，不屑的吐了一口唾沫，说傻X，还评论 Andrew Ng 的视频。。&lt;/p&gt;
&lt;p&gt;我还知道还有一部分人，看 Andrew Ng 的视频就是看不懂，那神秘的数学推导，那迷之微笑的英文版的教学，我何尝又不是这样走过来的？？ 我的心可能比你们都痛，因为我在网上收藏过上10部《机器学习》相关视频，外加国内本土风格的教程：7月+小象 等等，我都很难去听懂，直到有一天，被一个百度的高级算法分析师推荐说：《机器学习实战》还不错，通俗易懂，你去试试？？&lt;/p&gt;
&lt;p&gt;我试了试，还好我的Python基础和调试能力还不错，基本上代码都调试过一遍，很多高大上的 "理论+推导"，在我眼中变成了几个 "加减乘除+循环"，我想这不就是像我这样的程序员想要的入门教程么？&lt;/p&gt;
&lt;p&gt;很多程序员说机器学习 TM 太难学了，是的，真 TM 难学，我想最难的是：没有一本像《机器学习实战》那样的作者愿意以程序员 Coding 角度去给大家讲解！！&lt;/p&gt;
&lt;p&gt;最近几天，GitHub 涨了 300颗 star，加群的200人， 现在还在不断的增加++，我想大家可能都是感同身受吧！&lt;/p&gt;
&lt;p&gt;很多想入门新手就是被忽悠着收藏收藏再收藏，但是最后还是什么都没有学到，也就是"资源收藏家"，也许新手要的就是 &lt;a href="https://docs.apachecn.org/map" rel="nofollow"&gt;MachineLearning(机器学习) 学习路线图&lt;/a&gt;。没错，我可以给你们的一份，因为我们还通过视频记录下来我们的学习过程。水平当然也有限，不过对于新手入门，绝对没问题，如果你还不会，那算我输！！&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;视频怎么看？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/4aeb51811bbc73e4715ced3ebc64ab26670bdc67/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f4d61696e506167652f417061636865434e2d4d4c2d62696c6962696c692d636f6d706172652e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/4aeb51811bbc73e4715ced3ebc64ab26670bdc67/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f4d61696e506167652f417061636865434e2d4d4c2d62696c6962696c692d636f6d706172652e6a7067" alt="" data-canonical-src="http://data.apachecn.org/img/AiLearning/MainPage/ApacheCN-ML-bilibili-compare.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;理论科班出身-建议去学习 Andrew Ng 的视频（Ng 的视频绝对是权威，这个毋庸置疑）&lt;/li&gt;
&lt;li&gt;编码能力强 - 建议看我们的&lt;a href="https://space.bilibili.com/97678687/#!/channel/detail?cid=22486" rel="nofollow"&gt;《机器学习实战-教学版》&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;编码能力弱 - 建议看我们的&lt;a href="https://space.bilibili.com/97678687/#!/channel/detail?cid=13045" rel="nofollow"&gt;《机器学习实战-讨论版》&lt;/a&gt;，不过在看理论的时候，看 教学版-理论部分；讨论版的废话太多，不过在讲解代码的时候是一行一行讲解的；所以，根据自己的需求，自由的组合。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;【免费】数学教学视频 - 可汗学院 入门篇&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=""&gt;@于振梓&lt;/a&gt; 推荐: 可汗学院-网易公开课&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;概率&lt;/th&gt;
&lt;th&gt;统计&lt;/th&gt;
&lt;th&gt;线性代数&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://open.163.com/special/Khan/probability.html" rel="nofollow"&gt;可汗学院(概率)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://open.163.com/special/Khan/khstatistics.html" rel="nofollow"&gt;可汗学院(统计学)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://open.163.com/special/Khan/linearalgebra.html" rel="nofollow"&gt;可汗学院(线性代数)&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;机器学习视频 - ApacheCN 教学版&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;AcFun&lt;/td&gt;
&lt;td&gt;B站&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a title="AcFun（机器学习视频）" href="http://www.acfun.cn/u/12540256.aspx#page=1" rel="nofollow"&gt;&lt;img width="290" src="https://camo.githubusercontent.com/122aa82278121b78486f6cc20b3813851832d1b0/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f4d61696e506167652f417061636865434e2d4d4c2d416346756e2e6a7067" data-canonical-src="http://data.apachecn.org/img/AiLearning/MainPage/ApacheCN-ML-AcFun.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a title="bilibili（机器学习视频）" href="https://space.bilibili.com/97678687/#!/channel/index" rel="nofollow"&gt;&lt;img width="290" src="https://camo.githubusercontent.com/c04107f0478a7e3e15b5103004d534af8ec36afd/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f4d61696e506167652f417061636865434e2d4d4c2d62696c6962696c692e6a7067" data-canonical-src="http://data.apachecn.org/img/AiLearning/MainPage/ApacheCN-ML-bilibili.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;优酷&lt;/td&gt;
&lt;td&gt;网易云课堂&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a title="YouKu（机器学习视频）" href="http://i.youku.com/apachecn" rel="nofollow"&gt;&lt;img width="290" src="https://camo.githubusercontent.com/ff306cb8a0eac3f6a9a59f01e73b538b0be8588e/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f4d61696e506167652f417061636865434d2d4d4c2d796f756b752e6a7067" data-canonical-src="http://data.apachecn.org/img/AiLearning/MainPage/ApacheCM-ML-youku.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a title="WangYiYunKeTang（机器学习视频）" href="http://study.163.com/course/courseMain.htm?courseId=1004582003" rel="nofollow"&gt;&lt;img width="290" src="https://camo.githubusercontent.com/615d94638b0fefc25253ca5a4147a5153e35379f/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f4d61696e506167652f417061636865434d2d4d4c2d57616e67596959756e4b6554616e672e706e67" data-canonical-src="http://data.apachecn.org/img/AiLearning/MainPage/ApacheCM-ML-WangYiYunKeTang.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;【免费】机器/深度学习视频 - 吴恩达&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;机器学习&lt;/th&gt;
&lt;th&gt;深度学习&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://study.163.com/course/courseMain.htm?courseId=1004570029" rel="nofollow"&gt;吴恩达机器学习&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://mooc.study.163.com/course/2001281002?tid=2001392029" rel="nofollow"&gt;神经网络和深度学习&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-2深度学习" class="anchor" aria-hidden="true" href="#2深度学习"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2.深度学习&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-入门基础" class="anchor" aria-hidden="true" href="#入门基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;入门基础&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="/docs/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92.md"&gt;反向传递&lt;/a&gt;: &lt;a href="https://www.cnblogs.com/charlotte77/p/5629865.html" rel="nofollow"&gt;https://www.cnblogs.com/charlotte77/p/5629865.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/docs/dl/CNN%E5%8E%9F%E7%90%86.md"&gt;CNN原理&lt;/a&gt;: &lt;a href="http://www.cnblogs.com/charlotte77/p/7759802.html" rel="nofollow"&gt;http://www.cnblogs.com/charlotte77/p/7759802.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/docs/dl/RNN%E5%8E%9F%E7%90%86.md"&gt;RNN原理&lt;/a&gt;: &lt;a href="https://blog.csdn.net/qq_39422642/article/details/78676567" rel="nofollow"&gt;https://blog.csdn.net/qq_39422642/article/details/78676567&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/docs/dl/LSTM%E5%8E%9F%E7%90%86.md"&gt;LSTM原理&lt;/a&gt;: &lt;a href="https://blog.csdn.net/weixin_42111770/article/details/80900575" rel="nofollow"&gt;https://blog.csdn.net/weixin_42111770/article/details/80900575&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-pytorch---教程" class="anchor" aria-hidden="true" href="#pytorch---教程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pytorch - 教程&lt;/h3&gt;
&lt;p&gt;-- 待更新&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-tensorflow-20---教程" class="anchor" aria-hidden="true" href="#tensorflow-20---教程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow 2.0 - 教程&lt;/h3&gt;
&lt;p&gt;-- 待更新&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;目录结构:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/TensorFlow2.x/%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97.md"&gt;安装指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/TensorFlow2.x/Keras%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8.md"&gt;Kears 快速入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/TensorFlow2.x/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE_1_%E7%94%B5%E5%BD%B1%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB.md"&gt;实战项目 1 电影情感分类&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/TensorFlow2.x/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE_2_%E6%B1%BD%E8%BD%A6%E7%87%83%E6%B2%B9%E6%95%88%E7%8E%87.md"&gt;实战项目 2 汽车燃油效率&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-3自然语言处理" class="anchor" aria-hidden="true" href="#3自然语言处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3.自然语言处理&lt;/h2&gt;
&lt;p&gt;学习过程中-内心复杂的变化！！！&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;自从学习&lt;span class="pl-c1"&gt;NLP&lt;/span&gt;以后，才发现国内与国外的典型区别:
&lt;span class="pl-c1"&gt;1&lt;/span&gt;. 对资源的态度是完全相反的:
  &lt;span class="pl-c1"&gt;1&lt;/span&gt;) 国内：就好像为了名气，举办工作装逼的会议，就是没有干货，全部都是象征性的&lt;span class="pl-c1"&gt;PPT&lt;/span&gt;介绍，不是针对在做的各位
  &lt;span class="pl-c1"&gt;2&lt;/span&gt;）国外：就好像是为了推动nlp进步一样，分享者各种干货资料和具体的实现。（特别是: python自然语言处理）
&lt;span class="pl-c1"&gt;2&lt;/span&gt;. 论文的实现：
  &lt;span class="pl-c1"&gt;1&lt;/span&gt;) 各种高大上的论文实现，却还是没看到一个像样的GitHub项目！（可能我的搜索能力差了点，一直没找到）
  &lt;span class="pl-c1"&gt;2&lt;/span&gt;）国外就不举例了，我看不懂！
&lt;span class="pl-c1"&gt;3&lt;/span&gt;. 开源的框架
  &lt;span class="pl-c1"&gt;1&lt;/span&gt;）国外的开源框架： tensorflow&lt;span class="pl-k"&gt;/&lt;/span&gt;pytorch 文档&lt;span class="pl-k"&gt;+&lt;/span&gt;教程&lt;span class="pl-k"&gt;+&lt;/span&gt;视频（官方提供）
  &lt;span class="pl-c1"&gt;2&lt;/span&gt;) 国内的开源框架: 额额，还真举例不出来！但是牛逼吹得不比国外差！（MXNet虽然有众多国人参与开发，但不能算是国内开源框架。基于MXNet的动手学深度学习(http:&lt;span class="pl-k"&gt;//&lt;/span&gt;zh.d2l.ai &lt;span class="pl-k"&gt;&amp;amp;&lt;/span&gt; https:&lt;span class="pl-k"&gt;//&lt;/span&gt;discuss.gluon.ai&lt;span class="pl-k"&gt;/&lt;/span&gt;t&lt;span class="pl-k"&gt;/&lt;/span&gt;topic&lt;span class="pl-k"&gt;/&lt;/span&gt;&lt;span class="pl-c1"&gt;753&lt;/span&gt;)中文教程,已经由沐神(李沐)以及阿斯顿·张讲授录制，公开发布(文档&lt;span class="pl-k"&gt;+&lt;/span&gt;第一季教程&lt;span class="pl-k"&gt;+&lt;/span&gt;视频）。)
每一次深入都要去翻墙，每一次深入都要Google，每一次看着国内的说：哈工大、讯飞、中科大、百度、阿里多牛逼，但是资料还是得国外去找！
有时候真的挺恨的！真的有点瞧不起自己国内的技术环境！

当然谢谢国内很多博客大佬，特别是一些入门的Demo和基本概念。【深入的水平有限，没看懂】&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6535fd936f9a2b1db5392b626320ce725854f675/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f6e6c702f46393435383146363443323141313039344134373333393744464134324639432e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/6535fd936f9a2b1db5392b626320ce725854f675/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f41694c6561726e696e672f6e6c702f46393435383146363443323141313039344134373333393744464134324639432e6a7067" alt="" data-canonical-src="http://data.apachecn.org/img/AiLearning/nlp/F94581F64C21A1094A473397DFA42F9C.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;【入门须知】必须了解&lt;/strong&gt;: &lt;a href="https://github.com/apachecn/AiLearning/tree/master/docs/nlp"&gt;https://github.com/apachecn/AiLearning/tree/master/docs/nlp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;【入门教程】强烈推荐: PyTorch 自然语言处理&lt;/strong&gt;: &lt;a href="https://github.com/apachecn/NLP-with-PyTorch"&gt;https://github.com/apachecn/NLP-with-PyTorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Python 自然语言处理 第二版: &lt;a href="https://usyiyi.github.io/nlp-py-2e-zh" rel="nofollow"&gt;https://usyiyi.github.io/nlp-py-2e-zh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;推荐一个&lt;a href="https://github.com/liuhuanyong"&gt;liuhuanyong大佬&lt;/a&gt;整理的nlp全面知识体系: &lt;a href="https://liuhuanyong.github.io" rel="nofollow"&gt;https://liuhuanyong.github.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;开源 - 词向量库集合:
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Embedding/Chinese-Word-Vectors"&gt;https://github.com/Embedding/Chinese-Word-Vectors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/brightmart/nlp_chinese_corpus"&gt;https://github.com/brightmart/nlp_chinese_corpus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/codemayq/chinese_chatbot_corpus"&gt;https://github.com/codemayq/chinese_chatbot_corpus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/candlewill/Dialog_Corpus"&gt;https://github.com/candlewill/Dialog_Corpus&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-1使用场景-百度公开课" class="anchor" aria-hidden="true" href="#1使用场景-百度公开课"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.使用场景 （百度公开课）&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;第一部分 入门介绍&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;1.) &lt;a href="/docs/nlp/1.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D.md"&gt;自然语言处理入门介绍&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;第二部分 机器翻译&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;2.) &lt;a href="/docs/nlp/2.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md"&gt;机器翻译&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;第三部分 篇章分析&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;3.1.) &lt;a href="/docs/nlp/3.1.%E7%AF%87%E7%AB%A0%E5%88%86%E6%9E%90-%E5%86%85%E5%AE%B9%E6%A6%82%E8%BF%B0.md"&gt;篇章分析-内容概述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3.2.) &lt;a href="/docs/nlp/3.2.%E7%AF%87%E7%AB%A0%E5%88%86%E6%9E%90-%E5%86%85%E5%AE%B9%E6%A0%87%E7%AD%BE.md"&gt;篇章分析-内容标签&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3.3.) &lt;a href="/docs/nlp/3.3.%E7%AF%87%E7%AB%A0%E5%88%86%E6%9E%90-%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90.md"&gt;篇章分析-情感分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3.4.) &lt;a href="/docs/nlp/3.4.%E7%AF%87%E7%AB%A0%E5%88%86%E6%9E%90-%E8%87%AA%E5%8A%A8%E6%91%98%E8%A6%81.md"&gt;篇章分析-自动摘要&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;第四部分 UNIT-语言理解与交互技术&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;4.) &lt;a href="/docs/nlp/4.UNIT-%E8%AF%AD%E8%A8%80%E7%90%86%E8%A7%A3%E4%B8%8E%E4%BA%A4%E4%BA%92%E6%8A%80%E6%9C%AF.md"&gt;UNIT-语言理解与交互技术&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-应用领域" class="anchor" aria-hidden="true" href="#应用领域"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;应用领域&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-中文分词" class="anchor" aria-hidden="true" href="#中文分词"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;中文分词：&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;构建DAG图&lt;/li&gt;
&lt;li&gt;动态规划查找，综合正反向（正向加权反向输出）求得DAG最大概率路径&lt;/li&gt;
&lt;li&gt;使用了SBME语料训练了一套 HMM + Viterbi 模型，解决未登录词问题&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-1文本分类text-classification" class="anchor" aria-hidden="true" href="#1文本分类text-classification"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.文本分类（Text Classification）&lt;/h4&gt;
&lt;p&gt;文本分类是指标记句子或文档，例如电子邮件垃圾邮件分类和情感分析。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者文本分类数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html" rel="nofollow"&gt;路透社Newswire主题分类&lt;/a&gt;（路透社-21578）。1987年路透社出现的一系列新闻文件，按类别编制索引。&lt;a href="http://trec.nist.gov/data/reuters/reuters.html" rel="nofollow"&gt;另见RCV1，RCV2和TRC2&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ai.stanford.edu/~amaas/data/sentiment" rel="nofollow"&gt;IMDB电影评论情感分类（斯坦福）&lt;/a&gt;。来自网站imdb.com的一系列电影评论及其积极或消极的情绪。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.cornell.edu/people/pabo/movie-review-data/" rel="nofollow"&gt;新闻组电影评论情感分类（康奈尔）&lt;/a&gt;。来自网站imdb.com的一系列电影评论及其积极或消极的情绪。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有关更多信息，请参阅帖子：
&lt;a href="http://ana.cachopo.org/datasets-for-single-label-text-categorization" rel="nofollow"&gt;单标签文本分类的数据集&lt;/a&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;情感分析&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;比赛地址: &lt;a href="https://www.kaggle.com/c/word2vec-nlp-tutorial" rel="nofollow"&gt;https://www.kaggle.com/c/word2vec-nlp-tutorial&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;方案一(0.86)：WordCount + 朴素 Bayes&lt;/li&gt;
&lt;li&gt;方案二(0.94)：LDA + 分类模型（knn/决策树/逻辑回归/svm/xgboost/随机森林）
&lt;ul&gt;
&lt;li&gt;a) 决策树效果不是很好，这种连续特征不太适合的&lt;/li&gt;
&lt;li&gt;b) 通过参数调整 200 个topic，信息量保存效果较优（计算主题）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;方案三(0.72)：word2vec + CNN
&lt;ul&gt;
&lt;li&gt;说实话：没有一个好的机器，是调不出来一个好的结果 (: 逃&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;通过AUC 来评估模型的效果&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-2语言模型language-modeling" class="anchor" aria-hidden="true" href="#2语言模型language-modeling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2.语言模型（Language Modeling）&lt;/h4&gt;
&lt;p&gt;语言建模涉及开发一种统计模型，用于预测句子中的下一个单词或一个单词中的下一个单词。它是语音识别和机器翻译等任务中的前置任务。&lt;/p&gt;
&lt;p&gt;它是语音识别和机器翻译等任务中的前置任务。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者语言建模数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.gutenberg.org/" rel="nofollow"&gt;古腾堡项目&lt;/a&gt;，一系列免费书籍，可以用纯文本检索各种语言。&lt;/li&gt;
&lt;li&gt;还有更多正式的语料库得到了很好的研究; 例如：
&lt;a href="https://en.wikipedia.org/wiki/Brown_Corpus" rel="nofollow"&gt;布朗大学现代美国英语标准语料库&lt;/a&gt;。大量英语单词样本。
&lt;a href="https://github.com/ciprian-chelba/1-billion-word-language-modeling-benchmark"&gt;谷歌10亿字语料库&lt;/a&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;新词发现&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;中文分词新词发现&lt;/li&gt;
&lt;li&gt;python3利用互信息和左右信息熵的中文分词新词发现&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanzecheng/Chinese_segment_augment"&gt;https://github.com/zhanzecheng/Chinese_segment_augment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;句子相似度识别&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;项目地址: &lt;a href="https://www.kaggle.com/c/quora-question-pairs" rel="nofollow"&gt;https://www.kaggle.com/c/quora-question-pairs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;解决方案: word2vec + Bi-GRU&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;文本纠错&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;bi-gram + levenshtein&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-3图像字幕image-captioning" class="anchor" aria-hidden="true" href="#3图像字幕image-captioning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3.图像字幕（Image Captioning）&lt;/h4&gt;
&lt;p&gt;mage字幕是为给定图像生成文本描述的任务。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者图像字幕数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://mscoco.org/dataset/#overview" rel="nofollow"&gt;上下文中的公共对象（COCO）&lt;/a&gt;。包含超过12万张带描述的图像的集合&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nlp.cs.illinois.edu/HockenmaierGroup/8k-pictures.html" rel="nofollow"&gt;Flickr 8K&lt;/a&gt;。从flickr.com获取的8千个描述图像的集合。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://shannon.cs.illinois.edu/DenotationGraph/" rel="nofollow"&gt;Flickr 30K&lt;/a&gt;。从flickr.com获取的3万个描述图像的集合。
欲了解更多，请看帖子：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="http://sidgan.me/technical/2016/01/09/Exploring-Datasets" rel="nofollow"&gt;探索图像字幕数据集，2016年&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-4机器翻译machine-translation" class="anchor" aria-hidden="true" href="#4机器翻译machine-translation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4.机器翻译（Machine Translation）&lt;/h4&gt;
&lt;p&gt;机器翻译是将文本从一种语言翻译成另一种语言的任务。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者机器翻译数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.isi.edu/natural-language/download/hansard/" rel="nofollow"&gt;加拿大第36届议会的协调国会议员&lt;/a&gt;。成对的英语和法语句子。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.statmt.org/europarl/" rel="nofollow"&gt;欧洲议会诉讼平行语料库1996-2011&lt;/a&gt;。句子对一套欧洲语言。
有大量标准数据集用于年度机器翻译挑战; 看到：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="http://www.statmt.org/" rel="nofollow"&gt;统计机器翻译&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;机器翻译&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Encoder + Decoder(Attention)&lt;/li&gt;
&lt;li&gt;参考案例: &lt;a href="http://pytorch.apachecn.org/cn/tutorials/intermediate/seq2seq_translation_tutorial.html" rel="nofollow"&gt;http://pytorch.apachecn.org/cn/tutorials/intermediate/seq2seq_translation_tutorial.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-5问答系统question-answering" class="anchor" aria-hidden="true" href="#5问答系统question-answering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;5.问答系统（Question Answering）&lt;/h4&gt;
&lt;p&gt;问答是一项任务，其中提供了一个句子或文本样本，从中提出问题并且必须回答问题。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者问题回答数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/" rel="nofollow"&gt;斯坦福问题回答数据集（SQuAD）&lt;/a&gt;。回答有关维基百科文章的问题。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/deepmind/rc-data"&gt;Deepmind问题回答语料库&lt;/a&gt;。从每日邮报回答有关新闻文章的问题。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmcauley.ucsd.edu/data/amazon/qa/" rel="nofollow"&gt;亚马逊问答数据&lt;/a&gt;。回答有关亚马逊产品的问题。
有关更多信息，请参阅帖子：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="https://www.quora.com/Datasets-How-can-I-get-corpus-of-a-question-answering-website-like-Quora-or-Yahoo-Answers-or-Stack-Overflow-for-analyzing-answer-quality" rel="nofollow"&gt;数据集：我如何获得问答网站的语料库，如Quora或Yahoo Answers或Stack Overflow来分析答案质量？&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-6语音识别speech-recognition" class="anchor" aria-hidden="true" href="#6语音识别speech-recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;6.语音识别（Speech Recognition）&lt;/h4&gt;
&lt;p&gt;语音识别是将口语的音频转换为人类可读文本的任务。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者语音识别数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://catalog.ldc.upenn.edu/LDC93S1" rel="nofollow"&gt;TIMIT声学 - 语音连续语音语料库&lt;/a&gt;。不是免费的，但因其广泛使用而上市。口语美国英语和相关的转录。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://voxforge.org/" rel="nofollow"&gt;VoxForge&lt;/a&gt;。用于构建用于语音识别的开源数据库的项目。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.openslr.org/12/" rel="nofollow"&gt;LibriSpeech ASR语料库&lt;/a&gt;。从LibriVox收集的大量英语有声读物。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-7自动文摘document-summarization" class="anchor" aria-hidden="true" href="#7自动文摘document-summarization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;7.自动文摘（Document Summarization）&lt;/h4&gt;
&lt;p&gt;文档摘要是创建较大文档的简短有意义描述的任务。&lt;/p&gt;
&lt;p&gt;下面是一些很好的初学者文档摘要数据集。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://archive.ics.uci.edu/ml/datasets/Legal+Case+Reports" rel="nofollow"&gt;法律案例报告数据集&lt;/a&gt;。收集了4000份法律案件及其摘要。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www-nlpir.nist.gov/related_projects/tipster_summac/cmp_lg.html" rel="nofollow"&gt;TIPSTER文本摘要评估会议语料库&lt;/a&gt;。收集了近200份文件及其摘要。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://catalog.ldc.upenn.edu/LDC2002T31" rel="nofollow"&gt;英语新闻文本的AQUAINT语料库&lt;/a&gt;。不是免费的，而是广泛使用的。新闻文章的语料库。
欲了解更多信息：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="http://www-nlpir.nist.gov/projects/duc/data.html" rel="nofollow"&gt;文档理解会议（DUC）任务&lt;/a&gt;。
&lt;a href="https://www.quora.com/Where-can-I-find-good-data-sets-for-text-summarization" rel="nofollow"&gt;在哪里可以找到用于文本摘要的良好数据集？&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;命名实体识别&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Bi-LSTM CRF&lt;/li&gt;
&lt;li&gt;参考案例: &lt;a href="http://pytorch.apachecn.org/cn/tutorials/beginner/nlp/advanced_tutorial.html" rel="nofollow"&gt;http://pytorch.apachecn.org/cn/tutorials/beginner/nlp/advanced_tutorial.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CRF推荐文档: &lt;a href="https://www.jianshu.com/p/55755fc649b1" rel="nofollow"&gt;https://www.jianshu.com/p/55755fc649b1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;文本摘要&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;抽取式&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;word2vec + textrank&lt;/li&gt;
&lt;li&gt;word2vec推荐文档: &lt;a href="https://www.zhihu.com/question/44832436/answer/266068967" rel="nofollow"&gt;https://www.zhihu.com/question/44832436/answer/266068967&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;textrank推荐文档: &lt;a href="https://blog.csdn.net/BaiHuaXiu123/article/details/77847232" rel="nofollow"&gt;https://blog.csdn.net/BaiHuaXiu123/article/details/77847232&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-graph图计算慢慢更新" class="anchor" aria-hidden="true" href="#graph图计算慢慢更新"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Graph图计算【慢慢更新】&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;数据集: &lt;a href="data/nlp/graph"&gt;data/nlp/graph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;学习资料: spark graphX实战.pdf 【文件太大不方便提供，自己百度】&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-知识图谱" class="anchor" aria-hidden="true" href="#知识图谱"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;知识图谱&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;知识图谱，我只认 &lt;a href="https://www.zhihu.com/people/simmerchan" rel="nofollow"&gt;SimmerChan&lt;/a&gt;: &lt;a href="https://zhuanlan.zhihu.com/knowledgegraph" rel="nofollow"&gt;【知识图谱-给AI装个大脑】&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;说实话，我是看这博主老哥写的博客长大的，写的真的是深入浅出。我很喜欢，所以就分享给大家，希望你们也喜欢。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-进一步阅读" class="anchor" aria-hidden="true" href="#进一步阅读"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;进一步阅读&lt;/h3&gt;
&lt;p&gt;如果您希望更深入，本节提供了其他数据集列表。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#Text_data" rel="nofollow"&gt;维基百科研究中使用的文本数据集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/Datasets-What-are-the-major-text-corpora-used-by-computational-linguists-and-natural-language-processing-researchers-and-what-are-the-characteristics-biases-of-each-corpus" rel="nofollow"&gt;数据集：计算语言学家和自然语言处理研究人员使用的主要文本语料库是什么？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://nlp.stanford.edu/links/statnlp.html#Corpora" rel="nofollow"&gt;斯坦福统计自然语言处理语料库&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/niderhoff/nlp-datasets"&gt;按字母顺序排列的NLP数据集列表&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nltk.org/nltk_data/" rel="nofollow"&gt;该机构NLTK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://deeplearning4j.org/opendata" rel="nofollow"&gt;在DL4J上打开深度学习数据&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/caesar0301/awesome-public-datasets#natural-language"&gt;NLP数据集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;国内开放数据集: &lt;a href="https://bosonnlp.com/dev/resource" rel="nofollow"&gt;https://bosonnlp.com/dev/resource&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-项目负责人" class="anchor" aria-hidden="true" href="#项目负责人"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目负责人&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第一期 (2017-02-27)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jiangzhonglian"&gt;@片刻&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wangyangting"&gt;@那伊抹微笑&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chenyyx"&gt;@瑶妹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/report/2017-04-08_%E7%AC%AC%E4%B8%80%E6%9C%9F%E7%9A%84%E6%80%BB%E7%BB%93.md"&gt;2017-04-08_第一期的总结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第二期 (2017-08-14)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jiangzhonglian"&gt;@片刻&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wangyangting"&gt;@那伊抹微笑&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chenyyx"&gt;@瑶妹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mikechengwei"&gt;@Mike&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第三期 (2018-04-16)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-项目贡献者" class="anchor" aria-hidden="true" href="#项目贡献者"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目贡献者&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第一期 (2017-02-27)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/geekidentity"&gt;@侯法超&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/hello19883"&gt;@hello19883&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sheepmen"&gt;@徐鑫&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/highfei2011"&gt;@ibe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第二期 (2017-08-14)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/LeeMoonCh"&gt;@Arithmetic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/caopeirui"&gt;@Veyron C&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Cugtyt"&gt;@Cugtyt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/hey-bruce"&gt;@BBruceyuan&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第三期 (2018-04-16)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-群管理员换届" class="anchor" aria-hidden="true" href="#群管理员换届"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;群管理员换届&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/chenyyx"&gt;@瑶妹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wizardforcel"&gt;@飞龙&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jiangzhonglian"&gt;@片刻&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Watermelon233"&gt;@伪文艺.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wangyangting"&gt;@那伊抹微笑&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@LAMDA-健忘症&lt;/a&gt; 永久留任-非常感谢对群的贡献&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第一届 (2017-09-01)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=""&gt;@易漠&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mikechengwei"&gt;@Mike&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@Books&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@李孟禹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@张假飞&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@Glassy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@红色石头&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@微光同尘&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第二届 (2018-07-04)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=""&gt;@张假飞&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@李孟禹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@小明教主&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@平淡的天&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@凌少skierゞ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;@じ☆νЁ坐看云起&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;古柳-DesertsX&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;woodchuck&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;自由精灵&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;楚盟&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;99杆清台&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;时空守望者@&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;只想发论文的渣渣&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;目标: ml劝退专家&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第三届 (2019-01-01)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=""&gt;只会喊666的存在&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;codefun007.xyz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;荼靡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;大鱼&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;青鸟&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;古柳-DesertsX&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Edge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Alluka&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;不发篇paper不改名片&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;FontTian&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Bigjing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;仁 礼 智 爱&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;可啪的小乖受&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;老古董&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;时空守望者&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;我好菜啊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Messi 19&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;萌Jay小公举&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Ml 第四届 (2019-06-01)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=""&gt;佛学爱好者&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;楚盟&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;codefun007.xyz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;大鱼-群花-声优&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;大海&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Edge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;if only&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;李孟禹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;平静&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;任务做不完&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;仁礼智爱&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;园时空守望者@&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;坐看云起&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;阿花君霸占路人&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;烦焖鸡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;古柳-DesertsX&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;青鸟(服务员)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;小明教主&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;zhiqing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;SrL.z&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;欢迎贡献者不断的追加&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-免责声明---只供学习参考" class="anchor" aria-hidden="true" href="#免责声明---只供学习参考"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;免责声明 - 【只供学习参考】&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ApacheCN 纯粹出于学习目的与个人兴趣翻译本书&lt;/li&gt;
&lt;li&gt;ApacheCN 保留对此版本译文的署名权及其它相关权利&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-协议" class="anchor" aria-hidden="true" href="#协议"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;协议&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;以各项目协议为准。&lt;/li&gt;
&lt;li&gt;ApacheCN 账号下没有协议的项目，一律视为 &lt;a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="nofollow"&gt;CC BY-NC-SA 4.0&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-资料来源" class="anchor" aria-hidden="true" href="#资料来源"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;资料来源:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;【比赛收集平台】: &lt;a href="https://github.com/iphysresearch/DataSciComp"&gt;https://github.com/iphysresearch/DataSciComp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pbharrin/machinelearninginaction"&gt;https://github.com/pbharrin/machinelearninginaction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://machinelearningmastery.com/datasets-natural-language-processing" rel="nofollow"&gt;https://machinelearningmastery.com/datasets-natural-language-processing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-感谢信" class="anchor" aria-hidden="true" href="#感谢信"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;感谢信&lt;/h2&gt;
&lt;p&gt;最近无意收到群友推送的链接，发现得到大佬高度的认可，并在热心的推广&lt;/p&gt;
&lt;p&gt;在此感谢:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/org/liang-zi-wei-48" rel="nofollow"&gt;量子位&lt;/a&gt;: &lt;a href="https://www.zhihu.com/question/20472776/answer/691646493" rel="nofollow"&gt;https://www.zhihu.com/question/20472776/answer/691646493&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;人工智能前沿讲习: &lt;a href="https://mp.weixin.qq.com/s/f2dqulxOPkt7k5hqPsydyQ" rel="nofollow"&gt;https://mp.weixin.qq.com/s/f2dqulxOPkt7k5hqPsydyQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-赞助我们" class="anchor" aria-hidden="true" href="#赞助我们"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;赞助我们&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2814efae28977e977f631af3a30acfe4e9089dd9/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f61626f75742f646f6e6174652e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/2814efae28977e977f631af3a30acfe4e9089dd9/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f61626f75742f646f6e6174652e6a7067" alt="微信&amp;amp;支付宝" data-canonical-src="http://data.apachecn.org/img/about/donate.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;特别赞助商(欢迎“私聊”赞助)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td align="center" valign="middle"&gt;
            &lt;a href="https://coding.net/?utm_source=ApacheCN&amp;amp;utm_medium=banner&amp;amp;utm_campaign=march2019" rel="nofollow"&gt;
              &lt;img width="1080" src="https://camo.githubusercontent.com/8d33a9d36a6822434ce78147cdb7cb41aba56a02/687474703a2f2f646174612e617061636865636e2e6f72672f696d672f5370656369616c53706f6e736f72732f436f64696e674e65742e706e67" data-canonical-src="http://data.apachecn.org/img/SpecialSponsors/CodingNet.png" style="max-width:100%;"&gt;
            &lt;/a&gt;
          &lt;/td&gt;
      &lt;/tr&gt;&lt;/tbody&gt;
&lt;/table&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>apachecn</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>notadamking/tensortrade #5 in Python, This week</title><link>https://github.com/notadamking/tensortrade</link><description>&lt;p&gt;&lt;i&gt;An open source reinforcement learning framework for training, evaluating, and deploying robust trading agents.&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensortrade-trade-efficiently-with-reinforcement-learning" class="anchor" aria-hidden="true" href="#tensortrade-trade-efficiently-with-reinforcement-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://towardsdatascience.com/trade-smarter-w-reinforcement-learning-a5e91163f315?source=friends_link&amp;amp;sk=ea3afd0a305141eb9147be4718826dfb" rel="nofollow"&gt;TensorTrade: Trade Efficiently with Reinforcement Learning&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/notadamking/tensortrade" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/41e140102a87bca237e00545bde70be469f5494f/68747470733a2f2f7472617669732d63692e636f6d2f6e6f746164616d6b696e672f74656e736f7274726164652e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/notadamking/tensortrade.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://tensortrade.org" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1507bfd72bf32b8fc46754503d5d8dc464c023fe/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f74656e736f7274726164652f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/tensortrade/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/25504145e91ed8726d8ce49c5ab2ad2a4bdfb098/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6e6f746164616d6b696e672f74656e736f7274726164652e7376673f636f6c6f723d627269676874677265656e" alt="Apache License" data-canonical-src="https://img.shields.io/github/license/notadamking/tensortrade.svg?color=brightgreen" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://discord.gg/ZZ7BGWh" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/11bef0bdfed0a6d99ad8c933cfa835cef46a755b/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3539323434363632343838323439313430322e7376673f636f6c6f723d627269676874677265656e" alt="Discord" data-canonical-src="https://img.shields.io/discord/592446624882491402.svg?color=brightgreen" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.python.org/downloads/release/python-360/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c2ed0c1d8ac1a5ebbe7281923d42b50b7962912c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d626c75652e737667" alt="Python 3.6" data-canonical-src="https://img.shields.io/badge/python-3.6-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;div align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/notadamking/tensortrade/blob/master/docs/source/_static/logo.jpg"&gt;&lt;img src="https://github.com/notadamking/tensortrade/raw/master/docs/source/_static/logo.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;TensorTrade is still in Alpha, meaning it should not be used in production systems yet, and it may contain bugs.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;TensorTrade is an open source Python framework for building, training, evaluating, and deploying robust trading algorithms using reinforcement learning. The framework focuses on being highly composable and extensible, to allow the system to scale from simple trading strategies on a single CPU, to complex investment strategies run on a distribution of HPC machines.&lt;/p&gt;
&lt;p&gt;Under the hood, the framework uses many of the APIs from existing machine learning libraries to maintain high quality data pipelines and learning models. One of the main goals of TensorTrade is to enable fast experimentation with algorithmic trading strategies, by leveraging the existing tools and pipelines provided by &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;, &lt;code&gt;gym&lt;/code&gt;, &lt;code&gt;keras&lt;/code&gt;, and &lt;code&gt;tensorflow&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Every piece of the framework is split up into re-usable components, allowing you to take advantage of the general use components built by the community, while keeping your proprietary features private. The aim is to simplify the process of testing and deploying robust trading agents using deep reinforcement learning, to allow you and I to focus on creating profitable strategies.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The goal of this framework is to enable fast experimentation, while maintaining production-quality data pipelines.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Read &lt;a href="http://tensortrade.org" rel="nofollow"&gt;the documentation&lt;/a&gt; or walk through &lt;a href="https://towardsdatascience.com/trade-smarter-w-reinforcement-learning-a5e91163f315?source=friends_link&amp;amp;sk=ea3afd0a305141eb9147be4718826dfb" rel="nofollow"&gt;the tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-guiding-principles" class="anchor" aria-hidden="true" href="#guiding-principles"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Guiding principles&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Inspired by &lt;a href="https://github.com/keras-team/keras"&gt;Keras' guiding principles&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;User friendliness.&lt;/strong&gt; TensorTrade is an API designed for human beings, not machines. It puts user experience front and center. TensorTrade follows best practices for reducing cognitive load: it offers consistent &amp;amp; simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear and actionable feedback upon user error.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Modularity.&lt;/strong&gt; A trading environment is a conglomeration of fully configurable modules that can be plugged together with as few restrictions as possible. In particular, instrument exchanges, feature pipelines, action strategies, reward strategies, trading agents, and performance reports are all standalone modules that you can combine to create new trading environments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Easy extensibility.&lt;/strong&gt; New modules are simple to add (as new classes and functions), and existing modules provide ample examples. To be able to easily create new modules allows for total expressiveness, making TensorTrade suitable for advanced research and production use.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-tensortrade-hall-of-fame" class="anchor" aria-hidden="true" href="#tensortrade-hall-of-fame"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorTrade Hall of Fame&lt;/h2&gt;
&lt;p&gt;TensorTrade is entirely community funded. We appreciate all of our great sponsors! If you would like to be featured on our Hall of Fame, or sponsor the framework in any other way, visit the &lt;a href="#sponsorship"&gt;Sponsorship section below&lt;/a&gt;.&lt;/p&gt;
&lt;a href="https://capfol.io" rel="nofollow"&gt;
  &lt;img alt="Capfolio" src="https://user-images.githubusercontent.com/14098106/67627791-fc291d80-f817-11e9-8fc5-0f0a3d72c646.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;You can get started testing on Google Colab or your local machine, by viewing our &lt;a href="https://github.com/notadamking/tensortrade/tree/master/examples"&gt;many examples&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;TensorTrade requires Python &amp;gt;= 3.6 for all functionality to work as expected.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install -r requirements.txt&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h2&gt;
&lt;p&gt;To run the commands below, ensure Docker is installed. Visit &lt;a href="https://docs.docker.com/install/" rel="nofollow"&gt;https://docs.docker.com/install/&lt;/a&gt; for more information.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-run-jupyter-notebooks" class="anchor" aria-hidden="true" href="#run-jupyter-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Run Jupyter Notebooks&lt;/h3&gt;
&lt;p&gt;To run a jupyter notebook in your browser, execute the following command and visit the &lt;code&gt;http://127.0.0.1:8888/?token=...&lt;/code&gt; link printed to the command line.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;make run-notebook&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-build-documentation" class="anchor" aria-hidden="true" href="#build-documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Build Documentation&lt;/h3&gt;
&lt;p&gt;To build the HTML documentation, execute the following command.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;make run-docs&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-run-test-suite" class="anchor" aria-hidden="true" href="#run-test-suite"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Run Test Suite&lt;/h3&gt;
&lt;p&gt;To run the test suite, execute the following command.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;make run-tests&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-support" class="anchor" aria-hidden="true" href="#support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support&lt;/h2&gt;
&lt;p&gt;You can ask questions and join the development discussion:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On the &lt;a href="https://discord.gg/ZZ7BGWh" rel="nofollow"&gt;TensorTrade Discord server&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;On the &lt;a href="https://gitter.im/tensortrade-framework/community" rel="nofollow"&gt;TensorTrade Gitter&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can also post &lt;strong&gt;bug reports and feature requests&lt;/strong&gt; in &lt;a href="https://github.com/notadamking/tensortrade/issues"&gt;GitHub issues&lt;/a&gt;. Make sure to read &lt;a href="https://github.com/notadamking/tensortrade/blob/master/CONTRIBUTING.md"&gt;our guidelines&lt;/a&gt; first.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sponsorship" class="anchor" aria-hidden="true" href="#sponsorship"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sponsorship&lt;/h2&gt;
&lt;p&gt;If you would like to support this project financially, there are a few ways you can contribute. Your contributions are greatly appreciated and help to keep TensorTrade maintained and always improving.&lt;/p&gt;
&lt;p&gt;Github Sponsors: &lt;a href="https://github.com/sponsors/notadamking"&gt;https://github.com/sponsors/notadamking&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;All Github Sponsors donations are matched 1:1 by Github up to $5,000!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;BTC Address: &lt;code&gt;1Lc47bhYvdyKGk1qN8oBHdYQTkbFLL3PFw&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;ETH Address: &lt;code&gt;0x9907A0cF64Ec9Fbf6Ed8FD4971090DE88222a9aC&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributors&lt;/h2&gt;
&lt;p&gt;Contributions are encouraged and welcomed. This project is meant to grow as the community around it grows. Let me know on Discord in the #suggestions channel if there is anything that you would like to see in the future, or if there is anything you feel is missing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Working on your first Pull Request?&lt;/strong&gt; You can learn how from this &lt;em&gt;free&lt;/em&gt; series &lt;a href="https://egghead.io/series/how-to-contribute-to-an-open-source-project-on-github" rel="nofollow"&gt;How to Contribute to an Open Source Project on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/11e0e3968f7aad0c841cdab9a5d746dd02b9c394/68747470733a2f2f636f6e7472696275746f72732d696d672e66697265626173656170702e636f6d2f696d6167653f7265706f3d6e6f746164616d6b696e672f74656e736f727472616465"&gt;&lt;img src="https://camo.githubusercontent.com/11e0e3968f7aad0c841cdab9a5d746dd02b9c394/68747470733a2f2f636f6e7472696275746f72732d696d672e66697265626173656170702e636f6d2f696d6167653f7265706f3d6e6f746164616d6b696e672f74656e736f727472616465" alt="https://github.com/notadamking/tensortrade/graphs/contributors" data-canonical-src="https://contributors-img.firebaseapp.com/image?repo=notadamking/tensortrade" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>notadamking</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>ownthink/KnowledgeGraphData #6 in Python, This week</title><link>https://github.com/ownthink/KnowledgeGraphData</link><description>&lt;p&gt;&lt;i&gt;史上最大规模1.4亿中文知识图谱开源下载&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1 align="center"&gt;&lt;a id="user-content-史上最大规模14亿中文知识图谱开源下载" class="anchor" aria-hidden="true" href="#史上最大规模14亿中文知识图谱开源下载"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;史上最大规模1.4亿中文知识图谱开源下载&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/kg.png"&gt;&lt;img src="img/kg.png" alt="知识图谱" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;知识就是力量，知识图谱是人工智能新时代的产物，简单地说知识图谱就是通过关联关系将知识组成网状的结构，然后我们的人工智能可以通过这个图谱来认识其代表的这一个现实事件，这个事件可以是现实，也可以是虚构的。&lt;/p&gt;
&lt;p&gt;知识图谱可以应用于机器人问答系统，知识推荐等等，下图为知识图谱在机器人上的应用。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/bot.png"&gt;&lt;img src="img/bot.png" alt="机器人" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本次ownthink开源了史上最大规模的中文知识图谱，数据是以（实体、属性、值），（实体、关系、实体）混合的形式组织，数据格式采用csv格式，下载链接见文末。&lt;/p&gt;
&lt;p&gt;解压后查看知识图谱规模：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ wc -l ownthink_v2.csv
140919781 ownthink_v2.csv&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;查看知识图谱数据：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ head ownthink_v2.csv
实体,属性,值
胶饴,描述,别名: 饴糖、畅糖、畅、软糖。
词条,描述,词条（拼音：cí tiáo）也叫词目，是辞书学用语，指收列的词语及其释文。
词条,标签,文化
红色食品,描述,红色食品是指食品为红色、橙红色或棕红色的食品。
红色食品,中文名,红色食品
红色食品,是否含防腐剂,否
红色食品,主要食用功效,预防感冒，缓解疲劳
红色食品,适宜人群,全部人群
红色食品,用途,增强表皮细胞再生和防止皮肤衰老&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;使用python进行读取测试：&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; sys
&lt;span class="pl-k"&gt;import&lt;/span&gt; csv

&lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-c1"&gt;open&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ownthink_v2.csv&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;r&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;encoding&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;utf8&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-k"&gt;as&lt;/span&gt; fin:
  reader &lt;span class="pl-k"&gt;=&lt;/span&gt; csv.reader(fin)
  &lt;span class="pl-k"&gt;for&lt;/span&gt; index, read &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;enumerate&lt;/span&gt;(reader):
    &lt;span class="pl-c1"&gt;print&lt;/span&gt;(read)
    
    &lt;span class="pl-k"&gt;if&lt;/span&gt; index &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;:
      sys.exit(&lt;span class="pl-c1"&gt;0&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;运行以上脚本输出结果：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;实体&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;属性&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;值&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;胶饴&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;描述&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;别名: 饴糖、畅糖、畅、软糖。&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;词条&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;描述&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;词条（拼音：cí tiáo）也叫词目，是辞书学用语，指收列的词语及其释文。&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;词条&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;标签&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;文化&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;描述&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品是指食品为红色、橙红色或棕红色的食品。&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;中文名&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;是否含防腐剂&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;否&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;主要食用功效&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;预防感冒，缓解疲劳&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;适宜人群&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;全部人群&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;用途&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;增强表皮细胞再生和防止皮肤衰老&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;标签&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;非科学&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;红色食品&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;标签&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;生活&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;数据下载方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;关注思知机器人回复【数据下载】获取下载链接&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;百度网盘（链接: &lt;a href="https://pan.baidu.com/s/1LZjs9Dsta0yD9NH-1y0sAw" rel="nofollow"&gt;https://pan.baidu.com/s/1LZjs9Dsta0yD9NH-1y0sAw&lt;/a&gt; 提取码: 3hpp ）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注：解压密码是：&lt;a href="https://www.ownthink.com/" rel="nofollow"&gt;https://www.ownthink.com/&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ownthink</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>vinta/awesome-python #7 in Python, This week</title><link>https://github.com/vinta/awesome-python</link><description>&lt;p&gt;&lt;i&gt;A curated list of awesome Python frameworks, libraries, software and resources&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-awesome-python-" class="anchor" aria-hidden="true" href="#awesome-python-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Awesome Python &lt;a href="https://github.com/sindresorhus/awesome"&gt;&lt;img src="https://camo.githubusercontent.com/13c4e50d88df7178ae1882a203ed57b641674f94/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667" alt="Awesome" data-canonical-src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;A curated list of awesome Python frameworks, libraries, software and resources.&lt;/p&gt;
&lt;p&gt;Inspired by &lt;a href="https://github.com/ziadoz/awesome-php"&gt;awesome-php&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#awesome-python"&gt;Awesome Python&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#admin-panels"&gt;Admin Panels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#algorithms-and-design-patterns"&gt;Algorithms and Design Patterns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#audio"&gt;Audio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#authentication"&gt;Authentication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#build-tools"&gt;Build Tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#built-in-classes-enhancement"&gt;Built-in Classes Enhancement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#caching"&gt;Caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#chatops-tools"&gt;ChatOps Tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cms"&gt;CMS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#code-analysis"&gt;Code Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#command-line-interface-development"&gt;Command-line Interface Development&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#command-line-tools"&gt;Command-line Tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#compatibility"&gt;Compatibility&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#computer-vision"&gt;Computer Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#concurrency-and-parallelism"&gt;Concurrency and Parallelism&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cryptography"&gt;Cryptography&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data-analysis"&gt;Data Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data-validation"&gt;Data Validation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data-visualization"&gt;Data Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#database"&gt;Database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#database-drivers"&gt;Database Drivers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#date-and-time"&gt;Date and Time&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#debugging-tools"&gt;Debugging Tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#deep-learning"&gt;Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#devops-tools"&gt;DevOps Tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#distributed-computing"&gt;Distributed Computing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#distribution"&gt;Distribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#downloader"&gt;Downloader&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#e-commerce"&gt;E-commerce&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#editor-plugins-and-ides"&gt;Editor Plugins and IDEs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#email"&gt;Email&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#environment-management"&gt;Environment Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#files"&gt;Files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#foreign-function-interface"&gt;Foreign Function Interface&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#forms"&gt;Forms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#functional-programming"&gt;Functional Programming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#game-development"&gt;Game Development&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#geolocation"&gt;Geolocation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#gui-development"&gt;GUI Development&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#hardware"&gt;Hardware&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#html-manipulation"&gt;HTML Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#http-clients"&gt;HTTP Clients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#image-processing"&gt;Image Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#implementations"&gt;Implementations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#interactive-interpreter"&gt;Interactive Interpreter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#internationalization"&gt;Internationalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#job-scheduler"&gt;Job Scheduler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#logging"&gt;Logging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#machine-learning"&gt;Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#miscellaneous"&gt;Miscellaneous&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#natural-language-processing"&gt;Natural Language Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#network-virtualization"&gt;Network Virtualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#networking"&gt;Networking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#news-feed"&gt;News Feed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#orm"&gt;ORM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#package-management"&gt;Package Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#package-repositories"&gt;Package Repositories&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#permissions"&gt;Permissions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#processes"&gt;Processes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#queue"&gt;Queue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#recommender-systems"&gt;Recommender Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#restful-api"&gt;RESTful API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#robotics"&gt;Robotics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rpc-servers"&gt;RPC Servers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#science"&gt;Science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#search"&gt;Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#serialization"&gt;Serialization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#serverless-frameworks"&gt;Serverless Frameworks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#specific-formats-processing"&gt;Specific Formats Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#static-site-generator"&gt;Static Site Generator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tagging"&gt;Tagging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#template-engine"&gt;Template Engine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#testing"&gt;Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#text-processing"&gt;Text Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#third-party-apis"&gt;Third-party APIs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#url-manipulation"&gt;URL Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#video"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#web-asset-management"&gt;Web Asset Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#web-content-extracting"&gt;Web Content Extracting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#web-crawling"&gt;Web Crawling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#web-frameworks"&gt;Web Frameworks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#websocket"&gt;WebSocket&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wsgi-servers"&gt;WSGI Servers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#services"&gt;Services&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#code-quality"&gt;Code Quality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#continuous-integration"&gt;Continuous Integration&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#resources"&gt;Resources&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#podcasts"&gt;Podcasts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#twitter"&gt;Twitter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#websites"&gt;Websites&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#weekly"&gt;Weekly&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-admin-panels" class="anchor" aria-hidden="true" href="#admin-panels"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Admin Panels&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for administrative interfaces.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ajenti/ajenti"&gt;ajenti&lt;/a&gt; - The admin panel your servers deserve.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://grappelliproject.com/" rel="nofollow"&gt;django-grappelli&lt;/a&gt; - A jazzy skin for the Django Admin-Interface.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/geex-arts/django-jet"&gt;django-jet&lt;/a&gt; - Modern responsive template for the Django admin interface with improved functionality.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://djangosuit.com/" rel="nofollow"&gt;django-suit&lt;/a&gt; - Alternative Django Admin-Interface (free only for Non-commercial use).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sshwsfc/xadmin"&gt;django-xadmin&lt;/a&gt; - Drop-in replacement of Django admin comes with lots of goodies.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jet-admin/jet-bridge"&gt;jet-bridge&lt;/a&gt; - Admin panel framework for any application with nice UI (ex Jet Django)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/flask-admin/flask-admin"&gt;flask-admin&lt;/a&gt; - Simple and extensible administrative interface framework for Flask.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mher/flower"&gt;flower&lt;/a&gt; - Real-time monitor and web admin for Celery.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wooey/wooey"&gt;wooey&lt;/a&gt; - A Django app which creates automatic web UIs for Python scripts.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-algorithms-and-design-patterns" class="anchor" aria-hidden="true" href="#algorithms-and-design-patterns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Algorithms and Design Patterns&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Python implementation of algorithms and design patterns.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/keon/algorithms"&gt;algorithms&lt;/a&gt; - Minimal examples of data structures and algorithms in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tylerlaberge/PyPattyrn"&gt;PyPattyrn&lt;/a&gt; - A simple yet effective library for implementing common design patterns.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/faif/python-patterns"&gt;python-patterns&lt;/a&gt; - A collection of design patterns in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/grantjenks/python-sortedcontainers"&gt;sortedcontainers&lt;/a&gt; - Fast, pure-Python implementation of SortedList, SortedDict, and SortedSet types.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-audio" class="anchor" aria-hidden="true" href="#audio"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Audio&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for manipulating audio and its metadata.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Audio
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/beetbox/audioread"&gt;audioread&lt;/a&gt; - Cross-library (GStreamer + Core Audio + MAD + FFmpeg) audio decoding.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/worldveil/dejavu"&gt;dejavu&lt;/a&gt; - Audio fingerprinting and recognition.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://bspaans.github.io/python-mingus/" rel="nofollow"&gt;mingus&lt;/a&gt; - An advanced music theory and notation package with MIDI file and playback support.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tyiannak/pyAudioAnalysis"&gt;pyAudioAnalysis&lt;/a&gt; - Audio feature extraction, classification, segmentation and applications.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jiaaro/pydub"&gt;pydub&lt;/a&gt; - Manipulate audio with a simple and easy high level interface.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Parisson/TimeSide"&gt;TimeSide&lt;/a&gt; - Open web audio processing framework.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Metadata
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/beetbox/beets"&gt;beets&lt;/a&gt; - A music library manager and &lt;a href="https://musicbrainz.org/" rel="nofollow"&gt;MusicBrainz&lt;/a&gt; tagger.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nicfit/eyeD3"&gt;eyeD3&lt;/a&gt; - A tool for working with audio files, specifically MP3 files containing ID3 metadata.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/quodlibet/mutagen"&gt;mutagen&lt;/a&gt; - A Python module to handle audio metadata.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/devsnd/tinytag"&gt;tinytag&lt;/a&gt; - A library for reading music meta data of MP3, OGG, FLAC and Wave files.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-authentication" class="anchor" aria-hidden="true" href="#authentication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authentication&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for implementing authentications schemes.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OAuth
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/lepture/authlib"&gt;authlib&lt;/a&gt; - JavaScript Object Signing and Encryption draft implementation.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pennersr/django-allauth"&gt;django-allauth&lt;/a&gt; - Authentication app for Django that "just works."&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/evonove/django-oauth-toolkit"&gt;django-oauth-toolkit&lt;/a&gt; - OAuth 2 goodies for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/idan/oauthlib"&gt;oauthlib&lt;/a&gt; - A generic and thorough implementation of the OAuth request-signing logic.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/joestump/python-oauth2"&gt;python-oauth2&lt;/a&gt; - A fully tested, abstract interface to creating OAuth clients and servers.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/omab/python-social-auth"&gt;python-social-auth&lt;/a&gt; - An easy-to-setup social authentication mechanism.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;JWT
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jpadilla/pyjwt"&gt;pyjwt&lt;/a&gt; - JSON Web Token implementation in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mpdavis/python-jose/"&gt;python-jose&lt;/a&gt; - A JOSE implementation in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/davedoesdev/python-jwt"&gt;python-jwt&lt;/a&gt; - A module for generating and verifying JSON Web Tokens.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-build-tools" class="anchor" aria-hidden="true" href="#build-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Build Tools&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Compile software from source code.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.yoctoproject.org/docs/1.6/bitbake-user-manual/bitbake-user-manual.html" rel="nofollow"&gt;BitBake&lt;/a&gt; - A make-like build tool for embedded Linux.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.buildout.org/en/latest/" rel="nofollow"&gt;buildout&lt;/a&gt; - A build system for creating, assembling and deploying applications from multiple parts.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/platformio/platformio-core"&gt;PlatformIO&lt;/a&gt; - A console tool to build code with different development platforms.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pybuilder/pybuilder"&gt;pybuilder&lt;/a&gt; - A continuous build tool written in pure Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.scons.org/" rel="nofollow"&gt;SCons&lt;/a&gt; - A software construction tool.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-built-in-classes-enhancement" class="anchor" aria-hidden="true" href="#built-in-classes-enhancement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Built-in Classes Enhancement&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for enhancing Python built-in classes.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/dataclasses.html" rel="nofollow"&gt;dataclasses&lt;/a&gt; - (Python standard library) Data classes.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/python-attrs/attrs"&gt;attrs&lt;/a&gt; - Replacement for &lt;code&gt;__init__&lt;/code&gt;, &lt;code&gt;__eq__&lt;/code&gt;, &lt;code&gt;__repr__&lt;/code&gt;, etc. boilerplate in class definitions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jab/bidict"&gt;bidict&lt;/a&gt; - Efficient, Pythonic bidirectional map data structures and related functionality..&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cdgriffith/Box"&gt;Box&lt;/a&gt; - Python dictionaries with advanced dot notation access.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/carlosescri/DottedDict"&gt;DottedDict&lt;/a&gt; - A library that provides a method of accessing lists and dicts with a dotted path notation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-cms" class="anchor" aria-hidden="true" href="#cms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CMS&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Content Management Systems.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://wagtail.io/" rel="nofollow"&gt;wagtail&lt;/a&gt; - A Django content management system.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.django-cms.org/en/" rel="nofollow"&gt;django-cms&lt;/a&gt; - An Open source enterprise CMS based on the Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/feincms/feincms"&gt;feincms&lt;/a&gt; - One of the most advanced Content Management Systems built on Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kotti/Kotti"&gt;Kotti&lt;/a&gt; - A high-level, Pythonic web application framework built on Pyramid.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/stephenmcd/mezzanine"&gt;mezzanine&lt;/a&gt; - A powerful, consistent, and flexible content management platform.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://plone.org/" rel="nofollow"&gt;plone&lt;/a&gt; - A CMS built on top of the open source application server Zope.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rochacbruno/quokka"&gt;quokka&lt;/a&gt; - Flexible, extensible, small CMS powered by Flask and MongoDB.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-caching" class="anchor" aria-hidden="true" href="#caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Caching&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for caching data.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/bbangert/beaker"&gt;beaker&lt;/a&gt; - A WSGI middleware for sessions and caching.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/django-cache-machine/django-cache-machine"&gt;django-cache-machine&lt;/a&gt; - Automatic caching and invalidation for Django models.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Suor/django-cacheops"&gt;django-cacheops&lt;/a&gt; - A slick ORM cache with automatic granular event-driven invalidation.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dogpilecache.readthedocs.io/en/latest/" rel="nofollow"&gt;dogpile.cache&lt;/a&gt; - dogpile.cache is next generation replacement for Beaker made by same authors.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/HermesCache/" rel="nofollow"&gt;HermesCache&lt;/a&gt; - Python caching library with tag-based invalidation and dogpile effect prevention.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lericson/pylibmc"&gt;pylibmc&lt;/a&gt; - A Python wrapper around the &lt;a href="https://libmemcached.org/libMemcached.html" rel="nofollow"&gt;libmemcached&lt;/a&gt; interface.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.grantjenks.com/docs/diskcache/" rel="nofollow"&gt;python-diskcache&lt;/a&gt; - SQLite and file backed cache backend with faster lookups than memcached and redis.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-chatops-tools" class="anchor" aria-hidden="true" href="#chatops-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ChatOps Tools&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for chatbot development.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/errbotio/errbot/"&gt;errbot&lt;/a&gt; - The easiest and most popular chatbot to implement ChatOps.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-code-analysis" class="anchor" aria-hidden="true" href="#code-analysis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code Analysis&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Tools of static analysis, linters and code quality checkers. Also see &lt;a href="https://github.com/mre/awesome-static-analysis"&gt;awesome-static-analysis&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Code Analysis
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/coala/coala/"&gt;coala&lt;/a&gt; - Language independent and easily extendable code analysis application.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/scottrogowski/code2flow"&gt;code2flow&lt;/a&gt; - Turn your Python and JavaScript code into DOT flowcharts.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PyCQA/prospector"&gt;prospector&lt;/a&gt; - A tool to analyse Python code.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gak/pycallgraph"&gt;pycallgraph&lt;/a&gt; - A library that visualises the flow (call graph) of your Python application.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Code Linters
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/flake8/" rel="nofollow"&gt;flake8&lt;/a&gt; - A wrapper around &lt;code&gt;pycodestyle&lt;/code&gt;, &lt;code&gt;pyflakes&lt;/code&gt; and McCabe.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/DmytroLitvinov/awesome-flake8-extensions"&gt;awesome-flake8-extensions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.pylint.org/" rel="nofollow"&gt;pylint&lt;/a&gt; - A fully customizable source code analyzer.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/klen/pylama"&gt;pylama&lt;/a&gt; - A code audit tool for Python and JavaScript.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wemake-services/wemake-python-styleguide"&gt;wemake-python-styleguide&lt;/a&gt; - The strictest and most opinionated python linter ever.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Code Formatters
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/python/black"&gt;black&lt;/a&gt; - The uncompromising Python code formatter.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/yapf"&gt;yapf&lt;/a&gt; - Yet another Python code formatter from Google.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Static Type Checkers, also see &lt;a href="https://github.com/typeddjango/awesome-python-typing"&gt;awesome-python-typing&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mypy-lang.org/" rel="nofollow"&gt;mypy&lt;/a&gt; - Check variable types during compile time.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebook/pyre-check"&gt;pyre-check&lt;/a&gt; - Performant type checking.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Static Type Annotations Generators
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Instagram/MonkeyType"&gt;MonkeyType&lt;/a&gt; - A system for Python that generates static type annotations by collecting runtime types&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-command-line-interface-development" class="anchor" aria-hidden="true" href="#command-line-interface-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Command-line Interface Development&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for building command-line applications.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Command-line Application Development
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://builtoncement.com/" rel="nofollow"&gt;cement&lt;/a&gt; - CLI Application Framework for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://click.pocoo.org/dev/" rel="nofollow"&gt;click&lt;/a&gt; - A package for creating beautiful command line interfaces in a composable way.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.openstack.org/developer/cliff/" rel="nofollow"&gt;cliff&lt;/a&gt; - A framework for creating command-line programs with multi-level commands.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/clint"&gt;clint&lt;/a&gt; - Python Command-line Application Tools.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docopt.org/" rel="nofollow"&gt;docopt&lt;/a&gt; - Pythonic command line arguments parser.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/python-fire"&gt;python-fire&lt;/a&gt; - A library for creating command line interfaces from absolutely any Python object.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jonathanslenders/python-prompt-toolkit"&gt;python-prompt-toolkit&lt;/a&gt; - A library for building powerful interactive command lines.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Terminal Rendering
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/peterbrittain/asciimatics"&gt;asciimatics&lt;/a&gt; - A package to create full-screen text UIs (from interactive forms to ASCII animations).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/glamp/bashplotlib"&gt;bashplotlib&lt;/a&gt; - Making basic plots in the terminal.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/colorama/" rel="nofollow"&gt;colorama&lt;/a&gt; - Cross-platform colored terminal text.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tqdm/tqdm"&gt;tqdm&lt;/a&gt; - Fast, extensible progress bar for loops and CLI.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-command-line-tools" class="anchor" aria-hidden="true" href="#command-line-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Command-line Tools&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Useful CLI-based tools for productivity.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Productivity Tools
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/audreyr/cookiecutter"&gt;cookiecutter&lt;/a&gt; - A command-line utility that creates projects from cookiecutters (project templates).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sloria/doitlive"&gt;doitlive&lt;/a&gt; - A tool for live presentations in the terminal.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gleitz/howdoi"&gt;howdoi&lt;/a&gt; - Instant coding answers via the command line.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebook/PathPicker"&gt;PathPicker&lt;/a&gt; - Select files out of bash output.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mooz/percol"&gt;percol&lt;/a&gt; - Adds flavor of interactive selection to the traditional pipe concept on UNIX.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nvbn/thefuck"&gt;thefuck&lt;/a&gt; - Correcting your previous console command.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tony/tmuxp"&gt;tmuxp&lt;/a&gt; - A &lt;a href="https://github.com/tmux/tmux"&gt;tmux&lt;/a&gt; session manager.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/timofurrer/try"&gt;try&lt;/a&gt; - A dead simple CLI to try out python packages - it's never been easier.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CLI Enhancements
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jakubroztocil/httpie"&gt;httpie&lt;/a&gt; - A command line HTTP client, a user-friendly cURL replacement.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cloudnativelabs/kube-shell"&gt;kube-shell&lt;/a&gt; - An integrated shell for working with the Kubernetes CLI.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dbcli/mycli"&gt;mycli&lt;/a&gt; - A Terminal Client for MySQL with AutoCompletion and Syntax Highlighting.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dbcli/pgcli"&gt;pgcli&lt;/a&gt; - Postgres CLI with autocompletion and syntax highlighting.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/saws"&gt;saws&lt;/a&gt; - A Supercharged &lt;a href="https://github.com/aws/aws-cli"&gt;aws-cli&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-compatibility" class="anchor" aria-hidden="true" href="#compatibility"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Compatibility&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for migrating from Python 2 to 3.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://python-future.org/index.html" rel="nofollow"&gt;python-future&lt;/a&gt; - The missing compatibility layer between Python 2 and Python 3.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mitsuhiko/python-modernize"&gt;python-modernize&lt;/a&gt; - Modernizes Python code for eventual Python 3 migration.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/six/" rel="nofollow"&gt;six&lt;/a&gt; - Python 2 and 3 compatibility utilities.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-computer-vision" class="anchor" aria-hidden="true" href="#computer-vision"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Computer Vision&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for computer vision.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://opencv.org/" rel="nofollow"&gt;OpenCV&lt;/a&gt; - Open Source Computer Vision Library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/madmaze/pytesseract"&gt;pytesseract&lt;/a&gt; - Another wrapper for &lt;a href="https://github.com/tesseract-ocr"&gt;Google Tesseract OCR&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://simplecv.org/" rel="nofollow"&gt;SimpleCV&lt;/a&gt; - An open source framework for building computer vision applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-concurrency-and-parallelism" class="anchor" aria-hidden="true" href="#concurrency-and-parallelism"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Concurrency and Parallelism&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for concurrent and parallel execution. Also see &lt;a href="https://github.com/timofurrer/awesome-asyncio"&gt;awesome-asyncio&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow"&gt;concurrent.futures&lt;/a&gt; - (Python standard library) A high-level interface for asynchronously executing callables.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow"&gt;multiprocessing&lt;/a&gt; - (Python standard library) Process-based parallelism.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://eventlet.net/" rel="nofollow"&gt;eventlet&lt;/a&gt; - Asynchronous framework with WSGI support.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.gevent.org/" rel="nofollow"&gt;gevent&lt;/a&gt; - A coroutine-based Python networking library that uses &lt;a href="https://github.com/python-greenlet/greenlet"&gt;greenlet&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MagicStack/uvloop"&gt;uvloop&lt;/a&gt; - Ultra fast implementation of &lt;code&gt;asyncio&lt;/code&gt; event loop on top of &lt;code&gt;libuv&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/soravux/scoop"&gt;scoop&lt;/a&gt; - Scalable Concurrent Operations in Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-configuration" class="anchor" aria-hidden="true" href="#configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuration&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for storing and parsing configuration options.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/DiffSK/configobj"&gt;configobj&lt;/a&gt; - INI file parser with validation.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/configparser.html" rel="nofollow"&gt;configparser&lt;/a&gt; - (Python standard library) INI file parser.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://profig.readthedocs.io/en/default/" rel="nofollow"&gt;profig&lt;/a&gt; - Config from multiple formats with value conversion.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/henriquebastos/python-decouple"&gt;python-decouple&lt;/a&gt; - Strict separation of settings from code.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-cryptography" class="anchor" aria-hidden="true" href="#cryptography"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cryptography&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cryptography.io/en/latest/" rel="nofollow"&gt;cryptography&lt;/a&gt; - A package designed to expose cryptographic primitives and recipes to Python developers.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/paramiko/paramiko"&gt;paramiko&lt;/a&gt; - The leading native Python SSHv2 protocol library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://passlib.readthedocs.io/en/stable/" rel="nofollow"&gt;passlib&lt;/a&gt; - Secure password storage/hashing library, very high level.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pyca/pynacl"&gt;pynacl&lt;/a&gt; - Python binding to the Networking and Cryptography (NaCl) library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-data-analysis" class="anchor" aria-hidden="true" href="#data-analysis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Analysis&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for data analyzing.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/blaze/blaze"&gt;Blaze&lt;/a&gt; - NumPy and Pandas interface to Big Data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mining/mining"&gt;Open Mining&lt;/a&gt; - Business Intelligence (BI) in Pandas interface.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://orange.biolab.si/" rel="nofollow"&gt;Orange&lt;/a&gt; - Data mining, data visualization, analysis and machine learning through visual programming or scripts.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pandas.pydata.org/" rel="nofollow"&gt;Pandas&lt;/a&gt; - A library providing high-performance, easy-to-use data structures and data analysis tools.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ironmussa/Optimus"&gt;Optimus&lt;/a&gt; - Agile Data Science Workflows made easy with PySpark.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-data-validation" class="anchor" aria-hidden="true" href="#data-validation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Validation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for validating data. Used for forms in many cases.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pyeve/cerberus"&gt;Cerberus&lt;/a&gt; - A lightweight and extensible data validation library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.pylonsproject.org/projects/colander/en/latest/" rel="nofollow"&gt;colander&lt;/a&gt; - Validating and deserializing data obtained via XML, JSON, an HTML form post.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Julian/jsonschema"&gt;jsonschema&lt;/a&gt; - An implementation of &lt;a href="http://json-schema.org/" rel="nofollow"&gt;JSON Schema&lt;/a&gt; for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/keleshev/schema"&gt;schema&lt;/a&gt; - A library for validating Python data structures.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/schematics/schematics"&gt;Schematics&lt;/a&gt; - Data Structure Validation.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/podio/valideer"&gt;valideer&lt;/a&gt; - Lightweight extensible data validation and adaptation library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/alecthomas/voluptuous"&gt;voluptuous&lt;/a&gt; - A Python data validation library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-data-visualization" class="anchor" aria-hidden="true" href="#data-visualization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Visualization&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for visualizing data. Also see &lt;a href="https://github.com/sorrycc/awesome-javascript#data-visualization"&gt;awesome-javascript&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/altair-viz/altair"&gt;Altair&lt;/a&gt; - Declarative statistical visualization library for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bokeh/bokeh"&gt;Bokeh&lt;/a&gt; - Interactive Web Plotting for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bloomberg/bqplot"&gt;bqplot&lt;/a&gt; - Interactive Plotting Library for the Jupyter Notebook&lt;/li&gt;
&lt;li&gt;&lt;a href="https://plot.ly/products/dash/" rel="nofollow"&gt;Dash&lt;/a&gt; - Built on top of Flask, React and Plotly aimed at analytical web applications.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Acrotrend/awesome-dash"&gt;awesome-dash&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/has2k1/plotnine"&gt;plotnine&lt;/a&gt; - A grammar of graphics for Python based on ggplot2.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://matplotlib.org/" rel="nofollow"&gt;Matplotlib&lt;/a&gt; - A Python 2D plotting library.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pygal.org/en/latest/" rel="nofollow"&gt;Pygal&lt;/a&gt; - A Python SVG Charts Creator.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/pygraphviz/" rel="nofollow"&gt;PyGraphviz&lt;/a&gt; - Python interface to &lt;a href="http://www.graphviz.org/" rel="nofollow"&gt;Graphviz&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pyqtgraph.org/" rel="nofollow"&gt;PyQtGraph&lt;/a&gt; - Interactive and realtime 2D/3D/Image plotting and science/engineering widgets.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mwaskom/seaborn"&gt;Seaborn&lt;/a&gt; - Statistical data visualization using Matplotlib.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/vispy/vispy"&gt;VisPy&lt;/a&gt; - High-performance scientific visualization based on OpenGL.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-database" class="anchor" aria-hidden="true" href="#database"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Databases implemented in Python.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/patx/pickledb"&gt;pickleDB&lt;/a&gt; - A simple and lightweight key-value store for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/msiemens/tinydb"&gt;tinydb&lt;/a&gt; - A tiny, document-oriented database.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zopefoundation/ZODB"&gt;ZODB&lt;/a&gt; - A native object database for Python. A key-value and object graph database.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-database-drivers" class="anchor" aria-hidden="true" href="#database-drivers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database Drivers&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for connecting and operating databases.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MySQL - &lt;a href="http://shlomi-noach.github.io/awesome-mysql/" rel="nofollow"&gt;awesome-mysql&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/PyMySQL/mysqlclient-python"&gt;mysqlclient&lt;/a&gt; - MySQL connector with Python 3 support (&lt;a href="https://sourceforge.net/projects/mysql-python/" rel="nofollow"&gt;mysql-python&lt;/a&gt; fork).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PyMySQL/PyMySQL"&gt;PyMySQL&lt;/a&gt; - A pure Python MySQL driver compatible to mysql-python.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PostgreSQL - &lt;a href="https://github.com/dhamaniasad/awesome-postgres"&gt;awesome-postgres&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://initd.org/psycopg/" rel="nofollow"&gt;psycopg2&lt;/a&gt; - The most popular PostgreSQL adapter for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gmr/queries"&gt;queries&lt;/a&gt; - A wrapper of the psycopg2 library for interacting with PostgreSQL.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Other Relational Databases
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.pymssql.org/en/latest/" rel="nofollow"&gt;pymssql&lt;/a&gt; - A simple database interface to Microsoft SQL Server.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NoSQL Databases
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/datastax/python-driver"&gt;cassandra-driver&lt;/a&gt; - The Python Driver for Apache Cassandra.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wbolster/happybase"&gt;happybase&lt;/a&gt; - A developer-friendly library for Apache HBase.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dpkp/kafka-python"&gt;kafka-python&lt;/a&gt; - The Python client for Apache Kafka.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://py2neo.org/" rel="nofollow"&gt;py2neo&lt;/a&gt; - Python wrapper client for Neo4j's restful interface.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mongodb/mongo-python-driver"&gt;pymongo&lt;/a&gt; - The official Python client for MongoDB.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/andymccurdy/redis-py"&gt;redis-py&lt;/a&gt; - The Python client for Redis.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Asynchronous Clients
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/mongodb/motor"&gt;motor&lt;/a&gt; - The async Python driver for MongoDB.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/driftx/Telephus"&gt;Telephus&lt;/a&gt; - Twisted based client for Cassandra.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wulczer/txpostgres"&gt;txpostgres&lt;/a&gt; - Twisted based asynchronous driver for PostgreSQL.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/deldotdr/txRedis"&gt;txRedis&lt;/a&gt; - Twisted based client for Redis.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-date-and-time" class="anchor" aria-hidden="true" href="#date-and-time"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Date and Time&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with dates and times.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/KoffeinFlummi/Chronyk"&gt;Chronyk&lt;/a&gt; - A Python 3 library for parsing human-written times and dates.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dateutil/dateutil"&gt;dateutil&lt;/a&gt; - Extensions to the standard Python &lt;a href="https://docs.python.org/3/library/datetime.html" rel="nofollow"&gt;datetime&lt;/a&gt; module.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/myusuf3/delorean/"&gt;delorean&lt;/a&gt; - A library for clearing up the inconvenient truths that arise dealing with datetimes.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zachwill/moment"&gt;moment&lt;/a&gt; - A Python library for dealing with dates/times. Inspired by &lt;a href="http://momentjs.com/" rel="nofollow"&gt;Moment.js&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sdispater/pendulum"&gt;Pendulum&lt;/a&gt; - Python datetimes made easy.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/shinux/PyTime"&gt;PyTime&lt;/a&gt; - An easy-to-use Python module which aims to operate date/time/datetime by string.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://launchpad.net/pytz" rel="nofollow"&gt;pytz&lt;/a&gt; - World timezone definitions, modern and historical. Brings the &lt;a href="https://en.wikipedia.org/wiki/Tz_database" rel="nofollow"&gt;tz database&lt;/a&gt; into Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dirn/When.py"&gt;when.py&lt;/a&gt; - Providing user-friendly functions to help perform common date and time actions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/maya"&gt;maya&lt;/a&gt; - Datetimes for Humans.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-debugging-tools" class="anchor" aria-hidden="true" href="#debugging-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Debugging Tools&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for debugging code.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pdb-like Debugger
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/gotcha/ipdb"&gt;ipdb&lt;/a&gt; - IPython-enabled &lt;a href="https://docs.python.org/3/library/pdb.html" rel="nofollow"&gt;pdb&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/antocuni/pdb"&gt;pdb++&lt;/a&gt; - Another drop-in replacement for pdb.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/inducer/pudb"&gt;pudb&lt;/a&gt; - A full-screen, console-based Python debugger.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kozea/wdb"&gt;wdb&lt;/a&gt; - An improbable web debugger through WebSockets.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tracing
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/khamidou/lptrace"&gt;lptrace&lt;/a&gt; - &lt;a href="http://man7.org/linux/man-pages/man1/strace.1.html" rel="nofollow"&gt;strace&lt;/a&gt; for Python programs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ionelmc/python-manhole"&gt;manhole&lt;/a&gt; - Debugging UNIX socket connections and present the stacktraces for all threads and an interactive prompt.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/pyringe"&gt;pyringe&lt;/a&gt; - Debugger capable of attaching to and injecting code into Python processes.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ionelmc/python-hunter"&gt;python-hunter&lt;/a&gt; - A flexible code tracing toolkit.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Profiler
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/rkern/line_profiler"&gt;line_profiler&lt;/a&gt; - Line-by-line profiling.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fabianp/memory_profiler"&gt;memory_profiler&lt;/a&gt; - Monitor Memory usage of Python code.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/what-studio/profiling"&gt;profiling&lt;/a&gt; - An interactive Python profiler.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/benfred/py-spy"&gt;py-spy&lt;/a&gt; - A sampling profiler for Python programs. Written in Rust.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/uber/pyflame"&gt;pyflame&lt;/a&gt; - A ptracing profiler For Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nvdv/vprof"&gt;vprof&lt;/a&gt; - Visual Python profiler.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Others
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/gruns/icecream"&gt;icecream&lt;/a&gt; - Inspect variables, expressions, and program execution with a single, simple function call.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jazzband/django-debug-toolbar"&gt;django-debug-toolbar&lt;/a&gt; - Display various debug information for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dcramer/django-devserver"&gt;django-devserver&lt;/a&gt; - A drop-in replacement for Django's runserver.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mgood/flask-debugtoolbar"&gt;flask-debugtoolbar&lt;/a&gt; - A port of the django-debug-toolbar to flask.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/eliben/pyelftools"&gt;pyelftools&lt;/a&gt; - Parsing and analyzing ELF files and DWARF debugging information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-deep-learning" class="anchor" aria-hidden="true" href="#deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Frameworks for Neural Networks and Deep Learning. Also see &lt;a href="https://github.com/ChristosChristofidis/awesome-deep-learning"&gt;awesome-deep-learning&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/BVLC/caffe"&gt;caffe&lt;/a&gt; - A fast open framework for deep learning..&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/keras-team/keras"&gt;keras&lt;/a&gt; - A high-level neural networks library and capable of running on top of either TensorFlow or Theano.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dmlc/mxnet"&gt;mxnet&lt;/a&gt; - A deep learning framework designed for both efficiency and flexibility.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pytorch/pytorch"&gt;pytorch&lt;/a&gt; - Tensors and Dynamic neural networks in Python with strong GPU acceleration.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/SerpentAI/SerpentAI"&gt;SerpentAI&lt;/a&gt; - Game agent framework. Use any video game as a deep learning sandbox.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tensorflow"&gt;tensorflow&lt;/a&gt; - The most popular Deep Learning framework created by Google.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Theano/Theano"&gt;Theano&lt;/a&gt; - A library for fast numerical computation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-devops-tools" class="anchor" aria-hidden="true" href="#devops-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DevOps Tools&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Software and libraries for DevOps.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ansible/ansible"&gt;ansible&lt;/a&gt; - A radically simple IT automation platform.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cloudinit.readthedocs.io/en/latest/" rel="nofollow"&gt;cloudinit&lt;/a&gt; - A multi-distribution package that handles early initialization of a cloud instance.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sebastien/cuisine"&gt;cuisine&lt;/a&gt; - Chef-like functionality for Fabric.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.docker.com/compose/" rel="nofollow"&gt;docker-compose&lt;/a&gt; - Fast, isolated development environments using &lt;a href="https://www.docker.com/" rel="nofollow"&gt;Docker&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fabric/fabric"&gt;fabric&lt;/a&gt; - A simple, Pythonic tool for remote execution and deployment.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fabtools/fabtools"&gt;fabtools&lt;/a&gt; - Tools for writing awesome Fabric files.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nickstenning/honcho"&gt;honcho&lt;/a&gt; - A Python clone of &lt;a href="https://github.com/ddollar/foreman"&gt;Foreman&lt;/a&gt;, for managing Procfile-based applications.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.openstack.org/" rel="nofollow"&gt;OpenStack&lt;/a&gt; - Open source software for building private and public clouds.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pexpect/pexpect"&gt;pexpect&lt;/a&gt; - Controlling interactive programs in a pseudo-terminal like GNU expect.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/giampaolo/psutil"&gt;psutil&lt;/a&gt; - A cross-platform process and system utilities module.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/saltstack/salt"&gt;saltstack&lt;/a&gt; - Infrastructure automation and management system.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Supervisor/supervisor"&gt;supervisor&lt;/a&gt; - Supervisor process control system for UNIX.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-distributed-computing" class="anchor" aria-hidden="true" href="#distributed-computing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Distributed Computing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Frameworks and libraries for Distributed Computing.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Batch Processing
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/pyspark/" rel="nofollow"&gt;PySpark&lt;/a&gt; - &lt;a href="https://spark.apache.org/" rel="nofollow"&gt;Apache Spark&lt;/a&gt; Python API.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dask/dask"&gt;dask&lt;/a&gt; - A flexible parallel computing library for analytic computing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/spotify/luigi"&gt;luigi&lt;/a&gt; - A module that helps you build complex pipelines of batch jobs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Yelp/mrjob"&gt;mrjob&lt;/a&gt; - Run MapReduce jobs on Hadoop or Amazon Web Services.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ray-project/ray/"&gt;Ray&lt;/a&gt; - A system for parallel and distributed Python that unifies the machine learning ecosystem.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stream Processing
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/robinhood/faust"&gt;faust&lt;/a&gt; - A stream processing library, porting the ideas from &lt;a href="https://kafka.apache.org/documentation/streams/" rel="nofollow"&gt;Kafka Streams&lt;/a&gt; to Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Parsely/streamparse"&gt;streamparse&lt;/a&gt; - Run Python code against real-time streams of data via &lt;a href="http://storm.apache.org/" rel="nofollow"&gt;Apache Storm&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-distribution" class="anchor" aria-hidden="true" href="#distribution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Distribution&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries to create packaged executables for release distribution.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/spotify/dh-virtualenv"&gt;dh-virtualenv&lt;/a&gt; - Build and distribute a virtualenv as a Debian package.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nuitka.net/" rel="nofollow"&gt;Nuitka&lt;/a&gt; - Compile scripts, modules, packages to an executable or extension module.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pythonhosted.org/py2app/" rel="nofollow"&gt;py2app&lt;/a&gt; - Freezes Python scripts (Mac OS X).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.py2exe.org/" rel="nofollow"&gt;py2exe&lt;/a&gt; - Freezes Python scripts (Windows).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pyinstaller/pyinstaller"&gt;PyInstaller&lt;/a&gt; - Converts Python programs into stand-alone executables (cross-platform).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pynsist.readthedocs.io/en/latest/" rel="nofollow"&gt;pynsist&lt;/a&gt; - A tool to build Windows installers, installers bundle Python itself.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for generating project documentation.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/sphinx-doc/sphinx/"&gt;sphinx&lt;/a&gt; - Python Documentation generator.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/yoloseem/awesome-sphinxdoc"&gt;awesome-sphinxdoc&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mitmproxy/pdoc"&gt;pdoc&lt;/a&gt; - Epydoc replacement to auto generate API documentation for Python libraries.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pycco-docs/pycco"&gt;pycco&lt;/a&gt; - The literate-programming-style documentation generator.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-downloader" class="anchor" aria-hidden="true" href="#downloader"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Downloader&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for downloading.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/s3tools/s3cmd"&gt;s3cmd&lt;/a&gt; - A command line tool for managing Amazon S3 and CloudFront.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bloomreach/s4cmd"&gt;s4cmd&lt;/a&gt; - Super S3 command line tool, good for higher performance.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://you-get.org/" rel="nofollow"&gt;you-get&lt;/a&gt; - A YouTube/Youku/Niconico video downloader written in Python 3.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://rg3.github.io/youtube-dl/" rel="nofollow"&gt;youtube-dl&lt;/a&gt; - A small command-line program to download videos from YouTube.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-e-commerce" class="anchor" aria-hidden="true" href="#e-commerce"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;E-commerce&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Frameworks and libraries for e-commerce and payments.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/lxneng/alipay"&gt;alipay&lt;/a&gt; - Unofficial Alipay API for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/stephenmcd/cartridge"&gt;Cartridge&lt;/a&gt; - A shopping cart app built using the Mezzanine.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://oscarcommerce.com/" rel="nofollow"&gt;django-oscar&lt;/a&gt; - An open-source e-commerce framework for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/awesto/django-shop"&gt;django-shop&lt;/a&gt; - A Django based shop system.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/agiliq/merchant"&gt;merchant&lt;/a&gt; - A Django app to accept payments from various payment processors.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/carlospalol/money"&gt;money&lt;/a&gt; - &lt;code&gt;Money&lt;/code&gt; class with optional CLDR-backed locale-aware formatting and an extensible currency exchange.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Alir3z4/python-currencies"&gt;python-currencies&lt;/a&gt; - Display money format and its filthy currencies.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MicroPyramid/forex-python"&gt;forex-python&lt;/a&gt; - Foreign exchange rates, Bitcoin price index and currency conversion.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://getsaleor.com/" rel="nofollow"&gt;saleor&lt;/a&gt; - An e-commerce storefront for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.shuup.com/en/" rel="nofollow"&gt;shoop&lt;/a&gt; - An open source E-Commerce platform based on Django.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-editor-plugins-and-ides" class="anchor" aria-hidden="true" href="#editor-plugins-and-ides"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Editor Plugins and IDEs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Emacs
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jorgenschaefer/elpy"&gt;elpy&lt;/a&gt; - Emacs Python Development Environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sublime Text
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/DamnWidget/anaconda"&gt;anaconda&lt;/a&gt; - Anaconda turns your Sublime Text 3 in a full featured Python development IDE.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/srusskih/SublimeJEDI"&gt;SublimeJEDI&lt;/a&gt; - A Sublime Text plugin to the awesome auto-complete library Jedi.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Vim
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/davidhalter/jedi-vim"&gt;jedi-vim&lt;/a&gt; - Vim bindings for the Jedi auto-completion library for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/python-mode/python-mode"&gt;python-mode&lt;/a&gt; - An all in one plugin for turning Vim into a Python IDE.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Valloric/YouCompleteMe"&gt;YouCompleteMe&lt;/a&gt; - Includes &lt;a href="https://github.com/davidhalter/jedi"&gt;Jedi&lt;/a&gt;-based completion engine for Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Visual Studio
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Microsoft/PTVS"&gt;PTVS&lt;/a&gt; - Python Tools for Visual Studio.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Visual Studio Code
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-python.python" rel="nofollow"&gt;Python&lt;/a&gt; - The official VSCode extension with rich support for Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;IDE
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.jetbrains.com/pycharm/" rel="nofollow"&gt;PyCharm&lt;/a&gt; - Commercial Python IDE by JetBrains. Has free community edition available.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/spyder-ide/spyder"&gt;spyder&lt;/a&gt; - Open Source Python IDE.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-email" class="anchor" aria-hidden="true" href="#email"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Email&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for sending and parsing email.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://tomekwojcik.github.io/envelopes/" rel="nofollow"&gt;envelopes&lt;/a&gt; - Mailing for human beings.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mailgun/flanker"&gt;flanker&lt;/a&gt; - An email address and Mime parsing library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/martinrusev/imbox"&gt;imbox&lt;/a&gt; - Python IMAP for Humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/inbox.py"&gt;inbox.py&lt;/a&gt; - Python SMTP Server for Humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zedshaw/lamson"&gt;lamson&lt;/a&gt; - Pythonic SMTP Application Server.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/marrow/mailer"&gt;Marrow Mailer&lt;/a&gt; - High-performance extensible mail delivery framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/modoboa/modoboa"&gt;modoboa&lt;/a&gt; - A mail hosting and management platform including a modern and simplified Web UI.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nylas/sync-engine"&gt;Nylas Sync Engine&lt;/a&gt; - Providing a RESTful API on top of a powerful email sync platform.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kootenpv/yagmail"&gt;yagmail&lt;/a&gt; - Yet another Gmail/SMTP client.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-environment-management" class="anchor" aria-hidden="true" href="#environment-management"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Environment Management&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for Python version and virtual environment management.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pyenv/pyenv"&gt;pyenv&lt;/a&gt; - Simple Python version management.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pypa/pipenv"&gt;pipenv&lt;/a&gt; - Python Development Workflow for Humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sdispater/poetry"&gt;poetry&lt;/a&gt; - Python dependency management and packaging made easy.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pypa/virtualenv"&gt;virtualenv&lt;/a&gt; - A tool to create isolated Python environments.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-files" class="anchor" aria-hidden="true" href="#files"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Files&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for file manipulation and MIME type detection.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/mimetypes.html" rel="nofollow"&gt;mimetypes&lt;/a&gt; - (Python standard library) Map filenames to MIME types.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jaraco/path.py"&gt;path.py&lt;/a&gt; - A module wrapper for &lt;a href="https://docs.python.org/3/library/os.path.html" rel="nofollow"&gt;os.path&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/pathlib.html" rel="nofollow"&gt;pathlib&lt;/a&gt; - (Python standard library) An cross-platform, object-oriented path library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pyfilesystem/pyfilesystem2"&gt;PyFilesystem2&lt;/a&gt; - Python's filesystem abstraction layer.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ahupp/python-magic"&gt;python-magic&lt;/a&gt; - A Python interface to the libmagic file type identification library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mikeorr/Unipath"&gt;Unipath&lt;/a&gt; - An object-oriented approach to file/directory operations.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gorakhargosh/watchdog"&gt;watchdog&lt;/a&gt; - API and shell utilities to monitor file system events.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-foreign-function-interface" class="anchor" aria-hidden="true" href="#foreign-function-interface"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Foreign Function Interface&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for providing foreign function interface.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/cffi/" rel="nofollow"&gt;cffi&lt;/a&gt; - Foreign Function Interface for Python calling C code.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/ctypes.html" rel="nofollow"&gt;ctypes&lt;/a&gt; - (Python standard library) Foreign Function Interface for Python calling C code.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mathema.tician.de/software/pycuda/" rel="nofollow"&gt;PyCUDA&lt;/a&gt; - A Python wrapper for Nvidia's CUDA API.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.swig.org/Doc1.3/Python.html" rel="nofollow"&gt;SWIG&lt;/a&gt; - Simplified Wrapper and Interface Generator.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-forms" class="anchor" aria-hidden="true" href="#forms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Forms&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with forms.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Pylons/deform"&gt;Deform&lt;/a&gt; - Python HTML form generation library influenced by the formish form generation library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dyve/django-bootstrap3"&gt;django-bootstrap3&lt;/a&gt; - Bootstrap 3 integration with Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zostera/django-bootstrap4"&gt;django-bootstrap4&lt;/a&gt; - Bootstrap 4 integration with Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/django-crispy-forms/django-crispy-forms"&gt;django-crispy-forms&lt;/a&gt; - A Django app which lets you create beautiful forms in a very elegant and DRY way.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/WiserTogether/django-remote-forms"&gt;django-remote-forms&lt;/a&gt; - A platform independent Django form serializer.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wtforms/wtforms"&gt;WTForms&lt;/a&gt; - A flexible forms validation and rendering library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-functional-programming" class="anchor" aria-hidden="true" href="#functional-programming"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Functional Programming&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Functional Programming with Python.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://coconut-lang.org/" rel="nofollow"&gt;Coconut&lt;/a&gt; - Coconut is a variant of Python built for simple, elegant, Pythonic functional programming.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pytoolz/cytoolz/"&gt;CyToolz&lt;/a&gt; - Cython implementation of Toolz: High performance functional utilities.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kachayev/fn.py"&gt;fn.py&lt;/a&gt; - Functional programming in Python: implementation of missing features to enjoy FP.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Suor/funcy"&gt;funcy&lt;/a&gt; - A fancy and practical functional tools.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pytoolz/toolz"&gt;Toolz&lt;/a&gt; - A collection of functional utilities for iterators, functions, and dictionaries.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-gui-development" class="anchor" aria-hidden="true" href="#gui-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GUI Development&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with graphical user interface applications.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/curses.html" rel="nofollow"&gt;curses&lt;/a&gt; - Built-in wrapper for &lt;a href="http://www.gnu.org/software/ncurses/" rel="nofollow"&gt;ncurses&lt;/a&gt; used to create terminal GUI applications.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ChrisKnott/Eel"&gt;Eel&lt;/a&gt; - A library for making simple Electron-like offline HTML/JS GUI apps.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nucleic/enaml"&gt;enaml&lt;/a&gt; - Creating beautiful user-interfaces with Declarative Syntax like QML.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zoofIO/flexx"&gt;Flexx&lt;/a&gt; - Flexx is a pure Python toolkit for creating GUI's, that uses web technology for its rendering.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chriskiehl/Gooey"&gt;Gooey&lt;/a&gt; - Turn command line programs into a full GUI application with one line.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://kivy.org/" rel="nofollow"&gt;kivy&lt;/a&gt; - A library for creating NUI applications, running on Windows, Linux, Mac OS X, Android and iOS.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bitbucket.org/pyglet/pyglet/wiki/Home" rel="nofollow"&gt;pyglet&lt;/a&gt; - A cross-platform windowing and multimedia library for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.gnome.org/Projects/PyGObject" rel="nofollow"&gt;PyGObject&lt;/a&gt; - Python Bindings for GLib/GObject/GIO/GTK+ (GTK+3).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://riverbankcomputing.com/software/pyqt/intro" rel="nofollow"&gt;PyQt&lt;/a&gt; - Python bindings for the &lt;a href="https://www.qt.io/" rel="nofollow"&gt;Qt&lt;/a&gt; cross-platform application and UI framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PySimpleGUI/PySimpleGUI"&gt;PySimpleGUI&lt;/a&gt; - Wrapper for tkinter, Qt, WxPython and Remi.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/r0x0r/pywebview/"&gt;pywebview&lt;/a&gt; - A lightweight cross-platform native wrapper around a webview component.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.python.org/moin/TkInter" rel="nofollow"&gt;Tkinter&lt;/a&gt; - Tkinter is Python's de-facto standard GUI package.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pybee/toga"&gt;Toga&lt;/a&gt; - A Python native, OS native GUI toolkit.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://urwid.org/" rel="nofollow"&gt;urwid&lt;/a&gt; - A library for creating terminal GUI applications with strong support for widgets, events, rich colors, etc.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wxpython.org/" rel="nofollow"&gt;wxPython&lt;/a&gt; - A blending of the wxWidgets C++ class library with the Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-game-development" class="anchor" aria-hidden="true" href="#game-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Game Development&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Awesome game development libraries.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://cocos2d.org/" rel="nofollow"&gt;Cocos2d&lt;/a&gt; - cocos2d is a framework for building 2D games, demos, and other graphical/interactive applications.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.harfang3d.com" rel="nofollow"&gt;Harfang3D&lt;/a&gt; - Python framework for 3D, VR and game development.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.panda3d.org/" rel="nofollow"&gt;Panda3D&lt;/a&gt; - 3D game engine developed by Disney.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pygame.org/news.html" rel="nofollow"&gt;Pygame&lt;/a&gt; - Pygame is a set of Python modules designed for writing games.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ogre3d.org/tikiwiki/PyOgre" rel="nofollow"&gt;PyOgre&lt;/a&gt; - Python bindings for the Ogre 3D render engine, can be used for games, simulations, anything 3D.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pyopengl.sourceforge.net/" rel="nofollow"&gt;PyOpenGL&lt;/a&gt; - Python ctypes bindings for OpenGL and it's related APIs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pysdl2.readthedocs.io" rel="nofollow"&gt;PySDL2&lt;/a&gt; - A ctypes based wrapper for the SDL2 library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.renpy.org/" rel="nofollow"&gt;RenPy&lt;/a&gt; - A Visual Novel engine.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-geolocation" class="anchor" aria-hidden="true" href="#geolocation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Geolocation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for geocoding addresses and working with latitudes and longitudes.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/SmileyChris/django-countries"&gt;django-countries&lt;/a&gt; - A Django app that provides a country field for models and forms.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.djangoproject.com/en/dev/ref/contrib/gis/" rel="nofollow"&gt;GeoDjango&lt;/a&gt; - A world-class geographic web framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/maxmind/geoip-api-python"&gt;GeoIP&lt;/a&gt; - Python API for MaxMind GeoIP Legacy Database.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/frewsxcv/python-geojson"&gt;geojson&lt;/a&gt; - Python bindings and utilities for GeoJSON.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/geopy/geopy"&gt;geopy&lt;/a&gt; - Python Geocoding Toolbox.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/appliedsec/pygeoip"&gt;pygeoip&lt;/a&gt; - Pure Python GeoIP API.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-html-manipulation" class="anchor" aria-hidden="true" href="#html-manipulation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;HTML Manipulation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with HTML and XML.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="nofollow"&gt;BeautifulSoup&lt;/a&gt; - Providing Pythonic idioms for iterating, searching, and modifying HTML or XML.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mozilla/bleach"&gt;bleach&lt;/a&gt; - A whitelist-based HTML sanitization and text linkification library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/cssutils/" rel="nofollow"&gt;cssutils&lt;/a&gt; - A CSS library for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/html5lib/html5lib-python"&gt;html5lib&lt;/a&gt; - A standards-compliant library for parsing and serializing HTML documents and fragments.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lxml.de/" rel="nofollow"&gt;lxml&lt;/a&gt; - A very fast, easy-to-use and versatile library for handling HTML and XML.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pallets/markupsafe"&gt;MarkupSafe&lt;/a&gt; - Implements a XML/HTML/XHTML Markup safe string for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gawel/pyquery"&gt;pyquery&lt;/a&gt; - A jQuery-like library for parsing HTML.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/stchris/untangle"&gt;untangle&lt;/a&gt; - Converts XML documents to Python objects for easy access.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://weasyprint.org" rel="nofollow"&gt;WeasyPrint&lt;/a&gt; - A visual rendering engine for HTML and CSS that can export to PDF.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://xmldataset.readthedocs.io/en/latest/" rel="nofollow"&gt;xmldataset&lt;/a&gt; - Simple XML Parsing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/martinblech/xmltodict"&gt;xmltodict&lt;/a&gt; - Working with XML feel like you are working with JSON.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-http-clients" class="anchor" aria-hidden="true" href="#http-clients"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;HTTP Clients&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with HTTP.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/grequests"&gt;grequests&lt;/a&gt; - requests + gevent for asynchronous HTTP requests.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/httplib2/httplib2"&gt;httplib2&lt;/a&gt; - Comprehensive HTTP client library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://requests.kennethreitz.org/en/master/" rel="nofollow"&gt;requests&lt;/a&gt; - HTTP Requests for Humans™.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/twisted/treq"&gt;treq&lt;/a&gt; - Python requests like API built on top of Twisted's HTTP client.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/shazow/urllib3"&gt;urllib3&lt;/a&gt; - A HTTP library with thread-safe connection pooling, file post support, sanity friendly.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-hardware" class="anchor" aria-hidden="true" href="#hardware"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hardware&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for programming with hardware.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://inotool.org/" rel="nofollow"&gt;ino&lt;/a&gt; - Command line toolkit for working with &lt;a href="https://www.arduino.cc/" rel="nofollow"&gt;Arduino&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/boppreh/keyboard"&gt;keyboard&lt;/a&gt; - Hook and simulate global keyboard events on Windows and Linux.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/boppreh/mouse"&gt;mouse&lt;/a&gt; - Hook and simulate global mouse events on Windows and Linux.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pingo.io/" rel="nofollow"&gt;Pingo&lt;/a&gt; - Pingo provides a uniform API to program devices like the Raspberry Pi, pcDuino, Intel Galileo, etc.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/SavinaRoja/PyUserInput"&gt;PyUserInput&lt;/a&gt; - A module for cross-platform control of the mouse and keyboard.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/secdev/scapy"&gt;scapy&lt;/a&gt; - A brilliant packet manipulation library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rockymeza/wifi"&gt;wifi&lt;/a&gt; - A Python library and command line tool for working with WiFi on Linux.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-image-processing" class="anchor" aria-hidden="true" href="#image-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image Processing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for manipulating images.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/rossgoodwin/hmap"&gt;hmap&lt;/a&gt; - Image histogram remapping.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sourceforge.net/projects/imgseek/" rel="nofollow"&gt;imgSeek&lt;/a&gt; - A project for searching a collection of images using visual similarity.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/hhatto/nude.py"&gt;nude.py&lt;/a&gt; - Nudity detection.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/daboth/pagan"&gt;pagan&lt;/a&gt; - Retro identicon (Avatar) generation based on input string and hash.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/python-pillow/Pillow"&gt;pillow&lt;/a&gt; - Pillow is the friendly &lt;a href="http://www.pythonware.com/products/pil/" rel="nofollow"&gt;PIL&lt;/a&gt; fork.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pythonhosted.org/pyBarcode/" rel="nofollow"&gt;pyBarcode&lt;/a&gt; - Create barcodes in Python without needing PIL.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ajkumar25/pygram"&gt;pygram&lt;/a&gt; - Instagram-like image filters.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lincolnloop/python-qrcode"&gt;python-qrcode&lt;/a&gt; - A pure Python QR Code generator.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fogleman/Quads"&gt;Quads&lt;/a&gt; - Computer art based on quadtrees.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-image.org/" rel="nofollow"&gt;scikit-image&lt;/a&gt; - A Python library for (scientific) image processing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/thumbor/thumbor"&gt;thumbor&lt;/a&gt; - A smart imaging service. It enables on-demand crop, re-sizing and flipping of images.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dahlia/wand"&gt;wand&lt;/a&gt; - Python bindings for &lt;a href="http://www.imagemagick.org/script/magick-wand.php" rel="nofollow"&gt;MagickWand&lt;/a&gt;, C API for ImageMagick.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-implementations" class="anchor" aria-hidden="true" href="#implementations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Implementations&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Implementations of Python.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/python/cpython"&gt;CPython&lt;/a&gt; - &lt;strong&gt;Default, most widely used implementation of the Python programming language written in C.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cython.org/" rel="nofollow"&gt;Cython&lt;/a&gt; - Optimizing Static Compiler for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/metawilm/cl-python"&gt;CLPython&lt;/a&gt; - Implementation of the Python programming language written in Common Lisp.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/grumpy"&gt;Grumpy&lt;/a&gt; - More compiler than interpreter as more powerful CPython2.7 replacement (alpha).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/IronLanguages/ironpython3"&gt;IronPython&lt;/a&gt; - Implementation of the Python programming language written in C#.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://hg.python.org/jython" rel="nofollow"&gt;Jython&lt;/a&gt; - Implementation of Python programming language written in Java for the JVM.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/micropython/micropython"&gt;MicroPython&lt;/a&gt; - A lean and efficient Python programming language implementation.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://numba.pydata.org/" rel="nofollow"&gt;Numba&lt;/a&gt; - Python JIT compiler to LLVM aimed at scientific Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Maratyszcza/PeachPy"&gt;PeachPy&lt;/a&gt; - x86-64 assembler embedded in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Microsoft/Pyjion"&gt;Pyjion&lt;/a&gt; - A JIT for Python based upon CoreCLR.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bitbucket.org/pypy/pypy" rel="nofollow"&gt;PyPy&lt;/a&gt; - A very fast and compliant implementation of the Python language.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dropbox/pyston"&gt;Pyston&lt;/a&gt; - A Python implementation using JIT techniques.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/stackless-dev/stackless"&gt;Stackless Python&lt;/a&gt; - An enhanced version of the Python programming language.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-interactive-interpreter" class="anchor" aria-hidden="true" href="#interactive-interpreter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive Interpreter&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Interactive Python interpreters (REPL).&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/bpython/bpython"&gt;bpython&lt;/a&gt; - A fancy interface to the Python interpreter.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jupyter.org" rel="nofollow"&gt;Jupyter Notebook (IPython)&lt;/a&gt; - A rich toolkit to help you make the most out of using Python interactively.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/markusschanta/awesome-jupyter"&gt;awesome-jupyter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jonathanslenders/ptpython"&gt;ptpython&lt;/a&gt; - Advanced Python REPL built on top of the &lt;a href="https://github.com/jonathanslenders/python-prompt-toolkit"&gt;python-prompt-toolkit&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-internationalization" class="anchor" aria-hidden="true" href="#internationalization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Internationalization&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with i18n.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://babel.pocoo.org/en/latest/" rel="nofollow"&gt;Babel&lt;/a&gt; - An internationalization library for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ovalhub/pyicu"&gt;PyICU&lt;/a&gt; - A wrapper of International Components for Unicode C++ library (&lt;a href="http://site.icu-project.org/" rel="nofollow"&gt;ICU&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-job-scheduler" class="anchor" aria-hidden="true" href="#job-scheduler"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Job Scheduler&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for scheduling jobs.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://apscheduler.readthedocs.io/en/latest/" rel="nofollow"&gt;APScheduler&lt;/a&gt; - A light but powerful in-process task scheduler that lets you schedule functions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/thauber/django-schedule"&gt;django-schedule&lt;/a&gt; - A calendaring app for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pydoit.org/" rel="nofollow"&gt;doit&lt;/a&gt; - A task runner and build tool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gunnery/gunnery"&gt;gunnery&lt;/a&gt; - Multipurpose task execution tool for distributed systems with web-based interface.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://joblib.readthedocs.io/" rel="nofollow"&gt;Joblib&lt;/a&gt; - A set of tools to provide lightweight pipelining in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fengsp/plan"&gt;Plan&lt;/a&gt; - Writing crontab file in Python like a charm.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dbader/schedule"&gt;schedule&lt;/a&gt; - Python job scheduling for humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/knipknap/SpiffWorkflow"&gt;Spiff&lt;/a&gt; - A powerful workflow engine implemented in pure Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.openstack.org/developer/taskflow/" rel="nofollow"&gt;TaskFlow&lt;/a&gt; - A Python library that helps to make task execution easy, consistent and reliable.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://airflow.apache.org/" rel="nofollow"&gt;Airflow&lt;/a&gt; - Airflow is a platform to programmatically author, schedule and monitor workflows.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-logging" class="anchor" aria-hidden="true" href="#logging"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Logging&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for generating and working with logs.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ScatterHQ/eliot"&gt;Eliot&lt;/a&gt; - Logging for complex &amp;amp; distributed systems.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://logbook.readthedocs.io/en/stable/" rel="nofollow"&gt;logbook&lt;/a&gt; - Logging replacement for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/logging.html" rel="nofollow"&gt;logging&lt;/a&gt; - (Python standard library) Logging facility for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/raven-python"&gt;raven&lt;/a&gt; - Python client for Sentry, a log/error tracking, crash reporting and aggregation platform for web applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-machine-learning" class="anchor" aria-hidden="true" href="#machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for Machine Learning. Also see &lt;a href="https://github.com/josephmisiti/awesome-machine-learning#python"&gt;awesome-machine-learning&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/h2oai/h2o-3"&gt;H2O&lt;/a&gt; - Open Source Fast Scalable Machine Learning Platform.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/benhamner/Metrics"&gt;Metrics&lt;/a&gt; - Machine learning evaluation metrics.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/numenta/nupic"&gt;NuPIC&lt;/a&gt; - Numenta Platform for Intelligent Computing.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/" rel="nofollow"&gt;scikit-learn&lt;/a&gt; - The most popular Python library for Machine Learning.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://spark.apache.org/docs/latest/ml-guide.html" rel="nofollow"&gt;Spark ML&lt;/a&gt; - &lt;a href="http://spark.apache.org/" rel="nofollow"&gt;Apache Spark&lt;/a&gt;'s scalable Machine Learning library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/josephreisinger/vowpal_porpoise"&gt;vowpal_porpoise&lt;/a&gt; - A lightweight Python wrapper for &lt;a href="https://github.com/JohnLangford/vowpal_wabbit/"&gt;Vowpal Wabbit&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dmlc/xgboost"&gt;xgboost&lt;/a&gt; - A scalable, portable, and distributed gradient boosting library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-microsoft-windows" class="anchor" aria-hidden="true" href="#microsoft-windows"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Microsoft Windows&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Python programming on Microsoft Windows.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://python-xy.github.io/" rel="nofollow"&gt;Python(x,y)&lt;/a&gt; - Scientific-applications-oriented Python Distribution based on Qt and Spyder.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/" rel="nofollow"&gt;pythonlibs&lt;/a&gt; - Unofficial Windows binaries for Python extension packages.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pythonnet/pythonnet"&gt;PythonNet&lt;/a&gt; - Python Integration with the .NET Common Language Runtime (CLR).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sourceforge.net/projects/pywin32/" rel="nofollow"&gt;PyWin32&lt;/a&gt; - Python Extensions for Windows.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://winpython.github.io/" rel="nofollow"&gt;WinPython&lt;/a&gt; - Portable development environment for Windows 7/8.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-miscellaneous" class="anchor" aria-hidden="true" href="#miscellaneous"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Miscellaneous&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Useful libraries or tools that don't fit in the categories above.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jek/blinker"&gt;blinker&lt;/a&gt; - A fast Python in-process signal/event dispatching system.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mahmoud/boltons"&gt;boltons&lt;/a&gt; - A set of pure-Python utilities.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pallets/itsdangerous"&gt;itsdangerous&lt;/a&gt; - Various helpers to pass trusted data to untrusted environments.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mitsuhiko/pluginbase"&gt;pluginbase&lt;/a&gt; - A simple but flexible plugin system for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.tryton.org/" rel="nofollow"&gt;tryton&lt;/a&gt; - A general purpose business framework.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-natural-language-processing" class="anchor" aria-hidden="true" href="#natural-language-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Natural Language Processing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with human languages.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;General
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/RaRe-Technologies/gensim"&gt;gensim&lt;/a&gt; - Topic Modeling for Humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/saffsd/langid.py"&gt;langid.py&lt;/a&gt; - Stand-alone language identification system.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nltk.org/" rel="nofollow"&gt;nltk&lt;/a&gt; - A leading platform for building Python programs to work with human language data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/clips/pattern"&gt;pattern&lt;/a&gt; - A web mining module for the Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/aboSamoor/polyglot"&gt;polyglot&lt;/a&gt; - Natural language pipeline supporting hundreds of languages.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/pytext"&gt;pytext&lt;/a&gt; - A natural language modeling framework based on PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PetrochukM/PyTorch-NLP"&gt;PyTorch-NLP&lt;/a&gt; - A toolkit enabling rapid deep learning NLP prototyping for research.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://spacy.io/" rel="nofollow"&gt;spacy&lt;/a&gt; - A library for industrial-strength natural language processing in Python and Cython.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/stanfordnlp/stanfordnlp"&gt;stanfordnlp&lt;/a&gt; - The Stanford NLP Group's official Python library, supporting 50+ languages.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Chinese
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/fxsjy/jieba"&gt;jieba&lt;/a&gt; - The most popular Chinese text segmentation library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lancopku/pkuseg-python"&gt;pkuseg-python&lt;/a&gt; - A toolkit for Chinese word segmentation in various domains.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/isnowfy/snownlp"&gt;snownlp&lt;/a&gt; - A library for processing Chinese text.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fighting41love/funNLP"&gt;funNLP&lt;/a&gt; - A collection of tools and datasets for Chinese NLP.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-network-virtualization" class="anchor" aria-hidden="true" href="#network-virtualization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Network Virtualization&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Tools and libraries for Virtual Networking and SDN (Software Defined Networking).&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/mininet/mininet"&gt;mininet&lt;/a&gt; - A popular network emulator and API written in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/noxrepo/pox"&gt;pox&lt;/a&gt; - A Python-based SDN control applications, such as OpenFlow SDN controllers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-networking" class="anchor" aria-hidden="true" href="#networking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Networking&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for networking programming.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow"&gt;asyncio&lt;/a&gt; - (Python standard library) Asynchronous I/O, event loop, coroutines and tasks.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/timofurrer/awesome-asyncio"&gt;awesome-asyncio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/quantmind/pulsar"&gt;pulsar&lt;/a&gt; - Event-driven concurrent framework for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zeromq/pyzmq"&gt;pyzmq&lt;/a&gt; - A Python wrapper for the ZeroMQ message library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twistedmatrix.com/trac/" rel="nofollow"&gt;Twisted&lt;/a&gt; - An event-driven networking engine.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/napalm-automation/napalm"&gt;napalm&lt;/a&gt; - Cross-vendor API to manipulate network devices.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-news-feed" class="anchor" aria-hidden="true" href="#news-feed"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;News Feed&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for building user's activities.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/justquick/django-activity-stream"&gt;django-activity-stream&lt;/a&gt; - Generating generic activity streams from the actions on your site.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tschellenbach/Stream-Framework"&gt;Stream Framework&lt;/a&gt; - Building news feed and notification systems using Cassandra and Redis.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-orm" class="anchor" aria-hidden="true" href="#orm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ORM&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries that implement Object-Relational Mapping or data mapping techniques.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Relational Databases
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.djangoproject.com/en/dev/topics/db/models/" rel="nofollow"&gt;Django Models&lt;/a&gt; - A part of Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sqlalchemy.org/" rel="nofollow"&gt;SQLAlchemy&lt;/a&gt; - The Python SQL Toolkit and Object Relational Mapper.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/dahlia/awesome-sqlalchemy"&gt;awesome-sqlalchemy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pudo/dataset"&gt;dataset&lt;/a&gt; - Store Python dicts in a database - works with SQLite, MySQL, and PostgreSQL.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sdispater/orator"&gt;orator&lt;/a&gt; -  The Orator ORM provides a simple yet beautiful ActiveRecord implementation.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/coleifer/peewee"&gt;peewee&lt;/a&gt; - A small, expressive ORM.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ponyorm/pony/"&gt;pony&lt;/a&gt; - ORM that provides a generator-oriented interface to SQL.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/web2py/pydal/"&gt;pydal&lt;/a&gt; - A pure Python Database Abstraction Layer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NoSQL Databases
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/stephenmcd/hot-redis"&gt;hot-redis&lt;/a&gt; - Rich Python data types for Redis.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MongoEngine/mongoengine"&gt;mongoengine&lt;/a&gt; - A Python Object-Document-Mapper for working with MongoDB.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pynamodb/PynamoDB"&gt;PynamoDB&lt;/a&gt; - A Pythonic interface for &lt;a href="https://aws.amazon.com/dynamodb/" rel="nofollow"&gt;Amazon DynamoDB&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kiddouk/redisco"&gt;redisco&lt;/a&gt; - A Python Library for Simple Models and Containers Persisted in Redis.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-package-management" class="anchor" aria-hidden="true" href="#package-management"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Package Management&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for package and dependency management.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pip.pypa.io/en/stable/" rel="nofollow"&gt;pip&lt;/a&gt; - The Python package and dependency manager.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.org/" rel="nofollow"&gt;PyPI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jazzband/pip-tools"&gt;pip-tools&lt;/a&gt; - A set of tools to keep your pinned Python dependencies fresh.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/conda/conda/"&gt;conda&lt;/a&gt; - Cross-platform, Python-agnostic binary package manager.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-package-repositories" class="anchor" aria-hidden="true" href="#package-repositories"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Package Repositories&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Local PyPI repository server and proxies.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pypa/warehouse"&gt;warehouse&lt;/a&gt; - Next generation Python Package Repository (PyPI).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pypa/bandersnatch/"&gt;bandersnatch&lt;/a&gt; - PyPI mirroring tool provided by Python Packaging Authority (PyPA).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/devpi/devpi"&gt;devpi&lt;/a&gt; - PyPI server and packaging/testing/release tool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jazzband/localshop"&gt;localshop&lt;/a&gt; - Local PyPI server (custom packages and auto-mirroring of pypi).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-permissions" class="anchor" aria-hidden="true" href="#permissions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Permissions&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries that allow or deny users access to data or functionality.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/django-guardian/django-guardian"&gt;django-guardian&lt;/a&gt; - Implementation of per object permissions for Django 1.2+&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dfunckt/django-rules"&gt;django-rules&lt;/a&gt; - A tiny but powerful app providing object-level permissions to Django, without requiring a database.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-processes" class="anchor" aria-hidden="true" href="#processes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Processes&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for starting and communicating with OS processes.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/delegator.py"&gt;delegator.py&lt;/a&gt; - &lt;a href="https://docs.python.org/3.6/library/subprocess.html" rel="nofollow"&gt;Subprocesses&lt;/a&gt; for Humans™ 2.0.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sarge.readthedocs.io/en/latest/" rel="nofollow"&gt;sarge&lt;/a&gt; - Yet another wrapper for subprocess.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/amoffat/sh"&gt;sh&lt;/a&gt; - A full-fledged subprocess replacement for Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-queue" class="anchor" aria-hidden="true" href="#queue"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Queue&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with event and task queues.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.celeryproject.org/" rel="nofollow"&gt;celery&lt;/a&gt; - An asynchronous task queue/job queue based on distributed message passing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/coleifer/huey"&gt;huey&lt;/a&gt; - Little multi-threaded task queue.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pricingassistant/mrq"&gt;mrq&lt;/a&gt; - Mr. Queue - A distributed worker task queue in Python using Redis &amp;amp; gevent.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rq/rq"&gt;rq&lt;/a&gt; - Simple job queues for Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-recommender-systems" class="anchor" aria-hidden="true" href="#recommender-systems"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Recommender Systems&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for building recommender systems.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/spotify/annoy"&gt;annoy&lt;/a&gt; - Approximate Nearest Neighbors in C++/Python optimized for memory usage.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ibayer/fastFM"&gt;fastFM&lt;/a&gt; - A library for Factorization Machines.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/benfred/implicit"&gt;implicit&lt;/a&gt; - A fast Python implementation of collaborative filtering for implicit datasets.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/guestwalk/libffm"&gt;libffm&lt;/a&gt; - A library for Field-aware Factorization Machine (FFM).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lyst/lightfm"&gt;lightfm&lt;/a&gt; - A Python implementation of a number of popular recommendation algorithms.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/maciejkula/spotlight"&gt;spotlight&lt;/a&gt; - Deep recommender models using PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/NicolasHug/Surprise"&gt;Surprise&lt;/a&gt; - A scikit for building and analyzing recommender systems.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jfkirk/tensorrec"&gt;tensorrec&lt;/a&gt; - A Recommendation Engine Framework in TensorFlow.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-restful-api" class="anchor" aria-hidden="true" href="#restful-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RESTful API&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for developing RESTful APIs.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Django
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.django-rest-framework.org/" rel="nofollow"&gt;django-rest-framework&lt;/a&gt; - A powerful and flexible toolkit to build web APIs.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://tastypieapi.org/" rel="nofollow"&gt;django-tastypie&lt;/a&gt; - Creating delicious APIs for Django apps.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Flask
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pyeve/eve"&gt;eve&lt;/a&gt; - REST API framework powered by Flask, MongoDB and good intentions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/marselester/flask-api-utils"&gt;flask-api-utils&lt;/a&gt; - Taking care of API representation and authentication for Flask.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.flaskapi.org/" rel="nofollow"&gt;flask-api&lt;/a&gt; - Browsable Web APIs for Flask.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/flask-restful/flask-restful"&gt;flask-restful&lt;/a&gt; - Quickly building REST APIs for Flask.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jfinkels/flask-restless"&gt;flask-restless&lt;/a&gt; - Generating RESTful APIs for database models defined with SQLAlchemy.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pyramid
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Cornices/cornice"&gt;cornice&lt;/a&gt; - A RESTful framework for Pyramid.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Framework agnostic
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/encode/apistar"&gt;apistar&lt;/a&gt; - A smart Web API framework, designed for Python 3.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://falconframework.org/" rel="nofollow"&gt;falcon&lt;/a&gt; - A high-performance framework for building cloud APIs and web app backends.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/timothycrosley/hug"&gt;hug&lt;/a&gt; - A Python 3 framework for cleanly exposing APIs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/toastdriven/restless"&gt;restless&lt;/a&gt; - Framework agnostic REST framework based on lessons learned from Tastypie.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/vertical-knowledge/ripozo"&gt;ripozo&lt;/a&gt; - Quickly creating REST/HATEOAS/Hypermedia APIs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jeffknupp/sandman"&gt;sandman&lt;/a&gt; - Automated REST APIs for existing database-driven systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-robotics" class="anchor" aria-hidden="true" href="#robotics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Robotics&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for robotics.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics"&gt;PythonRobotics&lt;/a&gt; - This is a compilation of various robotics algorithms with visualizations.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://wiki.ros.org/rospy" rel="nofollow"&gt;rospy&lt;/a&gt; - This is a library for ROS (Robot Operating System).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-rpc-servers" class="anchor" aria-hidden="true" href="#rpc-servers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RPC Servers&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;RPC-compatible servers.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/joshmarshall/jsonrpclib/"&gt;SimpleJSONRPCServer&lt;/a&gt; - This library is an implementation of the JSON-RPC specification.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/xmlrpc.server.html" rel="nofollow"&gt;SimpleXMLRPCServer&lt;/a&gt; - (Python standard library) Simple XML-RPC server implementation, single-threaded.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/0rpc/zerorpc-python"&gt;zeroRPC&lt;/a&gt; - zerorpc is a flexible RPC implementation based on &lt;a href="http://zeromq.org/" rel="nofollow"&gt;ZeroMQ&lt;/a&gt; and &lt;a href="http://msgpack.org/" rel="nofollow"&gt;MessagePack&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-science" class="anchor" aria-hidden="true" href="#science"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Science&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for scientific computing. Also see &lt;a href="https://github.com/TomNicholas/Python-for-Scientists"&gt;Python-for-Scientists&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.astropy.org/" rel="nofollow"&gt;astropy&lt;/a&gt; - A community Python library for Astronomy.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chapmanb/bcbio-nextgen"&gt;bcbio-nextgen&lt;/a&gt; - Providing best-practice pipelines for fully automated high throughput sequencing analysis.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chapmanb/bcbb"&gt;bccb&lt;/a&gt; - Collection of useful code related to biological analysis.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://biopython.org/wiki/Main_Page" rel="nofollow"&gt;Biopython&lt;/a&gt; - Biopython is a set of freely available tools for biological computation.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cclib.github.io/" rel="nofollow"&gt;cclib&lt;/a&gt; - A library for parsing and interpreting the results of computational chemistry packages.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://colour-science.org/" rel="nofollow"&gt;Colour&lt;/a&gt; - Implementing a comprehensive number of colour theory transformations and algorithms.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://networkx.github.io/" rel="nofollow"&gt;NetworkX&lt;/a&gt; - A high-productivity software for complex networks.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nipy.org" rel="nofollow"&gt;NIPY&lt;/a&gt; - A collection of neuroimaging toolkits.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.numpy.org/" rel="nofollow"&gt;NumPy&lt;/a&gt; - A fundamental package for scientific computing with Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://openbabel.org/wiki/Main_Page" rel="nofollow"&gt;Open Babel&lt;/a&gt; - A chemical toolbox designed to speak the many languages of chemical data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/obspy/obspy/wiki/"&gt;ObsPy&lt;/a&gt; - A Python toolbox for seismology.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pydy.org/" rel="nofollow"&gt;PyDy&lt;/a&gt; - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pymc-devs/pymc3"&gt;PyMC&lt;/a&gt; - Markov Chain Monte Carlo sampling toolkit.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://qutip.org/" rel="nofollow"&gt;QuTiP&lt;/a&gt; - Quantum Toolbox in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.rdkit.org/" rel="nofollow"&gt;RDKit&lt;/a&gt; - Cheminformatics and Machine Learning Software.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.scipy.org/" rel="nofollow"&gt;SciPy&lt;/a&gt; - A Python-based ecosystem of open-source software for mathematics, science, and engineering.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/statsmodels/statsmodels"&gt;statsmodels&lt;/a&gt; - Statistical modeling and econometrics in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sympy/sympy"&gt;SymPy&lt;/a&gt; - A Python library for symbolic mathematics.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/quantopian/zipline"&gt;Zipline&lt;/a&gt; - A Pythonic algorithmic trading library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bitbucket.org/simpy/simpy" rel="nofollow"&gt;SimPy&lt;/a&gt; -  A process-based discrete-event simulation framework.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-search" class="anchor" aria-hidden="true" href="#search"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Search&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries and software for indexing and performing search queries on data.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/index.html" rel="nofollow"&gt;elasticsearch-py&lt;/a&gt; - The official low-level Python client for &lt;a href="https://www.elastic.co/products/elasticsearch" rel="nofollow"&gt;Elasticsearch&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/elastic/elasticsearch-dsl-py"&gt;elasticsearch-dsl-py&lt;/a&gt; - The official high-level Python client for Elasticsearch.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/django-haystack/django-haystack"&gt;django-haystack&lt;/a&gt; - Modular search for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/django-haystack/pysolr"&gt;pysolr&lt;/a&gt; - A lightweight Python wrapper for &lt;a href="https://lucene.apache.org/solr/" rel="nofollow"&gt;Apache Solr&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://whoosh.readthedocs.io/en/latest/" rel="nofollow"&gt;whoosh&lt;/a&gt; - A fast, pure Python search engine library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-serialization" class="anchor" aria-hidden="true" href="#serialization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Serialization&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for serializing complex data types&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/marshmallow-code/marshmallow"&gt;marshmallow&lt;/a&gt; - A lightweight library for converting complex objects to and from simple Python datatypes.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TkTech/pysimdjson"&gt;pysimdjson&lt;/a&gt; - A Python bindings for &lt;a href="https://github.com/lemire/simdjson"&gt;simdjson&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/python-rapidjson/python-rapidjson"&gt;python-rapidjson&lt;/a&gt; - A Python wrapper around &lt;a href="https://github.com/Tencent/rapidjson"&gt;RapidJSON&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-serverless-frameworks" class="anchor" aria-hidden="true" href="#serverless-frameworks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Serverless Frameworks&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Frameworks for developing serverless Python code.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/nficano/python-lambda"&gt;python-lambda&lt;/a&gt; - A toolkit for developing and deploying Python code in AWS Lambda.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Miserlou/Zappa"&gt;Zappa&lt;/a&gt; - A tool for deploying WSGI applications on AWS Lambda and API Gateway.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-specific-formats-processing" class="anchor" aria-hidden="true" href="#specific-formats-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Specific Formats Processing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for parsing and manipulating specific text formats.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;General
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/tablib"&gt;tablib&lt;/a&gt; - A module for Tabular Datasets in XLS, CSV, JSON, YAML.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Office
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://openpyxl.readthedocs.io/en/stable/" rel="nofollow"&gt;openpyxl&lt;/a&gt; - A library for reading and writing Excel 2010 xlsx/xlsm/xltx/xltm files.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pyexcel/pyexcel"&gt;pyexcel&lt;/a&gt; - Providing one API for reading, manipulating and writing csv, ods, xls, xlsx and xlsm files.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/python-openxml/python-docx"&gt;python-docx&lt;/a&gt; - Reads, queries and modifies Microsoft Word 2007/2008 docx files.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/scanny/python-pptx"&gt;python-pptx&lt;/a&gt; - Python library for creating and updating PowerPoint (.pptx) files.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/unoconv/unoconv"&gt;unoconv&lt;/a&gt; - Convert between any document format supported by LibreOffice/OpenOffice.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jmcnamara/XlsxWriter"&gt;XlsxWriter&lt;/a&gt; - A Python module for creating Excel .xlsx files.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ZoomerAnalytics/xlwings"&gt;xlwings&lt;/a&gt; - A BSD-licensed library that makes it easy to call Python from Excel and vice versa.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/python-excel/xlwt"&gt;xlwt&lt;/a&gt; / &lt;a href="https://github.com/python-excel/xlrd"&gt;xlrd&lt;/a&gt; - Writing and reading data and formatting information from Excel files.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PDF
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/euske/pdfminer"&gt;PDFMiner&lt;/a&gt; - A tool for extracting information from PDF documents.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mstamy2/PyPDF2"&gt;PyPDF2&lt;/a&gt; - A library capable of splitting, merging and transforming PDF pages.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reportlab.com/opensource/" rel="nofollow"&gt;ReportLab&lt;/a&gt; - Allowing Rapid creation of rich PDF documents.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Markdown
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/lepture/mistune"&gt;Mistune&lt;/a&gt; - Fastest and full featured pure Python parsers of Markdown.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/waylan/Python-Markdown"&gt;Python-Markdown&lt;/a&gt; - A Python implementation of John Gruber’s Markdown.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;YAML
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://pyyaml.org/" rel="nofollow"&gt;PyYAML&lt;/a&gt; - YAML implementations for Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CSV
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/wireservice/csvkit"&gt;csvkit&lt;/a&gt; - Utilities for converting to and working with CSV.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Archive
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/mitsuhiko/unp"&gt;unp&lt;/a&gt; - A command line tool that can unpack archives easily.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-static-site-generator" class="anchor" aria-hidden="true" href="#static-site-generator"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Static Site Generator&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Static site generator is a software that takes some text + templates as input and produces HTML files on the output.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/mkdocs/mkdocs/"&gt;mkdocs&lt;/a&gt; - Markdown friendly documentation generator.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getpelican/pelican"&gt;pelican&lt;/a&gt; - Static site generator that supports Markdown and reST syntax.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lektor/lektor"&gt;lektor&lt;/a&gt; - An easy to use static CMS and blog engine.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getnikola/nikola"&gt;nikola&lt;/a&gt; - A static website and blog generator.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-tagging" class="anchor" aria-hidden="true" href="#tagging"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tagging&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for tagging items.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jazzband/django-taggit"&gt;django-taggit&lt;/a&gt; - Simple tagging for Django.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-template-engine" class="anchor" aria-hidden="true" href="#template-engine"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Template Engine&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries and tools for templating and lexing.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pallets/jinja"&gt;Jinja2&lt;/a&gt; - A modern and designer friendly templating language.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://genshi.edgewall.org/" rel="nofollow"&gt;Genshi&lt;/a&gt; - Python templating toolkit for generation of web-aware output.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.makotemplates.org/" rel="nofollow"&gt;Mako&lt;/a&gt; - Hyperfast and lightweight templating for the Python platform.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-testing" class="anchor" aria-hidden="true" href="#testing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Testing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for testing codebases and generating test data.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Testing Frameworks
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.pytest.org/en/latest/" rel="nofollow"&gt;pytest&lt;/a&gt; - A mature full-featured Python testing tool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/HypothesisWorks/hypothesis"&gt;hypothesis&lt;/a&gt; - Hypothesis is an advanced Quickcheck style property based testing library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nose-devs/nose2"&gt;nose2&lt;/a&gt; - The successor to &lt;code&gt;nose&lt;/code&gt;, based on `unittest2.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/robotframework/robotframework"&gt;Robot Framework&lt;/a&gt; - A generic test automation framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/unittest.html" rel="nofollow"&gt;unittest&lt;/a&gt; - (Python standard library) Unit testing framework.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Test Runners
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/CleanCut/green"&gt;green&lt;/a&gt; - A clean, colorful test runner.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nestorsalceda.github.io/mamba/" rel="nofollow"&gt;mamba&lt;/a&gt; - The definitive testing tool for Python. Born under the banner of BDD.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tox.readthedocs.io/en/latest/" rel="nofollow"&gt;tox&lt;/a&gt; - Auto builds and tests distributions in multiple Python versions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GUI / Web Testing
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/locustio/locust"&gt;locust&lt;/a&gt; - Scalable user load testing tool written in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/asweigart/pyautogui"&gt;PyAutoGUI&lt;/a&gt; - PyAutoGUI is a cross-platform GUI automation Python module for human beings.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/selenium/" rel="nofollow"&gt;Selenium&lt;/a&gt; - Python bindings for &lt;a href="http://www.seleniumhq.org/" rel="nofollow"&gt;Selenium&lt;/a&gt; WebDriver.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/seatgeek/sixpack"&gt;sixpack&lt;/a&gt; - A language-agnostic A/B Testing framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cobrateam/splinter"&gt;splinter&lt;/a&gt; - Open source tool for testing web applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mock
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/unittest.mock.html" rel="nofollow"&gt;mock&lt;/a&gt; - (Python standard library) A mocking and patching library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/doublex/" rel="nofollow"&gt;doublex&lt;/a&gt; - Powerful test doubles framework for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/spulec/freezegun"&gt;freezegun&lt;/a&gt; - Travel through time by mocking the datetime module.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/patrys/httmock"&gt;httmock&lt;/a&gt; - A mocking library for requests for Python 2.6+ and 3.2+.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gabrielfalcao/HTTPretty"&gt;httpretty&lt;/a&gt; - HTTP request mock tool for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mindflayer/python-mocket"&gt;mocket&lt;/a&gt; - A socket mock framework with gevent/asyncio/SSL support.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getsentry/responses"&gt;responses&lt;/a&gt; - A utility library for mocking out the requests Python library.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kevin1024/vcrpy"&gt;VCR.py&lt;/a&gt; - Record and replay HTTP interactions on your tests.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Object Factories
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/FactoryBoy/factory_boy"&gt;factory_boy&lt;/a&gt; - A test fixtures replacement for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/klen/mixer"&gt;mixer&lt;/a&gt; - Another fixtures replacement. Supported Django, Flask, SQLAlchemy, Peewee and etc.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/vandersonmota/model_mommy"&gt;model_mommy&lt;/a&gt; - Creating random fixtures for testing in Django.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Code Coverage
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/coverage/" rel="nofollow"&gt;coverage&lt;/a&gt; - Code coverage measurement.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fake Data
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/lk-geimfari/mimesis"&gt;mimesis&lt;/a&gt; - is a Python library that help you generate fake data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/emirozer/fake2db"&gt;fake2db&lt;/a&gt; - Fake database generator.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/joke2k/faker"&gt;faker&lt;/a&gt; - A Python package that generates fake data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/radar/" rel="nofollow"&gt;radar&lt;/a&gt; - Generate random datetime / time.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-text-processing" class="anchor" aria-hidden="true" href="#text-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Text Processing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for parsing and manipulating plain texts.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;General
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/chardet/chardet"&gt;chardet&lt;/a&gt; - Python 2/3 compatible character encoding detector.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/difflib.html" rel="nofollow"&gt;difflib&lt;/a&gt; - (Python standard library) Helpers for computing deltas.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/LuminosoInsight/python-ftfy"&gt;ftfy&lt;/a&gt; - Makes Unicode text less broken and more consistent automagically.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/seatgeek/fuzzywuzzy"&gt;fuzzywuzzy&lt;/a&gt; - Fuzzy String Matching.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ztane/python-Levenshtein/"&gt;Levenshtein&lt;/a&gt; - Fast computation of Levenshtein distance and string similarity.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/vinta/pangu.py"&gt;pangu.py&lt;/a&gt; - Paranoid text spacing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pwaller/pyfiglet"&gt;pyfiglet&lt;/a&gt; - An implementation of figlet written in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mozillazg/python-pinyin"&gt;pypinyin&lt;/a&gt; - Convert Chinese hanzi (漢字) to pinyin (拼音).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/orsinium/textdistance"&gt;textdistance&lt;/a&gt; - Compute distance between sequences with 30+ algorithms.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/Unidecode/" rel="nofollow"&gt;unidecode&lt;/a&gt; - ASCII transliterations of Unicode text.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Slugify
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/dimka665/awesome-slugify"&gt;awesome-slugify&lt;/a&gt; - A Python slugify library that can preserve unicode.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/un33k/python-slugify"&gt;python-slugify&lt;/a&gt; - A Python slugify library that translates unicode to ASCII.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mozilla/unicode-slugify"&gt;unicode-slugify&lt;/a&gt; - A slugifier that generates unicode slugs with Django as a dependency.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Unique identifiers
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/davidaurelio/hashids-python"&gt;hashids&lt;/a&gt; - Implementation of &lt;a href="http://hashids.org" rel="nofollow"&gt;hashids&lt;/a&gt; in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/skorokithakis/shortuuid"&gt;shortuuid&lt;/a&gt; - A generator library for concise, unambiguous and URL-safe UUIDs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Parser
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/dabeaz/ply"&gt;ply&lt;/a&gt; - Implementation of lex and yacc parsing tools for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pygments.org/" rel="nofollow"&gt;pygments&lt;/a&gt; - A generic syntax highlighter.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pyparsing/pyparsing"&gt;pyparsing&lt;/a&gt; - A general purpose framework for generating parsers.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/derek73/python-nameparser"&gt;python-nameparser&lt;/a&gt; - Parsing human names into their individual components.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/daviddrysdale/python-phonenumbers"&gt;python-phonenumbers&lt;/a&gt; - Parsing, formatting, storing and validating international phone numbers.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/selwin/python-user-agents"&gt;python-user-agents&lt;/a&gt; - Browser user agent parser.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/andialbrecht/sqlparse"&gt;sqlparse&lt;/a&gt; - A non-validating SQL parser.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-third-party-apis" class="anchor" aria-hidden="true" href="#third-party-apis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Third-party APIs&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for accessing third party services APIs. Also see &lt;a href="https://github.com/realpython/list-of-python-api-wrappers"&gt;List of Python API Wrappers and Libraries&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://libcloud.apache.org/" rel="nofollow"&gt;apache-libcloud&lt;/a&gt; - One Python library for all clouds.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/boto/boto3"&gt;boto3&lt;/a&gt; - Python interface to Amazon Web Services.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/istrategylabs/django-wordpress"&gt;django-wordpress&lt;/a&gt; - WordPress models and views for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mobolic/facebook-sdk"&gt;facebook-sdk&lt;/a&gt; - Facebook Platform Python SDK.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/google/google-api-python-client"&gt;google-api-python-client&lt;/a&gt; - Google APIs Client Library for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/burnash/gspread"&gt;gspread&lt;/a&gt; - Google Spreadsheets Python API.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ryanmcgrath/twython"&gt;twython&lt;/a&gt; - A Python wrapper for the Twitter API.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-url-manipulation" class="anchor" aria-hidden="true" href="#url-manipulation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;URL Manipulation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for parsing URLs.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/gruns/furl"&gt;furl&lt;/a&gt; - A small Python library that makes parsing and manipulating URLs easy.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/codeinthehole/purl"&gt;purl&lt;/a&gt; - A simple, immutable URL class with a clean API for interrogation and manipulation.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ellisonleao/pyshorteners"&gt;pyshorteners&lt;/a&gt; - A pure Python URL shortening lib.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/marshmallow-code/webargs"&gt;webargs&lt;/a&gt; - A friendly library for parsing HTTP request arguments with built-in support for popular web frameworks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-video" class="anchor" aria-hidden="true" href="#video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Video&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for manipulating video and GIFs.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zulko.github.io/moviepy/" rel="nofollow"&gt;moviepy&lt;/a&gt; - A module for script-based movie editing with many formats, including animated GIFs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/aizvorski/scikit-video"&gt;scikit-video&lt;/a&gt; - Video processing routines for SciPy.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-wsgi-servers" class="anchor" aria-hidden="true" href="#wsgi-servers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WSGI Servers&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;WSGI-compatible web servers.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jonashaag/bjoern"&gt;bjoern&lt;/a&gt; - Asynchronous, very fast and written in C.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/benoitc/gunicorn"&gt;gunicorn&lt;/a&gt; - Pre-forked, partly written in C.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://uwsgi-docs.readthedocs.io/en/latest/" rel="nofollow"&gt;uWSGI&lt;/a&gt; - A project aims at developing a full stack for building hosting services, written in C.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Pylons/waitress"&gt;waitress&lt;/a&gt; - Multi-threaded, powers Pyramid.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pallets/werkzeug"&gt;werkzeug&lt;/a&gt; - A WSGI utility library for Python that powers Flask and can easily be embedded into your own projects.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-web-asset-management" class="anchor" aria-hidden="true" href="#web-asset-management"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web Asset Management&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Tools for managing, compressing and minifying website assets.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/django-compressor/django-compressor"&gt;django-compressor&lt;/a&gt; - Compresses linked and inline JavaScript or CSS into a single cached file.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jazzband/django-pipeline"&gt;django-pipeline&lt;/a&gt; - An asset packaging library for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jschneier/django-storages"&gt;django-storages&lt;/a&gt; - A collection of custom storage back ends for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.fanstatic.org/en/latest/" rel="nofollow"&gt;fanstatic&lt;/a&gt; - Packages, optimizes, and serves static file dependencies as Python packages.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://wimleers.com/fileconveyor" rel="nofollow"&gt;fileconveyor&lt;/a&gt; - A daemon to detect and sync files to CDNs, S3 and FTP.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/miracle2k/flask-assets"&gt;flask-assets&lt;/a&gt; - Helps you integrate webassets into your Flask app.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/miracle2k/webassets"&gt;webassets&lt;/a&gt; - Bundles, optimizes, and manages unique cache-busting URLs for static resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-web-content-extracting" class="anchor" aria-hidden="true" href="#web-content-extracting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web Content Extracting&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for extracting web contents.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Alir3z4/html2text"&gt;html2text&lt;/a&gt; - Convert HTML to Markdown-formatted text.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/michaelhelmick/lassie"&gt;lassie&lt;/a&gt; - Web Content Retrieval for Humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/coleifer/micawber"&gt;micawber&lt;/a&gt; - A small library for extracting rich content from URLs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/codelucas/newspaper"&gt;newspaper&lt;/a&gt; - News extraction, article extraction and content curation in Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/buriy/python-readability"&gt;python-readability&lt;/a&gt; - Fast Python port of arc90's readability tool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kennethreitz/requests-html"&gt;requests-html&lt;/a&gt; - Pythonic HTML Parsing for Humans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/miso-belica/sumy"&gt;sumy&lt;/a&gt; - A module for automatic summarization of text documents and HTML pages.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/deanmalmgren/textract"&gt;textract&lt;/a&gt; - Extract text from any document, Word, PowerPoint, PDFs, etc.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gaojiuli/toapi"&gt;toapi&lt;/a&gt; - Every web site provides APIs.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-web-crawling" class="anchor" aria-hidden="true" href="#web-crawling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web Crawling&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries to automate web scraping.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/chineking/cola"&gt;cola&lt;/a&gt; - A distributed crawling framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pythonhosted.org/feedparser/" rel="nofollow"&gt;feedparser&lt;/a&gt; - Universal feed parser.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lorien/grab"&gt;grab&lt;/a&gt; - Site scraping framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MechanicalSoup/MechanicalSoup"&gt;MechanicalSoup&lt;/a&gt; - A Python library for automating interaction with websites.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/binux/pyspider"&gt;pyspider&lt;/a&gt; - A powerful spider system.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jmcarp/robobrowser"&gt;robobrowser&lt;/a&gt; - A simple, Pythonic library for browsing the web without a standalone web browser.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://scrapy.org/" rel="nofollow"&gt;scrapy&lt;/a&gt; - A fast high-level screen scraping and web crawling framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/scrapinghub/portia"&gt;portia&lt;/a&gt; - Visual scraping for Scrapy.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-web-frameworks" class="anchor" aria-hidden="true" href="#web-frameworks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web Frameworks&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Full stack web frameworks.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.djangoproject.com/" rel="nofollow"&gt;Django&lt;/a&gt; - The most popular web framework in Python.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/shahraizali/awesome-django"&gt;awesome-django&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://flask.pocoo.org/" rel="nofollow"&gt;Flask&lt;/a&gt; - A microframework for Python.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/humiaozuzu/awesome-flask"&gt;awesome-flask&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MasoniteFramework/masonite"&gt;Masonite&lt;/a&gt; - The modern and developer centric Python web framework.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pylonsproject.org/" rel="nofollow"&gt;Pyramid&lt;/a&gt; - A small, fast, down-to-earth, open source Python web framework.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/uralbash/awesome-pyramid"&gt;awesome-pyramid&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/channelcat/sanic"&gt;Sanic&lt;/a&gt; - Web server that's written to go fast.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://vibora.io/" rel="nofollow"&gt;Vibora&lt;/a&gt; - Fast, efficient and asynchronous Web framework inspired by Flask.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.tornadoweb.org/en/latest/" rel="nofollow"&gt;Tornado&lt;/a&gt; - A Web framework and asynchronous networking library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-websocket" class="anchor" aria-hidden="true" href="#websocket"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WebSocket&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Libraries for working with WebSocket.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/crossbario/autobahn-python"&gt;autobahn-python&lt;/a&gt; - WebSocket &amp;amp; WAMP for Python on Twisted and &lt;a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow"&gt;asyncio&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/crossbario/crossbar/"&gt;crossbar&lt;/a&gt; - Open-source Unified Application Router (Websocket &amp;amp; WAMP for Python on Autobahn).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/django/channels"&gt;django-channels&lt;/a&gt; - Developer-friendly asynchrony for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/stephenmcd/django-socketio"&gt;django-socketio&lt;/a&gt; - WebSockets for Django.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Lawouach/WebSocket-for-Python"&gt;WebSocket-for-Python&lt;/a&gt; - WebSocket client and server library for Python 2 and 3 as well as PyPy.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-services" class="anchor" aria-hidden="true" href="#services"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Services&lt;/h1&gt;
&lt;p&gt;Online tools and APIs to simplify development.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-continuous-integration" class="anchor" aria-hidden="true" href="#continuous-integration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Continuous Integration&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Also see &lt;a href="https://github.com/ciandcd/awesome-ciandcd#online-build-system"&gt;awesome-CIandCD&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://circleci.com/" rel="nofollow"&gt;CircleCI&lt;/a&gt; - A CI service that can run very fast parallel testing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://travis-ci.org" rel="nofollow"&gt;Travis CI&lt;/a&gt; - A popular CI service for your open source and &lt;a href="https://travis-ci.com" rel="nofollow"&gt;private&lt;/a&gt; projects. (GitHub only)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://vexor.io" rel="nofollow"&gt;Vexor CI&lt;/a&gt; - A continuous integration tool for private apps with pay-per-minute billing model.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.wercker.com/" rel="nofollow"&gt;Wercker&lt;/a&gt; - A Docker-based platform for building and deploying applications and microservices.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-code-quality" class="anchor" aria-hidden="true" href="#code-quality"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code Quality&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.codacy.com/" rel="nofollow"&gt;Codacy&lt;/a&gt; - Automated Code Review to ship better code, faster.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://codecov.io/" rel="nofollow"&gt;Codecov&lt;/a&gt; - Code coverage dashboard.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.codefactor.io/" rel="nofollow"&gt;CodeFactor&lt;/a&gt; - Automated Code Review for Git.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://landscape.io/" rel="nofollow"&gt;Landscape&lt;/a&gt; - Hosted continuous Python code metrics.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pep8speaks.com/" rel="nofollow"&gt;PEP 8 Speaks&lt;/a&gt; - GitHub integration to review code style.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h1&gt;
&lt;p&gt;Where to discover new Python libraries.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-podcasts" class="anchor" aria-hidden="true" href="#podcasts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Podcasts&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://frompythonimportpodcast.com/" rel="nofollow"&gt;From Python Import Podcast&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://podcastinit.com/" rel="nofollow"&gt;Podcast.init&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pythonbytes.fm" rel="nofollow"&gt;Python Bytes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pythontesting.net" rel="nofollow"&gt;Python Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://radiofreepython.com/" rel="nofollow"&gt;Radio Free Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://talkpython.fm/" rel="nofollow"&gt;Talk Python To Me&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://testandcode.com/" rel="nofollow"&gt;Test and Code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-twitter" class="anchor" aria-hidden="true" href="#twitter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Twitter&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://twitter.com/codetengu" rel="nofollow"&gt;@codetengu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/getpy" rel="nofollow"&gt;@getpy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/importpython" rel="nofollow"&gt;@importpython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/planetpython" rel="nofollow"&gt;@planetpython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/pycoders" rel="nofollow"&gt;@pycoders&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/pypi" rel="nofollow"&gt;@pypi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/pythontrending" rel="nofollow"&gt;@pythontrending&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/PythonWeekly" rel="nofollow"&gt;@PythonWeekly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/talkpython" rel="nofollow"&gt;@TalkPython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/realpython" rel="nofollow"&gt;@realpython&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-websites" class="anchor" aria-hidden="true" href="#websites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Websites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/coolgithubprojects/" rel="nofollow"&gt;/r/CoolGithubProjects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/python" rel="nofollow"&gt;/r/Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://python.libhunt.com/" rel="nofollow"&gt;Awesome Python @LibHunt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://djangopackages.org/" rel="nofollow"&gt;Django Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.fullstackpython.com/" rel="nofollow"&gt;Full Stack Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.pythoncheatsheet.org/" rel="nofollow"&gt;Python Cheatsheet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://python.zeef.com/alan.richmond" rel="nofollow"&gt;Python ZEEF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ctolib.com/python/" rel="nofollow"&gt;Python 开发社区&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://realpython.com" rel="nofollow"&gt;Real Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/trending?l=python"&gt;Trending Python repositories on GitHub today&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://python-scripts.com/" rel="nofollow"&gt;Сообщество Python Программистов&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-weekly" class="anchor" aria-hidden="true" href="#weekly"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Weekly&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://weekly.codetengu.com/" rel="nofollow"&gt;CodeTengu Weekly 碼天狗週刊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://importpython.com/newsletter/" rel="nofollow"&gt;Import Python Newsletter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pycoders.com/" rel="nofollow"&gt;Pycoder's Weekly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pythonweekly.com/" rel="nofollow"&gt;Python Weekly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://realpython.com/python-tricks/" rel="nofollow"&gt;Python Tricks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h1&gt;
&lt;p&gt;Your contributions are always welcome! Please take a look at the &lt;a href="https://github.com/vinta/awesome-python/blob/master/CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt; first.&lt;/p&gt;
&lt;p&gt;I will keep some pull requests open if I'm not sure whether those libraries are awesome, you could &lt;a href="https://github.com/vinta/awesome-python/pulls"&gt;vote for them&lt;/a&gt; by adding &lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt; to them. Pull requests will be merged when their votes reach &lt;strong&gt;20&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;If you have any question about this opinionated list, do not hesitate to contact me &lt;a href="https://twitter.com/vinta" rel="nofollow"&gt;@vinta&lt;/a&gt; on Twitter or open an issue on GitHub.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>vinta</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>donnemartin/data-science-ipython-notebooks #8 in Python, This week</title><link>https://github.com/donnemartin/data-science-ipython-notebooks</link><description>&lt;p&gt;&lt;i&gt;Data science Python notebooks: Deep learning (TensorFlow, Theano, Caffe, Keras), scikit-learn, Kaggle, big data (Spark, Hadoop MapReduce, HDFS), matplotlib, pandas, NumPy, SciPy, Python essentials, AWS, and various command lines.&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/README_1200x800.gif"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/README_1200x800.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/coversmall_alt.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/coversmall_alt.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-data-science-ipython-notebooks" class="anchor" aria-hidden="true" href="#data-science-ipython-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;data-science-ipython-notebooks&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-index" class="anchor" aria-hidden="true" href="#index"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Index&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#deep-learning"&gt;deep-learning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#tensor-flow-tutorials"&gt;tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#theano-tutorials"&gt;theano&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#keras-tutorials"&gt;keras&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#deep-learning-misc"&gt;caffe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#scikit-learn"&gt;scikit-learn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#statistical-inference-scipy"&gt;statistical-inference-scipy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pandas"&gt;pandas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#matplotlib"&gt;matplotlib&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#numpy"&gt;numpy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#python-data"&gt;python-data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#kaggle-and-business-analyses"&gt;kaggle-and-business-analyses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#spark"&gt;spark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mapreduce-python"&gt;mapreduce-python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#aws"&gt;amazon web services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#commands"&gt;command lines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#misc"&gt;misc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#notebook-installation"&gt;notebook-installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#credits"&gt;credits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing"&gt;contributing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contact-info"&gt;contact-info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;license&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ee94aabdb3e1fc49fad71ea1ac9801c82095001d/687474703a2f2f692e696d6775722e636f6d2f5a684b58724b5a2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/ee94aabdb3e1fc49fad71ea1ac9801c82095001d/687474703a2f2f692e696d6775722e636f6d2f5a684b58724b5a2e706e67" data-canonical-src="http://i.imgur.com/ZhKXrKZ.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-deep-learning" class="anchor" aria-hidden="true" href="#deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;deep-learning&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating deep learning functionality.&lt;/p&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://avatars0.githubusercontent.com/u/15658638?v=3&amp;amp;s=100"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/15658638?v=3&amp;amp;s=100" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-tensor-flow-tutorials" class="anchor" aria-hidden="true" href="#tensor-flow-tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;tensor-flow-tutorials&lt;/h3&gt;
&lt;p&gt;Additional TensorFlow tutorials:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pkmital/tensorflow_tutorials"&gt;pkmital/tensorflow_tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nlintz/TensorFlow-Tutorials"&gt;nlintz/TensorFlow-Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/alrojo/tensorflow-tutorial"&gt;alrojo/tensorflow-tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/BinRoot/TensorFlow-Book"&gt;BinRoot/TensorFlow-Book&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tuanavu/tensorflow-basic-tutorials"&gt;tuanavu/tensorflow-basic-tutorials&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/1_intro/basic_operations.ipynb" rel="nofollow"&gt;tsf-basics&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/linear_regression.ipynb" rel="nofollow"&gt;tsf-linear&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement linear regression in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/logistic_regression.ipynb" rel="nofollow"&gt;tsf-logistic&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement logistic regression in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/nearest_neighbor.ipynb" rel="nofollow"&gt;tsf-nn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement nearest neighboars in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/alexnet.ipynb" rel="nofollow"&gt;tsf-alex&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement AlexNet in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/convolutional_network.ipynb" rel="nofollow"&gt;tsf-cnn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement convolutional neural networks in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/multilayer_perceptron.ipynb" rel="nofollow"&gt;tsf-mlp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement multilayer perceptrons in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/recurrent_network.ipynb" rel="nofollow"&gt;tsf-rnn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement recurrent neural networks in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/4_multi_gpu/multigpu_basics.ipynb" rel="nofollow"&gt;tsf-gpu&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about basic multi-GPU computation in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/graph_visualization.ipynb" rel="nofollow"&gt;tsf-gviz&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about graph visualization in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/loss_visualization.ipynb" rel="nofollow"&gt;tsf-lviz&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about loss visualization in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-tensor-flow-exercises" class="anchor" aria-hidden="true" href="#tensor-flow-exercises"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;tensor-flow-exercises&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/1_notmnist.ipynb" rel="nofollow"&gt;tsf-not-mnist&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/2_fullyconnected.ipynb" rel="nofollow"&gt;tsf-fully-connected&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Progressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/3_regularization.ipynb" rel="nofollow"&gt;tsf-regularization&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Explore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/4_convolutions.ipynb" rel="nofollow"&gt;tsf-convolutions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Create convolutional neural networks in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/5_word2vec.ipynb" rel="nofollow"&gt;tsf-word2vec&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Train a skip-gram model over Text8 data in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/6_lstm.ipynb" rel="nofollow"&gt;tsf-lstm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Train a LSTM character model over Text8 data in TensorFlow.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/f3f9ed69fc2544e3d53d866e01783a0f4facd3d8/687474703a2f2f7777772e646565706c6561726e696e672e6e65742f736f6674776172652f746865616e6f2f5f7374617469632f746865616e6f5f6c6f676f5f616c6c626c75655f3230307834362e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/f3f9ed69fc2544e3d53d866e01783a0f4facd3d8/687474703a2f2f7777772e646565706c6561726e696e672e6e65742f736f6674776172652f746865616e6f2f5f7374617469632f746865616e6f5f6c6f676f5f616c6c626c75655f3230307834362e706e67" data-canonical-src="http://www.deeplearning.net/software/theano/_static/theano_logo_allblue_200x46.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-theano-tutorials" class="anchor" aria-hidden="true" href="#theano-tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;theano-tutorials&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/intro_theano/intro_theano.ipynb" rel="nofollow"&gt;theano-intro&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Intro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/scan_tutorial/scan_tutorial.ipynb" rel="nofollow"&gt;theano-scan&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn scans, a mechanism to perform loops in a Theano graph.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/intro_theano/logistic_regression.ipynb" rel="nofollow"&gt;theano-logistic&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement logistic regression in Theano.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/rnn_tutorial/simple_rnn.ipynb" rel="nofollow"&gt;theano-rnn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement recurrent neural networks in Theano.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/theano_mlp/theano_mlp.ipynb" rel="nofollow"&gt;theano-mlp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement multilayer perceptrons in Theano.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/46a7861f9fd3f8b141c64dd3d01145874bf3546e/687474703a2f2f692e696d6775722e636f6d2f4c3435513863322e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/46a7861f9fd3f8b141c64dd3d01145874bf3546e/687474703a2f2f692e696d6775722e636f6d2f4c3435513863322e6a7067" data-canonical-src="http://i.imgur.com/L45Q8c2.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-keras-tutorials" class="anchor" aria-hidden="true" href="#keras-tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;keras-tutorials&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;keras&lt;/td&gt;
&lt;td&gt;Keras is an open source neural network library written in Python. It is capable of running on top of either Tensorflow or Theano.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/0.%20Preamble.ipynb" rel="nofollow"&gt;setup&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about the tutorial goals and how to set up your Keras environment.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.1%20Introduction%20-%20Deep%20Learning%20and%20ANN.ipynb" rel="nofollow"&gt;intro-deep-learning-ann&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Get an intro to deep learning with Keras and Artificial Neural Networks (ANN).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.2%20Introduction%20-%20Theano.ipynb" rel="nofollow"&gt;theano&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Theano by working with weights matrices and gradients.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.3%20Introduction%20-%20Keras.ipynb" rel="nofollow"&gt;keras-otto&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Keras by looking at the Kaggle Otto challenge.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.4%20%28Extra%29%20A%20Simple%20Implementation%20of%20ANN%20for%20MNIST.ipynb" rel="nofollow"&gt;ann-mnist&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Review a simple implementation of ANN for MNIST using Keras.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.1%20Supervised%20Learning%20-%20ConvNets.ipynb" rel="nofollow"&gt;conv-nets&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Convolutional Neural Networks (CNNs) with Keras.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.2.1%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20I.ipynb" rel="nofollow"&gt;conv-net-1&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Recognize handwritten digits from MNIST using Keras - Part 1.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.2.2%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20II.ipynb" rel="nofollow"&gt;conv-net-2&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Recognize handwritten digits from MNIST using Keras - Part 2.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.3%20Supervised%20Learning%20-%20Famous%20Models%20with%20Keras.ipynb" rel="nofollow"&gt;keras-models&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Use pre-trained models such as VGG16, VGG19, ResNet50, and Inception v3 with Keras.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.1%20Unsupervised%20Learning%20-%20AutoEncoders%20and%20Embeddings.ipynb" rel="nofollow"&gt;auto-encoders&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Autoencoders with Keras.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.2%20RNN%20and%20LSTM.ipynb" rel="nofollow"&gt;rnn-lstm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Recurrent Neural Networks (RNNs) with Keras.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.3%20%28Extra%29%20LSTM%20for%20Sentence%20Generation.ipynb" rel="nofollow"&gt;lstm-sentence-gen&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about RNNs using Long Short Term Memory (LSTM) networks with Keras.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-deep-learning-misc" class="anchor" aria-hidden="true" href="#deep-learning-misc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;deep-learning-misc&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/deep-dream/dream.ipynb" rel="nofollow"&gt;deep-dream&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Caffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scikitlearn.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scikitlearn.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-scikit-learn" class="anchor" aria-hidden="true" href="#scikit-learn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;scikit-learn&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating scikit-learn functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-intro.ipynb" rel="nofollow"&gt;intro&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Intro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-intro.ipynb#K-Nearest-Neighbors-Classifier" rel="nofollow"&gt;knn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement k-nearest neighbors in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-linear-reg.ipynb" rel="nofollow"&gt;linear-reg&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement linear regression in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-svm.ipynb" rel="nofollow"&gt;svm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement support vector machine classifiers with and without kernels in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-random-forest.ipynb" rel="nofollow"&gt;random-forest&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement random forest classifiers and regressors in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-k-means.ipynb" rel="nofollow"&gt;k-means&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement k-means clustering in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-pca.ipynb" rel="nofollow"&gt;pca&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement principal component analysis in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-gmm.ipynb" rel="nofollow"&gt;gmm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement Gaussian mixture models in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-validation.ipynb" rel="nofollow"&gt;validation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Implement validation and model selection in scikit-learn.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scipy.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scipy.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-statistical-inference-scipy" class="anchor" aria-hidden="true" href="#statistical-inference-scipy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;statistical-inference-scipy&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating statistical inference with SciPy functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;scipy&lt;/td&gt;
&lt;td&gt;SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/effect_size.ipynb" rel="nofollow"&gt;effect-size&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Explore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/sampling.ipynb" rel="nofollow"&gt;sampling&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Explore random sampling by analyzing the average weight of men and women in the United States using BRFSS data.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/hypothesis.ipynb" rel="nofollow"&gt;hypothesis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Explore hypothesis testing by analyzing the difference of first-born babies compared with others.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/pandas.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/pandas.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pandas" class="anchor" aria-hidden="true" href="#pandas"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;pandas&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating pandas functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/pandas.ipynb" rel="nofollow"&gt;pandas&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Software library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/donnemartin/viz/blob/master/githubstats/data_wrangling.ipynb"&gt;github-data-wrangling&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn how to load, clean, merge, and feature engineer by analyzing GitHub data from the &lt;a href="https://github.com/donnemartin/viz"&gt;&lt;code&gt;Viz&lt;/code&gt;&lt;/a&gt; repo.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.00-Introduction-to-Pandas.ipynb" rel="nofollow"&gt;Introduction-to-Pandas&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Introduction to Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.01-Introducing-Pandas-Objects.ipynb" rel="nofollow"&gt;Introducing-Pandas-Objects&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Pandas objects.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.02-Data-Indexing-and-Selection.ipynb" rel="nofollow"&gt;Data Indexing and Selection&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about data indexing and selection in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.03-Operations-in-Pandas.ipynb" rel="nofollow"&gt;Operations-in-Pandas&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about operating on data in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.04-Missing-Values.ipynb" rel="nofollow"&gt;Missing-Values&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about handling missing data in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.05-Hierarchical-Indexing.ipynb" rel="nofollow"&gt;Hierarchical-Indexing&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about hierarchical indexing in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.06-Concat-And-Append.ipynb" rel="nofollow"&gt;Concat-And-Append&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about combining datasets: concat and append in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.07-Merge-and-Join.ipynb" rel="nofollow"&gt;Merge-and-Join&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about combining datasets: merge and join in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.08-Aggregation-and-Grouping.ipynb" rel="nofollow"&gt;Aggregation-and-Grouping&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about aggregation and grouping in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.09-Pivot-Tables.ipynb" rel="nofollow"&gt;Pivot-Tables&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about pivot tables in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.10-Working-With-Strings.ipynb" rel="nofollow"&gt;Working-With-Strings&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about vectorized string operations in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.11-Working-with-Time-Series.ipynb" rel="nofollow"&gt;Working-with-Time-Series&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about working with time series in pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.12-Performance-Eval-and-Query.ipynb" rel="nofollow"&gt;Performance-Eval-and-Query&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about high-performance Pandas: eval() and query() in Pandas.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/matplotlib.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/matplotlib.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-matplotlib" class="anchor" aria-hidden="true" href="#matplotlib"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;matplotlib&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating matplotlib functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/matplotlib.ipynb" rel="nofollow"&gt;matplotlib&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/matplotlib-applied.ipynb" rel="nofollow"&gt;matplotlib-applied&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Apply matplotlib visualizations to Kaggle competitions for exploratory data analysis.  Learn how to create bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.00-Introduction-To-Matplotlib.ipynb" rel="nofollow"&gt;Introduction-To-Matplotlib&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Introduction to Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.01-Simple-Line-Plots.ipynb" rel="nofollow"&gt;Simple-Line-Plots&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about simple line plots in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.02-Simple-Scatter-Plots.ipynb" rel="nofollow"&gt;Simple-Scatter-Plots&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about simple scatter plots in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.03-Errorbars.ipynb" rel="nofollow"&gt;Errorbars.ipynb&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about visualizing errors in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.04-Density-and-Contour-Plots.ipynb" rel="nofollow"&gt;Density-and-Contour-Plots&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about density and contour plots in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.05-Histograms-and-Binnings.ipynb" rel="nofollow"&gt;Histograms-and-Binnings&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about histograms, binnings, and density in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.06-Customizing-Legends.ipynb" rel="nofollow"&gt;Customizing-Legends&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about customizing plot legends in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.07-Customizing-Colorbars.ipynb" rel="nofollow"&gt;Customizing-Colorbars&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about customizing colorbars in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.08-Multiple-Subplots.ipynb" rel="nofollow"&gt;Multiple-Subplots&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about multiple subplots in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.09-Text-and-Annotation.ipynb" rel="nofollow"&gt;Text-and-Annotation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about text and annotation in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.10-Customizing-Ticks.ipynb" rel="nofollow"&gt;Customizing-Ticks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about customizing ticks in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.11-Settings-and-Stylesheets.ipynb" rel="nofollow"&gt;Settings-and-Stylesheets&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about customizing Matplotlib: configurations and stylesheets.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.12-Three-Dimensional-Plotting.ipynb" rel="nofollow"&gt;Three-Dimensional-Plotting&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about three-dimensional plotting in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.13-Geographic-Data-With-Basemap.ipynb" rel="nofollow"&gt;Geographic-Data-With-Basemap&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about geographic data with basemap in Matplotlib.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.14-Visualization-With-Seaborn.ipynb" rel="nofollow"&gt;Visualization-With-Seaborn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about visualization with Seaborn.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-numpy" class="anchor" aria-hidden="true" href="#numpy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;numpy&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating NumPy functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/numpy.ipynb" rel="nofollow"&gt;numpy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.00-Introduction-to-NumPy.ipynb" rel="nofollow"&gt;Introduction-to-NumPy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Introduction to NumPy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.01-Understanding-Data-Types.ipynb" rel="nofollow"&gt;Understanding-Data-Types&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about data types in Python.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.02-The-Basics-Of-NumPy-Arrays.ipynb" rel="nofollow"&gt;The-Basics-Of-NumPy-Arrays&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about the basics of NumPy arrays.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.03-Computation-on-arrays-ufuncs.ipynb" rel="nofollow"&gt;Computation-on-arrays-ufuncs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about computations on NumPy arrays: universal functions.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.04-Computation-on-arrays-aggregates.ipynb" rel="nofollow"&gt;Computation-on-arrays-aggregates&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about aggregations: min, max, and everything in between in NumPy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.05-Computation-on-arrays-broadcasting.ipynb" rel="nofollow"&gt;Computation-on-arrays-broadcasting&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about computation on arrays: broadcasting in NumPy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.06-Boolean-Arrays-and-Masks.ipynb" rel="nofollow"&gt;Boolean-Arrays-and-Masks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about comparisons, masks, and boolean logic in NumPy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.07-Fancy-Indexing.ipynb" rel="nofollow"&gt;Fancy-Indexing&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about fancy indexing in NumPy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.08-Sorting.ipynb" rel="nofollow"&gt;Sorting&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about sorting arrays in NumPy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.09-Structured-Data-NumPy.ipynb" rel="nofollow"&gt;Structured-Data-NumPy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about structured data: NumPy's structured arrays.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/python.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/python.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-python-data" class="anchor" aria-hidden="true" href="#python-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;python-data&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating Python functionality geared towards data analysis.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/structs.ipynb" rel="nofollow"&gt;data structures&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn Python basics with tuples, lists, dicts, sets.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/structs_utils.ipynb" rel="nofollow"&gt;data structure utilities&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/functions.ipynb" rel="nofollow"&gt;functions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about more advanced Python features: Functions as objects, lambda functions, closures, *args, **kwargs currying, generators, generator expressions, itertools.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/datetime.ipynb" rel="nofollow"&gt;datetime&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn how to work with Python dates and times: datetime, strftime, strptime, timedelta.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/logs.ipynb" rel="nofollow"&gt;logging&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn about Python logging with RotatingFileHandler and TimedRotatingFileHandler.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/pdb.ipynb" rel="nofollow"&gt;pdb&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn how to debug in Python with the interactive source code debugger.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/unit_tests.ipynb" rel="nofollow"&gt;unit tests&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Learn how to test in Python with Nose unit tests.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/kaggle.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/kaggle.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-kaggle-and-business-analyses" class="anchor" aria-hidden="true" href="#kaggle-and-business-analyses"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;kaggle-and-business-analyses&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) used in &lt;a href="https://www.kaggle.com/" rel="nofollow"&gt;kaggle&lt;/a&gt; competitions and business analyses.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb" rel="nofollow"&gt;titanic&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Predict survival on the Titanic.  Learn data cleaning, exploratory data analysis, and machine learning.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/analyses/churn.ipynb" rel="nofollow"&gt;churn-analysis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Predict customer churn.  Exercise logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Includes discussions of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/spark.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/spark.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-spark" class="anchor" aria-hidden="true" href="#spark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;spark&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating spark and HDFS functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/spark/spark.ipynb" rel="nofollow"&gt;spark&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;In-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/spark/hdfs.ipynb" rel="nofollow"&gt;hdfs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Reliably stores very large files across machines in a large cluster.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/mrjob.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/mrjob.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-mapreduce-python" class="anchor" aria-hidden="true" href="#mapreduce-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;mapreduce-python&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/mapreduce/mapreduce-python.ipynb" rel="nofollow"&gt;mapreduce-python&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Runs MapReduce jobs in Python, executing jobs locally or on Hadoop clusters. Demonstrates Hadoop Streaming in Python code with unit test and &lt;a href="https://github.com/Yelp/mrjob"&gt;mrjob&lt;/a&gt; config file to analyze Amazon S3 bucket logs on Elastic MapReduce.  &lt;a href="https://github.com/discoproject/disco/"&gt;Disco&lt;/a&gt; is another python-based alternative.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/aws.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/aws.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-aws" class="anchor" aria-hidden="true" href="#aws"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;aws&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating Amazon Web Services (AWS) and AWS tools functionality.&lt;/p&gt;
&lt;p&gt;Also check out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/saws"&gt;SAWS&lt;/a&gt;: A Supercharged AWS command line interface (CLI).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/awesome-aws"&gt;Awesome AWS&lt;/a&gt;: A curated list of libraries, open source repos, guides, blogs, and other resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#Boto" rel="nofollow"&gt;boto&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Official AWS SDK for Python.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3cmd" rel="nofollow"&gt;s3cmd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Interacts with S3 through the command line.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3distcp" rel="nofollow"&gt;s3distcp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Combines smaller files and aggregates them together by taking in a pattern and target file.  S3DistCp can also be used to transfer large volumes of data from S3 to your Hadoop cluster.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3-parallel-put" rel="nofollow"&gt;s3-parallel-put&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Uploads multiple files to S3 in parallel.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#redshift" rel="nofollow"&gt;redshift&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Acts as a fast data warehouse built on top of technology from massive parallel processing (MPP).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#kinesis" rel="nofollow"&gt;kinesis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Streams data in real time with the ability to process thousands of data streams per second.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#lambda" rel="nofollow"&gt;lambda&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Runs code in response to events, automatically managing compute resources.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/commands.png"&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/commands.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-commands" class="anchor" aria-hidden="true" href="#commands"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;commands&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating various command lines for Linux, Git, etc.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/linux.ipynb" rel="nofollow"&gt;linux&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Unix-like and mostly POSIX-compliant computer operating system.  Disk usage, splitting files, grep, sed, curl, viewing running processes, terminal syntax highlighting, and Vim.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#anaconda" rel="nofollow"&gt;anaconda&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing, that aims to simplify package management and deployment.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#ipython-notebook" rel="nofollow"&gt;ipython notebook&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Web-based interactive computational environment where you can combine code execution, text, mathematics, plots and rich media into a single document.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#git" rel="nofollow"&gt;git&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Distributed revision control system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#ruby" rel="nofollow"&gt;ruby&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Used to interact with the AWS command line and for Jekyll, a blog framework that can be hosted on GitHub Pages.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#jekyll" rel="nofollow"&gt;jekyll&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Simple, blog-aware, static site generator for personal, project, or organization sites.  Renders Markdown or Textile and Liquid templates, and produces a complete, static website ready to be served by Apache HTTP Server, Nginx or another web server.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#pelican" rel="nofollow"&gt;pelican&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Python-based alternative to Jekyll.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#django" rel="nofollow"&gt;django&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;High-level Python Web framework that encourages rapid development and clean, pragmatic design. It can be useful to share reports/analyses and for blogging. Lighter-weight alternatives include &lt;a href="https://github.com/Pylons/pyramid"&gt;Pyramid&lt;/a&gt;, &lt;a href="https://github.com/pallets/flask"&gt;Flask&lt;/a&gt;, &lt;a href="https://github.com/tornadoweb/tornado"&gt;Tornado&lt;/a&gt;, and &lt;a href="https://github.com/bottlepy/bottle"&gt;Bottle&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-misc" class="anchor" aria-hidden="true" href="#misc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;misc&lt;/h2&gt;
&lt;p&gt;IPython Notebook(s) demonstrating miscellaneous functionality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Notebook&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/misc/regex.ipynb" rel="nofollow"&gt;regex&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Regular expression cheat sheet useful in data wrangling.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/misc/Algorithmia.ipynb" rel="nofollow"&gt;algorithmia&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Algorithmia is a marketplace for algorithms. This notebook showcases 4 different algorithms: Face Detection, Content Summarizer, Latent Dirichlet Allocation and Optical Character Recognition.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-notebook-installation" class="anchor" aria-hidden="true" href="#notebook-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;notebook-installation&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-anaconda" class="anchor" aria-hidden="true" href="#anaconda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;anaconda&lt;/h3&gt;
&lt;p&gt;Anaconda is a free distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing that aims to simplify package management and deployment.&lt;/p&gt;
&lt;p&gt;Follow instructions to install &lt;a href="https://docs.continuum.io/anaconda/install" rel="nofollow"&gt;Anaconda&lt;/a&gt; or the more lightweight &lt;a href="http://conda.pydata.org/miniconda.html" rel="nofollow"&gt;miniconda&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-dev-setup" class="anchor" aria-hidden="true" href="#dev-setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;dev-setup&lt;/h3&gt;
&lt;p&gt;For detailed instructions, scripts, and tools to set up your development environment for data analysis, check out the &lt;a href="https://github.com/donnemartin/dev-setup"&gt;dev-setup&lt;/a&gt; repo.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-running-notebooks" class="anchor" aria-hidden="true" href="#running-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;running-notebooks&lt;/h3&gt;
&lt;p&gt;To view interactive content or to modify elements within the IPython notebooks, you must first clone or download the repository then run the notebook.  More information on IPython Notebooks can be found &lt;a href="http://ipython.org/notebook.html" rel="nofollow"&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/donnemartin/data-science-ipython-notebooks.git
$ cd data-science-ipython-notebooks
$ jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notebooks tested with Python 2.7.x.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;credits&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793" rel="nofollow"&gt;Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython&lt;/a&gt; by Wes McKinney&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jakevdp/sklearn_pycon2015"&gt;PyCon 2015 Scikit-learn Tutorial&lt;/a&gt; by Jake VanderPlas&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jakevdp/PythonDataScienceHandbook"&gt;Python Data Science Handbook&lt;/a&gt; by Jake VanderPlas&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ogrisel/parallel_ml_tutorial"&gt;Parallel Machine Learning with scikit-learn and IPython&lt;/a&gt; by Olivier Grisel&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/AllenDowney/CompStats"&gt;Statistical Interference Using Computational Methods in Python&lt;/a&gt; by Allen Downey&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/aymericdamien/TensorFlow-Examples"&gt;TensorFlow Examples&lt;/a&gt; by Aymeric Damien&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pkmital/tensorflow_tutorials"&gt;TensorFlow Tutorials&lt;/a&gt; by Parag K Mital&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nlintz/TensorFlow-Tutorials"&gt;TensorFlow Tutorials&lt;/a&gt; by Nathan Lintz&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/alrojo/tensorflow-tutorial"&gt;TensorFlow Tutorials&lt;/a&gt; by Alexander R Johansen&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/BinRoot/TensorFlow-Book"&gt;TensorFlow Book&lt;/a&gt; by Nishant Shukla&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mila-udem/summerschool2015"&gt;Summer School 2015&lt;/a&gt; by mila-udem&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/leriomaggio/deep-learning-keras-tensorflow"&gt;Keras tutorials&lt;/a&gt; by Valerio Maggio&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/" rel="nofollow"&gt;Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.yhat.com/" rel="nofollow"&gt;Yhat Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;contributing&lt;/h2&gt;
&lt;p&gt;Contributions are welcome!  For bug reports or requests please &lt;a href="https://github.com/donnemartin/data-science-ipython-notebooks/issues"&gt;submit an issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contact-info" class="anchor" aria-hidden="true" href="#contact-info"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;contact-info&lt;/h2&gt;
&lt;p&gt;Feel free to contact me to discuss any issues, questions, or comments.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Email: &lt;a href="mailto:donne.martin@gmail.com"&gt;donne.martin@gmail.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Twitter: &lt;a href="https://twitter.com/donne_martin" rel="nofollow"&gt;@donne_martin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href="https://github.com/donnemartin"&gt;donnemartin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;LinkedIn: &lt;a href="https://www.linkedin.com/in/donnemartin" rel="nofollow"&gt;donnemartin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Website: &lt;a href="http://donnemartin.com" rel="nofollow"&gt;donnemartin.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;license&lt;/h2&gt;
&lt;p&gt;This repository contains a variety of content; some developed by Donne Martin, and some from third-parties.  The third-party content is distributed under the license provided by those parties.&lt;/p&gt;
&lt;p&gt;The content developed by Donne Martin is distributed under the following license:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Copyright 2015 Donne Martin

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>donnemartin</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>mlflow/mlflow #9 in Python, This week</title><link>https://github.com/mlflow/mlflow</link><description>&lt;p&gt;&lt;i&gt;Open source platform for the machine learning lifecycle&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body rst" data-path="README.rst"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-mlflow-a-machine-learning-lifecycle-platform" class="anchor" aria-hidden="true" href="#mlflow-a-machine-learning-lifecycle-platform"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MLflow: A Machine Learning Lifecycle Platform&lt;/h1&gt;
&lt;p&gt;MLflow is a platform to streamline machine learning development, including tracking experiments, packaging code
into reproducible runs, and sharing and deploying models. MLflow offers a set of lightweight APIs in that can
used with any existing machine learning application or library (TensorFlow, PyTorch, XGBoost, etc), wherever you
currently run ML code (e.g. in notebooks, standalone applications or the cloud). MLflow's current components are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://mlflow.org/docs/latest/tracking.html" rel="nofollow"&gt;MLflow Tracking&lt;/a&gt;: An API to log parameters, code, and
results in machine learning experiments and compare them using an interactive UI.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mlflow.org/docs/latest/projects.html" rel="nofollow"&gt;MLflow Projects&lt;/a&gt;: A code packaging format for reproducible
runs using Conda and Docker, so you can share your ML code with others.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mlflow.org/docs/latest/models.html" rel="nofollow"&gt;MLflow Models&lt;/a&gt;: A model packaging format and tools that let
you easily deploy the same model (from any ML library) to batch and real-time scoring on platforms such as
Docker, Apache Spark, Azure ML and AWS SageMaker.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://mlflow.org/docs/latest/index.html" rel="nofollow"&gt;&lt;img alt="Latest Docs" src="https://camo.githubusercontent.com/8897346570974d9343daaa3d0028f05fba3b2c96/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d737563636573732e737667" data-canonical-src="https://img.shields.io/badge/docs-latest-success.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://travis-ci.org/mlflow/mlflow" rel="nofollow"&gt;&lt;img alt="Build Status" src="https://camo.githubusercontent.com/cc7d1ba99188e8b7c1840ccc124e52dec84524e5/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f6d6c666c6f772f6d6c666c6f772e737667" data-canonical-src="https://img.shields.io/travis/mlflow/mlflow.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://pypi.org/project/mlflow/" rel="nofollow"&gt;&lt;img alt="Latest Python Release" src="https://camo.githubusercontent.com/64da7a7404b91748bf7f828013025ed864ad035c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6d6c666c6f772e737667" data-canonical-src="https://img.shields.io/pypi/v/mlflow.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://anaconda.org/conda-forge/mlflow" rel="nofollow"&gt;&lt;img alt="Latest Conda Release" src="https://camo.githubusercontent.com/433a5d0f4ed3fe6cfa7bc3501c05cb3b68fb149c/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f6d6c666c6f772e737667" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/mlflow.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://cran.r-project.org/package=mlflow" rel="nofollow"&gt;&lt;img alt="Latest CRAN Release" src="https://camo.githubusercontent.com/a0f2cb7d1126f71f1fa04d6d585a800e55c9ec6e/68747470733a2f2f696d672e736869656c64732e696f2f6372616e2f762f6d6c666c6f772e737667" data-canonical-src="https://img.shields.io/cran/v/mlflow.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://mvnrepository.com/artifact/org.mlflow" rel="nofollow"&gt;&lt;img alt="Maven Central" src="https://camo.githubusercontent.com/f65e7489205a7fb500ea5771c6176da3afb74162/68747470733a2f2f696d672e736869656c64732e696f2f6d6176656e2d63656e7472616c2f762f6f72672e6d6c666c6f772f6d6c666c6f772d706172656e742e737667" data-canonical-src="https://img.shields.io/maven-central/v/org.mlflow/mlflow-parent.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://github.com/mlflow/mlflow/blob/master/LICENSE.txt"&gt;&lt;img alt="Apache 2 License" src="https://camo.githubusercontent.com/34c5905ad22fdcb15a03e47e463e8773c815c2fd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d417061636865253230322d627269676874677265656e2e737667" data-canonical-src="https://img.shields.io/badge/license-Apache%202-brightgreen.svg" style="max-width:100%;"&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;a name="user-content-installing"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-installing" class="anchor" aria-hidden="true" href="#installing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing&lt;/h2&gt;
&lt;p&gt;Install MLflow from PyPi via &lt;code&gt;pip install mlflow&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;MLflow requires &lt;code&gt;conda&lt;/code&gt; to be on the &lt;code&gt;PATH&lt;/code&gt; for the projects feature.&lt;/p&gt;
&lt;p&gt;Nightly snapshots of MLflow master are also available &lt;a href="https://mlflow-snapshots.s3-us-west-2.amazonaws.com/" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-documentation"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;Official documentation for MLflow can be found at &lt;a href="https://mlflow.org/docs/latest/index.html" rel="nofollow"&gt;https://mlflow.org/docs/latest/index.html&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-community"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-community" class="anchor" aria-hidden="true" href="#community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community&lt;/h2&gt;
&lt;p&gt;For help or questions about MLflow usage (e.g. "how do I do X?") see the &lt;a href="https://mlflow.org/docs/latest/index.html" rel="nofollow"&gt;docs&lt;/a&gt;
or &lt;a href="https://stackoverflow.com/questions/tagged/mlflow" rel="nofollow"&gt;Stack Overflow&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To report a bug, file a documentation issue, or submit a feature request, please open a GitHub issue.&lt;/p&gt;
&lt;p&gt;For release announcements and other discussions, please subscribe to our mailing list (&lt;a href="mailto:mlflow-users@googlegroups.com"&gt;mlflow-users@googlegroups.com&lt;/a&gt;)
or join us on Slack at &lt;a href="https://tinyurl.com/mlflow-slack" rel="nofollow"&gt;https://tinyurl.com/mlflow-slack&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-running-a-sample-app-with-the-tracking-api"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-running-a-sample-app-with-the-tracking-api" class="anchor" aria-hidden="true" href="#running-a-sample-app-with-the-tracking-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running a Sample App With the Tracking API&lt;/h2&gt;
&lt;p&gt;The programs in &lt;code&gt;examples&lt;/code&gt; use the MLflow Tracking API. For instance, run:&lt;/p&gt;
&lt;pre&gt;python examples/quickstart/mlflow_tracking.py
&lt;/pre&gt;
&lt;p&gt;This program will use &lt;a href="https://mlflow.org/docs/latest/tracking.html" rel="nofollow"&gt;MLflow Tracking API&lt;/a&gt;,
which logs tracking data in &lt;code&gt;./mlruns&lt;/code&gt;. This can then be viewed with the Tracking UI.&lt;/p&gt;
&lt;a name="user-content-launching-the-tracking-ui"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-launching-the-tracking-ui" class="anchor" aria-hidden="true" href="#launching-the-tracking-ui"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Launching the Tracking UI&lt;/h2&gt;
&lt;p&gt;The MLflow Tracking UI will show runs logged in &lt;code&gt;./mlruns&lt;/code&gt; at &lt;a href="http://localhost:5000" rel="nofollow"&gt;http://localhost:5000&lt;/a&gt;.
Start it with:&lt;/p&gt;
&lt;pre&gt;mlflow ui
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Running &lt;code&gt;mlflow ui&lt;/code&gt; from within a clone of MLflow is not recommended - doing so will
run the dev UI from source. We recommend running the UI from a different working directory,
specifying a backend store via the &lt;code&gt;--backend-store-uri&lt;/code&gt; option. Alternatively, see
instructions for running the dev UI in the &lt;a href="CONTRIBUTING.rst"&gt;contributor guide&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-running-a-project-from-a-uri"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-running-a-project-from-a-uri" class="anchor" aria-hidden="true" href="#running-a-project-from-a-uri"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running a Project from a URI&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;mlflow run&lt;/code&gt; command lets you run a project packaged with a MLproject file from a local path
or a Git URI:&lt;/p&gt;
&lt;pre&gt;mlflow run examples/sklearn_elasticnet_wine -P alpha=0.4

mlflow run https://github.com/mlflow/mlflow-example.git -P alpha=0.4
&lt;/pre&gt;
&lt;p&gt;See &lt;code&gt;examples/sklearn_elasticnet_wine&lt;/code&gt; for a sample project with an MLproject file.&lt;/p&gt;
&lt;a name="user-content-saving-and-serving-models"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-saving-and-serving-models" class="anchor" aria-hidden="true" href="#saving-and-serving-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Saving and Serving Models&lt;/h2&gt;
&lt;p&gt;To illustrate managing models, the &lt;code&gt;mlflow.sklearn&lt;/code&gt; package can log scikit-learn models as
MLflow artifacts and then load them again for serving. There is an example training application in
&lt;code&gt;examples/sklearn_logistic_regression/train.py&lt;/code&gt; that you can run as follows:&lt;/p&gt;
&lt;pre&gt;$ python examples/sklearn_logistic_regression/train.py
Score: 0.666
Model saved in run &amp;lt;run-id&amp;gt;

$ mlflow models serve --model-uri runs:/&amp;lt;run-id&amp;gt;/model

$ curl -d '{"columns":[0],"index":[0,1],"data":[[1],[-1]]}' -H 'Content-Type: application/json'  localhost:5000/invocations
&lt;/pre&gt;
&lt;a name="user-content-contributing"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;We happily welcome contributions to MLflow. Please see our &lt;a href="CONTRIBUTING.rst"&gt;contribution guide&lt;/a&gt;
for details.&lt;/p&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>mlflow</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>OUCMachineLearning/OUCML #10 in Python, This week</title><link>https://github.com/OUCMachineLearning/OUCML</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-oucml" class="anchor" aria-hidden="true" href="#oucml"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;OUCML&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/OUCMachineLearning/OUCML/tree/master/One%20Day%20One%20GAN"&gt;ODOG&lt;/a&gt;一天一GAN&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/OUCMachineLearning/OUCML/tree/master/GAN"&gt;GAN&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/OUCMachineLearning/OUCML/tree/master/AutoML"&gt;AUTOML&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;大家编写README.MD文件的时候，可以参考&lt;a href="https://blog.csdn.net/liu537192/article/details/45693529" rel="nofollow"&gt;github上README.md文件如何编写&lt;/a&gt;。&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>OUCMachineLearning</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>eriklindernoren/ML-From-Scratch #11 in Python, This week</title><link>https://github.com/eriklindernoren/ML-From-Scratch</link><description>&lt;p&gt;&lt;i&gt;Machine Learning From Scratch. Bare bones NumPy implementations of machine learning models and algorithms with a focus on accessibility. Aims to cover everything from linear regression to deep learning.&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-from-scratch" class="anchor" aria-hidden="true" href="#machine-learning-from-scratch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning From Scratch&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-about" class="anchor" aria-hidden="true" href="#about"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About&lt;/h2&gt;
&lt;p&gt;Python implementations of some of the fundamental Machine Learning models and algorithms from scratch.&lt;/p&gt;
&lt;p&gt;The purpose of this project is not to produce as optimized and computationally efficient algorithms as possible
but rather to present the inner workings of them in a transparent and accessible way.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#machine-learning-from-scratch"&gt;Machine Learning From Scratch&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#about"&gt;About&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#examples"&gt;Examples&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#polynomial-regression"&gt;Polynomial Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#classification-with-cnn"&gt;Classification With CNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#density-based-clustering"&gt;Density-Based Clustering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#generating-handwritten-digits"&gt;Generating Handwritten Digits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#deep-reinforcement-learning"&gt;Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#image-reconstruction-with-rbm"&gt;Image Reconstruction With RBM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#evolutionary-evolved-neural-network"&gt;Evolutionary Evolved Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#genetic-algorithm"&gt;Genetic Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#association-analysis"&gt;Association Analysis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#implementations"&gt;Implementations&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#supervised-learning"&gt;Supervised Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#unsupervised-learning"&gt;Unsupervised Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#reinforcement-learning"&gt;Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#deep-learning"&gt;Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#contact"&gt;Contact&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/eriklindernoren/ML-From-Scratch
$ cd ML-From-Scratch
$ python setup.py install
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-polynomial-regression" class="anchor" aria-hidden="true" href="#polynomial-regression"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Polynomial Regression&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/polynomial_regression.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/d82416364e7916546886f94027e2652d3247e8ab/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f705f7265672e676966"&gt;&lt;img src="https://camo.githubusercontent.com/d82416364e7916546886f94027e2652d3247e8ab/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f705f7265672e676966" width="640" data-canonical-src="http://eriklindernoren.se/images/p_reg.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Training progress of a regularized polynomial regression model fitting &lt;br&gt;
    temperature data measured in Linköping, Sweden 2016.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-classification-with-cnn" class="anchor" aria-hidden="true" href="#classification-with-cnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Classification With CNN&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/convolutional_neural_network.py

+---------+
| ConvNet |
+---------+
Input Shape: (1, 8, 8)
+----------------------+------------+--------------+
| Layer Type           | Parameters | Output Shape |
+----------------------+------------+--------------+
| Conv2D               | 160        | (16, 8, 8)   |
| Activation (ReLU)    | 0          | (16, 8, 8)   |
| Dropout              | 0          | (16, 8, 8)   |
| BatchNormalization   | 2048       | (16, 8, 8)   |
| Conv2D               | 4640       | (32, 8, 8)   |
| Activation (ReLU)    | 0          | (32, 8, 8)   |
| Dropout              | 0          | (32, 8, 8)   |
| BatchNormalization   | 4096       | (32, 8, 8)   |
| Flatten              | 0          | (2048,)      |
| Dense                | 524544     | (256,)       |
| Activation (ReLU)    | 0          | (256,)       |
| Dropout              | 0          | (256,)       |
| BatchNormalization   | 512        | (256,)       |
| Dense                | 2570       | (10,)        |
| Activation (Softmax) | 0          | (10,)        |
+----------------------+------------+--------------+
Total Parameters: 538570

Training: 100% [------------------------------------------------------------------------] Time: 0:01:55
Accuracy: 0.987465181058
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/c2bca09f5d1ce2b72f33fe61464408607797caa3/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f6d6c66735f636e6e312e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/c2bca09f5d1ce2b72f33fe61464408607797caa3/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f6d6c66735f636e6e312e706e67" width="640" data-canonical-src="http://eriklindernoren.se/images/mlfs_cnn1.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Classification of the digit dataset using CNN.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-density-based-clustering" class="anchor" aria-hidden="true" href="#density-based-clustering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Density-Based Clustering&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/dbscan.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/eaf413b6e8cbf3f8fd048f3a63984482ffd7350e/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f6d6c66735f64627363616e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/eaf413b6e8cbf3f8fd048f3a63984482ffd7350e/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f6d6c66735f64627363616e2e706e67" width="640" data-canonical-src="http://eriklindernoren.se/images/mlfs_dbscan.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Clustering of the moons dataset using DBSCAN.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-generating-handwritten-digits" class="anchor" aria-hidden="true" href="#generating-handwritten-digits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generating Handwritten Digits&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/unsupervised_learning/generative_adversarial_network.py

+-----------+
| Generator |
+-----------+
Input Shape: (100,)
+------------------------+------------+--------------+
| Layer Type             | Parameters | Output Shape |
+------------------------+------------+--------------+
| Dense                  | 25856      | (256,)       |
| Activation (LeakyReLU) | 0          | (256,)       |
| BatchNormalization     | 512        | (256,)       |
| Dense                  | 131584     | (512,)       |
| Activation (LeakyReLU) | 0          | (512,)       |
| BatchNormalization     | 1024       | (512,)       |
| Dense                  | 525312     | (1024,)      |
| Activation (LeakyReLU) | 0          | (1024,)      |
| BatchNormalization     | 2048       | (1024,)      |
| Dense                  | 803600     | (784,)       |
| Activation (TanH)      | 0          | (784,)       |
+------------------------+------------+--------------+
Total Parameters: 1489936

+---------------+
| Discriminator |
+---------------+
Input Shape: (784,)
+------------------------+------------+--------------+
| Layer Type             | Parameters | Output Shape |
+------------------------+------------+--------------+
| Dense                  | 401920     | (512,)       |
| Activation (LeakyReLU) | 0          | (512,)       |
| Dropout                | 0          | (512,)       |
| Dense                  | 131328     | (256,)       |
| Activation (LeakyReLU) | 0          | (256,)       |
| Dropout                | 0          | (256,)       |
| Dense                  | 514        | (2,)         |
| Activation (Softmax)   | 0          | (2,)         |
+------------------------+------------+--------------+
Total Parameters: 533762
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/15ad5010011227a7ab8c6c77d19b7cc625cced30/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f67616e5f6d6e697374352e676966"&gt;&lt;img src="https://camo.githubusercontent.com/15ad5010011227a7ab8c6c77d19b7cc625cced30/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f67616e5f6d6e697374352e676966" width="640" data-canonical-src="http://eriklindernoren.se/images/gan_mnist5.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Training progress of a Generative Adversarial Network generating &lt;br&gt;
    handwritten digits.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-deep-reinforcement-learning" class="anchor" aria-hidden="true" href="#deep-reinforcement-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Reinforcement Learning&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/deep_q_network.py

+----------------+
| Deep Q-Network |
+----------------+
Input Shape: (4,)
+-------------------+------------+--------------+
| Layer Type        | Parameters | Output Shape |
+-------------------+------------+--------------+
| Dense             | 320        | (64,)        |
| Activation (ReLU) | 0          | (64,)        |
| Dense             | 130        | (2,)         |
+-------------------+------------+--------------+
Total Parameters: 450
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/c605134f41b739121c4710f3d5c6e8370a592e0c/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f6d6c66735f64716c312e676966"&gt;&lt;img src="https://camo.githubusercontent.com/c605134f41b739121c4710f3d5c6e8370a592e0c/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f6d6c66735f64716c312e676966" width="640" data-canonical-src="http://eriklindernoren.se/images/mlfs_dql1.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Deep Q-Network solution to the CartPole-v1 environment in OpenAI gym.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-image-reconstruction-with-rbm" class="anchor" aria-hidden="true" href="#image-reconstruction-with-rbm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image Reconstruction With RBM&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/restricted_boltzmann_machine.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/d209d42aed9e8e32a10eaec9b76f141319a2b0d7/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f72626d5f646967697473312e676966"&gt;&lt;img src="https://camo.githubusercontent.com/d209d42aed9e8e32a10eaec9b76f141319a2b0d7/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f72626d5f646967697473312e676966" width="640" data-canonical-src="http://eriklindernoren.se/images/rbm_digits1.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Shows how the network gets better during training at reconstructing &lt;br&gt;
    the digit 2 in the MNIST dataset.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-evolutionary-evolved-neural-network" class="anchor" aria-hidden="true" href="#evolutionary-evolved-neural-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Evolutionary Evolved Neural Network&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/neuroevolution.py

+---------------+
| Model Summary |
+---------------+
Input Shape: (64,)
+----------------------+------------+--------------+
| Layer Type           | Parameters | Output Shape |
+----------------------+------------+--------------+
| Dense                | 1040       | (16,)        |
| Activation (ReLU)    | 0          | (16,)        |
| Dense                | 170        | (10,)        |
| Activation (Softmax) | 0          | (10,)        |
+----------------------+------------+--------------+
Total Parameters: 1210

Population Size: 100
Generations: 3000
Mutation Rate: 0.01

[0 Best Individual - Fitness: 3.08301, Accuracy: 10.5%]
[1 Best Individual - Fitness: 3.08746, Accuracy: 12.0%]
...
[2999 Best Individual - Fitness: 94.08513, Accuracy: 98.5%]
Test set accuracy: 96.7%
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1a8abe4882d0195b8f8bd4c6f24caab639291e6e/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f65766f5f6e6e342e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/1a8abe4882d0195b8f8bd4c6f24caab639291e6e/687474703a2f2f6572696b6c696e6465726e6f72656e2e73652f696d616765732f65766f5f6e6e342e706e67" width="640" data-canonical-src="http://eriklindernoren.se/images/evo_nn4.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    Figure: Classification of the digit dataset by a neural network which has&lt;br&gt;
    been evolutionary evolved.
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-genetic-algorithm" class="anchor" aria-hidden="true" href="#genetic-algorithm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Genetic Algorithm&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/genetic_algorithm.py

+--------+
|   GA   |
+--------+
Description: Implementation of a Genetic Algorithm which aims to produce
the user specified target string. This implementation calculates each
candidate's fitness based on the alphabetical distance between the candidate
and the target. A candidate is selected as a parent with probabilities proportional
to the candidate's fitness. Reproduction is implemented as a single-point
crossover between pairs of parents. Mutation is done by randomly assigning
new characters with uniform probability.

Parameters
----------
Target String: 'Genetic Algorithm'
Population Size: 100
Mutation Rate: 0.05

[0 Closest Candidate: 'CJqlJguPlqzvpoJmb', Fitness: 0.00]
[1 Closest Candidate: 'MCxZxdr nlfiwwGEk', Fitness: 0.01]
[2 Closest Candidate: 'MCxZxdm nlfiwwGcx', Fitness: 0.01]
[3 Closest Candidate: 'SmdsAklMHn kBIwKn', Fitness: 0.01]
[4 Closest Candidate: '  lotneaJOasWfu Z', Fitness: 0.01]
...
[292 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]
[293 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]
[294 Answer: 'Genetic Algorithm']
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-association-analysis" class="anchor" aria-hidden="true" href="#association-analysis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Association Analysis&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/apriori.py
+-------------+
|   Apriori   |
+-------------+
Minimum Support: 0.25
Minimum Confidence: 0.8
Transactions:
    [1, 2, 3, 4]
    [1, 2, 4]
    [1, 2]
    [2, 3, 4]
    [2, 3]
    [3, 4]
    [2, 4]
Frequent Itemsets:
    [1, 2, 3, 4, [1, 2], [1, 4], [2, 3], [2, 4], [3, 4], [1, 2, 4], [2, 3, 4]]
Rules:
    1 -&amp;gt; 2 (support: 0.43, confidence: 1.0)
    4 -&amp;gt; 2 (support: 0.57, confidence: 0.8)
    [1, 4] -&amp;gt; 2 (support: 0.29, confidence: 1.0)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-implementations" class="anchor" aria-hidden="true" href="#implementations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Implementations&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-supervised-learning" class="anchor" aria-hidden="true" href="#supervised-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Supervised Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/adaboost.py"&gt;Adaboost&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/bayesian_regression.py"&gt;Bayesian Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/decision_tree.py"&gt;Decision Tree&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/regression.py"&gt;Elastic Net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/gradient_boosting.py"&gt;Gradient Boosting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/k_nearest_neighbors.py"&gt;K Nearest Neighbors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/regression.py"&gt;Lasso Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/linear_discriminant_analysis.py"&gt;Linear Discriminant Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/regression.py"&gt;Linear Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/logistic_regression.py"&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/multi_class_lda.py"&gt;Multi-class Linear Discriminant Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/multilayer_perceptron.py"&gt;Multilayer Perceptron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/naive_bayes.py"&gt;Naive Bayes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/neuroevolution.py"&gt;Neuroevolution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/particle_swarm_optimization.py"&gt;Particle Swarm Optimization of Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/perceptron.py"&gt;Perceptron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/regression.py"&gt;Polynomial Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/random_forest.py"&gt;Random Forest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/regression.py"&gt;Ridge Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/support_vector_machine.py"&gt;Support Vector Machine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/supervised_learning/xgboost.py"&gt;XGBoost&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-unsupervised-learning" class="anchor" aria-hidden="true" href="#unsupervised-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Unsupervised Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/apriori.py"&gt;Apriori&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/autoencoder.py"&gt;Autoencoder&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/dbscan.py"&gt;DBSCAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/fp_growth.py"&gt;FP-Growth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/gaussian_mixture_model.py"&gt;Gaussian Mixture Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/generative_adversarial_network.py"&gt;Generative Adversarial Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/genetic_algorithm.py"&gt;Genetic Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/k_means.py"&gt;K-Means&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/partitioning_around_medoids.py"&gt;Partitioning Around Medoids&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/principal_component_analysis.py"&gt;Principal Component Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py"&gt;Restricted Boltzmann Machine&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-reinforcement-learning" class="anchor" aria-hidden="true" href="#reinforcement-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reinforcement Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="mlfromscratch/reinforcement_learning/deep_q_network.py"&gt;Deep Q-Network&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-deep-learning" class="anchor" aria-hidden="true" href="#deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="mlfromscratch/deep_learning/neural_network.py"&gt;Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/deep_learning/layers.py"&gt;Layers&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Activation Layer&lt;/li&gt;
&lt;li&gt;Average Pooling Layer&lt;/li&gt;
&lt;li&gt;Batch Normalization Layer&lt;/li&gt;
&lt;li&gt;Constant Padding Layer&lt;/li&gt;
&lt;li&gt;Convolutional Layer&lt;/li&gt;
&lt;li&gt;Dropout Layer&lt;/li&gt;
&lt;li&gt;Flatten Layer&lt;/li&gt;
&lt;li&gt;Fully-Connected (Dense) Layer&lt;/li&gt;
&lt;li&gt;Fully-Connected RNN Layer&lt;/li&gt;
&lt;li&gt;Max Pooling Layer&lt;/li&gt;
&lt;li&gt;Reshape Layer&lt;/li&gt;
&lt;li&gt;Up Sampling Layer&lt;/li&gt;
&lt;li&gt;Zero Padding Layer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Model Types
&lt;ul&gt;
&lt;li&gt;&lt;a href="mlfromscratch/examples/convolutional_neural_network.py"&gt;Convolutional Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/examples/multilayer_perceptron.py"&gt;Multilayer Perceptron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mlfromscratch/examples/recurrent_neural_network.py"&gt;Recurrent Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h2&gt;
&lt;p&gt;If there's some implementation you would like to see here or if you're just feeling social,
feel free to &lt;a href="mailto:eriklindernoren@gmail.com"&gt;email&lt;/a&gt; me or connect with me on &lt;a href="https://www.linkedin.com/in/eriklindernoren/" rel="nofollow"&gt;LinkedIn&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>eriklindernoren</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>nvbn/thefuck #12 in Python, This week</title><link>https://github.com/nvbn/thefuck</link><description>&lt;p&gt;&lt;i&gt;Magnificent app which corrects your previous console command.&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-the-fuck-----" class="anchor" aria-hidden="true" href="#the-fuck-----"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Fuck &lt;a href="https://pypi.python.org/pypi/thefuck/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1354b987be5b712a696ce297c86f3b8bf75fc718/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7468656675636b2e7376673f6c6162656c3d76657273696f6e" alt="Version" data-canonical-src="https://img.shields.io/pypi/v/thefuck.svg?label=version" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://travis-ci.org/nvbn/thefuck" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/420a5527201a2037e3452204bc5f3a24e873e131/68747470733a2f2f7472617669732d63692e6f72672f6e76626e2f7468656675636b2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/nvbn/thefuck.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://ci.appveyor.com/project/nvbn/thefuck" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/148742d6f0fc1e93fda3d900f83e250b8c57eb8c/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f3173736b6a34696d6a3032756d3067752f6272616e63682f6d61737465723f7376673d74727565" alt="Windows Build Status" data-canonical-src="https://ci.appveyor.com/api/projects/status/1sskj4imj02um0gu/branch/master?svg=true" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/github/nvbn/thefuck" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/b31627a753c4602df5a3ae332331f19217285467/68747470733a2f2f696d672e736869656c64732e696f2f636f766572616c6c732f6e76626e2f7468656675636b2e737667" alt="Coverage" data-canonical-src="https://img.shields.io/coveralls/nvbn/thefuck.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="LICENSE.md"&gt;&lt;img src="https://camo.githubusercontent.com/a4a2b602f35a6fb803d4c7b56d9b2bf1bebb7748/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d3030374543372e737667" alt="MIT License" data-canonical-src="https://img.shields.io/badge/license-MIT-007EC7.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;The Fuck&lt;/em&gt; is a magnificent app, inspired by a &lt;a href="https://twitter.com/liamosaur/" rel="nofollow"&gt;@liamosaur&lt;/a&gt;
&lt;a href="https://twitter.com/liamosaur/status/506975850596536320" rel="nofollow"&gt;tweet&lt;/a&gt;,
that corrects errors in previous console commands.&lt;/p&gt;
&lt;p&gt;Is &lt;em&gt;The Fuck&lt;/em&gt; too slow? &lt;a href="#experimental-instant-mode"&gt;Try the experimental instant mode!&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/nvbn/thefuck/master/example.gif" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/nvbn/thefuck/master/example.gif" alt="gif with examples" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More examples:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;➜ apt-get install vim
E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)
E: Unable to lock the administration directory (/var/lib/dpkg/), are you root&lt;span class="pl-k"&gt;?&lt;/span&gt;

➜ fuck
sudo apt-get install vim [enter/↑/↓/ctrl+c]
[sudo] password &lt;span class="pl-k"&gt;for&lt;/span&gt; nvbn:
Reading package lists... Done
...&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;➜ git push
fatal: The current branch master has no upstream branch.
To push the current branch and &lt;span class="pl-c1"&gt;set&lt;/span&gt; the remote as upstream, use

    git push --set-upstream origin master


➜ fuck
git push --set-upstream origin master [enter/↑/↓/ctrl+c]
Counting objects: 9, done.
...&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;➜ puthon
No &lt;span class="pl-c1"&gt;command&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;puthon&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; found, did you mean:
 Command &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;python&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; from package &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;python-minimal&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; (main)
 Command &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;python&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; from package &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;python3&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; (main)
zsh: &lt;span class="pl-c1"&gt;command&lt;/span&gt; not found: puthon

➜ fuck
python [enter/↑/↓/ctrl+c]
Python 3.4.2 (default, Oct  8 2014, 13:08:17)
...&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;➜ git brnch
git: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;brnch&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; is not a git command. See &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;git --help&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.

Did you mean this&lt;span class="pl-k"&gt;?&lt;/span&gt;
    branch

➜ fuck
git branch [enter/↑/↓/ctrl+c]
&lt;span class="pl-k"&gt;*&lt;/span&gt; master&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;➜ lein rpl
&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;rpl&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; is not a task. See &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;lein help&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.

Did you mean this&lt;span class="pl-k"&gt;?&lt;/span&gt;
         repl

➜ fuck
lein repl [enter/↑/↓/ctrl+c]
nREPL server started on port 54848 on host 127.0.0.1 - nrepl://127.0.0.1:54848
REPL-y 0.3.1
...&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you're not afraid of blindly running corrected commands, the
&lt;code&gt;require_confirmation&lt;/code&gt; &lt;a href="#settings"&gt;settings&lt;/a&gt; option can be disabled:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;➜ apt-get install vim
E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)
E: Unable to lock the administration directory (/var/lib/dpkg/), are you root&lt;span class="pl-k"&gt;?&lt;/span&gt;

➜ fuck
sudo apt-get install vim
[sudo] password &lt;span class="pl-k"&gt;for&lt;/span&gt; nvbn:
Reading package lists... Done
...&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;python (3.4+)&lt;/li&gt;
&lt;li&gt;pip&lt;/li&gt;
&lt;li&gt;python-dev&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;On OS X, you can install &lt;em&gt;The Fuck&lt;/em&gt; via &lt;a href="https://brew.sh/" rel="nofollow"&gt;Homebrew&lt;/a&gt; (or via &lt;a href="https://linuxbrew.sh/" rel="nofollow"&gt;Linuxbrew&lt;/a&gt; on Linux):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;brew install thefuck&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On Ubuntu / Mint, install &lt;em&gt;The Fuck&lt;/em&gt; with the following commands:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo apt update
sudo apt install python3-dev python3-pip python3-setuptools
sudo pip3 install thefuck&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On FreeBSD, install &lt;em&gt;The Fuck&lt;/em&gt; with the following commands:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pkg install thefuck&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On ChromeOS, install &lt;em&gt;The Fuck&lt;/em&gt; using &lt;a href="https://github.com/skycocker/chromebrew"&gt;chromebrew&lt;/a&gt; with the following command:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;crew install thefuck&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On other systems, install &lt;em&gt;The Fuck&lt;/em&gt;  by using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install thefuck&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://github.com/nvbn/thefuck/wiki/Installation"&gt;Alternatively, you may use an OS package manager (OS X, Ubuntu, Arch).&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="#manual-installation" name="user-content-manual-installation"&gt;#&lt;/a&gt;
It is recommended that you place this command in your &lt;code&gt;.bash_profile&lt;/code&gt;,
&lt;code&gt;.bashrc&lt;/code&gt;, &lt;code&gt;.zshrc&lt;/code&gt; or other startup script:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;eval&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;thefuck --alias&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; You can use whatever you want as an alias, like for Mondays:&lt;/span&gt;
&lt;span class="pl-c1"&gt;eval&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;thefuck --alias FUCK&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://github.com/nvbn/thefuck/wiki/Shell-aliases"&gt;Or in your shell config (Bash, Zsh, Fish, Powershell, tcsh).&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Changes are only available in a new shell session. To make changes immediately
available, run &lt;code&gt;source ~/.bashrc&lt;/code&gt; (or your shell config file like &lt;code&gt;.zshrc&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;To run fixed commands without confirmation, use the &lt;code&gt;--yeah&lt;/code&gt; option (or just &lt;code&gt;-y&lt;/code&gt; for short, or &lt;code&gt;--hard&lt;/code&gt; if you're especially frustrated):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;fuck --yeah&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To fix commands recursively until succeeding, use the &lt;code&gt;-r&lt;/code&gt; option:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;fuck -r&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-updating" class="anchor" aria-hidden="true" href="#updating"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Updating&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip3 install thefuck --upgrade&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Note: Alias functionality was changed in v1.34 of &lt;em&gt;The Fuck&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-it-works" class="anchor" aria-hidden="true" href="#how-it-works"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How it works&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;The Fuck&lt;/em&gt; attempts to match the previous command with a rule. If a match is
found, a new command is created using the matched rule and executed. The
following rules are enabled by default:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;adb_unknown_command&lt;/code&gt; – fixes misspelled commands like &lt;code&gt;adb logcta&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ag_literal&lt;/code&gt; – adds &lt;code&gt;-Q&lt;/code&gt; to &lt;code&gt;ag&lt;/code&gt; when suggested;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;aws_cli&lt;/code&gt; – fixes misspelled commands like &lt;code&gt;aws dynamdb scan&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;az_cli&lt;/code&gt; – fixes misspelled commands like &lt;code&gt;az providers&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cargo&lt;/code&gt; – runs &lt;code&gt;cargo build&lt;/code&gt; instead of &lt;code&gt;cargo&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cargo_no_command&lt;/code&gt; – fixes wrongs commands like &lt;code&gt;cargo buid&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cat_dir&lt;/code&gt; – replaces &lt;code&gt;cat&lt;/code&gt; with &lt;code&gt;ls&lt;/code&gt; when you try to &lt;code&gt;cat&lt;/code&gt; a directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd_correction&lt;/code&gt; – spellchecks and correct failed cd commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd_mkdir&lt;/code&gt; – creates directories before cd'ing into them;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd_parent&lt;/code&gt; – changes &lt;code&gt;cd..&lt;/code&gt; to &lt;code&gt;cd ..&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;chmod_x&lt;/code&gt; – add execution bit;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;composer_not_command&lt;/code&gt; – fixes composer command name;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cp_omitting_directory&lt;/code&gt; – adds &lt;code&gt;-a&lt;/code&gt; when you &lt;code&gt;cp&lt;/code&gt; directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cpp11&lt;/code&gt; – adds missing &lt;code&gt;-std=c++11&lt;/code&gt; to &lt;code&gt;g++&lt;/code&gt; or &lt;code&gt;clang++&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dirty_untar&lt;/code&gt; – fixes &lt;code&gt;tar x&lt;/code&gt; command that untarred in the current directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dirty_unzip&lt;/code&gt; – fixes &lt;code&gt;unzip&lt;/code&gt; command that unzipped in the current directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;django_south_ghost&lt;/code&gt; – adds &lt;code&gt;--delete-ghost-migrations&lt;/code&gt; to failed because ghosts django south migration;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;django_south_merge&lt;/code&gt; – adds &lt;code&gt;--merge&lt;/code&gt; to inconsistent django south migration;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker_login&lt;/code&gt; – executes a &lt;code&gt;docker login&lt;/code&gt; and repeats the previous command;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker_not_command&lt;/code&gt; – fixes wrong docker commands like &lt;code&gt;docker tags&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker_image_being_used_by_container&lt;/code&gt; ‐ removes the container that is using the image before removing the image;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dry&lt;/code&gt; – fixes repetitions like &lt;code&gt;git git push&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fab_command_not_found&lt;/code&gt; – fix misspelled fabric commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fix_alt_space&lt;/code&gt; – replaces Alt+Space with Space character;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fix_file&lt;/code&gt; – opens a file with an error in your &lt;code&gt;$EDITOR&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gem_unknown_command&lt;/code&gt; – fixes wrong &lt;code&gt;gem&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_add&lt;/code&gt; – fixes &lt;em&gt;"pathspec 'foo' did not match any file(s) known to git."&lt;/em&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_add_force&lt;/code&gt; – adds &lt;code&gt;--force&lt;/code&gt; to &lt;code&gt;git add &amp;lt;pathspec&amp;gt;...&lt;/code&gt; when paths are .gitignore'd;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_bisect_usage&lt;/code&gt; – fixes &lt;code&gt;git bisect strt&lt;/code&gt;, &lt;code&gt;git bisect goood&lt;/code&gt;, &lt;code&gt;git bisect rset&lt;/code&gt;, etc. when bisecting;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_branch_delete&lt;/code&gt; – changes &lt;code&gt;git branch -d&lt;/code&gt; to &lt;code&gt;git branch -D&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_branch_delete_checked_out&lt;/code&gt; – changes &lt;code&gt;git branch -d&lt;/code&gt; to &lt;code&gt;git checkout master &amp;amp;&amp;amp; git branch -D&lt;/code&gt; when trying to delete a checked out branch;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_branch_exists&lt;/code&gt; – offers &lt;code&gt;git branch -d foo&lt;/code&gt;, &lt;code&gt;git branch -D foo&lt;/code&gt; or &lt;code&gt;git checkout foo&lt;/code&gt; when creating a branch that already exists;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_branch_list&lt;/code&gt; – catches &lt;code&gt;git branch list&lt;/code&gt; in place of &lt;code&gt;git branch&lt;/code&gt; and removes created branch;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_checkout&lt;/code&gt; – fixes branch name or creates new branch;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_commit_amend&lt;/code&gt; – offers &lt;code&gt;git commit --amend&lt;/code&gt; after previous commit;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_commit_reset&lt;/code&gt; – offers &lt;code&gt;git reset HEAD~&lt;/code&gt; after previous commit;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_diff_no_index&lt;/code&gt; – adds &lt;code&gt;--no-index&lt;/code&gt; to previous &lt;code&gt;git diff&lt;/code&gt; on untracked files;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_diff_staged&lt;/code&gt; – adds &lt;code&gt;--staged&lt;/code&gt; to previous &lt;code&gt;git diff&lt;/code&gt; with unexpected output;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_fix_stash&lt;/code&gt; – fixes &lt;code&gt;git stash&lt;/code&gt; commands (misspelled subcommand and missing &lt;code&gt;save&lt;/code&gt;);&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_flag_after_filename&lt;/code&gt; – fixes &lt;code&gt;fatal: bad flag '...' after filename&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_help_aliased&lt;/code&gt; – fixes &lt;code&gt;git help &amp;lt;alias&amp;gt;&lt;/code&gt; commands replacing  with the aliased command;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_merge&lt;/code&gt; – adds remote to branch names;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_merge_unrelated&lt;/code&gt; – adds &lt;code&gt;--allow-unrelated-histories&lt;/code&gt; when required&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_not_command&lt;/code&gt; – fixes wrong git commands like &lt;code&gt;git brnch&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_pull&lt;/code&gt; – sets upstream before executing previous &lt;code&gt;git pull&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_pull_clone&lt;/code&gt; – clones instead of pulling when the repo does not exist;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_pull_uncommitted_changes&lt;/code&gt; – stashes changes before pulling and pops them afterwards;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_push&lt;/code&gt; – adds &lt;code&gt;--set-upstream origin $branch&lt;/code&gt; to previous failed &lt;code&gt;git push&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_push_different_branch_names&lt;/code&gt; – fixes pushes when local brach name does not match remote branch name;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_push_pull&lt;/code&gt; – runs &lt;code&gt;git pull&lt;/code&gt; when &lt;code&gt;push&lt;/code&gt; was rejected;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_push_without_commits&lt;/code&gt; – Creates an initial commit if you forget and only &lt;code&gt;git add .&lt;/code&gt;, when setting up a new project;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_rebase_no_changes&lt;/code&gt; – runs &lt;code&gt;git rebase --skip&lt;/code&gt; instead of &lt;code&gt;git rebase --continue&lt;/code&gt; when there are no changes;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_remote_delete&lt;/code&gt; – replaces &lt;code&gt;git remote delete remote_name&lt;/code&gt; with &lt;code&gt;git remote remove remote_name&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_rm_local_modifications&lt;/code&gt; –  adds &lt;code&gt;-f&lt;/code&gt; or &lt;code&gt;--cached&lt;/code&gt; when you try to &lt;code&gt;rm&lt;/code&gt; a locally modified file;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_rm_recursive&lt;/code&gt; – adds &lt;code&gt;-r&lt;/code&gt; when you try to &lt;code&gt;rm&lt;/code&gt; a directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_rm_staged&lt;/code&gt; –  adds &lt;code&gt;-f&lt;/code&gt; or &lt;code&gt;--cached&lt;/code&gt; when you try to &lt;code&gt;rm&lt;/code&gt; a file with staged changes&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_rebase_merge_dir&lt;/code&gt; – offers &lt;code&gt;git rebase (--continue | --abort | --skip)&lt;/code&gt; or removing the &lt;code&gt;.git/rebase-merge&lt;/code&gt; dir when a rebase is in progress;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_remote_seturl_add&lt;/code&gt; – runs &lt;code&gt;git remote add&lt;/code&gt; when &lt;code&gt;git remote set_url&lt;/code&gt; on nonexistant remote;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_stash&lt;/code&gt; – stashes your local modifications before rebasing or switching branch;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_stash_pop&lt;/code&gt; – adds your local modifications before popping stash, then resets;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_tag_force&lt;/code&gt; – adds &lt;code&gt;--force&lt;/code&gt; to &lt;code&gt;git tag &amp;lt;tagname&amp;gt;&lt;/code&gt; when the tag already exists;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git_two_dashes&lt;/code&gt; – adds a missing dash to commands like &lt;code&gt;git commit -amend&lt;/code&gt; or &lt;code&gt;git rebase -continue&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;go_run&lt;/code&gt; – appends &lt;code&gt;.go&lt;/code&gt; extension when compiling/running Go programs;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;go_unknown_command&lt;/code&gt; – fixes wrong &lt;code&gt;go&lt;/code&gt; commands, for example &lt;code&gt;go bulid&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gradle_no_task&lt;/code&gt; – fixes not found or ambiguous &lt;code&gt;gradle&lt;/code&gt; task;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gradle_wrapper&lt;/code&gt; – replaces &lt;code&gt;gradle&lt;/code&gt; with &lt;code&gt;./gradlew&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;grep_arguments_order&lt;/code&gt; – fixes &lt;code&gt;grep&lt;/code&gt; arguments order for situations like &lt;code&gt;grep -lir . test&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;grep_recursive&lt;/code&gt; – adds &lt;code&gt;-r&lt;/code&gt; when you try to &lt;code&gt;grep&lt;/code&gt; directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;grunt_task_not_found&lt;/code&gt; – fixes misspelled &lt;code&gt;grunt&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gulp_not_task&lt;/code&gt; – fixes misspelled &lt;code&gt;gulp&lt;/code&gt; tasks;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;has_exists_script&lt;/code&gt; – prepends &lt;code&gt;./&lt;/code&gt; when script/binary exists;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;heroku_multiple_apps&lt;/code&gt; – add &lt;code&gt;--app &amp;lt;app&amp;gt;&lt;/code&gt; to &lt;code&gt;heroku&lt;/code&gt; commands like &lt;code&gt;heroku pg&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;heroku_not_command&lt;/code&gt; – fixes wrong &lt;code&gt;heroku&lt;/code&gt; commands like &lt;code&gt;heroku log&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;history&lt;/code&gt; – tries to replace command with most similar command from history;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hostscli&lt;/code&gt; – tries to fix &lt;code&gt;hostscli&lt;/code&gt; usage;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ifconfig_device_not_found&lt;/code&gt; – fixes wrong device names like &lt;code&gt;wlan0&lt;/code&gt; to &lt;code&gt;wlp2s0&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;java&lt;/code&gt; – removes &lt;code&gt;.java&lt;/code&gt; extension when running Java programs;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;javac&lt;/code&gt; – appends missing &lt;code&gt;.java&lt;/code&gt; when compiling Java files;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lein_not_task&lt;/code&gt; – fixes wrong &lt;code&gt;lein&lt;/code&gt; tasks like &lt;code&gt;lein rpl&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;long_form_help&lt;/code&gt; – changes &lt;code&gt;-h&lt;/code&gt; to &lt;code&gt;--help&lt;/code&gt; when the short form version is not supported&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ln_no_hard_link&lt;/code&gt; – catches hard link creation on directories, suggest symbolic link;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ln_s_order&lt;/code&gt; – fixes &lt;code&gt;ln -s&lt;/code&gt; arguments order;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ls_all&lt;/code&gt; – adds &lt;code&gt;-A&lt;/code&gt; to &lt;code&gt;ls&lt;/code&gt; when output is empty;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ls_lah&lt;/code&gt; – adds &lt;code&gt;-lah&lt;/code&gt; to &lt;code&gt;ls&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;man&lt;/code&gt; – changes manual section;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;man_no_space&lt;/code&gt; – fixes man commands without spaces, for example &lt;code&gt;mandiff&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mercurial&lt;/code&gt; – fixes wrong &lt;code&gt;hg&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;missing_space_before_subcommand&lt;/code&gt; – fixes command with missing space like &lt;code&gt;npminstall&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mkdir_p&lt;/code&gt; – adds &lt;code&gt;-p&lt;/code&gt; when you try to create a directory without parent;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn_no_command&lt;/code&gt; – adds &lt;code&gt;clean package&lt;/code&gt; to &lt;code&gt;mvn&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn_unknown_lifecycle_phase&lt;/code&gt; – fixes misspelled lifecycle phases with &lt;code&gt;mvn&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;npm_missing_script&lt;/code&gt; – fixes &lt;code&gt;npm&lt;/code&gt; custom script name in &lt;code&gt;npm run-script &amp;lt;script&amp;gt;&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;npm_run_script&lt;/code&gt; – adds missing &lt;code&gt;run-script&lt;/code&gt; for custom &lt;code&gt;npm&lt;/code&gt; scripts;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;npm_wrong_command&lt;/code&gt; – fixes wrong npm commands like &lt;code&gt;npm urgrade&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;no_command&lt;/code&gt; – fixes wrong console commands, for example &lt;code&gt;vom/vim&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;no_such_file&lt;/code&gt; – creates missing directories with &lt;code&gt;mv&lt;/code&gt; and &lt;code&gt;cp&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;open&lt;/code&gt; – either prepends &lt;code&gt;http://&lt;/code&gt; to address passed to &lt;code&gt;open&lt;/code&gt; or create a new file or directory and passes it to &lt;code&gt;open&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pip_install&lt;/code&gt; – fixes permission issues with &lt;code&gt;pip install&lt;/code&gt; commands by adding &lt;code&gt;--user&lt;/code&gt; or prepending &lt;code&gt;sudo&lt;/code&gt; if necessary;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pip_unknown_command&lt;/code&gt; – fixes wrong &lt;code&gt;pip&lt;/code&gt; commands, for example &lt;code&gt;pip instatl/pip install&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;php_s&lt;/code&gt; – replaces &lt;code&gt;-s&lt;/code&gt; by &lt;code&gt;-S&lt;/code&gt; when trying to run a local php server;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;port_already_in_use&lt;/code&gt; – kills process that bound port;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;prove_recursively&lt;/code&gt; – adds &lt;code&gt;-r&lt;/code&gt; when called with directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pyenv_no_such_command&lt;/code&gt; – fixes wrong pyenv commands like &lt;code&gt;pyenv isntall&lt;/code&gt; or &lt;code&gt;pyenv list&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;python_command&lt;/code&gt; – prepends &lt;code&gt;python&lt;/code&gt; when you try to run non-executable/without &lt;code&gt;./&lt;/code&gt; python script;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;python_execute&lt;/code&gt; – appends missing &lt;code&gt;.py&lt;/code&gt; when executing Python files;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;quotation_marks&lt;/code&gt; – fixes uneven usage of &lt;code&gt;'&lt;/code&gt; and &lt;code&gt;"&lt;/code&gt; when containing args';&lt;/li&gt;
&lt;li&gt;&lt;code&gt;path_from_history&lt;/code&gt; – replaces not found path with similar absolute path from history;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;react_native_command_unrecognized&lt;/code&gt; – fixes unrecognized &lt;code&gt;react-native&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;remove_trailing_cedilla&lt;/code&gt; – remove trailling cedillas &lt;code&gt;ç&lt;/code&gt;, a common typo for european keyboard layouts;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rm_dir&lt;/code&gt; – adds &lt;code&gt;-rf&lt;/code&gt; when you try to remove a directory;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;scm_correction&lt;/code&gt; – corrects wrong scm like &lt;code&gt;hg log&lt;/code&gt; to &lt;code&gt;git log&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sed_unterminated_s&lt;/code&gt; – adds missing '/' to &lt;code&gt;sed&lt;/code&gt;'s &lt;code&gt;s&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sl_ls&lt;/code&gt; – changes &lt;code&gt;sl&lt;/code&gt; to &lt;code&gt;ls&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ssh_known_hosts&lt;/code&gt; – removes host from &lt;code&gt;known_hosts&lt;/code&gt; on warning;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sudo&lt;/code&gt; – prepends &lt;code&gt;sudo&lt;/code&gt; to previous command if it failed because of permissions;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sudo_command_from_user_path&lt;/code&gt; – runs commands from users &lt;code&gt;$PATH&lt;/code&gt; with &lt;code&gt;sudo&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;switch_lang&lt;/code&gt; – switches command from your local layout to en;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;systemctl&lt;/code&gt; – correctly orders parameters of confusing &lt;code&gt;systemctl&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;terraform_init.py&lt;/code&gt; – run &lt;code&gt;terraform init&lt;/code&gt; before plan or apply;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;test.py&lt;/code&gt; – runs &lt;code&gt;py.test&lt;/code&gt; instead of &lt;code&gt;test.py&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;touch&lt;/code&gt; – creates missing directories before "touching";&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tsuru_login&lt;/code&gt; – runs &lt;code&gt;tsuru login&lt;/code&gt; if not authenticated or session expired;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tsuru_not_command&lt;/code&gt; – fixes wrong &lt;code&gt;tsuru&lt;/code&gt; commands like &lt;code&gt;tsuru shell&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tmux&lt;/code&gt; – fixes &lt;code&gt;tmux&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;unknown_command&lt;/code&gt; – fixes hadoop hdfs-style "unknown command", for example adds missing '-' to the command on &lt;code&gt;hdfs dfs ls&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;unsudo&lt;/code&gt; – removes &lt;code&gt;sudo&lt;/code&gt; from previous command if a process refuses to run on super user privilege.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vagrant_up&lt;/code&gt; – starts up the vagrant instance;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;whois&lt;/code&gt; – fixes &lt;code&gt;whois&lt;/code&gt; command;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;workon_doesnt_exists&lt;/code&gt; – fixes &lt;code&gt;virtualenvwrapper&lt;/code&gt; env name os suggests to create new.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn_alias&lt;/code&gt; – fixes aliased &lt;code&gt;yarn&lt;/code&gt; commands like &lt;code&gt;yarn ls&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn_command_not_found&lt;/code&gt; – fixes misspelled &lt;code&gt;yarn&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn_command_replaced&lt;/code&gt; – fixes replaced &lt;code&gt;yarn&lt;/code&gt; commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn_help&lt;/code&gt; – makes it easier to open &lt;code&gt;yarn&lt;/code&gt; documentation;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following rules are enabled by default on specific platforms only:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;apt_get&lt;/code&gt; – installs app from apt if it not installed (requires &lt;code&gt;python-commandnotfound&lt;/code&gt; / &lt;code&gt;python3-commandnotfound&lt;/code&gt;);&lt;/li&gt;
&lt;li&gt;&lt;code&gt;apt_get_search&lt;/code&gt; – changes trying to search using &lt;code&gt;apt-get&lt;/code&gt; with searching using &lt;code&gt;apt-cache&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;apt_invalid_operation&lt;/code&gt; – fixes invalid &lt;code&gt;apt&lt;/code&gt; and &lt;code&gt;apt-get&lt;/code&gt; calls, like &lt;code&gt;apt-get isntall vim&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;apt_list_upgradable&lt;/code&gt; – helps you run &lt;code&gt;apt list --upgradable&lt;/code&gt; after &lt;code&gt;apt update&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;apt_upgrade&lt;/code&gt; – helps you run &lt;code&gt;apt upgrade&lt;/code&gt; after &lt;code&gt;apt list --upgradable&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_cask_dependency&lt;/code&gt; – installs cask dependencies;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_install&lt;/code&gt; – fixes formula name for &lt;code&gt;brew install&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_reinstall&lt;/code&gt; – turns &lt;code&gt;brew install &amp;lt;formula&amp;gt;&lt;/code&gt; into &lt;code&gt;brew reinstall &amp;lt;formula&amp;gt;&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_link&lt;/code&gt; – adds &lt;code&gt;--overwrite --dry-run&lt;/code&gt; if linking fails;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_uninstall&lt;/code&gt; – adds &lt;code&gt;--force&lt;/code&gt; to &lt;code&gt;brew uninstall&lt;/code&gt; if multiple versions were installed;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_unknown_command&lt;/code&gt; – fixes wrong brew commands, for example &lt;code&gt;brew docto/brew doctor&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew_update_formula&lt;/code&gt; – turns &lt;code&gt;brew update &amp;lt;formula&amp;gt;&lt;/code&gt; into &lt;code&gt;brew upgrade &amp;lt;formula&amp;gt;&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dnf_no_such_command&lt;/code&gt; – fixes mistyped DNF commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nixos_cmd_not_found&lt;/code&gt; – installs apps on NixOS;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pacman&lt;/code&gt; – installs app with &lt;code&gt;pacman&lt;/code&gt; if it is not installed (uses &lt;code&gt;yay&lt;/code&gt; or &lt;code&gt;yaourt&lt;/code&gt; if available);&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pacman_not_found&lt;/code&gt; – fixes package name with &lt;code&gt;pacman&lt;/code&gt;, &lt;code&gt;yay&lt;/code&gt; or &lt;code&gt;yaourt&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yum_invalid_operation&lt;/code&gt; – fixes invalid &lt;code&gt;yum&lt;/code&gt; calls, like &lt;code&gt;yum isntall vim&lt;/code&gt;;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following commands are bundled with &lt;em&gt;The Fuck&lt;/em&gt;, but are not enabled by
default:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;git_push_force&lt;/code&gt; – adds &lt;code&gt;--force-with-lease&lt;/code&gt; to a &lt;code&gt;git push&lt;/code&gt; (may conflict with &lt;code&gt;git_push_pull&lt;/code&gt;);&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rm_root&lt;/code&gt; – adds &lt;code&gt;--no-preserve-root&lt;/code&gt; to &lt;code&gt;rm -rf /&lt;/code&gt; command.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-creating-your-own-rules" class="anchor" aria-hidden="true" href="#creating-your-own-rules"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Creating your own rules&lt;/h2&gt;
&lt;p&gt;To add your own rule, create a file named &lt;code&gt;your-rule-name.py&lt;/code&gt;
in &lt;code&gt;~/.config/thefuck/rules&lt;/code&gt;. The rule file must contain two functions:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;match(command: Command) &lt;span class="pl-ii"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;bool&lt;/span&gt;
get_new_command(command: Command) &lt;span class="pl-ii"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;str&lt;/span&gt; &lt;span class="pl-k"&gt;|&lt;/span&gt; list[&lt;span class="pl-c1"&gt;str&lt;/span&gt;]&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Additionally, rules can contain optional functions:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;side_effect(old_command: Command, fixed_command: &lt;span class="pl-c1"&gt;str&lt;/span&gt;) &lt;span class="pl-ii"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Rules can also contain the optional variables &lt;code&gt;enabled_by_default&lt;/code&gt;, &lt;code&gt;requires_output&lt;/code&gt; and &lt;code&gt;priority&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Command&lt;/code&gt; has three attributes: &lt;code&gt;script&lt;/code&gt;, &lt;code&gt;output&lt;/code&gt; and &lt;code&gt;script_parts&lt;/code&gt;.
Your rule should not change &lt;code&gt;Command&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rules api changed in 3.0:&lt;/strong&gt; To access a rule's settings, import it with
&lt;code&gt;from thefuck.conf import settings&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;settings&lt;/code&gt; is a special object assembled from &lt;code&gt;~/.config/thefuck/settings.py&lt;/code&gt;,
and values from env (&lt;a href="#settings"&gt;see more below&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;A simple example rule for running a script with &lt;code&gt;sudo&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;match&lt;/span&gt;(&lt;span class="pl-smi"&gt;command&lt;/span&gt;):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; (&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;permission denied&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;in&lt;/span&gt; command.output.lower()
            &lt;span class="pl-k"&gt;or&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;EACCES&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;in&lt;/span&gt; command.output)


&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;get_new_command&lt;/span&gt;(&lt;span class="pl-smi"&gt;command&lt;/span&gt;):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sudo &lt;span class="pl-c1"&gt;{}&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.format(command.script)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Optional:&lt;/span&gt;
enabled_by_default &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;True&lt;/span&gt;

&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;side_effect&lt;/span&gt;(&lt;span class="pl-smi"&gt;command&lt;/span&gt;, &lt;span class="pl-smi"&gt;fixed_command&lt;/span&gt;):
    subprocess.call(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;chmod 777 .&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;shell&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)

priority &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1000&lt;/span&gt;  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Lower first, default is 1000&lt;/span&gt;

requires_output &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;True&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://github.com/nvbn/thefuck/tree/master/thefuck/rules"&gt;More examples of rules&lt;/a&gt;,
&lt;a href="https://github.com/nvbn/thefuck/tree/master/thefuck/utils.py"&gt;utility functions for rules&lt;/a&gt;,
&lt;a href="https://github.com/nvbn/thefuck/tree/master/thefuck/specific/"&gt;app/os-specific helpers&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-settings" class="anchor" aria-hidden="true" href="#settings"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Settings&lt;/h2&gt;
&lt;p&gt;Several &lt;em&gt;The Fuck&lt;/em&gt; parameters can be changed in the file &lt;code&gt;$XDG_CONFIG_HOME/thefuck/settings.py&lt;/code&gt;
(&lt;code&gt;$XDG_CONFIG_HOME&lt;/code&gt; defaults to &lt;code&gt;~/.config&lt;/code&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rules&lt;/code&gt; – list of enabled rules, by default &lt;code&gt;thefuck.conf.DEFAULT_RULES&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;exclude_rules&lt;/code&gt; – list of disabled rules, by default &lt;code&gt;[]&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;require_confirmation&lt;/code&gt; – requires confirmation before running new command, by default &lt;code&gt;True&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wait_command&lt;/code&gt; – max amount of time in seconds for getting previous command output;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;no_colors&lt;/code&gt; – disable colored output;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;priority&lt;/code&gt; – dict with rules priorities, rule with lower &lt;code&gt;priority&lt;/code&gt; will be matched first;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;debug&lt;/code&gt; – enables debug output, by default &lt;code&gt;False&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;history_limit&lt;/code&gt; – numeric value of how many history commands will be scanned, like &lt;code&gt;2000&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;alter_history&lt;/code&gt; – push fixed command to history, by default &lt;code&gt;True&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wait_slow_command&lt;/code&gt; – max amount of time in seconds for getting previous command output if it in &lt;code&gt;slow_commands&lt;/code&gt; list;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;slow_commands&lt;/code&gt; – list of slow commands;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num_close_matches&lt;/code&gt; – maximum number of close matches to suggest, by default &lt;code&gt;3&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An example of &lt;code&gt;settings.py&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;rules &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sudo&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;no_command&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
exclude_rules &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;git_push&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
require_confirmation &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;True&lt;/span&gt;
wait_command &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;
no_colors &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;False&lt;/span&gt;
priority &lt;span class="pl-k"&gt;=&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sudo&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;no_command&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;9999&lt;/span&gt;}
debug &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;False&lt;/span&gt;
history_limit &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;9999&lt;/span&gt;
wait_slow_command &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;20&lt;/span&gt;
slow_commands &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;react-native&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;gradle&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;]
num_close_matches &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;5&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or via environment variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_RULES&lt;/code&gt; – list of enabled rules, like &lt;code&gt;DEFAULT_RULES:rm_root&lt;/code&gt; or &lt;code&gt;sudo:no_command&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_EXCLUDE_RULES&lt;/code&gt; – list of disabled rules, like &lt;code&gt;git_pull:git_push&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_REQUIRE_CONFIRMATION&lt;/code&gt; – require confirmation before running new command, &lt;code&gt;true/false&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_WAIT_COMMAND&lt;/code&gt; – max amount of time in seconds for getting previous command output;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_NO_COLORS&lt;/code&gt; – disable colored output, &lt;code&gt;true/false&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_PRIORITY&lt;/code&gt; – priority of the rules, like &lt;code&gt;no_command=9999:apt_get=100&lt;/code&gt;,
rule with lower &lt;code&gt;priority&lt;/code&gt; will be matched first;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_DEBUG&lt;/code&gt; – enables debug output, &lt;code&gt;true/false&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_HISTORY_LIMIT&lt;/code&gt; – how many history commands will be scanned, like &lt;code&gt;2000&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_ALTER_HISTORY&lt;/code&gt; – push fixed command to history &lt;code&gt;true/false&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_WAIT_SLOW_COMMAND&lt;/code&gt; – max amount of time in seconds for getting previous command output if it in &lt;code&gt;slow_commands&lt;/code&gt; list;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_SLOW_COMMANDS&lt;/code&gt; – list of slow commands, like &lt;code&gt;lein:gradle&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;THEFUCK_NUM_CLOSE_MATCHES&lt;/code&gt; – maximum number of close matches to suggest, like &lt;code&gt;5&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_RULES=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sudo:no_command&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_EXCLUDE_RULES=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;git_pull:git_push&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_REQUIRE_CONFIRMATION=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;true&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_WAIT_COMMAND=10
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_NO_COLORS=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;false&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_PRIORITY=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;no_command=9999:apt_get=100&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_HISTORY_LIMIT=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;2000&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; THEFUCK_NUM_CLOSE_MATCHES=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-third-party-packages-with-rules" class="anchor" aria-hidden="true" href="#third-party-packages-with-rules"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Third-party packages with rules&lt;/h2&gt;
&lt;p&gt;If you'd like to make a specific set of non-public rules, but would still like
to share them with others, create a package named &lt;code&gt;thefuck_contrib_*&lt;/code&gt; with
the following structure:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;thefuck_contrib_foo
  thefuck_contrib_foo
    rules
      __init__.py
      *third-party rules*
    __init__.py
    *third-party-utils*
  setup.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;The Fuck&lt;/em&gt; will find rules located in the &lt;code&gt;rules&lt;/code&gt; module.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-experimental-instant-mode" class="anchor" aria-hidden="true" href="#experimental-instant-mode"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Experimental instant mode&lt;/h2&gt;
&lt;p&gt;The default behavior of &lt;em&gt;The Fuck&lt;/em&gt; requires time to re-run previous commands.
When in instant mode, &lt;em&gt;The Fuck&lt;/em&gt; saves time by logging output with &lt;a href="https://en.wikipedia.org/wiki/Script_(Unix)" rel="nofollow"&gt;script&lt;/a&gt;,
then reading the log.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/nvbn/thefuck/master/example_instant_mode.gif" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/nvbn/thefuck/master/example_instant_mode.gif" alt="gif with instant mode" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Currently, instant mode only supports Python 3 with bash or zsh. zsh's autocorrect function also needs to be disabled in order for thefuck to work properly.&lt;/p&gt;
&lt;p&gt;To enable instant mode, add &lt;code&gt;--enable-experimental-instant-mode&lt;/code&gt;
to the alias initialization in &lt;code&gt;.bashrc&lt;/code&gt;, &lt;code&gt;.bash_profile&lt;/code&gt; or &lt;code&gt;.zshrc&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;eval&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;thefuck --alias --enable-experimental-instant-mode&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-developing" class="anchor" aria-hidden="true" href="#developing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Developing&lt;/h2&gt;
&lt;p&gt;See &lt;a href="CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license-mit" class="anchor" aria-hidden="true" href="#license-mit"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License MIT&lt;/h2&gt;
&lt;p&gt;Project License can be found &lt;a href="LICENSE.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>nvbn</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>quantopian/zipline #13 in Python, This week</title><link>https://github.com/quantopian/zipline</link><description>&lt;p&gt;&lt;i&gt;Zipline, a Pythonic Algorithmic Trading Library&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body rst" data-path="README.rst"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;a href="https://www.zipline.io" rel="nofollow"&gt;&lt;img alt="Zipline" src="https://camo.githubusercontent.com/887b8228aa4b569b2a519ef711c7da7e5d6b40cd/68747470733a2f2f6d656469612e7175616e746f7069616e2e636f6d2f6c6f676f732f6f70656e5f736f757263652f7a69706c696e652d6c6f676f2d30335f2e706e67" data-canonical-src="https://media.quantopian.com/logos/open_source/zipline-logo-03_.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href="https://gitter.im/quantopian/zipline?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img alt="Gitter" src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://pypi.python.org/pypi/zipline" rel="nofollow"&gt;&lt;img alt="version status" src="https://camo.githubusercontent.com/3eb069ec0b3e276829eb1f88f7c594f33fe1e3d8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f7a69706c696e652e737667" data-canonical-src="https://img.shields.io/pypi/pyversions/zipline.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://travis-ci.org/quantopian/zipline" rel="nofollow"&gt;&lt;img alt="travis status" src="https://camo.githubusercontent.com/29e70eddded2efd56e32b7fc5c150b90820099a1/68747470733a2f2f7472617669732d63692e6f72672f7175616e746f7069616e2f7a69706c696e652e706e673f6272616e63683d6d6173746572" data-canonical-src="https://travis-ci.org/quantopian/zipline.png?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/quantopian/zipline/branch/master" rel="nofollow"&gt;&lt;img alt="appveyor status" src="https://camo.githubusercontent.com/b0eef78a2d89bc9ea40ea6cfeafb438444705605/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f336467313865363232376476737477362f6272616e63682f6d61737465723f7376673d74727565" data-canonical-src="https://ci.appveyor.com/api/projects/status/3dg18e6227dvstw6/branch/master?svg=true" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://coveralls.io/r/quantopian/zipline" rel="nofollow"&gt;&lt;img alt="Coverage Status" src="https://camo.githubusercontent.com/1a7165b07669cce4c6c69f92ca68d7e3e374bffc/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f7175616e746f7069616e2f7a69706c696e652f62616467652e706e67" data-canonical-src="https://coveralls.io/repos/quantopian/zipline/badge.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zipline is a Pythonic algorithmic trading library. It is an event-driven
system for backtesting. Zipline is currently used in production as the backtesting and live-trading
engine powering &lt;a href="https://www.quantopian.com" rel="nofollow"&gt;Quantopian&lt;/a&gt; -- a free,
community-centered, hosted platform for building and executing trading
strategies.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://groups.google.com/forum/#!forum/zipline" rel="nofollow"&gt;Join our Community!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zipline.io" rel="nofollow"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Want to Contribute? See our &lt;a href="https://www.zipline.io/development-guidelines" rel="nofollow"&gt;Development Guidelines&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-features"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ease of Use:&lt;/strong&gt; Zipline tries to get out of your way so that you can
focus on algorithm development. See below for a code example.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;"Batteries Included":&lt;/strong&gt; many common statistics like
moving average and linear regression can be readily accessed from
within a user-written algorithm.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyData Integration:&lt;/strong&gt; Input of historical data and output of performance statistics are
based on Pandas DataFrames to integrate nicely into the existing
PyData ecosystem.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Statistics and Machine Learning Libraries:&lt;/strong&gt; You can use libraries like matplotlib, scipy,
statsmodels, and sklearn to support development, analysis, and
visualization of state-of-the-art trading systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-installation"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;a name="user-content-installing-with-pip"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-installing-with-pip" class="anchor" aria-hidden="true" href="#installing-with-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing With &lt;code&gt;pip&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Assuming you have all required (see note below) non-Python dependencies, you
can install Zipline with &lt;code&gt;pip&lt;/code&gt; via:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ pip install zipline&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Installing Zipline via &lt;code&gt;pip&lt;/code&gt; is slightly more involved than the
average Python package.  Simply running &lt;code&gt;pip install zipline&lt;/code&gt; will likely
fail if you've never installed any scientific Python packages before.&lt;/p&gt;
&lt;p&gt;There are two reasons for the additional complexity:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Zipline ships several C extensions that require access to the CPython C API.
In order to build the C extensions, &lt;code&gt;pip&lt;/code&gt; needs access to the CPython
header files for your Python installation.&lt;/li&gt;
&lt;li&gt;Zipline depends on &lt;a href="https://www.numpy.org/" rel="nofollow"&gt;numpy&lt;/a&gt;, the core library for
numerical array computing in Python.  Numpy depends on having the &lt;a href="https://www.netlib.org/lapack/" rel="nofollow"&gt;LAPACK&lt;/a&gt; linear algebra routines available.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Because LAPACK and the CPython headers are binary dependencies, the correct way
to install them varies from platform to platform.  On Linux, users generally
acquire these dependencies via a package manager like &lt;code&gt;apt&lt;/code&gt;, &lt;code&gt;yum&lt;/code&gt;, or
&lt;code&gt;pacman&lt;/code&gt;.  On OSX, &lt;a href="https://brew.sh/" rel="nofollow"&gt;Homebrew&lt;/a&gt; is a popular choice
providing similar functionality.&lt;/p&gt;
&lt;p&gt;See the full &lt;a href="https://www.zipline.io/install" rel="nofollow"&gt;Zipline Install Documentation&lt;/a&gt; for more information on acquiring
binary dependencies for your specific platform.&lt;/p&gt;
&lt;a name="user-content-conda"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-conda" class="anchor" aria-hidden="true" href="#conda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;conda&lt;/h3&gt;
&lt;p&gt;Another way to install Zipline is via the &lt;code&gt;conda&lt;/code&gt; package manager, which
comes as part of &lt;a href="https://www.anaconda.com/distribution/" rel="nofollow"&gt;Anaconda&lt;/a&gt; or can be
installed via &lt;code&gt;pip install conda&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once set up, you can install Zipline from our &lt;code&gt;Quantopian&lt;/code&gt; channel:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ conda install -c Quantopian zipline&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Currently supported platforms include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GNU/Linux 64-bit&lt;/li&gt;
&lt;li&gt;OSX 64-bit&lt;/li&gt;
&lt;li&gt;Windows 64-bit&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
&lt;p&gt;Note&lt;/p&gt;
&lt;p&gt;Windows 32-bit may work; however, it is not currently included in
continuous integration tests.&lt;/p&gt;
&lt;/div&gt;
&lt;a name="user-content-quickstart"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-quickstart" class="anchor" aria-hidden="true" href="#quickstart"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quickstart&lt;/h2&gt;
&lt;p&gt;See our &lt;a href="https://www.zipline.io/beginner-tutorial" rel="nofollow"&gt;getting started tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following code implements a simple dual moving average algorithm.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; zipline.api &lt;span class="pl-k"&gt;import&lt;/span&gt; order_target, record, symbol

&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;initialize&lt;/span&gt;(&lt;span class="pl-smi"&gt;context&lt;/span&gt;):
    context.i &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;
    context.asset &lt;span class="pl-k"&gt;=&lt;/span&gt; symbol(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;AAPL&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)


&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;handle_data&lt;/span&gt;(&lt;span class="pl-smi"&gt;context&lt;/span&gt;, &lt;span class="pl-smi"&gt;data&lt;/span&gt;):
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Skip first 300 days to get full windows&lt;/span&gt;
    context.i &lt;span class="pl-k"&gt;+=&lt;/span&gt; &lt;span class="pl-c1"&gt;1&lt;/span&gt;
    &lt;span class="pl-k"&gt;if&lt;/span&gt; context.i &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;300&lt;/span&gt;:
        &lt;span class="pl-k"&gt;return&lt;/span&gt;

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Compute averages&lt;/span&gt;
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; data.history() has to be called with the same params&lt;/span&gt;
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; from above and returns a pandas dataframe.&lt;/span&gt;
    short_mavg &lt;span class="pl-k"&gt;=&lt;/span&gt; data.history(context.asset, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;price&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;bar_count&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;frequency&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;1d&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;).mean()
    long_mavg &lt;span class="pl-k"&gt;=&lt;/span&gt; data.history(context.asset, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;price&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;bar_count&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;300&lt;/span&gt;, &lt;span class="pl-v"&gt;frequency&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;1d&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;).mean()

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Trading logic&lt;/span&gt;
    &lt;span class="pl-k"&gt;if&lt;/span&gt; short_mavg &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; long_mavg:
        &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; order_target orders as many shares as needed to&lt;/span&gt;
        &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; achieve the desired number of shares.&lt;/span&gt;
        order_target(context.asset, &lt;span class="pl-c1"&gt;100&lt;/span&gt;)
    &lt;span class="pl-k"&gt;elif&lt;/span&gt; short_mavg &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; long_mavg:
        order_target(context.asset, &lt;span class="pl-c1"&gt;0&lt;/span&gt;)

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Save values for later inspection&lt;/span&gt;
    record(&lt;span class="pl-v"&gt;AAPL&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;data.current(context.asset, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;price&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
           &lt;span class="pl-v"&gt;short_mavg&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;short_mavg,
           &lt;span class="pl-v"&gt;long_mavg&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;long_mavg)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can then run this algorithm using the Zipline CLI; you'll need a &lt;a href="https://docs.quandl.com/docs#section-authentication" rel="nofollow"&gt;Quandl&lt;/a&gt; API key to ingest the default data bundle.
Once you have your key, run the following from the command line:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ QUANDL_API_KEY=&lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;yourkey&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; zipline ingest -b quandl
$ zipline run -f dual_moving_average.py --start 2014-1-1 --end 2018-1-1 -o dma.pickle&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will download asset pricing data data from quandl, and stream it through the algorithm
over the specified time range. Then, the resulting performance DataFrame is saved in dma.pickle, which you
can load and analyze from within Python.&lt;/p&gt;
&lt;p&gt;You can find other examples in the &lt;code&gt;zipline/examples&lt;/code&gt; directory.&lt;/p&gt;
&lt;a name="user-content-questions"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-questions" class="anchor" aria-hidden="true" href="#questions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Questions?&lt;/h2&gt;
&lt;p&gt;If you find a bug, feel free to &lt;a href="https://github.com/quantopian/zipline/issues/new"&gt;open an issue&lt;/a&gt; and fill out the issue template.&lt;/p&gt;
&lt;a name="user-content-contributing"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;All contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome. Details on how to set up a development environment can be found in our &lt;a href="https://www.zipline.io/development-guidelines" rel="nofollow"&gt;development guidelines&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are looking to start working with the Zipline codebase, navigate to the GitHub issues tab and start looking through interesting issues. Sometimes there are issues labeled as &lt;a href="https://github.com/quantopian/zipline/issues?q=is%3Aissue+is%3Aopen+label%3A%22Beginner+Friendly%22"&gt;Beginner Friendly&lt;/a&gt; or &lt;a href="https://github.com/quantopian/zipline/issues?q=is%3Aissue+is%3Aopen+label%3A%22Help+Wanted%22"&gt;Help Wanted&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Feel free to ask questions on the &lt;a href="https://groups.google.com/forum/#!forum/zipline" rel="nofollow"&gt;mailing list&lt;/a&gt; or on &lt;a href="https://gitter.im/quantopian/zipline" rel="nofollow"&gt;Gitter&lt;/a&gt;.&lt;/p&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>quantopian</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>tiangolo/fastapi #14 in Python, This week</title><link>https://github.com/tiangolo/fastapi</link><description>&lt;p&gt;&lt;i&gt;FastAPI framework, high performance, easy to learn, fast to code, ready for production&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
  &lt;a href="https://fastapi.tiangolo.com" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/86dafd728b94c0e3c8f19a7295e87df678ed6751/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f6c6f676f2d6d617267696e2f6c6f676f2d7465616c2e706e67" alt="FastAPI" data-canonical-src="https://fastapi.tiangolo.com/img/logo-margin/logo-teal.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;em&gt;FastAPI framework, high performance, easy to learn, fast to code, ready for production&lt;/em&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
&lt;a href="https://travis-ci.org/tiangolo/fastapi" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/a063500cd90b05f7713e4e8a1d8425d56117ab54/68747470733a2f2f7472617669732d63692e6f72672f7469616e676f6c6f2f666173746170692e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/tiangolo/fastapi.svg?branch=master" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://codecov.io/gh/tiangolo/fastapi" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/f5a1eba9c0d4b5b01c08287fe78a467cc0b07512/68747470733a2f2f636f6465636f762e696f2f67682f7469616e676f6c6f2f666173746170692f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/tiangolo/fastapi/branch/master/graph/badge.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://pypi.org/project/fastapi" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/42b9100f882ee4300fe2372e7f1d4e65f95b1f4c/68747470733a2f2f62616467652e667572792e696f2f70792f666173746170692e737667" alt="Package version" data-canonical-src="https://badge.fury.io/py/fastapi.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://gitter.im/tiangolo/fastapi?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/2cc5eb2b608263a42d3938f63f69e0dcc697eaad/68747470733a2f2f6261646765732e6769747465722e696d2f7469616e676f6c6f2f666173746170692e737667" alt="Join the chat at https://gitter.im/tiangolo/fastapi" data-canonical-src="https://badges.gitter.im/tiangolo/fastapi.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href="https://fastapi.tiangolo.com" rel="nofollow"&gt;&lt;/a&gt;&lt;a href="https://fastapi.tiangolo.com" rel="nofollow"&gt;https://fastapi.tiangolo.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Source Code&lt;/strong&gt;: &lt;a href="https://github.com/tiangolo/fastapi"&gt;&lt;/a&gt;&lt;a href="https://github.com/tiangolo/fastapi"&gt;https://github.com/tiangolo/fastapi&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints.&lt;/p&gt;
&lt;p&gt;The key features are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fast&lt;/strong&gt;: Very high performance, on par with &lt;strong&gt;NodeJS&lt;/strong&gt; and &lt;strong&gt;Go&lt;/strong&gt; (thanks to Starlette and Pydantic). &lt;a href="#performance"&gt;One of the fastest Python frameworks available&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fast to code&lt;/strong&gt;: Increase the speed to develop features by about 200% to 300% *.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fewer bugs&lt;/strong&gt;: Reduce about 40% of human (developer) induced errors. *&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Intuitive&lt;/strong&gt;: Great editor support. Completion everywhere. Less time debugging.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Easy&lt;/strong&gt;: Designed to be easy to use and learn. Less time reading docs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Short&lt;/strong&gt;: Minimize code duplication. Multiple features from each parameter declaration. Fewer bugs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Robust&lt;/strong&gt;: Get production-ready code. With automatic interactive documentation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Standards-based&lt;/strong&gt;: Based on (and fully compatible with) the open standards for APIs: &lt;a href="https://github.com/OAI/OpenAPI-Specification"&gt;OpenAPI&lt;/a&gt; (previously known as Swagger) and &lt;a href="http://json-schema.org/" rel="nofollow"&gt;JSON Schema&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;* estimation based on tests on an internal development team, building production applications.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-opinions" class="anchor" aria-hidden="true" href="#opinions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Opinions&lt;/h2&gt;
&lt;p&gt;"&lt;em&gt;[...] I'm using &lt;strong&gt;FastAPI&lt;/strong&gt; a ton these days. [...] I'm actually planning to use it for all of my team's &lt;strong&gt;ML services at Microsoft&lt;/strong&gt;. Some of them are getting integrated into the core &lt;strong&gt;Windows&lt;/strong&gt; product and some &lt;strong&gt;Office&lt;/strong&gt; products.&lt;/em&gt;"&lt;/p&gt;
&lt;div&gt;Kabir Khan - &lt;strong&gt;Microsoft&lt;/strong&gt; &lt;a href="https://github.com/tiangolo/fastapi/pull/26"&gt;(ref)&lt;/a&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;"&lt;em&gt;I’m over the moon excited about &lt;strong&gt;FastAPI&lt;/strong&gt;. It’s so fun!&lt;/em&gt;"&lt;/p&gt;
&lt;div&gt;Brian Okken - &lt;strong&gt;&lt;a href="https://pythonbytes.fm/episodes/show/123/time-to-right-the-py-wrongs?time_in_sec=855" rel="nofollow"&gt;Python Bytes&lt;/a&gt; podcast host&lt;/strong&gt; &lt;a href="https://twitter.com/brianokken/status/1112220079972728832" rel="nofollow"&gt;(ref)&lt;/a&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;"&lt;em&gt;Honestly, what you've built looks super solid and polished. In many ways, it's what I wanted &lt;strong&gt;Hug&lt;/strong&gt; to be - it's really inspiring to see someone build that.&lt;/em&gt;"&lt;/p&gt;
&lt;div&gt;Timothy Crosley - &lt;strong&gt;&lt;a href="http://www.hug.rest/" rel="nofollow"&gt;Hug&lt;/a&gt; creator&lt;/strong&gt; &lt;a href="https://news.ycombinator.com/item?id=19455465" rel="nofollow"&gt;(ref)&lt;/a&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;"&lt;em&gt;If you're looking to learn one &lt;strong&gt;modern framework&lt;/strong&gt; for building REST APIs, check out &lt;strong&gt;FastAPI&lt;/strong&gt; [...] It's fast, easy to use and easy to learn [...]&lt;/em&gt;"&lt;/p&gt;
&lt;p&gt;"&lt;em&gt;We've switched over to &lt;strong&gt;FastAPI&lt;/strong&gt; for our &lt;strong&gt;APIs&lt;/strong&gt; [...] I think you'll like it [...]&lt;/em&gt;"&lt;/p&gt;
&lt;div&gt;Ines Montani - Matthew Honnibal - &lt;strong&gt;&lt;a href="https://explosion.ai" rel="nofollow"&gt;Explosion AI&lt;/a&gt; founders - &lt;a href="https://spacy.io" rel="nofollow"&gt;spaCy&lt;/a&gt; creators&lt;/strong&gt; &lt;a href="https://twitter.com/_inesmontani/status/1144173225322143744" rel="nofollow"&gt;(ref)&lt;/a&gt; - &lt;a href="https://twitter.com/honnibal/status/1144031421859655680" rel="nofollow"&gt;(ref)&lt;/a&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;"&lt;em&gt;We adopted the &lt;strong&gt;FastAPI&lt;/strong&gt; library to spawn a &lt;strong&gt;REST&lt;/strong&gt; server that can be queried to obtain &lt;strong&gt;predictions&lt;/strong&gt;. [for Ludwig]&lt;/em&gt;"&lt;/p&gt;
&lt;div&gt;Piero Molino, Yaroslav Dudin, and Sai Sumanth Miryala - &lt;strong&gt;Uber&lt;/strong&gt; &lt;a href="https://eng.uber.com/ludwig-v0-2/" rel="nofollow"&gt;(ref)&lt;/a&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h2&gt;
&lt;p&gt;Python 3.6+&lt;/p&gt;
&lt;p&gt;FastAPI stands on the shoulders of giants:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.starlette.io/" rel="nofollow"&gt;Starlette&lt;/a&gt; for the web parts.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pydantic-docs.helpmanual.io/" rel="nofollow"&gt;Pydantic&lt;/a&gt; for the data parts.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ pip install fastapi&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You will also need an ASGI server, for production such as &lt;a href="http://www.uvicorn.org" rel="nofollow"&gt;Uvicorn&lt;/a&gt; or &lt;a href="https://gitlab.com/pgjones/hypercorn" rel="nofollow"&gt;Hypercorn&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ pip install uvicorn&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-example" class="anchor" aria-hidden="true" href="#example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-create-it" class="anchor" aria-hidden="true" href="#create-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Create it&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Create a file &lt;code&gt;main.py&lt;/code&gt; with:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; fastapi &lt;span class="pl-k"&gt;import&lt;/span&gt; FastAPI

app &lt;span class="pl-k"&gt;=&lt;/span&gt; FastAPI()


&lt;span class="pl-en"&gt;@app.get&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;read_root&lt;/span&gt;():
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Hello&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;World&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;}


&lt;span class="pl-en"&gt;@app.get&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/items/&lt;span class="pl-c1"&gt;{item_id}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;read_item&lt;/span&gt;(&lt;span class="pl-smi"&gt;item_id&lt;/span&gt;: &lt;span class="pl-c1"&gt;int&lt;/span&gt;, &lt;span class="pl-smi"&gt;q&lt;/span&gt;: &lt;span class="pl-c1"&gt;str&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item_id, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;q&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: q}&lt;/pre&gt;&lt;/div&gt;
&lt;details&gt;
&lt;summary&gt;Or use &lt;code&gt;async def&lt;/code&gt;...&lt;/summary&gt;
&lt;p&gt;If your code uses &lt;code&gt;async&lt;/code&gt; / &lt;code&gt;await&lt;/code&gt;, use &lt;code&gt;async def&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; fastapi &lt;span class="pl-k"&gt;import&lt;/span&gt; FastAPI

app &lt;span class="pl-k"&gt;=&lt;/span&gt; FastAPI()


&lt;span class="pl-en"&gt;@app.get&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;async&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;read_root&lt;/span&gt;():
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Hello&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;World&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;}


&lt;span class="pl-en"&gt;@app.get&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/items/&lt;span class="pl-c1"&gt;{item_id}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;async&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;read_item&lt;/span&gt;(&lt;span class="pl-smi"&gt;item_id&lt;/span&gt;: &lt;span class="pl-c1"&gt;int&lt;/span&gt;, &lt;span class="pl-smi"&gt;q&lt;/span&gt;: &lt;span class="pl-c1"&gt;str&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item_id, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;q&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: q}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;If you don't know, check the &lt;em&gt;"In a hurry?"&lt;/em&gt; section about &lt;a href="https://fastapi.tiangolo.com/async/#in-a-hurry" rel="nofollow"&gt;&lt;code&gt;async&lt;/code&gt; and &lt;code&gt;await&lt;/code&gt; in the docs&lt;/a&gt;.&lt;/p&gt;
&lt;/details&gt;
&lt;h3&gt;&lt;a id="user-content-run-it" class="anchor" aria-hidden="true" href="#run-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Run it&lt;/h3&gt;
&lt;p&gt;Run the server with:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;uvicorn main:app --reload&lt;/pre&gt;&lt;/div&gt;
&lt;details&gt;
&lt;summary&gt;About the command &lt;code&gt;uvicorn main:app --reload&lt;/code&gt;...&lt;/summary&gt;
&lt;p&gt;The command &lt;code&gt;uvicorn main:app&lt;/code&gt; refers to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;main&lt;/code&gt;: the file &lt;code&gt;main.py&lt;/code&gt; (the Python "module").&lt;/li&gt;
&lt;li&gt;&lt;code&gt;app&lt;/code&gt;: the object created inside of &lt;code&gt;main.py&lt;/code&gt; with the line &lt;code&gt;app = FastAPI()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--reload&lt;/code&gt;: make the server restart after code changes. Only do this for development.&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;
&lt;h3&gt;&lt;a id="user-content-check-it" class="anchor" aria-hidden="true" href="#check-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Check it&lt;/h3&gt;
&lt;p&gt;Open your browser at &lt;a href="http://127.0.0.1:8000/items/5?q=somequery" rel="nofollow"&gt;&lt;/a&gt;&lt;a href="http://127.0.0.1:8000/items/5?q=somequery" rel="nofollow"&gt;http://127.0.0.1:8000/items/5?q=somequery&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You will see the JSON response as:&lt;/p&gt;
&lt;div class="highlight highlight-source-json"&gt;&lt;pre&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;5&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;q&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;somequery&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You already created an API that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Receives HTTP requests in the &lt;em&gt;paths&lt;/em&gt; &lt;code&gt;/&lt;/code&gt; and &lt;code&gt;/items/{item_id}&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Both &lt;em&gt;paths&lt;/em&gt; take &lt;code&gt;GET&lt;/code&gt; &lt;em&gt;operations&lt;/em&gt; (also known as HTTP &lt;em&gt;methods&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;path&lt;/em&gt; &lt;code&gt;/items/{item_id}&lt;/code&gt; has a &lt;em&gt;path parameter&lt;/em&gt; &lt;code&gt;item_id&lt;/code&gt; that should be an &lt;code&gt;int&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;path&lt;/em&gt; &lt;code&gt;/items/{item_id}&lt;/code&gt; has an optional &lt;code&gt;str&lt;/code&gt; &lt;em&gt;query parameter&lt;/em&gt; &lt;code&gt;q&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-interactive-api-docs" class="anchor" aria-hidden="true" href="#interactive-api-docs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive API docs&lt;/h3&gt;
&lt;p&gt;Now go to &lt;a href="http://127.0.0.1:8000/docs" rel="nofollow"&gt;&lt;/a&gt;&lt;a href="http://127.0.0.1:8000/docs" rel="nofollow"&gt;http://127.0.0.1:8000/docs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You will see the automatic interactive API documentation (provided by &lt;a href="https://github.com/swagger-api/swagger-ui"&gt;Swagger UI&lt;/a&gt;):&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/4695ec8d41da6a358a4faa882c61bbac9951b026/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30312d737761676765722d75692d73696d706c652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/4695ec8d41da6a358a4faa882c61bbac9951b026/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30312d737761676765722d75692d73696d706c652e706e67" alt="Swagger UI" data-canonical-src="https://fastapi.tiangolo.com/img/index/index-01-swagger-ui-simple.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-alternative-api-docs" class="anchor" aria-hidden="true" href="#alternative-api-docs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Alternative API docs&lt;/h3&gt;
&lt;p&gt;And now, go to &lt;a href="http://127.0.0.1:8000/redoc" rel="nofollow"&gt;&lt;/a&gt;&lt;a href="http://127.0.0.1:8000/redoc" rel="nofollow"&gt;http://127.0.0.1:8000/redoc&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You will see the alternative automatic documentation (provided by &lt;a href="https://github.com/Rebilly/ReDoc"&gt;ReDoc&lt;/a&gt;):&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/3a6ac8a74ecc2fca49f1e731ddd66cc5172d8c35/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30322d7265646f632d73696d706c652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/3a6ac8a74ecc2fca49f1e731ddd66cc5172d8c35/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30322d7265646f632d73696d706c652e706e67" alt="ReDoc" data-canonical-src="https://fastapi.tiangolo.com/img/index/index-02-redoc-simple.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-example-upgrade" class="anchor" aria-hidden="true" href="#example-upgrade"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example upgrade&lt;/h2&gt;
&lt;p&gt;Now modify the file &lt;code&gt;main.py&lt;/code&gt; to receive a body from a &lt;code&gt;PUT&lt;/code&gt; request.&lt;/p&gt;
&lt;p&gt;Declare the body using standard Python types, thanks to Pydantic.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; fastapi &lt;span class="pl-k"&gt;import&lt;/span&gt; FastAPI
&lt;span class="pl-k"&gt;from&lt;/span&gt; pydantic &lt;span class="pl-k"&gt;import&lt;/span&gt; BaseModel

app &lt;span class="pl-k"&gt;=&lt;/span&gt; FastAPI()


&lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;Item&lt;/span&gt;(&lt;span class="pl-e"&gt;BaseModel&lt;/span&gt;):
    name: &lt;span class="pl-c1"&gt;str&lt;/span&gt;
    price: &lt;span class="pl-c1"&gt;float&lt;/span&gt;
    is_offer: &lt;span class="pl-c1"&gt;bool&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;


&lt;span class="pl-en"&gt;@app.get&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;read_root&lt;/span&gt;():
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Hello&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;World&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;}


&lt;span class="pl-en"&gt;@app.get&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/items/&lt;span class="pl-c1"&gt;{item_id}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;read_item&lt;/span&gt;(&lt;span class="pl-smi"&gt;item_id&lt;/span&gt;: &lt;span class="pl-c1"&gt;int&lt;/span&gt;, &lt;span class="pl-smi"&gt;q&lt;/span&gt;: &lt;span class="pl-c1"&gt;str&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item_id, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;q&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: q}


&lt;span class="pl-en"&gt;@app.put&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/items/&lt;span class="pl-c1"&gt;{item_id}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;update_item&lt;/span&gt;(&lt;span class="pl-smi"&gt;item_id&lt;/span&gt;: &lt;span class="pl-c1"&gt;int&lt;/span&gt;, &lt;span class="pl-smi"&gt;item&lt;/span&gt;: Item):
    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_name&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item.name, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item_id}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The server should reload automatically (because you added &lt;code&gt;--reload&lt;/code&gt; to the &lt;code&gt;uvicorn&lt;/code&gt; command above).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-interactive-api-docs-upgrade" class="anchor" aria-hidden="true" href="#interactive-api-docs-upgrade"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive API docs upgrade&lt;/h3&gt;
&lt;p&gt;Now go to &lt;a href="http://127.0.0.1:8000/docs" rel="nofollow"&gt;&lt;/a&gt;&lt;a href="http://127.0.0.1:8000/docs" rel="nofollow"&gt;http://127.0.0.1:8000/docs&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The interactive API documentation will be automatically updated, including the new body:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/f0019a9c9b37044a50e6cff6d8750b426e7e0944/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30332d737761676765722d30322e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/f0019a9c9b37044a50e6cff6d8750b426e7e0944/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30332d737761676765722d30322e706e67" alt="Swagger UI" data-canonical-src="https://fastapi.tiangolo.com/img/index/index-03-swagger-02.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Click on the button "Try it out", it allows you to fill the parameters and directly interact with the API:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1be49d95361f60e81305eb315dd90fc197af3def/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30342d737761676765722d30332e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/1be49d95361f60e81305eb315dd90fc197af3def/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30342d737761676765722d30332e706e67" alt="Swagger UI interaction" data-canonical-src="https://fastapi.tiangolo.com/img/index/index-04-swagger-03.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Then click on the "Execute" button, the user interface will communicate with your API, send the parameters, get the results and show them on the screen:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/3a631804039f0a0cb0cf603689fac91b08628a7f/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30352d737761676765722d30342e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/3a631804039f0a0cb0cf603689fac91b08628a7f/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30352d737761676765722d30342e706e67" alt="Swagger UI interaction" data-canonical-src="https://fastapi.tiangolo.com/img/index/index-05-swagger-04.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-alternative-api-docs-upgrade" class="anchor" aria-hidden="true" href="#alternative-api-docs-upgrade"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Alternative API docs upgrade&lt;/h3&gt;
&lt;p&gt;And now, go to &lt;a href="http://127.0.0.1:8000/redoc" rel="nofollow"&gt;&lt;/a&gt;&lt;a href="http://127.0.0.1:8000/redoc" rel="nofollow"&gt;http://127.0.0.1:8000/redoc&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The alternative documentation will also reflect the new query parameter and body:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/8145a3ba1236551d039aca21225d3ef348f04ccf/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30362d7265646f632d30322e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/8145a3ba1236551d039aca21225d3ef348f04ccf/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f696e6465782f696e6465782d30362d7265646f632d30322e706e67" alt="ReDoc" data-canonical-src="https://fastapi.tiangolo.com/img/index/index-06-redoc-02.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-recap" class="anchor" aria-hidden="true" href="#recap"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Recap&lt;/h3&gt;
&lt;p&gt;In summary, you declare &lt;strong&gt;once&lt;/strong&gt; the types of parameters, body, etc. as function parameters.&lt;/p&gt;
&lt;p&gt;You do that with standard modern Python types.&lt;/p&gt;
&lt;p&gt;You don't have to learn a new syntax, the methods or classes of a specific library, etc.&lt;/p&gt;
&lt;p&gt;Just standard &lt;strong&gt;Python 3.6+&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;For example, for an &lt;code&gt;int&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;item_id: &lt;span class="pl-c1"&gt;int&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or for a more complex &lt;code&gt;Item&lt;/code&gt; model:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;item: Item&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;...and with that single declaration you get:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Editor support, including:
&lt;ul&gt;
&lt;li&gt;Completion.&lt;/li&gt;
&lt;li&gt;Type checks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Validation of data:
&lt;ul&gt;
&lt;li&gt;Automatic and clear errors when the data is invalid.&lt;/li&gt;
&lt;li&gt;Validation even for deeply nested JSON objects.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Conversion of input data: coming from the network to Python data and types. Reading from:
&lt;ul&gt;
&lt;li&gt;JSON.&lt;/li&gt;
&lt;li&gt;Path parameters.&lt;/li&gt;
&lt;li&gt;Query parameters.&lt;/li&gt;
&lt;li&gt;Cookies.&lt;/li&gt;
&lt;li&gt;Headers.&lt;/li&gt;
&lt;li&gt;Forms.&lt;/li&gt;
&lt;li&gt;Files.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Conversion of output data: converting from Python data and types to network data (as JSON):
&lt;ul&gt;
&lt;li&gt;Convert Python types (&lt;code&gt;str&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;, &lt;code&gt;float&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;, &lt;code&gt;list&lt;/code&gt;, etc).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;datetime&lt;/code&gt; objects.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;UUID&lt;/code&gt; objects.&lt;/li&gt;
&lt;li&gt;Database models.&lt;/li&gt;
&lt;li&gt;...and many more.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Automatic interactive API documentation, including 2 alternative user interfaces:
&lt;ul&gt;
&lt;li&gt;Swagger UI.&lt;/li&gt;
&lt;li&gt;ReDoc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Coming back to the previous code example, &lt;strong&gt;FastAPI&lt;/strong&gt; will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Validate that there is an &lt;code&gt;item_id&lt;/code&gt; in the path for &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;PUT&lt;/code&gt; requests.&lt;/li&gt;
&lt;li&gt;Validate that the &lt;code&gt;item_id&lt;/code&gt; is of type &lt;code&gt;int&lt;/code&gt; for &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;PUT&lt;/code&gt; requests.
&lt;ul&gt;
&lt;li&gt;If it is not, the client will see a useful, clear error.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Check if there is an optional query parameter named &lt;code&gt;q&lt;/code&gt; (as in &lt;code&gt;http://127.0.0.1:8000/items/foo?q=somequery&lt;/code&gt;) for &lt;code&gt;GET&lt;/code&gt; requests.
&lt;ul&gt;
&lt;li&gt;As the &lt;code&gt;q&lt;/code&gt; parameter is declared with &lt;code&gt;= None&lt;/code&gt;, it is optional.&lt;/li&gt;
&lt;li&gt;Without the &lt;code&gt;None&lt;/code&gt; it would be required (as is the body in the case with &lt;code&gt;PUT&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For &lt;code&gt;PUT&lt;/code&gt; requests to &lt;code&gt;/items/{item_id}&lt;/code&gt;, Read the body as JSON:
&lt;ul&gt;
&lt;li&gt;Check that it has a required attribute &lt;code&gt;name&lt;/code&gt; that should be a &lt;code&gt;str&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Check that is has a required attribute &lt;code&gt;price&lt;/code&gt; that has to be a &lt;code&gt;float&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Check that it has an optional attribute &lt;code&gt;is_offer&lt;/code&gt;, that should be a &lt;code&gt;bool&lt;/code&gt;, if present.&lt;/li&gt;
&lt;li&gt;All this would also work for deeply nested JSON objects.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Convert from and to JSON automatically.&lt;/li&gt;
&lt;li&gt;Document everything with OpenAPI, that can be used by:
&lt;ul&gt;
&lt;li&gt;Interactive documentation systems.&lt;/li&gt;
&lt;li&gt;Automatic client code generation systems, for many languages.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Provide 2 interactive documentation web interfaces directly.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;We just scratched the surface, but you already get the idea of how it all works.&lt;/p&gt;
&lt;p&gt;Try changing the line with:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;    &lt;span class="pl-k"&gt;return&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_name&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item.name, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item_id}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;...from:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;        &lt;span class="pl-c1"&gt;...&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_name&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item.name &lt;span class="pl-c1"&gt;...&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;...to:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;        &lt;span class="pl-c1"&gt;...&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;item_price&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: item.price &lt;span class="pl-c1"&gt;...&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;...and see how your editor will auto-complete the attributes and know their types:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b65e9d0dfe805713562159d8b226bc85acdd4c21/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f7673636f64652d636f6d706c6574696f6e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/b65e9d0dfe805713562159d8b226bc85acdd4c21/68747470733a2f2f666173746170692e7469616e676f6c6f2e636f6d2f696d672f7673636f64652d636f6d706c6574696f6e2e706e67" alt="editor support" data-canonical-src="https://fastapi.tiangolo.com/img/vscode-completion.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For a more complete example including more features, see the &lt;a href="https://fastapi.tiangolo.com/tutorial/intro/" rel="nofollow"&gt;Tutorial - User Guide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Spoiler alert&lt;/strong&gt;: the tutorial - user guide includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Declaration of &lt;strong&gt;parameters&lt;/strong&gt; from other different places as: &lt;strong&gt;headers&lt;/strong&gt;, &lt;strong&gt;cookies&lt;/strong&gt;, &lt;strong&gt;form fields&lt;/strong&gt; and &lt;strong&gt;files&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;How to set &lt;strong&gt;validation constraints&lt;/strong&gt; as &lt;code&gt;maximum_length&lt;/code&gt; or &lt;code&gt;regex&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;A very powerful and easy to use &lt;strong&gt;Dependency Injection&lt;/strong&gt; system.&lt;/li&gt;
&lt;li&gt;Security and authentication, including support for &lt;strong&gt;OAuth2&lt;/strong&gt; with &lt;strong&gt;JWT tokens&lt;/strong&gt; and &lt;strong&gt;HTTP Basic&lt;/strong&gt; auth.&lt;/li&gt;
&lt;li&gt;More advanced (but equally easy) techniques for declaring &lt;strong&gt;deeply nested JSON models&lt;/strong&gt; (thanks to Pydantic).&lt;/li&gt;
&lt;li&gt;Many extra features (thanks to Starlette) as:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;WebSockets&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GraphQL&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;extremely easy tests based on &lt;code&gt;requests&lt;/code&gt; and &lt;code&gt;pytest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CORS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cookie Sessions&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;...and more.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-performance" class="anchor" aria-hidden="true" href="#performance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Performance&lt;/h2&gt;
&lt;p&gt;Independent TechEmpower benchmarks show &lt;strong&gt;FastAPI&lt;/strong&gt; applications running under Uvicorn as &lt;a href="https://www.techempower.com/benchmarks/#section=test&amp;amp;runid=7464e520-0dc2-473d-bd34-dbdfd7e85911&amp;amp;hw=ph&amp;amp;test=query&amp;amp;l=zijzen-7" rel="nofollow"&gt;one of the fastest Python frameworks available&lt;/a&gt;, only below Starlette and Uvicorn themselves (used internally by FastAPI). (*)&lt;/p&gt;
&lt;p&gt;To understand more about it, see the section &lt;a href="https://fastapi.tiangolo.com/benchmarks/" rel="nofollow"&gt;Benchmarks&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-optional-dependencies" class="anchor" aria-hidden="true" href="#optional-dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Optional Dependencies&lt;/h2&gt;
&lt;p&gt;Used by Pydantic:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/esnme/ultrajson"&gt;&lt;code&gt;ujson&lt;/code&gt;&lt;/a&gt; - for faster JSON "parsing".&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/JoshData/python-email-validator"&gt;&lt;code&gt;email_validator&lt;/code&gt;&lt;/a&gt; - for email validation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Used by Starlette:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://docs.python-requests.org" rel="nofollow"&gt;&lt;code&gt;requests&lt;/code&gt;&lt;/a&gt; - Required if you want to use the &lt;code&gt;TestClient&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Tinche/aiofiles"&gt;&lt;code&gt;aiofiles&lt;/code&gt;&lt;/a&gt; - Required if you want to use &lt;code&gt;FileResponse&lt;/code&gt; or &lt;code&gt;StaticFiles&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jinja.pocoo.org" rel="nofollow"&gt;&lt;code&gt;jinja2&lt;/code&gt;&lt;/a&gt; - Required if you want to use the default template configuration.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://andrew-d.github.io/python-multipart/" rel="nofollow"&gt;&lt;code&gt;python-multipart&lt;/code&gt;&lt;/a&gt; - Required if you want to support form "parsing", with &lt;code&gt;request.form()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pythonhosted.org/itsdangerous/" rel="nofollow"&gt;&lt;code&gt;itsdangerous&lt;/code&gt;&lt;/a&gt; - Required for &lt;code&gt;SessionMiddleware&lt;/code&gt; support.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pyyaml.org/wiki/PyYAMLDocumentation" rel="nofollow"&gt;&lt;code&gt;pyyaml&lt;/code&gt;&lt;/a&gt; - Required for &lt;code&gt;SchemaGenerator&lt;/code&gt; support.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://graphene-python.org/" rel="nofollow"&gt;&lt;code&gt;graphene&lt;/code&gt;&lt;/a&gt; - Required for &lt;code&gt;GraphQLApp&lt;/code&gt; support.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/esnme/ultrajson"&gt;&lt;code&gt;ujson&lt;/code&gt;&lt;/a&gt; - Required if you want to use &lt;code&gt;UJSONResponse&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Used by FastAPI / Starlette:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.uvicorn.org" rel="nofollow"&gt;&lt;code&gt;uvicorn&lt;/code&gt;&lt;/a&gt; - for the server that loads and serves your application.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can install all of these with &lt;code&gt;pip3 install fastapi[all]&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is licensed under the terms of the MIT license.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>tiangolo</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>google-research/bert #15 in Python, This week</title><link>https://github.com/google-research/bert</link><description>&lt;p&gt;&lt;i&gt;TensorFlow code and pre-trained models for BERT&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-bert" class="anchor" aria-hidden="true" href="#bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;BERT&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;***** New May 31st, 2019: Whole Word Masking Models *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is a release of several new models which were the result of an improvement
the pre-processing code.&lt;/p&gt;
&lt;p&gt;In the original pre-processing code, we randomly select WordPiece tokens to
mask. For example:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Input Text: the man jumped up , put his basket on phil ##am ##mon ' s head&lt;/code&gt;
&lt;code&gt;Original Masked Input: [MASK] man [MASK] up , put his [MASK] on phil [MASK] ##mon ' s head&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The new technique is called Whole Word Masking. In this case, we always mask
&lt;em&gt;all&lt;/em&gt; of the the tokens corresponding to a word at once. The overall masking
rate remains the same.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Whole Word Masked Input: the man [MASK] up , put his basket on [MASK] [MASK] [MASK] ' s head&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The training is identical -- we still predict each masked WordPiece token
independently. The improvement comes from the fact that the original prediction
task was too 'easy' for words that had been split into multiple WordPieces.&lt;/p&gt;
&lt;p&gt;This can be enabled during data generation by passing the flag
&lt;code&gt;--do_whole_word_mask=True&lt;/code&gt; to &lt;code&gt;create_pretraining_data.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Pre-trained models with Whole Word Masking are linked below. The data and
training were otherwise identical, and the models have identical structure and
vocab to the original models. We only include BERT-Large models. When using
these models, please make it clear in the paper that you are using the Whole
Word Masking variant of BERT-Large.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Uncased (Whole Word Masking)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2019_05_30/wwm_cased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Cased (Whole Word Masking)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th align="center"&gt;SQUAD 1.1 F1/EM&lt;/th&gt;
&lt;th align="center"&gt;Multi NLI Accuracy&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;BERT-Large, Uncased (Original)&lt;/td&gt;
&lt;td align="center"&gt;91.0/84.3&lt;/td&gt;
&lt;td align="center"&gt;86.05&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BERT-Large, Uncased (Whole Word Masking)&lt;/td&gt;
&lt;td align="center"&gt;92.8/86.7&lt;/td&gt;
&lt;td align="center"&gt;87.07&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BERT-Large, Cased (Original)&lt;/td&gt;
&lt;td align="center"&gt;91.5/84.8&lt;/td&gt;
&lt;td align="center"&gt;86.09&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BERT-Large, Cased (Whole Word Masking)&lt;/td&gt;
&lt;td align="center"&gt;92.9/86.7&lt;/td&gt;
&lt;td align="center"&gt;86.46&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;***** New February 7th, 2019: TfHub Module *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;BERT has been uploaded to &lt;a href="https://tfhub.dev" rel="nofollow"&gt;TensorFlow Hub&lt;/a&gt;. See
&lt;code&gt;run_classifier_with_tfhub.py&lt;/code&gt; for an example of how to use the TF Hub module,
or run an example in the browser on
&lt;a href="https://colab.sandbox.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb" rel="nofollow"&gt;Colab&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;***** New November 23rd, 2018: Un-normalized multilingual model + Thai +
Mongolian *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We uploaded a new multilingual model which does &lt;em&gt;not&lt;/em&gt; perform any normalization
on the input (no lower casing, accent stripping, or Unicode normalization), and
additionally inclues Thai and Mongolian.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It is recommended to use this version for developing multilingual models,
especially on languages with non-Latin alphabets.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This does not require any code changes, and can be downloaded here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Multilingual Cased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
104 languages, 12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;***** New November 15th, 2018: SOTA SQuAD 2.0 System *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We released code changes to reproduce our 83% F1 SQuAD 2.0 system, which is
currently 1st place on the leaderboard by 3%. See the SQuAD 2.0 section of the
README for details.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;***** New November 5th, 2018: Third-party PyTorch and Chainer versions of
BERT available *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;NLP researchers from HuggingFace made a
&lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT"&gt;PyTorch version of BERT available&lt;/a&gt;
which is compatible with our pre-trained checkpoints and is able to reproduce
our results. Sosuke Kobayashi also made a
&lt;a href="https://github.com/soskek/bert-chainer"&gt;Chainer version of BERT available&lt;/a&gt;
(Thanks!) We were not involved in the creation or maintenance of the PyTorch
implementation so please direct any questions towards the authors of that
repository.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;***** New November 3rd, 2018: Multilingual and Chinese models available
*****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We have made two new BERT models available:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/multilingual_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Multilingual&lt;/code&gt;&lt;/a&gt;
(Not recommended, use &lt;code&gt;Multilingual Cased&lt;/code&gt; instead)&lt;/strong&gt;: 102 languages,
12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Chinese&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M
parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We use character-based tokenization for Chinese, and WordPiece tokenization for
all other languages. Both models should work out-of-the-box without any code
changes. We did update the implementation of &lt;code&gt;BasicTokenizer&lt;/code&gt; in
&lt;code&gt;tokenization.py&lt;/code&gt; to support Chinese character tokenization, so please update if
you forked it. However, we did not change the tokenization API.&lt;/p&gt;
&lt;p&gt;For more, see the
&lt;a href="https://github.com/google-research/bert/blob/master/multilingual.md"&gt;Multilingual README&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;***** End new information *****&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;BERT&lt;/strong&gt;, or &lt;strong&gt;B&lt;/strong&gt;idirectional &lt;strong&gt;E&lt;/strong&gt;ncoder &lt;strong&gt;R&lt;/strong&gt;epresentations from
&lt;strong&gt;T&lt;/strong&gt;ransformers, is a new method of pre-training language representations which
obtains state-of-the-art results on a wide array of Natural Language Processing
(NLP) tasks.&lt;/p&gt;
&lt;p&gt;Our academic paper which describes BERT in detail and provides full results on a
number of tasks can be found here:
&lt;a href="https://arxiv.org/abs/1810.04805" rel="nofollow"&gt;https://arxiv.org/abs/1810.04805&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To give a few numbers, here are the results on the
&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/" rel="nofollow"&gt;SQuAD v1.1&lt;/a&gt; question answering
task:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SQuAD v1.1 Leaderboard (Oct 8th 2018)&lt;/th&gt;
&lt;th align="center"&gt;Test EM&lt;/th&gt;
&lt;th align="center"&gt;Test F1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1st Place Ensemble - BERT&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;87.4&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;93.2&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2nd Place Ensemble - nlnet&lt;/td&gt;
&lt;td align="center"&gt;86.0&lt;/td&gt;
&lt;td align="center"&gt;91.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1st Place Single Model - BERT&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;85.1&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;91.8&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2nd Place Single Model - nlnet&lt;/td&gt;
&lt;td align="center"&gt;83.5&lt;/td&gt;
&lt;td align="center"&gt;90.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;And several natural language inference tasks:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;System&lt;/th&gt;
&lt;th align="center"&gt;MultiNLI&lt;/th&gt;
&lt;th align="center"&gt;Question NLI&lt;/th&gt;
&lt;th align="center"&gt;SWAG&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;BERT&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;86.7&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;91.1&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;86.3&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OpenAI GPT (Prev. SOTA)&lt;/td&gt;
&lt;td align="center"&gt;82.2&lt;/td&gt;
&lt;td align="center"&gt;88.1&lt;/td&gt;
&lt;td align="center"&gt;75.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Plus many other tasks.&lt;/p&gt;
&lt;p&gt;Moreover, these results were all obtained with almost no task-specific neural
network architecture design.&lt;/p&gt;
&lt;p&gt;If you already know what BERT is and you just want to get started, you can
&lt;a href="#pre-trained-models"&gt;download the pre-trained models&lt;/a&gt; and
&lt;a href="#fine-tuning-with-bert"&gt;run a state-of-the-art fine-tuning&lt;/a&gt; in only a few
minutes.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-what-is-bert" class="anchor" aria-hidden="true" href="#what-is-bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is BERT?&lt;/h2&gt;
&lt;p&gt;BERT is a method of pre-training language representations, meaning that we train
a general-purpose "language understanding" model on a large text corpus (like
Wikipedia), and then use that model for downstream NLP tasks that we care about
(like question answering). BERT outperforms previous methods because it is the
first &lt;em&gt;unsupervised&lt;/em&gt;, &lt;em&gt;deeply bidirectional&lt;/em&gt; system for pre-training NLP.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Unsupervised&lt;/em&gt; means that BERT was trained using only a plain text corpus, which
is important because an enormous amount of plain text data is publicly available
on the web in many languages.&lt;/p&gt;
&lt;p&gt;Pre-trained representations can also either be &lt;em&gt;context-free&lt;/em&gt; or &lt;em&gt;contextual&lt;/em&gt;,
and contextual representations can further be &lt;em&gt;unidirectional&lt;/em&gt; or
&lt;em&gt;bidirectional&lt;/em&gt;. Context-free models such as
&lt;a href="https://www.tensorflow.org/tutorials/representation/word2vec" rel="nofollow"&gt;word2vec&lt;/a&gt; or
&lt;a href="https://nlp.stanford.edu/projects/glove/" rel="nofollow"&gt;GloVe&lt;/a&gt; generate a single "word
embedding" representation for each word in the vocabulary, so &lt;code&gt;bank&lt;/code&gt; would have
the same representation in &lt;code&gt;bank deposit&lt;/code&gt; and &lt;code&gt;river bank&lt;/code&gt;. Contextual models
instead generate a representation of each word that is based on the other words
in the sentence.&lt;/p&gt;
&lt;p&gt;BERT was built upon recent work in pre-training contextual representations —
including &lt;a href="https://arxiv.org/abs/1511.01432" rel="nofollow"&gt;Semi-supervised Sequence Learning&lt;/a&gt;,
&lt;a href="https://blog.openai.com/language-unsupervised/" rel="nofollow"&gt;Generative Pre-Training&lt;/a&gt;,
&lt;a href="https://allennlp.org/elmo" rel="nofollow"&gt;ELMo&lt;/a&gt;, and
&lt;a href="http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html" rel="nofollow"&gt;ULMFit&lt;/a&gt;
— but crucially these models are all &lt;em&gt;unidirectional&lt;/em&gt; or &lt;em&gt;shallowly
bidirectional&lt;/em&gt;. This means that each word is only contextualized using the words
to its left (or right). For example, in the sentence &lt;code&gt;I made a bank deposit&lt;/code&gt; the
unidirectional representation of &lt;code&gt;bank&lt;/code&gt; is only based on &lt;code&gt;I made a&lt;/code&gt; but not
&lt;code&gt;deposit&lt;/code&gt;. Some previous work does combine the representations from separate
left-context and right-context models, but only in a "shallow" manner. BERT
represents "bank" using both its left and right context — &lt;code&gt;I made a ... deposit&lt;/code&gt;
— starting from the very bottom of a deep neural network, so it is &lt;em&gt;deeply
bidirectional&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;BERT uses a simple approach for this: We mask out 15% of the words in the input,
run the entire sequence through a deep bidirectional
&lt;a href="https://arxiv.org/abs/1706.03762" rel="nofollow"&gt;Transformer&lt;/a&gt; encoder, and then predict only
the masked words. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Input: the man went to the [MASK1] . he bought a [MASK2] of milk.
Labels: [MASK1] = store; [MASK2] = gallon
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to learn relationships between sentences, we also train on a simple
task which can be generated from any monolingual corpus: Given two sentences &lt;code&gt;A&lt;/code&gt;
and &lt;code&gt;B&lt;/code&gt;, is &lt;code&gt;B&lt;/code&gt; the actual next sentence that comes after &lt;code&gt;A&lt;/code&gt;, or just a random
sentence from the corpus?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Sentence A: the man went to the store .
Sentence B: he bought a gallon of milk .
Label: IsNextSentence
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Sentence A: the man went to the store .
Sentence B: penguins are flightless .
Label: NotNextSentence
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We then train a large model (12-layer to 24-layer Transformer) on a large corpus
(Wikipedia + &lt;a href="http://yknzhu.wixsite.com/mbweb" rel="nofollow"&gt;BookCorpus&lt;/a&gt;) for a long time (1M
update steps), and that's BERT.&lt;/p&gt;
&lt;p&gt;Using BERT has two stages: &lt;em&gt;Pre-training&lt;/em&gt; and &lt;em&gt;fine-tuning&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pre-training&lt;/strong&gt; is fairly expensive (four days on 4 to 16 Cloud TPUs), but is a
one-time procedure for each language (current models are English-only, but
multilingual models will be released in the near future). We are releasing a
number of pre-trained models from the paper which were pre-trained at Google.
Most NLP researchers will never need to pre-train their own model from scratch.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fine-tuning&lt;/strong&gt; is inexpensive. All of the results in the paper can be
replicated in at most 1 hour on a single Cloud TPU, or a few hours on a GPU,
starting from the exact same pre-trained model. SQuAD, for example, can be
trained in around 30 minutes on a single Cloud TPU to achieve a Dev F1 score of
91.0%, which is the single system state-of-the-art.&lt;/p&gt;
&lt;p&gt;The other important aspect of BERT is that it can be adapted to many types of
NLP tasks very easily. In the paper, we demonstrate state-of-the-art results on
sentence-level (e.g., SST-2), sentence-pair-level (e.g., MultiNLI), word-level
(e.g., NER), and span-level (e.g., SQuAD) tasks with almost no task-specific
modifications.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-what-has-been-released-in-this-repository" class="anchor" aria-hidden="true" href="#what-has-been-released-in-this-repository"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What has been released in this repository?&lt;/h2&gt;
&lt;p&gt;We are releasing the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TensorFlow code for the BERT model architecture (which is mostly a standard
&lt;a href="https://arxiv.org/abs/1706.03762" rel="nofollow"&gt;Transformer&lt;/a&gt; architecture).&lt;/li&gt;
&lt;li&gt;Pre-trained checkpoints for both the lowercase and cased version of
&lt;code&gt;BERT-Base&lt;/code&gt; and &lt;code&gt;BERT-Large&lt;/code&gt; from the paper.&lt;/li&gt;
&lt;li&gt;TensorFlow code for push-button replication of the most important
fine-tuning experiments from the paper, including SQuAD, MultiNLI, and MRPC.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of the code in this repository works out-of-the-box with CPU, GPU, and Cloud
TPU.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pre-trained-models" class="anchor" aria-hidden="true" href="#pre-trained-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-trained models&lt;/h2&gt;
&lt;p&gt;We are releasing the &lt;code&gt;BERT-Base&lt;/code&gt; and &lt;code&gt;BERT-Large&lt;/code&gt; models from the paper.
&lt;code&gt;Uncased&lt;/code&gt; means that the text has been lowercased before WordPiece tokenization,
e.g., &lt;code&gt;John Smith&lt;/code&gt; becomes &lt;code&gt;john smith&lt;/code&gt;. The &lt;code&gt;Uncased&lt;/code&gt; model also strips out any
accent markers. &lt;code&gt;Cased&lt;/code&gt; means that the true case and accent markers are
preserved. Typically, the &lt;code&gt;Uncased&lt;/code&gt; model is better unless you know that case
information is important for your task (e.g., Named Entity Recognition or
Part-of-Speech tagging).&lt;/p&gt;
&lt;p&gt;These models are all released under the same license as the source code (Apache
2.0).&lt;/p&gt;
&lt;p&gt;For information about the Multilingual and Chinese model, see the
&lt;a href="https://github.com/google-research/bert/blob/master/multilingual.md"&gt;Multilingual README&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When using a cased model, make sure to pass &lt;code&gt;--do_lower=False&lt;/code&gt; to the training
scripts. (Or pass &lt;code&gt;do_lower_case=False&lt;/code&gt; directly to &lt;code&gt;FullTokenizer&lt;/code&gt; if you're
using your own script.)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The links to the models are here (right-click, 'Save link as...' on the name):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Uncased (Whole Word Masking)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2019_05_30/wwm_cased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Cased (Whole Word Masking)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Uncased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Uncased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Cased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
12-layer, 768-hidden, 12-heads , 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Large, Cased&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Multilingual Cased (New, recommended)&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
104 languages, 12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/multilingual_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Multilingual Uncased (Orig, not recommended)&lt;/code&gt;&lt;/a&gt;
(Not recommended, use &lt;code&gt;Multilingual Cased&lt;/code&gt; instead)&lt;/strong&gt;: 102 languages,
12-layer, 768-hidden, 12-heads, 110M parameters&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip" rel="nofollow"&gt;&lt;code&gt;BERT-Base, Chinese&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M
parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each .zip file contains three items:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A TensorFlow checkpoint (&lt;code&gt;bert_model.ckpt&lt;/code&gt;) containing the pre-trained
weights (which is actually 3 files).&lt;/li&gt;
&lt;li&gt;A vocab file (&lt;code&gt;vocab.txt&lt;/code&gt;) to map WordPiece to word id.&lt;/li&gt;
&lt;li&gt;A config file (&lt;code&gt;bert_config.json&lt;/code&gt;) which specifies the hyperparameters of
the model.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-fine-tuning-with-bert" class="anchor" aria-hidden="true" href="#fine-tuning-with-bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning with BERT&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: All results on the paper were fine-tuned on a single Cloud TPU,
which has 64GB of RAM. It is currently not possible to re-produce most of the
&lt;code&gt;BERT-Large&lt;/code&gt; results on the paper using a GPU with 12GB - 16GB of RAM, because
the maximum batch size that can fit in memory is too small. We are working on
adding code to this repository which allows for much larger effective batch size
on the GPU. See the section on &lt;a href="#out-of-memory-issues"&gt;out-of-memory issues&lt;/a&gt; for
more details.&lt;/p&gt;
&lt;p&gt;This code was tested with TensorFlow 1.11.0. It was tested with Python2 and
Python3 (but more thoroughly with Python2, since this is what's used internally
in Google).&lt;/p&gt;
&lt;p&gt;The fine-tuning examples which use &lt;code&gt;BERT-Base&lt;/code&gt; should be able to run on a GPU
that has at least 12GB of RAM using the hyperparameters given.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-fine-tuning-with-cloud-tpus" class="anchor" aria-hidden="true" href="#fine-tuning-with-cloud-tpus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning with Cloud TPUs&lt;/h3&gt;
&lt;p&gt;Most of the examples below assumes that you will be running training/evaluation
on your local machine, using a GPU like a Titan X or GTX 1080.&lt;/p&gt;
&lt;p&gt;However, if you have access to a Cloud TPU that you want to train on, just add
the following flags to &lt;code&gt;run_classifier.py&lt;/code&gt; or &lt;code&gt;run_squad.py&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  --use_tpu=True \
  --tpu_name=$TPU_NAME
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please see the
&lt;a href="https://cloud.google.com/tpu/docs/tutorials/mnist" rel="nofollow"&gt;Google Cloud TPU tutorial&lt;/a&gt;
for how to use Cloud TPUs. Alternatively, you can use the Google Colab notebook
"&lt;a href="https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb" rel="nofollow"&gt;BERT FineTuning with Cloud TPUs&lt;/a&gt;".&lt;/p&gt;
&lt;p&gt;On Cloud TPUs, the pretrained model and the output directory will need to be on
Google Cloud Storage. For example, if you have a bucket named &lt;code&gt;some_bucket&lt;/code&gt;, you
might use the following flags instead:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  --output_dir=gs://some_bucket/my_output_dir/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The unzipped pre-trained model files can also be found in the Google Cloud
Storage folder &lt;code&gt;gs://bert_models/2018_10_18&lt;/code&gt;. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export BERT_BASE_DIR=gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-sentence-and-sentence-pair-classification-tasks" class="anchor" aria-hidden="true" href="#sentence-and-sentence-pair-classification-tasks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sentence (and sentence-pair) classification tasks&lt;/h3&gt;
&lt;p&gt;Before running this example you must download the
&lt;a href="https://gluebenchmark.com/tasks" rel="nofollow"&gt;GLUE data&lt;/a&gt; by running
&lt;a href="https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e"&gt;this script&lt;/a&gt;
and unpack it to some directory &lt;code&gt;$GLUE_DIR&lt;/code&gt;. Next, download the &lt;code&gt;BERT-Base&lt;/code&gt;
checkpoint and unzip it to some directory &lt;code&gt;$BERT_BASE_DIR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This example code fine-tunes &lt;code&gt;BERT-Base&lt;/code&gt; on the Microsoft Research Paraphrase
Corpus (MRPC) corpus, which only contains 3,600 examples and can fine-tune in a
few minutes on most GPUs.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12
&lt;span class="pl-k"&gt;export&lt;/span&gt; GLUE_DIR=/path/to/glue

python run_classifier.py \
  --task_name=MRPC \
  --do_train=true \
  --do_eval=true \
  --data_dir=&lt;span class="pl-smi"&gt;$GLUE_DIR&lt;/span&gt;/MRPC \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_model.ckpt \
  --max_seq_length=128 \
  --train_batch_size=32 \
  --learning_rate=2e-5 \
  --num_train_epochs=3.0 \
  --output_dir=/tmp/mrpc_output/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You should see output like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;***** Eval results *****
  eval_accuracy = 0.845588
  eval_loss = 0.505248
  global_step = 343
  loss = 0.505248
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This means that the Dev set accuracy was 84.55%. Small sets like MRPC have a
high variance in the Dev set accuracy, even when starting from the same
pre-training checkpoint. If you re-run multiple times (making sure to point to
different &lt;code&gt;output_dir&lt;/code&gt;), you should see results between 84% and 88%.&lt;/p&gt;
&lt;p&gt;A few other pre-trained models are implemented off-the-shelf in
&lt;code&gt;run_classifier.py&lt;/code&gt;, so it should be straightforward to follow those examples to
use BERT for any single-sentence or sentence-pair classification task.&lt;/p&gt;
&lt;p&gt;Note: You might see a message &lt;code&gt;Running train on CPU&lt;/code&gt;. This really just means
that it's running on something other than a Cloud TPU, which includes a GPU.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-prediction-from-classifier" class="anchor" aria-hidden="true" href="#prediction-from-classifier"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prediction from classifier&lt;/h4&gt;
&lt;p&gt;Once you have trained your classifier you can use it in inference mode by using
the --do_predict=true command. You need to have a file named test.tsv in the
input folder. Output will be created in file called test_results.tsv in the
output folder. Each line will contain output for each sample, columns are the
class probabilities.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12
&lt;span class="pl-k"&gt;export&lt;/span&gt; GLUE_DIR=/path/to/glue
&lt;span class="pl-k"&gt;export&lt;/span&gt; TRAINED_CLASSIFIER=/path/to/fine/tuned/classifier

python run_classifier.py \
  --task_name=MRPC \
  --do_predict=true \
  --data_dir=&lt;span class="pl-smi"&gt;$GLUE_DIR&lt;/span&gt;/MRPC \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$TRAINED_CLASSIFIER&lt;/span&gt; \
  --max_seq_length=128 \
  --output_dir=/tmp/mrpc_output/&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-squad-11" class="anchor" aria-hidden="true" href="#squad-11"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SQuAD 1.1&lt;/h3&gt;
&lt;p&gt;The Stanford Question Answering Dataset (SQuAD) is a popular question answering
benchmark dataset. BERT (at the time of the release) obtains state-of-the-art
results on SQuAD with almost no task-specific network architecture modifications
or data augmentation. However, it does require semi-complex data pre-processing
and post-processing to deal with (a) the variable-length nature of SQuAD context
paragraphs, and (b) the character-level answer annotations which are used for
SQuAD training. This processing is implemented and documented in &lt;code&gt;run_squad.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To run on SQuAD, you will first need to download the dataset. The
&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/" rel="nofollow"&gt;SQuAD website&lt;/a&gt; does not seem to
link to the v1.1 datasets any longer, but the necessary files can be found here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json" rel="nofollow"&gt;train-v1.1.json&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json" rel="nofollow"&gt;dev-v1.1.json&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/allenai/bi-att-flow/blob/master/squad/evaluate-v1.1.py"&gt;evaluate-v1.1.py&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Download these to some directory &lt;code&gt;$SQUAD_DIR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The state-of-the-art SQuAD results from the paper currently cannot be reproduced
on a 12GB-16GB GPU due to memory constraints (in fact, even batch size 1 does
not seem to fit on a 12GB GPU using &lt;code&gt;BERT-Large&lt;/code&gt;). However, a reasonably strong
&lt;code&gt;BERT-Base&lt;/code&gt; model can be trained on the GPU with these hyperparameters:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_squad.py \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_model.ckpt \
  --do_train=True \
  --train_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v1.1.json \
  --do_predict=True \
  --predict_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json \
  --train_batch_size=12 \
  --learning_rate=3e-5 \
  --num_train_epochs=2.0 \
  --max_seq_length=384 \
  --doc_stride=128 \
  --output_dir=/tmp/squad_base/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The dev set predictions will be saved into a file called &lt;code&gt;predictions.json&lt;/code&gt; in
the &lt;code&gt;output_dir&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/evaluate-v1.1.py &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json ./squad/predictions.json&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Which should produce an output like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;f1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 88.41249612335034, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;exact_match&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 81.2488174077578}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You should see a result similar to the 88.5% reported in the paper for
&lt;code&gt;BERT-Base&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you have access to a Cloud TPU, you can train with &lt;code&gt;BERT-Large&lt;/code&gt;. Here is a
set of hyperparameters (slightly different than the paper) which consistently
obtain around 90.5%-91.0% F1 single-system trained only on SQuAD:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_squad.py \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_model.ckpt \
  --do_train=True \
  --train_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v1.1.json \
  --do_predict=True \
  --predict_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json \
  --train_batch_size=24 \
  --learning_rate=3e-5 \
  --num_train_epochs=2.0 \
  --max_seq_length=384 \
  --doc_stride=128 \
  --output_dir=gs://some_bucket/squad_large/ \
  --use_tpu=True \
  --tpu_name=&lt;span class="pl-smi"&gt;$TPU_NAME&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For example, one random run with these parameters produces the following Dev
scores:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;f1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 90.87081895814865, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;exact_match&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 84.38978240302744}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you fine-tune for one epoch on
&lt;a href="http://nlp.cs.washington.edu/triviaqa/" rel="nofollow"&gt;TriviaQA&lt;/a&gt; before this the results will
be even better, but you will need to convert TriviaQA into the SQuAD json
format.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-squad-20" class="anchor" aria-hidden="true" href="#squad-20"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SQuAD 2.0&lt;/h3&gt;
&lt;p&gt;This model is also implemented and documented in &lt;code&gt;run_squad.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To run on SQuAD 2.0, you will first need to download the dataset. The necessary
files can be found here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json" rel="nofollow"&gt;train-v2.0.json&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json" rel="nofollow"&gt;dev-v2.0.json&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/" rel="nofollow"&gt;evaluate-v2.0.py&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Download these to some directory &lt;code&gt;$SQUAD_DIR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;On Cloud TPU you can run with BERT-Large as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_squad.py \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_model.ckpt \
  --do_train=True \
  --train_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v2.0.json \
  --do_predict=True \
  --predict_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v2.0.json \
  --train_batch_size=24 \
  --learning_rate=3e-5 \
  --num_train_epochs=2.0 \
  --max_seq_length=384 \
  --doc_stride=128 \
  --output_dir=gs://some_bucket/squad_large/ \
  --use_tpu=True \
  --tpu_name=&lt;span class="pl-smi"&gt;$TPU_NAME&lt;/span&gt; \
  --version_2_with_negative=True&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We assume you have copied everything from the output directory to a local
directory called ./squad/. The initial dev set predictions will be at
./squad/predictions.json and the differences between the score of no answer ("")
and the best non-null answer for each question will be in the file
./squad/null_odds.json&lt;/p&gt;
&lt;p&gt;Run this script to tune a threshold for predicting null versus non-null answers:&lt;/p&gt;
&lt;p&gt;python $SQUAD_DIR/evaluate-v2.0.py $SQUAD_DIR/dev-v2.0.json
./squad/predictions.json --na-prob-file ./squad/null_odds.json&lt;/p&gt;
&lt;p&gt;Assume the script outputs "best_f1_thresh" THRESH. (Typical values are between
-1.0 and -5.0). You can now re-run the model to generate predictions with the
derived threshold or alternatively you can extract the appropriate answers from
./squad/nbest_predictions.json.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_squad.py \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_LARGE_DIR&lt;/span&gt;/bert_model.ckpt \
  --do_train=False \
  --train_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v2.0.json \
  --do_predict=True \
  --predict_file=&lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v2.0.json \
  --train_batch_size=24 \
  --learning_rate=3e-5 \
  --num_train_epochs=2.0 \
  --max_seq_length=384 \
  --doc_stride=128 \
  --output_dir=gs://some_bucket/squad_large/ \
  --use_tpu=True \
  --tpu_name=&lt;span class="pl-smi"&gt;$TPU_NAME&lt;/span&gt; \
  --version_2_with_negative=True \
  --null_score_diff_threshold=&lt;span class="pl-smi"&gt;$THRESH&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-out-of-memory-issues" class="anchor" aria-hidden="true" href="#out-of-memory-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Out-of-memory issues&lt;/h3&gt;
&lt;p&gt;All experiments in the paper were fine-tuned on a Cloud TPU, which has 64GB of
device RAM. Therefore, when using a GPU with 12GB - 16GB of RAM, you are likely
to encounter out-of-memory issues if you use the same hyperparameters described
in the paper.&lt;/p&gt;
&lt;p&gt;The factors that affect memory usage are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;max_seq_length&lt;/code&gt;&lt;/strong&gt;: The released models were trained with sequence lengths
up to 512, but you can fine-tune with a shorter max sequence length to save
substantial memory. This is controlled by the &lt;code&gt;max_seq_length&lt;/code&gt; flag in our
example code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;train_batch_size&lt;/code&gt;&lt;/strong&gt;: The memory usage is also directly proportional to
the batch size.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model type, &lt;code&gt;BERT-Base&lt;/code&gt; vs. &lt;code&gt;BERT-Large&lt;/code&gt;&lt;/strong&gt;: The &lt;code&gt;BERT-Large&lt;/code&gt; model
requires significantly more memory than &lt;code&gt;BERT-Base&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Optimizer&lt;/strong&gt;: The default optimizer for BERT is Adam, which requires a lot
of extra memory to store the &lt;code&gt;m&lt;/code&gt; and &lt;code&gt;v&lt;/code&gt; vectors. Switching to a more memory
efficient optimizer can reduce memory usage, but can also affect the
results. We have not experimented with other optimizers for fine-tuning.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Using the default training scripts (&lt;code&gt;run_classifier.py&lt;/code&gt; and &lt;code&gt;run_squad.py&lt;/code&gt;), we
benchmarked the maximum batch size on single Titan X GPU (12GB RAM) with
TensorFlow 1.11.0:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;System&lt;/th&gt;
&lt;th&gt;Seq Length&lt;/th&gt;
&lt;th&gt;Max Batch Size&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;BERT-Base&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;128&lt;/td&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;320&lt;/td&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;384&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;512&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;BERT-Large&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;128&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;320&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;384&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;512&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Unfortunately, these max batch sizes for &lt;code&gt;BERT-Large&lt;/code&gt; are so small that they
will actually harm the model accuracy, regardless of the learning rate used. We
are working on adding code to this repository which will allow much larger
effective batch sizes to be used on the GPU. The code will be based on one (or
both) of the following techniques:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Gradient accumulation&lt;/strong&gt;: The samples in a minibatch are typically
independent with respect to gradient computation (excluding batch
normalization, which is not used here). This means that the gradients of
multiple smaller minibatches can be accumulated before performing the weight
update, and this will be exactly equivalent to a single larger update.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/openai/gradient-checkpointing"&gt;&lt;strong&gt;Gradient checkpointing&lt;/strong&gt;&lt;/a&gt;:
The major use of GPU/TPU memory during DNN training is caching the
intermediate activations in the forward pass that are necessary for
efficient computation in the backward pass. "Gradient checkpointing" trades
memory for compute time by re-computing the activations in an intelligent
way.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;However, this is not implemented in the current release.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-bert-to-extract-fixed-feature-vectors-like-elmo" class="anchor" aria-hidden="true" href="#using-bert-to-extract-fixed-feature-vectors-like-elmo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using BERT to extract fixed feature vectors (like ELMo)&lt;/h2&gt;
&lt;p&gt;In certain cases, rather than fine-tuning the entire pre-trained model
end-to-end, it can be beneficial to obtained &lt;em&gt;pre-trained contextual
embeddings&lt;/em&gt;, which are fixed contextual representations of each input token
generated from the hidden layers of the pre-trained model. This should also
mitigate most of the out-of-memory issues.&lt;/p&gt;
&lt;p&gt;As an example, we include the script &lt;code&gt;extract_features.py&lt;/code&gt; which can be used
like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Sentence A and Sentence B are separated by the ||| delimiter for sentence&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; pair tasks like question answering and entailment.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; For single sentence inputs, put one sentence per line and DON'T use the&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; delimiter.&lt;/span&gt;
&lt;span class="pl-c1"&gt;echo&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Who was Jim Henson ? ||| Jim Henson was a puppeteer&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; /tmp/input.txt

python extract_features.py \
  --input_file=/tmp/input.txt \
  --output_file=/tmp/output.jsonl \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_model.ckpt \
  --layers=-1,-2,-3,-4 \
  --max_seq_length=128 \
  --batch_size=8&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will create a JSON file (one line per line of input) containing the BERT
activations from each Transformer layer specified by &lt;code&gt;layers&lt;/code&gt; (-1 is the final
hidden layer of the Transformer, etc.)&lt;/p&gt;
&lt;p&gt;Note that this script will produce very large output files (by default, around
15kb for every input token).&lt;/p&gt;
&lt;p&gt;If you need to maintain alignment between the original and tokenized words (for
projecting training labels), see the &lt;a href="#tokenization"&gt;Tokenization&lt;/a&gt; section
below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You may see a message like &lt;code&gt;Could not find trained model in model_dir: /tmp/tmpuB5g5c, running initialization to predict.&lt;/code&gt; This message is expected, it
just means that we are using the &lt;code&gt;init_from_checkpoint()&lt;/code&gt; API rather than the
saved model API. If you don't specify a checkpoint or specify an invalid
checkpoint, this script will complain.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tokenization" class="anchor" aria-hidden="true" href="#tokenization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tokenization&lt;/h2&gt;
&lt;p&gt;For sentence-level tasks (or sentence-pair) tasks, tokenization is very simple.
Just follow the example code in &lt;code&gt;run_classifier.py&lt;/code&gt; and &lt;code&gt;extract_features.py&lt;/code&gt;.
The basic procedure for sentence-level tasks is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Instantiate an instance of &lt;code&gt;tokenizer = tokenization.FullTokenizer&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tokenize the raw text with &lt;code&gt;tokens = tokenizer.tokenize(raw_text)&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Truncate to the maximum sequence length. (You can use up to 512, but you
probably want to use shorter if possible for memory and speed reasons.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add the &lt;code&gt;[CLS]&lt;/code&gt; and &lt;code&gt;[SEP]&lt;/code&gt; tokens in the right place.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Word-level and span-level tasks (e.g., SQuAD and NER) are more complex, since
you need to maintain alignment between your input text and output text so that
you can project your training labels. SQuAD is a particularly complex example
because the input labels are &lt;em&gt;character&lt;/em&gt;-based, and SQuAD paragraphs are often
longer than our maximum sequence length. See the code in &lt;code&gt;run_squad.py&lt;/code&gt; to show
how we handle this.&lt;/p&gt;
&lt;p&gt;Before we describe the general recipe for handling word-level tasks, it's
important to understand what exactly our tokenizer is doing. It has three main
steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Text normalization&lt;/strong&gt;: Convert all whitespace characters to spaces, and
(for the &lt;code&gt;Uncased&lt;/code&gt; model) lowercase the input and strip out accent markers.
E.g., &lt;code&gt;John Johanson's, → john johanson's,&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Punctuation splitting&lt;/strong&gt;: Split &lt;em&gt;all&lt;/em&gt; punctuation characters on both sides
(i.e., add whitespace around all punctuation characters). Punctuation
characters are defined as (a) Anything with a &lt;code&gt;P*&lt;/code&gt; Unicode class, (b) any
non-letter/number/space ASCII character (e.g., characters like &lt;code&gt;$&lt;/code&gt; which are
technically not punctuation). E.g., &lt;code&gt;john johanson's, → john johanson ' s ,&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;WordPiece tokenization&lt;/strong&gt;: Apply whitespace tokenization to the output of
the above procedure, and apply
&lt;a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/text_encoder.py"&gt;WordPiece&lt;/a&gt;
tokenization to each token separately. (Our implementation is directly based
on the one from &lt;code&gt;tensor2tensor&lt;/code&gt;, which is linked). E.g., &lt;code&gt;john johanson ' s , → john johan ##son ' s ,&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The advantage of this scheme is that it is "compatible" with most existing
English tokenizers. For example, imagine that you have a part-of-speech tagging
task which looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Input:  John Johanson 's   house
Labels: NNP  NNP      POS NN
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The tokenized output will look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Tokens: john johan ##son ' s house
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Crucially, this would be the same output as if the raw text were &lt;code&gt;John Johanson's house&lt;/code&gt; (with no space before the &lt;code&gt;'s&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;If you have a pre-tokenized representation with word-level annotations, you can
simply tokenize each input word independently, and deterministically maintain an
original-to-tokenized alignment:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Input&lt;/span&gt;
orig_tokens &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;John&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Johanson&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;'s&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,  &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;house&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;]
labels      &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;NNP&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,  &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;NNP&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,      &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;POS&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;NN&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Output&lt;/span&gt;
bert_tokens &lt;span class="pl-k"&gt;=&lt;/span&gt; []

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Token map will be an int -&amp;gt; int mapping between the `orig_tokens` index and&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; the `bert_tokens` index.&lt;/span&gt;
orig_to_tok_map &lt;span class="pl-k"&gt;=&lt;/span&gt; []

tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; tokenization.FullTokenizer(
    &lt;span class="pl-v"&gt;vocab_file&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;vocab_file, &lt;span class="pl-v"&gt;do_lower_case&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)

bert_tokens.append(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;[CLS]&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;for&lt;/span&gt; orig_token &lt;span class="pl-k"&gt;in&lt;/span&gt; orig_tokens:
  orig_to_tok_map.append(&lt;span class="pl-c1"&gt;len&lt;/span&gt;(bert_tokens))
  bert_tokens.extend(tokenizer.tokenize(orig_token))
bert_tokens.append(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;[SEP]&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; bert_tokens == ["[CLS]", "john", "johan", "##son", "'", "s", "house", "[SEP]"]&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; orig_to_tok_map == [1, 2, 4, 6]&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now &lt;code&gt;orig_to_tok_map&lt;/code&gt; can be used to project &lt;code&gt;labels&lt;/code&gt; to the tokenized
representation.&lt;/p&gt;
&lt;p&gt;There are common English tokenization schemes which will cause a slight mismatch
between how BERT was pre-trained. For example, if your input tokenization splits
off contractions like &lt;code&gt;do n't&lt;/code&gt;, this will cause a mismatch. If it is possible to
do so, you should pre-process your data to convert these back to raw-looking
text, but if it's not possible, this mismatch is likely not a big deal.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pre-training-with-bert" class="anchor" aria-hidden="true" href="#pre-training-with-bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-training with BERT&lt;/h2&gt;
&lt;p&gt;We are releasing code to do "masked LM" and "next sentence prediction" on an
arbitrary text corpus. Note that this is &lt;em&gt;not&lt;/em&gt; the exact code that was used for
the paper (the original code was written in C++, and had some additional
complexity), but this code does generate pre-training data as described in the
paper.&lt;/p&gt;
&lt;p&gt;Here's how to run the data generation. The input is a plain text file, with one
sentence per line. (It is important that these be actual sentences for the "next
sentence prediction" task). Documents are delimited by empty lines. The output
is a set of &lt;code&gt;tf.train.Example&lt;/code&gt;s serialized into &lt;code&gt;TFRecord&lt;/code&gt; file format.&lt;/p&gt;
&lt;p&gt;You can perform sentence segmentation with an off-the-shelf NLP toolkit such as
&lt;a href="https://spacy.io/" rel="nofollow"&gt;spaCy&lt;/a&gt;. The &lt;code&gt;create_pretraining_data.py&lt;/code&gt; script will
concatenate segments until they reach the maximum sequence length to minimize
computational waste from padding (see the script for more details). However, you
may want to intentionally add a slight amount of noise to your input data (e.g.,
randomly truncate 2% of input segments) to make it more robust to non-sentential
input during fine-tuning.&lt;/p&gt;
&lt;p&gt;This script stores all of the examples for the entire input file in memory, so
for large data files you should shard the input file and call the script
multiple times. (You can pass in a file glob to &lt;code&gt;run_pretraining.py&lt;/code&gt;, e.g.,
&lt;code&gt;tf_examples.tf_record*&lt;/code&gt;.)&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;max_predictions_per_seq&lt;/code&gt; is the maximum number of masked LM predictions per
sequence. You should set this to around &lt;code&gt;max_seq_length&lt;/code&gt; * &lt;code&gt;masked_lm_prob&lt;/code&gt; (the
script doesn't do that automatically because the exact value needs to be passed
to both scripts).&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python create_pretraining_data.py \
  --input_file=./sample_text.txt \
  --output_file=/tmp/tf_examples.tfrecord \
  --vocab_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/vocab.txt \
  --do_lower_case=True \
  --max_seq_length=128 \
  --max_predictions_per_seq=20 \
  --masked_lm_prob=0.15 \
  --random_seed=12345 \
  --dupe_factor=5&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here's how to run the pre-training. Do not include &lt;code&gt;init_checkpoint&lt;/code&gt; if you are
pre-training from scratch. The model configuration (including vocab size) is
specified in &lt;code&gt;bert_config_file&lt;/code&gt;. This demo code only pre-trains for a small
number of steps (20), but in practice you will probably want to set
&lt;code&gt;num_train_steps&lt;/code&gt; to 10000 steps or more. The &lt;code&gt;max_seq_length&lt;/code&gt; and
&lt;code&gt;max_predictions_per_seq&lt;/code&gt; parameters passed to &lt;code&gt;run_pretraining.py&lt;/code&gt; must be the
same as &lt;code&gt;create_pretraining_data.py&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python run_pretraining.py \
  --input_file=/tmp/tf_examples.tfrecord \
  --output_dir=/tmp/pretraining_output \
  --do_train=True \
  --do_eval=True \
  --bert_config_file=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_config.json \
  --init_checkpoint=&lt;span class="pl-smi"&gt;$BERT_BASE_DIR&lt;/span&gt;/bert_model.ckpt \
  --train_batch_size=32 \
  --max_seq_length=128 \
  --max_predictions_per_seq=20 \
  --num_train_steps=20 \
  --num_warmup_steps=10 \
  --learning_rate=2e-5&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will produce an output like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;***** Eval results *****
  global_step = 20
  loss = 0.0979674
  masked_lm_accuracy = 0.985479
  masked_lm_loss = 0.0979328
  next_sentence_accuracy = 1.0
  next_sentence_loss = 3.45724e-05
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that since our &lt;code&gt;sample_text.txt&lt;/code&gt; file is very small, this example training
will overfit that data in only a few steps and produce unrealistically high
accuracy numbers.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-pre-training-tips-and-caveats" class="anchor" aria-hidden="true" href="#pre-training-tips-and-caveats"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-training tips and caveats&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;If using your own vocabulary, make sure to change &lt;code&gt;vocab_size&lt;/code&gt; in
&lt;code&gt;bert_config.json&lt;/code&gt;. If you use a larger vocabulary without changing this,
you will likely get NaNs when training on GPU or TPU due to unchecked
out-of-bounds access.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;If your task has a large domain-specific corpus available (e.g., "movie
reviews" or "scientific papers"), it will likely be beneficial to run
additional steps of pre-training on your corpus, starting from the BERT
checkpoint.&lt;/li&gt;
&lt;li&gt;The learning rate we used in the paper was 1e-4. However, if you are doing
additional steps of pre-training starting from an existing BERT checkpoint,
you should use a smaller learning rate (e.g., 2e-5).&lt;/li&gt;
&lt;li&gt;Current BERT models are English-only, but we do plan to release a
multilingual model which has been pre-trained on a lot of languages in the
near future (hopefully by the end of November 2018).&lt;/li&gt;
&lt;li&gt;Longer sequences are disproportionately expensive because attention is
quadratic to the sequence length. In other words, a batch of 64 sequences of
length 512 is much more expensive than a batch of 256 sequences of
length 128. The fully-connected/convolutional cost is the same, but the
attention cost is far greater for the 512-length sequences. Therefore, one
good recipe is to pre-train for, say, 90,000 steps with a sequence length of
128 and then for 10,000 additional steps with a sequence length of 512. The
very long sequences are mostly needed to learn positional embeddings, which
can be learned fairly quickly. Note that this does require generating the
data twice with different values of &lt;code&gt;max_seq_length&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If you are pre-training from scratch, be prepared that pre-training is
computationally expensive, especially on GPUs. If you are pre-training from
scratch, our recommended recipe is to pre-train a &lt;code&gt;BERT-Base&lt;/code&gt; on a single
&lt;a href="https://cloud.google.com/tpu/docs/pricing" rel="nofollow"&gt;preemptible Cloud TPU v2&lt;/a&gt;, which
takes about 2 weeks at a cost of about $500 USD (based on the pricing in
October 2018). You will have to scale down the batch size when only training
on a single Cloud TPU, compared to what was used in the paper. It is
recommended to use the largest batch size that fits into TPU memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pre-training-data" class="anchor" aria-hidden="true" href="#pre-training-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-training data&lt;/h3&gt;
&lt;p&gt;We will &lt;strong&gt;not&lt;/strong&gt; be able to release the pre-processed datasets used in the paper.
For Wikipedia, the recommended pre-processing is to download
&lt;a href="https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2" rel="nofollow"&gt;the latest dump&lt;/a&gt;,
extract the text with
&lt;a href="https://github.com/attardi/wikiextractor"&gt;&lt;code&gt;WikiExtractor.py&lt;/code&gt;&lt;/a&gt;, and then apply
any necessary cleanup to convert it into plain text.&lt;/p&gt;
&lt;p&gt;Unfortunately the researchers who collected the
&lt;a href="http://yknzhu.wixsite.com/mbweb" rel="nofollow"&gt;BookCorpus&lt;/a&gt; no longer have it available for
public download. The
&lt;a href="https://web.eecs.umich.edu/~lahiri/gutenberg_dataset.html" rel="nofollow"&gt;Project Guttenberg Dataset&lt;/a&gt;
is a somewhat smaller (200M word) collection of older books that are public
domain.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://commoncrawl.org/" rel="nofollow"&gt;Common Crawl&lt;/a&gt; is another very large collection of
text, but you will likely have to do substantial pre-processing and cleanup to
extract a usable corpus for pre-training BERT.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-learning-a-new-wordpiece-vocabulary" class="anchor" aria-hidden="true" href="#learning-a-new-wordpiece-vocabulary"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learning a new WordPiece vocabulary&lt;/h3&gt;
&lt;p&gt;This repository does not include code for &lt;em&gt;learning&lt;/em&gt; a new WordPiece vocabulary.
The reason is that the code used in the paper was implemented in C++ with
dependencies on Google's internal libraries. For English, it is almost always
better to just start with our vocabulary and pre-trained models. For learning
vocabularies of other languages, there are a number of open source options
available. However, keep in mind that these are not compatible with our
&lt;code&gt;tokenization.py&lt;/code&gt; library:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/google/sentencepiece"&gt;Google's SentencePiece library&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/text_encoder_build_subword.py"&gt;tensor2tensor's WordPiece generation script&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/rsennrich/subword-nmt"&gt;Rico Sennrich's Byte Pair Encoding library&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-using-bert-in-colab" class="anchor" aria-hidden="true" href="#using-bert-in-colab"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using BERT in Colab&lt;/h2&gt;
&lt;p&gt;If you want to use BERT with &lt;a href="https://colab.research.google.com" rel="nofollow"&gt;Colab&lt;/a&gt;, you can
get started with the notebook
"&lt;a href="https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb" rel="nofollow"&gt;BERT FineTuning with Cloud TPUs&lt;/a&gt;".
&lt;strong&gt;At the time of this writing (October 31st, 2018), Colab users can access a
Cloud TPU completely for free.&lt;/strong&gt; Note: One per user, availability limited,
requires a Google Cloud Platform account with storage (although storage may be
purchased with free credit for signing up with GCP), and this capability may not
longer be available in the future. Click on the BERT Colab that was just linked
for more information.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-faq" class="anchor" aria-hidden="true" href="#faq"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FAQ&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-is-this-code-compatible-with-cloud-tpus-what-about-gpus" class="anchor" aria-hidden="true" href="#is-this-code-compatible-with-cloud-tpus-what-about-gpus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Is this code compatible with Cloud TPUs? What about GPUs?&lt;/h4&gt;
&lt;p&gt;Yes, all of the code in this repository works out-of-the-box with CPU, GPU, and
Cloud TPU. However, GPU training is single-GPU only.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-i-am-getting-out-of-memory-errors-what-is-wrong" class="anchor" aria-hidden="true" href="#i-am-getting-out-of-memory-errors-what-is-wrong"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;I am getting out-of-memory errors, what is wrong?&lt;/h4&gt;
&lt;p&gt;See the section on &lt;a href="#out-of-memory-issues"&gt;out-of-memory issues&lt;/a&gt; for more
information.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-is-there-a-pytorch-version-available" class="anchor" aria-hidden="true" href="#is-there-a-pytorch-version-available"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Is there a PyTorch version available?&lt;/h4&gt;
&lt;p&gt;There is no official PyTorch implementation. However, NLP researchers from
HuggingFace made a
&lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT"&gt;PyTorch version of BERT available&lt;/a&gt;
which is compatible with our pre-trained checkpoints and is able to reproduce
our results. We were not involved in the creation or maintenance of the PyTorch
implementation so please direct any questions towards the authors of that
repository.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-is-there-a-chainer-version-available" class="anchor" aria-hidden="true" href="#is-there-a-chainer-version-available"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Is there a Chainer version available?&lt;/h4&gt;
&lt;p&gt;There is no official Chainer implementation. However, Sosuke Kobayashi made a
&lt;a href="https://github.com/soskek/bert-chainer"&gt;Chainer version of BERT available&lt;/a&gt;
which is compatible with our pre-trained checkpoints and is able to reproduce
our results. We were not involved in the creation or maintenance of the Chainer
implementation so please direct any questions towards the authors of that
repository.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-will-models-in-other-languages-be-released" class="anchor" aria-hidden="true" href="#will-models-in-other-languages-be-released"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Will models in other languages be released?&lt;/h4&gt;
&lt;p&gt;Yes, we plan to release a multi-lingual BERT model in the near future. We cannot
make promises about exactly which languages will be included, but it will likely
be a single model which includes &lt;em&gt;most&lt;/em&gt; of the languages which have a
significantly-sized Wikipedia.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-will-models-larger-than-bert-large-be-released" class="anchor" aria-hidden="true" href="#will-models-larger-than-bert-large-be-released"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Will models larger than &lt;code&gt;BERT-Large&lt;/code&gt; be released?&lt;/h4&gt;
&lt;p&gt;So far we have not attempted to train anything larger than &lt;code&gt;BERT-Large&lt;/code&gt;. It is
possible that we will release larger models if we are able to obtain significant
improvements.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-what-license-is-this-library-released-under" class="anchor" aria-hidden="true" href="#what-license-is-this-library-released-under"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What license is this library released under?&lt;/h4&gt;
&lt;p&gt;All code &lt;em&gt;and&lt;/em&gt; models are released under the Apache 2.0 license. See the
&lt;code&gt;LICENSE&lt;/code&gt; file for more information.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-how-do-i-cite-bert" class="anchor" aria-hidden="true" href="#how-do-i-cite-bert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How do I cite BERT?&lt;/h4&gt;
&lt;p&gt;For now, cite &lt;a href="https://arxiv.org/abs/1810.04805" rel="nofollow"&gt;the Arxiv paper&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we submit the paper to a conference or journal, we will update the BibTeX.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;This is not an official Google product.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contact-information" class="anchor" aria-hidden="true" href="#contact-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact information&lt;/h2&gt;
&lt;p&gt;For help or issues using BERT, please submit a GitHub issue.&lt;/p&gt;
&lt;p&gt;For personal communication related to BERT, please contact Jacob Devlin
(&lt;code&gt;jacobdevlin@google.com&lt;/code&gt;), Ming-Wei Chang (&lt;code&gt;mingweichang@google.com&lt;/code&gt;), or
Kenton Lee (&lt;code&gt;kentonl@google.com&lt;/code&gt;).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>google-research</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>microsoft/unilm #16 in Python, This week</title><link>https://github.com/microsoft/unilm</link><description>&lt;p&gt;&lt;i&gt;UniLM - Unified Language Model Pre-training&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-unilm" class="anchor" aria-hidden="true" href="#unilm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;UniLM&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;We develop pre-trained models for natural language understanding (NLU) and generation (NLG) tasks&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;***** New October 1st, 2019: UniLM v1 release *****&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UniLM v1&lt;/strong&gt; (September 30th, 2019): the code and pre-trained models for the NeurIPS 2019 paper entitled "&lt;a href="https://arxiv.org/abs/1905.03197" rel="nofollow"&gt;Unified Language Model Pre-training for Natural Language Understanding and Generation&lt;/a&gt;". UniLM (v1) achieves the &lt;strong&gt;new SOTA results&lt;/strong&gt; in &lt;strong&gt;NLG&lt;/strong&gt; (especially &lt;strong&gt;sequence-to-sequence generation&lt;/strong&gt;) tasks/benchmarks, including abstractive summarization (the Gigaword and CNN/DM dataset), question generation (the SQuAD QG dataset), etc.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UniLM v2&lt;/strong&gt;: the new pre-training protocol and implementation scheme (coming soon).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-environment" class="anchor" aria-hidden="true" href="#environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Environment&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h3&gt;
&lt;p&gt;The recommended way to run the code is using docker under Linux:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;alias=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;`&lt;/span&gt;whoami &lt;span class="pl-k"&gt;|&lt;/span&gt; cut -d&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;.&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; -f2&lt;span class="pl-pds"&gt;`&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-k"&gt;;&lt;/span&gt; docker run -it --rm --runtime=nvidia --ipc=host --privileged -v /home/&lt;span class="pl-smi"&gt;${alias}&lt;/span&gt;:/home/&lt;span class="pl-smi"&gt;${alias}&lt;/span&gt; pytorch/pytorch:1.1.0-cuda10.0-cudnn7.5-devel bash&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The docker is initialized by:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;.&lt;/span&gt; .bashrc
apt-get update
apt-get install -y vim wget ssh

PWD_DIR=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;pwd&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;$(&lt;/span&gt;mktemp -d&lt;span class="pl-pds"&gt;)&lt;/span&gt;&lt;/span&gt;
git clone -q https://github.com/NVIDIA/apex.git
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; apex
git reset --hard 1603407bf49c7fc3da74fceb6a6c7b47fece2ef8
python setup.py install --user --cuda_ext --cpp_ext
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; &lt;span class="pl-smi"&gt;$PWD_DIR&lt;/span&gt;

pip install --user tensorboardX six numpy tqdm path.py pandas scikit-learn lmdb pyarrow py-lz4framed methodtools py-rouge pyrouge nltk
python -c &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;import nltk; nltk.download('punkt')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
pip install -e git://github.com/Maluuba/nlg-eval.git#egg=nlg-eval&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The mixed-precision training code requires the specific version of &lt;a href="https://github.com/NVIDIA/apex/tree/1603407bf49c7fc3da74fceb6a6c7b47fece2ef8"&gt;NVIDIA/apex&lt;/a&gt;, which only supports pytorch&amp;lt;1.2.0.&lt;/p&gt;
&lt;p&gt;Install the repo as a package in the docker:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;mkdir &lt;span class="pl-k"&gt;~&lt;/span&gt;/code&lt;span class="pl-k"&gt;;&lt;/span&gt; &lt;span class="pl-c1"&gt;cd&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/code
git clone https://github.com/microsoft/unilm.git
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/code/unilm/src
pip install --user --editable &lt;span class="pl-c1"&gt;.&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-pre-trained-models" class="anchor" aria-hidden="true" href="#pre-trained-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-trained Models&lt;/h2&gt;
&lt;p&gt;We release a large &lt;strong&gt;cased&lt;/strong&gt; UniLM model pre-trained with &lt;strong&gt;Wikipedia and BookCorpus&lt;/strong&gt; corpora. The model is trained by using the same model configuration and WordPiece vocabulary as BERT. The model parameters can be loaded as in the fine-tuning code.&lt;/p&gt;
&lt;p&gt;The links to the pre-trained models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://drive.google.com/open?id=1Zj_nZWO7YffaOInj3Q4SZyn09Mb3In-e" rel="nofollow"&gt;UniLMv1-large-cased&lt;/a&gt;: 24-layer, 1024-hidden, 16-heads, 340M parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-fine-tuning" class="anchor" aria-hidden="true" href="#fine-tuning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning&lt;/h2&gt;
&lt;p&gt;We provide instructions on how to fine-tune UniLM as a sequence-to-sequence model to support various downstream natural language generation tasks as follows. It is recommended to use 2 or 4 v100-32G GPU cards to fine-tune the model. Gradient accumulation (&lt;code&gt;--gradient_accumulation_steps&lt;/code&gt;) can be enabled if there is an OOM error.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-abstractive-summarization---gigaword-10k" class="anchor" aria-hidden="true" href="#abstractive-summarization---gigaword-10k"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Abstractive Summarization - &lt;a href="https://github.com/harvardnlp/sent-summary"&gt;Gigaword&lt;/a&gt; (10K)&lt;/h3&gt;
&lt;p&gt;In the example, only 10K examples of the Gigaword training data are used to fine-tune UniLM. As shown in the following table, pre-training significantly improves performance for low-resource settings.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;ROUGE-1&lt;/th&gt;
&lt;th&gt;ROUGE-2&lt;/th&gt;
&lt;th&gt;ROUGE-L&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://proceedings.mlr.press/v97/song19d/song19d.pdf" rel="nofollow"&gt;Transformer&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;10.97&lt;/td&gt;
&lt;td&gt;2.23&lt;/td&gt;
&lt;td&gt;10.42&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;UniLM&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;34.21&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;15.28&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;31.54&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The data can be downloaded from &lt;a href="https://drive.google.com/open?id=1USoQ8lJgN8kAWnUnRrupMGrPMLlDVqlV" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run fine-tuning&lt;/span&gt;
DATA_DIR=/{path_of_data}/gigaword
OUTPUT_DIR=/{path_of_fine-tuned_model}/
MODEL_RECOVER_PATH=/{path_of_pre-trained_model}/unilmv1-large-cased.bin
&lt;span class="pl-k"&gt;export&lt;/span&gt; PYTORCH_PRETRAINED_BERT_CACHE=/{tmp_folder}/bert-cased-pretrained-cache
&lt;span class="pl-k"&gt;export&lt;/span&gt; CUDA_VISIBLE_DEVICES=0,1,2,3
python biunilm/run_seq2seq.py --do_train --fp16 --amp --num_workers 0 \
  --bert_model bert-large-cased --new_segment_ids --tokenized_input \
  --data_dir &lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt; --src_file train.src.10k --tgt_file train.tgt.10k \
  --output_dir &lt;span class="pl-smi"&gt;${OUTPUT_DIR}&lt;/span&gt;/bert_save \
  --log_dir &lt;span class="pl-smi"&gt;${OUTPUT_DIR}&lt;/span&gt;/bert_log \
  --model_recover_path &lt;span class="pl-smi"&gt;${MODEL_RECOVER_PATH}&lt;/span&gt; \
  --max_seq_length 192 --max_position_embeddings 192 \
  --trunc_seg a --always_truncate_tail --max_len_b 64 \
  --mask_prob 0.7 --max_pred 64 \
  --train_batch_size 128 --gradient_accumulation_steps 1 \
  --learning_rate 0.00001 --warmup_proportion 0.1 --label_smoothing 0.1 \
  --num_train_epochs 30&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We provide a fine-tuned checkpoint (downloaded from &lt;a href="https://drive.google.com/open?id=1yKFBpT2dbN5d6WBjFlJqlXs9DQKCbRWe" rel="nofollow"&gt;here&lt;/a&gt;) used for decoding. The inference and evaluation process is conducted as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run decoding&lt;/span&gt;
DATA_DIR=/{path_of_data}/gigaword
MODEL_RECOVER_PATH=/{path_of_fine-tuned_model}/ggw10k_model.bin
EVAL_SPLIT=test
&lt;span class="pl-k"&gt;export&lt;/span&gt; PYTORCH_PRETRAINED_BERT_CACHE=/{tmp_folder}/bert-cased-pretrained-cache
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run decoding&lt;/span&gt;
python biunilm/decode_seq2seq.py --fp16 --amp --bert_model bert-large-cased --new_segment_ids --mode s2s --need_score_traces \
  --input_file &lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt;/&lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt;.src --split &lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt; --tokenized_input \
  --model_recover_path &lt;span class="pl-smi"&gt;${MODEL_RECOVER_PATH}&lt;/span&gt; \
  --max_seq_length 192 --max_tgt_length 32 \
  --batch_size 64 --beam_size 5 --length_penalty 0 \
  --forbid_duplicate_ngrams --forbid_ignore_word &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run evaluation&lt;/span&gt;
python gigaword/eval.py --pred &lt;span class="pl-smi"&gt;${MODEL_RECOVER_PATH}&lt;/span&gt;.&lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt; \
  --gold &lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt;/org_data/&lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt;.tgt.txt --perl&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The program &lt;code&gt;eval.py&lt;/code&gt; generates a post-processed output file &lt;code&gt;${MODEL_RECOVER_PATH}.${EVAL_SPLIT}.post&lt;/code&gt; (downloaded from &lt;a href="https://drive.google.com/open?id=15R7IvOVT3irdH3d2eqHPs_5Lbh1LIy8U" rel="nofollow"&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-abstractive-summarization---gigaword" class="anchor" aria-hidden="true" href="#abstractive-summarization---gigaword"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Abstractive Summarization - &lt;a href="https://github.com/harvardnlp/sent-summary"&gt;Gigaword&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The training set of Gigaword contains 3.8M examples for headline generation.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;ROUGE-1&lt;/th&gt;
&lt;th&gt;ROUGE-2&lt;/th&gt;
&lt;th&gt;ROUGE-L&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://aclweb.org/anthology/P18-1015" rel="nofollow"&gt;OpenNMT&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;36.73&lt;/td&gt;
&lt;td&gt;17.86&lt;/td&gt;
&lt;td&gt;33.68&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://aclweb.org/anthology/P18-1015" rel="nofollow"&gt;Re3Sum (Cao et al., 2018)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;37.04&lt;/td&gt;
&lt;td&gt;19.03&lt;/td&gt;
&lt;td&gt;34.46&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://proceedings.mlr.press/v97/song19d/song19d.pdf" rel="nofollow"&gt;MASS (Song et al., 2019)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;38.73&lt;/td&gt;
&lt;td&gt;19.71&lt;/td&gt;
&lt;td&gt;35.96&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1907.12461.pdf" rel="nofollow"&gt;BertShare (Rothe et al., 2019)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;38.13&lt;/td&gt;
&lt;td&gt;19.81&lt;/td&gt;
&lt;td&gt;35.62&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;UniLM&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;38.90&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;20.05&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;36.00&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The data can be downloaded from &lt;a href="https://drive.google.com/open?id=1USoQ8lJgN8kAWnUnRrupMGrPMLlDVqlV" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run fine-tuning&lt;/span&gt;
DATA_DIR=/{path_of_data}/gigaword
OUTPUT_DIR=/{path_of_fine-tuned_model}/
MODEL_RECOVER_PATH=/{path_of_pre-trained_model}/unilmv1-large-cased.bin
&lt;span class="pl-k"&gt;export&lt;/span&gt; PYTORCH_PRETRAINED_BERT_CACHE=/{tmp_folder}/bert-cased-pretrained-cache
&lt;span class="pl-k"&gt;export&lt;/span&gt; CUDA_VISIBLE_DEVICES=0,1,2,3
python biunilm/run_seq2seq.py --do_train --fp16 --amp --num_workers 0 \
  --bert_model bert-large-cased --new_segment_ids --tokenized_input \
  --data_dir &lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt; \
  --output_dir &lt;span class="pl-smi"&gt;${OUTPUT_DIR}&lt;/span&gt;/bert_save \
  --log_dir &lt;span class="pl-smi"&gt;${OUTPUT_DIR}&lt;/span&gt;/bert_log \
  --model_recover_path &lt;span class="pl-smi"&gt;${MODEL_RECOVER_PATH}&lt;/span&gt; \
  --max_seq_length 192 --max_position_embeddings 192 \
  --trunc_seg a --always_truncate_tail --max_len_a 0 --max_len_b 64 \
  --mask_prob 0.7 --max_pred 48 \
  --train_batch_size 128 --gradient_accumulation_steps 1 \
  --learning_rate 0.00003 --warmup_proportion 0.1 --label_smoothing 0.1 \
  --num_train_epochs 30&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The size of full training data (3.8M) is quite large. We can stop the fine-tuning procedure after 10 epochs.&lt;/p&gt;
&lt;p&gt;We provide a fine-tuned checkpoint (downloaded from &lt;a href="https://drive.google.com/open?id=1jOI2nO16Uz4a0OWZ7Ro-jnD54MHMDlsv" rel="nofollow"&gt;here&lt;/a&gt;) used for decoding. The inference and evaluation process is conducted as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_DIR=/{path_of_data}/gigaword
MODEL_RECOVER_PATH=/{path_of_fine-tuned_model}/ggw38m_model.bin
EVAL_SPLIT=test
&lt;span class="pl-k"&gt;export&lt;/span&gt; PYTORCH_PRETRAINED_BERT_CACHE=/{tmp_folder}/bert-cased-pretrained-cache
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run decoding&lt;/span&gt;
python biunilm/decode_seq2seq.py --fp16 --amp --bert_model bert-large-cased --new_segment_ids --mode s2s --need_score_traces \
  --input_file &lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt;/&lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt;.src --split &lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt; --tokenized_input \
  --model_recover_path &lt;span class="pl-smi"&gt;${MODEL_RECOVER_PATH}&lt;/span&gt; \
  --max_seq_length 192 --max_tgt_length 32 \
  --batch_size 64 --beam_size 5 --length_penalty 0 \
  --forbid_duplicate_ngrams --forbid_ignore_word &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; apply length penalty&lt;/span&gt;
python biunilm/gen_seq_from_trace.py --bert_model bert-large-cased --alpha 0.6 \
  --input &lt;span class="pl-smi"&gt;${MODEL_RECOVER_PATH}&lt;/span&gt;.&lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run evaluation&lt;/span&gt;
python gigaword/eval.py --pred &lt;span class="pl-smi"&gt;${MODEL_RECOVER_PATH}&lt;/span&gt;.&lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt;.alp0.6 \
  --gold &lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt;/org_data/&lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt;.tgt.txt --perl&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The program &lt;code&gt;eval.py&lt;/code&gt; generates a post-processed output file &lt;code&gt;${MODEL_RECOVER_PATH}.${EVAL_SPLIT}.alp0.6.post&lt;/code&gt; (downloaded from &lt;a href="https://drive.google.com/open?id=1oycvzMC6ZoWZV7BOt5OlZ7q0SxM_0Zc9" rel="nofollow"&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-abstractive-summarization---cnn--daily-mail" class="anchor" aria-hidden="true" href="#abstractive-summarization---cnn--daily-mail"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Abstractive Summarization - &lt;a href="https://github.com/harvardnlp/sent-summary"&gt;CNN / Daily Mail&lt;/a&gt;&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;ROUGE-1&lt;/th&gt;
&lt;th&gt;ROUGE-2&lt;/th&gt;
&lt;th&gt;ROUGE-L&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.aclweb.org/anthology/P17-1099" rel="nofollow"&gt;PGNet (See et al., 2017)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;39.53&lt;/td&gt;
&lt;td&gt;17.28&lt;/td&gt;
&lt;td&gt;36.38&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.aclweb.org/anthology/D18-1443" rel="nofollow"&gt;Bottom-Up (Gehrmann et al., 2018)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;41.22&lt;/td&gt;
&lt;td&gt;18.68&lt;/td&gt;
&lt;td&gt;38.34&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="nofollow"&gt;GPT-2 TL;DR: (Radford et al., 2019)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;29.34&lt;/td&gt;
&lt;td&gt;8.27&lt;/td&gt;
&lt;td&gt;26.58&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/microsoft/MASS#results-on-abstractive-summarization-9272019"&gt;MASS (Song et al., 2019)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;42.12&lt;/td&gt;
&lt;td&gt;19.50&lt;/td&gt;
&lt;td&gt;39.01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1907.12461.pdf" rel="nofollow"&gt;BertShare (Rothe et al., 2019)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;39.25&lt;/td&gt;
&lt;td&gt;18.09&lt;/td&gt;
&lt;td&gt;36.45&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1908.08345.pdf" rel="nofollow"&gt;BertSumAbs (Liu and Lapata, 2019)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;41.72&lt;/td&gt;
&lt;td&gt;19.39&lt;/td&gt;
&lt;td&gt;38.76&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;UniLM&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;43.08&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;20.43&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;40.34&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The data can be downloaded from &lt;a href="https://drive.google.com/open?id=1jiDbDbAsqy_5BM79SmX6aSu5DQVCAZq1" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run fine-tuning&lt;/span&gt;
DATA_DIR=/{path_of_data}/cnn_dailymail
OUTPUT_DIR=/{path_of_fine-tuned_model}/
MODEL_RECOVER_PATH=/{path_of_pre-trained_model}/unilmv1-large-cased.bin
&lt;span class="pl-k"&gt;export&lt;/span&gt; PYTORCH_PRETRAINED_BERT_CACHE=/{tmp_folder}/bert-cased-pretrained-cache
&lt;span class="pl-k"&gt;export&lt;/span&gt; CUDA_VISIBLE_DEVICES=0,1,2,3
python biunilm/run_seq2seq.py --do_train --fp16 --amp --num_workers 0 \
  --bert_model bert-large-cased --new_segment_ids --tokenized_input \
  --data_dir &lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt; \
  --output_dir &lt;span class="pl-smi"&gt;${OUTPUT_DIR}&lt;/span&gt;/bert_save \
  --log_dir &lt;span class="pl-smi"&gt;${OUTPUT_DIR}&lt;/span&gt;/bert_log \
  --model_recover_path &lt;span class="pl-smi"&gt;${MODEL_RECOVER_PATH}&lt;/span&gt; \
  --max_seq_length 768 --max_position_embeddings 768 \
  --trunc_seg a --always_truncate_tail \
  --max_len_a 568 --max_len_b 200 \
  --mask_prob 0.7 --max_pred 140 \
  --train_batch_size 48 --gradient_accumulation_steps 2 \
  --learning_rate 0.00003 --warmup_proportion 0.1 --label_smoothing 0.1 \
  --num_train_epochs 30  &lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We provide a fine-tuned checkpoint (downloaded from &lt;a href="https://drive.google.com/open?id=1RyJxShxC9tDYVAyZwUwqkSoQ3l5DfjuE" rel="nofollow"&gt;here&lt;/a&gt;) used for decoding. The inference and evaluation process is conducted as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_DIR=/{path_of_data}/cnn_dailymail
MODEL_RECOVER_PATH=/{path_of_fine-tuned_model}/cnndm_model.bin
EVAL_SPLIT=test
&lt;span class="pl-k"&gt;export&lt;/span&gt; PYTORCH_PRETRAINED_BERT_CACHE=/{tmp_folder}/bert-cased-pretrained-cache
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run decoding&lt;/span&gt;
python biunilm/decode_seq2seq.py --fp16 --amp --bert_model bert-large-cased --new_segment_ids --mode s2s --need_score_traces \
  --input_file &lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt;/&lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt;.src --split &lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt; --tokenized_input \
  --model_recover_path &lt;span class="pl-smi"&gt;${MODEL_RECOVER_PATH}&lt;/span&gt; \
  --max_seq_length 768 --max_tgt_length 128 \
  --batch_size 64 --beam_size 5 --length_penalty 0 \
  --forbid_duplicate_ngrams --forbid_ignore_word &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;.|[X_SEP]&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; apply length penalty&lt;/span&gt;
python biunilm/gen_seq_from_trace.py --bert_model bert-large-cased --alpha 1.0 \
  --input &lt;span class="pl-smi"&gt;${MODEL_RECOVER_PATH}&lt;/span&gt;.&lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run evaluation&lt;/span&gt;
python cnndm/eval.py --pred &lt;span class="pl-smi"&gt;${MODEL_RECOVER_PATH}&lt;/span&gt;.&lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt;.alp1.0 \
  --gold &lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt;/org_data/&lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt;.summary --trunc_len 70 --perl&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The program &lt;code&gt;eval.py&lt;/code&gt; generates a post-processed output file &lt;code&gt;${MODEL_RECOVER_PATH}.${EVAL_SPLIT}.alp1.0.post&lt;/code&gt; (downloaded from &lt;a href="https://drive.google.com/open?id=1p93XD0wo3YvyxZnNYywujtnQoNCDiTF7" rel="nofollow"&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-question-generation---squad" class="anchor" aria-hidden="true" href="#question-generation---squad"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Question Generation - &lt;a href="https://arxiv.org/abs/1806.03822" rel="nofollow"&gt;SQuAD&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;We present the results following the same &lt;a href="https://github.com/xinyadu/nqg/tree/master/data"&gt;data split&lt;/a&gt; and &lt;a href="https://github.com/xinyadu/nqg/tree/master/qgevalcap"&gt;evaluation scripts&lt;/a&gt; as in &lt;a href="https://arxiv.org/pdf/1705.00106.pdf" rel="nofollow"&gt;(Du et al., 2017)&lt;/a&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;BLEU-4&lt;/th&gt;
&lt;th&gt;METEOR&lt;/th&gt;
&lt;th&gt;ROUGE-L&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.aclweb.org/anthology/P18-1177" rel="nofollow"&gt;(Du and Cardie, 2018)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;15.16&lt;/td&gt;
&lt;td&gt;19.12&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1909.06356.pdf" rel="nofollow"&gt;(Zhang and Bansal, 2019)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;18.37&lt;/td&gt;
&lt;td&gt;22.65&lt;/td&gt;
&lt;td&gt;46.68&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;UniLM&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;22.78&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;25.49&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;51.57&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We also report the results following the data split as in &lt;a href="https://aclweb.org/anthology/D18-1424" rel="nofollow"&gt;(Zhao et al., 2018)&lt;/a&gt;, which uses the reversed dev-test setup.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;BLEU-4&lt;/th&gt;
&lt;th&gt;METEOR&lt;/th&gt;
&lt;th&gt;ROUGE-L&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://aclweb.org/anthology/D18-1424" rel="nofollow"&gt;(Zhao et al., 2018)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;16.38&lt;/td&gt;
&lt;td&gt;20.25&lt;/td&gt;
&lt;td&gt;44.48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1909.06356.pdf" rel="nofollow"&gt;(Zhang and Bansal, 2019)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;20.76&lt;/td&gt;
&lt;td&gt;24.20&lt;/td&gt;
&lt;td&gt;48.91&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;UniLM&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;24.32&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;26.10&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;52.69&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note: If we directly use the tokenized references provided by &lt;a href="https://arxiv.org/pdf/1705.00106.pdf" rel="nofollow"&gt;Du et al. (2017)&lt;/a&gt;, the results are (22.17 BLEU-4 / 25.47 METEOR / 51.53 ROUGE-L) on the &lt;a href="https://github.com/xinyadu/nqg/tree/master/data"&gt;raw data split&lt;/a&gt;, and (23.69 BLEU-4 / 26.08 METEOR / 52.70 ROUGE-L) in the reversed dev-test setup.&lt;/p&gt;
&lt;p&gt;Our processed data can be downloaded from &lt;a href="https://drive.google.com/open?id=11E3Ij-ctbRUTIQjueresZpoVzLMPlVUZ" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run fine-tuning&lt;/span&gt;
DATA_DIR=/{path_of_data}/qg/train
OUTPUT_DIR=/{path_of_fine-tuned_model}/
MODEL_RECOVER_PATH=/{path_of_pre-trained_model}/unilmv1-large-cased.bin
&lt;span class="pl-k"&gt;export&lt;/span&gt; PYTORCH_PRETRAINED_BERT_CACHE=/{tmp_folder}/bert-cased-pretrained-cache
&lt;span class="pl-k"&gt;export&lt;/span&gt; CUDA_VISIBLE_DEVICES=0,1,2,3
python biunilm/run_seq2seq.py --do_train --num_workers 0 \
  --bert_model bert-large-cased --new_segment_ids --tokenized_input \
  --data_dir &lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt; --src_file train.pa.tok.txt --tgt_file train.q.tok.txt \
  --output_dir &lt;span class="pl-smi"&gt;${OUTPUT_DIR}&lt;/span&gt;/bert_save \
  --log_dir &lt;span class="pl-smi"&gt;${OUTPUT_DIR}&lt;/span&gt;/bert_log \
  --model_recover_path &lt;span class="pl-smi"&gt;${MODEL_RECOVER_PATH}&lt;/span&gt; \
  --max_seq_length 512 --max_position_embeddings 512 \
  --mask_prob 0.7 --max_pred 48 \
  --train_batch_size 32 --gradient_accumulation_steps 2 \
  --learning_rate 0.00002 --warmup_proportion 0.1 --label_smoothing 0.1 \
  --num_train_epochs 10&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We provide a fine-tuned checkpoint (downloaded from &lt;a href="https://drive.google.com/open?id=1JN2wnkSRotwUnJ_Z-AbWwoPdP53Gcfsn" rel="nofollow"&gt;here&lt;/a&gt;) used for decoding. The inference and evaluation process is conducted as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;DATA_DIR=/{path_of_data}/qg/test
MODEL_RECOVER_PATH=/{path_of_fine-tuned_model}/qg_model.bin
EVAL_SPLIT=test
&lt;span class="pl-k"&gt;export&lt;/span&gt; PYTORCH_PRETRAINED_BERT_CACHE=/{tmp_folder}/bert-cased-pretrained-cache
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run decoding&lt;/span&gt;
python biunilm/decode_seq2seq.py --bert_model bert-large-cased --new_segment_ids --mode s2s \
  --input_file &lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt;/&lt;span class="pl-smi"&gt;$test&lt;/span&gt;.pa.tok.txt --split &lt;span class="pl-smi"&gt;${EVAL_SPLIT}&lt;/span&gt; --tokenized_input \
  --model_recover_path &lt;span class="pl-smi"&gt;${MODEL_RECOVER_PATH}&lt;/span&gt; \
  --max_seq_length 512 --max_tgt_length 48 \
  --batch_size 16 --beam_size 1 --length_penalty 0
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run evaluation using our tokenized data as reference&lt;/span&gt;
python qg/eval_on_unilm_tokenized_ref.py --out_file qg/output/qg.test.output.txt
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; run evaluation using tokenized data of Du et al. (2017) as reference&lt;/span&gt;
python qg/eval.py --out_file qg/output/qg.test.output.txt&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The files &lt;code&gt;qg/eval_on_unilm_tokenized_ref.py&lt;/code&gt; and &lt;code&gt;qg/eval.py&lt;/code&gt; are in Python 2.*, because they are dependent on the &lt;a href="https://github.com/xinyadu/nqg/tree/master/qgevalcap"&gt;evaluation scripts&lt;/a&gt; of &lt;a href="https://arxiv.org/pdf/1705.00106.pdf" rel="nofollow"&gt;Du et al., (2017)&lt;/a&gt;. The output files can be downloaded from &lt;a href="https://drive.google.com/open?id=1MdaRftgl_HMqN7DLvYmw-zKkvOBZCP6U" rel="nofollow"&gt;here&lt;/a&gt;. Notice that our model predictions are cased, while the gold outputs provided by Du et al., (2017) are uncased. So the predicted results need to be converted to lowercase before computing the evaluation metrics.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-faq" class="anchor" aria-hidden="true" href="#faq"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FAQ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Install ROUGE-1.5.5
&lt;ul&gt;
&lt;li&gt;If we would like to use the Perl script of ROUGE, it can be installed by following &lt;a href="https://gist.github.com/donglixp/d7eea02d57ba2e099746f8463c2f6597"&gt;instruction-1&lt;/a&gt; and &lt;a href="https://github.com/bheinzerling/pyrouge#installation"&gt;instruction-2&lt;/a&gt;. The ROUGE-1.5.5 package (written in Perl) can be downloaded from &lt;a href="https://github.com/andersjo/pyrouge/tree/master/tools/ROUGE-1.5.5"&gt;here&lt;/a&gt;. We can also use the Python-version evaluation script by removing the flag &lt;code&gt;--perl&lt;/code&gt; when running &lt;code&gt;eval.py&lt;/code&gt;. Notice that there would be slight number difference between them due to the implementation details.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you find UniLM useful in your work, you can cite the following paper:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@inproceedings{unilm,
    title={Unified Language Model Pre-training for Natural Language Understanding and Generation},
    author={Dong, Li and Yang, Nan and Wang, Wenhui and Wei, Furu and Liu, Xiaodong and Wang, Yu and Gao, Jianfeng and Zhou, Ming and Hon, Hsiao-Wuen},
    year={2019},
    booktitle = "33rd Conference on Neural Information Processing Systems (NeurIPS 2019)"
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-related-projectscodebase" class="anchor" aria-hidden="true" href="#related-projectscodebase"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Related Projects/Codebase&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Vision-Language Pre-training: &lt;a href="https://github.com/LuoweiZhou/VLP"&gt;https://github.com/LuoweiZhou/VLP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MT-DNN: &lt;a href="https://github.com/namisan/mt-dnn"&gt;https://github.com/namisan/mt-dnn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Response Generation Pre-training: &lt;a href="https://github.com/microsoft/DialoGPT"&gt;https://github.com/microsoft/DialoGPT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Our code is based on &lt;a href="https://github.com/huggingface/pytorch-transformers/tree/v0.4.0"&gt;pytorch-transformers v0.4.0&lt;/a&gt;. We thank the authors for their wonderful open-source efforts.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is licensed under the license found in the LICENSE file in the root directory of this source tree.
Portions of the source code are based on the &lt;a href="https://github.com/huggingface/pytorch-transformers/tree/v0.4.0"&gt;pytorch-transformers v0.4.0&lt;/a&gt; project.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://opensource.microsoft.com/codeofconduct" rel="nofollow"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contact-information" class="anchor" aria-hidden="true" href="#contact-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact Information&lt;/h3&gt;
&lt;p&gt;For help or issues using UniLM, please submit a GitHub issue.&lt;/p&gt;
&lt;p&gt;For personal communication related to UniLM, please contact Li Dong (&lt;code&gt;lidong1@microsoft.com&lt;/code&gt;), Furu Wei (&lt;code&gt;fuwei@microsoft.com&lt;/code&gt;).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>microsoft</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>elaine-zheng/summer2020internships #17 in Python, This week</title><link>https://github.com/elaine-zheng/summer2020internships</link><description>&lt;p&gt;&lt;i&gt;Keep track of internships for Summer 2020 for undergraduates interested in tech./SWE/related fields&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-summer-2020-internships" class="anchor" aria-hidden="true" href="#summer-2020-internships"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Summer 2020 Internships&lt;/h1&gt;
&lt;p&gt;Keep track of internships for Summer 2020 for undergraduates interested in tech, SWE, and related fields. Never too early to get started in your search! Thanks to &lt;a href="https://github.com/christine-hu/summer-2019-internships"&gt;christine-hu&lt;/a&gt; who made a similar document for the 2019 season for formatting inspiration. Utilize the Python Script to recieve an outputted Excel-Friendly version&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Sites used to find internships include LinkedIn, Indeed, Glassdoor, and AngelList (startups).
Summer 2019 Tech Internships!
Positions are geared towards Computer Science majors who may have intersectional interests such as Design, &amp;gt; Finance, Research, etc. All positions are open to anyone enrolled in a Bachelor's degree program.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To contribute:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Fork repository&lt;/li&gt;
&lt;li&gt;Edit README.md &lt;em&gt;(I used the &lt;a href="https://stackedit.io/app#" rel="nofollow"&gt;StackEdit Markdown Editor&lt;/a&gt;)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Open a pull request!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Locations may potentially span globally.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-the-list" class="anchor" aria-hidden="true" href="#the-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The List&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Location&lt;/th&gt;
&lt;th&gt;Application Period&lt;/th&gt;
&lt;th&gt;Notes&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://imc.wd5.myworkdayjobs.com/invitation/job/Chicago/Quant-Trader-Intern---Summer-2020_REQ-00550" rel="nofollow"&gt;IMC Trading&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Chicago&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Min. GPA 3.5, prefers Python programming skills&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.ebayinc.com/job/san-jose/software-engineer-intern/403/13338627" rel="nofollow"&gt;Ebay&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Jose, California&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Java, Python programming skills&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://sjobs.brassring.com/TGnewUI/Search/home/HomeWithPreLoad?PageType=JobDetails&amp;amp;partnerid=25779&amp;amp;siteid=5149&amp;amp;jobid=601713&amp;amp;jobLocation=Bellevue,%2BWashington#jobDetails=601713_5149" rel="nofollow"&gt;T-Mobile&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Bellevue, Washington&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.mathworks.com/company/jobs/opportunities/16121-edg-intern-ms-and-phd-computer-science-majors?job_type_id%5B%5D=1755&amp;amp;" rel="nofollow"&gt;MathWorks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;US-MA-Natick&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://us-redhat.icims.com/jobs/72990/software-engineering-internship---cloud-security-technologies/job?hub=7&amp;amp;mobile=false&amp;amp;width=1011&amp;amp;height=500&amp;amp;bga=true&amp;amp;needsRedirect=false&amp;amp;jan1offset=-420&amp;amp;jun1offset=-420" rel="nofollow"&gt;Red hat&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Golang, Python programming skills&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.citrix.com/job/CITRA0058R18394/Software-Engineer-Intern-Summer-2020" rel="nofollow"&gt;Citrix&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Ft Lauderdale, Florida&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Min. GPA 3.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.esri.com/en-us/about/careers/job-detail?jobID=11338&amp;amp;mode=job&amp;amp;iis=Job%2BBoard&amp;amp;iisn=LinkedIn" rel="nofollow"&gt;Esri&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Multiple Locations&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;C++, C#, Python, Java, JavaScript, TypeScript, HTML5, iOS, Android or Windows mobile technology skills&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.smartrecruiters.com/Visa/743999694381436-intern-sr-software-engineer-masters-degree-multiple-locations?trid=623f64f4-c657-499b-989f-16ab0ccee0d9" rel="nofollow"&gt;Visa&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Multiple locations&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Min. GPA 3.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://akunacapital.com/careers#careers" rel="nofollow"&gt;Akuna&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Chicago&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Juniors+, several different roles&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.fidelity.com/ShowJob/Id/580980/Summer-2020-Technical-Internship-Program/" rel="nofollow"&gt;Fidelity Investments&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;US-NC-Durham, US-NH-Merrimack, US-MA-Boston, US-RI-Smithfield&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.jpmorgan.com/us/en/students/programs/software-engineer-summer#careers-section7" rel="nofollow"&gt;JP Morgan Chase&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Asia: Singapore, Europe, Middle East, US: IL, OH, TX, NY, DE, TX, CA, WA, FL&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Juniors+, All JP Morgan Chase positions open including IB/Quant/Data Analytics&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.americanexpress.com/jobs?keywords=Internship" rel="nofollow"&gt;American Express&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Multiple Cities&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Sophomores+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://angel.co/company/groceristar/jobs" rel="nofollow"&gt;Groceristar&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Remote/Work From Home&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.businessinsider.com/unpaid-internships-bad-for-students-bad-for-workers-bad-for-society-2012-5" rel="nofollow"&gt;UNPAID:&lt;/a&gt; Many positions available: Engineers, Q&amp;amp;A, Project manager, Personal Assistant, Growth Hacker. Seems to have strong mentorship and learning experience&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://goldmansachs.tal.net/vx/lang-en-GB/mobile-0/brand-2/user-1414453/candidate/so/pm/1/pl/1/opp/2-Summer-Analyst-Summer-Associate-Internship-programs/en-GB" rel="nofollow"&gt;Goldman Sachs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Several: Americas&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;For technology roles: Select Engineering-&amp;gt;General&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.microsoft.com/us/en/" rel="nofollow"&gt;Microsoft&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Global&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.apple.com/en-us/search?location=united-states-USA&amp;amp;team=Internships-STDNT-INTRN" rel="nofollow"&gt;Apple&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Santa Clara Valley (Cupertino), California (Mainly)&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;SWE, Hardware, UI/UX, Sales, ML&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers-sas.icims.com/jobs/18311/2020-autism-spectrum-summer-internship-program-%28expression-of-interest%29/job?hub=9&amp;amp;mode=job&amp;amp;iis=SocialMedia&amp;amp;iisn=LinkedIn&amp;amp;mobile=false&amp;amp;width=1137&amp;amp;height=500&amp;amp;bga=true&amp;amp;needsRedirect=false&amp;amp;jan1offset=-300&amp;amp;jun1offset=-240" rel="nofollow"&gt;SAS&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Santa Clara Valley (Cupertino), California (Mainly)&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Pipeline for students with Autism&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://belvederetrading.applicantstack.com/x/detail/a2sa4x08859m" rel="nofollow"&gt;Belvedere Trading&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Chicago&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Juniors+; No sponsorship&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://utc-disability.jobs/cedar-rapids-ia/software-engineering-intern-summer-2020/C20735DD166648E4991FC2872EF732CB/job" rel="nofollow"&gt;Collins Aerospace&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Cedar Rapids, IA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Must be capable of obtaining a U.S. Department of Defense (DoD) Security Clearance, US Citizenship is required&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://fortive.taleo.net/careersection/external/jobdetail.ftl?job=MAT001868&amp;amp;src=%5Bu%27JB-10138%27%2C+u%27JB-10138%27%5D" rel="nofollow"&gt;Matco Tools&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Stow, OH&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Juniors+, prefers Java programming skills&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://breakthroughfuel.applytojob.com/apply/3a3PNGue1o/Summer-2020-Intern" rel="nofollow"&gt;Breakthrough&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Green Bay, WI&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Min. GPA 3.0, Cover letter required&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/rimeto/d357c4b5-5a3e-4c75-84fd-057d2051cd92" rel="nofollow"&gt;Rimeto&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.facebook.com/careers/jobs/?roles%5B0%5D=intern" rel="nofollow"&gt;Facebook&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Several: Menlo Park, New York, Boston, Seattle, etc.&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;FrontEnd, SWE, AI, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.vanguardjobs.com/job-search-results/?keyword=124896%20OR%20124907%20OR%20124884%20OR%20124925" rel="nofollow"&gt;The Vanguard Group&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Malvern, PA and Charlotte, NC&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;3.0 GPA Preferred, Software Development, Technology Operations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.leidos.com/search/intern/jobs" rel="nofollow"&gt;Leidos&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;McLean, VA and Morgantown, WV&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobszp1.lanl.gov/OA_HTML/OA.jsp?page=/oracle/apps/irc/candidateSelfService/webui/VisVacDispPG&amp;amp;OAHP=IRC_EXT_SITE_VISITOR_APPL&amp;amp;OASF=IRC_VIS_VAC_DISPLAY&amp;amp;akRegionApplicationId=821&amp;amp;transactionid=1590195690&amp;amp;retainAM=N&amp;amp;addBreadCrumb=RP&amp;amp;p_svid=73935&amp;amp;p_spid=3367360&amp;amp;oapc=5&amp;amp;oas=fVtHbWr4rfa7MThh6_ybbw.." rel="nofollow"&gt;Los Alamos National Lab&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Los Alamos, NM&lt;/td&gt;
&lt;td&gt;due September 30&lt;/td&gt;
&lt;td&gt;Min. GPA 3.0 Coverletter Required&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/duolingo/jobs/4351727002" rel="nofollow"&gt;Duolingo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Pittsburgh, PA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Juniors+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/robinhood/jobs/1739582" rel="nofollow"&gt;Robinhood&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Menlo Park, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://morganstanley.tal.net/vx/lang-en-us/mobile-0/brand-2/xf-88b1eb77da85/candidate/so/pm/1/pl/1/opp/8319/apply/en-us" rel="nofollow"&gt;Morgan Stanley&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Min. GPA 3.0, prefers C, C++, Java or C# programming skills&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://hire.withgoogle.com/public/jobs/houstonmechatronicscom/view/P_AAAAAAFAACPOqH3qYYp_8y" rel="nofollow"&gt;Houston Mechatronics&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Webster, TX&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;US Citizenship is required; Prefers robotics experience, Linux command line, and Python programming language&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.optiver.com/na/en/job-opportunities/us-4315469002" rel="nofollow"&gt;Optiver&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Chicago&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Prefers C, C++, Java or C# programming skills; No sponsorship&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/virtu/jobs/4367942002" rel="nofollow"&gt;Virtu Financial&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Prefers C++ or Java programming skills&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.citadel.com/careers/open-positions/positions-for-students/" rel="nofollow"&gt;Citadel&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Several:  Dublin, London, Chicago, Hong Kong, London, New York, Austin&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;SWE, Quant, IT, DevOps&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.redventures.com/application/position/1755893?gh_jid=1755893&amp;amp;gh_src=cec562fc1&amp;amp;gh_jid=1755893&amp;amp;gh_src=cec562fc1" rel="nofollow"&gt;Red Ventures&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Austin, TX&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Juniors, Prefers experience with top web languages&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://frontapp.com/jobs" rel="nofollow"&gt;Front&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, Paris&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Juniors+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.vailsys.com/about/careers/" rel="nofollow"&gt;Vail&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Chicago&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;SWE, DevOps&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.stationf.co/companies/vyte" rel="nofollow"&gt;Vyte&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Paris, France&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Positions available for both Frontend and Backend Internships in Paris&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.fastenterprises.com/careers/positions/" rel="nofollow"&gt;Fast Enterprises&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;USA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Must be pursuing degree&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://phone2action.com/civic-tech-fellows-program/" rel="nofollow"&gt;Phone2Action&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Arlington, VA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;All levels accepted - including high school. Well paid fellowships available in Product, Engineering, Sales, Marketing, Customer Success, and Operations. Interested in applying? Send your resume and a letter of interest to Jennifer Leo at &lt;a href="mailto:jleo@phone2action.com"&gt;jleo@phone2action.com&lt;/a&gt; ... and see our &lt;a href="https://phone2action.com/jobs" rel="nofollow"&gt;jobs site for FT positions&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.ibm.com/ListJobs/All/Search/Position-Type/Intern/?lang=en" rel="nofollow"&gt;IBM&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Multiple Countries&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://salesforce.wd1.myworkdayjobs.com/en-US/External_Career_Site/job/California---San-Francisco/Summer-2020-Intern---Software-Engineer_JR45627-1" rel="nofollow"&gt;Salesforce&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;10+ Locations Across the US&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.dropbox.com/jobs/listing/1810089/apply?gh_src=aonhf1" rel="nofollow"&gt;Dropbox&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, Seattle, New York&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/qualtrics/jobs/755570?t=edd9906d1" rel="nofollow"&gt;Qualtrics&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Provo, Seattle&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/databricks/jobs/4374189002?gh_src=62a881d62" rel="nofollow"&gt;Databricks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;2020, 2021 graduate working on a BS/MS or PhD degree in Computer Science, Engineering, or a related subject&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/twitch/jobs/4387419002" rel="nofollow"&gt;Twitch&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;BA/BS Graduation Year: 2021 (No Masters/PhD)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.amazon.jobs/en/jobs/908695/software-development-engineer-internship-summer-2020-us" rel="nofollow"&gt;Amazon&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Austin, Bay Area, Bellevue, Boston, Denver, Detroit, Herndon, Irvine, New York, Madison, Minneapolis, Phoenix, Portland, San Diego, also Vancouver, Toronto and Winnipeg (Canada has seperate application)&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.twosigma.com/careers/JobDetail/New-York-New-York-United-States-Software-Engineering-Internship-NYC/5982" rel="nofollow"&gt;Two Sigma&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/flexport/jobs/1802354" rel="nofollow"&gt;Flexport&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, Chicago&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.qualcomm.com/public/jobDetails.xhtml?requisitionId=1975484" rel="nofollow"&gt;Qualcomm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Diego, Boulder, Austin, San Jose, Santa Clara&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;In study towards Bachelors (3.0 GPA or above), or Masters (3.5 GPA or above), in Computer Science, Electrical Engineering, or Computer Engineering. Must be available for 3 months during Summer 2020 (May-September)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/atlassian/9484630b-4039-415e-af9a-c1e2c34e5a8b" rel="nofollow"&gt;Atlassian&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Mountain View, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Must be currently enrolled in a full-time degree program and returning to the program after the completion of the internship, graduating by June 2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://campus.capitalone.com/job/mclean/technology-internship-program-summer-2020/1786/12562814" rel="nofollow"&gt;Capital One&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;McLean, Virginia; Boston, Massachusetts; New York, New York; San Francisco, California; Chicago, Illinois; Wilmington, Delaware; Richmond, Virginia; Plano, Texas&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Bachelor’s degree or higher obtained between December 2020 and August 2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.smartrecruiters.com/ni/Twitter2/c9c8d155-aab8-43cb-a530-629689467768-2020-university-application-full-time-internship" rel="nofollow"&gt;Twitter&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/figma/91da97b9-ff1d-4e08-a2f1-4867537e5eb2" rel="nofollow"&gt;Figma&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.cisco.com/jobs/ProjectDetail/Software-Engineer-Bachelor-s-Intern-United-States/1265291" rel="nofollow"&gt;Cisco&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Jose, Seattle, San Francisco, Richardson, Austin, Cambridge, Richfield, Knoxville, Lawrenceville, Alpharetta, Fulton&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/wish/a7c634f6-40d6-43cd-828a-dc0bfc8b33a8" rel="nofollow"&gt;Wish&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/samsara/jobs/1818392" rel="nofollow"&gt;Samsara&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, Atlanta&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;San Francisco and Atlanta have seperate job applications to fill out&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://recruiting.ultipro.com/KON1000/JobBoard/c70fc266-51c5-5296-2005-ff4f122ccc1c//OpportunityDetail?opportunityId=da62060d-b31c-4a36-94c6-b20b3ae4d6cd" rel="nofollow"&gt;Konami&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Las Vegas&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Must be local candidate, no relocation availible&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.jobvite.com/splunk/job/o21NafwK" rel="nofollow"&gt;Splunk&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Jose, San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://stripe.com/jobs/listing/software-engineering-intern/1793449" rel="nofollow"&gt;Stripe&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco or Seattle&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Plan to graduate in 2021 or 2022&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/palantir/d39b3432-8742-4df0-b97f-47ab4122cd05/apply" rel="nofollow"&gt;Palantir&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.jobvite.com/fiverings/jobs" rel="nofollow"&gt;Five Rings Capital&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;SWE, Quant&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://buildyourfuture.withgoogle.com/internships/" rel="nofollow"&gt;Google&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Various locations across the world&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;STEP, BOLD, Software Engineering, IT&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers-alliancebernstein.icims.com/jobs/6602/software-development-internship---technology-%26-operations-program/job" rel="nofollow"&gt;AllianceBernstein&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Nashville, TN&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Juniors&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.janestreet.com/join-jane-street/internships/" rel="nofollow"&gt;Jane Street&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, London, Hong Kong&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Trading Interns, Business Development Interns, Engineering Interns, Research Interns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.toasttab.com/?url=job&amp;amp;gh_jid=1876789" rel="nofollow"&gt;Toast&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Dublin, Boston&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/thumbtack/jobs/1814883" rel="nofollow"&gt;Thumbtack&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Graduating in 2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/gusto/jobs/1823034" rel="nofollow"&gt;Gusto&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, Denver&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Denver has a seperate application.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.yelp.com/careers/job-openings?keywords=Summer&amp;amp;team=all&amp;amp;location=all" rel="nofollow"&gt;Yelp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://hire.withgoogle.com/public/jobs/rocksetio/view/P_AAAAAADAAADMHn16UbFdig" rel="nofollow"&gt;Rockset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Mateo&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://hire.withgoogle.com/public/jobs/maticiancom" rel="nofollow"&gt;Matician&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Palo Alto&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.getknowt.com/team/#apply" rel="nofollow"&gt;Knowt&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Remote&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Low compensation work at an early stage startup&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobsearch.paypal-corp.com/en-US/search?facetcategory=internship&amp;amp;orderby=-date" rel="nofollow"&gt;PayPal&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Austin, TX; Timonium, MD; San Francisco, CA; San Jose, CA; Scottsdale, AZ; Conshohocken, PA; New York, NY;&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.appian.com/careers/search/job/?gh_jid=1770583" rel="nofollow"&gt;Appian&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Tysons, Virginia&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Undergraduate student pursuing B.S. in Computer Science, CoGrmputer Engineering or similar, with 3.7 GPA &amp;amp; above.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://hire.withgoogle.com/public/jobs/appliedintuitioncom/view/P_AAAAAADAAAOIEfFoeqoZTq" rel="nofollow"&gt;Applied Intuition&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Sunnyvale, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.wolve.com/careers" rel="nofollow"&gt;Wolverine Trading&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Chicago, IL&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Juniors+, sponsorship is not available, multiple positions: SWE, Data, and Quant&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/quorum/jobs/599939?gh_jid=%5Bu%27599939%27%5D" rel="nofollow"&gt;Quorum&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Washington, DC&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.homedepot.com/job-search-results/?keyword=Software%20Engineer%20Intern&amp;amp;parent_category=Corporate%2FOther" rel="nofollow"&gt;The Home Depot&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Atlanta, Austin, Dallas&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Must be legally permitted to work in the United States&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/sonyinteractiveentertainmentplaystation/jobs/1833253" rel="nofollow"&gt;Sony Interactive Entertainment PlayStation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Seniors, must be proficiency with C#, JavaScript and experience with C++, Python&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.quantcast.com/careers/openings/#department%3D__team%3D__location%3D__commitment%3DIntern" rel="nofollow"&gt;Quantcast&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, Seattle&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Graduation date between Dec 2020 and June 2021, prefers experience with Java, C++, or Python&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://osisoft.wd1.myworkdayjobs.com/en-US/osisoft_careers/job/San-Leandro-California-USA/Software-Developer-Intern---Summer-2020_R002107-1" rel="nofollow"&gt;OSIsoft&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Johnson City, Philadelphia, San Leandro, Scottsdale&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Min. GPA 3.25, prefers experience with C, C++, C#, Java, JavaScript, or Python&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.vistaequitypartners.com/our-firm/careers/?jobid=506363&amp;amp;location=1083" rel="nofollow"&gt;Cvent&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Atlanta, GA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Rising senior, Min. GPA 3.0,&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/postmates/jobs/1134685" rel="nofollow"&gt;Postmates&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nuro.ai/careersitem?gh_jid=1785972" rel="nofollow"&gt;Nuro&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Mountain View&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;You have experience in one or more of the following areas: backend API design, applications development, large-scale distributed systems; data storage and processing systems; advanced algorithms using C++ and Python; machine learning, multithreading; x86 architecture; and software performance tuning and optimization, robotics software frameworks, different compute modalities (CPU, GPU, FPGA) etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.taboola.com/job/1786167?gh_jid=1786167&amp;amp;gh_src=u6pd1t&amp;amp;t=1566291622" rel="nofollow"&gt;Taboola&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Los Angeles&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/jingchicorp/jobs/1448478?gh_src=c6dae5a61" rel="nofollow"&gt;WeRide.ai&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Jose, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;BS/MS/PhD degree in Robotics, Computer Science or equivalent practical experience. Experience in data structures and advanced algorithms. Experience programming in C++. Graduating in Dec 2019 or May 2020&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.jumptrading.com/apply.html?gh_jid=1550728" rel="nofollow"&gt;Jump Trading&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Chicago&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://hire.withgoogle.com/public/jobs/platform9com/view/P_AAAAAADAAF5OEdk-bHtkWY" rel="nofollow"&gt;Platform9&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Sunnyvale, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Coursework in one or more areas: operating systems, distributed systems, networks, security or user interface design, Knowledge of Linux/Unix Systems, Programming proficiency in any one language: python, javascript, C/C++, java, golang, GPA 3.5 and above&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/selfmade/bca70f35-f732-4ecb-981e-b847fc9b5809" rel="nofollow"&gt;SelfMade&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.nerdwallet.com/careers/job/1799768" rel="nofollow"&gt;NerdWallet&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/lyft/jobs/4358047002" rel="nofollow"&gt;Lyft&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, Seattle, New York&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.valkyrietrading.com/careers/software-engineer-intern/" rel="nofollow"&gt;Valkyrie&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Chicago, IL&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Expected graduation prior to June 2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://cbre.referrals.selectminds.com/jobs/software-engineer-intern-59481" rel="nofollow"&gt;CBRE Build&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Dallas, TX; New York, NY; Boston, MA; Seattle, WA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Minimum 3.0 undergraduate GPA and knowledge of one or more general purpose programming languages: JavaScript, Python, Java, C, C# is required (Each city has a seperate application)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/sumologic/" rel="nofollow"&gt;Sumo Logic&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Redwood City, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Analytics, Frontend, Backend. Requirements: Entering junior year of B.S or graduating in fall 2020 or spring 2021 and previous internship or full-time experience as a Software Engineer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/memsql/jobs/1666552" rel="nofollow"&gt;MemSQL&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA; Seattle, WA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.bloomberg.com/job/detail/76852" rel="nofollow"&gt;Bloomberg&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Have programming experience in C, C++, Java or Python, Have a minimum GPA of 3.0, Be working toward a BA, BS, MS or PhD in Computer Science&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/embed/job_app?token=1808516" rel="nofollow"&gt;Yext&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.jobvite.com/paloaltonetworks/job/ocL89fwY" rel="nofollow"&gt;Palo Alto Networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Santa Clara, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;To apply, you must be pursuing a 4-year Undergraduate Degree with a GPA of 3.0 or above, a 2-year Master’s Degree or a Doctorate degree and returning to school in the fall. You must have the authorization to work within the United States.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/limebike/abbcff74-b22f-4a84-84d6-1bc3919eabb1" rel="nofollow"&gt;Lime&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.golucid.co/careers/c689ce29-c74a-48d5-854f-f9dbc82a350e/?team=Internships" rel="nofollow"&gt;Lucid Software&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Salt Lake City, UT&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Must be pursuing technical degree.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/coursera/6dc86ebb-ac85-4e63-ab61-25aaee9ec45d" rel="nofollow"&gt;Coursera&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Mountain View&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;We are looking for rising juniors and seniors for our summer internship programs. The programs are highly competitive, so apply as soon as you know you are available.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://asana.com/jobs/university-recruiting#jobs-listings" rel="nofollow"&gt;Asana&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, New York&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://cadre.com/careers/apply" rel="nofollow"&gt;Cadre&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Graduating in December 2020 or May 2021 with a Bachelor’s degree in Computer Science, Computer Engineering, or a related field&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.twilio.com/company/jobs?department=students#open-positions" rel="nofollow"&gt;Twilio&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, Denver, Irvine, Redwood City&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://redfin.wd1.myworkdayjobs.com/redfin_careers/job/WA---Seattle/Software-Developer-Intern---Summer-2020----Seattle--WA---San-Francisco--CA---Frisco--TX_23752" rel="nofollow"&gt;Redfin&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, Seattle&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/affirm/5340f1d3-cd6d-44ef-a5c6-f9def8609d02" rel="nofollow"&gt;Affirm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.viasat.com/careers/FolderDetail/Software-Engineer-Intern/3446" rel="nofollow"&gt;Viasat&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Carlsbad, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/quorum/jobs/599939?gh_jid=599939" rel="nofollow"&gt;Quorum&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Washington, DC&lt;/td&gt;
&lt;td&gt;Recruitment on a rolling basis until the position is filled&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.willowtreeapps.com/careers/jobs/4381004002/software-engineer-intern" rel="nofollow"&gt;WillowTree&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Charlottesville, VA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Graduating in 2021 or 2022&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nvidia.wd5.myworkdayjobs.com/en-US/UniversityJobs" rel="nofollow"&gt;Nvidia&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Various in US, Canada, China&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.confluent.io/careers" rel="nofollow"&gt;Confluent&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Palo Alto, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Frontend and Backend have seperate applications&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.benchling.com/careers/?gh_jid=1843932#detail" rel="nofollow"&gt;Benchling&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://garmin.taleo.net/careersection/garmin+career+section/jobsearch.ftl" rel="nofollow"&gt;Garmin&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Various in US&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Seperate application for each location, part-time internships availible&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/ctrl-labs/9218edb0-e31a-452c-8949-66d59e40423c" rel="nofollow"&gt;CTRL-Lab&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.bookbub.com/positions?gh_jid=1809830" rel="nofollow"&gt;BookBub&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Cambridge, MA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://stantec.jobs/burlington-ma/computer-science-engineering-intern/C8AE9D32CDAE4CC3A474DC47B041DCBF/job/" rel="nofollow"&gt;Stantec&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Burlington, MA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/betterment/jobs/1836744?gh_jid=1836744" rel="nofollow"&gt;Betterment&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;An undergraduate degree in Computer Science or a related field (graduating Spring/Summer 2020)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://tableau.wd1.myworkdayjobs.com/en-US/External/job/Seattle-WA/Software-Engineer-Intern_R0000234?source=LinkedIn" rel="nofollow"&gt;Tableau&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Seattle, WA; Cambridge, MA; Palo Alto, CA; Austin, TX&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://plaid.com/careers/openings/?department=Engineering&amp;amp;location=All%20locations" rel="nofollow"&gt;Plaid&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA; Salt Lake City, UT&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/embed/job_app?token=4417366002&amp;amp;gh_src=uwvxb4jc2" rel="nofollow"&gt;Lyft Level 5&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Palo Alto, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.riotgames.com/en/work-with-us/job/1839619?gh_src=vs7ga51" rel="nofollow"&gt;Riot Games&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;SF Bay Area&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Familiarity with an object-oriented programming (OOP) language i.e. Java, C++&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.pinterest.com/careers/university-0" rel="nofollow"&gt;Pinterest&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, Seattle&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Pinterest Labs Intern, Data Science and SWE availible&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://blackrock.tal.net/vx/candidate/jobboard/vacancy/1/adv" rel="nofollow"&gt;Blackrock&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Asia, Americas, EMEA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Summer Analyst and Placement, Juniors Only&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://mastercard.wd1.myworkdayjobs.com/Campus/0/refreshFacet/318c8bb6f553100021d223d9780d30be" rel="nofollow"&gt;Mastercard&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Arlington, VA; Singapore&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.crowdstrike.com/careers/job-listings/" rel="nofollow"&gt;Crowdstrike&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;El Segundo, California; Irvine, California&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://aurora.tech/jobs/?gh_jid=4237844002" rel="nofollow"&gt;Aurora&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Pittsburgh, PA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;MS or PhD in Robotics, Computer Science, EE, MechE, or related field highly preferred&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.hudson-trading.com/careers/" rel="nofollow"&gt;Hudson River Trading&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, Chicago&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.airbnb.com/positions/1815030/" rel="nofollow"&gt;Airbnb&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA and Seattle, WA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Prefers experience with Java, Scala, Ruby and/or Ruby on Rails, C++, SQL, or HTML/CSS and Javascript&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://flatiron.com/careers/open-positions/1805778" rel="nofollow"&gt;Flatiron&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York City, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Juniors+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/kivaorg/jobs/1845233" rel="nofollow"&gt;Kiva&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA and Portland, OR&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Freshmen and Sophomores ONLY&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/sigopt/141cec90-5ff0-46dc-8e99-02760d3e0f2d" rel="nofollow"&gt;SigOpt&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Prefers engineering internship or professional experience and strong programming ability it at least one language&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.datto.com/careers/job-board/post/1604239" rel="nofollow"&gt;datto&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Boston, Norwalk, Rochester&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Prefers PHP experience with object-oriented programming skills and MySQL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/karat/jobs/4252508002" rel="nofollow"&gt;Karat&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Seattle, WA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Prefers dynamic programming language in web development and web apps&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.scm-lp.com/internships" rel="nofollow"&gt;Stevens Capital Management&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Radnor, PA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/petalcard/907525c3-7bd3-40d4-98a9-636304415e4f/apply" rel="nofollow"&gt;Petal&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs-intersystems.icims.com/jobs/5277/intersystems-summer-internship-2020/job" rel="nofollow"&gt;InterSystems&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Cambridge, Boston&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.okta.com/company/careers/" rel="nofollow"&gt;Okta&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA Bellevue, WA San Jose, CA, Toronto, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Ability to program in at least one OO programming language (e.g. Java, JavaScript C#, C++)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://blackstone.wd1.myworkdayjobs.com/en-US/Blackstone_Campus_Careers/job/New-York/Innovations---Software-Developer---2020-Summer-Analyst_9144" rel="nofollow"&gt;Blackstone&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Anticipated graduation date: Fall 2020 – Spring 2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.tripadvisor.com/c/campus-jobs" rel="nofollow"&gt;TripAdvisor&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;El Segundo, CA; Needham, MA; Ottawa, ON&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Graduating in 2020, 2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/etsy/44a07d1f-d198-4a2a-9c28-64d0ad7db531/apply" rel="nofollow"&gt;Etsy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://hire.withgoogle.com/public/jobs/enfusionsystemscom/view/P_AAAAAACAAKFDmOJkch85P4" rel="nofollow"&gt;Enfusion&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Chicago, IL&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Minimum 6 months experience in JAVA is required&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/c3iot/jobs/4086849002" rel="nofollow"&gt;C3.ai&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Redwood, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Prefers experience with JavaScript, Java, or other object-oriented programming language.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/pocketgems/jobs/1849185?gh_src=%5Bu%270c25bb191%27%5D" rel="nofollow"&gt;Pocket Gems&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Looking for students going to U.S. universities, graduating in Winter 2020 or Spring 2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.cmegroup.com/jobs/4575089-software-engineering-internship-summer-2020" rel="nofollow"&gt;CME Group&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Chicago, IL&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Prefers experience with Java, Python, or C++&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers-hyland.icims.com/jobs/5425/software-development-internship-(summer-2020)/job" rel="nofollow"&gt;Hyland&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Westlake, OH&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Prefers experience with object oriented programming languages and Microsoft Office software products&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.jobvite.com/servicenow/job/oPtSafw4" rel="nofollow"&gt;ServiceNow&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Santa Clara, CA; San Diego, CA; Kirkland, WA; Chicago, IL; San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Prefers experience with C++, Java, Perl, PHP, or Python; Ability to obtain and maintain work authorization in the country of employment in 2018&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://jobs.jobvite.com/newrelic/job/oJHXafwh" rel="nofollow"&gt;New Relic&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Phoenix, AZ; San Francisco, CA; Portland, OR&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Visa sponsorship is not available; Prefers experience with Java, C#, Ruby, Python, or Go as well as Javascript and frameworks&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.tripadvisor.com/c/campus-jobs" rel="nofollow"&gt;TripAdvisor&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;El Segundo, CA; Needham, MA; Ottawa, ON&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Graduating in 2020, 2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.mongodb.com/careers/jobs/1855372?gh_src=0wcvpq1" rel="nofollow"&gt;MongoDB&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://keeptruckin.com/careers" rel="nofollow"&gt;KeepTruckin&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.rubrik.com/company/careers/university-talent/jobs/software-engineering-internship-783507/" rel="nofollow"&gt;Rubrik&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Palo Alto, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/purestorage/jobs/1852570" rel="nofollow"&gt;Pure Storage&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Mountain View, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers-grammatech.icims.com/jobs/1128/software-engineer-intern-%28research%29---summer-2020/job" rel="nofollow"&gt;GrammaTech&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Ithaca, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Currently enrolled in a BS&amp;lt; MS, or PhD in Computer Science, Excellent programming skills (C++, C, Python) in Linux or Windows environments. Visa sponsorship not available.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/huobi/c454e383-9302-4bec-88c0-7a9f749cb5f9" rel="nofollow"&gt;Huobi&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Sunnyvale, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.joinhoney.com/careers/internships" rel="nofollow"&gt;Honey&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Los Angeles, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.linkedin.com/students/Internships/Technical" rel="nofollow"&gt;LinkedIn&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.hioscar.com/careers/1845429" rel="nofollow"&gt;Oscar&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.uber.com/global/en/careers/list/54737/" rel="nofollow"&gt;Uber&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Seattle, Washington; Boulder, Colorado; Palo Alto, California; San Francisco, California&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/cambly/21350d5c-8ef0-4284-8348-8d3218d24ecd" rel="nofollow"&gt;Cambly&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Currently enrolled in a Computer Science degree program with at least 3 years of study completed.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/cogolabs" rel="nofollow"&gt;Cogo Labs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Cambridge, MA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;You are a smart, collaborative Junior (2021 grad).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://expedia.wd5.myworkdayjobs.com/search/job/Washington---Seattle-HQ/Internship---Multiple-Locations---Software-Development_R-46462" rel="nofollow"&gt;Expedia&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Seattle, Quebec, Chicago, Austin, Denver, San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Currently enrolled in a 4-year university graduating December 2020 or Spring 2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.getcruise.com/careers/university" rel="nofollow"&gt;Cruise&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/about/careers#internships"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;You must be returning to school the Fall after your internship (Fall 2020). Your internship will be 10 weeks from June 8th, 2020 to August 14th, 2020. We will accommodate quarter system intern starts.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://corp.roblox.com/careers/listing/?gh_jid=1860562" rel="nofollow"&gt;Roblox&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Mateo, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.mozilla.org/listings/?position_type=Internteam=Engineering" rel="nofollow"&gt;Mozilla&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Berlin, Mountain View, San Francisco, Toronto&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Must be graduating December 2020 and onward&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.tesla.com/careers/search#/?keyword=Intern&amp;amp;department=1" rel="nofollow"&gt;Tesla&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Multiple Cities&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/2020kpfellows" rel="nofollow"&gt;Kleiner Perkins Fellows Program&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Bay Area, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Product: Graduating in Fall 2019 or Spring 2020 / Engineering: Graduating after Spring 2020 / Design: Graduating by Spring 2020&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/vimeo/jobs/1851794" rel="nofollow"&gt;Vimeo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;You are currently pursuing a BS or MS in Computer Science, Engineering, or a related technical discipline, with an expected graduation date of 2020 or 2021.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://slack.com/careers/university-recruiting#openings" rel="nofollow"&gt;Slack&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://careers.zillowgroup.com/ShowJob/Id/355556/Software%20Development%20Engineer%20%20%20Intern" rel="nofollow"&gt;Zillow&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Seattle, San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/lob/jobs/1862312" rel="nofollow"&gt;Lob&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Completion of your junior year of BS/BA (or first year of MS) in Computer Science or a related field by the start of Summer 2020 OR the completion of a coding bootcamp.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://tripactions.com/job-openings" rel="nofollow"&gt;TripActions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Palo Alto, CA; San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;BS or MS in Computer Science or Computer Engineering Graduation Year: 2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.box.com/job/1862637/Software-Engineering-Intern-Summer-2020" rel="nofollow"&gt;Box&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Redwood City, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Graduating between December 2020-June 2021 with a BA/BS, majoring in Computer Science or a related field.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/kensho/2c82a1f0-3f96-47e1-a785-cfd2acdbed7a" rel="nofollow"&gt;Kensho&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Cambridge, MA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/ironcladapp/7dc69333-8b40-40d9-b1c1-b8165471d88c" rel="nofollow"&gt;Ironclad&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/convoy/63403442-d175-4f25-9521-d8ee4121433b" rel="nofollow"&gt;Convoy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Seattle, WA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Currently working toward a degree in Computer Science, with a graduation date in 2021.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/fivestars/jobs/1874507" rel="nofollow"&gt;Fivestars&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/transfix/c9c05b4f-18f7-4ba3-9361-bacd89192589" rel="nofollow"&gt;Transfix&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Must be a Sophomore or a Junior Competency in algorithms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/embed/job_app?token=1870995" rel="nofollow"&gt;Checkr&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://wpengine.careers/internships/" rel="nofollow"&gt;WPEngine&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Austin, TX&lt;/td&gt;
&lt;td&gt;Present (Fall and Spring period)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.jobvite.com/sugarcrm/job/oDOUafwf" rel="nofollow"&gt;SugarCRM&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/embed/job_app?token=1870995" rel="nofollow"&gt;Checkr&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.mark43.com/list-jobs/1335587/?gh_jid=1335587" rel="nofollow"&gt;Mark43&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.hulu.com/jobs/positions/ozhuafw4" rel="nofollow"&gt;Hulu&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Santa Monica, CA, Seattle, WA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.datadoghq.com/careers/detail/?gh_jid=1839157" rel="nofollow"&gt;Datadog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Boston, MA, New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.gotinder.com/jobs/apply?gh_jid=1866819" rel="nofollow"&gt;Tinder&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Los Angeles, San Francisco, Palo Alto, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/braze/jobs/840086?gh_jid=840086" rel="nofollow"&gt;Braze&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.blackboard.com/careers/position/software-engineer-intern-indianapolis-in-usa-8" rel="nofollow"&gt;Blackboard&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Indianapolis, IN&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/embed/job_app?token=1870995" rel="nofollow"&gt;Checkr&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.tech.la/" rel="nofollow"&gt;Tech.LA Fellowship&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Rolling applications&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.8vcfellowship.com/" rel="nofollow"&gt;8VC Fellowship&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.bvp.com/bessemer-fellows" rel="nofollow"&gt;Bessemer Fellowship&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Due January 31&lt;/td&gt;
&lt;td&gt;Applications are accepted for third year undergraduate students.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.teamworthy.com/teamworthy-fellowship" rel="nofollow"&gt;The Teamworthy Fellowship&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, Austin, Boston, Chicago, DC, Denver, Los Angeles, New York City, Salt Lake City, San Francisco, and Saskatoon (Canada)&lt;/td&gt;
&lt;td&gt;We accept applications on a rolling basis until May 1, 2020.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.hackerfellows.com/" rel="nofollow"&gt;Hacker Fellows&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Ann Arbor, Michigan&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.joinhandshake.com/join-us/" rel="nofollow"&gt;Handshake&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Denver, CO; San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://poshmark.com/careers" rel="nofollow"&gt;Poshmark&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Redwood City, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.deshaw.com/careers/3840" rel="nofollow"&gt;D.E. Shaw&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/embed/job_app?token=1886472" rel="nofollow"&gt;Chan Zuckerberg Initiative&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Redwood City, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/strava/jobs/1892381" rel="nofollow"&gt;Strava&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Rising Senior (2021 grad) or new grad (2020), requires cover letter&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/reddit/jobs/1861780" rel="nofollow"&gt;Reddit&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;A rising senior actively working towards a Bachelor’s degree in CS or a related field; Graduating between December 2020 and Summer 2021; Able to program your way out of a paper bag; Requires Cover Letter&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/cora" rel="nofollow"&gt;Cora&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Mountain View, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://hosted-washpost.submissionplatform.com/sub/hosted/56427121208965c923528efd" rel="nofollow"&gt;The Washington Post&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Washington D.C.&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/neeva/93e622dc-0cd6-4bfe-91f0-f67aedb97e53" rel="nofollow"&gt;Neeva&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Mountain View, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.spotifyjobs.com/students/" rel="nofollow"&gt;Spotify&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Boston and New York&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.tusimple.com/careers/#jobs" rel="nofollow"&gt;TuSimple&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Diego, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers.hpe.com/jobs" rel="nofollow"&gt;HP Enterprise&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Multiple Locations&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.oath.com/careers/job-openings" rel="nofollow"&gt;Oath&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Multiple Locations&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://nytimes.wd5.myworkdayjobs.com/en-US/Intern-Biz" rel="nofollow"&gt;New York Times&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://solutions.axs.com/axs-careers-apply/?jid=4461510002" rel="nofollow"&gt;axs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Francisco, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.esri.com/en-us/about/careers/job-detail?req=11338&amp;amp;title=Internships%20-%20Software%20Development%20and%20Engineering%202020" rel="nofollow"&gt;esri&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Due Time: Dec 31&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://careers-redhat.icims.com/jobs/search?ss=1&amp;amp;searchKeyword=internship&amp;amp;searchCategory=17505" rel="nofollow"&gt;Red Hat&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Various, remote available&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Various positions from DevOps to SWE to UX, does not provide housing stipend&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://adobe.wd5.myworkdayjobs.com/external_university/" rel="nofollow"&gt;Adobe&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Franciso, CA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.lever.co/relativity/d17dcf2a-eebd-40de-b715-0a0e9db8bc87" rel="nofollow"&gt;Relativity&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Chicago, IL&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/embed/job_app?token=1316736&amp;amp;gh_src=36td7o" rel="nofollow"&gt;Braintree&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Chicago, San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://job.bytedance.com/en/job?functions=&amp;amp;locations=&amp;amp;position=&amp;amp;keyword=intern&amp;amp;offset=0" rel="nofollow"&gt;ByteDance&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Various across the world&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://uscareers-intuit.icims.com/jobs/search?ss=1&amp;amp;searchKeyword=intern" rel="nofollow"&gt;Intuit&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Mountain View, San Diego&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://lytx.wd1.myworkdayjobs.com/en-US/Lytx/job/Office---San-Diego-CA/Software-Engineer-Intern_R-633" rel="nofollow"&gt;Lytx&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Diego&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://hire.withgoogle.com/public/jobs/podiumcom/view/P_AAAAAACAAEnJeSNEIEUO0f" rel="nofollow"&gt;Podium&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Lehi, UT&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/propellerhealth/jobs/50761?gh_src=o7hkam" rel="nofollow"&gt;Propeller&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Madison, San Francisco&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/pendo/jobs/4454910002/" rel="nofollow"&gt;Pendo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Raleigh, NC&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/snowflakecomputing" rel="nofollow"&gt;Snowflake&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;San Mateo, Seattle&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://boards.greenhouse.io/mailchimp" rel="nofollow"&gt;MailChimp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Atlanta&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.tapad.com/careers/openings/?gh_jid=1866144" rel="nofollow"&gt;Tapad&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;New York, NA&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.jobvite.com/servicenow/job/oPtSafw4/" rel="nofollow"&gt;ServiceNow&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Santa Clara, California; San Diego, Californial; Kirkland, Washington; Chicago, Illinois; San Francisco, California&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://jobs.rbc.com/ca/en/amplify" rel="nofollow"&gt;RBC&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Toronto, ON&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Graduating in 2020, 2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.lockheedmartinjobs.com/job/owego/software-engineering-intern/694/13093474?utm_campaign=google_jobs_apply&amp;amp;utm_source=google_jobs_apply&amp;amp;utm_medium=organic" rel="nofollow"&gt;Lockheed Martin&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Owego, NY&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;Must have at least a 3.0 GPA, Must be able to obtain an interim secret clearance prior to start, and must be able to obtain and maintain a security clearance&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>elaine-zheng</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>soimort/you-get #18 in Python, This week</title><link>https://github.com/soimort/you-get</link><description>&lt;p&gt;&lt;i&gt;:arrow_double_down: Dumb downloader that scrapes the web&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-you-get" class="anchor" aria-hidden="true" href="#you-get"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;You-Get&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://pypi.python.org/pypi/you-get/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/59a8468e96c17f2aad012be69c1364f393073a69/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f796f752d6765742e737667" alt="PyPI version" data-canonical-src="https://img.shields.io/pypi/v/you-get.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.org/soimort/you-get" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ecb41bc19c41a53ecdc7dc7e44d195b6c1cfcde2/68747470733a2f2f7472617669732d63692e6f72672f736f696d6f72742f796f752d6765742e737667" alt="Build Status" data-canonical-src="https://travis-ci.org/soimort/you-get.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/soimort/you-get?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTICE: Read &lt;a href="https://github.com/soimort/you-get/blob/develop/CONTRIBUTING.md"&gt;this&lt;/a&gt; if you are looking for the conventional "Issues" tab.&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href="https://you-get.org/" rel="nofollow"&gt;You-Get&lt;/a&gt; is a tiny command-line utility to download media contents (videos, audios, images) from the Web, in case there is no other handy way to do it.&lt;/p&gt;
&lt;p&gt;Here's how you use &lt;code&gt;you-get&lt;/code&gt; to download a video from &lt;a href="https://www.youtube.com/watch?v=jNQXAC9IVRw" rel="nofollow"&gt;YouTube&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;$ &lt;span class="pl-s1"&gt;you-get &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;https://www.youtube.com/watch?v=jNQXAC9IVRw&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c1"&gt;site:                YouTube&lt;/span&gt;
&lt;span class="pl-c1"&gt;title:               Me at the zoo&lt;/span&gt;
&lt;span class="pl-c1"&gt;stream:&lt;/span&gt;
&lt;span class="pl-c1"&gt;    - itag:          43&lt;/span&gt;
&lt;span class="pl-c1"&gt;      container:     webm&lt;/span&gt;
&lt;span class="pl-c1"&gt;      quality:       medium&lt;/span&gt;
&lt;span class="pl-c1"&gt;      size:          0.5 MiB (564215 bytes)&lt;/span&gt;
&lt;span class="pl-c1"&gt;    # download-with: you-get --itag=43 [URL]&lt;/span&gt;

&lt;span class="pl-c1"&gt;Downloading Me at the zoo.webm ...&lt;/span&gt;
&lt;span class="pl-c1"&gt; 100% (  0.5/  0.5MB) ├██████████████████████████████████┤[1/1]    6 MB/s&lt;/span&gt;

&lt;span class="pl-c1"&gt;Saving Me at the zoo.en.srt ... Done.&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And here's why you might want to use it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You enjoyed something on the Internet, and just want to download them for your own pleasure.&lt;/li&gt;
&lt;li&gt;You watch your favorite videos online from your computer, but you are prohibited from saving them. You feel that you have no control over your own computer. (And it's not how an open Web is supposed to work.)&lt;/li&gt;
&lt;li&gt;You want to get rid of any closed-source technology or proprietary JavaScript code, and disallow things like Flash running on your computer.&lt;/li&gt;
&lt;li&gt;You are an adherent of hacker culture and free software.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What &lt;code&gt;you-get&lt;/code&gt; can do for you:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download videos / audios from popular websites such as YouTube, Youku, Niconico, and a bunch more. (See the &lt;a href="#supported-sites"&gt;full list of supported sites&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Stream an online video in your media player. No web browser, no more ads.&lt;/li&gt;
&lt;li&gt;Download images (of interest) by scraping a web page.&lt;/li&gt;
&lt;li&gt;Download arbitrary non-HTML contents, i.e., binary files.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Interested? &lt;a href="#installation"&gt;Install it&lt;/a&gt; now and &lt;a href="#getting-started"&gt;get started by examples&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Are you a Python programmer? Then check out &lt;a href="https://github.com/soimort/you-get"&gt;the source&lt;/a&gt; and fork it!&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/af66ed3ad2d9fd159b9f5fdc92ba0a1804cff642/68747470733a2f2f692e696d6775722e636f6d2f4766746846417a2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/af66ed3ad2d9fd159b9f5fdc92ba0a1804cff642/68747470733a2f2f692e696d6775722e636f6d2f4766746846417a2e706e67" alt="" data-canonical-src="https://i.imgur.com/GfthFAz.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prerequisites&lt;/h3&gt;
&lt;p&gt;The following dependencies are necessary:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://www.python.org/downloads/" rel="nofollow"&gt;Python&lt;/a&gt;&lt;/strong&gt;  3.2 or above&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://www.ffmpeg.org/" rel="nofollow"&gt;FFmpeg&lt;/a&gt;&lt;/strong&gt; 1.0 or above&lt;/li&gt;
&lt;li&gt;(Optional) &lt;a href="https://rtmpdump.mplayerhq.hu/" rel="nofollow"&gt;RTMPDump&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-option-1-install-via-pip" class="anchor" aria-hidden="true" href="#option-1-install-via-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 1: Install via pip&lt;/h3&gt;
&lt;p&gt;The official release of &lt;code&gt;you-get&lt;/code&gt; is distributed on &lt;a href="https://pypi.python.org/pypi/you-get" rel="nofollow"&gt;PyPI&lt;/a&gt;, and can be installed easily from a PyPI mirror via the &lt;a href="https://en.wikipedia.org/wiki/Pip_(package_manager)" rel="nofollow"&gt;pip&lt;/a&gt; package manager. Note that you must use the Python 3 version of &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pip3 install you-get
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-option-2-install-via-antigen-for-zsh-users" class="anchor" aria-hidden="true" href="#option-2-install-via-antigen-for-zsh-users"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 2: Install via &lt;a href="https://github.com/zsh-users/antigen"&gt;Antigen&lt;/a&gt; (for Zsh users)&lt;/h3&gt;
&lt;p&gt;Add the following line to your &lt;code&gt;.zshrc&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;antigen bundle soimort/you-get
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-option-3-download-from-github" class="anchor" aria-hidden="true" href="#option-3-download-from-github"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 3: Download from GitHub&lt;/h3&gt;
&lt;p&gt;You may either download the &lt;a href="https://github.com/soimort/you-get/archive/master.zip"&gt;stable&lt;/a&gt; (identical with the latest release on PyPI) or the &lt;a href="https://github.com/soimort/you-get/archive/develop.zip"&gt;develop&lt;/a&gt; (more hotfixes, unstable features) branch of &lt;code&gt;you-get&lt;/code&gt;. Unzip it, and put the directory containing the &lt;code&gt;you-get&lt;/code&gt; script into your &lt;code&gt;PATH&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Alternatively, run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ [sudo] python3 setup.py install
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 setup.py install --user
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to install &lt;code&gt;you-get&lt;/code&gt; to a permanent path.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-option-4-git-clone" class="anchor" aria-hidden="true" href="#option-4-git-clone"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 4: Git clone&lt;/h3&gt;
&lt;p&gt;This is the recommended way for all developers, even if you don't often code in Python.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone git://github.com/soimort/you-get.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then put the cloned directory into your &lt;code&gt;PATH&lt;/code&gt;, or run &lt;code&gt;./setup.py install&lt;/code&gt; to install &lt;code&gt;you-get&lt;/code&gt; to a permanent path.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-option-5-homebrew-mac-only" class="anchor" aria-hidden="true" href="#option-5-homebrew-mac-only"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 5: Homebrew (Mac only)&lt;/h3&gt;
&lt;p&gt;You can install &lt;code&gt;you-get&lt;/code&gt; easily via:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ brew install you-get
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-option-6-pkg-freebsd-only" class="anchor" aria-hidden="true" href="#option-6-pkg-freebsd-only"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 6: pkg (FreeBSD only)&lt;/h3&gt;
&lt;p&gt;You can install &lt;code&gt;you-get&lt;/code&gt; easily via:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# pkg install you-get
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-shell-completion" class="anchor" aria-hidden="true" href="#shell-completion"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Shell completion&lt;/h3&gt;
&lt;p&gt;Completion definitions for Bash, Fish and Zsh can be found in &lt;a href="https://github.com/soimort/you-get/tree/develop/contrib/completion"&gt;&lt;code&gt;contrib/completion&lt;/code&gt;&lt;/a&gt;. Please consult your shell's manual for how to take advantage of them.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-upgrading" class="anchor" aria-hidden="true" href="#upgrading"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Upgrading&lt;/h2&gt;
&lt;p&gt;Based on which option you chose to install &lt;code&gt;you-get&lt;/code&gt;, you may upgrade it via:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pip3 install --upgrade you-get
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or download the latest release via:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get https://github.com/soimort/you-get/archive/master.zip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to get the latest &lt;code&gt;develop&lt;/code&gt; branch without messing up the PIP, you can try:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pip3 install --upgrade git+https://github.com/soimort/you-get@develop
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-download-a-video" class="anchor" aria-hidden="true" href="#download-a-video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Download a video&lt;/h3&gt;
&lt;p&gt;When you get a video of interest, you might want to use the &lt;code&gt;--info&lt;/code&gt;/&lt;code&gt;-i&lt;/code&gt; option to see all available quality and formats:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get -i 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
site:                YouTube
title:               Me at the zoo
streams:             # Available quality and codecs
    [ DASH ] ____________________________________
    - itag:          242
      container:     webm
      quality:       320x240
      size:          0.6 MiB (618358 bytes)
    # download-with: you-get --itag=242 [URL]

    - itag:          395
      container:     mp4
      quality:       320x240
      size:          0.5 MiB (550743 bytes)
    # download-with: you-get --itag=395 [URL]

    - itag:          133
      container:     mp4
      quality:       320x240
      size:          0.5 MiB (498558 bytes)
    # download-with: you-get --itag=133 [URL]

    - itag:          278
      container:     webm
      quality:       192x144
      size:          0.4 MiB (392857 bytes)
    # download-with: you-get --itag=278 [URL]

    - itag:          160
      container:     mp4
      quality:       192x144
      size:          0.4 MiB (370882 bytes)
    # download-with: you-get --itag=160 [URL]

    - itag:          394
      container:     mp4
      quality:       192x144
      size:          0.4 MiB (367261 bytes)
    # download-with: you-get --itag=394 [URL]

    [ DEFAULT ] _________________________________
    - itag:          43
      container:     webm
      quality:       medium
      size:          0.5 MiB (568748 bytes)
    # download-with: you-get --itag=43 [URL]

    - itag:          18
      container:     mp4
      quality:       small
    # download-with: you-get --itag=18 [URL]

    - itag:          36
      container:     3gp
      quality:       small
    # download-with: you-get --itag=36 [URL]

    - itag:          17
      container:     3gp
      quality:       small
    # download-with: you-get --itag=17 [URL]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, the one on the top is the one you will get. If that looks cool to you, download it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
site:                YouTube
title:               Me at the zoo
stream:
    - itag:          242
      container:     webm
      quality:       320x240
      size:          0.6 MiB (618358 bytes)
    # download-with: you-get --itag=242 [URL]

Downloading Me at the zoo.webm ...
 100% (  0.6/  0.6MB) ├██████████████████████████████████████████████████████████████████████████████┤[2/2]    2 MB/s
Merging video parts... Merged into Me at the zoo.webm

Saving Me at the zoo.en.srt ... Done.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(If a YouTube video has any closed captions, they will be downloaded together with the video file, in SubRip subtitle format.)&lt;/p&gt;
&lt;p&gt;Or, if you prefer another format (mp4), just use whatever the option &lt;code&gt;you-get&lt;/code&gt; shows to you:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get --itag=18 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;At this point, format selection has not been generally implemented for most of our supported sites; in that case, the default format to download is the one with the highest quality.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ffmpeg&lt;/code&gt; is a required dependency, for downloading and joining videos streamed in multiple parts (e.g. on some sites like Youku), and for YouTube videos of 1080p or high resolution.&lt;/li&gt;
&lt;li&gt;If you don't want &lt;code&gt;you-get&lt;/code&gt; to join video parts after downloading them, use the &lt;code&gt;--no-merge&lt;/code&gt;/&lt;code&gt;-n&lt;/code&gt; option.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-download-anything-else" class="anchor" aria-hidden="true" href="#download-anything-else"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Download anything else&lt;/h3&gt;
&lt;p&gt;If you already have the URL of the exact resource you want, you can download it directly with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get https://stallman.org/rms.jpg
Site:       stallman.org
Title:      rms
Type:       JPEG Image (image/jpeg)
Size:       0.06 MiB (66482 Bytes)

Downloading rms.jpg ...
100.0% (  0.1/0.1  MB) ├████████████████████████████████████████┤[1/1]  127 kB/s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Otherwise, &lt;code&gt;you-get&lt;/code&gt; will scrape the web page and try to figure out if there's anything interesting to you:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get http://kopasas.tumblr.com/post/69361932517
Site:       Tumblr.com
Title:      kopasas
Type:       Unknown type (None)
Size:       0.51 MiB (536583 Bytes)

Site:       Tumblr.com
Title:      tumblr_mxhg13jx4n1sftq6do1_1280
Type:       Portable Network Graphics (image/png)
Size:       0.51 MiB (536583 Bytes)

Downloading tumblr_mxhg13jx4n1sftq6do1_1280.png ...
100.0% (  0.5/0.5  MB) ├████████████████████████████████████████┤[1/1]   22 MB/s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This feature is an experimental one and far from perfect. It works best on scraping large-sized images from popular websites like Tumblr and Blogger, but there is really no universal pattern that can apply to any site on the Internet.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-search-on-google-videos-and-download" class="anchor" aria-hidden="true" href="#search-on-google-videos-and-download"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Search on Google Videos and download&lt;/h3&gt;
&lt;p&gt;You can pass literally anything to &lt;code&gt;you-get&lt;/code&gt;. If it isn't a valid URL, &lt;code&gt;you-get&lt;/code&gt; will do a Google search and download the most relevant video for you. (It might not be exactly the thing you wish to see, but still very likely.)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get "Richard Stallman eats"
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-pause-and-resume-a-download" class="anchor" aria-hidden="true" href="#pause-and-resume-a-download"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pause and resume a download&lt;/h3&gt;
&lt;p&gt;You may use &lt;kbd&gt;Ctrl&lt;/kbd&gt;+&lt;kbd&gt;C&lt;/kbd&gt; to interrupt a download.&lt;/p&gt;
&lt;p&gt;A temporary &lt;code&gt;.download&lt;/code&gt; file is kept in the output directory. Next time you run &lt;code&gt;you-get&lt;/code&gt; with the same arguments, the download progress will resume from the last session. In case the file is completely downloaded (the temporary &lt;code&gt;.download&lt;/code&gt; extension is gone), &lt;code&gt;you-get&lt;/code&gt; will just skip the download.&lt;/p&gt;
&lt;p&gt;To enforce re-downloading, use the &lt;code&gt;--force&lt;/code&gt;/&lt;code&gt;-f&lt;/code&gt; option. (&lt;strong&gt;Warning:&lt;/strong&gt; doing so will overwrite any existing file or temporary file with the same name!)&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-set-the-path-and-name-of-downloaded-file" class="anchor" aria-hidden="true" href="#set-the-path-and-name-of-downloaded-file"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Set the path and name of downloaded file&lt;/h3&gt;
&lt;p&gt;Use the &lt;code&gt;--output-dir&lt;/code&gt;/&lt;code&gt;-o&lt;/code&gt; option to set the path, and &lt;code&gt;--output-filename&lt;/code&gt;/&lt;code&gt;-O&lt;/code&gt; to set the name of the downloaded file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get -o ~/Videos -O zoo.webm 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Tips:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;These options are helpful if you encounter problems with the default video titles, which may contain special characters that do not play well with your current shell / operating system / filesystem.&lt;/li&gt;
&lt;li&gt;These options are also helpful if you write a script to batch download files and put them into designated folders with designated names.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-proxy-settings" class="anchor" aria-hidden="true" href="#proxy-settings"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Proxy settings&lt;/h3&gt;
&lt;p&gt;You may specify an HTTP proxy for &lt;code&gt;you-get&lt;/code&gt; to use, via the &lt;code&gt;--http-proxy&lt;/code&gt;/&lt;code&gt;-x&lt;/code&gt; option:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get -x 127.0.0.1:8087 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, the system proxy setting (i.e. the environment variable &lt;code&gt;http_proxy&lt;/code&gt;) is applied by default. To disable any proxy, use the &lt;code&gt;--no-proxy&lt;/code&gt; option.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tips:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you need to use proxies a lot (in case your network is blocking certain sites), you might want to use &lt;code&gt;you-get&lt;/code&gt; with &lt;a href="https://github.com/rofl0r/proxychains-ng"&gt;proxychains&lt;/a&gt; and set &lt;code&gt;alias you-get="proxychains -q you-get"&lt;/code&gt; (in Bash).&lt;/li&gt;
&lt;li&gt;For some websites (e.g. Youku), if you need access to some videos that are only available in mainland China, there is an option of using a specific proxy to extract video information from the site: &lt;code&gt;--extractor-proxy&lt;/code&gt;/&lt;code&gt;-y&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-watch-a-video" class="anchor" aria-hidden="true" href="#watch-a-video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Watch a video&lt;/h3&gt;
&lt;p&gt;Use the &lt;code&gt;--player&lt;/code&gt;/&lt;code&gt;-p&lt;/code&gt; option to feed the video into your media player of choice, e.g. &lt;code&gt;mpv&lt;/code&gt; or &lt;code&gt;vlc&lt;/code&gt;, instead of downloading it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get -p vlc 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or, if you prefer to watch the video in a browser, just without ads or comment section:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ you-get -p chromium 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Tips:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is possible to use the &lt;code&gt;-p&lt;/code&gt; option to start another download manager, e.g., &lt;code&gt;you-get -p uget-gtk 'https://www.youtube.com/watch?v=jNQXAC9IVRw'&lt;/code&gt;, though they may not play together very well.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-load-cookies" class="anchor" aria-hidden="true" href="#load-cookies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Load cookies&lt;/h3&gt;
&lt;p&gt;Not all videos are publicly available to anyone. If you need to log in your account to access something (e.g., a private video), it would be unavoidable to feed the browser cookies to &lt;code&gt;you-get&lt;/code&gt; via the &lt;code&gt;--cookies&lt;/code&gt;/&lt;code&gt;-c&lt;/code&gt; option.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As of now, we are supporting two formats of browser cookies: Mozilla &lt;code&gt;cookies.sqlite&lt;/code&gt; and Netscape &lt;code&gt;cookies.txt&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-reuse-extracted-data" class="anchor" aria-hidden="true" href="#reuse-extracted-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reuse extracted data&lt;/h3&gt;
&lt;p&gt;Use &lt;code&gt;--url&lt;/code&gt;/&lt;code&gt;-u&lt;/code&gt; to get a list of downloadable resource URLs extracted from the page. Use &lt;code&gt;--json&lt;/code&gt; to get an abstract of extracted data in the JSON format.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For the time being, this feature has &lt;strong&gt;NOT&lt;/strong&gt; been stabilized and the JSON schema may have breaking changes in the future.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-supported-sites" class="anchor" aria-hidden="true" href="#supported-sites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Supported Sites&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Site&lt;/th&gt;
&lt;th align="left"&gt;URL&lt;/th&gt;
&lt;th align="center"&gt;Videos?&lt;/th&gt;
&lt;th align="center"&gt;Images?&lt;/th&gt;
&lt;th align="center"&gt;Audios?&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;YouTube&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.youtube.com/" rel="nofollow"&gt;https://www.youtube.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Twitter&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://twitter.com/" rel="nofollow"&gt;https://twitter.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;VK&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://vk.com/" rel="nofollow"&gt;http://vk.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Vine&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://vine.co/" rel="nofollow"&gt;https://vine.co/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Vimeo&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://vimeo.com/" rel="nofollow"&gt;https://vimeo.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Vidto&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://vidto.me/" rel="nofollow"&gt;http://vidto.me/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Videomega&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://videomega.tv/" rel="nofollow"&gt;http://videomega.tv/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Veoh&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.veoh.com/" rel="nofollow"&gt;http://www.veoh.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Tumblr&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.tumblr.com/" rel="nofollow"&gt;https://www.tumblr.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;TED&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.ted.com/" rel="nofollow"&gt;http://www.ted.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;SoundCloud&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://soundcloud.com/" rel="nofollow"&gt;https://soundcloud.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;SHOWROOM&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.showroom-live.com/" rel="nofollow"&gt;https://www.showroom-live.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Pinterest&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.pinterest.com/" rel="nofollow"&gt;https://www.pinterest.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;MusicPlayOn&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://en.musicplayon.com/" rel="nofollow"&gt;http://en.musicplayon.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;MTV81&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.mtv81.com/" rel="nofollow"&gt;http://www.mtv81.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Mixcloud&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.mixcloud.com/" rel="nofollow"&gt;https://www.mixcloud.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Metacafe&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.metacafe.com/" rel="nofollow"&gt;http://www.metacafe.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Magisto&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.magisto.com/" rel="nofollow"&gt;http://www.magisto.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Khan Academy&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.khanacademy.org/" rel="nofollow"&gt;https://www.khanacademy.org/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Internet Archive&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://archive.org/" rel="nofollow"&gt;https://archive.org/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Instagram&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://instagram.com/" rel="nofollow"&gt;https://instagram.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;InfoQ&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.infoq.com/presentations/" rel="nofollow"&gt;http://www.infoq.com/presentations/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Imgur&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://imgur.com/" rel="nofollow"&gt;http://imgur.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Heavy Music Archive&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.heavy-music.ru/" rel="nofollow"&gt;http://www.heavy-music.ru/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Google+&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://plus.google.com/" rel="nofollow"&gt;https://plus.google.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Freesound&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.freesound.org/" rel="nofollow"&gt;http://www.freesound.org/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Flickr&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.flickr.com/" rel="nofollow"&gt;https://www.flickr.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;FC2 Video&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://video.fc2.com/" rel="nofollow"&gt;http://video.fc2.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Facebook&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.facebook.com/" rel="nofollow"&gt;https://www.facebook.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;eHow&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.ehow.com/" rel="nofollow"&gt;http://www.ehow.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Dailymotion&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.dailymotion.com/" rel="nofollow"&gt;http://www.dailymotion.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Coub&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://coub.com/" rel="nofollow"&gt;http://coub.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;CBS&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.cbs.com/" rel="nofollow"&gt;http://www.cbs.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Bandcamp&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://bandcamp.com/" rel="nofollow"&gt;http://bandcamp.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;AliveThai&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://alive.in.th/" rel="nofollow"&gt;http://alive.in.th/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;interest.me&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://ch.interest.me/tvn" rel="nofollow"&gt;http://ch.interest.me/tvn&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;755&lt;br&gt;ナナゴーゴー&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://7gogo.jp/" rel="nofollow"&gt;http://7gogo.jp/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;niconico&lt;br&gt;ニコニコ動画&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.nicovideo.jp/" rel="nofollow"&gt;http://www.nicovideo.jp/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;163&lt;br&gt;网易视频&lt;br&gt;网易云音乐&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://v.163.com/" rel="nofollow"&gt;http://v.163.com/&lt;/a&gt;&lt;br&gt;&lt;a href="http://music.163.com/" rel="nofollow"&gt;http://music.163.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;56网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.56.com/" rel="nofollow"&gt;http://www.56.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;AcFun&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.acfun.cn/" rel="nofollow"&gt;http://www.acfun.cn/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Baidu&lt;br&gt;百度贴吧&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://tieba.baidu.com/" rel="nofollow"&gt;http://tieba.baidu.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;爆米花网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.baomihua.com/" rel="nofollow"&gt;http://www.baomihua.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;bilibili&lt;br&gt;哔哩哔哩&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.bilibili.com/" rel="nofollow"&gt;http://www.bilibili.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;豆瓣&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.douban.com/" rel="nofollow"&gt;http://www.douban.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;斗鱼&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.douyutv.com/" rel="nofollow"&gt;http://www.douyutv.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Panda&lt;br&gt;熊猫&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.panda.tv/" rel="nofollow"&gt;http://www.panda.tv/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;凤凰视频&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://v.ifeng.com/" rel="nofollow"&gt;http://v.ifeng.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;风行网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.fun.tv/" rel="nofollow"&gt;http://www.fun.tv/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;iQIYI&lt;br&gt;爱奇艺&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.iqiyi.com/" rel="nofollow"&gt;http://www.iqiyi.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;激动网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.joy.cn/" rel="nofollow"&gt;http://www.joy.cn/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;酷6网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.ku6.com/" rel="nofollow"&gt;http://www.ku6.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;酷狗音乐&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.kugou.com/" rel="nofollow"&gt;http://www.kugou.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;酷我音乐&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.kuwo.cn/" rel="nofollow"&gt;http://www.kuwo.cn/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;乐视网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.le.com/" rel="nofollow"&gt;http://www.le.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;荔枝FM&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.lizhi.fm/" rel="nofollow"&gt;http://www.lizhi.fm/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;秒拍&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.miaopai.com/" rel="nofollow"&gt;http://www.miaopai.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;MioMio弹幕网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.miomio.tv/" rel="nofollow"&gt;http://www.miomio.tv/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;MissEvan&lt;br&gt;猫耳FM&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.missevan.com/" rel="nofollow"&gt;http://www.missevan.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;痞客邦&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.pixnet.net/" rel="nofollow"&gt;https://www.pixnet.net/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;PPTV聚力&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.pptv.com/" rel="nofollow"&gt;http://www.pptv.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;齐鲁网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://v.iqilu.com/" rel="nofollow"&gt;http://v.iqilu.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;QQ&lt;br&gt;腾讯视频&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://v.qq.com/" rel="nofollow"&gt;http://v.qq.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;企鹅直播&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://live.qq.com/" rel="nofollow"&gt;http://live.qq.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Sina&lt;br&gt;新浪视频&lt;br&gt;微博秒拍视频&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://video.sina.com.cn/" rel="nofollow"&gt;http://video.sina.com.cn/&lt;/a&gt;&lt;br&gt;&lt;a href="http://video.weibo.com/" rel="nofollow"&gt;http://video.weibo.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Sohu&lt;br&gt;搜狐视频&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://tv.sohu.com/" rel="nofollow"&gt;http://tv.sohu.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Tudou&lt;br&gt;土豆&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.tudou.com/" rel="nofollow"&gt;http://www.tudou.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;虾米&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.xiami.com/" rel="nofollow"&gt;http://www.xiami.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;阳光卫视&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.isuntv.com/" rel="nofollow"&gt;http://www.isuntv.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;音悦Tai&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.yinyuetai.com/" rel="nofollow"&gt;http://www.yinyuetai.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Youku&lt;br&gt;优酷&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.youku.com/" rel="nofollow"&gt;http://www.youku.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;战旗TV&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.zhanqi.tv/lives" rel="nofollow"&gt;http://www.zhanqi.tv/lives&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;央视网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.cntv.cn/" rel="nofollow"&gt;http://www.cntv.cn/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Naver&lt;br&gt;네이버&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://tvcast.naver.com/" rel="nofollow"&gt;http://tvcast.naver.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;芒果TV&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.mgtv.com/" rel="nofollow"&gt;http://www.mgtv.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;火猫TV&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.huomao.com/" rel="nofollow"&gt;http://www.huomao.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;阳光宽频网&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://www.365yg.com/" rel="nofollow"&gt;http://www.365yg.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;西瓜视频&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.ixigua.com/" rel="nofollow"&gt;https://www.ixigua.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;快手&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.kuaishou.com/" rel="nofollow"&gt;https://www.kuaishou.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;抖音&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.douyin.com/" rel="nofollow"&gt;https://www.douyin.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;TikTok&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.tiktok.com/" rel="nofollow"&gt;https://www.tiktok.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;中国体育(TV)&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://v.zhibo.tv/" rel="nofollow"&gt;http://v.zhibo.tv/&lt;/a&gt; &lt;br&gt;&lt;a href="http://video.zhibo.tv/" rel="nofollow"&gt;http://video.zhibo.tv/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;知乎&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://www.zhihu.com/" rel="nofollow"&gt;https://www.zhihu.com/&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;✓&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For all other sites not on the list, the universal extractor will take care of finding and downloading interesting resources from the page.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-known-bugs" class="anchor" aria-hidden="true" href="#known-bugs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Known bugs&lt;/h3&gt;
&lt;p&gt;If something is broken and &lt;code&gt;you-get&lt;/code&gt; can't get you things you want, don't panic. (Yes, this happens all the time!)&lt;/p&gt;
&lt;p&gt;Check if it's already a known problem on &lt;a href="https://github.com/soimort/you-get/wiki/Known-Bugs"&gt;https://github.com/soimort/you-get/wiki/Known-Bugs&lt;/a&gt;. If not, follow the guidelines on &lt;a href="https://github.com/soimort/you-get/blob/develop/CONTRIBUTING.md"&gt;how to report an issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-involved" class="anchor" aria-hidden="true" href="#getting-involved"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Involved&lt;/h2&gt;
&lt;p&gt;You can reach us on the Gitter channel &lt;a href="https://gitter.im/soimort/you-get" rel="nofollow"&gt;#soimort/you-get&lt;/a&gt; (here's how you &lt;a href="http://irc.gitter.im" rel="nofollow"&gt;set up your IRC client&lt;/a&gt; for Gitter). If you have a quick question regarding &lt;code&gt;you-get&lt;/code&gt;, ask it there.&lt;/p&gt;
&lt;p&gt;If you are seeking to report an issue or contribute, please make sure to read &lt;a href="https://github.com/soimort/you-get/blob/develop/CONTRIBUTING.md"&gt;the guidelines&lt;/a&gt; first.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-legal-issues" class="anchor" aria-hidden="true" href="#legal-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Legal Issues&lt;/h2&gt;
&lt;p&gt;This software is distributed under the &lt;a href="https://raw.github.com/soimort/you-get/master/LICENSE.txt"&gt;MIT license&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In particular, please be aware that&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Translated to human words:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;In case your use of the software forms the basis of copyright infringement, or you use the software for any other illegal purposes, the authors cannot take any responsibility for you.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We only ship the code here, and how you are going to use it is left to your own discretion.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authors&lt;/h2&gt;
&lt;p&gt;Made by &lt;a href="https://github.com/soimort"&gt;@soimort&lt;/a&gt;, who is in turn powered by &lt;g-emoji class="g-emoji" alias="coffee" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2615.png"&gt;☕️&lt;/g-emoji&gt;, &lt;g-emoji class="g-emoji" alias="beer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f37a.png"&gt;🍺&lt;/g-emoji&gt; and &lt;g-emoji class="g-emoji" alias="ramen" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f35c.png"&gt;🍜&lt;/g-emoji&gt;.&lt;/p&gt;
&lt;p&gt;You can find the &lt;a href="https://github.com/soimort/you-get/graphs/contributors"&gt;list of all contributors&lt;/a&gt; here.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>soimort</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>mnielsen/neural-networks-and-deep-learning #19 in Python, This week</title><link>https://github.com/mnielsen/neural-networks-and-deep-learning</link><description>&lt;p&gt;&lt;i&gt;Code samples for my book "Neural Networks and Deep Learning"&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-code-samples-for-neural-networks-and-deep-learning" class="anchor" aria-hidden="true" href="#code-samples-for-neural-networks-and-deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code samples for "Neural Networks and Deep Learning"&lt;/h1&gt;
&lt;p&gt;This repository contains code samples for my book on &lt;a href="http://neuralnetworksanddeeplearning.com" rel="nofollow"&gt;"Neural Networks
and Deep Learning"&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The code is written for Python 2.6 or 2.7. Michal Daniel Dobrzanski
has a repository for Python 3
&lt;a href="https://github.com/MichalDanielDobrzanski/DeepLearningPython35"&gt;here&lt;/a&gt;. I
will not be updating the current repository for Python 3
compatibility.&lt;/p&gt;
&lt;p&gt;The program &lt;code&gt;src/network3.py&lt;/code&gt; uses version 0.6 or 0.7 of the Theano
library.  It needs modification for compatibility with later versions
of the library.  I will not be making such modifications.&lt;/p&gt;
&lt;p&gt;As the code is written to accompany the book, I don't intend to add
new features. However, bug reports are welcome, and you should feel
free to fork and modify the code.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;MIT License&lt;/p&gt;
&lt;p&gt;Copyright (c) 2012-2018 Michael Nielsen&lt;/p&gt;
&lt;p&gt;Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:&lt;/p&gt;
&lt;p&gt;The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.&lt;/p&gt;
&lt;p&gt;THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>mnielsen</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>keras-team/keras #20 in Python, This week</title><link>https://github.com/keras-team/keras</link><description>&lt;p&gt;&lt;i&gt;Deep Learning for humans&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-keras-deep-learning-for-humans" class="anchor" aria-hidden="true" href="#keras-deep-learning-for-humans"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Keras: Deep Learning for humans&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0d08dc4f9466d347e8d28a951ea51e3430c6f92c/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6b657261732e696f2f696d672f6b657261732d6c6f676f2d323031382d6c617267652d313230302e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/0d08dc4f9466d347e8d28a951ea51e3430c6f92c/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6b657261732e696f2f696d672f6b657261732d6c6f676f2d323031382d6c617267652d313230302e706e67" alt="Keras logo" data-canonical-src="https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/keras-team/keras" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f8208f284c67046b0531446a3498b3e54c1a31e5/68747470733a2f2f7472617669732d63692e6f72672f6b657261732d7465616d2f6b657261732e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/keras-team/keras.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/keras-team/keras/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/72b8fa08522b87c996b58d36be5132a346d434c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6173686170652f6170697374617475732e7376673f6d61784167653d32353932303030" alt="license" data-canonical-src="https://img.shields.io/github/license/mashape/apistatus.svg?maxAge=2592000" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-you-have-just-found-keras" class="anchor" aria-hidden="true" href="#you-have-just-found-keras"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;You have just found Keras.&lt;/h2&gt;
&lt;p&gt;Keras is a high-level neural networks API, written in Python and capable of running on top of &lt;a href="https://github.com/tensorflow/tensorflow"&gt;TensorFlow&lt;/a&gt;, &lt;a href="https://github.com/Microsoft/cntk"&gt;CNTK&lt;/a&gt;, or &lt;a href="https://github.com/Theano/Theano"&gt;Theano&lt;/a&gt;. It was developed with a focus on enabling fast experimentation. &lt;em&gt;Being able to go from idea to result with the least possible delay is key to doing good research.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Use Keras if you need a deep learning library that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).&lt;/li&gt;
&lt;li&gt;Supports both convolutional networks and recurrent networks, as well as combinations of the two.&lt;/li&gt;
&lt;li&gt;Runs seamlessly on CPU and GPU.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Read the documentation at &lt;a href="https://keras.io" rel="nofollow"&gt;Keras.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Keras is compatible with: &lt;strong&gt;Python 2.7-3.6&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-multi-backend-keras-and-tfkeras" class="anchor" aria-hidden="true" href="#multi-backend-keras-and-tfkeras"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Multi-backend Keras and tf.keras:&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;At this time, we recommend that Keras users who use multi-backend Keras with the TensorFlow backend switch to &lt;code&gt;tf.keras&lt;/code&gt; in TensorFlow 2.0&lt;/strong&gt;. &lt;code&gt;tf.keras&lt;/code&gt; is better maintained and has better integration with TensorFlow features (eager execution, distribution support and other).&lt;/p&gt;
&lt;p&gt;Keras 2.2.5 was the last release of Keras implementing the 2.2.* API. It was the last release to only support TensorFlow 1 (as well as Theano and CNTK).&lt;/p&gt;
&lt;p&gt;The current release is Keras 2.3.0, which makes significant API changes and add support for TensorFlow 2.0. The 2.3.0 release will be the last major release of multi-backend Keras. Multi-backend Keras is superseded by &lt;code&gt;tf.keras&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Bugs present in multi-backend Keras will only be fixed until April 2020 (as part of minor releases).&lt;/p&gt;
&lt;p&gt;For more information about the future of Keras, see &lt;a href="http://bit.ly/keras-meeting-notes" rel="nofollow"&gt;the Keras meeting notes&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-guiding-principles" class="anchor" aria-hidden="true" href="#guiding-principles"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Guiding principles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;User friendliness.&lt;/strong&gt; Keras is an API designed for human beings, not machines. It puts user experience front and center. Keras follows best practices for reducing cognitive load: it offers consistent &amp;amp; simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear and actionable feedback upon user error.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Modularity.&lt;/strong&gt; A model is understood as a sequence or a graph of standalone, fully configurable modules that can be plugged together with as few restrictions as possible. In particular, neural layers, cost functions, optimizers, initialization schemes, activation functions and regularization schemes are all standalone modules that you can combine to create new models.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Easy extensibility.&lt;/strong&gt; New modules are simple to add (as new classes and functions), and existing modules provide ample examples. To be able to easily create new modules allows for total expressiveness, making Keras suitable for advanced research.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Work with Python&lt;/strong&gt;. No separate models configuration files in a declarative format. Models are described in Python code, which is compact, easier to debug, and allows for ease of extensibility.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started-30-seconds-to-keras" class="anchor" aria-hidden="true" href="#getting-started-30-seconds-to-keras"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting started: 30 seconds to Keras&lt;/h2&gt;
&lt;p&gt;The core data structure of Keras is a &lt;strong&gt;model&lt;/strong&gt;, a way to organize layers. The simplest type of model is the &lt;a href="https://keras.io/getting-started/sequential-model-guide" rel="nofollow"&gt;&lt;code&gt;Sequential&lt;/code&gt;&lt;/a&gt; model, a linear stack of layers. For more complex architectures, you should use the &lt;a href="https://keras.io/getting-started/functional-api-guide" rel="nofollow"&gt;Keras functional API&lt;/a&gt;, which allows to build arbitrary graphs of layers.&lt;/p&gt;
&lt;p&gt;Here is the &lt;code&gt;Sequential&lt;/code&gt; model:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; keras.models &lt;span class="pl-k"&gt;import&lt;/span&gt; Sequential

model &lt;span class="pl-k"&gt;=&lt;/span&gt; Sequential()&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Stacking layers is as easy as &lt;code&gt;.add()&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; keras.layers &lt;span class="pl-k"&gt;import&lt;/span&gt; Dense

model.add(Dense(&lt;span class="pl-v"&gt;units&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;64&lt;/span&gt;, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;relu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;input_dim&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;))
model.add(Dense(&lt;span class="pl-v"&gt;units&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;10&lt;/span&gt;, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;softmax&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once your model looks good, configure its learning process with &lt;code&gt;.compile()&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;model.compile(&lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;categorical_crossentropy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
              &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sgd&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
              &lt;span class="pl-v"&gt;metrics&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;accuracy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code).&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;model.compile(&lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;keras.losses.categorical_crossentropy,
              &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;keras.optimizers.SGD(&lt;span class="pl-v"&gt;lr&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0.01&lt;/span&gt;, &lt;span class="pl-v"&gt;momentum&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0.9&lt;/span&gt;, &lt;span class="pl-v"&gt;nesterov&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can now iterate on your training data in batches:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.&lt;/span&gt;
model.fit(x_train, y_train, &lt;span class="pl-v"&gt;epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;5&lt;/span&gt;, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;32&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Alternatively, you can feed batches to your model manually:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;model.train_on_batch(x_batch, y_batch)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Evaluate your performance in one line:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;loss_and_metrics &lt;span class="pl-k"&gt;=&lt;/span&gt; model.evaluate(x_test, y_test, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or generate predictions on new data:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;classes &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict(x_test, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Building a question answering system, an image classification model, a Neural Turing Machine, or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful?&lt;/p&gt;
&lt;p&gt;For a more in-depth tutorial about Keras, you can check out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://keras.io/getting-started/sequential-model-guide" rel="nofollow"&gt;Getting started with the Sequential model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://keras.io/getting-started/functional-api-guide" rel="nofollow"&gt;Getting started with the functional API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the &lt;a href="https://github.com/keras-team/keras/tree/master/examples"&gt;examples folder&lt;/a&gt; of the repository, you will find more advanced models: question-answering with memory networks, text generation with stacked LSTMs, etc.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;Before installing Keras, please install one of its backend engines: TensorFlow, Theano, or CNTK. We recommend the TensorFlow backend.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/install/" rel="nofollow"&gt;TensorFlow installation instructions&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://deeplearning.net/software/theano/install.html#install" rel="nofollow"&gt;Theano installation instructions&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine" rel="nofollow"&gt;CNTK installation instructions&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You may also consider installing the following &lt;strong&gt;optional dependencies&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.nvidia.com/deeplearning/sdk/cudnn-install/" rel="nofollow"&gt;cuDNN&lt;/a&gt; (recommended if you plan on running Keras on GPU).&lt;/li&gt;
&lt;li&gt;HDF5 and &lt;a href="http://docs.h5py.org/en/latest/build.html" rel="nofollow"&gt;h5py&lt;/a&gt; (required if you plan on saving Keras models to disk).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://graphviz.gitlab.io/download/" rel="nofollow"&gt;graphviz&lt;/a&gt; and &lt;a href="https://github.com/erocarrera/pydot"&gt;pydot&lt;/a&gt; (used by &lt;a href="https://keras.io/visualization/" rel="nofollow"&gt;visualization utilities&lt;/a&gt; to plot model graphs).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then, you can install Keras itself. There are two ways to install Keras:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Install Keras from PyPI (recommended):&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note: These installation steps assume that you are on a Linux or Mac environment.
If you are on Windows, you will need to remove &lt;code&gt;sudo&lt;/code&gt; to run the commands below.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo pip install keras&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you are using a virtualenv, you may want to avoid using sudo:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install keras&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Alternatively: install Keras from the GitHub source:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, clone Keras using &lt;code&gt;git&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/keras-team/keras.git&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, &lt;code&gt;cd&lt;/code&gt; to the Keras folder and run the install command:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;cd&lt;/span&gt; keras
sudo python setup.py install&lt;/pre&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-configuring-your-keras-backend" class="anchor" aria-hidden="true" href="#configuring-your-keras-backend"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuring your Keras backend&lt;/h2&gt;
&lt;p&gt;By default, Keras will use TensorFlow as its tensor manipulation library. &lt;a href="https://keras.io/backend/" rel="nofollow"&gt;Follow these instructions&lt;/a&gt; to configure the Keras backend.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-support" class="anchor" aria-hidden="true" href="#support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support&lt;/h2&gt;
&lt;p&gt;You can ask questions and join the development discussion:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On the &lt;a href="https://groups.google.com/forum/#!forum/keras-users" rel="nofollow"&gt;Keras Google group&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;On the &lt;a href="https://kerasteam.slack.com" rel="nofollow"&gt;Keras Slack channel&lt;/a&gt;. Use &lt;a href="https://keras-slack-autojoin.herokuapp.com/" rel="nofollow"&gt;this link&lt;/a&gt; to request an invitation to the channel.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can also post &lt;strong&gt;bug reports and feature requests&lt;/strong&gt; (only) in &lt;a href="https://github.com/keras-team/keras/issues"&gt;GitHub issues&lt;/a&gt;. Make sure to read &lt;a href="https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md"&gt;our guidelines&lt;/a&gt; first.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-why-this-name-keras" class="anchor" aria-hidden="true" href="#why-this-name-keras"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why this name, Keras?&lt;/h2&gt;
&lt;p&gt;Keras (κέρας) means &lt;em&gt;horn&lt;/em&gt; in Greek. It is a reference to a literary image from ancient Greek and Latin literature, first found in the &lt;em&gt;Odyssey&lt;/em&gt;, where dream spirits (&lt;em&gt;Oneiroi&lt;/em&gt;, singular &lt;em&gt;Oneiros&lt;/em&gt;) are divided between those who deceive men with false visions, who arrive to Earth through a gate of ivory, and those who announce a future that will come to pass, who arrive through a gate of horn. It's a play on the words κέρας (horn) / κραίνω (fulfill), and ἐλέφας (ivory) / ἐλεφαίρομαι (deceive).&lt;/p&gt;
&lt;p&gt;Keras was initially developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;"Oneiroi are beyond our unravelling --who can be sure what tale they tell? Not all that men look for comes to pass. Two gates there are that give passage to fleeting Oneiroi; one is made of horn, one of ivory. The Oneiroi that pass through sawn ivory are deceitful, bearing a message that will not be fulfilled; those that come out through polished horn have truth behind them, to be accomplished for men who see them."&lt;/em&gt; Homer, Odyssey 19. 562 ff (Shewring translation).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>keras-team</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>tensorflow/models #21 in Python, This week</title><link>https://github.com/tensorflow/models</link><description>&lt;p&gt;&lt;i&gt;Models and examples built with TensorFlow&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-models" class="anchor" aria-hidden="true" href="#tensorflow-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow Models&lt;/h1&gt;
&lt;p&gt;This repository contains a number of different models implemented in &lt;a href="https://www.tensorflow.org" rel="nofollow"&gt;TensorFlow&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;The &lt;a href="official"&gt;official models&lt;/a&gt; are a collection of example models that use TensorFlow's high-level APIs. They are intended to be well-maintained, tested, and kept up to date with the latest stable TensorFlow API. They should also be reasonably optimized for fast performance while still being easy to read. We especially recommend newer TensorFlow users to start here.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/tensorflow/models/tree/master/research"&gt;research models&lt;/a&gt; are a large collection of models implemented in TensorFlow by researchers. They are not officially supported or available in release branches; it is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.&lt;/p&gt;
&lt;p&gt;The &lt;a href="samples"&gt;samples folder&lt;/a&gt; contains code snippets and smaller models that demonstrate features of TensorFlow, including code presented in various blog posts.&lt;/p&gt;
&lt;p&gt;The &lt;a href="tutorials"&gt;tutorials folder&lt;/a&gt; is a collection of models described in the &lt;a href="https://www.tensorflow.org/tutorials/" rel="nofollow"&gt;TensorFlow tutorials&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-guidelines" class="anchor" aria-hidden="true" href="#contribution-guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution guidelines&lt;/h2&gt;
&lt;p&gt;If you want to contribute to models, be sure to review the &lt;a href="CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a href="LICENSE"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>tensorflow</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>dmlc/tvm #22 in Python, This week</title><link>https://github.com/dmlc/tvm</link><description>&lt;p&gt;&lt;i&gt;Open deep learning compiler stack for cpu, gpu and specialized accelerators&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;













&lt;h1&gt;&lt;a id="user-content--open-deep-learning-compiler-stack" class="anchor" aria-hidden="true" href="#-open-deep-learning-compiler-stack"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/tqchen/tvm.ai/master/images/logo/tvm-logo-small.png"&gt;&lt;img src="https://raw.githubusercontent.com/tqchen/tvm.ai/master/images/logo/tvm-logo-small.png" width="128/" style="max-width:100%;"&gt;&lt;/a&gt; Open Deep Learning Compiler Stack&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://docs.tvm.ai" rel="nofollow"&gt;Documentation&lt;/a&gt; |
&lt;a href="CONTRIBUTORS.md"&gt;Contributors&lt;/a&gt; |
&lt;a href="https://tvm.ai/community.html" rel="nofollow"&gt;Community&lt;/a&gt; |
&lt;a href="NEWS.md"&gt;Release Notes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://ci.tvm.ai:8080/job/tvm/job/master/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2598574fe2f049e6de2e47df24bc02762d8b8191/687474703a2f2f63692e74766d2e61693a383038302f6275696c645374617475732f69636f6e3f6a6f623d74766d2f6d6173746572" alt="Build Status" data-canonical-src="http://ci.tvm.ai:8080/buildStatus/icon?job=tvm/master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://dev.azure.com/tvmai/tvm/_build/latest?definitionId=2&amp;amp;branchName=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2cfbb6cb0edbdd866539d0c4845a7435cd114ecf/68747470733a2f2f6465762e617a7572652e636f6d2f74766d61692f74766d2f5f617069732f6275696c642f7374617475732f77696e646f77735f6d61635f6275696c643f6272616e63684e616d653d6d6173746572" alt="Azure Pipeline" data-canonical-src="https://dev.azure.com/tvmai/tvm/_apis/build/status/windows_mac_build?branchName=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;TVM is a compiler stack for deep learning systems. It is designed to close the gap between the
productivity-focused deep learning frameworks, and the performance- and efficiency-focused hardware backends.
TVM works with deep learning frameworks to provide end to end compilation to different backends.
Checkout the &lt;a href="https://tvm.ai/" rel="nofollow"&gt;tvm stack homepage&lt;/a&gt;  for more information.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;© Contributors Licensed under an &lt;a href="https://github.com/dmlc/tvm/blob/master/LICENSE"&gt;Apache-2.0&lt;/a&gt; license.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribute-to-tvm" class="anchor" aria-hidden="true" href="#contribute-to-tvm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribute to TVM&lt;/h2&gt;
&lt;p&gt;TVM adopts apache committer model, we aim to create an open source project that is maintained and owned by the community.
Checkout the &lt;a href="https://docs.tvm.ai/contribute/" rel="nofollow"&gt;Contributor Guide&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgement" class="anchor" aria-hidden="true" href="#acknowledgement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;We learned a lot from the following projects when building TVM.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/halide/Halide"&gt;Halide&lt;/a&gt;: TVM uses &lt;a href="https://github.com/dmlc/HalideIR"&gt;HalideIR&lt;/a&gt; as data structure for
arithmetic simplification and low level lowering. We also learned and adapted some part of lowering pipeline from Halide.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/inducer/loopy"&gt;Loopy&lt;/a&gt;: use of integer set analysis and its loop transformation primitives.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Theano/Theano"&gt;Theano&lt;/a&gt;: the design inspiration of symbolic scan operator for recurrence.&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dmlc</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>swisskyrepo/PayloadsAllTheThings #23 in Python, This week</title><link>https://github.com/swisskyrepo/PayloadsAllTheThings</link><description>&lt;p&gt;&lt;i&gt;A list of useful payloads and bypass for Web Application Security and Pentest/CTF&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-payloads-all-the-things" class="anchor" aria-hidden="true" href="#payloads-all-the-things"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Payloads All The Things&lt;/h1&gt;
&lt;p&gt;A list of useful payloads and bypasses for Web Application Security.
Feel free to improve with your payloads and techniques !
I &lt;g-emoji class="g-emoji" alias="heart" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2764.png"&gt;❤️&lt;/g-emoji&gt; pull requests :)&lt;/p&gt;
&lt;p&gt;You can also contribute with a &lt;g-emoji class="g-emoji" alias="beers" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f37b.png"&gt;🍻&lt;/g-emoji&gt; IRL&lt;/p&gt;
&lt;p&gt;Every section contains the following files, you can use the &lt;code&gt;_template_vuln&lt;/code&gt; folder to create a new chapter:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;README.md - vulnerability description and how to exploit it&lt;/li&gt;
&lt;li&gt;Intruder - a set of files to give to Burp Intruder&lt;/li&gt;
&lt;li&gt;Images - pictures for the README.md&lt;/li&gt;
&lt;li&gt;Files - some files referenced in the README.md&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You might also like the &lt;code&gt;Methodology and Resources&lt;/code&gt; folder :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/"&gt;Methodology and Resources&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Active%20Directory%20Attack.md"&gt;Active Directory Attack.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Linux%20-%20Persistence.md"&gt;Linux - Persistence.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Linux%20-%20Privilege%20Escalation.md"&gt;Linux - Privilege Escalation.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Metasploit%20-%20Cheatsheet.md"&gt;Metasploit - Cheatsheet.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Methodology%20and%20enumeration.md"&gt;Methodology and enumeration.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Network%20Pivoting%20Techniques.md"&gt;Network Pivoting Techniques.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Network%20Discovery.md"&gt;Network Discovery.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Reverse%20Shell%20Cheatsheet.md"&gt;Reverse Shell Cheatsheet.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Subdomains%20Enumeration.md"&gt;Subdomains Enumeration.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Download%20and%20Execute.md"&gt;Windows - Download and Execute.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Mimikatz.md"&gt;Windows - Mimikatz.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Persistence.md"&gt;Windows - Persistence.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Post%20Exploitation%20Koadic.md"&gt;Windows - Post Exploitation Koadic.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Privilege%20Escalation.md"&gt;Windows - Privilege Escalation.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Using%20credentials.md"&gt;Windows - Using credentials.md&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/CVE%20Exploits"&gt;CVE Exploits&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apache Struts 2 CVE-2013-2251 CVE-2017-5638 CVE-2018-11776_.py&lt;/li&gt;
&lt;li&gt;Apache Struts 2 CVE-2017-9805.py&lt;/li&gt;
&lt;li&gt;Apache Struts 2 CVE-2018-11776.py&lt;/li&gt;
&lt;li&gt;Docker API RCE.py&lt;/li&gt;
&lt;li&gt;Drupalgeddon2 CVE-2018-7600.rb&lt;/li&gt;
&lt;li&gt;Heartbleed CVE-2014-0160.py&lt;/li&gt;
&lt;li&gt;JBoss CVE-2015-7501.py&lt;/li&gt;
&lt;li&gt;Jenkins CVE-2015-8103.py&lt;/li&gt;
&lt;li&gt;Jenkins CVE-2016-0792.py&lt;/li&gt;
&lt;li&gt;Rails CVE-2019-5420.rb&lt;/li&gt;
&lt;li&gt;Shellshock CVE-2014-6271.py&lt;/li&gt;
&lt;li&gt;Tomcat CVE-2017-12617.py&lt;/li&gt;
&lt;li&gt;WebLogic CVE-2016-3510.py&lt;/li&gt;
&lt;li&gt;WebLogic CVE-2017-10271.py&lt;/li&gt;
&lt;li&gt;WebLogic CVE-2018-2894.py&lt;/li&gt;
&lt;li&gt;WebSphere CVE-2015-7450.py&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You want more ? Check the &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/BOOKS.md"&gt;Books&lt;/a&gt; and &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/YOUTUBE.md"&gt;Youtube videos&lt;/a&gt; selections.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>swisskyrepo</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>cornellius-gp/gpytorch #24 in Python, This week</title><link>https://github.com/cornellius-gp/gpytorch</link><description>&lt;p&gt;&lt;i&gt;A highly efficient and modular implementation of Gaussian Processes in PyTorch&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-gpytorch-beta-release" class="anchor" aria-hidden="true" href="#gpytorch-beta-release"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GPyTorch (Beta Release)&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/cornellius-gp/gpytorch" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/086e31820ce909a5325c4529fb5f9ff12a2d4ae1/68747470733a2f2f7472617669732d63692e6f72672f636f726e656c6c6975732d67702f677079746f7263682e7376673f6272616e63683d6d6173746572" alt="Build status" data-canonical-src="https://travis-ci.org/cornellius-gp/gpytorch.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gpytorch.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0658d8fb97af292063f7b818705b541df283c035/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f677079746f7263682f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/gpytorch/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://forthebadge.com" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/eae52829d6125ed81803704fdbcb158c1160e528/68747470733a2f2f666f7274686562616467652e636f6d2f696d616765732f6261646765732f616765732d31322e737667" alt="forthebadge" data-canonical-src="https://forthebadge.com/images/badges/ages-12.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;News!&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Beta release is currently out! Note that it &lt;strong&gt;requires PyTorch &amp;gt;= 1.3&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;If you need to install the alpha release (we recommend you use the latest version though!), check out &lt;a href="https://github.com/cornellius-gp/gpytorch/tree/alpha"&gt;the alpha release&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GPyTorch is a Gaussian process library implemented using PyTorch. GPyTorch is designed for creating scalable, flexible, and modular Gaussian process models with ease.&lt;/p&gt;
&lt;p&gt;Internally, GPyTorch differs from many existing approaches to GP inference by performing all inference operations using modern numerical linear algebra techniques like preconditioned conjugate gradients. Implementing a scalable GP method is as simple as providing a matrix multiplication routine with the kernel matrix and its derivative via our &lt;code&gt;LazyTensor&lt;/code&gt; interface, or by composing many of our already existing &lt;code&gt;LazyTensors&lt;/code&gt;. This allows not only for easy implementation of popular scalable GP techniques, but often also for significantly improved utilization of GPU computing compared to solvers based on the Cholesky decomposition.&lt;/p&gt;
&lt;p&gt;GPyTorch provides (1) significant GPU acceleration (through MVM based inference); (2) state-of-the-art implementations of the latest algorithmic advances for scalability and flexibility (&lt;a href="http://proceedings.mlr.press/v37/wilson15.pdf" rel="nofollow"&gt;SKI/KISS-GP&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1711.03481" rel="nofollow"&gt;stochastic Lanczos expansions&lt;/a&gt;, &lt;a href="https://arxiv.org/pdf/1803.06058.pdf" rel="nofollow"&gt;LOVE&lt;/a&gt;, &lt;a href="https://arxiv.org/pdf/1802.08903.pdf" rel="nofollow"&gt;SKIP&lt;/a&gt;, &lt;a href="https://arxiv.org/pdf/1611.00336.pdf" rel="nofollow"&gt;stochastic variational&lt;/a&gt; &lt;a href="http://proceedings.mlr.press/v51/wilson16.pdf" rel="nofollow"&gt;deep kernel learning&lt;/a&gt;, ...); (3) easy integration with deep learning frameworks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-examples-and-tutorials" class="anchor" aria-hidden="true" href="#examples-and-tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples and Tutorials&lt;/h2&gt;
&lt;p&gt;See our numerous &lt;a href="http://github.com/cornellius-gp/gpytorch/blob/master/examples"&gt;&lt;strong&gt;examples and tutorials&lt;/strong&gt;&lt;/a&gt; on how to construct all sorts of models in GPyTorch. These example notebooks and a walk through of GPyTorch are also available at our &lt;strong&gt;ReadTheDocs page &lt;a href="https://gpytorch.readthedocs.io/en/latest/index.html" rel="nofollow"&gt;here&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Requirements&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python &amp;gt;= 3.6&lt;/li&gt;
&lt;li&gt;PyTorch &amp;gt;= 1.3&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;N.B.&lt;/strong&gt; GPyTorch will not run on PyTorch 0.4.1 or earlier versions.&lt;/p&gt;
&lt;p&gt;First make sure that you have PyTorch (`&amp;gt;= 1.3&lt;/p&gt;
&lt;p&gt;`) installed using the appropriate command from &lt;a href="https://pytorch.org/get-started/locally/" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Then install GPyTorch using pip or conda:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install gpytorch
conda install gpytorch -c gpytorch&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To use packages globally but install GPyTorch as a user-only package, use &lt;code&gt;pip install --user&lt;/code&gt; above.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-latest-unstable-version" class="anchor" aria-hidden="true" href="#latest-unstable-version"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latest (unstable) version&lt;/h4&gt;
&lt;p&gt;To get the latest (unstable) version, run&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install git+https://github.com/cornellius-gp/gpytorch.git&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-citing-us" class="anchor" aria-hidden="true" href="#citing-us"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citing Us&lt;/h2&gt;
&lt;p&gt;If you use GPyTorch, please cite the following papers:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1809.11165" rel="nofollow"&gt;Gardner, Jacob R., Geoff Pleiss, David Bindel, Kilian Q. Weinberger, and Andrew Gordon Wilson. "GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration." In Advances in Neural Information Processing Systems (2018).&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;@inproceedings{gardner2018gpytorch,
  title={GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration},
  author={Gardner, Jacob R and Pleiss, Geoff and Bindel, David and Weinberger, Kilian Q and Wilson, Andrew Gordon},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;For &lt;strong&gt;tutorials and examples&lt;/strong&gt;, check out &lt;a href="https://github.com/cornellius-gp/gpytorch/tree/master/examples"&gt;the examples folder&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For in-depth &lt;strong&gt;documentation&lt;/strong&gt;, check out our &lt;a href="http://gpytorch.readthedocs.io/" rel="nofollow"&gt;read the docs&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-development" class="anchor" aria-hidden="true" href="#development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development&lt;/h2&gt;
&lt;p&gt;To run the unit tests:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -m unittest&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By default, the random seeds are locked down for some of the tests.
If you want to run the tests without locking down the seed, run&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;UNLOCK_SEED=true python -m unittest&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Please lint the code with &lt;code&gt;flake8&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install flake8  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; if not already installed&lt;/span&gt;
flake8&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-the-team" class="anchor" aria-hidden="true" href="#the-team"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Team&lt;/h2&gt;
&lt;p&gt;GPyTorch is primarily maintained by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://github.com/jacobrgardner"&gt;Jake Gardner&lt;/a&gt; (Uber AI Labs)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://github.com/gpleiss"&gt;Geoff Pleiss&lt;/a&gt; (Cornell University)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://kilian.cs.cornell.edu/" rel="nofollow"&gt;Kilian Weinberger&lt;/a&gt; (Cornell University)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://people.orie.cornell.edu/andrew/" rel="nofollow"&gt;Andrew Gordon Wilson&lt;/a&gt; (Cornell University)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://research.fb.com/people/balandat-max/" rel="nofollow"&gt;Max Balandat&lt;/a&gt; (Facebook)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0c115437df284dad869f6254be0daf42d2d32d9a/68747470733a2f2f6272616e642e636f726e656c6c2e6564752f6173736574732f696d616765732f646f776e6c6f6164732f6c6f676f732f636f726e656c6c5f6c6f676f5f73696d706c652f636f726e656c6c5f6c6f676f5f73696d706c652e737667"&gt;&lt;img width="300" src="https://camo.githubusercontent.com/0c115437df284dad869f6254be0daf42d2d32d9a/68747470733a2f2f6272616e642e636f726e656c6c2e6564752f6173736574732f696d616765732f646f776e6c6f6164732f6c6f676f732f636f726e656c6c5f6c6f676f5f73696d706c652f636f726e656c6c5f6c6f676f5f73696d706c652e737667" alt="Cornell Logo" data-canonical-src="https://brand.cornell.edu/assets/images/downloads/logos/cornell_logo_simple/cornell_logo_simple.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/cornellius-gp/cornellius-gp.github.io/master/static/media/facebook_logo.2835357a.png"&gt;&lt;img width="300" src="https://raw.githubusercontent.com/cornellius-gp/cornellius-gp.github.io/master/static/media/facebook_logo.2835357a.png" alt="Facebook Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/13804bb567d948c1bd440eed09f5ee28ff8cd6c9/68747470733a2f2f677079746f7263682e61692f7374617469632f6d656469612f756265725f61695f686f72697a6f6e74616c2e66653961623635332e706e67"&gt;&lt;img width="300" src="https://camo.githubusercontent.com/13804bb567d948c1bd440eed09f5ee28ff8cd6c9/68747470733a2f2f677079746f7263682e61692f7374617469632f6d656469612f756265725f61695f686f72697a6f6e74616c2e66653961623635332e706e67" alt="Uber AI Logo" data-canonical-src="https://gpytorch.ai/static/media/uber_ai_horizontal.fe9ab653.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
We would like to thank our other contributors including (but not limited to)  David Arbour, Eytan Bakshy, David Eriksson, Jared Frank, Sam Stanton, Bram Wallace, Ke Alexander Wang, Ruihan Wu.
&lt;h2&gt;&lt;a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;Development of GPyTorch is supported by funding from the &lt;a href="https://www.gatesfoundation.org/" rel="nofollow"&gt;Bill and Melinda Gates Foundation&lt;/a&gt;, the &lt;a href="https://www.nsf.gov/" rel="nofollow"&gt;National Science Foundation&lt;/a&gt;, and &lt;a href="https://www.sap.com/index.html" rel="nofollow"&gt;SAP&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>cornellius-gp</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>KubeOperator/KubeOperator #25 in Python, This week</title><link>https://github.com/KubeOperator/KubeOperator</link><description>&lt;p&gt;&lt;i&gt;KubeOperator 是一个开源项目，通过 Web UI 在 VMware、OpenStack、物理机上一键部署和管理生产级别的 Kubernetes 集群。&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-kubeoperator---从这里开启您的-kubernetes-之旅" class="anchor" aria-hidden="true" href="#kubeoperator---从这里开启您的-kubernetes-之旅"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;KubeOperator - 从这里开启您的 Kubernetes 之旅&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/KubeOperatpr/KubeOperatpr/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/7197a397ba1baf73679f3cf0edf68d821c35ae52/687474703a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d61706163686525323076322d626c75652e737667" alt="License" data-canonical-src="http://img.shields.io/badge/license-apache%20v2-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.python.org/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d4c11ac2b538cba463dfd1e43d05fe4f30f2d33d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d677265656e2e7376673f7374796c653d706c6173746963" alt="Python3" data-canonical-src="https://img.shields.io/badge/python-3.6-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.djangoproject.com/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/35798c7a6bb116ad2e8d420db49766bce91239b1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646a616e676f2d322e312d627269676874677265656e2e7376673f7374796c653d706c6173746963" alt="Django" data-canonical-src="https://img.shields.io/badge/django-2.1-brightgreen.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.ansible.com/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/dbfb9037d993ab109b0dd41252b2aabcd703e4a5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616e7369626c652d322e362e352d626c75652e7376673f7374796c653d706c6173746963" alt="Ansible" data-canonical-src="https://img.shields.io/badge/ansible-2.6.5-blue.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.angular.cn/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9829fdfaae3736e19d738b29efaeec4aaf21c61c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616e67756c61722d372e302e342d7265642e7376673f7374796c653d706c6173746963" alt="Angular" data-canonical-src="https://img.shields.io/badge/angular-7.0.4-red.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;KubeOperator 是一个开源项目，在离线网络环境下，通过可视化 Web UI 在 VMware、Openstack 或者物理机上规划、部署和管理生产级别的 Kubernetes 集群。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/KubeOperator/docs/blob/master/website/static/img/overview.png?raw=true"&gt;&lt;img src="https://github.com/KubeOperator/docs/raw/master/website/static/img/overview.png?raw=true" alt="overview" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-web-ui-展示" class="anchor" aria-hidden="true" href="#web-ui-展示"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web UI 展示&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/KubeOperator/docs/blob/master/website/static/img/kubeoperator-ui.jpg?raw=true"&gt;&lt;img src="https://github.com/KubeOperator/docs/raw/master/website/static/img/kubeoperator-ui.jpg?raw=true" alt="overview" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;更多功能截屏请查看：&lt;a href="https://docs.kubeoperator.io/kubeoperator-v2.1/screenshot" rel="nofollow"&gt;https://docs.kubeoperator.io/kubeoperator-v2.1/screenshot&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-整体架构" class="anchor" aria-hidden="true" href="#整体架构"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;整体架构&lt;/h2&gt;
&lt;p&gt;KubeOperator 使用 Terraform 在 IaaS 平台上自动创建主机（用户也可以自行准备主机，比如物理机或者虚机），通过 Ansible 完成自动化部署和变更操作，支持 Kubernetes 集群 从 Day 0 规划，到 Day 1 部署，到 Day 2 运维及变更的全生命周期管理。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/KubeOperator/docs/blob/master/website/static/img/KubeOperator.jpeg?raw=true"&gt;&lt;img src="https://github.com/KubeOperator/docs/raw/master/website/static/img/KubeOperator.jpeg?raw=true" alt="overview" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-技术优势" class="anchor" aria-hidden="true" href="#技术优势"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;技术优势&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;按需创建：调用云平台 API，一键快速创建和部署 Kubernetes 集群 (即 Kubernetes as a Service)；&lt;/li&gt;
&lt;li&gt;按需伸缩：快速伸缩 Kubernetes 集群，优化资源使用效率；&lt;/li&gt;
&lt;li&gt;按需修补：快速升级和修补 Kubernetes 集群，并与社区最新版本同步，保证安全性；&lt;/li&gt;
&lt;li&gt;自我修复：通过重建故障节点确保集群可用性；&lt;/li&gt;
&lt;li&gt;离线部署：持续更新包括 Kubernetes 及常用组件的离线包；&lt;/li&gt;
&lt;li&gt;Multi-AZ 支持：通过把 Kubernetes 集群 Master 节点分布在不同的故障域上确保的高可用；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-demo-视频使用文档" class="anchor" aria-hidden="true" href="#demo-视频使用文档"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Demo 视频、使用文档&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://kubeoperator-1256577600.file.myqcloud.com/video/KubeOperator2.1.mp4" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="tv" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4fa.png"&gt;📺&lt;/g-emoji&gt;8 分钟演示视频&lt;/a&gt;：详细演示 KubeOperator 的功能。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.kubeoperator.io/" rel="nofollow"&gt;&lt;g-emoji class="g-emoji" alias="books" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4da.png"&gt;📚&lt;/g-emoji&gt;安装及使用文档&lt;/a&gt;：包括 KubeOperator 安装文档、使用文档、功能截屏、常见问题等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-kubernetes-离线安装包" class="anchor" aria-hidden="true" href="#kubernetes-离线安装包"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Kubernetes 离线安装包&lt;/h2&gt;
&lt;p&gt;KubeOperator 提供完整的离线 Kubernetes 安装包（包括 Kubernetes、Docker、etcd、Dashboard、Promethus、OS 补丁等），每个安装包会被构建成一个独立容器镜像供 KubeOperator 使用，具体信息请参考：&lt;a href="https://github.com/KubeOperator/k8s-package"&gt;k8s-package&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-版本规划" class="anchor" aria-hidden="true" href="#版本规划"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;版本规划&lt;/h2&gt;
&lt;p&gt;v1.0 （已发布）&lt;/p&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 提供原生 Kubernetes 的离线包仓库；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持一主多节点部署模式；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持离线环境下的一键自动化部署，可视化展示集群部署进展和结果；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 内置 Kubernetes 常用系统应用的安装，包括 Registry、Promethus、Dashboard、Traefik Ingress、Helm 等；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 提供简易明了的 Kubernetes 集群运行状况面板；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 NFS 作为持久化存储；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Flannel 网络插件；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Kubernetes 集群手动部署模式（自行准备主机和 NFS）；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;v2.0 （已发布）&lt;/p&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持调用 VMware vCenter API 自动创建集群主机；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 VMware vSAN 、VMFS/NFS 作为持久化存储；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Multi AZ，支持多主多节点部署模式；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Calico 网络插件；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 内置 Weave Scope；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持通过 F5 BIG-IP Controller 对外暴露服务（Nodeport mode, 七层和四层服务都支持）；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;v2.1 （已发布）&lt;/p&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Openstack 云平台；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Openstack Cinder 作为持久化存储；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Kubernetes 集群升级 （Day 2）；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Kubernetes 集群扩缩容（Day 2）；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Kubernetes 集群备份与恢复（Day 2）；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 Kubernetes 集群健康检查与诊断（Day 2）；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; 支持 &lt;a href="https://github.com/webkubectl/webkubectl"&gt;webkubectl&lt;/a&gt; ；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;v2.2 （计划中，预计 2019.12.31 发布）&lt;/p&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 国际化支持；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 集成 KubeApps 应用商店；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 支持 VMware NSX-T；&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 日志收集及管理方案；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-沟通交流" class="anchor" aria-hidden="true" href="#沟通交流"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;沟通交流&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;技术交流 QQ 群：825046920；&lt;/li&gt;
&lt;li&gt;技术支持邮箱：&lt;a href="mailto:support@fit2cloud.com"&gt;support@fit2cloud.com&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;微信群： 搜索微信号 wh_it0224，添加好友，备注（城市-github用户名）, 验证通过会加入群聊；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-致谢" class="anchor" aria-hidden="true" href="#致谢"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;致谢&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/hashicorp/terraform"&gt;Terraform&lt;/a&gt;: KubeOperator 采用 Terraform 来自动创建虚机；&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/vmware/clarity/"&gt;Clarity&lt;/a&gt;: KubeOperator 采用 Clarity 作为前端 Web 框架；&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ansible/ansible"&gt;Ansible&lt;/a&gt;: KubeOperator 采用 Ansible 作为自动化部署工具；&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/easzlab/kubeasz"&gt;kubeasz&lt;/a&gt;: 提供各种 Kubernetes Ansible 脚本；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright (c) 2014-2019 FIT2CLOUD 飞致云&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.fit2cloud.com" rel="nofollow"&gt;https://www.fit2cloud.com&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;KubeOperator is licensed under the Apache License, Version 2.0.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>KubeOperator</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item></channel></rss>