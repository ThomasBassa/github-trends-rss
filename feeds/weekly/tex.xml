<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: TeX, This week</title><link>https://github.com/trending/tex?since=weekly</link><description>The top repositories on GitHub for tex, measured weekly</description><pubDate>Thu, 28 Nov 2019 01:06:12 GMT</pubDate><lastBuildDate>Thu, 28 Nov 2019 01:06:12 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>HarisIqbal88/PlotNeuralNet #1 in TeX, This week</title><link>https://github.com/HarisIqbal88/PlotNeuralNet</link><description>&lt;p&gt;&lt;i&gt;Latex code for making neural networks diagrams&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-plotneuralnet" class="anchor" aria-hidden="true" href="#plotneuralnet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PlotNeuralNet&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://doi.org/10.5281/zenodo.2526396" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/89c8c312f40c2d237b2319aececd5740a147b11c/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e323532363339362e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.2526396.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Latex code for drawing neural networks for reports and presentation. Have a look into examples to see how they are made. Additionally, lets consolidate any improvements that you make and fix any bugs to help more people with this code.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Install the following packages on Ubuntu.
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ubuntu 16.04&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install texlive-latex-extra
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ubuntu 18.04.2
Base on this &lt;a href="https://gist.github.com/rain1024/98dd5e2c6c8c28f9ea9d"&gt;website&lt;/a&gt;, please install the following packages.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install texlive-latex-base
sudo apt-get install texlive-fonts-recommended
sudo apt-get install texlive-fonts-extra
sudo apt-get install texlive-latex-extra
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Execute the example as followed.
&lt;pre&gt;&lt;code&gt;cd pyexamples/
bash ../tikzmake.sh test_simple
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-todo" class="anchor" aria-hidden="true" href="#todo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TODO&lt;/h2&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; Python interface&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Add easy legend functionality&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Add more layer shapes like TruncatedPyramid, 2DSheet etc&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Add examples for RNN and likes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-latex-usage" class="anchor" aria-hidden="true" href="#latex-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latex usage&lt;/h2&gt;
&lt;p&gt;See &lt;a href="examples"&gt;&lt;code&gt;examples&lt;/code&gt;&lt;/a&gt; directory for usage.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-python-usage" class="anchor" aria-hidden="true" href="#python-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python usage&lt;/h2&gt;
&lt;p&gt;First, create a new directory and a new Python file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mkdir my_project
$ cd my_project
vim my_arch.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add the following code to your new file:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; sys
sys.path.append(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;../&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;from&lt;/span&gt; pycore.tikzeng &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; defined your arch&lt;/span&gt;
arch &lt;span class="pl-k"&gt;=&lt;/span&gt; [
    to_head( &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;..&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; ),
    to_cor(),
    to_begin(),
    to_Conv(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;conv1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;512&lt;/span&gt;, &lt;span class="pl-c1"&gt;64&lt;/span&gt;, &lt;span class="pl-v"&gt;offset&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;(0,0,0)&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;to&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;(0,0,0)&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;64&lt;/span&gt;, &lt;span class="pl-v"&gt;depth&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;64&lt;/span&gt;, &lt;span class="pl-v"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt; ),
    to_Pool(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;pool1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;offset&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;(0,0,0)&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;to&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;(conv1-east)&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;),
    to_Conv(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;conv2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-c1"&gt;64&lt;/span&gt;, &lt;span class="pl-v"&gt;offset&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;(1,0,0)&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;to&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;(pool1-east)&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;32&lt;/span&gt;, &lt;span class="pl-v"&gt;depth&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;32&lt;/span&gt;, &lt;span class="pl-v"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt; ),
    to_connection( &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;pool1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;conv2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;),
    to_Pool(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;pool2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;offset&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;(0,0,0)&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;to&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;(conv2-east)&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;28&lt;/span&gt;, &lt;span class="pl-v"&gt;depth&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;28&lt;/span&gt;, &lt;span class="pl-v"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;),
    to_SoftMax(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;soft1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;10&lt;/span&gt; ,&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;(3,0,0)&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;(pool1-east)&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;caption&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;SOFT&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;  ),
    to_connection(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;pool2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;soft1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;),
    to_end()
    ]

&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;main&lt;/span&gt;():
    namefile &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;str&lt;/span&gt;(sys.argv[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]).split(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;.&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
    to_generate(arch, namefile &lt;span class="pl-k"&gt;+&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;.tex&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; )

&lt;span class="pl-k"&gt;if&lt;/span&gt; &lt;span class="pl-c1"&gt;__name__&lt;/span&gt; &lt;span class="pl-k"&gt;==&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;__main__&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;:
    main()&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, run the program as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bash ../tikzmake.sh my_arch
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;p&gt;Following are some network representations:&lt;/p&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/17570785/50308846-c2231880-049c-11e9-8763-3daa1024de78.png"&gt;&lt;img src="https://user-images.githubusercontent.com/17570785/50308846-c2231880-049c-11e9-8763-3daa1024de78.png" width="85%" height="85%" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h6 align="center"&gt;&lt;a id="user-content-fcn-8" class="anchor" aria-hidden="true" href="#fcn-8"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FCN-8&lt;/h6&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/17570785/50308873-e2eb6e00-049c-11e9-9587-9da6bdec011b.png"&gt;&lt;img src="https://user-images.githubusercontent.com/17570785/50308873-e2eb6e00-049c-11e9-9587-9da6bdec011b.png" width="85%" height="85%" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h6 align="center"&gt;&lt;a id="user-content-fcn-32" class="anchor" aria-hidden="true" href="#fcn-32"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FCN-32&lt;/h6&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/17570785/50308911-03b3c380-049d-11e9-92d9-ce15669017ad.png"&gt;&lt;img src="https://user-images.githubusercontent.com/17570785/50308911-03b3c380-049d-11e9-92d9-ce15669017ad.png" width="85%" height="85%" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h6 align="center"&gt;&lt;a id="user-content-holistically-nested-edge-detection" class="anchor" aria-hidden="true" href="#holistically-nested-edge-detection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Holistically-Nested Edge Detection&lt;/h6&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>HarisIqbal88</author><guid isPermaLink="false">https://github.com/HarisIqbal88/PlotNeuralNet</guid><pubDate>Thu, 28 Nov 2019 00:01:00 GMT</pubDate></item><item><title>mohuangrui/ucasthesis #2 in TeX, This week</title><link>https://github.com/mohuangrui/ucasthesis</link><description>&lt;p&gt;&lt;i&gt; [最新样式] 中国科学院大学学位论文 LaTeX 模板  LaTeX Thesis Template for the University of Chinese Academy of Sciences &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-ucasthesis-国科大学位论文-latex-模板-最新样式" class="anchor" aria-hidden="true" href="#ucasthesis-国科大学位论文-latex-模板-最新样式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;ucasthesis&lt;/code&gt; 国科大学位论文 LaTeX 模板 [最新样式]&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-模板下载" class="anchor" aria-hidden="true" href="#模板下载"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;模板下载&lt;/h2&gt;
&lt;p&gt;请在页面右边点击：&lt;strong&gt;Clone or download -&amp;gt; Download Zip&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-重要建议" class="anchor" aria-hidden="true" href="#重要建议"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;重要建议&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;关于 LaTeX 的知识性问题，请查阅 &lt;a href="https://github.com/mohuangrui/ucasthesis/wiki"&gt;LaTeX 知识小站&lt;/a&gt; 和 &lt;a href="https://en.wikibooks.org/wiki/LaTeX" rel="nofollow"&gt;LaTeX Wikibook&lt;/a&gt;，如发问需前往 &lt;a href="https://github.com/CTeX-org/forum"&gt;CTeX Forum&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;关于 ucasthesis 编译和设计的问题，请先读 &lt;strong&gt;模板使用说明.pdf&lt;/strong&gt;，如发问需遵从&lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98"&gt;提问流程&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;使用邮件传播 ucasthesis 时，请先删除 &lt;code&gt;artratex.bat&lt;/code&gt; 以防范 Dos 脚本的潜在风险。&lt;/li&gt;
&lt;li&gt;开题报告请见：&lt;a href="https://github.com/mohuangrui/ucasproposal"&gt;ucasproposal: 中国科学院大学开题报告 LaTeX 模板&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;书脊制作请见：&lt;a href="https://github.com/mohuangrui/latexspine"&gt;latexspine: LaTeX 书脊模板&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-模板简介" class="anchor" aria-hidden="true" href="#模板简介"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;模板简介&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ucasthesis 为撰写中国科学院大学&lt;strong&gt;本&lt;/strong&gt;、&lt;strong&gt;硕&lt;/strong&gt;、&lt;strong&gt;博&lt;/strong&gt;学位论文和&lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98#%E5%A6%82%E4%BD%95%E5%A1%AB%E5%86%99%E5%8D%9A%E5%A3%AB%E5%90%8E%E7%9A%84-frontinfotex-"&gt;&lt;strong&gt;博后&lt;/strong&gt;&lt;/a&gt;报告的 LaTeX 模版。ucasthesis 提供了简单明了的&lt;strong&gt;模板使用说明.pdf&lt;/strong&gt;。无论你是否具有 LaTeX 使用经验，都可较为轻松地使用以完成学位论文的撰写和排版。谢谢大家的测试、反馈和支持，我们一起的努力让 ucasthesis 非常荣幸地得到了国科大本科部陆晴老师、本科部学位办丁云云老师和中科院数学与系统科学研究院吴凌云研究员的支持，并得到吴凌云学长在 &lt;a href="http://www.ctex.org/HomePage" rel="nofollow"&gt;CTEX&lt;/a&gt; 的发布。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;考虑到许多同学可能缺乏 LaTeX 使用经验，ucasthesis 将 LaTeX 的复杂性高度封装，开放出简单的接口，以便轻易使用。同时，对用 LaTeX 撰写论文的一些主要难题，如制图、制表、文献索引等，进行了详细说明，并提供了相应的代码样本，理解了上述问题后，对于初学者而言，使用此模板撰写学位论文将不存在实质性的困难。所以，如果你是初学者，请不要直接放弃，因为同样为初学者的我，十分明白让 LaTeX 简单易用的重要性，而这正是 ucasthesis 所追求和体现的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;此中国科学院大学学位论文模板 ucasthesis 基于中科院数学与系统科学研究院吴凌云研究员的 CASthesis 模板发展而来。当前 ucasthesis 模板满足最新的中国科学院大学学位论文撰写要求和封面设定。兼顾操作系统：Windows，Linux，MacOS 和 LaTeX 编译引擎：pdflatex，xelatex，lualatex。支持中文书签、中文渲染、中文粗体显示、拷贝 PDF 中的文本到其他文本编辑器等特性（&lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E5%AD%97%E4%BD%93%E9%85%8D%E7%BD%AE"&gt;Windows 系统 PDF 拷贝乱码的解决方案需见：字体配置&lt;/a&gt;）。此外，对模板的文档结构进行了精心设计，撰写了编译脚本提高模板的易用性和使用效率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ucasthesis 的目标在于简化学位论文的撰写，利用 LaTeX 格式与内容分离的特征，模板将格式设计好后，作者可只需关注论文内容。 同时，ucasthesis 有着整洁一致的代码结构和扼要的注解，对文档的仔细阅读可为初学者提供一个学习 LaTeX 的窗口。此外，模板的架构十分注重通用性，事实上，ucasthesis 不仅是国科大学位论文模板，同时，通过少量修改即可成为使用 LaTeX 撰写中英文文章或书籍的通用模板，并为使用者的个性化设定提供了接口。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-重要通知" class="anchor" aria-hidden="true" href="#重要通知"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;重要通知&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;2019-10-21&lt;/code&gt; 模板样式进行了修改，请查看下面的修改描述，以决定是否需要更新。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-更新记录" class="anchor" aria-hidden="true" href="#更新记录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;更新记录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-10-12&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/198"&gt;huiwenzhang, issue #198&lt;/a&gt; 修复&lt;code&gt;mainmatter&lt;/code&gt;下&lt;code&gt;\chapter*&lt;/code&gt;的页眉错误。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-10-12&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/195"&gt;Fancy0609, muzimuzhi, issue #195&lt;/a&gt; 调整由&lt;code&gt;AutoFakeBold&lt;/code&gt;控制的伪粗体加粗程度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-10-11&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/190"&gt;Pantrick, issue #190&lt;/a&gt; 采用 &lt;a href="https://github.com/muzimuzhi"&gt;muzimuzhi&lt;/a&gt; 提供的方法实现&lt;code&gt;\advisor{}&lt;/code&gt;和&lt;code&gt;\institute{}&lt;/code&gt;的自动换行功能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-08-01&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/183"&gt;vectorliu, issue #183&lt;/a&gt; 修改英文模式下的&lt;code&gt;plain&lt;/code&gt;选项为&lt;code&gt;scheme=plain&lt;/code&gt;以消除对&lt;code&gt;Algorithm&lt;/code&gt;样式的修改。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-06-15&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/177"&gt;HaorenWang, issue #177&lt;/a&gt; 调整矢量、矩阵、张量字体样式。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-06-09&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/170"&gt;DRjy, issue #170&lt;/a&gt; 轻微缩减目录中编号与标题的间距；根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/174"&gt;e71828, issue #174&lt;/a&gt; 轻微增加页眉中编号与标题的间距。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-05-25&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/169"&gt;CDMA2019, issue #169&lt;/a&gt; 提供横排图表环境下页眉页脚的横排，具体使用见 &lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E6%A8%AA%E6%8E%92%E5%9B%BE%E8%A1%A8"&gt;横排图表&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-04-24&lt;/code&gt; 拓展模版兼容 &lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98#%E5%A6%82%E4%BD%95%E5%A1%AB%E5%86%99%E5%8D%9A%E5%A3%AB%E5%90%8E%E7%9A%84-frontinfotex-"&gt;博后报告&lt;/a&gt;。修复 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/156"&gt;gsp2014, issue #156&lt;/a&gt; 文献引用中的连字符的间断显示和上标引用中逗号下沉。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-04-19&lt;/code&gt; 修复 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/117"&gt;nihaomiao, issue #117&lt;/a&gt;&lt;code&gt;\mathbf&lt;/code&gt;失效问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-04-16&lt;/code&gt; 修复国际生需要的&lt;code&gt;plain&lt;/code&gt;模式下无法改变英文章标题字体大小的问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-04-09&lt;/code&gt; 对部分宏命令进行调整，无功能及样式上的修改。若需更新，建议参考 &lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E6%9B%B4%E6%96%B0%E6%8C%87%E5%8D%97"&gt;更新指南&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-04-04&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/134"&gt;liuy334, songchunlin, issue #134&lt;/a&gt; ，调整行距使&lt;code&gt;LaTeX&lt;/code&gt;版与&lt;code&gt;Word&lt;/code&gt;版的行数和每行字数相一致。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-03-28&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/49"&gt;zssasa, allenwoods, issue #49&lt;/a&gt; ，修复&lt;code&gt;bicaption&lt;/code&gt;对&lt;code&gt;longtable&lt;/code&gt;的兼容性。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/133"&gt;BowenHou, issue #133&lt;/a&gt; ，使下划线能对长标题自动换行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-03-25&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/127"&gt;DRjy, muzimuzhi, issue #127&lt;/a&gt; ，为&lt;code&gt;摘要&lt;/code&gt;等无需在目录中显示的结构元素建立书签。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/130"&gt;muzimuzhi, issue #130&lt;/a&gt; ，修正对&lt;code&gt;\voffset&lt;/code&gt;的使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-03-14&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/121"&gt;opt-gaobin, issue #121&lt;/a&gt; ，修正中文标点使下划线断掉的问题。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/120"&gt;Guoqiang Zhang, email; weili-ict, issue #120&lt;/a&gt; ，修复&lt;code&gt;\proofname&lt;/code&gt;命令对2015年及更早&lt;code&gt;LaTeX&lt;/code&gt;编译器的兼容性问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-02-20&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/100"&gt;opt-gaobin, issue #100&lt;/a&gt; ，增加定理、定义、证明等数学环境。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/102"&gt;DRjy, issue #102&lt;/a&gt; ，调整&lt;code&gt;\mathcal&lt;/code&gt;字体样式。根据 [zike Liu, email] ，适当缩减目录列表的缩进。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/105"&gt;xiaoyaoE, issue #105&lt;/a&gt; ，使数字字体和英文字体一致。完善中文版和国际版之间的中英格式切换。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-01-10&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/57"&gt;mnpengjk, issue #57&lt;/a&gt; ， 将公式编号前加点纳入模版默认，更多讨论可见：&lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E7%90%90%E5%B1%91%E7%BB%86%E8%8A%82"&gt;琐屑细节&lt;/a&gt; 。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/95"&gt;yunyun2019, issue #95&lt;/a&gt; ，采用 &lt;a href="https://github.com/zepinglee"&gt;zepinglee&lt;/a&gt; 基于国标样式为&lt;code&gt;ucas&lt;/code&gt;所定制文献样式：&lt;a href="https://github.com/CTeX-org/gbt7714-bibtex-style/tree/ucas"&gt;ucas 样式分支&lt;/a&gt; ，文献样式更多讨论可见：&lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E6%96%87%E7%8C%AE%E6%A0%B7%E5%BC%8F"&gt;文献样式&lt;/a&gt;。根据 [邵岳林, email] ，将附录复原为常规的排版设置，若需将附录置于参考文献后，请见：&lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E7%90%90%E5%B1%91%E7%BB%86%E8%8A%82"&gt;琐屑细节&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2018-04-03&lt;/code&gt; 根据国科大本科部陆晴老师和本科部学位办丁云云老师的复审审核建议再次修复一些样式细节问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2018-04-02&lt;/code&gt; 模板进行了重大更新，修复了样式、字体、格式等许多问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;根据国科大本科部陆晴老师的建议对模版样式进行了诸多拓展和修正，并完善对本科生论文元素的兼容性。&lt;/li&gt;
&lt;li&gt;在 &lt;a href="https://github.com/CTeX-org/ctex-kit"&gt;ctex&lt;/a&gt; 开发者的帮助下解决了如何多次调用&lt;code&gt;Times New Roman&lt;/code&gt;而不导致黑体调用错误的问题。根据 [twn1993, email]，修复默认黑体为微软雅黑而不是&lt;code&gt;SimHei&lt;/code&gt;的问题。&lt;/li&gt;
&lt;li&gt;繁复折腾测试后终于找出一个在&lt;code&gt;ctex&lt;/code&gt;默认黑体替换粗宋体设定环境内全局&lt;code&gt;AutoFakeBold&lt;/code&gt;失效状态下折衷特定字体库不全条件下生僻字显示和系统默认字重不全条件下粗宋体显示以及不同操作系统下如何平衡上述字库自重矛盾还有根据操作系统自动调用所带有的&lt;code&gt;Times&lt;/code&gt;字体的方案。&lt;/li&gt;
&lt;li&gt;设定论文封面据英文学位名如自动切换。密级据是否填写自动显示。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2018-03-22&lt;/code&gt; 演示表标题居表上，加粗图表标注，设置长图表标题悬挂缩进（由于&lt;code&gt;bicaption&lt;/code&gt;宏包无法正确接受&lt;code&gt;caption&lt;/code&gt;宏包的&lt;code&gt;margin&lt;/code&gt;选项，图表中英标题第一行无法正确同步缩进，从而放弃第一行的缩进），强调多图中子图标题的规范使用，通过摘要和符号列表演示标题不在目录中显示却仍在页眉中显示。根据 [赵永明, email]，设置双语图表标题和&lt;code&gt;bicaption&lt;/code&gt;不在图形列表和表格列表中显示英文标题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2018-03-21&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/42"&gt;zhanglinbo, issue #42&lt;/a&gt; ，使用 &lt;a href="https://github.com/xiaoyao9933/UCASthesis"&gt;xiaoyao9933&lt;/a&gt; 制作的&lt;code&gt;ucas_logo.pdf&lt;/code&gt;使学校&lt;code&gt;logo&lt;/code&gt;放大不失真。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/41"&gt;Starsky Wong, issue #41&lt;/a&gt; ，设置标题英文设为&lt;code&gt;Times New Roman&lt;/code&gt;。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/29"&gt;will0n, issue #29&lt;/a&gt; ，&lt;a href="https://github.com/mohuangrui/ucasthesis/issues/26"&gt;Man-Ting-Fang, issue #26&lt;/a&gt; ，&lt;a href="https://github.com/mohuangrui/ucasthesis/issues/12"&gt;diyiliaoya, issue #12&lt;/a&gt; ，和 [赵永明, email] ，矫正一些格式细节问题。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/30"&gt;tangjie1992, issue #30&lt;/a&gt; ，配置算法环境。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2018-02-04&lt;/code&gt; 在 &lt;a href="https://github.com/CTeX-org/ctex-kit"&gt;ctex&lt;/a&gt; 开发者的帮助下修复误用字体命令导致的粗宋体异常。然后，将模板兼容性进一步扩展为兼容操作系统&lt;code&gt;Windows&lt;/code&gt;，&lt;code&gt;Linux&lt;/code&gt;，&lt;code&gt;MacOS&lt;/code&gt;和&lt;code&gt;LaTeX &lt;/code&gt;编译引擎&lt;code&gt;pdflatex&lt;/code&gt;，&lt;code&gt;xelatex&lt;/code&gt;，&lt;code&gt;lualatex&lt;/code&gt;。移除&lt;code&gt;microtype&lt;/code&gt;宏包以提高编译效率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2018-01-28&lt;/code&gt; 基于国科大&lt;code&gt;2018&lt;/code&gt;新版论文规范进行了重大修改，采用新的封面、声明、页眉页脚样式。展示标题中使用数学公式。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2017-05-14&lt;/code&gt; 根据 [赵永明, email] ，增加&lt;code&gt;\citepns{}&lt;/code&gt;和&lt;code&gt;\citetns{}&lt;/code&gt;命令提供上标引用下混合非上标引用的需求。根据 [臧光明, email] ，添加设定论文为&lt;code&gt;thesis&lt;/code&gt;或&lt;code&gt;dissertation&lt;/code&gt;的命令。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>mohuangrui</author><guid isPermaLink="false">https://github.com/mohuangrui/ucasthesis</guid><pubDate>Thu, 28 Nov 2019 00:02:00 GMT</pubDate></item><item><title>terryum/awesome-deep-learning-papers #3 in TeX, This week</title><link>https://github.com/terryum/awesome-deep-learning-papers</link><description>&lt;p&gt;&lt;i&gt;The most cited deep learning papers&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-awesome---most-cited-deep-learning-papers" class="anchor" aria-hidden="true" href="#awesome---most-cited-deep-learning-papers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Awesome - Most Cited Deep Learning Papers&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/sindresorhus/awesome"&gt;&lt;img src="https://camo.githubusercontent.com/13c4e50d88df7178ae1882a203ed57b641674f94/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667" alt="Awesome" data-canonical-src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[Notice] This list is not being maintained anymore because of the overwhelming amount of deep learning papers published every day since 2017.&lt;/p&gt;
&lt;p&gt;A curated list of the most cited deep learning papers (2012-2016)&lt;/p&gt;
&lt;p&gt;We believe that there exist &lt;em&gt;classic&lt;/em&gt; deep learning papers which are worth reading regardless of their application domain. Rather than providing overwhelming amount of papers, We would like to provide a &lt;em&gt;curated list&lt;/em&gt; of the awesome deep learning papers which are considered as &lt;em&gt;must-reads&lt;/em&gt; in certain research domains.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-background" class="anchor" aria-hidden="true" href="#background"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Background&lt;/h2&gt;
&lt;p&gt;Before this list, there exist other &lt;em&gt;awesome deep learning lists&lt;/em&gt;, for example, &lt;a href="https://github.com/kjw0612/awesome-deep-vision"&gt;Deep Vision&lt;/a&gt; and &lt;a href="https://github.com/kjw0612/awesome-rnn"&gt;Awesome Recurrent Neural Networks&lt;/a&gt;. Also, after this list comes out, another awesome list for deep learning beginners, called &lt;a href="https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap"&gt;Deep Learning Papers Reading Roadmap&lt;/a&gt;, has been created and loved by many deep learning researchers.&lt;/p&gt;
&lt;p&gt;Although the &lt;em&gt;Roadmap List&lt;/em&gt; includes lots of important deep learning papers, it feels overwhelming for me to read them all. As I mentioned in the introduction, I believe that seminal works can give us lessons regardless of their application domain. Thus, I would like to introduce &lt;strong&gt;top 100 deep learning papers&lt;/strong&gt; here as a good starting point of overviewing deep learning researches.&lt;/p&gt;
&lt;p&gt;To get the news for newly released papers everyday, follow my &lt;a href="https://twitter.com/TerryUm_ML" rel="nofollow"&gt;twitter&lt;/a&gt; or &lt;a href="https://www.facebook.com/terryum.io/" rel="nofollow"&gt;facebook page&lt;/a&gt;!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-awesome-list-criteria" class="anchor" aria-hidden="true" href="#awesome-list-criteria"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Awesome list criteria&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;A list of &lt;strong&gt;top 100 deep learning papers&lt;/strong&gt; published from 2012 to 2016 is suggested.&lt;/li&gt;
&lt;li&gt;If a paper is added to the list, another paper (usually from *More Papers from 2016" section) should be removed to keep top 100 papers. (Thus, removing papers is also important contributions as well as adding papers)&lt;/li&gt;
&lt;li&gt;Papers that are important, but failed to be included in the list, will be listed in &lt;em&gt;More than Top 100&lt;/em&gt; section.&lt;/li&gt;
&lt;li&gt;Please refer to &lt;em&gt;New Papers&lt;/em&gt; and &lt;em&gt;Old Papers&lt;/em&gt; sections for the papers published in recent 6 months or before 2012.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;(Citation criteria)&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt; 6 months&lt;/strong&gt; : &lt;em&gt;New Papers&lt;/em&gt; (by discussion)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2016&lt;/strong&gt; :  +60 citations or "More Papers from 2016"&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2015&lt;/strong&gt; :  +200 citations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2014&lt;/strong&gt; :  +400 citations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2013&lt;/strong&gt; :  +600 citations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2012&lt;/strong&gt; :  +800 citations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;~2012&lt;/strong&gt; : &lt;em&gt;Old Papers&lt;/em&gt; (by discussion)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please note that we prefer seminal deep learning papers that can be applied to various researches rather than application papers. For that reason, some papers that meet the criteria may not be accepted while others can be. It depends on the impact of the paper, applicability to other researches scarcity of the research domain, and so on.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We need your contributions!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you have any suggestions (missing papers, new papers, key researchers or typos), please feel free to edit and pull a request.
(Please read the &lt;a href="https://github.com/terryum/awesome-deep-learning-papers/blob/master/Contributing.md"&gt;contributing guide&lt;/a&gt; for further instructions, though just letting me know the title of papers can also be a big contribution to us.)&lt;/p&gt;
&lt;p&gt;(Update) You can download all top-100 papers with &lt;a href="https://github.com/terryum/awesome-deep-learning-papers/blob/master/fetch_papers.py"&gt;this&lt;/a&gt; and collect all authors' names with &lt;a href="https://github.com/terryum/awesome-deep-learning-papers/blob/master/get_authors.py"&gt;this&lt;/a&gt;. Also, &lt;a href="https://github.com/terryum/awesome-deep-learning-papers/blob/master/top100papers.bib"&gt;bib file&lt;/a&gt; for all top-100 papers are available. Thanks, doodhwala, &lt;a href="https://github.com/sunshinemyson"&gt;Sven&lt;/a&gt; and &lt;a href="https://github.com/grepinsight"&gt;grepinsight&lt;/a&gt;!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can anyone contribute the code for obtaining the statistics of the authors of Top-100 papers?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#understanding--generalization--transfer"&gt;Understanding / Generalization / Transfer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#optimization--training-techniques"&gt;Optimization / Training Techniques&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#unsupervised--generative-models"&gt;Unsupervised / Generative Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#convolutional-neural-network-models"&gt;Convolutional Network Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#image-segmentation--object-detection"&gt;Image Segmentation / Object Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#image--video--etc"&gt;Image / Video / Etc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#natural-language-processing--rnns"&gt;Natural Language Processing / RNNs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#speech--other-domain"&gt;Speech / Other Domain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#reinforcement-learning--robotics"&gt;Reinforcement Learning / Robotics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#more-papers-from-2016"&gt;More Papers from 2016&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;(More than Top 100)&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#new-papers"&gt;New Papers&lt;/a&gt; : Less than 6 months&lt;/li&gt;
&lt;li&gt;&lt;a href="#old-papers"&gt;Old Papers&lt;/a&gt; : Before 2012&lt;/li&gt;
&lt;li&gt;&lt;a href="#hw--sw--dataset"&gt;HW / SW / Dataset&lt;/a&gt; : Technical reports&lt;/li&gt;
&lt;li&gt;&lt;a href="#book--survey--review"&gt;Book / Survey / Review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#video-lectures--tutorials--blogs"&gt;Video Lectures / Tutorials / Blogs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#appendix-more-than-top-100"&gt;Appendix: More than Top 100&lt;/a&gt; : More papers not in the list&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3&gt;&lt;a id="user-content-understanding--generalization--transfer" class="anchor" aria-hidden="true" href="#understanding--generalization--transfer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Understanding / Generalization / Transfer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Distilling the knowledge in a neural network&lt;/strong&gt; (2015), G. Hinton et al. &lt;a href="http://arxiv.org/pdf/1503.02531" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deep neural networks are easily fooled: High confidence predictions for unrecognizable images&lt;/strong&gt; (2015), A. Nguyen et al. &lt;a href="http://arxiv.org/pdf/1412.1897" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;How transferable are features in deep neural networks?&lt;/strong&gt; (2014), J. Yosinski et al. &lt;a href="http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CNN features off-the-Shelf: An astounding baseline for recognition&lt;/strong&gt; (2014), A. Razavian et al. &lt;a href="http://www.cv-foundation.org//openaccess/content_cvpr_workshops_2014/W15/papers/Razavian_CNN_Features_Off-the-Shelf_2014_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learning and transferring mid-Level image representations using convolutional neural networks&lt;/strong&gt; (2014), M. Oquab et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Visualizing and understanding convolutional networks&lt;/strong&gt; (2014), M. Zeiler and R. Fergus &lt;a href="http://arxiv.org/pdf/1311.2901" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decaf: A deep convolutional activation feature for generic visual recognition&lt;/strong&gt; (2014), J. Donahue et al. &lt;a href="http://arxiv.org/pdf/1310.1531" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;a id="user-content-optimization--training-techniques" class="anchor" aria-hidden="true" href="#optimization--training-techniques"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Optimization / Training Techniques&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Training very deep networks&lt;/strong&gt; (2015), R. Srivastava et al. &lt;a href="http://papers.nips.cc/paper/5850-training-very-deep-networks.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Batch normalization: Accelerating deep network training by reducing internal covariate shift&lt;/strong&gt; (2015), S. Loffe and C. Szegedy &lt;a href="http://arxiv.org/pdf/1502.03167" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Delving deep into rectifiers: Surpassing human-level performance on imagenet classification&lt;/strong&gt; (2015), K. He et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dropout: A simple way to prevent neural networks from overfitting&lt;/strong&gt; (2014), N. Srivastava et al. &lt;a href="http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Adam: A method for stochastic optimization&lt;/strong&gt; (2014), D. Kingma and J. Ba &lt;a href="http://arxiv.org/pdf/1412.6980" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Improving neural networks by preventing co-adaptation of feature detectors&lt;/strong&gt; (2012), G. Hinton et al. &lt;a href="http://arxiv.org/pdf/1207.0580.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Random search for hyper-parameter optimization&lt;/strong&gt; (2012) J. Bergstra and Y. Bengio &lt;a href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;a id="user-content-unsupervised--generative-models" class="anchor" aria-hidden="true" href="#unsupervised--generative-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Unsupervised / Generative Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pixel recurrent neural networks&lt;/strong&gt; (2016), A. Oord et al. &lt;a href="http://arxiv.org/pdf/1601.06759v2.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Improved techniques for training GANs&lt;/strong&gt; (2016), T. Salimans et al. &lt;a href="http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unsupervised representation learning with deep convolutional generative adversarial networks&lt;/strong&gt; (2015), A. Radford et al. &lt;a href="https://arxiv.org/pdf/1511.06434v2" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DRAW: A recurrent neural network for image generation&lt;/strong&gt; (2015), K. Gregor et al. &lt;a href="http://arxiv.org/pdf/1502.04623" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generative adversarial nets&lt;/strong&gt; (2014), I. Goodfellow et al. &lt;a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Auto-encoding variational Bayes&lt;/strong&gt; (2013), D. Kingma and M. Welling &lt;a href="http://arxiv.org/pdf/1312.6114" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Building high-level features using large scale unsupervised learning&lt;/strong&gt; (2013), Q. Le et al. &lt;a href="http://arxiv.org/pdf/1112.6209" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;a id="user-content-convolutional-neural-network-models" class="anchor" aria-hidden="true" href="#convolutional-neural-network-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Convolutional Neural Network Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Rethinking the inception architecture for computer vision&lt;/strong&gt; (2016), C. Szegedy et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inception-v4, inception-resnet and the impact of residual connections on learning&lt;/strong&gt; (2016), C. Szegedy et al. &lt;a href="http://arxiv.org/pdf/1602.07261" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Identity Mappings in Deep Residual Networks&lt;/strong&gt; (2016), K. He et al. &lt;a href="https://arxiv.org/pdf/1603.05027v2.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deep residual learning for image recognition&lt;/strong&gt; (2016), K. He et al. &lt;a href="http://arxiv.org/pdf/1512.03385" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spatial transformer network&lt;/strong&gt; (2015), M. Jaderberg et al., &lt;a href="http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Going deeper with convolutions&lt;/strong&gt; (2015), C. Szegedy et al.  &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Very deep convolutional networks for large-scale image recognition&lt;/strong&gt; (2014), K. Simonyan and A. Zisserman &lt;a href="http://arxiv.org/pdf/1409.1556" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Return of the devil in the details: delving deep into convolutional nets&lt;/strong&gt; (2014), K. Chatfield et al. &lt;a href="http://arxiv.org/pdf/1405.3531" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OverFeat: Integrated recognition, localization and detection using convolutional networks&lt;/strong&gt; (2013), P. Sermanet et al. &lt;a href="http://arxiv.org/pdf/1312.6229" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Maxout networks&lt;/strong&gt; (2013), I. Goodfellow et al. &lt;a href="http://arxiv.org/pdf/1302.4389v4" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Network in network&lt;/strong&gt; (2013), M. Lin et al. &lt;a href="http://arxiv.org/pdf/1312.4400" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ImageNet classification with deep convolutional neural networks&lt;/strong&gt; (2012), A. Krizhevsky et al. &lt;a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;a id="user-content-image-segmentation--object-detection" class="anchor" aria-hidden="true" href="#image-segmentation--object-detection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image: Segmentation / Object Detection&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;You only look once: Unified, real-time object detection&lt;/strong&gt; (2016), J. Redmon et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fully convolutional networks for semantic segmentation&lt;/strong&gt; (2015), J. Long et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks&lt;/strong&gt; (2015), S. Ren et al. &lt;a href="http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fast R-CNN&lt;/strong&gt; (2015), R. Girshick &lt;a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rich feature hierarchies for accurate object detection and semantic segmentation&lt;/strong&gt; (2014), R. Girshick et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spatial pyramid pooling in deep convolutional networks for visual recognition&lt;/strong&gt; (2014), K. He et al. &lt;a href="http://arxiv.org/pdf/1406.4729" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Semantic image segmentation with deep convolutional nets and fully connected CRFs&lt;/strong&gt;, L. Chen et al. &lt;a href="https://arxiv.org/pdf/1412.7062" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learning hierarchical features for scene labeling&lt;/strong&gt; (2013), C. Farabet et al. &lt;a href="https://hal-enpc.archives-ouvertes.fr/docs/00/74/20/77/PDF/farabet-pami-13.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;a id="user-content-image--video--etc" class="anchor" aria-hidden="true" href="#image--video--etc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image / Video / Etc&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Image Super-Resolution Using Deep Convolutional Networks&lt;/strong&gt; (2016), C. Dong et al. &lt;a href="https://arxiv.org/pdf/1501.00092v3.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A neural algorithm of artistic style&lt;/strong&gt; (2015), L. Gatys et al. &lt;a href="https://arxiv.org/pdf/1508.06576" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deep visual-semantic alignments for generating image descriptions&lt;/strong&gt; (2015), A. Karpathy and L. Fei-Fei &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Show, attend and tell: Neural image caption generation with visual attention&lt;/strong&gt; (2015), K. Xu et al. &lt;a href="http://arxiv.org/pdf/1502.03044" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Show and tell: A neural image caption generator&lt;/strong&gt; (2015), O. Vinyals et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Long-term recurrent convolutional networks for visual recognition and description&lt;/strong&gt; (2015), J. Donahue et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VQA: Visual question answering&lt;/strong&gt; (2015), S. Antol et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Antol_VQA_Visual_Question_ICCV_2015_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DeepFace: Closing the gap to human-level performance in face verification&lt;/strong&gt; (2014), Y. Taigman et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Taigman_DeepFace_Closing_the_2014_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Large-scale video classification with convolutional neural networks&lt;/strong&gt; (2014), A. Karpathy et al. &lt;a href="http://vision.stanford.edu/pdf/karpathy14.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Two-stream convolutional networks for action recognition in videos&lt;/strong&gt; (2014), K. Simonyan et al. &lt;a href="http://papers.nips.cc/paper/5353-two-stream-convolutional-networks-for-action-recognition-in-videos.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;3D convolutional neural networks for human action recognition&lt;/strong&gt; (2013), S. Ji et al. &lt;a href="http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_JiXYY10.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;&lt;a id="user-content-natural-language-processing--rnns" class="anchor" aria-hidden="true" href="#natural-language-processing--rnns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Natural Language Processing / RNNs&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Neural Architectures for Named Entity Recognition&lt;/strong&gt; (2016), G. Lample et al. &lt;a href="http://aclweb.org/anthology/N/N16/N16-1030.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exploring the limits of language modeling&lt;/strong&gt; (2016), R. Jozefowicz et al. &lt;a href="http://arxiv.org/pdf/1602.02410" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Teaching machines to read and comprehend&lt;/strong&gt; (2015), K. Hermann et al. &lt;a href="http://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Effective approaches to attention-based neural machine translation&lt;/strong&gt; (2015), M. Luong et al. &lt;a href="https://arxiv.org/pdf/1508.04025" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conditional random fields as recurrent neural networks&lt;/strong&gt; (2015), S. Zheng and S. Jayasumana. &lt;a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zheng_Conditional_Random_Fields_ICCV_2015_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memory networks&lt;/strong&gt; (2014), J. Weston et al. &lt;a href="https://arxiv.org/pdf/1410.3916" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Neural turing machines&lt;/strong&gt; (2014), A. Graves et al. &lt;a href="https://arxiv.org/pdf/1410.5401" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Neural machine translation by jointly learning to align and translate&lt;/strong&gt; (2014), D. Bahdanau et al. &lt;a href="http://arxiv.org/pdf/1409.0473" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sequence to sequence learning with neural networks&lt;/strong&gt; (2014), I. Sutskever et al. &lt;a href="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learning phrase representations using RNN encoder-decoder for statistical machine translation&lt;/strong&gt; (2014), K. Cho et al. &lt;a href="http://arxiv.org/pdf/1406.1078" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A convolutional neural network for modeling sentences&lt;/strong&gt; (2014), N. Kalchbrenner et al. &lt;a href="http://arxiv.org/pdf/1404.2188v1" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Convolutional neural networks for sentence classification&lt;/strong&gt; (2014), Y. Kim &lt;a href="http://arxiv.org/pdf/1408.5882" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Glove: Global vectors for word representation&lt;/strong&gt; (2014), J. Pennington et al. &lt;a href="http://anthology.aclweb.org/D/D14/D14-1162.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Distributed representations of sentences and documents&lt;/strong&gt; (2014), Q. Le and T. Mikolov &lt;a href="http://arxiv.org/pdf/1405.4053" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Distributed representations of words and phrases and their compositionality&lt;/strong&gt; (2013), T. Mikolov et al. &lt;a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Efficient estimation of word representations in vector space&lt;/strong&gt; (2013), T. Mikolov et al.  &lt;a href="http://arxiv.org/pdf/1301.3781" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recursive deep models for semantic compositionality over a sentiment treebank&lt;/strong&gt; (2013), R. Socher et al. &lt;a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.383.1327&amp;amp;rep=rep1&amp;amp;type=pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generating sequences with recurrent neural networks&lt;/strong&gt; (2013), A. Graves. &lt;a href="https://arxiv.org/pdf/1308.0850" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;a id="user-content-speech--other-domain" class="anchor" aria-hidden="true" href="#speech--other-domain"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speech / Other Domain&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;End-to-end attention-based large vocabulary speech recognition&lt;/strong&gt; (2016), D. Bahdanau et al. &lt;a href="https://arxiv.org/pdf/1508.04395" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deep speech 2: End-to-end speech recognition in English and Mandarin&lt;/strong&gt; (2015), D. Amodei et al. &lt;a href="https://arxiv.org/pdf/1512.02595" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Speech recognition with deep recurrent neural networks&lt;/strong&gt; (2013), A. Graves &lt;a href="http://arxiv.org/pdf/1303.5778.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups&lt;/strong&gt; (2012), G. Hinton et al. &lt;a href="http://www.cs.toronto.edu/~asamir/papers/SPM_DNN_12.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition&lt;/strong&gt; (2012) G. Dahl et al. &lt;a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.337.7548&amp;amp;rep=rep1&amp;amp;type=pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Acoustic modeling using deep belief networks&lt;/strong&gt; (2012), A. Mohamed et al. &lt;a href="http://www.cs.toronto.edu/~asamir/papers/speechDBN_jrnl.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;a id="user-content-reinforcement-learning--robotics" class="anchor" aria-hidden="true" href="#reinforcement-learning--robotics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reinforcement Learning / Robotics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;End-to-end training of deep visuomotor policies&lt;/strong&gt; (2016), S. Levine et al. &lt;a href="http://www.jmlr.org/papers/volume17/15-522/source/15-522.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection&lt;/strong&gt; (2016), S. Levine et al. &lt;a href="https://arxiv.org/pdf/1603.02199" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Asynchronous methods for deep reinforcement learning&lt;/strong&gt; (2016), V. Mnih et al. &lt;a href="http://www.jmlr.org/proceedings/papers/v48/mniha16.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deep Reinforcement Learning with Double Q-Learning&lt;/strong&gt; (2016), H. Hasselt et al. &lt;a href="https://arxiv.org/pdf/1509.06461.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mastering the game of Go with deep neural networks and tree search&lt;/strong&gt; (2016), D. Silver et al. &lt;a href="http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Continuous control with deep reinforcement learning&lt;/strong&gt; (2015), T. Lillicrap et al. &lt;a href="https://arxiv.org/pdf/1509.02971" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Human-level control through deep reinforcement learning&lt;/strong&gt; (2015), V. Mnih et al. &lt;a href="http://www.davidqiu.com:8888/research/nature14236.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deep learning for detecting robotic grasps&lt;/strong&gt; (2015), I. Lenz et al. &lt;a href="http://www.cs.cornell.edu/~asaxena/papers/lenz_lee_saxena_deep_learning_grasping_ijrr2014.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Playing atari with deep reinforcement learning&lt;/strong&gt; (2013), V. Mnih et al. &lt;a href="http://arxiv.org/pdf/1312.5602.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;a id="user-content-more-papers-from-2016" class="anchor" aria-hidden="true" href="#more-papers-from-2016"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More Papers from 2016&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Layer Normalization&lt;/strong&gt; (2016), J. Ba et al. &lt;a href="https://arxiv.org/pdf/1607.06450v1.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learning to learn by gradient descent by gradient descent&lt;/strong&gt; (2016), M. Andrychowicz et al. &lt;a href="http://arxiv.org/pdf/1606.04474v1" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Domain-adversarial training of neural networks&lt;/strong&gt; (2016), Y. Ganin et al. &lt;a href="http://www.jmlr.org/papers/volume17/15-239/source/15-239.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WaveNet: A Generative Model for Raw Audio&lt;/strong&gt; (2016), A. Oord et al. &lt;a href="https://arxiv.org/pdf/1609.03499v2" rel="nofollow"&gt;[pdf]&lt;/a&gt; &lt;a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Colorful image colorization&lt;/strong&gt; (2016), R. Zhang et al. &lt;a href="https://arxiv.org/pdf/1603.08511" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generative visual manipulation on the natural image manifold&lt;/strong&gt; (2016), J. Zhu et al. &lt;a href="https://arxiv.org/pdf/1609.03552" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Texture networks: Feed-forward synthesis of textures and stylized images&lt;/strong&gt; (2016), D Ulyanov et al. &lt;a href="http://www.jmlr.org/proceedings/papers/v48/ulyanov16.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SSD: Single shot multibox detector&lt;/strong&gt; (2016), W. Liu et al. &lt;a href="https://arxiv.org/pdf/1512.02325" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and&amp;lt; 1MB model size&lt;/strong&gt; (2016), F. Iandola et al. &lt;a href="http://arxiv.org/pdf/1602.07360" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eie: Efficient inference engine on compressed deep neural network&lt;/strong&gt; (2016), S. Han et al. &lt;a href="http://arxiv.org/pdf/1602.01528" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1&lt;/strong&gt; (2016), M. Courbariaux et al. &lt;a href="https://arxiv.org/pdf/1602.02830" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic memory networks for visual and textual question answering&lt;/strong&gt; (2016), C. Xiong et al. &lt;a href="http://www.jmlr.org/proceedings/papers/v48/xiong16.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stacked attention networks for image question answering&lt;/strong&gt; (2016), Z. Yang et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yang_Stacked_Attention_Networks_CVPR_2016_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hybrid computing using a neural network with dynamic external memory&lt;/strong&gt; (2016), A. Graves et al. &lt;a href="https://www.gwern.net/docs/2016-graves.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Google's neural machine translation system: Bridging the gap between human and machine translation&lt;/strong&gt; (2016), Y. Wu et al. &lt;a href="https://arxiv.org/pdf/1609.08144" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3&gt;&lt;a id="user-content-new-papers" class="anchor" aria-hidden="true" href="#new-papers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;New papers&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Newly published papers (&amp;lt; 6 months) which are worth reading&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications (2017), Andrew G. Howard et al. &lt;a href="https://arxiv.org/pdf/1704.04861.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Convolutional Sequence to Sequence Learning (2017), Jonas Gehring et al. &lt;a href="https://arxiv.org/pdf/1705.03122" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A Knowledge-Grounded Neural Conversation Model (2017), Marjan Ghazvininejad et al. &lt;a href="https://arxiv.org/pdf/1702.01932" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Accurate, Large Minibatch SGD:Training ImageNet in 1 Hour (2017), Priya Goyal et al. &lt;a href="https://research.fb.com/wp-content/uploads/2017/06/imagenet1kin1h3.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TACOTRON: Towards end-to-end speech synthesis (2017), Y. Wang et al. &lt;a href="https://arxiv.org/pdf/1703.10135.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep Photo Style Transfer (2017), F. Luan et al. &lt;a href="http://arxiv.org/pdf/1703.07511v1.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Evolution Strategies as a Scalable Alternative to Reinforcement Learning (2017), T. Salimans et al. &lt;a href="http://arxiv.org/pdf/1703.03864v1.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deformable Convolutional Networks (2017), J. Dai et al. &lt;a href="http://arxiv.org/pdf/1703.06211v2.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Mask R-CNN (2017), K. He et al. &lt;a href="https://128.84.21.199/pdf/1703.06870" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Learning to discover cross-domain relations with generative adversarial networks (2017), T. Kim et al. &lt;a href="http://arxiv.org/pdf/1703.05192v1.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep voice: Real-time neural text-to-speech (2017), S. Arik et al., &lt;a href="http://arxiv.org/pdf/1702.07825v2.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;PixelNet: Representation of the pixels, by the pixels, and for the pixels (2017), A. Bansal et al. &lt;a href="http://arxiv.org/pdf/1702.06506v1.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Batch renormalization: Towards reducing minibatch dependence in batch-normalized models (2017), S. Ioffe. &lt;a href="https://arxiv.org/abs/1702.03275" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Wasserstein GAN (2017), M. Arjovsky et al. &lt;a href="https://arxiv.org/pdf/1701.07875v1" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Understanding deep learning requires rethinking generalization (2017), C. Zhang et al. &lt;a href="https://arxiv.org/pdf/1611.03530" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Least squares generative adversarial networks (2016), X. Mao et al. &lt;a href="https://arxiv.org/abs/1611.04076v2" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-old-papers" class="anchor" aria-hidden="true" href="#old-papers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Old Papers&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Classic papers published before 2012&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An analysis of single-layer networks in unsupervised feature learning (2011), A. Coates et al. &lt;a href="http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_CoatesNL11.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep sparse rectifier neural networks (2011), X. Glorot et al. &lt;a href="http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_GlorotBB11.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Natural language processing (almost) from scratch (2011), R. Collobert et al. &lt;a href="http://arxiv.org/pdf/1103.0398" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Recurrent neural network based language model (2010), T. Mikolov et al. &lt;a href="http://www.fit.vutbr.cz/research/groups/speech/servite/2010/rnnlm_mikolov.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion (2010), P. Vincent et al. &lt;a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.297.3484&amp;amp;rep=rep1&amp;amp;type=pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Learning mid-level features for recognition (2010), Y. Boureau &lt;a href="http://ece.duke.edu/~lcarin/boureau-cvpr-10.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A practical guide to training restricted boltzmann machines (2010), G. Hinton &lt;a href="http://www.csri.utoronto.ca/~hinton/absps/guideTR.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Understanding the difficulty of training deep feedforward neural networks (2010), X. Glorot and Y. Bengio &lt;a href="http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_GlorotB10.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Why does unsupervised pre-training help deep learning (2010), D. Erhan et al. &lt;a href="http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_ErhanCBV10.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Learning deep architectures for AI (2009), Y. Bengio. &lt;a href="http://sanghv.com/download/soft/machine%20learning,%20artificial%20intelligence,%20mathematics%20ebooks/ML/learning%20deep%20architectures%20for%20AI%20(2009).pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations (2009), H. Lee et al. &lt;a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.802&amp;amp;rep=rep1&amp;amp;type=pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Greedy layer-wise training of deep networks (2007), Y. Bengio et al. &lt;a href="http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_739.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Reducing the dimensionality of data with neural networks, G. Hinton and R. Salakhutdinov. &lt;a href="http://homes.mpimf-heidelberg.mpg.de/~mhelmsta/pdf/2006%20Hinton%20Salakhudtkinov%20Science.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A fast learning algorithm for deep belief nets (2006), G. Hinton et al. &lt;a href="http://nuyoo.utm.mx/~jjf/rna/A8%20A%20fast%20learning%20algorithm%20for%20deep%20belief%20nets.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gradient-based learning applied to document recognition (1998), Y. LeCun et al. &lt;a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Long short-term memory (1997), S. Hochreiter and J. Schmidhuber. &lt;a href="http://www.mitpressjournals.org/doi/pdfplus/10.1162/neco.1997.9.8.1735" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-hw--sw--dataset" class="anchor" aria-hidden="true" href="#hw--sw--dataset"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;HW / SW / Dataset&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SQuAD: 100,000+ Questions for Machine Comprehension of Text (2016), Rajpurkar et al. &lt;a href="https://arxiv.org/pdf/1606.05250.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OpenAI gym (2016), G. Brockman et al. &lt;a href="https://arxiv.org/pdf/1606.01540" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TensorFlow: Large-scale machine learning on heterogeneous distributed systems (2016), M. Abadi et al. &lt;a href="http://arxiv.org/pdf/1603.04467" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Theano: A Python framework for fast computation of mathematical expressions, R. Al-Rfou et al.&lt;/li&gt;
&lt;li&gt;Torch7: A matlab-like environment for machine learning, R. Collobert et al. &lt;a href="https://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MatConvNet: Convolutional neural networks for matlab (2015), A. Vedaldi and K. Lenc &lt;a href="http://arxiv.org/pdf/1412.4564" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Imagenet large scale visual recognition challenge (2015), O. Russakovsky et al. &lt;a href="http://arxiv.org/pdf/1409.0575" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Caffe: Convolutional architecture for fast feature embedding (2014), Y. Jia et al. &lt;a href="http://arxiv.org/pdf/1408.5093" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-book--survey--review" class="anchor" aria-hidden="true" href="#book--survey--review"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Book / Survey / Review&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;On the Origin of Deep Learning (2017), H. Wang and Bhiksha Raj. &lt;a href="https://arxiv.org/pdf/1702.07800" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep Reinforcement Learning: An Overview (2017), Y. Li, &lt;a href="http://arxiv.org/pdf/1701.07274v2.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Neural Machine Translation and Sequence-to-sequence Models(2017): A Tutorial, G. Neubig. &lt;a href="http://arxiv.org/pdf/1703.01619v1.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Neural Network and Deep Learning (Book, Jan 2017), Michael Nielsen. &lt;a href="http://neuralnetworksanddeeplearning.com/index.html" rel="nofollow"&gt;[html]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep learning (Book, 2016), Goodfellow et al. &lt;a href="http://www.deeplearningbook.org/" rel="nofollow"&gt;[html]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;LSTM: A search space odyssey (2016), K. Greff et al. &lt;a href="https://arxiv.org/pdf/1503.04069.pdf?utm_content=buffereddc5&amp;amp;utm_medium=social&amp;amp;utm_source=plus.google.com&amp;amp;utm_campaign=buffer" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Tutorial on Variational Autoencoders (2016), C. Doersch. &lt;a href="https://arxiv.org/pdf/1606.05908" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep learning (2015), Y. LeCun, Y. Bengio and G. Hinton &lt;a href="https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep learning in neural networks: An overview (2015), J. Schmidhuber &lt;a href="http://arxiv.org/pdf/1404.7828" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Representation learning: A review and new perspectives (2013), Y. Bengio et al. &lt;a href="http://arxiv.org/pdf/1206.5538" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-video-lectures--tutorials--blogs" class="anchor" aria-hidden="true" href="#video-lectures--tutorials--blogs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Video Lectures / Tutorials / Blogs&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;(Lectures)&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CS231n, Convolutional Neural Networks for Visual Recognition, Stanford University &lt;a href="http://cs231n.stanford.edu/" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CS224d, Deep Learning for Natural Language Processing, Stanford University &lt;a href="http://cs224d.stanford.edu/" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Oxford Deep NLP 2017, Deep Learning for Natural Language Processing, University of Oxford &lt;a href="https://github.com/oxford-cs-deepnlp-2017/lectures"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;(Tutorials)&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NIPS 2016 Tutorials, Long Beach &lt;a href="https://nips.cc/Conferences/2016/Schedule?type=Tutorial" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ICML 2016 Tutorials, New York City &lt;a href="http://techtalks.tv/icml/2016/tutorials/" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ICLR 2016 Videos, San Juan &lt;a href="http://videolectures.net/iclr2016_san_juan/" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep Learning Summer School 2016, Montreal &lt;a href="http://videolectures.net/deeplearning2016_montreal/" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bay Area Deep Learning School 2016, Stanford &lt;a href="https://www.bayareadlschool.org/" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;(Blogs)&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenAI &lt;a href="https://www.openai.com/" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Distill &lt;a href="http://distill.pub/" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Andrej Karpathy Blog &lt;a href="http://karpathy.github.io/" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Colah's Blog &lt;a href="http://colah.github.io/" rel="nofollow"&gt;[Web]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;WildML &lt;a href="http://www.wildml.com/" rel="nofollow"&gt;[Web]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;FastML &lt;a href="http://www.fastml.com/" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TheMorningPaper &lt;a href="https://blog.acolyer.org" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-appendix-more-than-top-100" class="anchor" aria-hidden="true" href="#appendix-more-than-top-100"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Appendix: More than Top 100&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;(2016)&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A character-level decoder without explicit segmentation for neural machine translation (2016), J. Chung et al. &lt;a href="https://arxiv.org/pdf/1603.06147" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Dermatologist-level classification of skin cancer with deep neural networks (2017), A. Esteva et al. &lt;a href="http://www.nature.com/nature/journal/v542/n7639/full/nature21056.html" rel="nofollow"&gt;[html]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Weakly supervised object localization with multi-fold multiple instance learning (2017), R. Gokberk et al. &lt;a href="https://arxiv.org/pdf/1503.00949" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Brain tumor segmentation with deep neural networks (2017), M. Havaei et al. &lt;a href="https://arxiv.org/pdf/1505.03540" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Professor Forcing: A New Algorithm for Training Recurrent Networks (2016), A. Lamb et al. &lt;a href="https://arxiv.org/pdf/1610.09038" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Adversarially learned inference (2016), V. Dumoulin et al. &lt;a href="https://ishmaelbelghazi.github.io/ALI/" rel="nofollow"&gt;[web]&lt;/a&gt;&lt;a href="https://arxiv.org/pdf/1606.00704v1" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Understanding convolutional neural networks (2016), J. Koushik &lt;a href="https://arxiv.org/pdf/1605.09081v1" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Taking the human out of the loop: A review of bayesian optimization (2016), B. Shahriari et al. &lt;a href="https://www.cs.ox.ac.uk/people/nando.defreitas/publications/BayesOptLoop.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Adaptive computation time for recurrent neural networks (2016), A. Graves &lt;a href="http://arxiv.org/pdf/1603.08983" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Densely connected convolutional networks (2016), G. Huang et al. &lt;a href="https://arxiv.org/pdf/1608.06993v1" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Region-based convolutional networks for accurate object detection and segmentation (2016), R. Girshick et al.&lt;/li&gt;
&lt;li&gt;Continuous deep q-learning with model-based acceleration (2016), S. Gu et al. &lt;a href="http://www.jmlr.org/proceedings/papers/v48/gu16.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A thorough examination of the cnn/daily mail reading comprehension task (2016), D. Chen et al. &lt;a href="https://arxiv.org/pdf/1606.02858" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Achieving open vocabulary neural machine translation with hybrid word-character models, M. Luong and C. Manning. &lt;a href="https://arxiv.org/pdf/1604.00788" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Very Deep Convolutional Networks for Natural Language Processing (2016), A. Conneau et al. &lt;a href="https://arxiv.org/pdf/1606.01781" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bag of tricks for efficient text classification (2016), A. Joulin et al. &lt;a href="https://arxiv.org/pdf/1607.01759" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Efficient piecewise training of deep structured models for semantic segmentation (2016), G. Lin et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Lin_Efficient_Piecewise_Training_CVPR_2016_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Learning to compose neural networks for question answering (2016), J. Andreas et al. &lt;a href="https://arxiv.org/pdf/1601.01705" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Perceptual losses for real-time style transfer and super-resolution (2016), J. Johnson et al. &lt;a href="https://arxiv.org/pdf/1603.08155" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Reading text in the wild with convolutional neural networks (2016), M. Jaderberg et al. &lt;a href="http://arxiv.org/pdf/1412.1842" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;What makes for effective detection proposals? (2016), J. Hosang et al. &lt;a href="https://arxiv.org/pdf/1502.05082" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks (2016), S. Bell et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Bell_Inside-Outside_Net_Detecting_CVPR_2016_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Instance-aware semantic segmentation via multi-task network cascades (2016), J. Dai et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Dai_Instance-Aware_Semantic_Segmentation_CVPR_2016_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Conditional image generation with pixelcnn decoders (2016), A. van den Oord et al. &lt;a href="http://papers.nips.cc/paper/6527-tree-structured-reinforcement-learning-for-sequential-object-localization.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep networks with stochastic depth (2016), G. Huang et al., &lt;a href="https://arxiv.org/pdf/1603.09382" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Consistency and Fluctuations For Stochastic Gradient Langevin Dynamics (2016), Yee Whye Teh et al. &lt;a href="http://www.jmlr.org/papers/volume17/teh16a/teh16a.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;(2015)&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ask your neurons: A neural-based approach to answering questions about images (2015), M. Malinowski et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Malinowski_Ask_Your_Neurons_ICCV_2015_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Exploring models and data for image question answering (2015), M. Ren et al. &lt;a href="http://papers.nips.cc/paper/5640-stochastic-variational-inference-for-hidden-markov-models.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Are you talking to a machine? dataset and methods for multilingual image question (2015), H. Gao et al. &lt;a href="http://papers.nips.cc/paper/5641-are-you-talking-to-a-machine-dataset-and-methods-for-multilingual-image-question.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Mind's eye: A recurrent visual representation for image caption generation (2015), X. Chen and C. Zitnick. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Chen_Minds_Eye_A_2015_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;From captions to visual concepts and back (2015), H. Fang et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Fang_From_Captions_to_2015_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Towards AI-complete question answering: A set of prerequisite toy tasks (2015), J. Weston et al. &lt;a href="http://arxiv.org/pdf/1502.05698" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ask me anything: Dynamic memory networks for natural language processing (2015), A. Kumar et al. &lt;a href="http://arxiv.org/pdf/1506.07285" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Unsupervised learning of video representations using LSTMs (2015), N. Srivastava et al. &lt;a href="http://www.jmlr.org/proceedings/papers/v37/srivastava15.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2015), S. Han et al. &lt;a href="https://arxiv.org/pdf/1510.00149" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Improved semantic representations from tree-structured long short-term memory networks (2015), K. Tai et al. &lt;a href="https://arxiv.org/pdf/1503.00075" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Character-aware neural language models (2015), Y. Kim et al. &lt;a href="https://arxiv.org/pdf/1508.06615" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Grammar as a foreign language (2015), O. Vinyals et al. &lt;a href="http://papers.nips.cc/paper/5635-grammar-as-a-foreign-language.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Trust Region Policy Optimization (2015), J. Schulman et al. &lt;a href="http://www.jmlr.org/proceedings/papers/v37/schulman15.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Beyond short snippents: Deep networks for video classification (2015) &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Ng_Beyond_Short_Snippets_2015_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Learning Deconvolution Network for Semantic Segmentation (2015), H. Noh et al. &lt;a href="https://arxiv.org/pdf/1505.04366v1" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Learning spatiotemporal features with 3d convolutional networks (2015), D. Tran et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Tran_Learning_Spatiotemporal_Features_ICCV_2015_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Understanding neural networks through deep visualization (2015), J. Yosinski et al. &lt;a href="https://arxiv.org/pdf/1506.06579" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;An Empirical Exploration of Recurrent Network Architectures (2015), R. Jozefowicz et al.  &lt;a href="http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep generative image models using a￼ laplacian pyramid of adversarial networks (2015), E.Denton et al. &lt;a href="http://papers.nips.cc/paper/5773-deep-generative-image-models-using-a-laplacian-pyramid-of-adversarial-networks.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gated Feedback Recurrent Neural Networks (2015), J. Chung et al. &lt;a href="http://www.jmlr.org/proceedings/papers/v37/chung15.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Fast and accurate deep network learning by exponential linear units (ELUS) (2015), D. Clevert et al. &lt;a href="https://arxiv.org/pdf/1511.07289.pdf%5Cnhttp://arxiv.org/abs/1511.07289%5Cnhttp://arxiv.org/abs/1511.07289" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Pointer networks (2015), O. Vinyals et al. &lt;a href="http://papers.nips.cc/paper/5866-pointer-networks.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Visualizing and Understanding Recurrent Networks (2015), A. Karpathy et al. &lt;a href="https://arxiv.org/pdf/1506.02078" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Attention-based models for speech recognition (2015), J. Chorowski et al. &lt;a href="http://papers.nips.cc/paper/5847-attention-based-models-for-speech-recognition.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;End-to-end memory networks (2015), S. Sukbaatar et al. &lt;a href="http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Describing videos by exploiting temporal structure (2015), L. Yao et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yao_Describing_Videos_by_ICCV_2015_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A neural conversational model (2015), O. Vinyals and Q. Le. &lt;a href="https://arxiv.org/pdf/1506.05869.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Improving distributional similarity with lessons learned from word embeddings, O. Levy et al. [[pdf]] (&lt;a href="https://www.transacl.org/ojs/index.php/tacl/article/download/570/124" rel="nofollow"&gt;https://www.transacl.org/ojs/index.php/tacl/article/download/570/124&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Transition-Based Dependency Parsing with Stack Long Short-Term Memory (2015), C. Dyer et al. &lt;a href="http://aclweb.org/anthology/P/P15/P15-1033.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Improved Transition-Based Parsing by Modeling Characters instead of Words with LSTMs (2015), M. Ballesteros et al. &lt;a href="http://aclweb.org/anthology/D/D15/D15-1041.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Finding function in form: Compositional character models for open vocabulary word representation (2015), W. Ling et al. &lt;a href="http://aclweb.org/anthology/D/D15/D15-1176.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;(~2014)&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DeepPose: Human pose estimation via deep neural networks (2014), A. Toshev and C. Szegedy &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Toshev_DeepPose_Human_Pose_2014_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Learning a Deep Convolutional Network for Image Super-Resolution (2014, C. Dong et al. &lt;a href="https://www.researchgate.net/profile/Chen_Change_Loy/publication/264552416_Lecture_Notes_in_Computer_Science/links/53e583e50cf25d674e9c280e.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Recurrent models of visual attention (2014), V. Mnih et al. &lt;a href="http://arxiv.org/pdf/1406.6247.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Empirical evaluation of gated recurrent neural networks on sequence modeling (2014), J. Chung et al. &lt;a href="https://arxiv.org/pdf/1412.3555" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Addressing the rare word problem in neural machine translation (2014), M. Luong et al. &lt;a href="https://arxiv.org/pdf/1410.8206" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;On the properties of neural machine translation: Encoder-decoder approaches (2014), K. Cho et. al.&lt;/li&gt;
&lt;li&gt;Recurrent neural network regularization (2014), W. Zaremba et al. &lt;a href="http://arxiv.org/pdf/1409.2329" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Intriguing properties of neural networks (2014), C. Szegedy et al. &lt;a href="https://arxiv.org/pdf/1312.6199.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Towards end-to-end speech recognition with recurrent neural networks (2014), A. Graves and N. Jaitly. &lt;a href="http://www.jmlr.org/proceedings/papers/v32/graves14.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Scalable object detection using deep neural networks (2014), D. Erhan et al. &lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Erhan_Scalable_Object_Detection_2014_CVPR_paper.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;On the importance of initialization and momentum in deep learning (2013), I. Sutskever et al. &lt;a href="http://machinelearning.wustl.edu/mlpapers/paper_files/icml2013_sutskever13.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Regularization of neural networks using dropconnect (2013), L. Wan et al. &lt;a href="http://machinelearning.wustl.edu/mlpapers/paper_files/icml2013_wan13.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Learning Hierarchical Features for Scene Labeling (2013), C. Farabet et al. &lt;a href="https://hal-enpc.archives-ouvertes.fr/docs/00/74/20/77/PDF/farabet-pami-13.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Linguistic Regularities in Continuous Space Word Representations (2013), T. Mikolov et al. &lt;a href="http://www.aclweb.org/anthology/N13-1#page=784" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Large scale distributed deep networks (2012), J. Dean et al. &lt;a href="http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A Fast and Accurate Dependency Parser using Neural Networks. Chen and Manning. &lt;a href="http://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf" rel="nofollow"&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgement" class="anchor" aria-hidden="true" href="#acknowledgement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;Thank you for all your contributions. Please make sure to read the &lt;a href="https://github.com/terryum/awesome-deep-learning-papers/blob/master/Contributing.md"&gt;contributing guide&lt;/a&gt; before you make a pull request.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://creativecommons.org/publicdomain/zero/1.0/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/60561947585c982aee67ed3e3b25388184cc0aa3/687474703a2f2f6d6972726f72732e6372656174697665636f6d6d6f6e732e6f72672f70726573736b69742f627574746f6e732f38387833312f7376672f63632d7a65726f2e737667" alt="CC0" data-canonical-src="http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To the extent possible under law, &lt;a href="https://www.facebook.com/terryum.io/" rel="nofollow"&gt;Terry T. Um&lt;/a&gt; has waived all copyright and related or neighboring rights to this work.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>terryum</author><guid isPermaLink="false">https://github.com/terryum/awesome-deep-learning-papers</guid><pubDate>Thu, 28 Nov 2019 00:03:00 GMT</pubDate></item><item><title>zhanwen/MathModel #4 in TeX, This week</title><link>https://github.com/zhanwen/MathModel</link><description>&lt;p&gt;&lt;i&gt;研究生数学建模，数学建模竞赛优秀论文，数学建模算法，LaTeX论文模板，算法思维导图，参考书籍，Matlab软件教程，PPT&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-数学建模资源" class="anchor" aria-hidden="true" href="#数学建模资源"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数学建模资源&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-2019-年研究生数模" class="anchor" aria-hidden="true" href="#2019-年研究生数模"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2019 年研究生数模&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-20191111-又是双十一比赛结果经过一个半月的评审在这一天公布了获奖名单大家的努力相信都会有所收获余生还有很多有意义的事情需要我们去做让我们一起努力oo" class="anchor" aria-hidden="true" href="#20191111-又是双十一比赛结果经过一个半月的评审在这一天公布了获奖名单大家的努力相信都会有所收获余生还有很多有意义的事情需要我们去做让我们一起努力oo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2019.11.11 又是双十一，比赛结果经过一个半月的评审，在这一天公布了&lt;a href="2019%E5%B9%B4%E6%9C%80%E7%BB%88%E8%8E%B7%E5%A5%96%E5%90%8D%E5%8D%95"&gt;获奖名单&lt;/a&gt;，大家的努力相信都会有所收获。余生还有很多有意义的事情需要我们去做，让我们一起努力。(o^o)&lt;/h4&gt;
&lt;h3&gt;&lt;a id="user-content-20199192019923-比赛已经结束大家耐心等待获奖吧oo" class="anchor" aria-hidden="true" href="#20199192019923-比赛已经结束大家耐心等待获奖吧oo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2019.9.19—2019.9.23 比赛已经结束，大家耐心等待获奖吧（(o^^o)）&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-论文提交md5使用方法" class="anchor" aria-hidden="true" href="#论文提交md5使用方法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;论文提交（MD5使用方法）&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;MD5文件校验和使用说明：&lt;/em&gt; &lt;a href="https://github.com/zhanwen/MathModel/blob/master/MD5%E6%96%87%E4%BB%B6%E6%A0%A1%E9%AA%8C%E5%92%8C%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E.md"&gt;&lt;strong&gt;MD5文件校验和使用说明&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-论文模版更新" class="anchor" aria-hidden="true" href="#论文模版更新"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;论文模版更新&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;LaTex 论文模版：&lt;/em&gt; &lt;a href="https://github.com/zhanwen/MathModel/blob/master/2019%E5%B9%B4%E8%AE%BA%E6%96%87%E6%A8%A1%E7%89%88/2019%E5%B9%B4Latex%E6%A8%A1%E7%89%88.zip"&gt;&lt;strong&gt;LaTex 论文模版&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
&lt;em&gt;Word 论文模版：&lt;/em&gt; &lt;a href="https://github.com/zhanwen/MathModel/blob/master/2019%E5%B9%B4%E8%AE%BA%E6%96%87%E6%A8%A1%E7%89%88/%E2%80%9C%E5%8D%8E%E4%B8%BA%E6%9D%AF%E2%80%9D%E7%AC%AC%E5%8D%81%E5%85%AD%E5%B1%8A%E4%B8%AD%E5%9B%BD%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AE%BA%E6%96%87%E6%A0%BC%E5%BC%8F%E8%A7%84%E8%8C%83.doc"&gt;&lt;strong&gt;Word 论文模版（已更新最新）&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
&lt;em&gt;LaTex 论文模版使用方式：&lt;/em&gt; &lt;a href="https://github.com/zhanwen/MathModel/tree/master/2019%E5%B9%B4%E8%AE%BA%E6%96%87%E6%A8%A1%E7%89%88/latex_note.md"&gt;&lt;strong&gt;如何编译 Latex 文件&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-下载方式仓库比较大建议单个文件下载" class="anchor" aria-hidden="true" href="#下载方式仓库比较大建议单个文件下载"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;下载方式(仓库比较大，建议单个文件下载)&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./images/downloaddemo2.gif"&gt;&lt;img src="./images/downloaddemo2.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt;  
&lt;p&gt;&lt;em&gt;主题：&lt;/em&gt; &lt;a href="https://cpipc.chinadegrees.cn/cw/hp/4" rel="nofollow"&gt;&lt;strong&gt;“华为杯”第十六届中国研究生数学建模竞赛&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
&lt;em&gt;报名时间：&lt;/em&gt; &lt;strong&gt;2019年6月1日8:00——9月10日17:00&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;审核时间：&lt;/em&gt; &lt;strong&gt;2019年6月1日8:00——9月12日17:00&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;交费时间：&lt;/em&gt; &lt;strong&gt;2019年7月1日8:00——9月15日17:00&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;比赛时间：&lt;/em&gt; &lt;strong&gt;2019年9月19日8:00——9月23日12:00&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-官网报名地址官网地址" class="anchor" aria-hidden="true" href="#官网报名地址官网地址"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;官网报名地址：&lt;a href="https://cpipc.chinadegrees.cn/cw/hp/4" rel="nofollow"&gt;官网地址&lt;/a&gt;&lt;/h4&gt;
&lt;hr&gt;  
&lt;h3&gt;&lt;a id="user-content-2018915-祝大家比赛开心-_" class="anchor" aria-hidden="true" href="#2018915-祝大家比赛开心-_"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2018.9.15 祝大家比赛开心 （^_^）&lt;/h3&gt;
&lt;h3&gt;&lt;a id="user-content-2018919-比赛已经结束大家耐心等待获奖吧o" class="anchor" aria-hidden="true" href="#2018919-比赛已经结束大家耐心等待获奖吧o"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2018.9.19 比赛已经结束，大家耐心等待获奖吧（^o^）&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-20181111-比赛结果经过一个半月的评审终于在昨天公布了获奖名单大家的努力相信都会有所收获余生还有很多有意义的事情需要我们去做让我们一起努力oo" class="anchor" aria-hidden="true" href="#20181111-比赛结果经过一个半月的评审终于在昨天公布了获奖名单大家的努力相信都会有所收获余生还有很多有意义的事情需要我们去做让我们一起努力oo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2018.11.11 比赛结果经过一个半月的评审，终于在昨天公布了&lt;a href="https://github.com/zhanwen/MathModel/tree/master/2018%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/2018%E5%B9%B4%E6%9C%80%E7%BB%88%E8%8E%B7%E5%A5%96%E5%90%8D%E5%8D%95"&gt;获奖名单&lt;/a&gt;，大家的努力相信都会有所收获。余生还有很多有意义的事情需要我们去做，让我们一起努力。(o^^o)&lt;/h4&gt;
&lt;hr&gt;  
&lt;h4&gt;&lt;a id="user-content-更新添加比赛官网地址戳这里" class="anchor" aria-hidden="true" href="#更新添加比赛官网地址戳这里"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;更新/添加比赛官网地址&lt;a href="https://cpipc.chinadegrees.cn/" rel="nofollow"&gt;戳这里&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cpipc.chinadegrees.cn/cw/hp/4" rel="nofollow"&gt;数学建模竞赛&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cpipc.chinadegrees.cn/cw/hp/6" rel="nofollow"&gt;电子设计竞赛&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cpipc.chinadegrees.cn/cw/hp/2c9088a5696cbf370169a3f8101510bd" rel="nofollow"&gt;人工智能创新大赛&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cpipc.chinadegrees.cn/cw/hp/2c9088a5696cbf370169a3f8934810be" rel="nofollow"&gt;机器人创新设计大赛&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3&gt;&lt;a id="user-content-下载与使用由于整个项目直接下载比较慢可以看方式四" class="anchor" aria-hidden="true" href="#下载与使用由于整个项目直接下载比较慢可以看方式四"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;下载与使用（由于整个项目直接下载比较慢，可以看方式四）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;方式一：使用 &lt;code&gt;git&lt;/code&gt; 下载。&lt;br&gt;
&lt;code&gt;git clone https://github.com/zhanwen/MathModel.git&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;方式二：直接下载压缩包。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./images/downloaddemo.gif"&gt;&lt;img src="./images/downloaddemo.gif" height="250" width="500" align="center" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;方式三
&lt;ul&gt;
&lt;li&gt;可以单个文件下载，选择自己需要的某篇论文，直接在对应的页面点击下载即可。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./images/download3.gif"&gt;&lt;img src="./images/download3.gif" height="250" width="500" align="center" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;方式四：百度云下载（推荐）
&lt;ul&gt;
&lt;li&gt;使用百度云下载，正常的客户端会出现限速，导致下载的很慢，这里给大家推荐一个绕过百度云下载限速的方式。具体怎么下载，请参照 &lt;a href="https://github.com/iikira/BaiduPCS-Go"&gt;绕过限速&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;该项目的百度云链接 &lt;a href="https://pan.baidu.com/s/1UnngHxNR0EVoyBpKlPxFAw" rel="nofollow"&gt;https://pan.baidu.com/s/1UnngHxNR0EVoyBpKlPxFAw&lt;/a&gt;，密码：&lt;code&gt;ea2n&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-国赛试题" class="anchor" aria-hidden="true" href="#国赛试题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;国赛试题&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2019%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2019年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2018%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2018年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2017%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2017年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2016%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2016年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2015%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2015年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2014%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2014年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2013%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2013年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2012%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2012年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2011%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2011年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2010%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2010年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2009%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2009年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2008%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2008年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2007%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2007年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2006%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2006年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2005%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2005年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2004%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2004年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-国赛论文" class="anchor" aria-hidden="true" href="#国赛论文"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;国赛论文&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2018年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：关于跳台跳水体型系数设置的建模分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：光传送网建模与价值评估&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：对恐怖袭击事件记录数据的量化分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：基于卫星高度计海面高度异常资料获取潮汐调和常数方法及应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/E"&gt;E题：多无人机对组网雷达的协同干扰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/F"&gt;F题：航站楼扩增评估&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2017年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：无人机在抢险救灾中的优化运用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：面向下一代光通信的 VCSEL 激光器仿真模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：航班恢复问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：基于监控视频的前景目标提取&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/E"&gt;E题：多波次导弹发射中的规划问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/F"&gt;F题：地下物流系统网络&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2016年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：多无人机协同任务规划&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：具有遗传性疾病和性状的遗传位点分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：基于无线通信基站的室内三维定位问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：军事行动避空侦察的时机和路线选择&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/E"&gt;E题：粮食最低收购价政策问题研究&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2015年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：水面舰艇编队防空和信息化战争评估模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：数据的多流形结构分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：移动通信中的无线信道“指纹”特征建模&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：面向节能的单/多列车优化决策问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/E"&gt;E题：数控加工刀具运动的优化控制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/F"&gt;F题：旅游路线规划问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2014年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：小鼠视觉感受区电位信号(LFP)与视觉刺激之间的关系研究&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：机动目标的跟踪与反跟踪&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：无线通信中的快时变信道建模&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：人体营养健康角度的中国果蔬发展战略研究&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/E"&gt;E题：乘用车物流运输计划问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2013年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：变循环发动机部件法建模及优化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：功率放大器非线性特性及预失真模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：微蜂窝环境中无线接收信号的特性分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：空气中PM2.5问题的研究 attachment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/E"&gt;E题：中等收入定位与人口度量模型研究&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/F"&gt;F题：可持续的中国城乡居民养老保险体系的数学模型研究&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2012%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2012年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2012%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：基因识别问题及其算法实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2012%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：基于卫星无源探测的空间飞行器主动段轨道估计与误差分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2012%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：有杆抽油系统的数学建模及诊断&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2012%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：基于卫星云图的风失场(云导风)度量模型与算法探讨&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2011%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2011年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2011%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：基于光的波粒二象性一种猜想的数学仿真&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2011%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：吸波材料与微波暗室问题的数学建模&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2011%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：小麦发育后期茎杆抗倒性的数学模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2011%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：房地产行业的数学建模&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2010%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2010年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2010%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：确定肿瘤的重要基因信息&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2010%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：与封堵渍口有关的重物落水后运动过程的数学建模&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2010%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：神经元的形态分类和识别&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2010%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：特殊工件磨削加工的数学建模&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2009%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2009年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2009%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：我国就业人数或城镇登记失业率的数学建模&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2009%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：枪弹头痕迹，自动比对方法的研究&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2009%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：多传感器数据融合与航迹预测&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2009%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：110 警车配置及巡逻方案&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2008%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2008年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2008%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：汶川地震中唐家山堪塞湖泄洪问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2008%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：城市道路交通信号实时控制问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;C题：货运列车的编组调度问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;D题：中央空调系统节能设计问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2007%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2007年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2007%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：建立食品卫生安全保障体系数学模型及改进模型的若干理论问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2007%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：械臂运动路径设计问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2007%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：探讨提高高速公路路面质量的改进方案&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2007%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：邮政运输网络中的邮路规划和邮车调运&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2006%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2006年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2006%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：Ad Hoc 网络中的区域划分和资源分配问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2006%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：确定高精度参数问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2006%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：维修线性流量阀时的内筒设计问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2006%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：学生面试问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2005%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2005年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2005%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：Highway Traveling time Estimate and Optimal Routing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2005%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：空中加油&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2005%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：城市交通管理中的出租车规划&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2005%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：仓库容量有限条件下的随机存贮管理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2004%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2004年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2004%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：发现黄球并定位&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2004%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：使用下料问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2004%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：售后服务数据的运用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2004%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：研究生录取问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-美赛论文" class="anchor" aria-hidden="true" href="#美赛论文"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;美赛论文&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2017年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2016年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2015年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2014年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2013年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2012%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2012年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2011%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2011年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2010%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2010年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2009%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2009年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2008%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2008年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2007%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2007年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2006%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2006年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2005%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2005年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2004%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2004年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-数学建模算法" class="anchor" aria-hidden="true" href="#数学建模算法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数学建模算法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95"&gt;经典算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95"&gt;现代算法&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BB%BF%E7%9C%9F"&gt;计算机仿真&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%95"&gt;粒子群算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE"&gt;马尔可夫链&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%B3%95"&gt;蒙特卡洛法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E6%B3%95"&gt;模拟退火法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;神经网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E5%B0%8F%E6%B3%A2%E5%88%86%E6%9E%90"&gt;小波分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95"&gt;遗传算法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-教材及课件" class="anchor" aria-hidden="true" href="#教材及课件"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;教材及课件&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E6%95%99%E6%9D%90%E5%8F%8A%E8%AF%BE%E4%BB%B6/%E5%9B%BD%E9%98%B2%E7%A7%91%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6"&gt;国防科技术大学&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E6%95%99%E6%9D%90%E5%8F%8A%E8%AF%BE%E4%BB%B6/%E6%B5%99%E6%B1%9F%E5%A4%A7%E5%AD%A6%E8%AF%BE%E4%BB%B6/PPT%E8%AF%BE%E4%BB%B6"&gt;浙江大学课件&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-数学建模算法思维导图" class="anchor" aria-hidden="true" href="#数学建模算法思维导图"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数学建模算法思维导图&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/Mind"&gt;思维导图&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-matlab-入门教程" class="anchor" aria-hidden="true" href="#matlab-入门教程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Matlab 入门教程&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/Matlab%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B"&gt;Matlab入门和在线性代数中的应用&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt; 
&lt;h3&gt;&lt;a id="user-content-声明" class="anchor" aria-hidden="true" href="#声明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;声明&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;其中有些内容整理自互联网，如有侵权，请联系，我将及时处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-个人微信公众号" class="anchor" aria-hidden="true" href="#个人微信公众号"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;个人微信公众号&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;dotzhang&lt;/code&gt;：一名不羁的学僧，我的世界不只有学术。一条迷途的咸鱼，正在游向属于它的天地！&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/images/donate/common.jpg"&gt;&lt;img src="/images/donate/common.jpg" width="150" height="150" alt="weixin" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-赞助和支持" class="anchor" aria-hidden="true" href="#赞助和支持"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;赞助和支持&lt;/h3&gt;
&lt;p&gt;这些内容都是我花了不少时间整理出来的, 如果你觉得它对你很有帮助, 请你也分享给需要学习的朋友们。如果你看好我的内容分享, 也可以考虑适当的赞助打赏, 让我有更多的动力去继续分享更好的内容给大家。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;微信&lt;/th&gt;
&lt;th&gt;支付宝&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/donate/weixinpay.jpg"&gt;&lt;img src="images/donate/weixinpay.jpg" width="150" height="150" alt="pay check" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/donate/alipay.jpg"&gt;&lt;img src="images/donate/alipay.jpg" width="150" height="150" alt="pay check" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-联系" class="anchor" aria-hidden="true" href="#联系"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;联系&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Email：&lt;a href="https://mail.google.com/" rel="nofollow"&gt;hanwenme@gmail.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;微  信（有任何问题都可以直接怼我）：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/donate/wechat.png"&gt;&lt;img src="images/donate/wechat.png" width="150" height="150" alt="pay check" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>zhanwen</author><guid isPermaLink="false">https://github.com/zhanwen/MathModel</guid><pubDate>Thu, 28 Nov 2019 00:04:00 GMT</pubDate></item><item><title>jikexueyuanwiki/tensorflow-zh #5 in TeX, This week</title><link>https://github.com/jikexueyuanwiki/tensorflow-zh</link><description>&lt;p&gt;&lt;i&gt;谷歌全新开源人工智能系统TensorFlow官方文档中文版&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-官方文档中文版" class="anchor" aria-hidden="true" href="#tensorflow-官方文档中文版"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow 官方文档中文版&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="SOURCE/images/TensorFlow.jpg"&gt;&lt;img src="SOURCE/images/TensorFlow.jpg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-你正在阅读的项目可能会比-android-系统更加深远地影响着世界" class="anchor" aria-hidden="true" href="#你正在阅读的项目可能会比-android-系统更加深远地影响着世界"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;你正在阅读的项目可能会比 Android 系统更加深远地影响着世界！&lt;/h3&gt;
&lt;h2&gt;&lt;a id="user-content-缘起" class="anchor" aria-hidden="true" href="#缘起"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;缘起&lt;/h2&gt;
&lt;p&gt;2015年11月9日，Google发布人工智能系统TensorFlow并宣布开源，同日，极客学院组织在线TensorFlow中文文档翻译。&lt;/p&gt;
&lt;p&gt;机器学习作为人工智能的一种类型，可以让软件根据大量的数据来对未来的情况进行阐述或预判。如今，领先的科技巨头无不在机器学习下予以极大投入。Facebook、苹果、微软，甚至国内的百度。Google 自然也在其中。「TensorFlow」是 Google 多年以来内部的机器学习系统。如今，Google 正在将此系统成为开源系统，并将此系统的参数公布给业界工程师、学者和拥有大量编程能力的技术人员，这意味着什么呢？&lt;/p&gt;
&lt;p&gt;打个不太恰当的比喻，如今 Google 对待 TensorFlow 系统，有点类似于该公司对待旗下移动操作系统 Android。如果更多的数据科学家开始使用 Google 的系统来从事机器学习方面的研究，那么这将有利于 Google 对日益发展的机器学习行业拥有更多的主导权。&lt;/p&gt;
&lt;p&gt;为了让国内的技术人员在最短的时间内迅速掌握这一世界领先的 AI 系统，极客学院 Wiki 团队发起对 TensorFlow 官方文档的中文协同翻译，一周之内，全部翻译认领完成，一个月后，全部30章节翻译校对完成，上线极客学院Wiki平台并提供下载。&lt;/p&gt;
&lt;p&gt;Google TensorFlow项目负责人Jeff Dean为该中文翻译项目回信称："&lt;em&gt;看到能够将TensorFlow翻译成中文我非常激动，我们将TensorFlow开源的主要原因之一是为了让全世界的人们能够从机器学习与人工智能中获益，类似这样的协作翻译能够让更多的人更容易地接触到TensorFlow项目，很期待接下来该项目在全球范围内的应用!&lt;/em&gt;"&lt;/p&gt;
&lt;p&gt;Jeff回信原文：&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="SOURCE/images/jeff.png"&gt;&lt;img src="SOURCE/images/jeff.png" alt="jeff" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;再次衷心感谢每一位为该翻译项目做出贡献的同学，我们会持续关注TensorFlow、AI领域以及其它最新技术的发展、持续维护该协作翻译、持续提供更多更优质的内容，为广大IT学习者们服务！&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-内容来源" class="anchor" aria-hidden="true" href="#内容来源"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;内容来源&lt;/h2&gt;
&lt;p&gt;英文官方网站：&lt;br&gt;
&lt;a href="http://tensorflow.org/" rel="nofollow"&gt;http://tensorflow.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;官方GitHub仓库：&lt;br&gt;
&lt;a href="https://github.com/tensorflow/tensorflow"&gt;https://github.com/tensorflow/tensorflow&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;中文版 GitHub 仓库：&lt;br&gt;
&lt;a href="https://github.com/jikexueyuanwiki/tensorflow-zh"&gt;https://github.com/jikexueyuanwiki/tensorflow-zh&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-参与者按认领章节排序" class="anchor" aria-hidden="true" href="#参与者按认领章节排序"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;参与者（按认领章节排序）&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-翻译" class="anchor" aria-hidden="true" href="#翻译"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;翻译&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/PFZheng"&gt;@PFZheng&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/linbojin"&gt;@Tony Jin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chenweican"&gt;@chenweican&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bingjin"&gt;@bingjin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/oskycar"&gt;@oskycar&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/btpeter"&gt;@btpeter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Warln"&gt;@Warln&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ericxk"&gt;@ericxk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wangaicc"&gt;@wangaicc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TerenceCooper"&gt;@Terence Cooper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhyhooo"&gt;@zhyhooo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/thylaco1eo"&gt;@thylaco1eo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/volvet"&gt;@volvet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhangkom"&gt;@zhangkom&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/derekshang"&gt;@derekshang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lianghyv"&gt;@lianghyv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nb312"&gt;@nb312&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Jim-Zenn"&gt;@Jim-Zenn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/andyiac"&gt;@andyiac&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TerenceCooper"&gt;@Terence Cooper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/leege100"&gt;@leege100&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-校对" class="anchor" aria-hidden="true" href="#校对"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;校对&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/sstruct"&gt;@yangtze&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ericxk"&gt;@ericxk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/WangHong-yang"&gt;@HongyangWang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/LichAmnesia"&gt;@LichAmnesia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhyhooo"&gt;@zhyhooo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/waiwaizheng"&gt;@waiwaizheng&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/WangHong-yang"&gt;@HongyangWang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorfly"&gt;@tensorfly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lonlonago"&gt;@lonlonago&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jishaoming"&gt;@jishaoming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lucky521"&gt;@lucky521&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://github.com/allensummer"&gt;@allensummer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/volvet"&gt;@volvet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ZHNathanielLee"&gt;@ZHNathanielLee&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PengFoo"&gt;@pengfoo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/qiaohaijun"&gt;@qiaohaijun&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/SeikaScarlet"&gt;@Seika&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-进度记录" class="anchor" aria-hidden="true" href="#进度记录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;进度记录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;2015-11-10, 谷歌发布全新人工智能系统TensorFlow并宣布开源, 极客学院Wiki启动协同翻译，创建 GitHub 仓库，制定协同规范&lt;/li&gt;
&lt;li&gt;2015-11-18, 所有章节认领完毕，翻译完成18章，校对认领7章，Star数361，fork数100，协同翻译QQ群及技术交流群的TF爱好者将近300人，GitHub搜索TensorFlow排名第二&lt;/li&gt;
&lt;li&gt;2015-12-10, Star数超过500&lt;/li&gt;
&lt;li&gt;2015-12-15, 项目正式上线&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-花絮" class="anchor" aria-hidden="true" href="#花絮"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;花絮&lt;/h2&gt;
&lt;p&gt;在组织翻译的过程中，有些事情令人印象深刻，记录下来，希望以后来学习文档的同学能够明了到手中这份文档的由来：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;参加翻译的有学生，也有老师；有专门研究AI/ML的，也有对此感兴趣的；有国内的，也有远在纽约的；有工程技术人员也有博士、专家&lt;/li&gt;
&lt;li&gt;其中一位，&lt;a href="http://www.longmotto.com" rel="nofollow"&gt;恩泽&lt;/a&gt;同学，为了翻译一篇文档，在前一天没有睡觉的情况下坚持翻完，20个小时没有合眼&lt;/li&gt;
&lt;li&gt;还有一位老师，刚从讲台上讲完课，就立即给我们的翻译提修改意见&lt;/li&gt;
&lt;li&gt;很多同学自发的将搭建环境中遇到的问题总结到FAQ里帮助他人&lt;/li&gt;
&lt;li&gt;为了一个翻译细节，经常是来回几次，和其他人讨论完善&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-持续改进" class="anchor" aria-hidden="true" href="#持续改进"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;持续改进&lt;/h2&gt;
&lt;p&gt;这样的一个高技术领域的文档，我们在翻译的过程中，难免会有不完善的地方，希望请大家一起帮助我们持续改进文档的翻译质量，帮助更多的人，方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在GitHub上提Issue或Pull Request，地址为: &lt;a href="https://github.com/jikexueyuanwiki/tensorflow-zh"&gt;https://github.com/jikexueyuanwiki/tensorflow-zh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;加入TensorFlow技术交流群，与TensorFlower们一起研究交流技术干货--TensorFlow技术交流群：782484288&lt;/li&gt;
&lt;li&gt;对翻译感兴趣？加入协同翻译群：248320884，与翻译大神一道研究TensorFlow的本地化&lt;/li&gt;
&lt;li&gt;给我们写邮件： &lt;a href="mailto:wiki@jikexueyuan.com"&gt;wiki@jikexueyuan.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-感谢支持" class="anchor" aria-hidden="true" href="#感谢支持"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;感谢支持&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://wiki.jikexueyuan.com" rel="nofollow"&gt;极客学院 Wiki&lt;/a&gt; 提供图文教程托管服务&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-离线版本" class="anchor" aria-hidden="true" href="#离线版本"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;离线版本&lt;/h2&gt;
&lt;p&gt;目前，离线版本(PDF、ePub)可正常下载、使用&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tex-pdf-修订版" class="anchor" aria-hidden="true" href="#tex-pdf-修订版"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tex-PDF 修订版&lt;/h2&gt;
&lt;p&gt;&lt;a href="tex_pdf"&gt;Tex-PDF 修订版&lt;/a&gt; 目前正在编订中，欢迎加入进来一起修订。您可以在此查看&lt;a href="tex_pdf/tensorflow_manual_cn.pdf"&gt;预览版&lt;/a&gt;目前最新状态。&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jikexueyuanwiki</author><guid isPermaLink="false">https://github.com/jikexueyuanwiki/tensorflow-zh</guid><pubDate>Thu, 28 Nov 2019 00:05:00 GMT</pubDate></item><item><title>THUNLP-MT/MT-Reading-List #6 in TeX, This week</title><link>https://github.com/THUNLP-MT/MT-Reading-List</link><description>&lt;p&gt;&lt;i&gt;A machine translation reading list maintained by Tsinghua Natural Language Processing Group&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-translation-reading-list" class="anchor" aria-hidden="true" href="#machine-translation-reading-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Translation Reading List&lt;/h1&gt;
&lt;p&gt;This is a machine translation reading list maintained by the Tsinghua Natural Language Processing Group.&lt;/p&gt;
&lt;p&gt;The past three decades have witnessed the rapid development of machine translation, especially for data-driven approaches such as statistical machine translation (SMT) and neural machine translation (NMT). Due to the dominance of NMT at the present time, priority is given to collecting important, up-to-date NMT papers; the &lt;a href="http://www.statmt.org/survey/" rel="nofollow"&gt;Edinburgh/JHU MT research survey wiki&lt;/a&gt; has good coverage of older papers and a brief description for each sub-topic of MT. Our list is still incomplete and the categorization might be inappropriate. We will keep adding papers and improving the list. Any suggestions are welcome!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#10_must_reads"&gt;10 Must Reads&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#statistical_machine_translation"&gt;Statistical Machine Translation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#smt_tutorials"&gt;Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#word_based_models"&gt;Word-based Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#phrase_based_models"&gt;Phrase-based Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#syntax_based_models"&gt;Syntax-based Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#discriminative_training"&gt;Discriminative Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#system_combination"&gt;System Combination&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#human_centered_smt"&gt;Human-centered SMT&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#interactive"&gt;Interactive SMT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#adaptation_smt"&gt;Adaptation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#evaluation"&gt;Evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#neural_machine_translation"&gt;Neural Machine Translation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#nmt_tutorials"&gt;Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#model_architecture"&gt;Model Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#attention_mechanism"&gt;Attention Mechanism&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#open_vocabulary"&gt;Open Vocabulary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#training"&gt;Training Framework&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#decoding"&gt;Decoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#low_resource_language_translation"&gt;Low-resource Language Translation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#semi_supervised"&gt;Semi-supervised Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#unsupervised"&gt;Unsupervised Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pivot_based"&gt;Pivot-based Methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data_augmentation"&gt;Data Augmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data_selection"&gt;Data Selection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#transfer_learning"&gt;Transfer Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#meta_learning"&gt;Meta Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#multi-task_learning"&gt;Multilingual Machine Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#prior_knowledge_integration"&gt;Prior Knowledge Integration&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#word_phrase_constraints"&gt;Word/Phrase Constraints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#syntactic_semantic_constraints"&gt;Syntactic/Semantic Constraints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#coverage_constraints"&gt;Coverage Constraints&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#document_level_translation"&gt;Document-level Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#robustness"&gt;Robustness&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#interpretability"&gt;Interpretability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#linguistic_interpretation"&gt;Linguistic Interpretation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fairness_and_diversity"&gt;Fairness and Diversity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#efficiency"&gt;Efficiency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#speech_translation_and_simultaneous_translation"&gt;Speech Translation and Simultaneous Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#multi_modality"&gt;Multi-modality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ensemble_reranking"&gt;Ensemble and Reranking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pre_training"&gt;Pre-training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#domain_adaptation"&gt;Domain Adaptation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#quality_estimation"&gt;Quality Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#human_centered"&gt;Human-centered NMT&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#interactive_nmt"&gt;Interactive NMT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ape"&gt;Automatic Post-Editing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#poetry_translation"&gt;Poetry Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#eco_friendly"&gt;Eco-friendly&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#word_translation"&gt;Word Translation (Bilingual Lexicon Induction)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wmt_winners"&gt;WMT Winners&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#wmt19"&gt;WMT 2019&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wmt18"&gt;WMT 2018&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wmt17"&gt;WMT 2017&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wmt16"&gt;WMT 2016&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="user-content-10_must_reads"&gt;&lt;a id="user-content-10-must-reads" class="anchor" aria-hidden="true" href="#10-must-reads"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;10 Must Reads&lt;/h2&gt; 
&lt;ul&gt;
&lt;li&gt;Peter E. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. &lt;a href="http://aclweb.org/anthology/J93-2003" rel="nofollow"&gt;The Mathematics of Statistical Machine Translation: Parameter Estimation&lt;/a&gt;. &lt;em&gt;Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=2259057253133260714&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4,965)&lt;/li&gt;
&lt;li&gt;Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. &lt;a href="http://aclweb.org/anthology/P02-1040" rel="nofollow"&gt;BLEU: a Method for Automatic Evaluation of Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2002&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=9019091454858686906&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 8,507)&lt;/li&gt;
&lt;li&gt;Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. &lt;a href="http://aclweb.org/anthology/N03-1017" rel="nofollow"&gt;Statistical Phrase-Based Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2003&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=11796378766060939113&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3,514)&lt;/li&gt;
&lt;li&gt;Franz Josef Och. 2003. &lt;a href="http://aclweb.org/anthology/P03-1021" rel="nofollow"&gt;Minimum Error Rate Training in Statistical Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2003&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=15358949031331886708&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2,982)&lt;/li&gt;
&lt;li&gt;David Chiang. 2007. &lt;a href="http://aclweb.org/anthology/J07-2003" rel="nofollow"&gt;Hierarchical Phrase-Based Translation&lt;/a&gt;. &lt;em&gt;Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=17074501474509484516&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1,192)&lt;/li&gt;
&lt;li&gt;Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. &lt;a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" rel="nofollow"&gt;Sequence to Sequence Learning
with Neural Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of NIPS 2014&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13133880703797056141&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5,428)&lt;/li&gt;
&lt;li&gt;Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. &lt;a href="https://arxiv.org/pdf/1409.0473.pdf" rel="nofollow"&gt;Neural Machine Translation by Jointly Learning to Align and Translate&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2015&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=9430221802571417838&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5,572)&lt;/li&gt;
&lt;li&gt;Diederik P. Kingma, Jimmy Ba. 2015. &lt;a href="https://arxiv.org/pdf/1412.6980" rel="nofollow"&gt;Adam: A Method for Stochastic Optimization&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2015&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=16194105527543080940&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 16,572)&lt;/li&gt;
&lt;li&gt;Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. &lt;a href="https://arxiv.org/pdf/1508.07909.pdf" rel="nofollow"&gt;Neural Machine Translation of Rare Words with Subword Units&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=1307964014330144942&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 789)&lt;/li&gt;
&lt;li&gt;Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. &lt;a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" rel="nofollow"&gt;Attention is All You Need&lt;/a&gt;. In &lt;em&gt;Proceedings of NIPS 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=2960712678066186980&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1,047)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="user-content-statistical_machine_translation"&gt;&lt;a id="user-content-statistical-machine-translation" class="anchor" aria-hidden="true" href="#statistical-machine-translation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Statistical Machine Translation&lt;/h2&gt;
&lt;h3 id="user-content-smt_tutorials"&gt;&lt;a id="user-content-tutorials" class="anchor" aria-hidden="true" href="#tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorials&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Philipp Koehn. 2006. &lt;a href="http://homepages.inf.ed.ac.uk/pkoehn/publications/tutorial2006.pdf" rel="nofollow"&gt;Statistical Machine Translation: the Basic, the Novel, and the Speculative&lt;/a&gt;. &lt;em&gt;EACL 2006 Tutorial&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=226053141145183075&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 10)&lt;/li&gt;
&lt;li&gt;Adam Lopez. 2008. &lt;a href="http://delivery.acm.org/10.1145/1390000/1380586/a8-lopez.pdf?ip=101.5.129.50&amp;amp;id=1380586&amp;amp;acc=ACTIVE%20SERVICE&amp;amp;key=BF85BBA5741FDC6E%2E587F3204F5B62A59%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;amp;__acm__=1546058891_981e84a24804f2dbc0549b9892a2ea1d" rel="nofollow"&gt;Statistical Machine Translation&lt;/a&gt;. &lt;em&gt;ACM Computing Surveys&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13327711981648149476&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 373)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-word_based_models"&gt;&lt;a id="user-content-word-based-models" class="anchor" aria-hidden="true" href="#word-based-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Word-based Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Peter E. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. &lt;a href="http://aclweb.org/anthology/J93-2003" rel="nofollow"&gt;The Mathematics of Statistical Machine Translation: Parameter Estimation&lt;/a&gt;. &lt;em&gt;Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=2259057253133260714&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4,965)&lt;/li&gt;
&lt;li&gt;Stephan Vogel, Hermann Ney, and Christoph Tillmann. 1996. &lt;a href="http://aclweb.org/anthology/C96-2141" rel="nofollow"&gt;HMM-Based Word Alignment in Statistical Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 1996&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=6742027174667056165&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 940)&lt;/li&gt;
&lt;li&gt;Franz Josef Och and Hermann Ney. 2003. &lt;a href="http://aclweb.org/anthology/J03-1002" rel="nofollow"&gt;A Systematic Comparison of Various Statistical Alignment Models&lt;/a&gt;. &lt;em&gt;Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=7906670690027479083&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3,980)&lt;/li&gt;
&lt;li&gt;Percy Liang, Ben Taskar, and Dan Klein. 2006. &lt;a href="https://cs.stanford.edu/~pliang/papers/alignment-naacl2006.pdf" rel="nofollow"&gt;Alignment by Agreement&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2006&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=10766838746666771394&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 452)&lt;/li&gt;
&lt;li&gt;Chris Dyer, Victor Chahuneau, and Noah A. Smith. 2013. &lt;a href="http://www.aclweb.org/anthology/N13-1073" rel="nofollow"&gt;A Simple, Fast, and Effective Reparameterization of IBM Model 2&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2013&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13560076980956479370&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 310)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-phrase_based_models"&gt;&lt;a id="user-content-phrase-based-models" class="anchor" aria-hidden="true" href="#phrase-based-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Phrase-based Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. &lt;a href="http://aclweb.org/anthology/N03-1017" rel="nofollow"&gt;Statistical Phrase-Based Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2003&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=11796378766060939113&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3,516)&lt;/li&gt;
&lt;li&gt;Michel Galley and Christopher D. Manning. 2008. &lt;a href="https://nlp.stanford.edu/pubs/emnlp08-lexorder.pdf" rel="nofollow"&gt;A Simple and Effective Hierarchical Phrase Reordering Model&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2008&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=14572547803642015856&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 275)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-syntax_based_models"&gt;&lt;a id="user-content-syntax-based-models" class="anchor" aria-hidden="true" href="#syntax-based-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Syntax-based Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dekai Wu. 1997. &lt;a href="http://aclweb.org/anthology/J97-3002" rel="nofollow"&gt;Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora&lt;/a&gt;. &lt;em&gt;Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=7926725626202301933&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1,009)&lt;/li&gt;
&lt;li&gt;Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer. 2006. &lt;a href="http://aclweb.org/anthology/P06-1121" rel="nofollow"&gt;Scalable Inference and Training of Context-Rich Syntactic Translation Models&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING/ACL 2006&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=2650671041278094269&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 475)&lt;/li&gt;
&lt;li&gt;Yang Liu, Qun Liu, and Shouxun Lin. 2006. &lt;a href="http://aclweb.org/anthology/P06-1077" rel="nofollow"&gt;Tree-to-String Alignment Template for Statistical Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING/ACL 2006&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=8683308453323663525&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 391)&lt;/li&gt;
&lt;li&gt;Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. &lt;a href="https://aclanthology.info/pdf/P/P06/P06-1066.pdf" rel="nofollow"&gt;Maximum Entropy Based Phrase Reordering Model for Statistical Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING/ACL 2006&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=11896300896063367737&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 299)&lt;/li&gt;
&lt;li&gt;David Chiang. 2007. &lt;a href="http://aclweb.org/anthology/J07-2003" rel="nofollow"&gt;Hierarchical Phrase-Based Translation&lt;/a&gt;. &lt;em&gt;Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=17074501474509484516&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1,192)&lt;/li&gt;
&lt;li&gt;Liang Huang and David Chiang. 2007. &lt;a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.5058&amp;amp;rep=rep1&amp;amp;type=pdf" rel="nofollow"&gt;Forest Rescoring: Faster Decoding with Integrated Language Models&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2007&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=2826188279623417237&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 280)&lt;/li&gt;
&lt;li&gt;Haitao Mi, Liang Huang, and Qun Liu. 2008. &lt;a href="http://aclweb.org/anthology/P08-1023" rel="nofollow"&gt;Forest-based Translation&lt;/a&gt;. &lt;em&gt;In Proceedings of ACL 2008&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=11263493281241243162&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 239)&lt;/li&gt;
&lt;li&gt;Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li, Chew Lim Tan, and Sheng Li. 2008. &lt;a href="http://www.aclweb.org/anthology/P08-1064" rel="nofollow"&gt;A Tree Sequence Alignment-based Tree-to-Tree Translation Model&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2008&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=4828105603038412208&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 124)&lt;/li&gt;
&lt;li&gt;Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. &lt;a href="http://aclweb.org/anthology/P08-1066" rel="nofollow"&gt;A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2008&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=15082517325172081801&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 278)&lt;/li&gt;
&lt;li&gt;Haitao Mi and Liang Huang. 2008. &lt;a href="http://aclweb.org/anthology/D08-1022" rel="nofollow"&gt;Forest-based Translation Rule Extraction&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2008&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=11263493281241243162&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 239)&lt;/li&gt;
&lt;li&gt;Yang Liu, Yajuan Lü, and Qun Liu. 2009. &lt;a href="http://aclweb.org/anthology/P09-1063" rel="nofollow"&gt;Improving Tree-to-Tree Translation with Packed Forests&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL/IJNLP 2009&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=3907324274083528908&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 93)&lt;/li&gt;
&lt;li&gt;David Chiang. 2010. &lt;a href="http://aclweb.org/anthology/P10-1146" rel="nofollow"&gt;Learning to Translate with Source and Target Syntax&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2010&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=18270412258769590027&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 118)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-discriminative_training"&gt;&lt;a id="user-content-discriminative-training" class="anchor" aria-hidden="true" href="#discriminative-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Discriminative Training&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Franz Josef Och and Hermann Ney. 2002. &lt;a href="http://aclweb.org/anthology/P02-1038" rel="nofollow"&gt;Discriminative Training and Maximum Entropy Models for Statistical Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2002&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=2845378992177918439&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1,258)&lt;/li&gt;
&lt;li&gt;Franz Josef Och. 2003. &lt;a href="http://aclweb.org/anthology/P03-1021" rel="nofollow"&gt;Minimum Error Rate Training in Statistical Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2003&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=15358949031331886708&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2,984)&lt;/li&gt;
&lt;li&gt;Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki Isozaki. 2007. &lt;a href="http://aclweb.org/anthology/D07-1080" rel="nofollow"&gt;Online Large-Margin Training for Statistical Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP-CoNLL 2007&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=6690339336101573833&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 197)&lt;/li&gt;
&lt;li&gt;David Chiang, Kevin Knight, and Wei Wang. 2009. &lt;a href="http://aclweb.org/anthology/N09-1025" rel="nofollow"&gt;11,001 New Features for Statistical Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2009&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=14062409519286340147&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 251)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-system_combination"&gt;&lt;a id="user-content-system-combination" class="anchor" aria-hidden="true" href="#system-combination"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;System Combination&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Antti-Veikko Rosti, Spyros Matsoukas, and Richard Schwartz. 2007. &lt;a href="http://aclweb.org/anthology/P07-1040" rel="nofollow"&gt;Improved Word-Level System Combination for Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2007&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13310846375895519088&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 144)&lt;/li&gt;
&lt;li&gt;Xiaodong He, Mei Yang, Jianfeng Gao, Patrick Nguyen, and Robert Moore. 2008. &lt;a href="http://aclweb.org/anthology/D08-1011" rel="nofollow"&gt;Indirect-HMM-based Hypothesis Alignment for Combining Outputs from Machine Translation Systems&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2008&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=5843300493006970528&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 96)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-human_centered_smt"&gt;&lt;a id="user-content-human-centered-smt" class="anchor" aria-hidden="true" href="#human-centered-smt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Human-centered SMT&lt;/h3&gt;
&lt;h4 id="user-content-interactive"&gt;&lt;a id="user-content-interactive-smt" class="anchor" aria-hidden="true" href="#interactive-smt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive SMT&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;George Foster, Pierre Isabelle and Pierre Plamondon. 1997. &lt;a href="https://sci-hub.tw/10.2307/40009035" rel="nofollow"&gt;Target-text mediated interactive machine translation&lt;/a&gt;. &lt;em&gt;Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=17084037882064721827&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 116)&lt;/li&gt;
&lt;li&gt;Philippe Langlais, Guy Lapalme and Marie Lorange. 2002. &lt;a href="https://sci-hub.tw/10.2307/40007093" rel="nofollow"&gt;TransType: Development-Evaluation Cycles to Boost Translator’s Productivity&lt;/a&gt;. &lt;em&gt;Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=7892155138946158318&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 74)&lt;/li&gt;
&lt;li&gt;Jesús Tomas and Francisco Casacuberta. 2006. &lt;a href="http://aclweb.org/anthology/P06-2107" rel="nofollow"&gt;Statistical phrase-based models for interactive computer-assisted translation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING/ACL&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=2242179645100420046&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 31)&lt;/li&gt;
&lt;li&gt;Enrique Vidal, Francisco Casacuberta, Luis Rodríguez-Ruiz, Jorge Civera, Carlos D. Martínez-Hinarejos. 2006. &lt;a href="https://ieeexplore.ieee.org/document/1621206" rel="nofollow"&gt;Computer-Assisted Translation Using Speech Recognition&lt;/a&gt;. &lt;em&gt;IEEE Transaction on Audio, Speech and Language Processing&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=32625184311110830&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 62)&lt;/li&gt;
&lt;li&gt;Shahram Khadivi and Hermann Ney. 2008. &lt;a href="https://sci-hub.tw/10.1109/tasl.2008.2004301" rel="nofollow"&gt;Integration of Speech Recognition and Machine Translation in Computer-Assisted Translation&lt;/a&gt;. &lt;em&gt;IEEE Transaction on Audio, Speech and Language Processing&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=1690852455408892756&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 30)&lt;/li&gt;
&lt;li&gt;Sergio Barrachina, Oliver Bender, Francisco Casacuberta, Jorge Civera, Elsa Cubel, Shahram Khadivi, Antonio L. Lagarda, Hermann Ney, Jesús Tomás and Enrique Vidal. 2009. &lt;a href="https://www.mitpressjournals.org/doi/abs/10.1162/coli.2008.07-055-R2-06-29" rel="nofollow"&gt;Statistical approaches to computer-assisted translation&lt;/a&gt;. &lt;em&gt;Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=17691637682117292572&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 207)&lt;/li&gt;
&lt;li&gt;Francisco Casacuberta, Jorge Civera, Elsa Cubel, Antonio L. Lagarda, Guy Lapalme, Elliott Macklovitch, Enrique Vidal. 2009. &lt;a href="https://sci-hub.tw/10.1145/1562764.1562798" rel="nofollow"&gt;Human interaction for high quality machine translation&lt;/a&gt;. &lt;em&gt;Communications of the ACM&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=6184654159576071790&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 49)&lt;/li&gt;
&lt;li&gt;Vicent Alabau, Alberto Sanchis and Francisco Casacuberta. 2014. &lt;a href="sci-hub.tw/10.1016/j.patcog.2013.09.035"&gt;Improving on-line handwritten recognition in interactive machine translation&lt;/a&gt;. &lt;em&gt;Pattern Recognition&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=11987123133913382404&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 18)&lt;/li&gt;
&lt;li&gt;Shanbo Cheng, Shujian Huang, Huadong Chen, Xin-Yu Dai and  Jiajun Chen. 2016. &lt;a href="http://www.aclweb.org/anthology/N16-1148" rel="nofollow"&gt;PRIMT: A Pick-Revise Framework for Interactive Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=3643727460542665178&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 9)&lt;/li&gt;
&lt;li&gt;Miguel Domingo, Álvaro Peris and Francisco Casacuberta. 2018. &lt;a href="https://www.researchgate.net/publication/322275484_Segment-based_interactive-predictive_machine_translation" rel="nofollow"&gt;Segment-based interactive-predictive machine translation&lt;/a&gt;. &lt;em&gt;Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=4148585683672959462&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="user-content-adaptation_smt"&gt;&lt;a id="user-content-adaptation" class="anchor" aria-hidden="true" href="#adaptation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Adaptation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Pascual Martínez-Gómez, Germán Sanchis-Trilles and Francisco Casacuberta. 2012. &lt;a href="https://sci-hub.tw/10.1016/j.patcog.2012.01.011" rel="nofollow"&gt;Online adaptation strategies for statistical machine translation in post-editing scenarios&lt;/a&gt;. &lt;em&gt;Pattern Recognition&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=9143628035426486873&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 40)&lt;/li&gt;
&lt;li&gt;Jesús González-Rubio and Francisco Casacuberta. 2014. &lt;a href="https://sci-hub.tw/10.1016/j.patrec.2013.06.007" rel="nofollow"&gt;Cost-Sensitive Active Learning for Computer-Assisted Translation&lt;/a&gt;. &lt;em&gt;Pattern Recognition Letters&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13196627956841822823&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Antonio L. Lagarda, Daniel Ortiz-Martínez, Vicent Alabau and Francisco Casacuberta. 2015. &lt;a href="https://sci-hub.tw/10.1016/j.csl.2014.10.004" rel="nofollow"&gt;Translating without in-domain corpus: Machine translation post-editing with online learning techniques&lt;/a&gt;. &lt;em&gt;Computer Speech &amp;amp; Language&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=6721510771212778605&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 10)&lt;/li&gt;
&lt;li&gt;Germán Sanchis-Trilles, Francisco Casacuberta. 2015. &lt;a href="https://sci-hub.tw/10.1016/j.csl.2015.03.001" rel="nofollow"&gt;Improving translation quality stability using Bayesian predictive adaptation&lt;/a&gt;. &lt;em&gt;Computer Speech &amp;amp; Language&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?q=Improving+translation+quality+stability+using+Bayesian+predictive+adaptation" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Daniel Ortiz-Martínez. 2016. &lt;a href="https://www.mitpressjournals.org/doi/full/10.1162/COLI_a_00244" rel="nofollow"&gt;Online Learning for Statistical Machine Translation&lt;/a&gt;. &lt;em&gt;Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=4979468821667106694&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 13)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="user-content-evaluation"&gt;&lt;a id="user-content-evaluation" class="anchor" aria-hidden="true" href="#evaluation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Evaluation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. &lt;a href="http://aclweb.org/anthology/P02-1040" rel="nofollow"&gt;BLEU: a Method for Automatic Evaluation of Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2002&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9019091454858686906&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 8,499)&lt;/li&gt;
&lt;li&gt;Philipp Koehn. 2004. &lt;a href="http://www.aclweb.org/anthology/W04-3250" rel="nofollow"&gt;Statistical Significance Tests for Machine Translation Evaluation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2004&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=6141850486206753388&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1,015)&lt;/li&gt;
&lt;li&gt;Satanjeev Banerjee and Alon Lavie. 2005. &lt;a href="http://aclweb.org/anthology/W05-0909" rel="nofollow"&gt;METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments&lt;/a&gt;. In &lt;em&gt;Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=11797833340491598355&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1,355)&lt;/li&gt;
&lt;li&gt;Matthew Snover and Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. &lt;a href="http://mt-archive.info/AMTA-2006-Snover.pdf" rel="nofollow"&gt;A Study of Translation Edit Rate with Targeted Human Annotation&lt;/a&gt;. In &lt;em&gt;Proceedings of AMTA 2006&lt;/em&gt;.   (&lt;a href="https://scholar.google.com.hk/scholar?cites=1809540661740640949&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1,713)&lt;/li&gt;
&lt;li&gt;Maja Popovic. 2015. &lt;a href="http://aclweb.org/anthology/W15-3049" rel="nofollow"&gt;chrF: Character n-gram F-score for Automatic MT Evaluation&lt;/a&gt;. In &lt;em&gt;Proceedings of WMT 2015&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=12169100229181212462" rel="nofollow"&gt;Citation&lt;/a&gt;: 58)&lt;/li&gt;
&lt;li&gt;Xin Wang, Wenhu Chen, Yuan-Fang Wang, and William Yang Wang. 2018. &lt;a href="http://aclweb.org/anthology/P18-1083" rel="nofollow"&gt;No Metrics Are Perfect: Adversarial Reward Learning for Visual Storytelling&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=1809540661740640949&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 10)&lt;/li&gt;
&lt;li&gt;Arun Tejasvi Chaganty, Stephen Mussman, and Percy Liang. 2018. &lt;a href="https://arxiv.org/pdf/1807.02202" rel="nofollow"&gt;The price of debiasing automatic metrics in natural language evaluation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Graham Neubig, Zi-Yi Dou, Junjie Hu, Paul Michel, Danish Pruthi, and Xinyi Wang. 2019. &lt;a href="https://arxiv.org/pdf/1903.07926.pdf" rel="nofollow"&gt;compare-mt: A Tool for Holistic Comparison of Language Generation Systems&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Robert Schwarzenberg, David Harbecke, Vivien Macketanz, Eleftherios Avramidis, and Sebastian Möller. 2019. &lt;a href="https://arxiv.org/pdf/1903.12017.pdf" rel="nofollow"&gt;Train, Sort, Explain: Learning to Diagnose Translation Models&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Nitika Mathur, Timothy Baldwin, and Trevor Cohn. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1269" rel="nofollow"&gt;Putting Evaluation in Context: Contextual Embeddings Improve Machine Translation Evaluation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Prathyusha Jwalapuram, Shafiq Joty, Irina Temnikova, and Preslav Nakov. 2019. &lt;a href="https://arxiv.org/pdf/1909.00131" rel="nofollow"&gt;Evaluating Pronominal Anaphora in Machine Translation: An Evaluation Measure and a Test Suite&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="user-content-neural_machine_translation"&gt;&lt;a id="user-content-neural-machine-translation" class="anchor" aria-hidden="true" href="#neural-machine-translation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Neural Machine Translation&lt;/h2&gt;
&lt;h3 id="user-content-nmt_tutorials"&gt;&lt;a id="user-content-tutorials-1" class="anchor" aria-hidden="true" href="#tutorials-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorials&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Thang Luong, Kyunghyun Cho, and Christopher Manning. 2016. &lt;a href="https://nlp.stanford.edu/projects/nmt/Luong-Cho-Manning-NMT-ACL2016-v4.pdf" rel="nofollow"&gt;Neural Machine Translation&lt;/a&gt;. &lt;em&gt;ACL 2016 Tutorial&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Graham Neubig. 2017. &lt;a href="https://arxiv.org/pdf/1703.01619.pdf" rel="nofollow"&gt;Neural Machine Translation and Sequence-to-sequence Models: A Tutorial&lt;/a&gt;. &lt;em&gt;arXiv:1703.01619&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=17621873290135947085&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 45)&lt;/li&gt;
&lt;li&gt;Oriol Vinyals and Navdeep Jaitly. 2017. &lt;a href="https://docs.google.com/presentation/d/1quIMxEEPEf5EkRHc2USQaoJRC4QNX6_KomdZTBMBWjk/present?slide=id.p" rel="nofollow"&gt;Seq2Seq ICML Tutorial&lt;/a&gt;. &lt;em&gt;ICML 2017 Tutorial&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Philipp Koehn. 2017. &lt;a href="https://arxiv.org/abs/1709.07809" rel="nofollow"&gt;Neural Machine Translation&lt;/a&gt;. &lt;em&gt;arxiv:1709.07809&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Philipp Koehn and Rebecca Knowles. 2017. &lt;a href="http://www.aclweb.org/anthology/W17-3204" rel="nofollow"&gt;Six Challenges for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of the First Workshop on Neural Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=2797085496823228867&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 121)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-model_architecture"&gt;&lt;a id="user-content-model-architecture" class="anchor" aria-hidden="true" href="#model-architecture"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Nal Kalchbrenner and Phil Blunsom. 2013. &lt;a href="http://aclweb.org/anthology/D13-1176" rel="nofollow"&gt;Recurrent Continuous Translation Models&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2013&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=14122455772200752032&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 623)&lt;/li&gt;
&lt;li&gt;Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. &lt;a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" rel="nofollow"&gt;Sequence to Sequence Learning
with Neural Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of NIPS 2014&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13133880703797056141&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5,452)&lt;/li&gt;
&lt;li&gt;Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. &lt;a href="https://arxiv.org/pdf/1409.0473" rel="nofollow"&gt;Neural Machine Translation by Jointly Learning to Align and Translate&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2015&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=9430221802571417838&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5,596)&lt;/li&gt;
&lt;li&gt;Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Łukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes, and Jeffrey Dean. 2016. &lt;a href="https://arxiv.org/pdf/1609.08144" rel="nofollow"&gt;Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NIPS 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=17018428530559089870&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1,046)&lt;/li&gt;
&lt;li&gt;Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. 2016. &lt;a href="http://aclweb.org/anthology/Q16-1027" rel="nofollow"&gt;Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=2319930273054317494&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 73)&lt;/li&gt;
&lt;li&gt;Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O.K. Li. 2016. &lt;a href="http://aclweb.org/anthology/P16-1154" rel="nofollow"&gt;Incorporating Copying Mechanism in Sequence-to-Sequence Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=6836221883265474919&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 254)&lt;/li&gt;
&lt;li&gt;Biao Zhang, Deyi Xiong, Jinsong Su, Hong Duan, and Min Zhang. 2016. &lt;a href="http://aclweb.org/anthology/D16-1050" rel="nofollow"&gt;Variational Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=16453011540088245227&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 38)&lt;/li&gt;
&lt;li&gt;Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Koray Kavukcuoglu. 2016. &lt;a href="https://arxiv.org/pdf/1610.10099" rel="nofollow"&gt;Neural Machine Translation in Linear Time&lt;/a&gt;. &lt;em&gt;arXiv:1610.10099&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13142156854384740601&amp;amp;as_sdt=5,39&amp;amp;sciodt=0,39&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 189)&lt;/li&gt;
&lt;li&gt;Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. 2017. &lt;a href="https://arxiv.org/pdf/1705.03122.pdf" rel="nofollow"&gt;Convolutional Sequence to Sequence Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=9032432574575787905&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 453)&lt;/li&gt;
&lt;li&gt;Jonas Gehring, Michael Auli, David Grangier, and Yann Dauphin. 2017. &lt;a href="http://aclweb.org/anthology/P17-1012" rel="nofollow"&gt;A Convolutional Encoder Model for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13078160224216368728&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 85)&lt;/li&gt;
&lt;li&gt;Mingxuan Wang, Zhengdong Lu, Jie Zhou, and Qun Liu. 2017. &lt;a href="http://aclweb.org/anthology/P17-1013" rel="nofollow"&gt;Deep Neural Machine Translation with Linear Associative Unit&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13710779557836853910&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 21)&lt;/li&gt;
&lt;li&gt;Matthias Sperber, Graham Neubig, Jan Niehues, and Alex Waibel. 2017. &lt;a href="http://aclweb.org/anthology/D17-1145" rel="nofollow"&gt;Neural Lattice-to-Sequence Models for Uncertain Inputs&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=6601112324222176825&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc Le. 2017. &lt;a href="http://aclweb.org/anthology/D17-1151" rel="nofollow"&gt;Massive Exploration of Neural Machine Translation Architectures&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=17797498583666145091&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 114)&lt;/li&gt;
&lt;li&gt;Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. &lt;a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" rel="nofollow"&gt;Attention is All You Need&lt;/a&gt;. In &lt;em&gt;Proceedings of NIPS 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=2960712678066186980&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1,748)&lt;/li&gt;
&lt;li&gt;Yingce Xia, Fei Tian, Lijun Wu, Jianxin Lin, Tao Qin, Nenghai Yu, and Tie-Yan Liu. 2017. &lt;a href="https://papers.nips.cc/paper/6775-deliberation-networks-sequence-generation-beyond-one-pass-decoding.pdf" rel="nofollow"&gt;Deliberation Networks: Sequence Generation Beyond One-Pass Decoding&lt;/a&gt;. In &lt;em&gt;Proceedings of NIPS 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=5359968740795634948" rel="nofollow"&gt;Citation&lt;/a&gt;: 38)&lt;/li&gt;
&lt;li&gt;Zhaopeng Tu, Yang Liu, Lifeng Shang, Xiaohua Liu, and Hang Li. 2017. &lt;a href="https://arxiv.org/pdf/1611.01874" rel="nofollow"&gt;Neural machine translation with reconstruction&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=1310099558617172101&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 75)&lt;/li&gt;
&lt;li&gt;Lukasz Kaiser, Aidan N. Gomez, and Francois Chollet. 2018. &lt;a href="https://openreview.net/pdf?id=S1jBcueAb" rel="nofollow"&gt;Depthwise Separable Convolutions for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=7520360878420709403&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 27)&lt;/li&gt;
&lt;li&gt;Yanyao Shen, Xu Tan, Di He, Tao Qin, and Tie-Yan Liu. 2018. &lt;a href="http://aclweb.org/anthology/N18-1117" rel="nofollow"&gt;Dense Information Flow for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=12417301759540220817&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Wenhu Chen, Guanlin Li, Shuo Ren, Shujie Liu, Zhirui Zhang, Mu Li, and Ming Zhou. 2018. &lt;a href="http://aclweb.org/anthology/N18-1154" rel="nofollow"&gt;Generative Bridging Network for Neural Sequence Prediction&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=16479416225427738693" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Mia Xu Chen, Orhan Firat, Ankur Bapna, Melvin Johnson, Wolfgang Macherey, George Foster, Llion Jones, Mike Schuster, Noam Shazeer, Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Zhifeng Chen, Yonghui Wu, and Macduff Hughes. 2018. &lt;a href="http://aclweb.org/anthology/P18-1008" rel="nofollow"&gt;The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=1960239321427735403&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 22)&lt;/li&gt;
&lt;li&gt;Weiyue Wang, Derui Zhu, Tamer Alkhouli, Zixuan Gan, and Hermann Ney. 2018. &lt;a href="http://aclweb.org/anthology/P18-2060" rel="nofollow"&gt;Neural Hidden Markov Model for Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13737032050194395214&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Jingjing Gong, Xipeng Qiu, Shaojing Wang, and Xuanjing Huang. 2018. &lt;a href="http://aclweb.org/anthology/C18-1232" rel="nofollow"&gt;Information Aggregation via Dynamic Routing for Sequence Encoding&lt;/a&gt;. In &lt;em&gt;COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Qiang Wang, Fuxue Li, Tong Xiao, Yanyang Li, Yinqiao Li, and Jingbo Zhu. 2018. &lt;a href="http://aclweb.org/anthology/C18-1255" rel="nofollow"&gt;Multi-layer Representation Fusion for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yachao Li, Junhui Li, and Min Zhang. 2018. &lt;a href="http://aclweb.org/anthology/C18-1257" rel="nofollow"&gt;Adaptive Weighting for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Kaitao Song, Xu Tan, Di He, Jianfeng Lu, Tao Qin, and Tie-Yan Liu. 2018. &lt;a href="http://aclweb.org/anthology/C18-1259" rel="nofollow"&gt;Double Path Networks for Sequence to Sequence Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Zi-Yi Dou, Zhaopeng Tu, Xing Wang, Shuming Shi, and Tong Zhang. 2018. &lt;a href="http://aclweb.org/anthology/D18-1457" rel="nofollow"&gt;Exploiting Deep Representations for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=8760242283445305561&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Biao Zhang, Deyi Xiong, Jinsong Su, Qian Lin, and Huiji Zhang. 2018. &lt;a href="http://aclweb.org/anthology/D18-1459" rel="nofollow"&gt;Simplifying Neural Machine Translation with Addition-Subtraction Twin-Gated Recurrent Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Gongbo Tang, Mathias Müller, Annette Rios, and Rico Sennrich. 2018. &lt;a href="http://aclweb.org/anthology/D18-1458" rel="nofollow"&gt;Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=8994080673363827758&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Ke Tran, Arianna Bisazza, and Christof Monz. 2018. &lt;a href="http://aclweb.org/anthology/D18-1503" rel="nofollow"&gt;The Importance of Being Recurrent for Modeling Hierarchical Structure&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=16387948292048936516&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Parnia Bahar, Christopher Brix, and Hermann Ney. 2018. &lt;a href="http://aclweb.org/anthology/D18-1335" rel="nofollow"&gt;Towards Two-Dimensional Sequence to Sequence Model in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=4611047151878523903&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Tianyu He, Xu Tan, Yingce Xia, Di He, Tao Qin, Zhibo Chen, and Tie-Yan Liu. 2018. &lt;a href="http://papers.nips.cc/paper/8019-layer-wise-coordination-between-encoder-and-decoder-for-neural-machine-translation.pdf" rel="nofollow"&gt;Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NeurIPS 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=14258883426797488339&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Harshil Shah and David Barber. 2018. &lt;a href="http://papers.nips.cc/paper/7409-generative-neural-machine-translation.pdf" rel="nofollow"&gt;Generative Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NeurIPS 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Hany Hassan, Anthony Aue, Chang Chen, Vishal Chowdhary, Jonathan Clark, Christian Federmann, Xuedong Huang, Marcin Junczys-Dowmunt, William Lewis, Mu Li, Shujie Liu, Tie-Yan Liu, Renqian Luo, Arul Menezes, Tao Qin, Frank Seide, Xu Tan, Fei Tian, Lijun Wu, Shuangzhi Wu, Yingce Xia, Dongdong Zhang, Zhirui Zhang, and Ming Zhou. 2018. &lt;a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/final-achieving-human.pdf" rel="nofollow"&gt;Achieving Human Parity on Automatic Chinese to English News Translation&lt;/a&gt;. Technical report. Microsoft AI &amp;amp; Research. (&lt;a href="https://scholar.google.com/scholar?cites=3670312788898741170&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 41)&lt;/li&gt;
&lt;li&gt;Yikang Shen, Shawn Tan, Alessandro Sordoni, and Aaron Courville. 2019. &lt;a href="https://openreview.net/pdf?id=B1l6qiR5F7" rel="nofollow"&gt;Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Felix Wu, Angela Fan, Alexei Baevski, Yann Dauphin, and Michael Auli. 2019. &lt;a href="https://openreview.net/pdf?id=SkVhlh09tX" rel="nofollow"&gt;Pay Less Attention with Lightweight and Dynamic Convolutions&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2019&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=3358231780148394025" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit, Lukasz Kaiser. 2019. &lt;a href="https://openreview.net/pdf?id=HyzdRiR9Y7" rel="nofollow"&gt;Universal Transformers&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2019&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=8443376534582904234&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 12)&lt;/li&gt;
&lt;li&gt;Zi-Yi Dou, Zhaopeng Tu, Xing Wang, Longyue Wang, Shuming Shi, and Tong Zhang. 2019. &lt;a href="https://arxiv.org/pdf/1902.05770.pdf" rel="nofollow"&gt;Dynamic Layer Aggregation for Neural Machine Translation with Routing-by-Agreement&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, and Ruslan Salakhutdinov. 2019. &lt;a href="https://arxiv.org/pdf/1901.02860" rel="nofollow"&gt;Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=7150055013029036741" rel="nofollow"&gt;Citation&lt;/a&gt;: 8)&lt;/li&gt;
&lt;li&gt;Qipeng Guo, Xipeng Qiu, Pengfei Liu, Yunfan Shao, Xiangyang Xue, and Zheng Zhang. 2019. &lt;a href="https://arxiv.org/pdf/1902.09113.pdf" rel="nofollow"&gt;Star-Transformer&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sho Takase and Naoaki Okazaki. 2019. &lt;a href="https://arxiv.org/pdf/1904.07418.pdf" rel="nofollow"&gt;Positional Encoding to Control Output Sequence Length&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jian Li, Baosong Yang, Zi-Yi Dou, Xing Wang, Michael R. Lyu, and Zhaopeng Tu. 2019. &lt;a href="https://arxiv.org/pdf/1904.03100.pdf" rel="nofollow"&gt;Information Aggregation for Multi-Head Attention with Routing-by-Agreement&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Baosong Yang, Longyue Wang, Derek Wong, Lidia S. Chao, and Zhaopeng Tu. 2019. &lt;a href="https://arxiv.org/pdf/1904.03107.pdf" rel="nofollow"&gt;Convolutional Self-Attention Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jie Hao, Xing Wang, Baosong Yang, Longyue Wang, Jinfeng Zhang, and Zhaopeng Tu. 2019. &lt;a href="https://arxiv.org/pdf/1904.03092.pdf" rel="nofollow"&gt;Modeling Recurrence for Transformer&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Nikolaos Pappas and James Henderson. 2019. &lt;a href="https://arxiv.org/pdf/1905.05513.pdf" rel="nofollow"&gt;Deep Residual Output Layers for Neural Language Generation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;David R. So, Chen Liang, and Quoc V. Le. 2019. &lt;a href="https://arxiv.org/pdf/1901.11117" rel="nofollow"&gt;The Evolved Transformer&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Ben Peters, Vlad Niculae, and André F.T. Martins. 2019. &lt;a href="https://arxiv.org/pdf/1905.05702" rel="nofollow"&gt;Sparse Sequence-to-Sequence Models&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Roberto Dessì and Marco Baroni. 2019. &lt;a href="https://arxiv.org/pdf/1905.08527" rel="nofollow"&gt;CNNs found to jump around more skillfully than RNNs: Compositional generalization in seq2seq convolutional networks&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sainbayar Sukhbaatar, Edouard Grave, Piotr Bojanowski, and Armand Joulin. 2019. &lt;a href="https://arxiv.org/pdf/1905.07799" rel="nofollow"&gt;Adaptive Attention Span in Transformers&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yi Tay, Aston Zhang, Luu Anh Tuan, Jinfeng Rao, Shuai Zhang, Shuohang Wang, Jie Fu, and Siu Cheung Hui. 2019. &lt;a href="https://arxiv.org/pdf/1906.04393" rel="nofollow"&gt;Lightweight and Efficient Neural Natural Language Processing with Quaternion Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Qiang Wang, Bei Li, Tong Xiao, Jingbo Zhu, Changliang Li, Derek F. Wong, and Lidia S. Chao. 2019. &lt;a href="https://arxiv.org/pdf/1906.01787" rel="nofollow"&gt;Learning Deep Transformer Models for Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Fengshun Xiao, Jiangtong Li, Hai Zhao, Rui Wang, and Kehai Chen. 2019. &lt;a href="https://arxiv.org/pdf/1906.01282" rel="nofollow"&gt;Lattice-Based Transformer Encoder for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Matthias Sperber, Graham Neubig, Ngoc-Quan Pham, and Alex Waibel. 2019. &lt;a href="https://arxiv.org/pdf/1906.01617" rel="nofollow"&gt;Self-Attentional Models for Lattice Inputs&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xing Wang, Zhaopeng Tu, Longyue Wang, and Shuming Shi. 2019. &lt;a href="https://arxiv.org/pdf/1906.01268" rel="nofollow"&gt;Exploiting Sentential Context for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Kris Korrel, Dieuwke Hupkes, Verna Dankers, and Elia Bruni. 2019. &lt;a href="https://arxiv.org/pdf/1906.01234" rel="nofollow"&gt;Transcoding compositionally: using attention to find more generalizable solutions&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Lijun Wu, Yiren Wang, Yingce Xia, Fei Tian, Fei Gao, Tao Qin, Jianhuang Lai, and Tie-Yan Liu. 2019. &lt;a href="https://arxiv.org/pdf/1907.01968" rel="nofollow"&gt;Depth Growing for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Shaojie Bai, J. Zico Kolter, and Vladlen Koltun. 2019. &lt;a href="https://arxiv.org/pdf/1909.01377.pdf" rel="nofollow"&gt;Deep Equilibrium Models&lt;/a&gt;. In &lt;em&gt;Proceedings of NeurIPS 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Gonçalo M. Correia, Vlad Niculae, and André F.T. Martins. 2019. &lt;a href="https://arxiv.org/pdf/1909.00015" rel="nofollow"&gt;Adaptively Sparse Transformers&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xuezhe Ma, Chunting Zhou, Xian Li, Graham Neubig, and Eduard Hovy. 2019. &lt;a href="https://arxiv.org/pdf/1909.02480" rel="nofollow"&gt;FlowSeq: Non-Autoregressive Conditional Sequence Generation with Generative Flow&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yau-Shian Wang, Hung-Yi Lee, and Yun-Nung Chen. 2019. &lt;a href="https://arxiv.org/pdf/1909.06639" rel="nofollow"&gt;Tree Transformer: Integrating Tree Structures into Self-Attention&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Mingxuan Wang, Jun xie, Zhixing Tan, Jinsong Su, Deyi Xiong and Lei Li. 2019. &lt;a href="https://www.aclweb.org/anthology/D19-1074.pdf" rel="nofollow"&gt;Towards Linear Time Neural Machine Translation with Capsule Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Biao Zhang, Ivan Titov and Rico Sennrich. 2019. &lt;a href="https://www.aclweb.org/anthology/D19-1083.pdf" rel="nofollow"&gt;Improving Deep Transformer with Depth-Scaled Initialization and Merged Attention&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-attention_mechanism"&gt;&lt;a id="user-content-attention-mechanism" class="anchor" aria-hidden="true" href="#attention-mechanism"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Attention Mechanism&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. &lt;a href="https://arxiv.org/pdf/1409.0473" rel="nofollow"&gt;Neural Machine Translation by Jointly Learning to Align and Translate&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2015&lt;/em&gt;. (&lt;a href="https://scholar.google.com.sg/scholar?cites=9430221802571417838&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5,596)&lt;/li&gt;
&lt;li&gt;Minh-Thang Luong, Hieu Pham, and Christopher D. Manning. 2015. &lt;a href="https://arxiv.org/pdf/1508.04025" rel="nofollow"&gt;Effective Approaches to Attention-based Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2015&lt;/em&gt;. (&lt;a href="https://scholar.google.com.sg/scholar?cites=12347446836257434866&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1,466)&lt;/li&gt;
&lt;li&gt;Shi Feng, Shujie Liu, Nan Yang, Mu Li, Ming Zhou, and Kenny Q. Zhu. 2016. &lt;a href="https://www.aclweb.org/anthology/C16-1290" rel="nofollow"&gt;Improving Attention Modeling with Implicit Distortion and Fertility for Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?&amp;amp;cites=1624882767342343496&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 18)&lt;/li&gt;
&lt;li&gt;Haitao Mi, Zhiguo Wang, and Abe Ittycheriah. 2016. &lt;a href="http://aclweb.org/anthology/D16-1249" rel="nofollow"&gt;Supervised Attentions for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.sg/scholar?cites=16345118068023322142&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 43)&lt;/li&gt;
&lt;li&gt;Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio. 2017. &lt;a href="https://arxiv.org/abs/1703.03130" rel="nofollow"&gt;A Structured
Self-attentive Sentence Embedding&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.sg/scholar?cites=3666844900655302515&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 216)&lt;/li&gt;
&lt;li&gt;Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, Shirui Pan, and Chengqi Zhang. 2018. &lt;a href="https://arxiv.org/pdf/1709.04696.pdf" rel="nofollow"&gt;DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.sg/scholar?cites=7311258646982866903&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 60)&lt;/li&gt;
&lt;li&gt;Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, and Chengqi Zhang. 2018. &lt;a href="https://arxiv.org/abs/1804.00857" rel="nofollow"&gt;Bi-directional Block Self-attention for Fast and Memory-efficient Sequence Modeling&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.sg/scholar?cites=7203374430207428965&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 13)&lt;/li&gt;
&lt;li&gt;Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, Sen Wang, Chengqi Zhang. 2018.  &lt;a href="https://arxiv.org/abs/1801.10296" rel="nofollow"&gt;Reinforced Self-Attention Network: a Hybrid of Hard and Soft Attention for Sequence Modeling&lt;/a&gt;. In &lt;em&gt;Proceedings of IJCAI 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.sg/scholar?cites=3809241292668177959&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 18)&lt;/li&gt;
&lt;li&gt;Peter Shaw, Jakob Uszkorei, and Ashish Vaswani. 2018. &lt;a href="http://aclweb.org/anthology/N18-2074" rel="nofollow"&gt;Self-Attention with Relative Position Representations&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.sg/scholar?cites=5563767891081728261&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 24)&lt;/li&gt;
&lt;li&gt;Lesly Miculicich Werlen, Nikolaos Pappas, Dhananjay Ram, and Andrei Popescu-Belis. 2018. &lt;a href="http://aclweb.org/anthology/N18-1124" rel="nofollow"&gt;Self-Attentive Residual Decoder for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=10357155207431596394" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Xintong Li, Lemao Liu, Zhaopeng Tu, Shuming Shi, and Max Meng. 2018. &lt;a href="http://aclweb.org/anthology/N18-1125" rel="nofollow"&gt;Target Foresight Based Attention for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Biao Zhang, Deyi Xiong, and Jinsong Su. 2018. &lt;a href="http://aclweb.org/anthology/P18-1166" rel="nofollow"&gt;Accelerating Neural Transformer via an Average Attention Network&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=16436039193082710776&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Tobias Domhan. 2018. &lt;a href="http://aclweb.org/anthology/P18-1167" rel="nofollow"&gt;How Much Attention Do You Need? A Granular Analysis of Neural Machine Translation Architectures&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=16338550517026915979&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Shaohui Kuang, Junhui Li, António Branco, Weihua Luo, and Deyi Xiong. 2018. &lt;a href="http://aclweb.org/anthology/P18-1164" rel="nofollow"&gt;Attention Focusing for Neural Machine Translation by Bridging Source and Target Embeddings&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13357719581808108940&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Chaitanya Malaviya, Pedro Ferreira, and André F. T. Martins. 2018. &lt;a href="http://aclweb.org/anthology/P18-2059" rel="nofollow"&gt;Sparse and Constrained Attention for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=11257363334017043172&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4)&lt;/li&gt;
&lt;li&gt;Jian Li, Zhaopeng Tu, Baosong Yang, Michael R. Lyu, and Tong Zhang. 2018. &lt;a href="http://aclweb.org/anthology/D18-1317" rel="nofollow"&gt;Multi-Head Attention with Disagreement Regularization&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=4230613606718109837&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Wei Wu, Houfeng Wang, Tianyu Liu and Shuming Ma.  2018. &lt;a href="http://aclweb.org/anthology/D18-1408" rel="nofollow"&gt;Phrase-level Self-Attention Networks for Universal Sentence Encoding&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Baosong Yang, Zhaopeng Tu, Derek F. Wong, Fandong Meng, Lidia S. Chao, and Tong Zhang. 2018. &lt;a href="https://arxiv.org/abs/1810.10182" rel="nofollow"&gt;Modeling Localness for Self-Attention Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=16651306350908112709&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Junyang Lin, Xu Sun, Xuancheng Ren, Muyu Li, and Qi Su. 2018. &lt;a href="http://aclweb.org/anthology/D18-1331" rel="nofollow"&gt;Learning When to Concentrate or Divert Attention: Self-Adaptive Attention Temperature for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Shiv Shankar, Siddhant Garg, and Sunita Sarawagi. 2018. &lt;a href="http://aclweb.org/anthology/D18-1065" rel="nofollow"&gt;Surprisingly Easy Hard-Attention for Sequence to Sequence Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Ankur Bapna, Mia Chen, Orhan Firat, Yuan Cao, and Yonghui Wu. 2018. &lt;a href="http://aclweb.org/anthology/D18-1338" rel="nofollow"&gt;Training Deeper Neural Machine Translation Models with Transparent Attention&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Hareesh Bahuleyan, Lili Mou, Olga Vechtomova, and Pascal Poupart. 2018. &lt;a href="http://aclweb.org/anthology/C18-1142" rel="nofollow"&gt;Variational Attention for Sequence-to-Sequence Models&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=1653411252630135531" rel="nofollow"&gt;Citation&lt;/a&gt;: 14)&lt;/li&gt;
&lt;li&gt;Maha Elbayad, Laurent Besacier, and Jakob Verbeek. 2018. &lt;a href="http://aclweb.org/anthology/K18-1010" rel="nofollow"&gt;Pervasive Attention: 2D Convolutional Neural Networks for Sequence-to-Sequence Prediction&lt;/a&gt;. In &lt;em&gt;Proceedings of CoNLL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=14016975442337015010&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4)&lt;/li&gt;
&lt;li&gt;Yuntian Deng, Yoon Kim, Justin Chiu, Demi Guo, and Alexander M. Rush. 2018 &lt;a href="https://papers.nips.cc/paper/8179-latent-alignment-and-variational-attention.pdf" rel="nofollow"&gt;Latent Alignment and Variational Attention&lt;/a&gt;. In &lt;em&gt;Proceedings of NeurIPS 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?client=safari&amp;amp;rls=en&amp;amp;oe=UTF-8&amp;amp;um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=6335407498429393003" rel="nofollow"&gt;Citation&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Wenpeng Yin and Hinrich Schütze. 2019. &lt;a href="https://arxiv.org/pdf/1710.00519" rel="nofollow"&gt;Attentive Convolution: Equipping CNNs with RNN-style Attention Mechanisms&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Shiv Shankar and Sunita Sarawagi. 2019. &lt;a href="https://openreview.net/pdf?id=BkltNhC9FX" rel="nofollow"&gt;Posterior Attention Models for Sequence to Sequence Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Baosong Yang, Jian Li, Derek Wong, Lidia S. Chao, Xing Wang, and Zhaopeng Tu. 2019. &lt;a href="https://arxiv.org/pdf/1902.05766.pdf" rel="nofollow"&gt;Context-Aware Self-Attention Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Reza Ghaeini, Xiaoli Z. Fern, Hamed Shahbazi, and Prasad Tadepalli. 2019. &lt;a href="https://arxiv.org/pdf/1902.08649.pdf" rel="nofollow"&gt;Saliency Learning: Teaching the Model Where to Pay Attention&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sameen Maruf, André F. T. Martins, and Gholamreza Haffari. 2019. &lt;a href="https://arxiv.org/pdf/1903.08788.pdf" rel="nofollow"&gt;Selective Attention for Context-aware Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sainbayar Sukhbaatar, Edouard Grave, Piotr Bojanowski, and Armand Joulin. 2019. &lt;a href="https://arxiv.org/pdf/1905.07799" rel="nofollow"&gt;Adaptive Attention Span in Transformers&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Kris Korrel, Dieuwke Hupkes, Verna Dankers, and Elia Bruni. 2019. &lt;a href="https://arxiv.org/pdf/1906.01234" rel="nofollow"&gt;Transcoding compositionally: using attention to find more generalizable solutions&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jesse Vig. 2019. &lt;a href="https://arxiv.org/pdf/1906.05714" rel="nofollow"&gt;A Multiscale Visualization of Attention in the Transformer Model&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sathish Reddy Indurthi, Insoo Chung, and Sangha Kim. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1290" rel="nofollow"&gt;Look Harder: A Neural Machine Translation Model with Hard Attention&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Mingzhou Xu, Derek F. Wong, Baosong Yang, Yue Zhang, and Lidia S. Chao. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1295" rel="nofollow"&gt;Leveraging Local and Global Patterns for Self-Attention Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sarthak Jain and Byron C. Wallace. 2019. &lt;a href="https://arxiv.org/pdf/1902.10186.pdf" rel="nofollow"&gt;Attention is not Explanation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sarah Wiegreffe and Yuval Pinter. 2019. &lt;a href="https://arxiv.org/pdf/1908.04626" rel="nofollow"&gt;Attention is not not Explanation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xing Wang, Zhaopeng Tu, Longyue Wang, and Shuming Shi. 2019. &lt;a href="https://arxiv.org/pdf/1909.00383" rel="nofollow"&gt;Self-Attention with Structural Position Representations&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yao-Hung Hubert Tsai, Shaojie Bai, Makoto Yamada, Louis-Philippe Morency, and Ruslan Salakhutdinov
. 2019. &lt;a href="https://arxiv.org/pdf/1908.11775" rel="nofollow"&gt;Transformer Dissection: An Unified Understanding for Transformer's Attention via the Lens of Kernel&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-open_vocabulary"&gt;&lt;a id="user-content-open-vocabulary" class="anchor" aria-hidden="true" href="#open-vocabulary"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Open Vocabulary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Felix Hill, Kyunghyun Cho, Sebastien Jean, Coline Devin, and Yoshua Bengio. 2015. &lt;a href="https://arxiv.org/pdf/1412.6448.pdf" rel="nofollow"&gt;Embedding Word Similarity with Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2015&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=3941248209566557946&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 24)&lt;/li&gt;
&lt;li&gt;Thang Luong, Ilya Sutskever, Quoc Le, Oriol Vinyals, and Wojciech Zaremba. 2015. &lt;a href="http://aclweb.org/anthology/P15-1002" rel="nofollow"&gt;Addressing the Rare Word Problem in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2015&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=1855379039969159341&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 367)&lt;/li&gt;
&lt;li&gt;Sébastien Jean, Kyunghyun Cho, Roland Memisevic, and Yoshua Bengio. 2015. &lt;a href="http://www.aclweb.org/anthology/P15-1001" rel="nofollow"&gt;On Using Very Large Target Vocabulary for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2015&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13222564911222792417&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 455)&lt;/li&gt;
&lt;li&gt;Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. &lt;a href="https://arxiv.org/pdf/1508.07909.pdf" rel="nofollow"&gt;Neural Machine Translation of Rare Words with Subword Units&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=1307964014330144942&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 795)&lt;/li&gt;
&lt;li&gt;Minh-Thang Luong and Christopher D. Manning. 2016. &lt;a href="http://aclweb.org/anthology/P16-1100" rel="nofollow"&gt;Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=7652846715026310814&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 173)&lt;/li&gt;
&lt;li&gt;Junyoung Chung, Kyunghyun Cho, and Yoshua Bengio. 2016. &lt;a href="http://aclweb.org/anthology/P16-1160" rel="nofollow"&gt;A Character-level Decoder without Explicit Segmentation for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=2193535701900882329&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 171)&lt;/li&gt;
&lt;li&gt;Jason Lee, Kyunghyun Cho, and Thomas Hofmann. 2017. &lt;a href="http://aclweb.org/anthology/Q17-1026" rel="nofollow"&gt;Fully Character-Level Neural Machine Translation without Explicit Segmentation&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13463489320810094413&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 116)&lt;/li&gt;
&lt;li&gt;Yang Feng, Shiyue Zhang, Andi Zhang, Dong Wang, and Andrew Abel. 2017. &lt;a href="http://aclweb.org/anthology/D17-1146" rel="nofollow"&gt;Memory-augmented Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=825727884820810695&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 9)&lt;/li&gt;
&lt;li&gt;Baosong Yang, Derek F. Wong, Tong Xiao, Lidia S. Chao, and Jingbo Zhu. 2017. &lt;a href="http://aclweb.org/anthology/D17-1150" rel="nofollow"&gt;Towards Bidirectional Hierarchical Representations for Attention-based Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=18313642653606285813&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Peyman Passban, Qun Liu, and Andy Way. 2018. &lt;a href="http://aclweb.org/anthology/N18-1006" rel="nofollow"&gt;Improving Character-Based Decoding Using Target-Side Morphological Information for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13968879243228181963&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Huadong Chen, Shujian Huang, David Chiang, Xinyu Dai, and Jiajun Chen. 2018. &lt;a href="http://aclweb.org/anthology/N18-1116" rel="nofollow"&gt;Combining Character and Word Information in Neural Machine Translation Using a Multi-Level Attention&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Frederick Liu, Han Lu, and Graham Neubig. 2018. &lt;a href="http://aclweb.org/anthology/N18-1121" rel="nofollow"&gt;Handling Homographs in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=8530214186708420865&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 8)&lt;/li&gt;
&lt;li&gt;Taku Kudo. 2018. &lt;a href="http://aclweb.org/anthology/P18-1007" rel="nofollow"&gt;Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=10996996628614665108&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 17)&lt;/li&gt;
&lt;li&gt;Makoto Morishita, Jun Suzuki, and Masaaki Nagata. 2018. &lt;a href="http://aclweb.org/anthology/C18-1052" rel="nofollow"&gt;Improving Neural Machine Translation by Incorporating Hierarchical Subword Features&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yang Zhao, Jiajun Zhang, Zhongjun He, Chengqing Zong, and Hua Wu. 2018. &lt;a href="http://aclweb.org/anthology/D18-1036" rel="nofollow"&gt;Addressing Troublesome Words in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Colin Cherry, George Foster, Ankur Bapna, Orhan Firat, and Wolfgang Macherey. 2018. &lt;a href="http://aclweb.org/anthology/D18-1461" rel="nofollow"&gt;Revisiting Character-Based Neural Machine Translation with Capacity and Compression&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=1263295983934592415&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Rebecca Knowles and Philipp Koehn. 2018. &lt;a href="http://aclweb.org/anthology/D18-1339" rel="nofollow"&gt;Context and Copying in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Matthias Huck, Viktor Hangya, and Alexander Fraser. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1581" rel="nofollow"&gt;Better OOV Translation with Bilingual Terminology Mining&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-training"&gt;&lt;a id="user-content-training-objectives-and-frameworks" class="anchor" aria-hidden="true" href="#training-objectives-and-frameworks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training Objectives and Frameworks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Marc'Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba. 2016. &lt;a href="https://arxiv.org/pdf/1511.06732" rel="nofollow"&gt;Sequence Level Training with Recurrent Neural Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=4877899442083611721&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 373)&lt;/li&gt;
&lt;li&gt;Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. 2016. &lt;a href="https://arxiv.org/pdf/1511.06114" rel="nofollow"&gt;Multi-task Sequence to Sequence Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=6045967109711129604&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 282)&lt;/li&gt;
&lt;li&gt;Shiqi Shen, Yong Cheng, Zhongjun He, Wei He, Hua Wu, Maosong Sun, and Yang Liu. 2016. &lt;a href="http://aclweb.org/anthology/P16-1159" rel="nofollow"&gt;Minimum Risk Training for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13568140432319924245&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 184)&lt;/li&gt;
&lt;li&gt;Sam Wiseman and Alexander M. Rush. 2016. &lt;a href="http://aclweb.org/anthology/D16-1137" rel="nofollow"&gt;Sequence-to-Sequence Learning as Beam-Search Optimization&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=8919612243620131744&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 141)&lt;/li&gt;
&lt;li&gt;Di He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, Wei-Ying Ma. 2016. &lt;a href="https://papers.nips.cc/paper/6469-dual-learning-for-machine-translation.pdf" rel="nofollow"&gt;Dual Learning for Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NIPS 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=15841765927830550600&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 138)&lt;/li&gt;
&lt;li&gt;Dzmitry Bahdanau, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron Courville, and Yoshua Bengio. 2017. &lt;a href="https://arxiv.org/pdf/1607.07086" rel="nofollow"&gt;An Actor-Critic Algorithm for Sequence Prediction&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=5228204938243984917&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 167)&lt;/li&gt;
&lt;li&gt;Julia Kreutzer, Artem Sokolov, Stefan Riezler. 2017. &lt;a href="http://aclweb.org/anthology/P17-1138" rel="nofollow"&gt;Bandit Structured Prediction for Neural Sequence-to-Sequence Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?oi=bibs&amp;amp;hl=en&amp;amp;cites=2303245646235792457,8131913197545815057" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Yingce Xia, Tao Qin, Wei Chen, Jiang Bian, Nenghai Yu, and Tie-Yan Liu. 2017. &lt;a href="https://arxiv.org/pdf/1707.00415.pdf" rel="nofollow"&gt;Dual Supervised Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=17907972833117899731" rel="nofollow"&gt;Citation&lt;/a&gt;: 29)&lt;/li&gt;
&lt;li&gt;Yingce Xia, Jiang Bian, Tao Qin, Nenghai Yu, and Tie-Yan Liu. 2017. &lt;a href="https://www.ijcai.org/proceedings/2017/0434.pdf" rel="nofollow"&gt;Dual Inference for Machine Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of IJCAI 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=15405750739898389436" rel="nofollow"&gt;Citation&lt;/a&gt;: 9)&lt;/li&gt;
&lt;li&gt;Di He, Hanqing Lu, Yingce Xia, Tao Qin, Liwei Wang, and Tieyan Liu. 2017. &lt;a href="http://papers.nips.cc/paper/6622-decoding-with-value-networks-for-neural-machine-translation.pdf" rel="nofollow"&gt;Decoding with Value Networks for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NIPS 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9924066051536654397&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Sergey Edunov, Myle Ott, Michael Auli, David Grangier, and Marc’Aurelio Ranzato. 2018. &lt;a href="http://aclweb.org/anthology/N18-1033" rel="nofollow"&gt;Classical Structured Prediction Losses for Sequence to Sequence Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=7858632228846408271&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 20)&lt;/li&gt;
&lt;li&gt;Zihang Dai, Qizhe Xie, and Eduard Hovy. 2018. &lt;a href="http://aclweb.org/anthology/P18-1155" rel="nofollow"&gt;From Credit Assignment to Entropy Regularization: Two New Algorithms for Neural Sequence Prediction&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?hl=zh-CN&amp;amp;as_sdt=0,5&amp;amp;sciodt=0,5&amp;amp;cites=73472736706758753&amp;amp;scipsc=" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Zhen Yang, Wei Chen, Feng Wang, and Bo Xu. 2018. &lt;a href="http://aclweb.org/anthology/N18-1122" rel="nofollow"&gt;Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=14312548252804187966&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 43)&lt;/li&gt;
&lt;li&gt;Kevin Clark, Minh-Thang Luong, Christopher D. Manning, and Quoc Le. 2018. &lt;a href="http://aclweb.org/anthology/D18-1217" rel="nofollow"&gt;Semi-Supervised Sequence Modeling with Cross-View Training&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Lijun Wu, Fei Tian, Tao Qin, Jianhuang Lai, and Tie-Yan Liu. 2018. &lt;a href="http://aclweb.org/anthology/D18-1397" rel="nofollow"&gt;A Study of Reinforcement Learning for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9706797919793848294&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Jason Lee, Elman Mansimov, and Kyunghyun Cho. 2018. &lt;a href="http://aclweb.org/anthology/D18-1149" rel="nofollow"&gt;Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Semih Yavuz, Chung-Cheng Chiu, Patrick Nguyen, and Yonghui Wu. 2018. &lt;a href="http://aclweb.org/anthology/D18-1406" rel="nofollow"&gt;CaLcs: Continuously Approximating Longest Common Subsequence for Sequence Level Optimization&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Lijun Wu, Fei Tian, Yingce Xia, Yang Fan, Tao Qin, Jianhuang Lai, and Tie-Yan Liu. 2018. &lt;a href="https://papers.nips.cc/paper/7882-learning-to-teach-with-dynamic-loss-functions.pdf" rel="nofollow"&gt;Learning to Teach with Dynamic Loss Functions&lt;/a&gt;. In &lt;em&gt;Proceedings of NeurIPS 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yiren Wang, Yingce Xia, Tianyu He, Fei Tian, Tao Qin, ChengXiang Zhai, and Tie-Yan Liu. 2019. &lt;a href="https://openreview.net/pdf?id=HyGhN2A5tm" rel="nofollow"&gt;Multi-Agent Dual Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Liqun Chen, Yizhe Zhang, Ruiyi Zhang, Chenyang Tao, Zhe Gan, Haichao Zhang, Bai Li, Dinghan Shen, Changyou Chen, and Lawrence Carin. 2019. &lt;a href="https://openreview.net/pdf?id=S1xtAjR5tX" rel="nofollow"&gt;Improving Sequence-to-Sequence Learning via Optimal Transport&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sachin Kumar and Yulia Tsvetkov. 2019. &lt;a href="https://openreview.net/pdf?id=rJlDnoA5Y7" rel="nofollow"&gt;Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xing Niu, Weijia Xu, and Marine Carpuat. 2019. &lt;a href="https://arxiv.org/pdf/1811.01116.pdf" rel="nofollow"&gt;Bi-Directional Differentiable Input Reconstruction for Low-Resource Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Weijia Xu, Xing Niu, and Marine Carpuat. 2019. &lt;a href="https://arxiv.org/pdf/1904.04079.pdf" rel="nofollow"&gt;Differentiable Sampling with Flexible Reference Word Order for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Inigo Jauregi Unanue, Ehsan Zare Borzeshi, Nazanin Esmaili, and Massimo Piccardi. &lt;a href="https://arxiv.org/pdf/1904.02461.pdf" rel="nofollow"&gt;ReWE: Regressing Word Embeddings for Regularization of Neural Machine Translation Systems&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Reuben Cohn-Gordon and Noah Goodman. 2019. &lt;a href="https://arxiv.org/pdf/1902.09514.pdf" rel="nofollow"&gt;Lost in Machine Translation: A Method to Reduce Meaning Loss&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Emmanouil Antonios Platanios, Otilia Stretcu, Graham Neubig, Barnabas Poczos, and Tom M. Mitchell. 2019. &lt;a href="https://arxiv.org/pdf/1903.09848.pdf" rel="nofollow"&gt;Competence-based Curriculum Learning for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Gaurav Kumar, George Foster, Colin Cherry, and Maxim Krikun. 2019. &lt;a href="https://arxiv.org/pdf/1903.00041.pdf" rel="nofollow"&gt;Reinforcement Learning based Curriculum Optimization for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sean Welleck, Kianté Brantley, Hal Daumé III, and Kyunghyun Cho. 2019. &lt;a href="https://arxiv.org/pdf/1902.02192" rel="nofollow"&gt;Non-Monotonic Sequential Text Generation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Mitchell Stern, William Chan, Jamie Kiros, Jakob Uszkoreit. 2019. &lt;a href="http://proceedings.mlr.press/v97/stern19a/stern19a.pdf" rel="nofollow"&gt;Insertion Transformer: Flexible Sequence Generation via Insertion Operations&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Chenze Shao, Yang Feng, Jinchao Zhang, Fandong Meng, Xilin Chen, and Jie Zhou. 2019. &lt;a href="https://arxiv.org/pdf/1906.09444" rel="nofollow"&gt;Retrieving Sequential Information for Non-Autoregressive Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Laura Jehl, Carolin Lawrence, and Stefan Riezler. 2019. &lt;a href="https://arxiv.org/pdf/1907.03748" rel="nofollow"&gt;Learning Neural Sequence-to-Sequence Models from Weak Feedback with Bipolar Ramp Loss&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Motoki Sato, Jun Suzuki, and Shun Kiyono. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1020" rel="nofollow"&gt;Effective Adversarial Regularization for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Kehai Chen, Rui Wang, Masao Utiyama, and Eiichiro Sumita. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1174" rel="nofollow"&gt;Neural Machine Translation with Reordering Embeddings&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Bram Bulte and Arda Tezcan. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1175" rel="nofollow"&gt;Neural Fuzzy Repair: Integrating Fuzzy Matches into Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Mingming Yang, Rui Wang, Kehai Chen, Masao Utiyama, Eiichiro Sumita, Min Zhang, and Tiejun Zhao. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1296" rel="nofollow"&gt;Sentence-Level Agreement for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Wen Zhang, Yang Feng, Fandong Meng, Di You, and Qun Liu. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1426" rel="nofollow"&gt;Bridging the Gap between Training and Inference for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;John Wieting, Taylor Berg-Kirkpatrick, Kevin Gimpel, and Graham Neubig. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1427" rel="nofollow"&gt;Beyond BLEU:Training Neural Machine Translation with Semantic Similarity&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Zonghan Yang, Yong Cheng, Yang Liu, Maosong Sun. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1623" rel="nofollow"&gt;Reducing Word Omission Errors in Neural Machine Translation: A Contrastive Learning Approach&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Kyra Yee, Nathan Ng, Yann N. Dauphin, and Michael Auli. 2019. &lt;a href="https://arxiv.org/pdf/1908.05731" rel="nofollow"&gt;Simple and Effective Noisy Channel Modeling for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sarthak Garg, Stephan Peitz, Udhyakumar Nallasamy, and Matthias Paulik. 2019. &lt;a href="https://arxiv.org/pdf/1909.02074" rel="nofollow"&gt;Jointly Learning to Align and Translate with Transformer Models&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;tianchi bi, hao xiong, Zhongjun He, Hua Wu and Haifeng Wang. 2019. &lt;a href="https://www.aclweb.org/anthology/D19-1079.pdf" rel="nofollow"&gt;Multi-agent Learning for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-decoding"&gt;&lt;a id="user-content-decoding" class="anchor" aria-hidden="true" href="#decoding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Decoding&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Mingxuan Wang, Zhengdong Lu, Hang Li, and Qun Liu. 2016. &lt;a href="http://aclweb.org/anthology/D16-1027" rel="nofollow"&gt;Memory-enhanced Decoder for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=8953099567327192144&amp;amp;as_sdt=5,43&amp;amp;sciodt=0,43&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 30)&lt;/li&gt;
&lt;li&gt;Shonosuke Ishiwatari, Jingtao Yao, Shujie Liu, Mu Li, Ming Zhou, Naoki Yoshinaga, Masaru Kitsuregawa, and Weijia Jia. 2017. &lt;a href="http://aclweb.org/anthology/P17-1174" rel="nofollow"&gt;Chunk-based Decoder for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=12622466792413888553&amp;amp;as_sdt=5,43&amp;amp;sciodt=0,43&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4)&lt;/li&gt;
&lt;li&gt;Hao Zhou, Zhaopeng Tu, Shujian Huang, Xiaohua Liu, Hang Li, and Jiajun Chen. 2017. &lt;a href="http://aclweb.org/anthology/P17-2092" rel="nofollow"&gt;Chunk-Based Bi-Scale Decoder for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=15037334213705032139&amp;amp;as_sdt=5,43&amp;amp;sciodt=0,43&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Zichao Yang, Zhiting Hu, Yuntian Deng, Chris Dyer, and Alex Smola. 2017. &lt;a href="http://aclweb.org/anthology/E17-2061" rel="nofollow"&gt;Neural Machine Translation with Recurrent Attention Modeling&lt;/a&gt;.  In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=5621977008323303060&amp;amp;as_sdt=5,43&amp;amp;sciodt=0,43&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 25)&lt;/li&gt;
&lt;li&gt;Markus Freitag and Yaser Al-Onaizan. 2017. &lt;a href="http://aclweb.org/anthology/W17-3207" rel="nofollow"&gt;Beam Search Strategies for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of the First Workshop on Neural Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9963996198070293328&amp;amp;as_sdt=5,43&amp;amp;sciodt=0,43&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 14)&lt;/li&gt;
&lt;li&gt;Rajen Chatterjee, Matteo Negri, Marco Turchi, Marcello Federico, Lucia Specia, and Frédéric Blain. 2017. &lt;a href="http://aclweb.org/anthology/W17-4716" rel="nofollow"&gt;Guiding Neural Machine Translation Decoding with External Knowledge&lt;/a&gt;. In &lt;em&gt;Proceedings of the Second Conference on Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=16027327382881304751&amp;amp;as_sdt=5,43&amp;amp;sciodt=0,43&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 8)&lt;/li&gt;
&lt;li&gt;Cong Duy Vu Hoang, Gholamreza Haffari, and Trevor Cohn. 2017. &lt;a href="http://aclweb.org/anthology/D17-1014" rel="nofollow"&gt;Towards Decoding as Continuous Optimisation in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=3256665477810901088&amp;amp;as_sdt=5,43&amp;amp;sciodt=0,43&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4)&lt;/li&gt;
&lt;li&gt;Yin-Wen Chang and Michael Collins. 2017. &lt;a href="http://aclweb.org/anthology/D17-1157" rel="nofollow"&gt;Source-Side Left-to-Right or Target-Side Left-to-Right? An Empirical Comparison of Two Phrase-Based Decoding Algorithms&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jiatao Gu, Kyunghyun Cho, and Victor O.K. Li. 2017. &lt;a href="http://aclweb.org/anthology/D17-1210" rel="nofollow"&gt;Trainable Greedy Decoding for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=8731447567218149379&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 18)&lt;/li&gt;
&lt;li&gt;Huda Khayrallah, Gaurav Kumar, Kevin Duh, Matt Post, and Philipp Koehn. 2017. &lt;a href="http://www.aclweb.org/anthology/I17-2004" rel="nofollow"&gt;Neural Lattice Search for Domain Adaptation in Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of IJCNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cluster=1478484647323458623&amp;amp;hl=zh-CN&amp;amp;as_sdt=0,5" rel="nofollow"&gt;Citation&lt;/a&gt;: 4)&lt;/li&gt;
&lt;li&gt;Jiatao Gu, James Bradbury, Caiming Xiong, Victor O.K. Li, and Richard Socher. 2018. &lt;a href="https://arxiv.org/abs/1711.02281" rel="nofollow"&gt;Non-Autoregressive Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=3482831974828539059&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 23)&lt;/li&gt;
&lt;li&gt;Łukasz Kaiser, Aurko Roy, Ashish Vaswani, Niki Parmar, Samy Bengio, Jakob Uszkoreit, and Noam Shazeer. 2018. &lt;a href="https://arxiv.org/pdf/1803.03382.pdf" rel="nofollow"&gt;Fast Decoding in Sequence Models Using Discrete Latent Variables&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=4042994175439965815&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Xiangwen Zhang, Jinsong Su, Yue Qin, Yang Liu, Rongrong Ji, and Hongji Wang. 2018. &lt;a href="https://arxiv.org/pdf/1801.05122" rel="nofollow"&gt;Asynchronous Bidirectional Decoding for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=8717464809531813198&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 10)&lt;/li&gt;
&lt;li&gt;Jiatao Gu, Daniel Jiwoong Im, and Victor O.K. Li. 2018. &lt;a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17299/16059" rel="nofollow"&gt;Neural machine translation with gumbel-greedy decoding&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13306026917760415053&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Philip Schulz, Wilker Aziz, and Trevor Cohn. 2018. &lt;a href="http://aclweb.org/anthology/P18-1115" rel="nofollow"&gt;A Stochastic Decoder for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=2090499795836532737&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Raphael Shu and Hideki Nakayama. 2018. &lt;a href="http://aclweb.org/anthology/P18-2054" rel="nofollow"&gt;Improving Beam Search by Removing Monotonic Constraint for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Junyang Lin, Xu Sun, Xuancheng Ren, Shuming Ma, Jinsong Su, and Qi Su. 2018. &lt;a href="http://aclweb.org/anthology/C18-1276" rel="nofollow"&gt;Deconvolution-Based Global Decoding for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=7984371866238647123&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Chunqi Wang, Ji Zhang, and Haiqing Chen. 2018. &lt;a href="http://aclweb.org/anthology/D18-1044" rel="nofollow"&gt;Semi-Autoregressive Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xinwei Geng, Xiaocheng Feng, Bing Qin, and Ting Liu. 2018. &lt;a href="http://aclweb.org/anthology/D18-1048" rel="nofollow"&gt;Adaptive Multi-pass Decoder for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Wen Zhang, Liang Huang, Yang Feng, Lei Shen, and Qun Liu. 2018. &lt;a href="http://aclweb.org/anthology/D18-1460" rel="nofollow"&gt;Speeding Up Neural Machine Translation Decoding by Cube Pruning&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xinyi Wang, Hieu Pham, Pengcheng Yin, and Graham Neubig. 2018. &lt;a href="http://aclweb.org/anthology/D18-1509" rel="nofollow"&gt;A Tree-based Decoder for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9083843868999368969&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Chenze Shao, Xilin Chen, and Yang Feng. 2018. &lt;a href="http://aclweb.org/anthology/D18-1510" rel="nofollow"&gt;Greedy Search with Probabilistic N-gram Matching for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Zhisong Zhang, Rui Wang, Masao Utiyama, Eiichiro Sumita, and Hai Zhao. 2018. &lt;a href="http://aclweb.org/anthology/D18-1511" rel="nofollow"&gt;Exploring Recombination for Efficient Decoding of Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jetic Gū, Hassan S. Shavarani, and Anoop Sarkar. 2018. &lt;a href="http://aclweb.org/anthology/D18-1037" rel="nofollow"&gt;Top-down Tree Structured Decoding with Syntactic Connections for Neural Machine Translation and Parsing&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yilin Yang, Liang Huang, and Mingbo Ma. 2018. &lt;a href="http://aclweb.org/anthology/D18-1342" rel="nofollow"&gt;Breaking the Beam Search Curse: A Study of (Re-)Scoring Methods and Stopping Criteria for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=7003078853740771503&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Yun Chen, Victor O.K. Li, Kyunghyun Cho, and Samuel R. Bowman. 2018. &lt;a href="http://aclweb.org/anthology/D18-1035" rel="nofollow"&gt;A Stable and Effective Learning Strategy for Trainable Greedy Decoding&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Junliang Guo, Xu Tan, Di He, Tao Qin, Linli Xu, and Tie-Yan Liu. 2019. &lt;a href="https://arxiv.org/pdf/1812.09664.pdf" rel="nofollow"&gt;Non-Autoregressive Neural Machine Translation with Enhanced Decoder Input&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2019&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=14984310531770070805&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Yiren Wang, Fei Tian, Di He, Tao Qin, ChengXiang Zhai, and Tie-Yan Liu. 2019. &lt;a href="https://arxiv.org/pdf/1902.10245.pdf" rel="nofollow"&gt;Non-Autoregressive Machine Translation with Auxiliary Regularization&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Wouter Kool, Herke van Hoof, and Max Welling. 2019. &lt;a href="http://proceedings.mlr.press/v97/kool19a/kool19a.pdf" rel="nofollow"&gt;Stochastic Beams and Where to Find Them: The Gumbel-Top-k Trick for Sampling Sequences Without Replacement&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Ashwin Kalyan, Peter Anderson, Stefan Lee, and Dhruv Batra. 2019. &lt;a href="http://proceedings.mlr.press/v97/kalyan19a/kalyan19a.pdf" rel="nofollow"&gt;Trainable Decoding of Sets of Sequences for Neural Sequence Models&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Eldan Cohen and Christopher Beck. 2019. &lt;a href="http://proceedings.mlr.press/v97/cohen19a/cohen19a.pdf" rel="nofollow"&gt;Empirical Analysis of Beam Search Performance Degradation in Neural Sequence Models&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Kartik Goyal, Chris Dyer, and Taylor Berg-Kirkpatrick. 2019. &lt;a href="https://arxiv.org/pdf/1904.06834.pdf" rel="nofollow"&gt;An Empirical Investigation of Global and Local Normalization for Recurrent Neural Sequence Models Using a Continuous Relaxation to Beam Search&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Mingbo Ma, Renjie Zheng, and Liang Huang. 2019. &lt;a href="https://arxiv.org/pdf/1904.01032.pdf" rel="nofollow"&gt;Learning to Stop in Structured Prediction for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Bingzhen Wei, Mingxuan Wang, Hao Zhou, Junyang Lin, and Xu Sun. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1125" rel="nofollow"&gt;Imitation Learning for Non-Autoregressive Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Han Fu, Chenghao Liu, and Jianling Sun. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1287" rel="nofollow"&gt;Reference Network for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Long Zhou, Jiajun Zhang, and Chengqing Zong. 2019. &lt;a href="https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00256" rel="nofollow"&gt;Synchronous Bidirectional Neural Machine Translation&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Zhiqing Sun, Zhuohan Li, Haoqing Wang, Zi Lin, Di He, and Zhi-Hong Deng. 2019. &lt;a href="https://arxiv.org/pdf/1910.11555" rel="nofollow"&gt;Fast Structured Decoding for Sequence Models&lt;/a&gt;. In &lt;em&gt;Proceedings of NeurIPS 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-low_resource_language_translation"&gt;&lt;a id="user-content-low-resource-language-translation" class="anchor" aria-hidden="true" href="#low-resource-language-translation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Low-resource Language Translation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Rico Sennrich and Biao Zhang. 2019. &lt;a href="https://arxiv.org/pdf/1905.11901" rel="nofollow"&gt;Revisiting Low-Resource Neural Machine Translation: A Case Study&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="user-content-semi_supervised"&gt;&lt;a id="user-content-semi-supervised-learning" class="anchor" aria-hidden="true" href="#semi-supervised-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Semi-supervised Learning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. &lt;a href="https://arxiv.org/pdf/1511.06709" rel="nofollow"&gt;Improving Neural Machine Translation Models with Monolingual Data&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=16647011114557315277&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 220)&lt;/li&gt;
&lt;li&gt;Yong Cheng, Wei Xu, Zhongjun He, Wei He, Hua Wu, Maosong Sun, and Yang Liu. 2016. &lt;a href="http://aclweb.org/anthology/P16-1185" rel="nofollow"&gt;Semi-Supervised Learning for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=4238720597816763796&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 59)&lt;/li&gt;
&lt;li&gt;Tobias Domhan and Felix Hieber. 2017. &lt;a href="http://aclweb.org/anthology/D17-1158" rel="nofollow"&gt;Using Target-side Monolingual Data for Neural Machine Translation through Multi-task Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=3638267208501348823&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Anna Currey, Antonio Valerio Miceli Barone, and Kenneth Heafield. 2017. &lt;a href="http://aclweb.org/anthology/W17-4715" rel="nofollow"&gt;Copied Monolingual Data Improves Low-Resource Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of the Second Conference on Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=5102771697654796737&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 14)&lt;/li&gt;
&lt;li&gt;Shuo Wang, Yang Liu, Chao Wang, Huanbo Luan, and Maosong Sun. 2019. &lt;a href="https://arxiv.org/pdf/1909.00157" rel="nofollow"&gt;Improving Back-Translation with Uncertainty-based Confidence Estimation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="user-content-unsupervised"&gt;&lt;a id="user-content-unsupervised-learning" class="anchor" aria-hidden="true" href="#unsupervised-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Unsupervised Learning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Nima Pourdamghani and Kevin Knight. 2017. &lt;a href="http://aclweb.org/anthology/D17-1266" rel="nofollow"&gt;Deciphering Related Languages&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=1168382888604094286&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Mikel Artetxe, Gorka Labaka, Eneko Agirre, and Kyunghyun Cho. 2018. &lt;a href="https://openreview.net/pdf?id=Sy2ogebAW" rel="nofollow"&gt;Unsupervised Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=6109181985493123662&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 78)&lt;/li&gt;
&lt;li&gt;Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc'Aurelio Ranzato. 2018. &lt;a href="https://openreview.net/pdf?id=rkYTTf-AZ" rel="nofollow"&gt;Unsupervised Machine Translation Using Monolingual Corpora Only&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=682955820897938264&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 78)&lt;/li&gt;
&lt;li&gt;Zhen Yang, Wei Chen, Feng Wang, and Bo Xu. 2018. &lt;a href="http://aclweb.org/anthology/P18-1005" rel="nofollow"&gt;Unsupervised Neural Machine Translation with Weight Sharing&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=16608767535553803928&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, and Marc'Aurelio Ranzato. 2018. &lt;a href="http://aclweb.org/anthology/D18-1549" rel="nofollow"&gt;Phrase-Based &amp;amp; Neural Unsupervised Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=17725098892021008539&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 24)&lt;/li&gt;
&lt;li&gt;Iftekhar Naim, Parker Riley, and Daniel Gildea. 2018. &lt;a href="http://aclweb.org/anthology/J18-3006" rel="nofollow"&gt;Feature-Based Decipherment for Machine Translation&lt;/a&gt;. &lt;em&gt;Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=17725098892021008539&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 24)&lt;/li&gt;
&lt;li&gt;Jiawei Wu, Xin Wang, and William Yang Wang. 2019. &lt;a href="https://arxiv.org/pdf/1904.02331.pdf" rel="nofollow"&gt;Extract and Edit: An Alternative to Back-Translation for Unsupervised Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Nima Pourdamghani, Nada Aldarrab, Marjan Ghazvininejad, Kevin Knight, and Jonathan May. 2019. &lt;a href="https://arxiv.org/pdf/1906.05683" rel="nofollow"&gt;Translating Translationese: A Two-Step Approach to Unsupervised Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jiaming Luo, Yuan Cao, and Regina Barzilay. 2019. &lt;a href="https://arxiv.org/pdf/1906.06718" rel="nofollow"&gt;Neural Decipherment via Minimum-Cost Flow: from Ugaritic to Linear B&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yichong Leng, Xu Tan, Tao Qin, Xiang-Yang Li, and Tie-Yan Liu. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1017" rel="nofollow"&gt;Unsupervised Pivot Translation for Distant Languages&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1019" rel="nofollow"&gt;An Effective Approach to Unsupervised Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Viktor Hangya and Alexander Fraser. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1119" rel="nofollow"&gt;Unsupervised Parallel Sentence Extraction with Parallel Segment Detection Helps Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Haipeng Sun, Rui Wang, Kehai Chen, Masao Utiyama, Eiichiro Sumita, and Tiejun Zhao. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1119" rel="nofollow"&gt;Unsupervised Bilingual Word Embedding Agreement for Unsupervised Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jiatao Gu, Yong Wang, Kyunghyun Cho, and Victor O.K. Li. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1121" rel="nofollow"&gt;Improved Zero-shot Neural Machine Translation via Ignoring Spurious Correlations&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sukanta Sen, Kamal Kumar Gupta, Asif Ekbal, and Pushpak Bhattacharyya. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1297" rel="nofollow"&gt;Multilingual Unsupervised NMT using Shared Encoder and Language-Specific Decoders&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Shuo Ren, Yu Wu, Shujie Liu, Ming Zhou and Shuai Ma. 2019. &lt;a href="https://www.aclweb.org/anthology/D19-1071.pdf" rel="nofollow"&gt;Explicit Cross-lingual Pre-training for Unsupervised Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="user-content-pivot_based"&gt;&lt;a id="user-content-pivot-based-methods" class="anchor" aria-hidden="true" href="#pivot-based-methods"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pivot-based Methods&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Orhan Firat, Baskaran Sankaran, Yaser Al-Onaizan, Fatos T. Yarman Vural, and Kyunghyun Cho. 2016. &lt;a href="http://aclweb.org/anthology/D16-1026" rel="nofollow"&gt;Zero-Resource Translation with Multi-Lingual Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=9699063558012530354" rel="nofollow"&gt;Citation&lt;/a&gt;: 50)&lt;/li&gt;
&lt;li&gt;Hao Zheng, Yong Cheng, and Yang Liu. 2017. &lt;a href="http://nlp.csai.tsinghua.edu.cn/~ly/papers/ijcai2017_zh.pdf" rel="nofollow"&gt;Maximum Expected Likelihood Estimation for Zero-resource Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of IJCAI 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=8742684674953684271&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 9)&lt;/li&gt;
&lt;li&gt;Yong Cheng, Qian Yang, Yang Liu, Maosong Sun, and Wei Xu. 2017. &lt;a href="http://nlp.csai.tsinghua.edu.cn/~ly/papers/ijcai2017_cy.pdf" rel="nofollow"&gt;Joint Training for Pivot-based Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of IJCAI 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=11174626133676084798&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Yun Chen, Yang Liu, Yong Cheng and Victor O.K. Li. 2017. &lt;a href="http://aclweb.org/anthology/P17-1176" rel="nofollow"&gt;A Teacher-Student Framework for Zero-resource Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13349008860652038472&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 15)&lt;/li&gt;
&lt;li&gt;Yun Chen, Yang Liu, and Victor O. K. Li. 2018. &lt;a href="https://arxiv.org/pdf/1802.03116" rel="nofollow"&gt;Zero-Resource Neural Machine Translation with Multi-Agent Communication Game&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13902575159717479954&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Shuo Ren, Wenhu Chen, Shujie Liu, Mu Li, Ming Zhou, and Shuai Ma. 2018. &lt;a href="http://aclweb.org/anthology/P18-1006" rel="nofollow"&gt;Triangular Architecture for Rare Language Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=10337098101101097173&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Yunsu Kim, Petre Petrov, Pavel Petrushkov, Shahram Khadivi, and Hermann Ney. 2019. &lt;a href="https://arxiv.org/pdf/1909.09524" rel="nofollow"&gt;Pivot-based Transfer Learning for Neural Machine Translation between Non-English Languages&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="user-content-data_augmentation"&gt;&lt;a id="user-content-data-augmentation-methods" class="anchor" aria-hidden="true" href="#data-augmentation-methods"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Augmentation Methods&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Marzieh Fadaee, Arianna Bisazza, and Christof Monz. 2017. &lt;a href="http://aclweb.org/anthology/P17-2090" rel="nofollow"&gt;Data Augmentation for Low-Resource Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=6141657859614474985&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 26)&lt;/li&gt;
&lt;li&gt;Marzieh Fadaee and Christof Monz. 2018. &lt;a href="http://aclweb.org/anthology/D18-1040" rel="nofollow"&gt;Back-Translation Sampling by Targeting Difficult Words in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sergey Edunov, Myle Ott, Michael Auli, and David Grangier. 2018. &lt;a href="http://aclweb.org/anthology/D18-1045" rel="nofollow"&gt;Understanding Back-Translation at Scale&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=5388849145974890035&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Xinyi Wang, Hieu Pham, Zihang Dai, and Graham Neubig. 2018. &lt;a href="http://aclweb.org/anthology/D18-1100" rel="nofollow"&gt;SwitchOut: an Efficient Data Augmentation Algorithm for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=3839046500027819595&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4)&lt;/li&gt;
&lt;li&gt;Mengzhou Xia, Xiang Kong, Antonios Anastasopoulos, and Graham Neubig. 2019. &lt;a href="https://arxiv.org/pdf/1906.03785" rel="nofollow"&gt;Generalized Data Augmentation for Low-Resource Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jinhua Zhu, Fei Gao, Lijun Wu, Yingce Xia, Tao Qin, Wengang Zhou, Xueqi Cheng, and Tie-Yan Liu. 2019. &lt;a href="https://arxiv.org/pdf/1905.10523" rel="nofollow"&gt;Soft Contextual Data Augmentation for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Chunting Zhou, Xuezhe Ma, Junjie Hu, and Graham Neubig. 2019. &lt;a href="https://arxiv.org/pdf/1909.00040" rel="nofollow"&gt;Handling Syntactic Divergence in Low-resource Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yuanpeng Li, Liang Zhao, Jianyu Wang, and Joel Hestness. 2019. &lt;a href="https://arxiv.org/pdf/1910.02612" rel="nofollow"&gt;Compositional Generalization for Primitive Substitutions&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="user-content-data_selection"&gt;&lt;a id="user-content-data-selection-methods" class="anchor" aria-hidden="true" href="#data-selection-methods"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Selection Methods&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Marlies van der Wees, Arianna Bisazza and Christof Monz. 2017. &lt;a href="http://aclweb.org/anthology/D17-1147" rel="nofollow"&gt;Dynamic Data Selection for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.com/scholar?cites=2308754825624963103&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 16)&lt;/li&gt;
&lt;li&gt;Wei Wang, Taro Watanabe, Macduff Hughes, Tetsuji Nakagawa, and Ciprian Chelba. 2018. &lt;a href="http://aclweb.org/anthology/W18-6314" rel="nofollow"&gt;Denoising Neural Machine Translation Training with Trusted Data and Online Data Selection&lt;/a&gt;. In &lt;em&gt;Proceedings of the Third Conference on Machine Translation&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Minh Quang Pham, Josep Crego, Jean Senellart, and François Yvon. 2018. &lt;a href="http://aclweb.org/anthology/D18-1328" rel="nofollow"&gt;Fixing Translation Divergences in Parallel Corpora for Neural MT&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xinyi Wang and Graham Neubig. 2019. &lt;a href="https://arxiv.org/pdf/1905.08212" rel="nofollow"&gt;Target Conditioned Sampling: Optimizing Data Selection for Multilingual Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Wei Wang, Isaac Caswell, and Ciprian Chelba. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1123" rel="nofollow"&gt;Dynamically Composing Domain-Data Selection with Clean-Data Selection by “Co-Curricular Learning” for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Dana Ruiter, Cristina España-Bonet, and Josef van Genabith. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1178" rel="nofollow"&gt;Self-Supervised Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="user-content-transfer_learning"&gt;&lt;a id="user-content-transfer-learning" class="anchor" aria-hidden="true" href="#transfer-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transfer Learning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Barret Zoph, Deniz Yuret, Jonathan May, and Kevin Knight. 2016. &lt;a href="https://www.isi.edu/natural-language/mt/emnlp16-transfer.pdf" rel="nofollow"&gt;Transfer Learning for Low-Resource Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=10126416754494258051&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 104)&lt;/li&gt;
&lt;li&gt;Jiatao Gu, Hany Hassan, Jacob Devlin, and Victor O.K. Li. 2018. &lt;a href="http://aclweb.org/anthology/N18-1032" rel="nofollow"&gt;Universal Neural Machine Translation for Extremely Low Resource Languages&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=17858246967554922903&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 17)&lt;/li&gt;
&lt;li&gt;Tom Kocmi and Ondřej Bojar. 2018. &lt;a href="http://aclweb.org/anthology/W18-6325" rel="nofollow"&gt;Trivial Transfer Learning for Low-Resource Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of the Third Conference on Machine Translation: Research Papers&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Boyuan Pan, Yazheng Yang, Hao Li, Zhou Zhao, Yueting Zhuang, Deng Cai, and Xiaofei He. 2018. &lt;a href="https://papers.nips.cc/paper/7848-macnet-transferring-knowledge-from-machine-comprehension-to-sequence-to-sequence-models.pdf" rel="nofollow"&gt;MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models&lt;/a&gt;. In &lt;em&gt;Proceedings of NeurIPS 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yunsu Kim, Yingbo Gao, and Hermann Ney. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1120" rel="nofollow"&gt;Effective Cross-lingual Transfer of Neural Machine Translation Models without Shared Vocabularies&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="user-content-meta_learning"&gt;&lt;a id="user-content-meta-learning" class="anchor" aria-hidden="true" href="#meta-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Meta Learning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Jiatao Gu, Yong Wang, Yun Chen, Kyunghyun Cho, and Victor O.K. Li. 2018. &lt;a href="http://aclweb.org/anthology/D18-1398" rel="nofollow"&gt;Meta-Learning for Low-Resource Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=15276484097983678999&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-multi-task_learning"&gt;&lt;a id="user-content-multilingual-machine-translation" class="anchor" aria-hidden="true" href="#multilingual-machine-translation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Multilingual Machine Translation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, and Haifeng Wang. 2015. &lt;a href="http://aclweb.org/anthology/P15-1166" rel="nofollow"&gt;Multi-Task Learning for Multiple Language Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2015&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=6980356795259585193" rel="nofollow"&gt;Citation&lt;/a&gt;: 126)&lt;/li&gt;
&lt;li&gt;Orhan Firat, Kyunghyun Cho and Yoshua Bengio. 2016. &lt;a href="https://arxiv.org/pdf/1601.01073.pdf" rel="nofollow"&gt;Multi-way, Multilingual Neural Machine Translation with a Shared Attention Mechanism&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=1297298716616390295&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 146)&lt;/li&gt;
&lt;li&gt;Barret Zoph and Kevin Knight. 2016. &lt;a href="https://arxiv.org/pdf/1601.00710.pdf" rel="nofollow"&gt;Multi-Source Neural Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=9798500345837394101&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 87)&lt;/li&gt;
&lt;li&gt;Orhan Firat, Baskaran SanKaran, Yaser Al-Onaizan, Fatos T.Yarman Vural, Kyunghyun Cho. 2016. &lt;a href="https://arxiv.org/pdf/1606.04164.pdf" rel="nofollow"&gt;Zero-Resource Translation with Multi-Lingual Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=9699063558012530354&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 50)&lt;/li&gt;
&lt;li&gt;Melvin Johnson, Mike Schuster, Quoc V. Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda Viégas, Martin Wattenberg, Greg Corrado, Macduff Hughes, and Jeffrey Dean. 2017. &lt;a href="https://arxiv.org/pdf/1611.04558" rel="nofollow"&gt;Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=12207392403413415154&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 297)&lt;/li&gt;
&lt;li&gt;Poorya Zaremoodi and Gholamreza Haffari. 2018. &lt;a href="http://aclweb.org/anthology/N18-1123" rel="nofollow"&gt;Neural Machine Translation for Bilingually Scarce Scenarios: a Deep Multi-Task Learning Approach&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=2302112873809678173&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Poorya Zaremoodi, Wray Buntine, and Gholamreza Haffari. 2018. &lt;a href="http://aclweb.org/anthology/P18-2104" rel="nofollow"&gt;Adaptive Knowledge Sharing in Multi-Task Learning: Improving Low-Resource Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Surafel Melaku Lakew, Mauro Cettolo, and Marcello Federico. 2018. &lt;a href="http://aclweb.org/anthology/C18-1054" rel="nofollow"&gt;A Comparison of Transformer and Recurrent Neural Networks on Multilingual Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=3404592318370335271&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Graeme Blackwood, Miguel Ballesteros, and Todd Ward. 2018. &lt;a href="http://aclweb.org/anthology/C18-1263" rel="nofollow"&gt;Multilingual Neural Machine Translation with Task-Specific Attention&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=2095693945870319009&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Devendra Singh Sachan and Graham Neubig. 2018. &lt;a href="http://aclweb.org/anthology/W18-6327" rel="nofollow"&gt;Parameter Sharing Methods for Multilingual Self-Attentional Translation Models&lt;/a&gt;. In &lt;em&gt;Proceedings of the Third Conference on Machine Translation: Research Papers&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Emmanouil Antonios Platanios, Mrinmaya Sachan, Graham Neubig, and Tom Mitchell. 2018. &lt;a href="http://aclweb.org/anthology/D18-1039" rel="nofollow"&gt;Contextual Parameter Generation for Universal Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yining Wang, Jiajun Zhang, Feifei Zhai, Jingfang Xu, and Chengqing Zong. 2018. &lt;a href="http://aclweb.org/anthology/D18-1326" rel="nofollow"&gt;Three Strategies to Improve One-to-Many Multilingual Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xu Tan, Yi Ren, Di He, Tao Qin, Zhou Zhao, and Tie-Yan Liu. 2019. &lt;a href="https://openreview.net/pdf?id=S1gUsoR9YX" rel="nofollow"&gt;Multilingual Neural Machine Translation with Knowledge Distillation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xinyi Wang, Hieu Pham, Philip Arthur, and Graham Neubig. 2019. &lt;a href="https://openreview.net/pdf?id=Skeke3C5Fm" rel="nofollow"&gt;Multilingual Neural Machine Translation With Soft Decoupled Encoding&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Maruan Al-Shedivat and Ankur P. Parikh. 2019. &lt;a href="https://arxiv.org/pdf/1904.02338.pdf" rel="nofollow"&gt;Consistency by Agreement in Zero-shot Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Roee Aharoni, Melvin Johnson, and Orhan Firat. 2019. &lt;a href="https://arxiv.org/pdf/1903.00089.pdf" rel="nofollow"&gt;Massively Multilingual Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yunsu Kim, Yingbo Gao, and Hermann Ney. 2019. &lt;a href="https://arxiv.org/pdf/1905.05475" rel="nofollow"&gt;Effective Cross-lingual Transfer of Neural Machine Translation Models without Shared Vocabularies&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Carlos Escolano, Marta R. Costa-Jussà, and José A. R. Fonollosa. 2019. &lt;a href="https://arxiv.org/pdf/1907.00735" rel="nofollow"&gt;From Bilingual to Multilingual Neural Machine Translation by Incremental Training&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yining Wang, Long Zhou, Jiajun Zhang, Feifei Zhai, Jingfang Xu, and Chengqing Zong. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1117" rel="nofollow"&gt;A Compact and Language-Sensitive Multilingual Translation Method&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sukanta Sen, Kamal Kumar Gupta, Asif Ekbal, and Pushpak Bhattacharyya. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1297" rel="nofollow"&gt;Multilingual Unsupervised NMT using Shared Encoder and Language-Specific Decoders&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xu Tan, Jiale Chen, Di He, Yingce Xia, Tao Qin, and Tie-Yan Liu. 2019. &lt;a href="https://arxiv.org/pdf/1908.09324" rel="nofollow"&gt;Multilingual Neural Machine Translation with Language Clustering&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sneha Reddy Kudugunta, Ankur Bapna, Isaac Caswell, Naveen Arivazhagan, and Orhan Firat. 2019. &lt;a href="https://arxiv.org/pdf/1909.02197" rel="nofollow"&gt;Investigating Multilingual NMT Representations at Scale&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Ankur Bapna, Naveen Arivazhagan, and Orhan Firat. 2019. &lt;a href="https://arxiv.org/pdf/1909.08478" rel="nofollow"&gt;Simple, Scalable Adaptation for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-prior_knowledge_integration"&gt;&lt;a id="user-content-prior-knowledge-integration" class="anchor" aria-hidden="true" href="#prior-knowledge-integration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prior Knowledge Integration&lt;/h3&gt;
&lt;h4 id="user-content-word_phrase_constraints"&gt;&lt;a id="user-content--wordphrase-constraints-" class="anchor" aria-hidden="true" href="#-wordphrase-constraints-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt; Word/Phrase Constraints &lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Wei He, Zhongjun He, Hua Wu, and Haifeng Wang. 2016. &lt;a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12189/11577" rel="nofollow"&gt;Improved nerual machine translation with SMT features&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=11596393526530282899&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 46)&lt;/li&gt;
&lt;li&gt;Haitao Mi, Zhiguo Wang, and Abe Ittycheriah. 2016. &lt;a href="http://anthology.aclweb.org/P16-2021" rel="nofollow"&gt;Vocabulary Manipulation for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=10504291626587983597&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 36)&lt;/li&gt;
&lt;li&gt;Philip Arthur, Graham Neubig, and Satoshi Nakamura. 2016. &lt;a href="http://aclweb.org/anthology/D16-1162" rel="nofollow"&gt;Incorporating Discrete Translation Lexicons into Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=3629816068189607565&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 55)&lt;/li&gt;
&lt;li&gt;Xing Wang, Zhengdong Lu, Zhaopeng Tu, Hang Li, Deyi Xiong, Min Zhang. 2017. &lt;a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/viewPaper/14451" rel="nofollow"&gt;Neural Machine Translation Advised by Statistical Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=9788492799819599206&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 34)&lt;/li&gt;
&lt;li&gt;Jiacheng Zhang, Yang Liu, Huanbo Luan, Jingfang Xu and Maosong Sun. 2017. &lt;a href="http://aclweb.org/anthology/P17-1139" rel="nofollow"&gt;Prior Knowledge Integration for Neural Machine Translation using Posterior Regularization&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=16820322563543305280&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 13)&lt;/li&gt;
&lt;li&gt;Chris Hokamp and Qun Liu. 2017. &lt;a href="http://aclweb.org/anthology/P17-1141" rel="nofollow"&gt;Lexically Constrained Decoding for Sequence Generation Using Grid Beam Search&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=3629816068189607565&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 19)&lt;/li&gt;
&lt;li&gt;Zichao Yang, Zhiting Hu, Yuntian Deng, Chris Dyer, and Alex Smola. 2017. &lt;a href="http://aclweb.org/anthology/E17-2061" rel="nofollow"&gt;Neural Machine Translation with Recurrent Attention Modeling&lt;/a&gt;.  In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=5621977008323303060&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 25)&lt;/li&gt;
&lt;li&gt;Ofir Press and Lior Wolf. 2017. &lt;a href="http://aclweb.org/anthology/E17-2025" rel="nofollow"&gt;Using the Output Embedding to Improve Language Models&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=3142797974561089298&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 127)&lt;/li&gt;
&lt;li&gt;Rajen Chatterjee, Matteo Negri, Marco Turchi, Marcello Federico, Lucia Specia, and Frédéric Blain. 2017. &lt;a href="http://aclweb.org/anthology/W17-4716" rel="nofollow"&gt;Guiding Neural Machine Translation Decoding with External Knowledge&lt;/a&gt;. In &lt;em&gt;Proceedings of the Second Conference on Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=16027327382881304751&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 8)&lt;/li&gt;
&lt;li&gt;Rongxiang Weng, Shujian Huang, Zaixiang Zheng, Xinyu Dai, and Jiajun Chen. 2017. &lt;a href="http://aclweb.org/anthology/D17-1013" rel="nofollow"&gt;Neural Machine Translation with Word Predictions&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=9033034245087042151&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 8)&lt;/li&gt;
&lt;li&gt;Yang Feng, Shiyue Zhang, Andi Zhang, Dong Wang, and Andrew Abel. 2017. &lt;a href="http://aclweb.org/anthology/D17-1146" rel="nofollow"&gt;Memory-augmented Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=825727884820810695&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 9)&lt;/li&gt;
&lt;li&gt;Leonard Dahlmann, Evgeny Matusov, Pavel Petrushkov, and Shahram Khadivi. 2017. &lt;a href="http://aclweb.org/anthology/D17-1148" rel="nofollow"&gt;Neural Machine Translation Leveraging Phrase-based Models in A Hybrid Search&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=4507716603851611885&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Xing Wang, Zhaopeng Tu, Deyi Xiong, and Min Zhang. 2017. &lt;a href="http://aclweb.org/anthology/D17-1149" rel="nofollow"&gt;Translating Phrases in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13251445351500921697&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 15)&lt;/li&gt;
&lt;li&gt;Baosong Yang, Derek F. Wong, Tong Xiao, Lidia S. Chao, and Jingbo Zhu. 2017. &lt;a href="http://aclweb.org/anthology/D17-1150" rel="nofollow"&gt;Towards Bidirectional Hierarchical Representations for Attention-based Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=18313642653606285813&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Po-Sen Huang, Chong Wang, Sitao Huang, Dengyong Zhou, and Li Deng. 2018. &lt;a href="https://openreview.net/pdf?id=HktJec1RZ" rel="nofollow"&gt;Towards Neural Phrase-based Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=14839462711165509564&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 15)&lt;/li&gt;
&lt;li&gt;Toan Nguyen and David Chiang. 2018. &lt;a href="http://aclweb.org/anthology/N18-1031" rel="nofollow"&gt;Improving Lexical Choice in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=8911122350121698073&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 8)&lt;/li&gt;
&lt;li&gt;Huadong Chen, Shujian Huang, David Chiang, Xinyu Dai, and Jiajun Chen. 2018. &lt;a href="http://aclweb.org/anthology/N18-1116" rel="nofollow"&gt;Combining Character and Word Information in Neural Machine Translation Using a Multi-Level Attention&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Matt Post and David Vilar. 2018. &lt;a href="http://aclweb.org/anthology/N18-1119" rel="nofollow"&gt;Fast Lexically Constrained Decoding with Dynamic Beam Allocation for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=3504623917475500888&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Jingyi Zhang, Masao Utiyama, Eiichro Sumita, Graham Neubig, and Satoshi Nakamura. 2018. &lt;a href="http://aclweb.org/anthology/N18-1120" rel="nofollow"&gt;Guiding Neural Machine Translation with Retrieved Translation Pieces&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=9376584188557423045&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Eva Hasler, Adrià de Gispert, Gonzalo Iglesias, and Bill Byrne. 2018. &lt;a href="http://aclweb.org/anthology/N18-2081" rel="nofollow"&gt;Neural Machine Translation Decoding with Terminology Constraints&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=17574582694557390759&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Nima Pourdamghani, Marjan Ghazvininejad, and Kevin Knight. 2018. &lt;a href="http://aclweb.org/anthology/N18-2083" rel="nofollow"&gt;Using Word Vectors to Improve Word Alignments for Low Resource Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=936856152380506206&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Shuming Ma, Xu SUN, Yizhong Wang, and Junyang Lin. 2018. &lt;a href="http://aclweb.org/anthology/P18-2053" rel="nofollow"&gt;Bag-of-Words as Target for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=4656961594972480096&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 10)&lt;/li&gt;
&lt;li&gt;Mingxuan Wang, Jun Xie, Zhixing Tan, Jinsong Su, Deyi Xiong, and Chao Bian. 2018. &lt;a href="http://aclweb.org/anthology/C18-1124" rel="nofollow"&gt;Neural Machine Translation with Decoding-History Enhanced Attention&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Arata Ugawa, Akihiro Tamura, Takashi Ninomiya, Hiroya Takamura, and Manabu Okumura. 2018. &lt;a href="http://aclweb.org/anthology/C18-1274" rel="nofollow"&gt;Neural Machine Translation Incorporating Named Entity&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Longyue Wang, Zhaopeng Tu, Andy Way, and Qun Liu. 2018. &lt;a href="http://aclweb.org/anthology/D18-1333" rel="nofollow"&gt;Learning to Jointly Translate and Predict Dropped Pronouns with a Shared Reconstruction Mechanism&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=7240636423092684747&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Qian Cao and Deyi Xiong. 2018. &lt;a href="http://aclweb.org/anthology/D18-1340" rel="nofollow"&gt;Encoding Gated Translation Memory into Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Chengyue Gong, Di He, Xu Tan, Tao Qin, Liwei Wang, and Tie-Yan Liu. 2018. &lt;a href="https://arxiv.org/pdf/1809.06858" rel="nofollow"&gt;FRAGE: Frequency-Agnostic Word Representation&lt;/a&gt;. In &lt;em&gt;Proceedings of NeurIPS 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=899516517229807927&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Inigo Jauregi Unanue, Ehsan Zare Borzeshi, Nazanin Esmaili, and Massimo Piccardi. &lt;a href="https://arxiv.org/pdf/1904.02461.pdf" rel="nofollow"&gt;ReWE: Regressing Word Embeddings for Regularization of Neural Machine Translation Systems&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Kai Song, Yue Zhang, Heng Yu, Weihua Luo, Kun Wang, and Min Zhang. 2019. &lt;a href="https://www.aclweb.org/anthology/N19-1044" rel="nofollow"&gt;Code-Switching for Enhancing NMT with Pre-Specified Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xuebo Liu, Derek F. Wong, Yang Liu, Lidia S. Chao, Tong Xiao, and Jingbo Zhu. 2019. &lt;a href="https://arxiv.org/pdf/1906.03100" rel="nofollow"&gt;Shared-Private Bilingual Word Embeddings for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Georgiana Dinu, Prashant Mathur, Marcello Federico, and Yaser Al-Onaizan. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1294" rel="nofollow"&gt;Training Neural Machine Translation to Apply Terminology Constraints&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Longyue Wang, Zhaopeng Tu, Xing Wang and Shuming Shi. 2019. &lt;a href="https://www.aclweb.org/anthology/D19-1085.pdf" rel="nofollow"&gt;One Model to Learn Both: Zero Pronoun Prediction and Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="user-content-syntactic_semantic_constraints"&gt;&lt;a id="user-content--syntacticsemantic-constraints-" class="anchor" aria-hidden="true" href="#-syntacticsemantic-constraints-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt; Syntactic/Semantic Constraints &lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Trevor Cohn, Cong Duy Vu Hoang, Ekaterina Vymolova, Kaisheng Yao, Chris Dyer, and Gholamreza Haffari. 2016. &lt;a href="https://arxiv.org/pdf/1601.01085.pdf" rel="nofollow"&gt;Incorporating Structural Alignment Biases into an Attentional Neural Translation Model&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=6876101136632328854&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 80)&lt;/li&gt;
&lt;li&gt;Yong Cheng, Shiqi Shen, Zhongjun He, Wei He, Hua Wu, Maosong Sun, and Yang Liu. 2016. &lt;a href="http://nlp.csai.tsinghua.edu.cn/~ly/papers/ijcai16_agree.pdf" rel="nofollow"&gt;Agreement-based Joint Training for Bidirectional Attention-based Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of IJCAI 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=7726998929707665947&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 26)&lt;/li&gt;
&lt;li&gt;Akiko Eriguchi, Kazuma Hashimoto, and Yoshimasa Tsuruoka. 2016. &lt;a href="http://aclweb.org/anthology/P16-1078" rel="nofollow"&gt;Tree-to-Sequence Attentional Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=10114639659174243367&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 79)&lt;/li&gt;
&lt;li&gt;Felix Stahlberg, Eva Hasler, Aurelien Waite, and Bill Byrne. 2016. &lt;a href="http://anthology.aclweb.org/P16-2049" rel="nofollow"&gt;Syntactically Guided Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=11012034683105038430" rel="nofollow"&gt;Citation&lt;/a&gt;: 32)&lt;/li&gt;
&lt;li&gt;Xing Shi, Inkit Padhi, and Kevin Knight. 2016. &lt;a href="http://aclweb.org/anthology/D16-1159" rel="nofollow"&gt;Does string-based neural MT learn source syntax?&lt;/a&gt;. In &lt;em&gt;Proceedings of the EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?oi=bibs&amp;amp;hl=en&amp;amp;cites=13782051589621719871" rel="nofollow"&gt;Citation&lt;/a&gt;: 57)&lt;/li&gt;
&lt;li&gt;Junhui Li, Deyi Xiong, Zhaopeng Tu, Muhua Zhu, Min Zhang, and Guodong Zhou. 2017. &lt;a href="http://aclweb.org/anthology/P17-1064" rel="nofollow"&gt;Modeling Source Syntax for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=4418568278013664001&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 30)&lt;/li&gt;
&lt;li&gt;Shuangzhi Wu, Dongdong Zhang, Nan Yang, Mu Li, and Ming Zhou. 2017. &lt;a href="http://aclweb.org/anthology/P17-1065" rel="nofollow"&gt;Sequence-to-Dependency Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13183481097489234938&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 19)&lt;/li&gt;
&lt;li&gt;Jinchao Zhang, Mingxuan Wang, Qun Liu, and Jie Zhou. 2017. &lt;a href="http://aclweb.org/anthology/P17-1140" rel="nofollow"&gt;Incorporating Word Reordering Knowledge into Attention-based Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9939097556529491198&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 8)&lt;/li&gt;
&lt;li&gt;Huadong Chen, Shujian Huang, David Chiang, and Jiajun Chen. 2017. &lt;a href="http://aclweb.org/anthology/P17-1177" rel="nofollow"&gt;Improved Neural Machine Translation with a Syntax-Aware Encoder and Decoder&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=17162498190462264248&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 32)&lt;/li&gt;
&lt;li&gt;Akiko Eriguchi, Yoshimasa Tsuruoka, and Kyunghyun Cho. 2017. &lt;a href="http://aclweb.org/anthology/P17-2012" rel="nofollow"&gt;Learning to Parse and Translate Improves Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=17499695818526131085&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 29)&lt;/li&gt;
&lt;li&gt;Roee Aharoni and Yoav Goldberg. 2017. &lt;a href="http://aclweb.org/anthology/P17-2021" rel="nofollow"&gt;Towards String-To-Tree Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13743835036381505969&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 45)&lt;/li&gt;
&lt;li&gt;Kazuma Hashimoto and Yoshimasa Tsuruoka. 2017. &lt;a href="http://aclweb.org/anthology/D17-1012" rel="nofollow"&gt;Neural Machine Translation with Source-Side Latent Graph Parsing&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=2595733316497621779&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 9)&lt;/li&gt;
&lt;li&gt;Joost Bastings, Ivan Titov, Wilker Aziz, Diego Marcheggiani, and Khalil Simaan. 2017. &lt;a href="http://aclweb.org/anthology/D17-1209" rel="nofollow"&gt;Graph Convolutional Encoders for Syntax-aware Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=4876389727678322394&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 31)&lt;/li&gt;
&lt;li&gt;Kehai Chen, Rui Wang, Masao Utiyama, Lemao Liu, Akihiro Tamura, Eiichiro Sumita, and Tiejun Zhao. 2017. &lt;a href="http://aclweb.org/anthology/D17-1304" rel="nofollow"&gt;Neural Machine Translation with Source Dependency Representation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=3839215870693368887&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 7)&lt;/li&gt;
&lt;li&gt;Peyman Passban, Qun Liu, and Andy Way. 2018. &lt;a href="http://aclweb.org/anthology/N18-1006" rel="nofollow"&gt;Improving Character-Based Decoding Using Target-Side Morphological Information for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13968879243228181963&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Diego Marcheggiani, Joost Bastings, and Ivan Titov. 2018. &lt;a href="http://aclweb.org/anthology/N18-2078" rel="nofollow"&gt;Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9319609055086898131&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 7)&lt;/li&gt;
&lt;li&gt;Chunpeng Ma, Akihiro Tamura, Masao Utiyama, Tiejun Zhao, and Eiichiro Sumita. 2018. &lt;a href="http://aclweb.org/anthology/P18-1116" rel="nofollow"&gt;Forest-Based Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=8184521634220071433&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Shaohui Kuang, Junhui Li, António Branco, Weihua Luo, and Deyi Xiong. 2018. &lt;a href="http://aclweb.org/anthology/P18-1164" rel="nofollow"&gt;Attention Focusing for Neural Machine Translation by Bridging Source and Target Embeddings&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13357719581808108940&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Duygu Ataman and Marcello Federico. 2018. &lt;a href="http://aclweb.org/anthology/P18-2049" rel="nofollow"&gt;Compositional Representation of Morphologically-Rich Input for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=12939556873639208603&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4)&lt;/li&gt;
&lt;li&gt;Daniel Beck, Gholamreza Haffari, and Trevor Cohn. 2018. &lt;a href="http://aclweb.org/anthology/P18-1026" rel="nofollow"&gt;Graph-to-Sequence Learning using Gated Graph Neural Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.au/scholar?cites=12197496840503693067&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;:3)&lt;/li&gt;
&lt;li&gt;Danielle Saunders, Felix Stahlberg, Adrià de Gispert, and Bill Byrne. 2018. &lt;a href="http://aclweb.org/anthology/P18-2051" rel="nofollow"&gt;Multi-representation Ensembles and Delayed SGD Updates Improve Syntax-based NMT&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Wen Zhang, Jiawei Hu, Yang Feng, and Qun Liu. 2018. &lt;a href="http://aclweb.org/anthology/C18-1110" rel="nofollow"&gt;Refining Source Representations with Relation Networks for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Poorya Zaremoodi and Gholamreza Haffari. 2018. &lt;a href="http://aclweb.org/anthology/C18-1120" rel="nofollow"&gt;Incorporating Syntactic Uncertainty in Neural Machine Translation with a Forest-to-Sequence Model&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Hao Zhang, Axel Ng, and Richard Sproat. 2018. &lt;a href="http://aclweb.org/anthology/C18-1123" rel="nofollow"&gt;Fast and Accurate Reordering with ITG Transition RNN&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jetic Gū, Hassan S. Shavarani, and Anoop Sarkar. 2018. &lt;a href="http://aclweb.org/anthology/D18-1037" rel="nofollow"&gt;Top-down Tree Structured Decoding with Syntactic Connections for Neural Machine Translation and Parsing&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Anna Currey and Kenneth Heafield. 2018. &lt;a href="http://aclweb.org/anthology/D18-1327" rel="nofollow"&gt;Multi-Source Syntactic Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xinyi Wang, Hieu Pham, Pengcheng Yin, and Graham Neubig. 2018. &lt;a href="http://aclweb.org/anthology/D18-1509" rel="nofollow"&gt;A Tree-based Decoder for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9083843868999368969&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Eliyahu Kiperwasser and Miguel Ballesteros. 2018. &lt;a href="http://aclweb.org/anthology/Q18-1017" rel="nofollow"&gt;Scheduled Multi-Task Learning: From Syntax to Translation&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=7224616032403591303&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4)&lt;/li&gt;
&lt;li&gt;Xiao Pu, Nikolaos Pappas, James Henderson, and Andrei Popescu-Belis. 2018. &lt;a href="https://www.aclweb.org/anthology/Q18-1044" rel="nofollow"&gt;Integrating Weakly Supervised Word Sense Disambiguation into Neural Machine Translation&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Kai Song, Yue Zhang, Min Zhang, and Weihua Luo. 2018. &lt;a href="https://arxiv.org/pdf/1801.03615" rel="nofollow"&gt;Improved English to Russian Translation by Neural Suffix Prediction&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Rudra Murthy V, Anoop Kunchukuttan, and Pushpak Bhattacharyya. 2019. &lt;a href="https://arxiv.org/pdf/1811.00383.pdf" rel="nofollow"&gt;Addressing word-order Divergence in Multilingual Neural Machine Translation for extremely Low Resource Languages&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Meishan Zhang, Zhenghua Li, Guohong Fu, and Min Zhang. 2019. &lt;a href="https://arxiv.org/pdf/1905.02878" rel="nofollow"&gt;Syntax-Enhanced Neural Machine Translation with Syntax-Aware Word Representations&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Linfeng Song, Daniel Gildea, Yue Zhang, Zhiguo Wang, and Jinsong Su. 2019. &lt;a href="https://www.aclweb.org/anthology/Q19-1002" rel="nofollow"&gt;Semantic Neural Machine Translation Using AMR&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Nader Akoury, Kalpesh Krishna, and Mohit Iyyer. 2019. &lt;a href="https://arxiv.org/pdf/1906.02780" rel="nofollow"&gt;Syntactically Supervised Transformers for Faster Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Zhijiang Guo, Yan Zhang, Zhiyang Teng, and Wei Lu. 2019. &lt;a href="https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00269" rel="nofollow"&gt;Densely Connected Graph Convolutional Networks for Graph-to-Sequence Learning&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xuewen Yang, Yingru Liu, Dongliang Xie, Xin Wang, and Niranjan Balasubramanian. 2019. &lt;a href="https://arxiv.org/pdf/1908.11782" rel="nofollow"&gt;Latent Part-of-Speech Sequences for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jie Hao, Xing Wang, Shuming Shi, Jinfeng Zhang, and Zhaopeng Tu. 2019. &lt;a href="https://arxiv.org/pdf/1909.02222" rel="nofollow"&gt;Multi-Granularity Self-Attention for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jie Hao, Xing Wang, Shuming Shi, Jinfeng Zhang, and Zhaopeng Tu. 2019. &lt;a href="https://arxiv.org/pdf/1909.01562" rel="nofollow"&gt;Towards Better Modeling Hierarchical Structure for Self-Attention with Ordered Neurons&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="user-content-coverage_constraints"&gt;&lt;a id="user-content-coverage-constraints" class="anchor" aria-hidden="true" href="#coverage-constraints"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Coverage Constraints&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Zhaopeng Tu, Zhengdong Lu, Yang Liu, Xiaohua Liu, and Hang Li. 2016. &lt;a href="http://aclweb.org/anthology/P16-1008" rel="nofollow"&gt;Modeling Coverage for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=894656013823838967&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 236)&lt;/li&gt;
&lt;li&gt;Haitao Mi, Baskaran Sankaran, Zhiguo Wang, and Abe Ittycheriah. 2016. &lt;a href="http://aclweb.org/anthology/D16-1096" rel="nofollow"&gt;Coverage Embedding Models for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=10478809182142146899&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 59)&lt;/li&gt;
&lt;li&gt;Zhaopeng Tu, Yang Liu, Zhengdong Lu, Xiaohua Liu, and Hang Li. 2017. &lt;a href="http://aclweb.org/anthology/Q17-1007" rel="nofollow"&gt;Context Gates for Neural Machine Translation&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=4217513324479200768&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 36)&lt;/li&gt;
&lt;li&gt;Yanyang Li, Tong Xiao, Yinqiao Li, Qiang Wang, Changming Xu, and Jingbo Zhu. 2018. &lt;a href="http://aclweb.org/anthology/P18-2047" rel="nofollow"&gt;A Simple and Effective Approach to Coverage-Aware Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9588245142858602659&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Zaixiang Zheng, Hao Zhou, Shujian Huang, Lili Mou, Xinyu Dai, Jiajun Chen, and Zhaopeng Tu. 2018. &lt;a href="https://aclanthology.coli.uni-saarland.de/events/tacl-2018" rel="nofollow"&gt;Modeling Past and Future for Neural Machine Translation&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=3361428233702531610&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 10)&lt;/li&gt;
&lt;li&gt;Xiang Kong, Zhaopeng Tu, Shuming Shi, Eduard Hovy, and Tong Zhang. &lt;a href="https://arxiv.org/pdf/1811.08541.pdf" rel="nofollow"&gt;Neural Machine Translation with Adequacy-Oriented Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-document_level_translation"&gt;&lt;a id="user-content-document-level-translation" class="anchor" aria-hidden="true" href="#document-level-translation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Document-level Translation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Longyue Wang, Zhaopeng Tu, Andy Way, and Qun Liu. 2017. &lt;a href="http://aclweb.org/anthology/D17-1301" rel="nofollow"&gt;Exploiting Cross-Sentence Context for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=7614033458131200423&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 19)&lt;/li&gt;
&lt;li&gt;Jörg Tiedemann, and Yves Scherrer. 2017. &lt;a href="http://www.aclweb.org/anthology/W17-4811" rel="nofollow"&gt;Neural Machine Translation with Extended Context&lt;/a&gt;. In &lt;em&gt;Proceedings of the Third Workshop on Discourse in Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=16950693252825831302" rel="nofollow"&gt;Citation&lt;/a&gt;: 12)&lt;/li&gt;
&lt;li&gt;Rachel Bawden, Rico Sennrich, Alexandra Birch, and Barry Haddow. 2018. &lt;a href="http://aclweb.org/anthology/N18-1118" rel="nofollow"&gt;Evaluating Discourse Phenomena in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=1436848483757205177&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Elena Voita, Pavel Serdyukov, Rico Sennrich, and Ivan Titov. 2018. &lt;a href="http://aclweb.org/anthology/P18-1117" rel="nofollow"&gt;Context-Aware Neural Machine Translation Learns Anaphora Resolution&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=16594777811418303416&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 7)&lt;/li&gt;
&lt;li&gt;Sameen Maruf and Gholamreza Haffari. 2018. &lt;a href="http://aclweb.org/anthology/P18-1118" rel="nofollow"&gt;Document Context Neural Machine Translation with Memory Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=17337605639464710308&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Shaohui Kuang, Deyi Xiong, Weihua Luo, Guodong Zhou. 2018. &lt;a href="http://aclweb.org/anthology/C18-1050" rel="nofollow"&gt;Modeling Coherence for Neural Machine Translation with Dynamic and Topic Caches&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=12991114209233735355&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Shaohui Kuang and Deyi Xiong. 2018. &lt;a href="https://arxiv.org/pdf/1806.04466.pdf" rel="nofollow"&gt;Fusing Recency into Neural Machine Translation with an Inter-Sentence Gate Model&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jiacheng Zhang, Huanbo Luan, Maosong Sun, Feifei Zhai, Jingfang Xu, Min Zhang and Yang Liu. 2018. &lt;a href="http://aclweb.org/anthology/D18-1049" rel="nofollow"&gt;Improving the Transformer Translation Model with Document-Level Context&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Samuel Läubli, Rico Sennrich, and Martin Volk. 2018. &lt;a href="http://aclweb.org/anthology/D18-1512" rel="nofollow"&gt;Has Machine Translation Achieved Human Parity? A Case for Document-level Evaluation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13135618112238453725&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Lesly Miculicich, Dhananjay Ram, Nikolaos Pappas, and James Henderson. 2018. &lt;a href="http://aclweb.org/anthology/D18-1325" rel="nofollow"&gt;Document-Level Neural Machine Translation with Hierarchical Attention Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Zhaopeng Tu, Yang Liu, Shuming Shi, and Tong Zhang. 2018. &lt;a href="https://arxiv.org/pdf/1711.09367.pdf" rel="nofollow"&gt;Learning to Remember Translation History with a Continuous Cache&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=15854294745619374487&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 9)&lt;/li&gt;
&lt;li&gt;Elena Voita, Rico Sennrich, and Ivan Titov. 2019. &lt;a href="https://arxiv.org/pdf/1905.05979" rel="nofollow"&gt;When a Good Translation is Wrong in Context: Context-Aware Machine Translation Improves on Deixis, Ellipsis, and Lexical Cohesion&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Elena Voita, Rico Sennrich, and Ivan Titov. 2019. &lt;a href="https://arxiv.org/pdf/1909.01383" rel="nofollow"&gt;Context-Aware Monolingual Repair for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-robustness"&gt;&lt;a id="user-content-robustness" class="anchor" aria-hidden="true" href="#robustness"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Robustness&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Yonatan Belinkov and Yonatan Bisk. 2018. &lt;a href="https://openreview.net/pdf?id=BJ8vJebC-" rel="nofollow"&gt;Synthetic and Natural Noise Both Break Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=10493132199224079445&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 33)&lt;/li&gt;
&lt;li&gt;Zhengli Zhao, Dheeru Dua, and Sameer Singh. 2018. &lt;a href="https://openreview.net/pdf?id=H1BLjgZCb" rel="nofollow"&gt;Generating Natural Adversarial Examples&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=6487263081764376046&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 45)&lt;/li&gt;
&lt;li&gt;Yong Cheng, Zhaopeng Tu, Fandong Meng, Junjie Zhai, and Yang Liu. 2018. &lt;a href="http://aclweb.org/anthology/P18-1163" rel="nofollow"&gt;Towards Robust Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13572592499424174633&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2018. &lt;a href="http://aclweb.org/anthology/P18-1079" rel="nofollow"&gt;Semantically Equivalent Adversarial Rules for Debugging NLP models&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=3200079019495885814&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 12)&lt;/li&gt;
&lt;li&gt;Javid Ebrahimi, Daniel Lowd, and Dejing Dou. 2018. &lt;a href="http://aclweb.org/anthology/C18-1055" rel="nofollow"&gt;On Adversarial Examples for Character-Level Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Paul Michel and Graham Neubig. 2018. &lt;a href="http://aclweb.org/anthology/D18-1050" rel="nofollow"&gt;MTNT: A Testbed for Machine Translation of Noisy Text&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Antonios Anastasopoulos, Alison Lui, Toan Nguyen, and David Chiang. 2019. &lt;a href="https://arxiv.org/pdf/1808.06267.pdf" rel="nofollow"&gt;Neural Machine Translation of Text from Non-Native Speakers&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Paul Michel, Xian Li, Graham Neubig, and Juan Miguel Pino. 2019. &lt;a href="https://arxiv.org/pdf/1903.06620.pdf" rel="nofollow"&gt;On Evaluation of Adversarial Perturbations for Sequence-to-Sequence Models&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Vaibhav Vaibhav, Sumeet Singh, Craig Stewart, and Graham Neubig. 2019. &lt;a href="https://arxiv.org/pdf/1902.09508.pdf" rel="nofollow"&gt;Improving Robustness of Machine Translation with Synthetic Noise&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yong Cheng, Lu Jiang, and Wolfgang Macherey. 2019. &lt;a href="https://arxiv.org/pdf/1906.02443" rel="nofollow"&gt;Robust Neural Machine Translation with Doubly Adversarial Inputs&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Hairong Liu, Mingbo Ma, Liang Huang, Hao Xiong, and Zhongjun He. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1291" rel="nofollow"&gt;Robust Neural Machine Translation with Joint Textual and Phonetic Embedding&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-interpretability"&gt;&lt;a id="user-content-interpretability" class="anchor" aria-hidden="true" href="#interpretability"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interpretability&lt;/h3&gt; 
&lt;ul&gt;
&lt;li&gt;Yanzhuo Ding, Yang Liu, Huanbo Luan and Maosong Sun. 2017. &lt;a href="http://aclweb.org/anthology/P17-1106" rel="nofollow"&gt;Visualizing and Understanding Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=6029143337933047130&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 22)&lt;/li&gt;
&lt;li&gt;Hendrik Strobelt, Sebastian Gehrmann, Michael Behrisch, Adam Perer, Hanspeter Pfister, and Alexander M. Rush. 2018. &lt;a href="https://arxiv.org/pdf/1804.09299.pdf" rel="nofollow"&gt;Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models&lt;/a&gt;. In &lt;em&gt;Proceedings of VAST 2018&lt;/em&gt; and &lt;em&gt;Proceedings of EMNLP-BlackBox 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=8924303979242528991&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Alessandro Raganato and Jorg Tiedemann. 2018. &lt;a href="http://aclweb.org/anthology/W18-5431" rel="nofollow"&gt;An Analysis of Encoder Representations in Transformer-Based Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP-BlackBox 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Felix Stahlberg, Danielle Saunders, and Bill Byrne. 2018. &lt;a href="http://aclweb.org/anthology/W18-5420" rel="nofollow"&gt;An Operation Sequence Model for Explainable Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP-BlackBox 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Fahim Dalvi, Nadir Durrani, Hassan Sajjad, Yonatan Belinkov, D. Anthony Bau, and James Glass. 2019. &lt;a href="http://people.csail.mit.edu/belinkov/assets/pdf/aaai2019.pdf" rel="nofollow"&gt;What Is One Grain of Sand in the Desert? Analyzing Individual Neurons in Deep NLP Models&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2019&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=9612190838970536755&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Anthony Bau, Yonatan Belinkov, Hassan Sajjad, Nadir Durrani, Fahim Dalvi, and James Glass. 2019. &lt;a href="https://openreview.net/pdf?id=H1z-PsR5KX" rel="nofollow"&gt;Identifying and Controlling Important Neurons in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2019&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=10670221460130643181&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Yonatan Belinkov, and James Glass. 2019. &lt;a href="https://www.aclweb.org/anthology/Q19-1004" rel="nofollow"&gt;Analysis Methods in Neural Language Processing: A Survey&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sofia Serrano and Noah A. Smith. 2019. &lt;a href="https://arxiv.org/pdf/1906.03731" rel="nofollow"&gt;Is Attention Interpretable?&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Elena Voita, David Talbot, Fedor Moiseev, Rico Sennrich, and Ivan Titov. 2019. &lt;a href="https://arxiv.org/pdf/1905.09418" rel="nofollow"&gt;Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Joris Baan, Jana Leible, Mitja Nikolaus, David Rau, Dennis Ulmer, Tim Baumgärtner, Dieuwke Hupkes, and Elia Bruni. 2019. &lt;a href="https://arxiv.org/pdf/1906.01634" rel="nofollow"&gt;On the Realization of Compositionality in Neural Networks&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jesse Vig and Yonatan Belinkov. 2019. &lt;a href="https://arxiv.org/pdf/1906.04284" rel="nofollow"&gt;Analyzing the Structure of Attention in a Transformer Language Model&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Baosong Yang, Longyue Wang, Derek F. Wong, Lidia S. Chao, and Zhaopeng Tu. 2019. &lt;a href="https://arxiv.org/pdf/1906.00592" rel="nofollow"&gt;Assessing the Ability of Self-Attention Networks to Learn Word Order&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xintong Li, Guanlin Li, Lemao Liu, Max Meng, and Shuming Shi. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1124" rel="nofollow"&gt;On the Word Alignment from Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Elena Voita, Rico Sennrich, and Ivan Titov. 2019. &lt;a href="https://arxiv.org/pdf/1909.01380" rel="nofollow"&gt;The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Shilin He, Zhaopeng Tu, Xing Wang, Longyue Wang, Michael R. Lyu, and Shuming Shi. 2019. &lt;a href="https://arxiv.org/pdf/1909.00326" rel="nofollow"&gt;Towards Understanding Neural Machine Translation with Word Importance&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Felix Stahlberg and Bill Byrne. 2019. &lt;a href="https://arxiv.org/pdf/1908.10090" rel="nofollow"&gt;On NMT Search Errors and Model Errors: Cat Got Your Tongue?&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-linguistic_interpretation"&gt;&lt;a id="user-content-linguistic-interpretation" class="anchor" aria-hidden="true" href="#linguistic-interpretation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linguistic Interpretation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Felix Hill, Kyunghyun Cho, Sebastien Jean, Coline Devin, and Yoshua Bengio. 2015. &lt;a href="https://arxiv.org/pdf/1412.6448.pdf" rel="nofollow"&gt;Embedding Word Similarity with Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2015&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=3941248209566557946&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 24)&lt;/li&gt;
&lt;li&gt;Xing Shi, Inkit Padhi, and Kevin Knight. 2016. &lt;a href="http://aclweb.org/anthology/D16-1159" rel="nofollow"&gt;Does String-based Neural MT Learn Source Syntax?&lt;/a&gt;. In &lt;em&gt;Proceedings of the EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?oi=bibs&amp;amp;hl=en&amp;amp;cites=13782051589621719871" rel="nofollow"&gt;Citation&lt;/a&gt;: 57)&lt;/li&gt;
&lt;li&gt;Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, and James Glass. 2017. &lt;a href="http://aclweb.org/anthology/P17-1080" rel="nofollow"&gt;What do Neural Machine Translation Models Learn about Morphology?&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=3142186338143493642&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 50)&lt;/li&gt;
&lt;li&gt;Ella Rabinovich, Noam Ordan, and Shuly Wintner. 2017. &lt;a href="http://aclweb.org/anthology/P17-1049" rel="nofollow"&gt;Found in Translation: Reconstructing Phylogenetic Language Trees from Translations&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=10035323574777301594&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Rico Sennrich. 2017. &lt;a href="http://aclweb.org/anthology/E17-2060" rel="nofollow"&gt;How Grammatical is Character-level Neural Machine Translation? Assessing MT Quality with Contrastive Translation Pairs&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=14294900718072928557&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 25)&lt;/li&gt;
&lt;li&gt;Adam Poliak, Yonatan Belinkov, James Glass, and Benjamin Van Durme. 2018. &lt;a href="http://aclweb.org/anthology/N18-2082" rel="nofollow"&gt;On the Evaluation of Semantic Phenomena in Neural Machine Translation Using Natural Language Inference&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=9402109271974711503&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Arianna Bisazza and Clara Tump. 2018. &lt;a href="http://aclweb.org/anthology/D18-1313" rel="nofollow"&gt;The Lazy Encoder: A Fine-Grained Analysis of the Role of Morphology in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Lijun Wu, Xu Tan, Di He, Fei Tian, Tao Qin, Jianhuang Lai, and Tie-Yan Liu. 2018. &lt;a href="http://aclweb.org/anthology/D18-1396" rel="nofollow"&gt;Beyond Error Propagation in Neural Machine Translation: Characteristics of Language Also Matter&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=1081737155461853408&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4)&lt;/li&gt;
&lt;li&gt;Gongbo Tang, Rico Sennrich, and Joakim Nivre. 2019. &lt;a href="https://arxiv.org/pdf/1908.11771" rel="nofollow"&gt;Encoders Help You Disambiguate Word Senses in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-fairness_and_diversity"&gt;&lt;a id="user-content-fairness-and-diversity" class="anchor" aria-hidden="true" href="#fairness-and-diversity"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fairness and Diversity&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Hayahide Yamagishi, Shin Kanouchi, Takayuki Sato, and Mamoru Komachi. 2016. &lt;a href="http://www.aclweb.org/anthology/W16-4620" rel="nofollow"&gt;Controlling the Voice of a Sentence in Japanese-to-English Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of the 3rd Workshop on Asian Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=3457358295141990828&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Rico Sennrich, Barry Haddow and Alexandra Birch. 2016. &lt;a href="http://aclweb.org/anthology/N16-1005" rel="nofollow"&gt;Controlling Politeness in Neural Machine Translation via Side Constraints&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=13603295392629577946&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 49)&lt;/li&gt;
&lt;li&gt;Xing Niu, Marianna Martindale, and Marine Carpuat. 2017. &lt;a href="http://aclweb.org/anthology/D17-1299" rel="nofollow"&gt;A Study of Style in Machine Translation: Controlling the Formality of Machine Translation Output&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=1203074987073423616&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 8)&lt;/li&gt;
&lt;li&gt;Ella Rabinovich, Raj Nath Patel, Shachar Mirkin, Lucia Specia, and Shuly Wintner. 2017. &lt;a href="http://aclweb.org/anthology/E17-1101" rel="nofollow"&gt;Personalized Machine Translation: Preserving Original Author Traits&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=6856955572531425903&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 10)&lt;/li&gt;
&lt;li&gt;Myle Ott, Michael Auli, David Grangier, and Marc'Aurelio Ranzato. 2018. &lt;a href="https://arxiv.org/pdf/1803.00047" rel="nofollow"&gt;Analyzing Uncertainty in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=1522001537063991105&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Paul Michel and Graham Neubig. 2018. &lt;a href="http://www.aclweb.org/anthology/P18-2050" rel="nofollow"&gt;Extreme Adaptation for Personalized Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=16717798879574507487&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Eva Vanmassenhove, Christian Hardmeier, and Andy Way. 2018. &lt;a href="http://www.aclweb.org/anthology/D18-1334" rel="nofollow"&gt;Getting Gender Right in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Ashwin Kalyan, Peter Anderson, Stefan Lee, and Dhruv Batra. 2019. &lt;a href="http://proceedings.mlr.press/v97/kalyan19a/kalyan19a.pdf" rel="nofollow"&gt;Trainable Decoding of Sets of Sequences for Neural Sequence Models&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Tianxiao Shen, Myle Ott, Michael Auli, and Marc’Aurelio Ranzato. 2019. &lt;a href="http://proceedings.mlr.press/v97/shen19c/shen19c.pdf" rel="nofollow"&gt;Mixture Models for Diverse Machine Translation: Tricks of the Trade&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Wouter Kool, Herke van Hoof, and Max Welling. 2019. &lt;a href="http://proceedings.mlr.press/v97/kool19a/kool19a.pdf" rel="nofollow"&gt;Stochastic Beams and Where to Find Them: The Gumbel-Top-k Trick for Sampling Sequences Without Replacement&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Won Ik Cho, Ji Won Kim, Seok Min Kim, and Nam Soo Kim. 2019. &lt;a href="https://arxiv.org/pdf/1905.11684" rel="nofollow"&gt;On Measuring Gender Bias in Translation of Gender-neutral Pronouns&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Gabriel Stanovsky, Noah A. Smith, and Luke Zettlemoyer. 2019. &lt;a href="https://arxiv.org/pdf/1906.00591" rel="nofollow"&gt;Evaluating Gender Bias in Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Keita Kurita, Nidhi Vyas, Ayush Pareek, Alan W Black, and Yulia Tsvetkov. 2019. &lt;a href="https://arxiv.org/pdf/1906.07337" rel="nofollow"&gt;Measuring Bias in Contextualized Word Representations&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Raphael Shu, Hideki Nakayama, and Kyunghyun Cho. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1177" rel="nofollow"&gt;Generating Diverse Translations with Sentence Codes&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Daphne Ippolito, Reno Kriz, Joao Sedoc, Maria Kustikova, and Chris Callison-Burch. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1365" rel="nofollow"&gt;Comparison of Diverse Decoding Methods from Conditional Language Models&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-efficiency"&gt;&lt;a id="user-content-efficiency" class="anchor" aria-hidden="true" href="#efficiency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Efficiency&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Abigail See, Minh-Thang Luong, and Christopher D. Manning. 2016. &lt;a href="http://aclweb.org/anthology/K16-1029" rel="nofollow"&gt;Compression of Neural Machine Translation Models via Pruning&lt;/a&gt;. In &lt;em&gt;Proceedings of CoNLL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13072353668416361496&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 33)&lt;/li&gt;
&lt;li&gt;Yusuke Oda, Philip Arthur, Graham Neubig, Koichiro Yoshino, and Satoshi Nakamura. 2017. &lt;a href="http://aclweb.org/anthology/P17-1079" rel="nofollow"&gt;Neural Machine Translation via Binary Code Prediction&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9954145361647418034&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Xing Shi and Kevin Knight. 2017. &lt;a href="http://aclweb.org/anthology/P17-2091" rel="nofollow"&gt;Speeding Up Neural Machine Translation Decoding by Shrinking Run-time Vocabulary&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=7302197227417767855&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Ofir Press and Lior Wolf. 2017. &lt;a href="http://aclweb.org/anthology/E17-2025" rel="nofollow"&gt;Using the Output Embedding to Improve Language Models&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=3142797974561089298" rel="nofollow"&gt;Citation&lt;/a&gt;: 126)&lt;/li&gt;
&lt;li&gt;Xiaowei Zhang, Wei Chen, Feng Wang, Shuang Xu, and Bo Xu. 2017. &lt;a href="http://aclweb.org/anthology/D17-1154" rel="nofollow"&gt;Towards Compact and Fast Neural Machine Translation Using a Combined Method&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=832815405370901340&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Felix Stahlberg and Bill Byrne. 2017. &lt;a href="http://aclweb.org/anthology/D17-1208" rel="nofollow"&gt;Unfolding and Shrinking Neural Machine Translation Ensembles&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=14880262780099335970&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Jacob Devlin. 2017. &lt;a href="http://aclweb.org/anthology/D17-1300" rel="nofollow"&gt;Sharp Models on Dull Hardware: Fast and Accurate Neural Machine Translation Decoding on the CPU&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=17103371978045782164&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 8)&lt;/li&gt;
&lt;li&gt;Dakun Zhang, Jungi Kim, Josep Crego, and Jean Senellart. 2017. &lt;a href="http://aclweb.org/anthology/I17-2046" rel="nofollow"&gt;Boosting Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of IJCNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=10941157301841399344&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Łukasz Kaiser, Aurko Roy, Ashish Vaswani, Niki Parmar, Samy Bengio, Jakob Uszkoreit, and Noam Shazeer. 2018. &lt;a href="https://arxiv.org/pdf/1803.03382.pdf" rel="nofollow"&gt;Fast Decoding in Sequence Models Using Discrete Latent Variables&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=4042994175439965815&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Gonzalo Iglesias, William Tambellini, Adrià de Gispert, Eva Hasler, and Bill Byrne. 2018. &lt;a href="http://aclweb.org/anthology/N18-3013" rel="nofollow"&gt;Accelerating NMT Batched Beam Decoding with LMBR Posteriors for Deployment&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jerry Quinn and Miguel Ballesteros. 2018. &lt;a href="http://aclweb.org/anthology/N18-3014" rel="nofollow"&gt;Pieces of Eight: 8-bit Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Matt Post and David Vilar. 2018. &lt;a href="http://aclweb.org/anthology/N18-1119" rel="nofollow"&gt;Fast Lexically Constrained Decoding with Dynamic Beam Allocation for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=3504623917475500888&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Biao Zhang, Deyi Xiong, and Jinsong Su. 2018. &lt;a href="http://aclweb.org/anthology/P18-1166" rel="nofollow"&gt;Accelerating Neural Transformer via an Average Attention Network&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=16436039193082710776&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Rui Wang, Masao Utiyama, and Eiichiro Sumita. 2018. &lt;a href="http://aclweb.org/anthology/P18-2048" rel="nofollow"&gt;Dynamic Sentence Sampling for Efficient Training of Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=867223386840543463&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Myle Ott, Sergey Edunov, David Grangier, and Michael Auli. 2018. &lt;a href="http://aclweb.org/anthology/W18-6301" rel="nofollow"&gt;Scaling Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of the Third Conference on Machine Translation: Research Papers&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Joern Wuebker, Patrick Simianer, and John DeNero. 2018. &lt;a href="http://aclweb.org/anthology/D18-1104" rel="nofollow"&gt;Compact Personalized Models for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Wen Zhang, Liang Huang, Yang Feng, Lei Shen, and Qun Liu. 2018. &lt;a href="http://aclweb.org/anthology/D18-1460" rel="nofollow"&gt;Speeding Up Neural Machine Translation Decoding by Cube Pruning&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Zhisong Zhang, Rui Wang, Masao Utiyama, Eiichiro Sumita, and Hai Zhao. 2018. &lt;a href="http://aclweb.org/anthology/D18-1511" rel="nofollow"&gt;Exploring Recombination for Efficient Decoding of Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Nikolay Bogoychev, Kenneth Heafield, Alham Fikri Aji, and Marcin Junczys-Dowmunt. 2018. &lt;a href="http://aclweb.org/anthology/D18-1332" rel="nofollow"&gt;Accelerating Asynchronous Stochastic Gradient Descent for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=12306021941401324130&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Mitchell Stern, Noam Shazeer, and Jakob Uszkoreit. 2018. &lt;a href="https://papers.nips.cc/paper/8212-blockwise-parallel-decoding-for-deep-autoregressive-models.pdf" rel="nofollow"&gt;Blockwise Parallel Decoding for Deep Autoregressive Models&lt;/a&gt;. In &lt;em&gt;Proceedings of NeurIPS 2018&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-pre_training"&gt;&lt;a id="user-content-pre-training" class="anchor" aria-hidden="true" href="#pre-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-Training&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Bryan McCann, James Bradbury, Caiming Xiong, and Richard Socher. 2017. &lt;a href="http://papers.nips.cc/paper/7209-learned-in-translation-contextualized-word-vectors.pdf" rel="nofollow"&gt;Learned in Translation: Contextualized Word Vectors&lt;/a&gt;. In &lt;em&gt;Proceedings of NIPS 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=12356231721397988330&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 136)&lt;/li&gt;
&lt;li&gt;Ye Qi, Devendra Sachan, Matthieu Felix, Sarguna Padmanabhan, and Graham Neubig. 2018. &lt;a href="http://aclweb.org/anthology/N18-2084" rel="nofollow"&gt;When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=6166308028416584239&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 19)&lt;/li&gt;
&lt;li&gt;Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. &lt;a href="http://aclweb.org/anthology/N18-1202" rel="nofollow"&gt;Deep Contextualized Word Representations&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=14181983828043963745&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 519)&lt;/li&gt;
&lt;li&gt;Jeremy Howard and Sebastian Ruder. 2018. &lt;a href="http://aclweb.org/anthology/P18-1031" rel="nofollow"&gt;Universal Language Model Fine-tuning for Text Classification&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=2986760879834934707&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 114)&lt;/li&gt;
&lt;li&gt;Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel Bowman, Holger Schwenk, and Veselin Stoyanov. 2018. &lt;a href="https://www.aclweb.org/anthology/D18-1269" rel="nofollow"&gt;XNLI: Evaluating Cross-lingual Sentence Representations&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=15041461338388299895" rel="nofollow"&gt;Citation&lt;/a&gt;: 9)&lt;/li&gt;
&lt;li&gt;Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. &lt;a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" rel="nofollow"&gt;Improving Language Understanding by Generative Pre-Training&lt;/a&gt;. Technical Report, OpenAI. (&lt;a href="https://scholar.google.com.hk/scholar?cites=8939608408376234789&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 94)&lt;/li&gt;
&lt;li&gt;Guillaume Lample and Alexis Conneau. 2019. &lt;a href="https://arxiv.org/pdf/1901.07291" rel="nofollow"&gt;Cross-lingual Language Model Pretraining&lt;/a&gt;. &lt;em&gt;arXiv:1901.07291&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=11542237222100207278" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. &lt;a href="https://arxiv.org/pdf/1810.04805" rel="nofollow"&gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=3166990653379142174&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 292)&lt;/li&gt;
&lt;li&gt;Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. &lt;a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="nofollow"&gt;Language Models are Unsupervised Multitask Learners&lt;/a&gt;. Technical Report, OpenAI. (&lt;a href="https://scholar.google.com/scholar?cites=7713405291981945630&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 9)&lt;/li&gt;
&lt;li&gt;Sergey Edunov, Alexei Baevski, and Michael Auli. 2019. &lt;a href="https://arxiv.org/pdf/1903.09722.pdf" rel="nofollow"&gt;Pre-trained Language Model Representations for Language Generation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=46961033050134131&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2019. &lt;a href="https://arxiv.org/pdf/1905.02450" rel="nofollow"&gt;MASS: Masked Sequence to Sequence Pre-training for Language Generation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019. &lt;a href="https://arxiv.org/pdf/1906.08237" rel="nofollow"&gt;XLNet: Generalized Autoregressive Pretraining for Language Understanding&lt;/a&gt;. &lt;em&gt;arXiv:1906.08237&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-speech_translation_and_simultaneous_translation"&gt;&lt;a id="user-content-speech-translation-and-simultaneous-translation" class="anchor" aria-hidden="true" href="#speech-translation-and-simultaneous-translation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speech Translation and Simultaneous Translation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Matt Post, Gaurav Kumar, Adam Lopez, Damianos Karakos, Chris Callison-Burch and Sanjeev Khudanpur. 2013. &lt;a href="http://www.mt-archive.info/10/IWSLT-2013-Post.pdf" rel="nofollow"&gt;Improved Speech-to-Text Translation with the Fisher and Callhome Spanish–English Speech Translation Corpus&lt;/a&gt;. In &lt;em&gt;Proceedings of IWSLT 2013&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=11894485689812442585&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 24)&lt;/li&gt;
&lt;li&gt;Gaurav Kumar, Matt Post, Daniel Povey and Sanjeev Khudanpur. 2014. &lt;a href="https://ieeexplore.ieee.org/abstract/document/6854197" rel="nofollow"&gt;Some insights from translating conversational telephone speech&lt;/a&gt; In &lt;em&gt;Proceedings of ICASSP 2014&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=8525865656244874295&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 9)&lt;/li&gt;
&lt;li&gt;Long Duong, Antonios Anastasopoulos, David Chiang, Steven Bird, and Trevor Cohn. 2016. &lt;a href="http://www.aclweb.org/anthology/N16-1109" rel="nofollow"&gt;An Attentional Model for Speech Translation without Transcription&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=17801967122712636447&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 37)&lt;/li&gt;
&lt;li&gt;Antonios Anastasopoulos, David Chiang, and Long Duong. 2016. &lt;a href="https://aclweb.org/anthology/D16-1133" rel="nofollow"&gt;An Unsupervised Probability Model for Speech-to-translation Alignment of Low-resource Languages&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=323823800810193203&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 9)&lt;/li&gt;
&lt;li&gt;Ron J. Weiss, Jan Chorowski, Navdeep Jaitly, Yonghui Wu and Zhifeng Chen. 2017. &lt;a href="https://arxiv.org/abs/1703.08581" rel="nofollow"&gt;Sequence-to-sequence Models can Directly Translate Foreign Speech&lt;/a&gt;. In &lt;em&gt;Proceedings of Interspeech 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=10073093152246570315&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 41)&lt;/li&gt;
&lt;li&gt;Jiatao Gu, Graham Neubig, Kyunghyun Cho, and Victor O.K. Li. 2017. &lt;a href="http://aclweb.org/anthology/E17-1099" rel="nofollow"&gt;Learning to Translate in Real-time with Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=14299891671990230013&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 17)&lt;/li&gt;
&lt;li&gt;Sameer Bansal, Herman Kamper, Adam Lopez, and Sharon Goldwater. 2017. &lt;a href="http://aclweb.org/anthology/E17-2076" rel="nofollow"&gt;Towards Speech-to-text Translation without Speech Recognition&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=639319209334631051&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 13)&lt;/li&gt;
&lt;li&gt;Jiatao Gu, James Bradbury, Caiming Xiong, Victor O.K. Li, and Richard Socher. 2018. &lt;a href="https://arxiv.org/abs/1711.02281" rel="nofollow"&gt;Non-Autoregressive Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=3482831974828539059&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 23)&lt;/li&gt;
&lt;li&gt;Antonios Anastasopoulos and David Chiang. 2018. &lt;a href="https://arxiv.org/pdf/1802.06655.pdf" rel="nofollow"&gt;Tied Multitask Learning for Neural Speech Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=5810351802252447673&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 10)&lt;/li&gt;
&lt;li&gt;Fahim Dalvi, Nadir Durrani, Hassan Sajjad, and Stephan Vogel. 2018. &lt;a href="http://aclweb.org/anthology/N18-2079" rel="nofollow"&gt;Incremental Decoding and Training Methods for Simultaneous Translation in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Craig Stewart, Nikolai Vogler, Junjie Hu, Jordan Boyd-Graber, and Graham Neubig. 2018. &lt;a href="http://aclweb.org/anthology/P18-2105" rel="nofollow"&gt;Automatic Estimation of Simultaneous Interpreter Performance&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=5687670489913511293&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Florian Dessloch, Thanh-Le Ha, Markus Müller, Jan Niehues, Thai Son Nguyen, Ngoc-Quan Pham, Elizabeth Salesky, Matthias Sperber, Sebastian Stüker, Thomas Zenkel, and Alexander Waibel. 2018. &lt;a href="http://aclweb.org/anthology/C18-2020" rel="nofollow"&gt;KIT Lecture Translator: Multilingual Speech Translation with One-Shot Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Chunqi Wang, Ji Zhang, and Haiqing Chen. 2018. &lt;a href="http://aclweb.org/anthology/D18-1044" rel="nofollow"&gt;Semi-Autoregressive Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jindřich Libovický and Jindřich Helcl. 2018. &lt;a href="http://aclweb.org/anthology/D18-1336" rel="nofollow"&gt;End-to-End Non-Autoregressive Neural Machine Translation with Connectionist Temporal Classification&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Ashkan Alinejad, Maryam Siahbani, and Anoop Sarkar. 2018. &lt;a href="http://aclweb.org/anthology/D18-1337" rel="nofollow"&gt;Prediction Improves Simultaneous Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Mitchell Stern, William Chan, Jamie Kiros, Jakob Uszkoreit. 2019. &lt;a href="http://proceedings.mlr.press/v97/stern19a/stern19a.pdf" rel="nofollow"&gt;Insertion Transformer: Flexible Sequence Generation via Insertion Operations&lt;/a&gt;. In Proceedings of ICML 2019.&lt;/li&gt;
&lt;li&gt;Sameer Bansal, Herman Kamper, Karen Livescu, Adam Lopez, and Sharon Goldwater. 2019. &lt;a href="https://arxiv.org/pdf/1809.01431.pdf" rel="nofollow"&gt;Pre-training on high-resource speech recognition improves low-resource speech-to-text translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Nikolai Vogler, Craig Stewart, and Graham Neubig. 2019. &lt;a href="https://arxiv.org/pdf/1904.00930.pdf" rel="nofollow"&gt;Lost in Interpretation: Predicting Untranslated Terminology in Simultaneous Interpretation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Elizabeth Salesky, Matthias Sperber, and Alex Waibel. 2019. &lt;a href="https://arxiv.org/pdf/1906.00556" rel="nofollow"&gt;Fluent Translations from Disfluent Speech in End-to-End Speech Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Naveen Arivazhagan, Colin Cherry, Wolfgang Macherey, Chung-Cheng Chiu, Semih Yavuz, Ruoming Pang, Wei Li, and Colin Raffel. 2019. &lt;a href="https://arxiv.org/pdf/1906.05218" rel="nofollow"&gt;Monotonic Infinite Lookback Attention for Simultaneous Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Matthias Sperber, Graham Neubig, Ngoc-Quan Pham, and Alex Waibel. 2019. &lt;a href="https://arxiv.org/pdf/1906.01617" rel="nofollow"&gt;Self-Attentional Models for Lattice Inputs&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Pei Zhang, Boxing Chen, Niyu Ge, and Kai Fan. 2019. &lt;a href="https://arxiv.org/pdf/1906.05551" rel="nofollow"&gt;Lattice Transformer for Speech Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Chenze Shao, Yang Feng, Jinchao Zhang, Fandong Meng, Xilin Chen, and Jie Zhou. 2019. &lt;a href="https://arxiv.org/pdf/1906.09444" rel="nofollow"&gt;Retrieving Sequential Information for Non-Autoregressive Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Bingzhen Wei, Mingxuan Wang, Hao Zhou, Junyang Lin, and Xu Sun. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1125" rel="nofollow"&gt;Imitation Learning for Non-Autoregressive Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Naveen Arivazhagan, Colin Cherry, Wolfgang Macherey, Chung-Cheng Chiu, Semih Yavuz, Ruoming Pang, Wei Li, and Colin Raffel. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1126" rel="nofollow"&gt;Monotonic Infinite Lookback Attention for Simultaneous Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Elizabeth Salesky, Matthias Sperber, and Alan W Black. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1179" rel="nofollow"&gt;Exploring Phoneme-Level Speech Representations for End-to-End Speech Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Mingbo Ma, Liang Huang, Hao Xiong, Renjie Zheng, Kaibo Liu, Baigong Zheng, Chuanqiang Zhang, Zhongjun He, Hairong Liu, Xing Li, Hua Wu, and Haifeng Wang.  2019. &lt;a href="https://www.aclweb.org/anthology/P19-1289" rel="nofollow"&gt;STACL: Simultaneous Translation with Implicit Anticipation and Controllable Latency using Prefix-to-Prefix Framework&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Baigong Zheng, Renjie Zheng, Mingbo Ma, and Liang Huang. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1582" rel="nofollow"&gt;Simultaneous Translation with Flexible Policy via Restricted Imitation Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Matthias Sperber, Graham Neubig, Jan Niehues, Alex Waibel. 2019. &lt;a href="https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00270" rel="nofollow"&gt;Attention-Passing Models for Robust and Data-Efficient End-to-End Speech Translation&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Baigong Zheng, Renjie Zheng, Mingbo Ma, and Liang Huang. 2019. &lt;a href="https://arxiv.org/pdf/1909.01559" rel="nofollow"&gt;Simpler and Faster Learning of Adaptive Policies for Simultaneous Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Zhuohan Li, Zi Lin, Di He, Fei Tian, Tao Qin, Liwei Wang, and Tie-Yan Liu. 2019. &lt;a href="https://arxiv.org/pdf/1909.06708" rel="nofollow"&gt;Hint-Based Training for Non-Autoregressive Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Renjie Zheng, Mingbo Ma, Baigong Zheng, and Liang Huang. 2019. &lt;a href="https://arxiv.org/pdf/1909.05421" rel="nofollow"&gt;Speculative Beam Search for Simultaneous Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-multi_modality"&gt;&lt;a id="user-content-multi-modality" class="anchor" aria-hidden="true" href="#multi-modality"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Multi-modality&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Julian Hitschler, Shigehiko Schamoni, Stefan Riezler. 2016. &lt;a href="http://aclweb.org/anthology/P16-1227" rel="nofollow"&gt;Multimodal Pivots for Image Caption Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?oi=bibs&amp;amp;hl=en&amp;amp;cites=2998317485328832141" rel="nofollow"&gt;Citation&lt;/a&gt;: 34)&lt;/li&gt;
&lt;li&gt;Lucia Specia, Stella Frank, Khalil Sima'an, and Desmond Elliott. 2016. &lt;a href="http://aclweb.org/anthology/W16-2346" rel="nofollow"&gt;A Shared Task on Multimodal Machine Translation and Crosslingual Image Description&lt;/a&gt;. In &lt;em&gt;Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?hl=en&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;cites=10227072007263391757&amp;amp;scipsc=" rel="nofollow"&gt;Citation&lt;/a&gt;: 47)&lt;/li&gt;
&lt;li&gt;Sergio Rodríguez Guasch, Marta R. Costa-jussà. 2016. &lt;a href="http://aclweb.org/anthology/W16-2362" rel="nofollow"&gt;WMT 2016 Multimodal Translation System Description based on Bidirectional Recurrent Neural Networks with Double-Embeddings&lt;/a&gt;. In &lt;em&gt;Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=4203794059992068345&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Po-Yao Huang, Frederick Liu, Sz-Rung Shiang, Jean Oh, and Chris Dyer. 2016. &lt;a href="https://www.aclweb.org/anthology/W16-2360" rel="nofollow"&gt;Attention-based Multimodal Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=3098391471855879500&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 34)&lt;/li&gt;
&lt;li&gt;Iacer Calixto, Desmond Elliott, and Stella Frank. 2016. &lt;a href="http://aclweb.org/anthology/W16-2359" rel="nofollow"&gt;DCU-UvA Multimodal MT &lt;strong&gt;System report&lt;/strong&gt;&lt;/a&gt;. In &lt;em&gt;Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13635685318707561524&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 12)&lt;/li&gt;
&lt;li&gt;Kashif Shah, Josiah Wang, and Lucia Specia. 2016. &lt;a href="https://aclweb.org/anthology/W16-2363" rel="nofollow"&gt;SHEF-Multimodal: Grounding Machine Translation on Images&lt;/a&gt;. In &lt;em&gt;Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=11223367231679829742&amp;amp;as_sdt=5,39&amp;amp;sciodt=0,39&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 17)&lt;/li&gt;
&lt;li&gt;Desmond Elliott, Stella Frank, Loïc Barrault, Fethi Bougares, and Lucia Specia. 2017. &lt;a href="http://aclweb.org/anthology/W17-4718" rel="nofollow"&gt;Findings of the Second Shared Task on Multimodal Machine Translation and Multilingual Image Description&lt;/a&gt;. In &lt;em&gt;Proceedings of the Second Conference on Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=268734032292286129&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 24)&lt;/li&gt;
&lt;li&gt;Iacer Calixto, Qun Liu, and Nick Campbell. 2017. &lt;a href="http://aclweb.org/anthology/P17-1175" rel="nofollow"&gt;Doubly-Attentive Decoder for Multi-modal Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9882133753270023054&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 31)&lt;/li&gt;
&lt;li&gt;Jean-Benoit Delbrouck and Stéphane Dupont. 2017. &lt;a href="http://aclweb.org/anthology/D17-1095" rel="nofollow"&gt;An empirical study on the effectiveness of images in Multimodal Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=4462543203996753904&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Iacer Calixto and Qun Liu. 2017. &lt;a href="http://aclweb.org/anthology/D17-1105" rel="nofollow"&gt;Incorporating Global Visual Features into Attention-based Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=6076628072948213440&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 14)&lt;/li&gt;
&lt;li&gt;Jason Lee, Kyunghyun Cho, Jason Weston, and Douwe Kiela. 2018. &lt;a href="https://openreview.net/pdf?id=H1vEXaxA-" rel="nofollow"&gt;Emergent Translation in Multi-Agent Communication&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=16875774594076963034&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 8)&lt;/li&gt;
&lt;li&gt;Yun Chen, Yang Liu, and Victor O. K. Li. 2018. &lt;a href="https://arxiv.org/pdf/1802.03116" rel="nofollow"&gt;Zero-Resource Neural Machine Translation with Multi-Agent Communication Game&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13902575159717479954&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Loïc Barrault, Fethi Bougares, Lucia Specia, Chiraag Lala, Desmond Elliott, and Stella Frank. 2018. &lt;a href="http://aclweb.org/anthology/W18-6402" rel="nofollow"&gt;Findings of the Third Shared Task on Multimodal Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of the Third Conference on Machine Translation: Shared Task Papers&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=1407951263246368352&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;John Hewitt, Daphne Ippolito, Brendan Callahan, Reno Kriz, Derry Tanti Wijaya, and Chris Callison-Burch. 2018. &lt;a href="http://aclweb.org/anthology/P18-1239" rel="nofollow"&gt;Learning Translations via Images with a Massively Multilingual Image Dataset&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=8128328221941110465&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Mingyang Zhou, Runxiang Cheng, Yong Jae Lee, and Zhou Yu. 2018. &lt;a href="http://aclweb.org/anthology/D18-1400" rel="nofollow"&gt;A Visual Attention Grounding Neural Model for Multimodal Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Desmond Elliott. 2018. &lt;a href="http://aclweb.org/anthology/D18-1329" rel="nofollow"&gt;Adversarial Evaluation of Multimodal Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Ozan Caglayan, Pranava Madhyastha, Lucia Specia, and Loïc Barrault. 2019. &lt;a href="https://arxiv.org/pdf/1903.08678.pdf" rel="nofollow"&gt;Probing the Need for Visual Context in Multimodal Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Iacer Calixto, Miguel Rios, and Wilker Aziz. 2019. &lt;a href="https://arxiv.org/pdf/1811.00357" rel="nofollow"&gt;Latent Variable Model for Multi-modal Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Julia Ive, Pranava Madhyastha, and Lucia Specia. 2019. &lt;a href="https://arxiv.org/pdf/1906.07701" rel="nofollow"&gt;Distilling Translations with Visual Awareness&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-ensemble_reranking"&gt;&lt;a id="user-content-ensemble-and-reranking" class="anchor" aria-hidden="true" href="#ensemble-and-reranking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ensemble and Reranking&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ekaterina Garmash, and Christof Monz. 2016. &lt;a href="http://aclweb.org/anthology/C16-1133" rel="nofollow"&gt;Ensemble Learning for Multi-Source Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=10720572689338720536&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 18)&lt;/li&gt;
&lt;li&gt;Long Zhou, Wenpeng Hu, Jiajun Zhang, and Chengqing Zong. 2017. &lt;a href="http://aclweb.org/anthology/P17-2060" rel="nofollow"&gt;Neural System Combination for Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=2547807449547851378&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 21)&lt;/li&gt;
&lt;li&gt;Jiaji Huang, Yi Li, Wei Ping, and Liang Huang. 2018. &lt;a href="http://aclweb.org/anthology/D18-1150" rel="nofollow"&gt;Large Margin Neural Language Model&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Tianxiao Shen, Myle Ott, Michael Auli, and Marc’Aurelio Ranzato. 2019. &lt;a href="http://proceedings.mlr.press/v97/shen19c/shen19c.pdf" rel="nofollow"&gt;Mixture Models for Diverse Machine Translation: Tricks of the Trade&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-domain_adaptation"&gt;&lt;a id="user-content-domain-adaptation" class="anchor" aria-hidden="true" href="#domain-adaptation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Domain Adaptation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Chenhui Chu, Raj Dabre, and Sadao Kurohashi. 2017. &lt;a href="http://aclweb.org/anthology/P17-2061" rel="nofollow"&gt;An Empirical Comparison of Domain Adaptation Methods for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=11154619650853156425&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 40)&lt;/li&gt;
&lt;li&gt;Rui Wang, Andrew Finch, Masao Utiyama, and Eiichiro Sumita. 2017. &lt;a href="http://aclweb.org/anthology/P17-2089" rel="nofollow"&gt;Sentence Embedding for Neural Machine Translation Domain Adaptation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=12026801731726213856&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 8)&lt;/li&gt;
&lt;li&gt;Boxing Chen, Colin Cherry, George Foster, and Samuel Larkin. 2017. &lt;a href="http://aclweb.org/anthology/W17-3205" rel="nofollow"&gt;Cost Weighting for Neural Machine Translation Domain Adaptation&lt;/a&gt;. In &lt;em&gt;Proceedings of the First Workshop on Neural Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=11511062396100603245&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 10)&lt;/li&gt;
&lt;li&gt;Reid Pryzant and Denny Britz. 2017. &lt;a href="http://aclweb.org/anthology/W17-4712" rel="nofollow"&gt;Effective Domain Mixing for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of the Second Conference on Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=5830143292179945460&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Mara Chinea-Rios, Álvaro Peris and Francisco Casacuberta. 2017. &lt;a href="http://aclweb.org/anthology/W17-4714" rel="nofollow"&gt;Adapting Neural Machine Translation with Parallel Synthetic Data&lt;/a&gt;. In &lt;em&gt;Proceedings of the Second Conference on Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=14166012599677352590&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Rui Wang, Masao Utiyama, Lemao Liu, Kehai Chen, and Eiichiro Sumita. 2017. &lt;a href="http://aclweb.org/anthology/D17-1155" rel="nofollow"&gt;Instance Weighting for Neural Machine Translation Domain Adaptation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=11790197905041828318&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 13)&lt;/li&gt;
&lt;li&gt;Antonio Valerio Miceli Barone, Barry Haddow, Ulrich Germann, and Rico Sennrich. 2017. &lt;a href="http://aclweb.org/anthology/D17-1156" rel="nofollow"&gt;Regularization techniques for fine-tuning in neural machine translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=10429379661740278678&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;David Vilar. 2018. &lt;a href="http://aclweb.org/anthology/N18-2080" rel="nofollow"&gt;Learning Hidden Unit Contribution for Adapting Neural Machine Translation Models&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=5262017870970882749&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Paul Michel and Graham Neubig. 2018. &lt;a href="http://aclweb.org/anthology/P18-2050" rel="nofollow"&gt;Extreme Adaptation for Personalized Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings for ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=16717798879574507487&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 6)&lt;/li&gt;
&lt;li&gt;Shiqi Zhang and Deyi Xiong. 2018. &lt;a href="http://aclweb.org/anthology/C18-1269" rel="nofollow"&gt;Sentence Weighting for Neural Machine Translation Domain Adaptation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Chenhui Chu and Rui Wang. 2018. &lt;a href="http://aclweb.org/anthology/C18-1111" rel="nofollow"&gt;A Survey of Domain Adaptation for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=12774117070156464640&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 7)&lt;/li&gt;
&lt;li&gt;Jiali Zeng, Jinsong Su, Huating Wen, Yang Liu, Jun Xie, Yongjing Yin, and Jianqiang Zhao. 2018. &lt;a href="http://aclweb.org/anthology/D18-1041" rel="nofollow"&gt;Multi-Domain Neural Machine Translation with Word-Level Domain Context Discrimination&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Graham Neubig and Junjie Hu. 2018. &lt;a href="http://aclweb.org/anthology/D18-1103" rel="nofollow"&gt;Rapid Adaptation of Neural Machine Translation to New Languages&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=18133973017615911986&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4)&lt;/li&gt;
&lt;li&gt;Shuhao Gu, Yang Feng, and Qun Liu. 2019. &lt;a href="https://arxiv.org/pdf/1904.03879.pdf" rel="nofollow"&gt;Improving Domain Adaptation Translation with Domain Invariant and Specific Information&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Ankur Bapna and Orhan Firat. 2019. &lt;a href="https://arxiv.org/pdf/1903.00058.pdf" rel="nofollow"&gt;Non-Parametric Adaptation for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Junjie Hu, Mengzhou Xia, Graham Neubig, and Jaime Carbonell. 2019. &lt;a href="https://arxiv.org/pdf/1906.00376" rel="nofollow"&gt;Domain Adaptation of Neural Machine Translation by Lexicon Induction&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Danielle Saunders, Felix Stahlberg, Adria de Gispert, and Bill Byrne. 2019. &lt;a href="https://arxiv.org/pdf/1906.00408" rel="nofollow"&gt;Domain Adaptive Inference for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Zi-Yi Dou, Junjie Hu, Antonios Anastasopoulos, and Graham Neubig. 2019. &lt;a href="https://arxiv.org/pdf/1908.10430.pdf" rel="nofollow"&gt;Unsupervised Domain Adaptation for Neural Machine Translation with Domain-Aware Feature Embeddings&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Ankur Bapna, Naveen Arivazhagan, and Orhan Firat. 2019. &lt;a href="https://arxiv.org/pdf/1909.08478" rel="nofollow"&gt;Simple, Scalable Adaptation for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jiali Zeng, Yang Liu, jinsong su, yubing Ge, Yaojie Lu, Yongjing Yin and jiebo luo. 2019. &lt;a href="https://www.aclweb.org/anthology/D19-1078.pdf" rel="nofollow"&gt;Iterative Dual Domain Adaptation for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-quality_estimation"&gt;&lt;a id="user-content-quality-estimation" class="anchor" aria-hidden="true" href="#quality-estimation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quality Estimation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Julia Kreutzer, Shigehiko Schamoni, Stefan Riezler. 2015. &lt;a href="http://www.aclweb.org/anthology/W15-3037" rel="nofollow"&gt;Quality Estimation from Scratch (QUETCH): Deep Learning for Word-Level Translation Quality Estimation&lt;/a&gt;. In &lt;em&gt;Proceedings of the Tenth Workshop on Statistical Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=2308754825624963103&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 24)&lt;/li&gt;
&lt;li&gt;Hyun Kim and Jong-Hyeok Lee. 2016. &lt;a href="http://aclweb.org/anthology/N16-1059" rel="nofollow"&gt;A Recurrent Neural Networks Approach for Estimating the Quality of Machine Translation Output&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=830241254846777269&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Hyun Kim and Jong-Hyeok Lee, Seung-Hoon Na. 2017. &lt;a href="http://aclweb.org/anthology/W17-4763" rel="nofollow"&gt;Predictor-Estimator using Multilevel Task Learning with Stack Propagation for Neural Quality Estimation&lt;/a&gt;. In &lt;em&gt;Proceedings of WMT 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=14077676925816230812&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 10)&lt;/li&gt;
&lt;li&gt;Osman Baskaya, Eray Yildiz, Doruk Tunaoglu, Mustafa Tolga Eren, and A. Seza Doğruöz. 2017. &lt;a href="http://aclweb.org/anthology/E17-1020" rel="nofollow"&gt;Integrating Meaning into Quality Evaluation of Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yvette Graham, Qingsong Ma, Timothy Baldwin, Qun Liu, Carla Parra, and Carolina Scarton. 2017. &lt;a href="http://aclweb.org/anthology/E17-2057" rel="nofollow"&gt;Improving Evaluation of Document-level Machine Translation Quality Estimation&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13409644842476040211&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Rico Sennrich. 2017. &lt;a href="http://aclweb.org/anthology/E17-2060" rel="nofollow"&gt;How Grammatical is Character-level Neural Machine Translation? Assessing MT Quality with Contrastive Translation Pairs&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=14294900718072928557&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 25)&lt;/li&gt;
&lt;li&gt;Pierre Isabelle, Colin Cherry, and George Foster. 2017. &lt;a href="http://aclweb.org/anthology/D17-1263" rel="nofollow"&gt;A Challenge Set Approach to Evaluating Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=10744403566307443052&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 26)&lt;/li&gt;
&lt;li&gt;André F.T. Martins, Marcin Junczys-Dowmunt, Fabio N. Kepler, Ramón Astudillo, Chris Hokamp, and Roman Grundkiewicz. 2017. &lt;a href="http://aclweb.org/anthology/Q17-1015" rel="nofollow"&gt;Pushing the Limits of Translation Quality Estimation&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=17497507120611954135&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 13)&lt;/li&gt;
&lt;li&gt;Maoxi Li, Qingyu Xiang, Zhiming Chen, and Mingwen Wang. 2018. &lt;a href="https://www.jstage.jst.go.jp/article/transinf/E101.D/9/E101.D_2018EDL8019/_article/-char/en" rel="nofollow"&gt;A Unified Neural Network for Quality Estimation of Machine Translation&lt;/a&gt;. &lt;em&gt;IEICE Transactions on Information and Systems&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=17497507120611954135&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 13)&lt;/li&gt;
&lt;li&gt;Lucia Specia, Frédéric Blain, Varvara Logacheva, Ramón F. Astudillo, and André Martins. 2018. &lt;a href="http://aclweb.org/anthology/W18-6451" rel="nofollow"&gt;Findings of the WMT 2018 Shared Task on Quality Estimation&lt;/a&gt;. In &lt;em&gt;Proceedings of the Third Conference on Machine Translation&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=11225823265419143916&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Craig Stewart, Nikolai Vogler, Junjie Hu, Jordan Boyd-Graber, and Graham Neubig. 2018. &lt;a href="http://aclweb.org/anthology/P18-2105" rel="nofollow"&gt;Automatic Estimation of Simultaneous Interpreter Performance&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?hl=en&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;cites=5687670489913511293&amp;amp;scipsc=" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Holger Schwenk. 2018. &lt;a href="http://aclweb.org/anthology/P18-2037" rel="nofollow"&gt;Filtering and Mining Parallel Data in a Joint Multilingual Space&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=7363119514762721542&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4)&lt;/li&gt;
&lt;li&gt;Julia Ive, Frédéric Blain, and Lucia Specia. 2018. &lt;a href="http://aclweb.org/anthology/C18-1266" rel="nofollow"&gt;deepQuest: A Framework for Neural-based Quality Estimation&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=4501237247493636014&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Kai Fan, Jiayi Wang, Bo Li, Fengming Zhou, Boxing Chen, and Luo Si. 2019. &lt;a href="https://arxiv.org/pdf/1807.09433" rel="nofollow"&gt;"Bilingual Expert" Can Find Translation Errors&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-human_centered"&gt;&lt;a id="user-content-human-centered-nmt" class="anchor" aria-hidden="true" href="#human-centered-nmt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Human-centered NMT&lt;/h3&gt;
&lt;h4 id="user-content-interactive_nmt"&gt;&lt;a id="user-content-interactive-nmt" class="anchor" aria-hidden="true" href="#interactive-nmt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive NMT&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Joern Wuebker, Spence Green, John DeNero, Saša Hasan and Minh-Thang Luong. 2016. &lt;a href="http://aclweb.org/anthology/P16-1007" rel="nofollow"&gt;Models and Inference for Prefix-Constrained Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=6217828709297735294&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=es" rel="nofollow"&gt;Citation&lt;/a&gt;: 14)&lt;/li&gt;
&lt;li&gt;Rebecca Knowles and Philipp Koehn. 2017. &lt;a href="https://www.cs.jhu.edu/~phi/publications/neural-interactive-translation.pdf" rel="nofollow"&gt;Neural Interactive Translation Prediction&lt;/a&gt;. In &lt;em&gt;Proceedings of AMTA 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.es/scholar?cites=16855799109441363843&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=es" rel="nofollow"&gt;Citation&lt;/a&gt;: 24)&lt;/li&gt;
&lt;li&gt;Álvaro Peris, Miguel Domingo and Francisco Casacuberta. 2017. &lt;a href="https://www.researchgate.net/publication/312275926" rel="nofollow"&gt;Interactive neural machine translation&lt;/a&gt;. In &lt;em&gt;Computer Speech and Language&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?oi=bibs&amp;amp;hl=es&amp;amp;cites=2848232799976037224&amp;amp;as_sdt=5" rel="nofollow"&gt;Citation&lt;/a&gt;: 21)&lt;/li&gt;
&lt;li&gt;Khanh Nguyen, Hal Daumé III, and Jordan Boyd-Graber. 2017. &lt;a href="http://aclweb.org/anthology/D17-1153" rel="nofollow"&gt;Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=15247143946986909844&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Álvaro Peris and Francisco Casacuberta. 2018. &lt;a href="http://aclweb.org/anthology/K18-1015" rel="nofollow"&gt;Active Learning for Interactive Neural Machine Translation of Data Streams&lt;/a&gt;. In &lt;em&gt;Proceedings of CoNLL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?oi=bibs&amp;amp;hl=es&amp;amp;cites=14996862010471139834&amp;amp;as_sdt=5" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Tsz Kin Lam, Julia Kreutzer, and Stefan Riezler. 2018. &lt;a href="https://arxiv.org/pdf/1805.01553" rel="nofollow"&gt;A Reinforcement Learning Approach to Interactive-Predictive Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EAMT 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Julia Kreutzer, Shahram Khadivi, Evgeny Matusov, Stefan Riezler. 2018. &lt;a href="http://aclweb.org/anthology/N18-3012" rel="nofollow"&gt;Can Neural Machine Translation be Improved with User Feedback?&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?oi=bibs&amp;amp;hl=en&amp;amp;cites=5878376279798739633" rel="nofollow"&gt;Citation&lt;/a&gt;: 3).&lt;/li&gt;
&lt;li&gt;Pavel Petrushkov, Shahram Khadivi and Evgeny Matusov. 2018. &lt;a href="http://aclweb.org/anthology/P18-2052" rel="nofollow"&gt;Learning from Chunk-based Feedback in Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=11022197412542590938&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Julia Kreutzer, Joshua Uyheng, and Stefan Riezler. 2018. &lt;a href="http://aclweb.org/anthology/P18-1165" rel="nofollow"&gt;Reliability and Learnability of Human Bandit Feedback for Sequence-to-Sequence Reinforcement Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=13544384067638756323&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Álvaro Peris and Francisco Casacuberta. 2019. &lt;a href="https://arxiv.org/pdf/1905.08181" rel="nofollow"&gt;A Neural, Interactive-predictive System for Multimodal Sequence to Sequence Tasks&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Miguel Domingo, Mercedes García-Martínez, Amando Estela, Laurent Bié, Alexandre Helle, Álvaro Peris, Francisco Casacuberta, and Manuerl Herranz. 2019. &lt;a href="https://arxiv.org/pdf/1906.09000" rel="nofollow"&gt;Demonstration of a Neural Machine Translation System with Online Learning for Translators&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Julia Kreutzer and Stefan Riezler. 2019. &lt;a href="https://arxiv.org/pdf/1907.05190.pdf" rel="nofollow"&gt;Self-Regulated Interactive Sequence-to-Sequence Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="user-content-ape"&gt;&lt;a id="user-content-automatic-post-editing" class="anchor" aria-hidden="true" href="#automatic-post-editing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Automatic Post-Editing&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Santanu Pal, Sudip Kumar Naskar, Mihaela Vela, and Josef van Genabith. 2016. &lt;a href="http://aclweb.org/anthology/P16-2046" rel="nofollow"&gt;A neural network based approach to automatic post-editing&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=12283909725778804406&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 14)&lt;/li&gt;
&lt;li&gt;Marcin Junczys-Dowmunt and Roman Grundkiewicz. 2016. &lt;a href="http://aclweb.org/anthology/W16-2378" rel="nofollow"&gt;Log-linear Combinations of Monolingual and Bilingual Neural Machine Translation Models for Automatic Post-Editing&lt;/a&gt;. In &lt;em&gt;Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=8379495332607620604&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 27)&lt;/li&gt;
&lt;li&gt;Santanu Pal, Sudip Kumar Naskar, Mihaela Vela, Qun Liu, and Josef van Genabith. 2017. &lt;a href="http://aclweb.org/anthology/E17-2056" rel="nofollow"&gt;Neural Automatic Post-Editing Using Prior Alignment and Reranking&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=17137949386428082191&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Rajen Chatterjee, Gebremedhen Gebremelak, Matteo Negri, and Marco Turchi. 2017. &lt;a href="http://aclweb.org/anthology/E17-1050" rel="nofollow"&gt;Online Automatic Post-editing for MT in a Multi-Domain Translation Environment&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=16624698279716802422&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Marcin Junczys-Dowmunt, Roman Grundkiewicz. 2017. &lt;a href="http://aclweb.org/anthology/I17-1013" rel="nofollow"&gt;An Exploration of Neural Sequence-to-Sequence Architectures for Automatic Post-Editing&lt;/a&gt;. In &lt;em&gt;Proceedings of IJCNLP 2017&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;David Grangier and Michael Auli. 2018. &lt;a href="http://aclweb.org/anthology/N18-1025" rel="nofollow"&gt;QuickEdit: Editing Text &amp;amp; Translations by Crossing Words Out&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9500777791162222168&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Thuy-Trang Vu and Gholamreza Haffari. 2018. &lt;a href="http://aclweb.org/anthology/D18-1341" rel="nofollow"&gt;Automatic Post-Editing of Machine Translation: A Neural Programmer-Interpreter Approach&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Marcin Junczys-Dowmunt, Roman Grundkiewicz. 2018. &lt;a href="https://arxiv.org/pdf/1809.00188.pdf" rel="nofollow"&gt;MS-UEdin Submission to the WMT2018 APE Shared Task: Dual-Source Transformer for Automatic Post-Editing&lt;/a&gt;. In &lt;em&gt;Proceedings of WMT 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Gonçalo M. Correia and André F. T. Martins. 2019. &lt;a href="https://arxiv.org/pdf/1906.06253" rel="nofollow"&gt;A Simple and Effective Approach to Automatic Post-Editing with Transfer Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xuancheng Huang, Yang Liu, Huanbo Luan, Jingfang Xu, Maosong Sun. 2019. &lt;a href="https://www.aclweb.org/anthology/D19-1634.pdf" rel="nofollow"&gt;Learning to Copy for Automatic Post-Editing&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-poetry_translation"&gt;&lt;a id="user-content-poetry-translation" class="anchor" aria-hidden="true" href="#poetry-translation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Poetry Translation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Marjan Ghazvininejad, Yejin Choi, and Kevin Knight. 2018. &lt;a href="http://aclweb.org/anthology/N18-2011" rel="nofollow"&gt;Neural Poetry Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=4597758342230970450&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-eco_friendly"&gt;&lt;a id="user-content-eco-friendly" class="anchor" aria-hidden="true" href="#eco-friendly"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Eco-friendly&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Emma Strubell, Ananya Ganesh, and Andrew McCallum. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1355" rel="nofollow"&gt;Energy and Policy Considerations for Deep Learning in NLP&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="user-content-word_translation"&gt;&lt;a id="user-content-word-translation" class="anchor" aria-hidden="true" href="#word-translation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Word Translation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tomas Mikolov, Quoc V. Le, and Ilya Sutskever. 2013. &lt;a href="https://arxiv.org/pdf/1309.4168.pdf" rel="nofollow"&gt;Exploiting Similarities among Languages for Machine Translation&lt;/a&gt;. &lt;em&gt;arxiv:1309.4168&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=18389495985810631724&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 581)&lt;/li&gt;
&lt;li&gt;Chao Xing, Dong Wang, Chao Liu, and Yiye Lin. 2015. &lt;a href="http://aclweb.org/anthology/N15-1104" rel="nofollow"&gt;Normalized Word Embedding and Orthogonal Transform for Bilingual Word Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2015&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?hl=zh-CN&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;cites=4009320309746318198&amp;amp;scipsc=" rel="nofollow"&gt;Citation&lt;/a&gt;: 89)&lt;/li&gt;
&lt;li&gt;Georgiana Dinu, Angeliki Lazaridou, and Marco Baroni. 2015. &lt;a href="https://arxiv.org/pdf/1412.6568.pdf" rel="nofollow"&gt;Improving Zero-shot Learning by Mitigating the Hubness Problem&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2015&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=4810137765860435505&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 110)&lt;/li&gt;
&lt;li&gt;Meng Zhang, Yang Liu, Huanbo Luan, Maosong Sun, Tatsuya Izuha, and Jie Hao. 2016. &lt;a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12227/12035" rel="nofollow"&gt;Building Earth Mover's Distance on Bilingual Word Embeddings for Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=10787724557107708547&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Meng Zhang, Yang Liu, Huanbo Luan, Yiqun Liu, and Maosong Sun. 2016. &lt;a href="http://aclweb.org/anthology/C16-1300" rel="nofollow"&gt;Inducing Bilingual Lexica From Non-Parallel Data With Earth Mover's Distance Regularization&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=7442971885961632428&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4)&lt;/li&gt;
&lt;li&gt;Ivan Vulić and Anna Korhonen. &lt;a href="http://www.aclweb.org/anthology/P16-1024" rel="nofollow"&gt;On the Role of Seed Lexicons in Learning Bilingual Word Embeddings&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9848186834020452809&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 39)&lt;/li&gt;
&lt;li&gt;Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2016. &lt;a href="http://www.aclweb.org/anthology/D16-1250" rel="nofollow"&gt;Learning principled bilingual mappings of word embeddings while preserving monolingual invariance&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2016&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=5308709105842309671&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 73)&lt;/li&gt;
&lt;li&gt;Meng Zhang, Haoruo Peng, Yang Liu, Huanbo Luan, and Maosong Sun. &lt;a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14682/14264" rel="nofollow"&gt;Bilingual Lexicon Induction from Non-Parallel Data with Minimal Supervision&lt;/a&gt;. In &lt;em&gt;Proceedings of AAAI 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=6351287463037630922&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Ann Irvine and Chris Callison-Burch. 2017. &lt;a href="http://aclweb.org/anthology/J17-2001" rel="nofollow"&gt;A Comprehensive Analysis of Bilingual Lexicon Induction&lt;/a&gt;. &lt;em&gt;Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=9284068492500255032&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 12)&lt;/li&gt;
&lt;li&gt;Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2017. &lt;a href="http://aclweb.org/anthology/P17-1042" rel="nofollow"&gt;Learning Bilingual Word Embeddings with (Almost) No Bilingual Data&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com.hk/scholar?cites=17614535864871662614&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 62)&lt;/li&gt;
&lt;li&gt;Meng Zhang, Yang Liu, Huanbo Luan, and Maosong Sun. 2017. &lt;a href="http://aclweb.org/anthology/P17-1179" rel="nofollow"&gt;Adversarial Training for Unsupervised Bilingual Lexicon Induction&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=1858752500147406961" rel="nofollow"&gt;Citation&lt;/a&gt;: 41)&lt;/li&gt;
&lt;li&gt;Geert Heyman, Ivan Vulić, and Marie-Francine Moens. 2017. &lt;a href="http://aclweb.org/anthology/E17-1102" rel="nofollow"&gt;Bilingual Lexicon Induction by Learning to Combine Word-Level and Character-Level Representations&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=585284476576929954&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 9)&lt;/li&gt;
&lt;li&gt;Bradley Hauer, Garrett Nicolai, and Grzegorz Kondrak. 2017. &lt;a href="http://aclweb.org/anthology/E17-2098" rel="nofollow"&gt;Bootstrapping Unsupervised Bilingual Lexicon Induction&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=12378647251883332742&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Yunsu Kim, Julian Schamper, and Hermann Ney. 2017. &lt;a href="http://aclweb.org/anthology/E17-2103" rel="nofollow"&gt;Unsupervised Training for Large Vocabulary Translation Using Sparse Lexicon and Word Classes&lt;/a&gt;. In &lt;em&gt;Proceedings of EACL 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=10713109281510942659" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Derry Tanti Wijaya, Brendan Callahan, John Hewitt, Jie Gao, Xiao Ling, Marianna Apidianaki, and Chris Callison-Burch. 2017. &lt;a href="http://aclweb.org/anthology/D17-1152" rel="nofollow"&gt;Learning Translations via Matrix Completion&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=9020955741604455257&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Meng Zhang, Yang Liu, Huanbo Luan, and Maosong Sun. 2017. &lt;a href="http://aclweb.org/anthology/D17-1207" rel="nofollow"&gt;Earth Mover's Distance Minimization for Unsupervised Bilingual Lexicon Induction&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=8228362677106813515&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 26)&lt;/li&gt;
&lt;li&gt;Ndapandula Nakashole and Raphael Flauger. 2017. &lt;a href="http://aclweb.org/anthology/D17-1264" rel="nofollow"&gt;Knowledge Distillation for Bilingual Dictionary Induction&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2017&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=1036105547945298329&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Hanan Aldarmaki, Mahesh Mohan, and Mona Diab. 2018. &lt;a href="http://aclweb.org/anthology/Q18-1014" rel="nofollow"&gt;Unsupervised Word Mapping Using Structural Similarities in Monolingual Embeddings&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=4781812228167043431&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 5)&lt;/li&gt;
&lt;li&gt;Guillaume Lample, Alexis Conneau, Marc'Aurelio Ranzato, Ludovic Denoyer, and Hervé Jégou. 2018. &lt;a href="https://openreview.net/pdf?id=H196sainb" rel="nofollow"&gt;Word Translation without Parallel Data&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=8622718096243524923&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 11)&lt;/li&gt;
&lt;li&gt;Fabienne Braune, Viktor Hangya, Tobias Eder, and Alexander Fraser. 2018. &lt;a href="http://aclweb.org/anthology/N18-2030" rel="nofollow"&gt;Evaluating Bilingual Word Embeddings on the Long Tail&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=1773448771543494989&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Ndapa Nakashole and Raphael Flauger. 2018. &lt;a href="http://aclweb.org/anthology/P18-2036" rel="nofollow"&gt;Characterizing Departures from Linearity in Word Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=669635789435605162&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Anders Søgaard, Sebastian Ruder, and Ivan Vulić. 2018. &lt;a href="http://aclweb.org/anthology/P18-1072" rel="nofollow"&gt;On the Limitations of Unsupervised Bilingual Dictionary Induction&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=1427533216601294786&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 17)&lt;/li&gt;
&lt;li&gt;Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2018. &lt;a href="http://aclweb.org/anthology/P18-1073" rel="nofollow"&gt;A Robust Self-learning Method for Fully Unsupervised Cross-lingual Mappings of Word Embeddings&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=7012967033921106213&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 17)&lt;/li&gt;
&lt;li&gt;Parker Riley and Daniel Gildea. 2018. &lt;a href="http://aclweb.org/anthology/P18-2062" rel="nofollow"&gt;Orthographic Features for Bilingual Lexicon Induction&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Amir Hazem and Emmanuel Morin. 2018. &lt;a href="http://aclweb.org/anthology/C18-1080" rel="nofollow"&gt;Leveraging Meta-Embeddings for Bilingual Lexicon Extraction from Specialized Comparable Corpora&lt;/a&gt;. In &lt;em&gt;Proceedings of COLING 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Lifu Huang, Kyunghyun Cho, Boliang Zhang, Heng Ji, and Kevin Knight. 2018. &lt;a href="http://aclweb.org/anthology/D18-1023" rel="nofollow"&gt;Multi-lingual Common Semantic Space Construction via Cluster-consistent Word Embedding&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Xilun Chen and Claire Cardie. 2018. &lt;a href="http://aclweb.org/anthology/D18-1024" rel="nofollow"&gt;Unsupervised Multilingual Word Embeddings&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=15847135808149408064&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 4)&lt;/li&gt;
&lt;li&gt;Ta Chung Chi and Yun-Nung Chen. 2018. &lt;a href="http://aclweb.org/anthology/D18-1025" rel="nofollow"&gt;CLUSE: Cross-Lingual Unsupervised Sense Embeddings&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=1931895311858153391&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 1)&lt;/li&gt;
&lt;li&gt;Yerai Doval, Jose Camacho-Collados, Luis Espinosa Anke, and Steven Schockaert. 2018. &lt;a href="http://aclweb.org/anthology/D18-1027" rel="nofollow"&gt;Improving Cross-Lingual Word Embeddings by Meeting in the Middle&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sebastian Ruder, Ryan Cotterell, Yova Kementchedjhieva, and Anders Søgaard. 2018. &lt;a href="http://aclweb.org/anthology/D18-1042" rel="nofollow"&gt;A Discriminative Latent-Variable Model for Bilingual Lexicon Induction&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yedid Hoshen and Lior Wolf. 2018. &lt;a href="http://aclweb.org/anthology/D18-1043" rel="nofollow"&gt;Non-Adversarial Unsupervised Word Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Ndapa Nakashole. 2018. &lt;a href="http://aclweb.org/anthology/D18-1047" rel="nofollow"&gt;NORMA: Neighborhood Sensitive Maps for Multilingual Word Embeddings&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Mareike Hartmann, Yova Kementchedjhieva, and Anders Søgaard. 2018. &lt;a href="http://aclweb.org/anthology/D18-1056" rel="nofollow"&gt;Why is unsupervised alignment of English embeddings from different algorithms so hard?&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Zi-Yi Dou, Zhi-Hao Zhou, and Shujian Huang. 2018. &lt;a href="http://aclweb.org/anthology/D18-1062" rel="nofollow"&gt;Unsupervised Bilingual Lexicon Induction via Latent Variable Models&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Tanmoy Mukherjee, Makoto Yamada, and Timothy Hospedales. 2018. &lt;a href="http://aclweb.org/anthology/D18-1063" rel="nofollow"&gt;Learning Unsupervised Word Translations Without Adversaries&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;David Alvarez-Melis and Tommi Jaakkola. 2018. &lt;a href="http://aclweb.org/anthology/D18-1214" rel="nofollow"&gt;Gromov-Wasserstein Alignment of Word Embedding Spaces&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Ruochen Xu, Yiming Yang, Naoki Otani, and Yuexin Wu. 2018. &lt;a href="http://aclweb.org/anthology/D18-1268" rel="nofollow"&gt;Unsupervised Cross-lingual Transfer of Word Embedding Spaces&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?um=1&amp;amp;ie=UTF-8&amp;amp;lr&amp;amp;cites=15320274773511615227" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Armand Joulin, Piotr Bojanowski, Tomas Mikolov, Hervé Jégou, and Edouard Grave. 2018. &lt;a href="http://aclweb.org/anthology/D18-1330" rel="nofollow"&gt;Loss in Translation: Learning Bilingual Word Mapping with a Retrieval Criterion&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2018&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=437763240249389525&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 2)&lt;/li&gt;
&lt;li&gt;Sebastian Ruder, Ivan Vulić, and Anders Søgaard. 2019. &lt;a href="https://arxiv.org/pdf/1706.04902.pdf" rel="nofollow"&gt;A Survey Of Cross-lingual Word Embedding Models&lt;/a&gt;. &lt;em&gt;Journal of Artificial Intelligence Research&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=2174368482827457639&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 22)&lt;/li&gt;
&lt;li&gt;Pratik Jawanpuria, Arjun Balgovind, Anoop Kunchukuttan, and Bamdev Mishra. 2019. &lt;a href="https://arxiv.org/pdf/1808.08773" rel="nofollow"&gt;Learning Multilingual Word Embeddings in Latent Metric Space: A Geometric Approach&lt;/a&gt;. &lt;em&gt;Transactions of the Association for Computational Linguistics&lt;/em&gt;. (&lt;a href="https://scholar.google.com/scholar?cites=3887586742254907953&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en" rel="nofollow"&gt;Citation&lt;/a&gt;: 3)&lt;/li&gt;
&lt;li&gt;Tasnim Mohiuddin and Shafiq Joty. 2019. &lt;a href="https://arxiv.org/pdf/1904.04116.pdf" rel="nofollow"&gt;Revisiting Adversarial Autoencoder for Unsupervised Word Translation with Cycle Consistency and Improved Training&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Chunting Zhou, Xuezhe Ma, Di Wang, and Graham Neubig. 2019. &lt;a href="https://arxiv.org/pdf/1904.02343.pdf" rel="nofollow"&gt;Density Matching for Bilingual Word Embedding&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Noa Yehezkel Lubin, Jacob Goldberger, and Yoav Goldberg. 2019. &lt;a href="https://arxiv.org/pdf/1903.10238.pdf" rel="nofollow"&gt;Aligning Vector-spaces with Noisy Supervised Lexicons&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Tal Schuster, Ori Ram, Regina Barzilay, and Amir Globerson. 2019. &lt;a href="https://arxiv.org/pdf/1902.09492.pdf" rel="nofollow"&gt;Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Hanan Aldarmaki and Mona Diab. 2019. &lt;a href="https://arxiv.org/pdf/1903.03243.pdf" rel="nofollow"&gt;Context-Aware Cross-Lingual Mapping&lt;/a&gt;. In &lt;em&gt;Proceedings of NAACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yoshinari Fujinuma, Jordan Boyd-Graber, and Michael J. Paul. 2019. &lt;a href="https://arxiv.org/pdf/1906.01926" rel="nofollow"&gt;A Resource-Free Evaluation Metric for Cross-Lingual Word Embeddings Based on Graph Modularity&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Mozhi Zhang, Keyulu Xu, Ken-ichi Kawarabayashi, Stefanie Jegelka, and Jordan Boyd-Graber. 2019. &lt;a href="https://arxiv.org/pdf/1906.01622" rel="nofollow"&gt;Are Girls Neko or Shōjo? Cross-Lingual Alignment of Non-Isomorphic Embeddings with Iterative Normalization&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Aitor Ormazabal, Mikel Artetxe, Gorka Labaka, Aitor Soroa, and Eneko Agirre. 2019. &lt;a href="https://arxiv.org/pdf/1906.05407" rel="nofollow"&gt;Analyzing the Limitations of Cross-lingual Word Embedding Mappings&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Takashi Wada, Tomoharu Iwata, and Yuji Matsumoto. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1300" rel="nofollow"&gt;Unsupervised Multilingual Word Embedding with Limited Resources using Neural Language Models&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Pengcheng Yang, Fuli Luo, Peng Chen, Tianyu Liu, and Xu Sun. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1308" rel="nofollow"&gt;MAAM: A Morphology-Aware Alignment Model for Unsupervised Bilingual Lexicon Induction&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Benjamin Marie and Atsushi Fujita. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1312" rel="nofollow"&gt;Unsupervised Joint Training of Bilingual Word Embeddings&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2019. &lt;a href="https://www.aclweb.org/anthology/P19-1494" rel="nofollow"&gt;Bilingual Lexicon Induction through Unsupervised Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Elias Stengel-Eskin, Tzu-Ray Su, Matt Post, and Benjamin Van Durme. 2019. &lt;a href="https://arxiv.org/pdf/1909.00444" rel="nofollow"&gt;A Discriminative Neural Model for Cross-Lingual Word Alignment&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Ivan Vulić, Goran Glavaš, Roi Reichart, and Anna Korhonen. 2019. &lt;a href="https://arxiv.org/pdf/1909.01638" rel="nofollow"&gt;Do We Really Need Fully Unsupervised Cross-Lingual Embeddings?&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Paula Czarnowska, Sebastian Ruder, Edouard Grave, Ryan Cotterell, and Ann Copestake. 2019. &lt;a href="https://arxiv.org/pdf/1909.02855" rel="nofollow"&gt;Don't Forget the Long Tail! A Comprehensive Analysis of Morphological Generalization in Bilingual Lexicon Induction&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Yova Kementchedjhieva, Mareike Hartmann, and Anders Søgaard. 2019. &lt;a href="https://arxiv.org/pdf/1909.05708" rel="nofollow"&gt;Lost in Evaluation: Misleading Benchmarks for Bilingual Dictionary Induction&lt;/a&gt;. In &lt;em&gt;Proceedings of EMNLP 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="user-content-wmt_winners"&gt;&lt;a id="user-content-wmt-winners" class="anchor" aria-hidden="true" href="#wmt-winners"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WMT Winners&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.statmt.org/wmt19/" rel="nofollow"&gt;WMT&lt;/a&gt; is the most important annual international competition on machine translation. We collect the &lt;a href="http://matrix.statmt.org" rel="nofollow"&gt;competition results&lt;/a&gt; on the news translation task since WMT 2016 (the First Conference of Machine Translation) and summarize the techniques used in the systems with the top performance. Currently, we focus on four directions: ZH-EN, EN-ZH, DE-EN, and EN-DE. The summarized algorithms might be incomplete; your suggestions are welcome!&lt;/p&gt;
&lt;h3 id="user-content-wmt19"&gt;&lt;a id="user-content-wmt-2019" class="anchor" aria-hidden="true" href="#wmt-2019"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WMT 2019&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The winner of &lt;a href="http://matrix.statmt.org/matrix/systems_list/1901" rel="nofollow"&gt;ZH-EN&lt;/a&gt;, &lt;a href="http://matrix.statmt.org/matrix/systems_list/1902" rel="nofollow"&gt;DE-EN&lt;/a&gt; and &lt;a href="http://matrix.statmt.org/matrix/systems_list/1909" rel="nofollow"&gt;EN-DE&lt;/a&gt;: &lt;strong&gt;Microsoft&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;System report&lt;/strong&gt;: Yingce Xia, Xu Tan, Fei Tian, Fei Gao, Di He, Weicong Chen, Yang Fan, Linyuan Gong, Yichong Leng, Renqian Luo, Yiren Wang, Lijun Wu, Jinhua Zhu, Tao Qin and Tie-Yan Liu. 2019. &lt;a href="http://www.statmt.org/wmt19/pdf/WMT0048.pdf" rel="nofollow"&gt;Microsoft Research Asia’s Systems for WMT19&lt;/a&gt;. In &lt;em&gt;Proceedings of the Fourth Conference on Machine Translation: Shared Task Papers&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;News&lt;/strong&gt;: &lt;a href="https://news.microsoft.com/apac/2019/05/22/microsoft-research-asia-msra-leads-in-2019-wmt-international-machine-translation-competition/" rel="nofollow"&gt;Microsoft Research Asia (MSRA) leads in 2019 WMT international machine translation competition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Yiren Wang, Yingce Xia, Tianyu He, Fei Tian, Tao Qin, ChengXiang Zhai, and Tie-Yan Liu. 2019. &lt;a href="https://openreview.net/pdf?id=HyGhN2A5tm" rel="nofollow"&gt;Multi-Agent Dual Learning&lt;/a&gt;. In &lt;em&gt;Proceedings of ICLR 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2019. &lt;a href="https://arxiv.org/pdf/1905.02450" rel="nofollow"&gt;MASS: Masked Sequence to Sequence Pre-training for Language Generation&lt;/a&gt;. In &lt;em&gt;Proceedings of ICML 2019&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Renqian Luo, Fei Tian, Tao Qin, Enhong Chen, and Tie-Yan Liu. 2018. &lt;a href="https://papers.nips.cc/paper/8007-neural-architecture-optimization.pdf" rel="nofollow"&gt;Neural Architecture Optimization&lt;/a&gt;. In &lt;em&gt;Proceedings of NeurIPS 2018&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Jinhua Zhu, Fei Gao, Lijun Wu, Yingce Xia, Tao Qin, Wengang Zhou, Xueqi Cheng, Tie-Yan Liu. 2019. &lt;a href="https://arxiv.org/pdf/1905.10523.pdf" rel="nofollow"&gt;Soft Contextual Data Augmentation for Neural Machine Translation&lt;/a&gt;. In &lt;em&gt;Proceedings of ACL 2019&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The winner of &lt;a href="http://matrix.statmt.org/matrix/systems_list/1908" rel="nofollow"&gt;EN-ZH&lt;/a&gt;: &lt;strong&gt;PATECH&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;System report&lt;/strong&gt;: Coming soon...&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Techniques&lt;/strong&gt;: Transformer + Back-Translation + Reranking + Ensemble&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-wmt18"&gt;&lt;a id="user-content-wmt-2018" class="anchor" aria-hidden="true" href="#wmt-2018"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WMT 2018&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The winner of &lt;a href="http://matrix.statmt.org/matrix/systems_list/1892" rel="nofollow"&gt;ZH-EN&lt;/a&gt;: &lt;strong&gt;Tencent&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;System report&lt;/strong&gt;: Mingxuan Wang, Li Gong, Wenhuan Zhu, Jun Xie, and Chao Bian. 2018. &lt;a href="https://www.aclweb.org/anthology/W18-6429" rel="nofollow"&gt;Tencent Neural Machine Translation Systems for WMT18&lt;/a&gt;. In &lt;em&gt;Proceedings of the Third Conference on Machine Translation: Shared Task Papers&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Techniques&lt;/strong&gt;: RNMT + Transformer + BPE + Rerank ensemble outputs with 48 features (including t2t R2l, t2t L2R, rnn L2R, rnn R2L etc.) + Back Translation + Joint Train with English to Chinese systems + Fine-tuning with selected data + Knowledge distillation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The winner of &lt;a href="http://matrix.statmt.org/matrix/systems_list/1893" rel="nofollow"&gt;EN-ZH&lt;/a&gt;: &lt;strong&gt;GTCOM&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;System report&lt;/strong&gt;: Chao Bei, Hao Zong, Yiming Wang, Baoyong Fan, Shiqi Li, and Conghu Yuan. 2018. &lt;a href="https://www.aclweb.org/anthology/W18-6404" rel="nofollow"&gt;An Empirical Study of Machine Translation for the Shared Task of WMT18&lt;/a&gt;. In &lt;em&gt;Proceedings of the Third Conference on Machine Translation: Shared Task Papers&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Techniques&lt;/strong&gt;: Transformer + Back-Translation + Data Filtering by rules, language models and translation models + BPE + Greedy Ensemble Decoding + Fine-Tuning with newstest2017 back translation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The winner of &lt;a href="http://matrix.statmt.org/matrix/systems_list/1880" rel="nofollow"&gt;DE-EN&lt;/a&gt;: &lt;strong&gt;RWTH Aachen University&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;System report&lt;/strong&gt;: Julian Schamper, Jan Rosendahl, Parnia Bahar, Yunsu Kim, Arne Nix, and Hermann Ney. 2018. &lt;a href="https://www.aclweb.org/anthology/W18-6426" rel="nofollow"&gt;The RWTH Aachen University Supervised Machine Translation Systems for WMT 2018&lt;/a&gt;. In &lt;em&gt;Proceedings of the Third Conference on Machine Translation: Shared Task Papers&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Techniques&lt;/strong&gt;: Ensemble of 3-strongest Transformer models + Data Selection + BPE + Fine-Tuning + Important Hyperparameters (batch size and model dimension)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The winner of &lt;a href="http://matrix.statmt.org/matrix/systems_list/1881" rel="nofollow"&gt;EN-DE&lt;/a&gt;: &lt;strong&gt;Microsoft&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;System report&lt;/strong&gt;: Marcin Junczys-Dowmunt. 2018. &lt;a href="https://www.aclweb.org/anthology/W18-6415" rel="nofollow"&gt;Microsoft’s Submission to the WMT2018 News Translation Task: How I Learned to Stop Worrying and Love the Data&lt;/a&gt;. In &lt;em&gt;Proceedings of the Third Conference on Machine Translation: Shared Task Papers&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Techniques&lt;/strong&gt;: Marian + Transformer-big + BPE + Ensemble + Data Filtering + Domain-Weighted {ParaCrawl, original data} + Decoder-time ensemble with in-domain Transformer-style language model + Reranking with Right-to-left Transformer-big models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-wmt17"&gt;&lt;a id="user-content-wmt-2017" class="anchor" aria-hidden="true" href="#wmt-2017"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WMT 2017&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The winner of &lt;a href="http://matrix.statmt.org/matrix/systems_list/1878" rel="nofollow"&gt;ZH-EN&lt;/a&gt;: &lt;strong&gt;Sogou&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;System report&lt;/strong&gt;: Yuguang Wang, Shanbo Cheng, Liyang Jiang, Jiajun Yang, Wei Chen, Muze Li, Lin Shi, Yanfeng Wang, and Hongtao Yang. 2017. &lt;a href="https://www.aclweb.org/anthology/W17-4742" rel="nofollow"&gt;Sogou Neural Machine Translation Systems for WMT17&lt;/a&gt;. In &lt;em&gt;Proceedings of the Second Conference on Machine Translation: Shared Task Papers&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Techniques&lt;/strong&gt;: Encoder-Decoder with Attention + BPE + Reranking (R2L, T2S, N-gram language models) + Tagging Model + Name Entity Translation + Ensemble&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The winner of &lt;a href="http://matrix.statmt.org/matrix/systems_list/1879" rel="nofollow"&gt;EN-ZH&lt;/a&gt;, &lt;a href="http://matrix.statmt.org/matrix/systems_list/1868" rel="nofollow"&gt;DE-EN&lt;/a&gt; and &lt;a href="http://matrix.statmt.org/matrix/systems_list/1869" rel="nofollow"&gt;EN-DE&lt;/a&gt;: &lt;strong&gt;University of Edinburgh&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;System report&lt;/strong&gt;: Rico Sennrich, Alexandra Birch, Anna Currey, Ulrich Germann, Barry Haddow, Kenneth Heafield, Antonio Valerio Miceli Barone, and Philip Williams. 2017. &lt;a href="https://www.aclweb.org/anthology/W17-4739" rel="nofollow"&gt;The University of Edinburgh’s Neural MT Systems for WMT17&lt;/a&gt;. In &lt;em&gt;Proceedings of the Second Conference on Machine Translation: Shared Task Papers&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Techniques&lt;/strong&gt;: Encoder-Decoder with Attention + Deep Model + Layer Normalization + Weight Tying + Back-Translation + BPE + Reranking(L2R, R2L) + Ensemble&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="user-content-wmt16"&gt;&lt;a id="user-content-wmt-2016" class="anchor" aria-hidden="true" href="#wmt-2016"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WMT 2016&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The winner of &lt;a href="http://matrix.statmt.org/matrix/systems_list/1846" rel="nofollow"&gt;DE-EN&lt;/a&gt;: &lt;strong&gt;University of Regensburg&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;System report&lt;/strong&gt;: Failed to find it&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Techniques&lt;/strong&gt;: Failed to find it&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The winner of &lt;a href="http://matrix.statmt.org/matrix/systems_list/1846" rel="nofollow"&gt;EN-DE&lt;/a&gt;: &lt;strong&gt;University of Edinburgh&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;System report&lt;/strong&gt;: &lt;a href="http://www.aclweb.org/anthology/W16-2323" rel="nofollow"&gt;Edinburgh Neural Machine Translation Systems for WMT 16&lt;/a&gt;. In &lt;em&gt;Proceedings of the First Conference on Machine Translation: Shared Task Papers&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Techniques&lt;/strong&gt;: Encoder-Decoder with Attention + Back-Translation + BPE + Reranking(R2L) + Ensemble&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>THUNLP-MT</author><guid isPermaLink="false">https://github.com/THUNLP-MT/MT-Reading-List</guid><pubDate>Thu, 28 Nov 2019 00:06:00 GMT</pubDate></item><item><title>posquit0/Awesome-CV #7 in TeX, This week</title><link>https://github.com/posquit0/Awesome-CV</link><description>&lt;p&gt;&lt;i&gt;:page_facing_up: Awesome CV is LaTeX template for your outstanding job application&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1 align="center"&gt;&lt;a id="user-content-------------awesome-cv" class="anchor" aria-hidden="true" href="#------------awesome-cv"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;
  &lt;a href="https://github.com/posquit0/Awesome-CV" title="AwesomeCV Documentation"&gt;
    &lt;img alt="AwesomeCV" src="https://github.com/posquit0/Awesome-CV/raw/master/icon.png" width="200px" height="200px" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;br&gt;
  Awesome CV
&lt;/h1&gt;
&lt;p align="center"&gt;
  LaTeX template for your outstanding job application
&lt;/p&gt;
&lt;div align="center"&gt;
  &lt;a href="https://www.paypal.me/posquit0" rel="nofollow"&gt;
    &lt;img alt="Donate" src="https://camo.githubusercontent.com/abbdd7bf97ae7919db5962b255f40aded5189c4f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d50617950616c2d626c75652e737667" data-canonical-src="https://img.shields.io/badge/Donate-PayPal-blue.svg" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://circleci.com/gh/posquit0/Awesome-CV" rel="nofollow"&gt;
    &lt;img alt="CircleCI" src="https://camo.githubusercontent.com/d42593802854990d35ca42943e478dd35d6c64c9/68747470733a2f2f636972636c6563692e636f6d2f67682f706f7371756974302f417765736f6d652d43562e7376673f7374796c653d736869656c64" data-canonical-src="https://circleci.com/gh/posquit0/Awesome-CV.svg?style=shield" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf" rel="nofollow"&gt;
    &lt;img alt="Example Resume" src="https://camo.githubusercontent.com/836d3a9f44da3462e5c47b6c58bf066bffbaf739/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f726573756d652d7064662d677265656e2e737667" data-canonical-src="https://img.shields.io/badge/resume-pdf-green.svg" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/cv.pdf" rel="nofollow"&gt;
    &lt;img alt="Example CV" src="https://camo.githubusercontent.com/8afab53a91bc30d0da18a9ea0cc70f2d0a1571df/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f63762d7064662d677265656e2e737667" data-canonical-src="https://img.shields.io/badge/cv-pdf-green.svg" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf" rel="nofollow"&gt;
    &lt;img alt="Example Coverletter" src="https://camo.githubusercontent.com/ce88ed0c1af9e5611df67818460447b69572ae9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f7665726c65747465722d7064662d677265656e2e737667" data-canonical-src="https://img.shields.io/badge/coverletter-pdf-green.svg" style="max-width:100%;"&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-what-is-awesome-cv" class="anchor" aria-hidden="true" href="#what-is-awesome-cv"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is Awesome CV?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Awesome CV&lt;/strong&gt; is LaTeX template for a &lt;strong&gt;CV(Curriculum Vitae)&lt;/strong&gt;, &lt;strong&gt;Résumé&lt;/strong&gt; or &lt;strong&gt;Cover Letter&lt;/strong&gt; inspired by &lt;a href="https://www.sharelatex.com/templates/cv-or-resume/fancy-cv" rel="nofollow"&gt;Fancy CV&lt;/a&gt;. It is easy to customize your own template, especially since it is really written by a clean, semantic markup.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-donate" class="anchor" aria-hidden="true" href="#donate"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Donate&lt;/h2&gt;
&lt;p&gt;Please help keep this project alive! Donations are welcome and will go towards further development of this project.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;PayPal: paypal.me/posquit0
BTC: 1Je3DxJVM2a9nTVPNo55SfQwpmxA6N2KKb
BCH: 1Mg1wG7PwHGrHYSWS67TsGSjo5GHEVbF16
ETH: 0x77ED9B4659F80205E9B9C9FB1E26EDB9904AFCC7
QTUM: QZT7D6m3QtTTqp7s4ZWAwLtGDsoHMMaM8E
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Thank you for your support!&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-preview" class="anchor" aria-hidden="true" href="#preview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preview&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-résumé" class="anchor" aria-hidden="true" href="#résumé"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Résumé&lt;/h4&gt;
&lt;p&gt;You can see &lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf" rel="nofollow"&gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Page. 1&lt;/th&gt;
&lt;th align="center"&gt;Page. 2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume-0.png" alt="Résumé" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume-1.png" alt="Résumé" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-cover-letter" class="anchor" aria-hidden="true" href="#cover-letter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cover Letter&lt;/h4&gt;
&lt;p&gt;You can see &lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf" rel="nofollow"&gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Without Sections&lt;/th&gt;
&lt;th align="center"&gt;With Sections&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter-0.png" alt="Cover Letter(Traditional)" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter-1.png" alt="Cover Letter(Awesome)" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.overleaf.com/latex/templates/awesome-cv/tvmzpvdjfqxp" rel="nofollow"&gt;&lt;strong&gt;Edit Résumé on OverLeaf.com&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.overleaf.com/latex/templates/awesome-cv-cover-letter/pfzzjspkthbk" rel="nofollow"&gt;&lt;strong&gt;Edit Cover Letter on OverLeaf.com&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Note:&lt;/em&gt; Above services do not guarantee up-to-date source code of Awesome CV&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-use" class="anchor" aria-hidden="true" href="#how-to-use"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to Use&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h4&gt;
&lt;p&gt;A full TeX distribution is assumed.  &lt;a href="http://tex.stackexchange.com/q/55437" rel="nofollow"&gt;Various distributions for different operating systems (Windows, Mac, *nix) are available&lt;/a&gt; but TeX Live is recommended.
You can &lt;a href="http://tex.stackexchange.com/q/1092" rel="nofollow"&gt;install TeX from upstream&lt;/a&gt; (recommended; most up-to-date) or use &lt;code&gt;sudo apt-get install texlive-full&lt;/code&gt; if you really want that.  (It's generally a few years behind.)&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h4&gt;
&lt;p&gt;At a command prompt, run&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ xelatex {your-cv}.tex&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This should result in the creation of &lt;code&gt;{your-cv}.pdf&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-credit" class="anchor" aria-hidden="true" href="#credit"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credit&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.latex-project.org" rel="nofollow"&gt;&lt;strong&gt;LaTeX&lt;/strong&gt;&lt;/a&gt; is a fantastic typesetting program that a lot of people use these days, especially the math and computer science people in academia.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/furl/latex-fontawesome"&gt;&lt;strong&gt;LaTeX FontAwesome&lt;/strong&gt;&lt;/a&gt; is bindings for FontAwesome icons to be used in XeLaTeX.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/google/roboto"&gt;&lt;strong&gt;Roboto&lt;/strong&gt;&lt;/a&gt; is the default font on Android and ChromeOS, and the recommended font for Google’s visual language, Material Design.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/adobe-fonts/source-sans-pro"&gt;&lt;strong&gt;Source Sans Pro&lt;/strong&gt;&lt;/a&gt; is a set of OpenType fonts that have been designed to work well in user interface (UI) environments.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h2&gt;
&lt;p&gt;You are free to take my &lt;code&gt;.tex&lt;/code&gt; file and modify it to create your own resume. Please don't use my resume for anything else without my permission, though!&lt;/p&gt;
&lt;p&gt;If you have any questions, feel free to join me at &lt;code&gt;#posquit0&lt;/code&gt; on Freenode and ask away. Click &lt;a href="https://kiwiirc.com/client/irc.freenode.net/posquit0" rel="nofollow"&gt;here&lt;/a&gt; to connect.&lt;/p&gt;
&lt;p&gt;Good luck!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-see-also" class="anchor" aria-hidden="true" href="#see-also"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;See Also&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/posquit0/hugo-awesome-identity"&gt;Awesome Identity&lt;/a&gt; - A single-page Hugo theme to introduce yourself.&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>posquit0</author><guid isPermaLink="false">https://github.com/posquit0/Awesome-CV</guid><pubDate>Thu, 28 Nov 2019 00:07:00 GMT</pubDate></item><item><title>xueruini/thuthesis #8 in TeX, This week</title><link>https://github.com/xueruini/thuthesis</link><description>&lt;p&gt;&lt;i&gt;LaTeX Thesis Template for Tsinghua University&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://travis-ci.org/xueruini/thuthesis" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5da8c22b95bd0e5eb940bc5fea16af8feb2ed401/68747470733a2f2f7472617669732d63692e6f72672f7875657275696e692f7468757468657369732e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/xueruini/thuthesis.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/thuthesis/Lobby" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f93c05a42da86d653b4d5ad075031b2f4a9c60a1/68747470733a2f2f6261646765732e6769747465722e696d2f7468757468657369732f4c6f6262792e737667" alt="Join the chat at https://gitter.im/thuthesis/Lobby" data-canonical-src="https://badges.gitter.im/thuthesis/Lobby.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/xueruini/thuthesis/releases"&gt;&lt;img src="https://camo.githubusercontent.com/495c01faee6697531e60e3f0ca1e66743582e890/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f646f776e6c6f6164732f7875657275696e692f7468757468657369732f746f74616c2e737667" alt="Github downloads" data-canonical-src="https://img.shields.io/github/downloads/xueruini/thuthesis/total.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/xueruini/thuthesis/releases/latest"&gt;&lt;img src="https://camo.githubusercontent.com/a08197fcf9be7d3e34ac0526686304fbd4817146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f7875657275696e692f7468757468657369732f616c6c2e737667" alt="GitHub release" data-canonical-src="https://img.shields.io/github/release/xueruini/thuthesis/all.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/xueruini/thuthesis/commits/master"&gt;&lt;img src="https://camo.githubusercontent.com/13a6034e83188b5338130101b729835496b5110f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f7875657275696e692f7468757468657369732f6c61746573742e737667" alt="GitHub commits" data-canonical-src="https://img.shields.io/github/commits-since/xueruini/thuthesis/latest.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-whats-thuthesis" class="anchor" aria-hidden="true" href="#whats-thuthesis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What's ThuThesis?&lt;/h1&gt;
&lt;p&gt;ThuThesis is an abbreviation of &lt;b&gt;T&lt;/b&gt;sing&lt;b&gt;h&lt;/b&gt;ua &lt;b&gt;U&lt;/b&gt;niversity &lt;b&gt;Thesis&lt;/b&gt; LaTeX Template.&lt;/p&gt;
&lt;p&gt;This package establishes a simple and easy-to-use LaTeX template for Tsinghua dissertations, including general undergraduate research papers, masters theses, doctoral theses, doctoral dissertations, and post-doc reports. Additional support for other formats (what else is there?) will be added continuously. An English translation of this README follows the Chinese below.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-thuthesis是什么" class="anchor" aria-hidden="true" href="#thuthesis是什么"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ThuThesis是什么？&lt;/h1&gt;
&lt;p&gt;ThuThesis为 &lt;b&gt;T&lt;/b&gt;sing&lt;b&gt;h&lt;/b&gt;ua &lt;b&gt;U&lt;/b&gt;niversity &lt;b&gt;Thesis&lt;/b&gt; LaTeX Template之缩写。&lt;/p&gt;
&lt;p&gt;此宏包旨在建立一个简单易用的清华大学学位论文LaTeX模板，包括本科综合论文训练、硕士论文、博士论文、博士哲学论文以及博士后出站报告。现在支持本科、硕士、博士论文、博士后出站报告格式，对其它格式（还有么？）的支持会陆续加入。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-文档" class="anchor" aria-hidden="true" href="#文档"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;文档&lt;/h1&gt;
&lt;p&gt;请&lt;a href="https://github.com/xueruini/thuthesis/releases"&gt;下载&lt;/a&gt;模板，里面包括具体使用说明以及示例文档：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模板使用说明 (thuthesis.pdf)&lt;/li&gt;
&lt;li&gt;示例文档 (main.pdf)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-下载" class="anchor" aria-hidden="true" href="#下载"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;下载&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;发行版：&lt;a href="http://www.ctan.org/pkg/thuthesis" rel="nofollow"&gt;CTAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;开发版：&lt;a href="https://github.com/xueruini/thuthesis"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-升级" class="anchor" aria-hidden="true" href="#升级"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;升级&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-自动更新" class="anchor" aria-hidden="true" href="#自动更新"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;自动更新&lt;/h2&gt;
&lt;p&gt;通过 TeX 发行版工具自动从 &lt;a href="http://www.ctan.org/pkg/thuthesis" rel="nofollow"&gt;CTAN&lt;/a&gt; 更新。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-手动更新" class="anchor" aria-hidden="true" href="#手动更新"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;手动更新&lt;/h2&gt;
&lt;p&gt;从 &lt;a href="https://github.com/xueruini/thuthesis"&gt;GitHub&lt;/a&gt; 下载放入论文目录，执行命令（Windows 用户在文件夹空白处按&lt;code&gt;Shift+鼠标右键&lt;/code&gt;，点击“在此处打开命令行窗口”）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;xetex thuthesis.ins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;即可得到 &lt;code&gt;thuthesis.cls&lt;/code&gt; 等模板文件。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-提问" class="anchor" aria-hidden="true" href="#提问"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;提问&lt;/h1&gt;
&lt;p&gt;按推荐顺序排序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先到 &lt;a href="https://github.com/xueruini/thuthesis/wiki/FAQ"&gt;FAQ&lt;/a&gt; 看看常见问题&lt;/li&gt;
&lt;li&gt;&lt;a href="http://github.com/xueruini/thuthesis/issues"&gt;Github Issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.newsmth.net/nForum/#!board/TeX" rel="nofollow"&gt;TeX@newsmth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://groups.google.com/group/thuthesis" rel="nofollow"&gt;ThuThesis@Google Groups&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-makefile的用法" class="anchor" aria-hidden="true" href="#makefile的用法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Makefile的用法&lt;/h1&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;make [{all&lt;span class="pl-k"&gt;|&lt;/span&gt;thesis&lt;span class="pl-k"&gt;|&lt;/span&gt;shuji&lt;span class="pl-k"&gt;|&lt;/span&gt;doc&lt;span class="pl-k"&gt;|&lt;/span&gt;clean&lt;span class="pl-k"&gt;|&lt;/span&gt;cleanall&lt;span class="pl-k"&gt;|&lt;/span&gt;distclean}]&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-目标" class="anchor" aria-hidden="true" href="#目标"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目标&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;make all&lt;/code&gt;       等于 &lt;code&gt;make thesis &amp;amp;&amp;amp; make shuji &amp;amp;&amp;amp; make doc&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make cls&lt;/code&gt;       生成模板文件；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make thesis&lt;/code&gt;    生成论文 main.pdf；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make shuji&lt;/code&gt;     生成书脊 shuji.pdf；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make doc&lt;/code&gt;       生成使用说明书 thuthesis.pdf；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make clean&lt;/code&gt;     删除示例文件的中间文件（不含 main.pdf）；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make cleanall&lt;/code&gt;  删除示例文件的中间文件和 main.pdf；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make distclean&lt;/code&gt; 删除示例文件和模板的所有中间文件和 PDF。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h1&gt;
&lt;p&gt;Download and unzip the template. Specific usage documentation and examples can be found in the files below. At present, these documents are &lt;b&gt;only available in Chinese&lt;/b&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Template usage (thuthesis.pdf)&lt;/li&gt;
&lt;li&gt;Template example (main.pdf)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-downloads" class="anchor" aria-hidden="true" href="#downloads"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Downloads&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Published version: &lt;a href="http://www.ctan.org/pkg/thuthesis" rel="nofollow"&gt;CTAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Developer version: &lt;a href="https://github.com/xueruini/thuthesis"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-updates" class="anchor" aria-hidden="true" href="#updates"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Updates&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-automatic" class="anchor" aria-hidden="true" href="#automatic"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Automatic&lt;/h2&gt;
&lt;p&gt;Get the most up-to-date published version of the TeX tools from &lt;a href="http://www.ctan.org/pkg/thuthesis" rel="nofollow"&gt;CTAN&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-manual" class="anchor" aria-hidden="true" href="#manual"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Manual&lt;/h2&gt;
&lt;p&gt;Download the package from &lt;a href="https://github.com/xueruini/thuthesis"&gt;GitHub&lt;/a&gt; to the root directory of your thesis, then execute the command (Windows users &lt;code&gt;Shift + right click&lt;/code&gt; white area in the file window and click "Open command line window here from the popup menu"):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;xetex thuthesis.ins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You'll get &lt;code&gt;thuthesis.cls&lt;/code&gt; along with other template files.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-reporting-issues" class="anchor" aria-hidden="true" href="#reporting-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reporting Issues&lt;/h1&gt;
&lt;p&gt;Please follow the procedure below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Check the  &lt;a href="https://github.com/xueruini/thuthesis/wiki/FAQ"&gt;FAQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://github.com/xueruini/thuthesis/issues"&gt;Github Issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.newsmth.net/nForum/#!board/TeX" rel="nofollow"&gt;TeX@newsmth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://groups.google.com/group/thuthesis" rel="nofollow"&gt;ThuThesis@Google Groups&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-makefile-usage" class="anchor" aria-hidden="true" href="#makefile-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Makefile Usage&lt;/h1&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;make [{all&lt;span class="pl-k"&gt;|&lt;/span&gt;thesis&lt;span class="pl-k"&gt;|&lt;/span&gt;shuji&lt;span class="pl-k"&gt;|&lt;/span&gt;doc&lt;span class="pl-k"&gt;|&lt;/span&gt;clean&lt;span class="pl-k"&gt;|&lt;/span&gt;cleanall&lt;span class="pl-k"&gt;|&lt;/span&gt;distclean}]&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-targets" class="anchor" aria-hidden="true" href="#targets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Targets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;make all&lt;/code&gt;       same as &lt;code&gt;make thesis &amp;amp;&amp;amp; make shuji &amp;amp;&amp;amp; make doc&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make cls&lt;/code&gt;       generate template file;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make thesis&lt;/code&gt;    generate thesis main.pdf;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make shuji&lt;/code&gt;     generate book spine for printing shuji.pdf;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make doc&lt;/code&gt;       generate documentation thuthesis.pdf;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make clean&lt;/code&gt;     delete all examples' files (excluding main.pdf);&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make cleanall&lt;/code&gt;  delete all examples' files and main.pdf;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make distclean&lt;/code&gt; delete all examples' and templates' files and PDFs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>xueruini</author><guid isPermaLink="false">https://github.com/xueruini/thuthesis</guid><pubDate>Thu, 28 Nov 2019 00:08:00 GMT</pubDate></item><item><title>soulmachine/leetcode #9 in TeX, This week</title><link>https://github.com/soulmachine/leetcode</link><description>&lt;p&gt;&lt;i&gt;LeetCode题解，151道题完整版&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-leetcode题解" class="anchor" aria-hidden="true" href="#leetcode题解"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;#LeetCode题解&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-在线阅读" class="anchor" aria-hidden="true" href="#在线阅读"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;在线阅读&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.gitbook.com/book/soulmachine/algorithm-essentials/" rel="nofollow"&gt;https://www.gitbook.com/book/soulmachine/algorithm-essentials/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;##PDF下载
&lt;a href="https://github.com/soulmachine/leetcode/raw/master/C%2B%2B/leetcode-cpp.pdf"&gt;LeetCode题解(C++版).pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;C++ 文件夹下是C++版，内容一模一样，代码是用C++写的。&lt;/p&gt;
&lt;p&gt;Java 文件夹下是Java版，目前正在编写中，由于拖延症，不知道猴年马月能完成。&lt;/p&gt;
&lt;p&gt;##LaTeX模板
本书使用的是陈硕开源的&lt;a href="https://github.com/chenshuo/typeset"&gt;模板&lt;/a&gt;。这个模板制作精良，很有taste，感谢陈硕 :)&lt;/p&gt;
&lt;p&gt;##在Windows下编译&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;安装Tex Live 2015 &lt;a href="http://www.tug.org/texlive/" rel="nofollow"&gt;http://www.tug.org/texlive/&lt;/a&gt;。把bin目录例如&lt;code&gt;D:\texlive\2015\bin\win32&lt;/code&gt;加入PATH环境变量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装字体。这个LaTex模板总共使用了10个字体，下载地址 &lt;a href="https://pan.baidu.com/s/1eRFJXnW" rel="nofollow"&gt;https://pan.baidu.com/s/1eRFJXnW&lt;/a&gt; ，有的字体Windows自带了，有的字体Ubuntu自带了，但都不全，还是一次性安装完所有字体比较方便。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装TeXstudio &lt;a href="http://texstudio.sourceforge.net/" rel="nofollow"&gt;http://texstudio.sourceforge.net/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(可选)启动Tex Live Manager，更新所有已安装的软件包。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;配置TeXstudio。&lt;/p&gt;
&lt;p&gt;启动Texstudio，选择 &lt;code&gt;Options--&amp;gt;Configure Texstudio--&amp;gt;Commands&lt;/code&gt;，XeLaTex 设置为 &lt;code&gt;xelatex -synctex=1 -interaction=nonstopmode %.tex&lt;/code&gt;；&lt;/p&gt;
&lt;p&gt;选择 &lt;code&gt;Options--&amp;gt;Configure Texstudio--&amp;gt;Build&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Build &amp;amp; View 由默认的 PDF Chain 改为 Compile &amp;amp; View；&lt;/p&gt;
&lt;p&gt;Default Compiler 由默认的PdfLaTex 修改为 XeLaTex ；&lt;/p&gt;
&lt;p&gt;PDF Viewer 改为 “Internal PDF Viewer(windowed)”，这样预览时会弹出一个独立的窗口，这样比较方便。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;编译。用TeXstudio打开&lt;code&gt;typeset.tex&lt;/code&gt;，点击界面上的绿色箭头就可以开始编译了。&lt;/p&gt;
&lt;p&gt;在下方的窗口可以看到TeXstudio正在使用的编译命令是&lt;code&gt;xelatex -synctex=1 -interaction=nonstopmode "typeset".tex&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;##在Ubuntu下编译&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;安装Tex Live 2015 &lt;a href="http://www.tug.org/texlive/" rel="nofollow"&gt;http://www.tug.org/texlive/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;1.1. 下载TexLive 2015 的ISO 光盘，地址 &lt;a href="http://www.tug.org/texlive/acquire-iso.html" rel="nofollow"&gt;http://www.tug.org/texlive/acquire-iso.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;1.2 mount 光盘，&lt;code&gt;sudo ./install-tl&lt;/code&gt; 开始安装&lt;/p&gt;
&lt;p&gt;1.3 加入环境变量&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; sudo vi /etc/profile
 export PATH=$PATH:/usr/local/texlive/2015/bin/x86_64-linux
 export MANPATH=$MANPATH:/usr/local/texlive/2015/texmf-dist/doc/man
 export INFPATH=$INFPATH:/usr/local/texlive/2015/texmf-dist/doc/info
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装字体。这个LaTex模板总共使用了10个字体，下载地址 &lt;a href="https://pan.baidu.com/s/1eRFJXnW" rel="nofollow"&gt;https://pan.baidu.com/s/1eRFJXnW&lt;/a&gt; ，有的字体Windows自带了，有的字体Ubuntu自带了，但都不全，还是一次性安装完所有字体比较方便。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装TeXstudio &lt;a href="http://texstudio.sourceforge.net/" rel="nofollow"&gt;http://texstudio.sourceforge.net/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;配置TeXstudio。&lt;/p&gt;
&lt;p&gt;启动Texstudio，选择 &lt;code&gt;Options--&amp;gt;Configure Texstudio--&amp;gt;Commands&lt;/code&gt;，XeLaTex 设置为 &lt;code&gt;xelatex -synctex=1 -interaction=nonstopmode %.tex&lt;/code&gt;；&lt;/p&gt;
&lt;p&gt;选择 &lt;code&gt;Options--&amp;gt;Configure Texstudio--&amp;gt;Build&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Build &amp;amp; View 由默认的 PDF Chain 改为 Compile &amp;amp; View；&lt;/p&gt;
&lt;p&gt;Default Compiler 由默认的PdfLaTex 修改为 XeLaTex ；&lt;/p&gt;
&lt;p&gt;PDF Viewer 改为 “Internal PDF Viewer(windowed)”，这样预览时会弹出一个独立的窗口，这样比较方便。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;编译。用TeXstudio打开&lt;code&gt;typeset.tex&lt;/code&gt;，点击界面上的绿色箭头就可以开始编译了。&lt;/p&gt;
&lt;p&gt;在下方的窗口可以看到TeXstudio正在使用的编译命令是&lt;code&gt;xelatex -synctex=1 -interaction=nonstopmode "typeset".tex&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;懒人版镜像。如果不想进行上面繁琐的安装过程，我做好了一个Ubuntu VMware虚拟机镜像，已经装好了 TexLive 2015, TexStudio和字体(详细的安装日志见压缩包注释)，开箱即用，下载地址 &lt;a href="http://pan.baidu.com/s/1cLWkgA" rel="nofollow"&gt;http://pan.baidu.com/s/1cLWkgA&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;##如何贡献代码
编译通过后，就具备了完整的LaTeX编译环境了。&lt;/p&gt;
&lt;p&gt;本书模板已经写好了，基本上不需要很多LaTeX知识就可以动手了。&lt;/p&gt;
&lt;p&gt;欢迎给本书添加内容或纠正错误，在自己本地编译成PDF，预览没问题后，就可以发pull request过来了。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-qq群" class="anchor" aria-hidden="true" href="#qq群"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;QQ群&lt;/h2&gt;
&lt;p&gt;237669375&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-小密圈" class="anchor" aria-hidden="true" href="#小密圈"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;小密圈&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/silicon-job.jpeg"&gt;&lt;img src="%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/silicon-job.jpeg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-algohub" class="anchor" aria-hidden="true" href="#algohub"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;AlgoHub&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.algohub.org" rel="nofollow"&gt;https://www.algohub.org&lt;/a&gt; 是我建立的一个刷题网站，即将上线，敬请期待&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-纸质书" class="anchor" aria-hidden="true" href="#纸质书"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;纸质书&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;本书即将由电子工业出版社出版，敬请期待&lt;/strong&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>soulmachine</author><guid isPermaLink="false">https://github.com/soulmachine/leetcode</guid><pubDate>Thu, 28 Nov 2019 00:09:00 GMT</pubDate></item><item><title>devonfw-forge/devonfw4flutter #10 in TeX, This week</title><link>https://github.com/devonfw-forge/devonfw4flutter</link><description>&lt;p&gt;&lt;i&gt; A guide aiming to bridge the gap between the absolute Flutter basics and clean, structured Flutter Development&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/devonfw-forge/devonfw4flutter/wiki//images/banner.png"&gt;&lt;img src="https://github.com/devonfw-forge/devonfw4flutter/wiki//images/banner.png" alt="Banner" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Guide is published in the &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki"&gt;Wiki of this repository&lt;/a&gt;. This Repository just hold a copy of the Wiki to make the commit history more readable. The README.md is a copy of the &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki"&gt;Introduction chapter&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Page Table of Contents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#the-goal-of-this-guide"&gt;The Goal of this Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#who-is-this-guide-for"&gt;Who is this Guide for?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#topics-that-will-be-covered"&gt;Topics that will be Covered&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#creation-context"&gt;Creation Context&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#structure"&gt;Structure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#my-sources"&gt;My Sources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#creation-process"&gt;Creation Process&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-the-goal-of-this-guide" class="anchor" aria-hidden="true" href="#the-goal-of-this-guide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Goal of this Guide&lt;/h2&gt;
&lt;p&gt;This guide aims to bridge the gap between the absolute Flutter &lt;a href="https://flutter.dev/" rel="nofollow"&gt;[1]&lt;/a&gt; basics and clean, structured Flutter development. It should bring you from the basics of knowing how to build an app with Flutter to an understanding of how to do it &lt;em&gt;properly&lt;/em&gt;. Or at least show you one possible way to make large scale Flutter projects clean and manageable.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-who-is-this-guide-for" class="anchor" aria-hidden="true" href="#who-is-this-guide-for"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Who is this Guide for?&lt;/h2&gt;
&lt;p&gt;For people with a basic knowledge of the Flutter Framework. I recommend following this tutorial by the Flutter team &lt;a href="https://flutter.dev/docs/get-started/codelab" rel="nofollow"&gt;[2]&lt;/a&gt;. It will walk you through developing your first Flutter application. You should also have a basic understanding of the Dart programming language &lt;a href="https://dart.dev/" rel="nofollow"&gt;[3]&lt;/a&gt;. No worries, it is very similar to Java &lt;a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" rel="nofollow"&gt;[4]&lt;/a&gt;, Kotlin &lt;a href="https://kotlinlang.org/" rel="nofollow"&gt;[5]&lt;/a&gt; and JavaScript &lt;a href="https://www.ecma-international.org/publications/standards/Ecma-262.htm" rel="nofollow"&gt;[6]&lt;/a&gt;. So if you know 1 or 2 of those languages you should be fine.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-topics-that-will-be-covered" class="anchor" aria-hidden="true" href="#topics-that-will-be-covered"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Topics that will be Covered&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A brief introduction to the &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki/100-The-Flutter-Framework"&gt;Flutter Framework&lt;/a&gt; in general:
&lt;ul&gt;
&lt;li&gt;How the &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki/110-Under-the-Hood"&gt;underlying technology&lt;/a&gt; works,&lt;/li&gt;
&lt;li&gt;how it’s &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki/120-Thinking-Declaratively"&gt;programming style&lt;/a&gt; is little different from other frameworks,&lt;/li&gt;
&lt;li&gt;how Flutter apps are &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki/130-The-Widget-Tree"&gt;structured&lt;/a&gt; on an abstract level and,&lt;/li&gt;
&lt;li&gt;how &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki/140-Asynchronous-Flutter"&gt;asynchrony&lt;/a&gt; and communication with the web can be implemented.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A showcase of possible &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki/210-State-Management-Alternatives"&gt;architectural styles&lt;/a&gt; you can use to build your app and
&lt;ul&gt;
&lt;li&gt;an &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki/220-BLoC"&gt;in-depth guide&lt;/a&gt; on one of those possibilities (BLoC Pattern &lt;a href="https://www.youtube.com/watch?v=PLHln7wHgPE" rel="nofollow"&gt;[7]&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How to &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki/300-Testing"&gt;test&lt;/a&gt; your app.&lt;/li&gt;
&lt;li&gt;Some &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki/400-Conventions"&gt;conventions and best practices&lt;/a&gt; for Dart, and the Flutter Framework in general.&lt;/li&gt;
&lt;li&gt;My personal &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki/500-Conclusion"&gt;evaluation of the framework&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-creation-context" class="anchor" aria-hidden="true" href="#creation-context"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Creation Context&lt;/h2&gt;
&lt;p&gt;This guide was written by a student in the Bachelor of Science Program “Computer Science and Media Technology” at Technical University Cologne &lt;a href="https://www.th-koeln.de/en/homepage_26.php" rel="nofollow"&gt;[8]&lt;/a&gt;, and it was created for one of the modules in that Bachelor. In addition to this, the guide was written in collaboration with DevonFw &lt;a href="https://devonfw.com/index.html" rel="nofollow"&gt;[9]&lt;/a&gt;. DevonFw released a guide on building an application with Angular &lt;a href="https://github.com/devonfw/devon4ng"&gt;[10]&lt;/a&gt; in May of 2019, this guide is meant to be the Flutter version of that.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-structure" class="anchor" aria-hidden="true" href="#structure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Structure&lt;/h2&gt;
&lt;p&gt;The guide is designed to be read in order, from chapter 0 (this one) to chapter 5. Code examples throughout the chapters will mainly be taken from Wisgen &lt;a href="https://github.com/Fasust/wisgen"&gt;[11]&lt;/a&gt;, an example Flutter application that was specifically built for the purposes of this guide. If you want to search for any specific terms in the guide, you can use &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki/gfm-guide"&gt;this page&lt;/a&gt;. It is all chapters of the guide combined into one page. There is going to be a few common symbols throughout the guide, this is what they stand for:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Symbol&lt;/th&gt;
&lt;th align="left"&gt;Meaning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;g-emoji class="g-emoji" alias="orange_book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d9.png"&gt;📙&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td align="left"&gt;Definition&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;g-emoji class="g-emoji" alias="clock1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f550.png"&gt;🕐&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td align="left"&gt;Shortened version (TLDR)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;⚠&lt;/td&gt;
&lt;td align="left"&gt;Important&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-my-sources" class="anchor" aria-hidden="true" href="#my-sources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;My Sources&lt;/h2&gt;
&lt;p&gt;I am basing this guide on a combination of conference talks, blog articles by respected Flutter developers, the official documentation, scientific papers that cover cross-platform mobile development in general and many other sources. All sources used in the guide are listed in chapter &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki/600-References"&gt;&lt;em&gt;6 References&lt;/em&gt;&lt;/a&gt;. To put that theoretical knowledge into practice, I built the Wisgen application &lt;a href="https://github.com/Fasust/wisgen"&gt;[11]&lt;/a&gt; using the Flutter Framework, the BLoC Pattern &lt;a href="https://www.youtube.com/watch?v=PLHln7wHgPE" rel="nofollow"&gt;[7]&lt;/a&gt;, and a four-layered architecture.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-creation-process" class="anchor" aria-hidden="true" href="#creation-process"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Creation Process&lt;/h2&gt;
&lt;p&gt;If your in interested in how this guide was created, how Wisgen was built, how a bridge between a citation software and Markdown was realized, or any other details about the creation process, check out the &lt;a href="https://github.com/devonfw-forge/devonfw4flutter/blob/master/Meta-Documentation.pdf"&gt;Meta-Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p align="right"&gt;&lt;a href="https://github.com/devonfw-forge/devonfw4flutter/wiki/100-The-Flutter-Framework"&gt;Next Chapter: The Flutter Framework &amp;gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align="center"&gt;&lt;a href="#"&gt;Back to Top&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>devonfw-forge</author><guid isPermaLink="false">https://github.com/devonfw-forge/devonfw4flutter</guid><pubDate>Thu, 28 Nov 2019 00:10:00 GMT</pubDate></item></channel></rss>