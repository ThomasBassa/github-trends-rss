<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Cuda, Today</title><link>https://github.com/trending/cuda?since=daily</link><description>The top repositories on GitHub for cuda, measured daily</description><pubDate>Tue, 10 Dec 2019 01:05:29 GMT</pubDate><lastBuildDate>Tue, 10 Dec 2019 01:05:29 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>chengdazhi/Deformable-Convolution-V2-PyTorch #1 in Cuda, Today</title><link>https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch</link><description>&lt;p&gt;&lt;i&gt;Deformable ConvNets V2 (DCNv2) in PyTorch&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deformable-convnets-v2-in-pytorch" class="anchor" aria-hidden="true" href="#deformable-convnets-v2-in-pytorch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deformable-ConvNets-V2 in PyTorch&lt;/h1&gt;
&lt;p&gt;This repo is an implementation of &lt;a href="https://arxiv.org/abs/1811.11168" rel="nofollow"&gt;Deformable Convolution V2&lt;/a&gt;.
Ported from the original &lt;a href="https://github.com/msracver/Deformable-ConvNets/tree/master/DCNv2_op"&gt;MXNet implementation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Refer to &lt;a href="https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch/tree/mmdetection"&gt;mmdetection branch&lt;/a&gt; in this repo for a complete framework. Results of DCNv2 based on mmdetection code base can be found at &lt;a href="https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch/blob/mmdetection/MODEL_ZOO.md#deformable-conv-v2"&gt;model zoo&lt;/a&gt;. Many thanks to &lt;a href="https://github.com/open-mmlab/mmdetection"&gt;mmdetection&lt;/a&gt; for their strong and clean framework.&lt;/p&gt;
&lt;p&gt;Operators in master branch are compatible with pytorch_v0.4.1. For operators on pytorch v1.0.0 (implemented by &lt;a href="https://github.com/xvjiarui"&gt;Jiarui Xu&lt;/a&gt;), please refer to &lt;a href="https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch/tree/pytorch_1.0.0"&gt;pytorch_1.0.0 branch&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thanks to &lt;a href="https://github.com/hellock"&gt;Kai Chen&lt;/a&gt; and other contributors from mmlab, DCNv2 is now included in the official mmdetection repo based on the master branch of this one. It is now written with the new cpp extension apis and it supports both PyTorch 0.4.1 and 1.0, with some minor speed and memory optimization. Results and models can be found at &lt;a href="https://github.com/open-mmlab/mmdetection/blob/master/MODEL_ZOO.md#deformable-convolution-v2"&gt;https://github.com/open-mmlab/mmdetection/blob/master/MODEL_ZOO.md#deformable-convolution-v2&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-build" class="anchor" aria-hidden="true" href="#build"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Build&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;sh make.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See &lt;code&gt;test.py&lt;/code&gt; and &lt;code&gt;test_modulated.py&lt;/code&gt; for example usage.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-notice" class="anchor" aria-hidden="true" href="#notice"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notice&lt;/h2&gt;
&lt;p&gt;This repo provides the deformable conv layer which can reproduce the results in the Deformable ConvNets v2 paper. The major changes are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;To better handle occasions where sampling locations are outside of the image boundary.&lt;/p&gt;
&lt;p&gt;In the previous operator, if the sampling location is outside of the feature map boundary, its sampled value would be zero. Thus, the gradient with respect to learnable offset would be zero. We found such a scheme may deteriate the performance in ImageNet classification (perhaps because the feature maps are of low resolution). For object detection on COCO, both the previous and the updated operators deliver the same results.&lt;/p&gt;
&lt;p&gt;In the new operator, if the sampling location is within one pixel outside of the feature map boundary, bilinear sampling would also be applied. And gradient with respect to learnable offset can be non zero for such locations. This is implemented by padding zeros (by one row/column) outside of the boundaries of feature maps, and performing bilinear sampling on the padded feature maps.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The efficiency of processing multiple images in a mini-batch is considerably improved.&lt;/p&gt;
&lt;p&gt;Both the previous and the updated operators follow the following computation pipeline (illustrated by a 3x3 deformable convolution with input data of NxCxHxW and output data of NxC'xHxW):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for i in range(N/S):
    step 1 (slicing): slicing the input data at the batch dimension from i*S to (i+1)*S, input (NxCxHxW) -&amp;gt; sliced input (SxCxHxW)
    step 2 (deformable im2col): sliced input (SxCxHxW)+sliced offset (Sx18xHxW) -&amp;gt; column (Cx9xSxHxW)
    step 3 (MatMul&amp;amp;reshape): weight matrix (C'x 9C) * column (9CxSHW) -&amp;gt; temp sliced output (C'xSxHxW) -&amp;gt; sliced output (SxC'xHxW)
    step 4 (Merge): merge sliced output to form the whole output data (NxC'xHxW) 
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the previous operator, S is fixed as 1. In the updated operator, S can be set by the &lt;em&gt;im2col_step&lt;/em&gt; parameter, whose default value is min(N, 64). The updated operator is significantly faster than the existing one when the image batch size is large.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>chengdazhi</author><guid isPermaLink="false">https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch</guid><pubDate>Tue, 10 Dec 2019 00:01:00 GMT</pubDate></item></channel></rss>