<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Jupyter Notebook, Today</title><link>https://github.com/trending/jupyter-notebook?since=daily</link><description>The top repositories on GitHub for jupyter-notebook, measured daily</description><pubDate>Sun, 09 Feb 2020 01:09:46 GMT</pubDate><lastBuildDate>Sun, 09 Feb 2020 01:09:46 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>xavier-zy/Awesome-pytorch-list-CNVersion #1 in Jupyter Notebook, Today</title><link>https://github.com/xavier-zy/Awesome-pytorch-list-CNVersion</link><description>&lt;p&gt;&lt;i&gt;Awesome-pytorch-list 翻译工作进行中......&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-awesome-pytorch-list厉害的pytorch项目" class="anchor" aria-hidden="true" href="#awesome-pytorch-list厉害的pytorch项目"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Awesome-Pytorch-list｜厉害的Pytorch项目&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/pytorch/pytorch/master/docs/source/_static/img/pytorch-logo-dark.png"&gt;&lt;img src="https://raw.githubusercontent.com/pytorch/pytorch/master/docs/source/_static/img/pytorch-logo-dark.png" alt="pytorch-logo-dark" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-english-version" class="anchor" aria-hidden="true" href="#english-version"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/bharathgs/Awesome-pytorch-list"&gt;English Version&lt;/a&gt;&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-contents内容" class="anchor" aria-hidden="true" href="#contents内容"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents｜内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#awesome-pytorch-list%EF%BD%9C%E5%8E%89%E5%AE%B3%E7%9A%84pytorch%E9%A1%B9%E7%9B%AE"&gt;Awesome-Pytorch-list｜厉害的Pytorch项目&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#english-version"&gt;English Version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contents%EF%BD%9C%E5%86%85%E5%AE%B9"&gt;Contents｜内容&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pytorch-related-libraries%EF%BD%9Cpytorch-%E7%9B%B8%E5%85%B3%E5%BA%93"&gt;Pytorch &amp;amp; related libraries｜Pytorch &amp;amp; 相关库&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#nlp-speech-processing%EF%BD%9C%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-%E8%AF%AD%E9%9F%B3%E5%A4%84%E7%90%86"&gt;NLP &amp;amp; Speech Processing｜自然语言处理 &amp;amp; 语音处理:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cv%EF%BD%9C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"&gt;CV｜计算机视觉:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#probabilisticgenerative-libraries%EF%BD%9C%E6%A6%82%E7%8E%87%E5%BA%93%E5%92%8C%E7%94%9F%E6%88%90%E5%BA%93"&gt;Probabilistic/Generative Libraries｜概率库和生成库:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other-libraries%EF%BD%9C%E5%85%B6%E4%BB%96%E5%BA%93"&gt;Other libraries｜其他库:&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#tutorials-examples%EF%BD%9C%E6%95%99%E7%A8%8B-%E7%A4%BA%E4%BE%8B"&gt;Tutorials &amp;amp; examples｜教程 &amp;amp; 示例&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#paper-implementations%EF%BD%9C%E8%AE%BA%E6%96%87%E5%AE%9E%E7%8E%B0"&gt;Paper implementations｜论文实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#talks-conferences%EF%BD%9C%E6%8A%A5%E5%91%8A-%E4%BC%9A%E8%AE%AE"&gt;Talks &amp;amp; conferences｜报告 &amp;amp; 会议&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pytorch-elsewhere-%EF%BD%9C-pytorch%E7%9B%B8%E5%85%B3"&gt;Pytorch elsewhere ｜ Pytorch相关&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-pytorch--related-librariespytorch--相关库" class="anchor" aria-hidden="true" href="#pytorch--related-librariespytorch--相关库"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pytorch &amp;amp; related libraries｜Pytorch &amp;amp; 相关库&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://pytorch.org" rel="nofollow"&gt;pytorch&lt;/a&gt;: Tensors and Dynamic neural networks in Python with strong GPU acceleration | 使用强GPU加速的Python张量计算和动态神经网络.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-nlp--speech-processing自然语言处理--语音处理" class="anchor" aria-hidden="true" href="#nlp--speech-processing自然语言处理--语音处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NLP &amp;amp; Speech Processing｜自然语言处理 &amp;amp; 语音处理:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;2000+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/text"&gt;text&lt;/a&gt;: 针对文本数据和NLP数据集的数据加载和抽象。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/IBM/pytorch-seq2seq"&gt;pytorch-seq2seq&lt;/a&gt;: Pytorch中处理seq2seq的开源框架。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Sandeep42/anuvada"&gt;anuvada&lt;/a&gt;: NLP可解释模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/audio"&gt;audio&lt;/a&gt;: 简单的音频I/O。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/loop"&gt;loop&lt;/a&gt;:  一种跨多说话者的语音生成方法。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;6000+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/fairseq-py"&gt;fairseq&lt;/a&gt;: Facebook开发的Sequence-to-Sequence python工具包。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/awni/speech"&gt;speech&lt;/a&gt;: 语音转文字的端到端模型实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3500+&lt;/kbd&gt; &lt;a href="https://github.com/OpenNMT/OpenNMT-py"&gt;OpenNMT-py&lt;/a&gt;: 开源神经机器翻译 &lt;a href="http://opennmt.net" rel="nofollow"&gt;http://opennmt.net&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/huggingface/neuralcoref"&gt;neuralcoref&lt;/a&gt;: 在spaCy中使用神经网络实现快速共指消解。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/sentiment-discovery"&gt;sentiment-discovery&lt;/a&gt;: 基于规模的无监督语言模型在稳健情绪分类中的应用。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2200+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/MUSE"&gt;MUSE&lt;/a&gt;: 一个多语言无监督或有监督词语嵌入库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/lium-lst/nmtpytorch"&gt;nmtpytorch&lt;/a&gt;: PyTorch中的Sequence-to-Sequence框架。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/vincentherrmann/pytorch-wavenet"&gt;pytorch-wavenet&lt;/a&gt;: 快速生成WaveNet的实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/soobinseo/Tacotron-pytorch"&gt;Tacotron-pytorch&lt;/a&gt;: Tacotron: 端到端语音合成。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;7400+&lt;/kbd&gt; &lt;a href="https://github.com/allenai/allennlp"&gt;AllenNLP&lt;/a&gt;: 开源NLP研究库，基于PyTorch。&lt;a href="https://allennlp.org" rel="nofollow"&gt;http://www.allennlp.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1500+&lt;/kbd&gt; &lt;a href="https://github.com/PetrochukM/PyTorch-NLP"&gt;PyTorch-NLP&lt;/a&gt;: 为加速NLP研究设立的一个库，包含神经网络层、文本处理模块和众多数据集。 pytorchnlp.readthedocs.io&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/outcastofmusic/quick-nlp"&gt;quick-nlp&lt;/a&gt;: 基于FastAI的Pytorch NLP库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/mozilla/TTS"&gt;TTS&lt;/a&gt;: 文本转语音的深度学习框架。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2000+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/LASER"&gt;LASER&lt;/a&gt;: LASER是一个用来计算和使用多语言语句嵌入的库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pyannote/pyannote-audio"&gt;pyannote-audio&lt;/a&gt;: 用于说话人分类的神经构建块：语音活动检测, 说话人变化检测, 说话人嵌入。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Maluuba/gensen"&gt;gensen&lt;/a&gt;: 基于大规模多任务学习的通用句子表示。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/translate"&gt;translate&lt;/a&gt;: 翻译——一个PyTorch语言库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1500+&lt;/kbd&gt; &lt;a href="https://github.com/espnet/espnet"&gt;espnet&lt;/a&gt;: 端到端语音处理工具集。 espnet.github.io/espnet&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2800+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/pythia"&gt;pythia&lt;/a&gt;: 源于FAIR(Facebook AI Research)的视觉与语言多模态研究的模块化框架。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/UnsupervisedMT"&gt;UnsupervisedMT&lt;/a&gt;: 基于短语的神经无监督机器翻译。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jsalt18-sentence-repl/jiant"&gt;jiant&lt;/a&gt;: 通用文本理解模型的jiant工具包。&lt;a href="https://jiant.info" rel="nofollow"&gt;https://jiant.info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2900+&lt;/kbd&gt; &lt;a href="https://github.com/codertimo/BERT-pytorch"&gt;BERT-PyTorch&lt;/a&gt;: Google AI 2018 BERT 的 Pytorch 实现，伴有简单注释。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/InferSent"&gt;InferSent&lt;/a&gt;: NLI的句子嵌入(InferSent)和训练代码。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/google/uis-rnn"&gt;uis-rnn&lt;/a&gt;:无限交错状态递归神经网络(UIS-RNN)算法，能够从嘈杂的环境中分辨声音，对应论文 Fully Supervised Speaker Diarization. arxiv.org/abs/1810.04719&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;7500+&lt;/kbd&gt; &lt;a href="https://github.com/zalandoresearch/flair"&gt;flair&lt;/a&gt;: 一个针对最先进的NLP的简单框架。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5500+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/pytext"&gt;pytext&lt;/a&gt;: 基于PyTorch的自然语言建模框架。 fb.me/pytextdocs&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/mindslab-ai/voicefilter"&gt;voicefilter&lt;/a&gt;: 谷歌AI的VoiceFilter的非官方实现。 &lt;a href="http://swpark.me/voicefilter" rel="nofollow"&gt;http://swpark.me/voicefilter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kamalkraj/BERT-NER"&gt;BERT-NER&lt;/a&gt;: 基于BERT的命名体识别(Named-Entity-Recognition)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/feedly/transfer-nlp"&gt;transfer-nlp&lt;/a&gt;: 为可复制实验管理而设计的NLP库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/asyml/texar-pytorch"&gt;texar-pytorch&lt;/a&gt;: 机器学习和文本生成工具包。 texar.io&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/mravanelli/pytorch-kaldi"&gt;pytorch-kaldi&lt;/a&gt;: pytorch-kaldi 是一个开发中的最先进的dnn/rnn混合语音识别系统。其DNN部分由PyTorch实现，而特征提取、标签计算和解码由kaldi工具包完成。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/NVIDIA/NeMo"&gt;NeMo&lt;/a&gt;: 神经模块：对话式AI（conversational AI）工具集 nvidia.github.io/NeMo&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/harvardnlp/pytorch-struct"&gt;pytorch-struct&lt;/a&gt;: 经过测试的GPU实现库，实现了深度学习中的一些核心的结构化算法，如HMM, Dep Trees, CKY, ...&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/freewym/espresso"&gt;espresso&lt;/a&gt;: Espresso: 快速的端到端神经语音识别工具集。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huggingface/transformers"&gt;transformers&lt;/a&gt;: huggingface Transformers: TensorFlow 2.0  和 PyTorch 上最先进的NLP工具。huggingface.co/transformers&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lucidrains/reformer-pytorch"&gt;reformer-pytorch&lt;/a&gt;: &lt;a href="https://openreview.net/pdf?id=rkgNKkHtvB" rel="nofollow"&gt;Reformer&lt;/a&gt; 的 PyTorch 版。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-cv计算机视觉" class="anchor" aria-hidden="true" href="#cv计算机视觉"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CV｜计算机视觉:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;4800+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/vision"&gt;pytorch vision&lt;/a&gt;: TorchVision包含流行的数据集、模型架构、计算机视觉中常用的图像变换。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tymokvo/pt-styletransfer"&gt;pt-styletransfer&lt;/a&gt;: 作为PyTorch中一个类的神经风格转移。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/thnkim/OpenFacePytorch"&gt;OpenFacePytorch&lt;/a&gt;: 使用OpenFace的nn4.small2.v1.t7模型的PyTorch模块。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/felixgwu/img_classification_pk_pytorch"&gt;img_classification_pk_pytorch&lt;/a&gt;: 将你的图像分类模型和最先进的模型进行快速比较 (比如DenseNet, ResNet, ...)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/SparseConvNet"&gt;SparseConvNet&lt;/a&gt;: 子流形稀疏卷积神经网络。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/automan000/Convolution_LSTM_pytorch"&gt;Convolution_LSTM_pytorch&lt;/a&gt;: 多层卷积LSTM(长短期记忆网络)模块。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3200+&lt;/kbd&gt; &lt;a href="https://github.com/1adrianb/face-alignment"&gt;face-alignment&lt;/a&gt;: &lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;🔥&lt;/g-emoji&gt; 基于 PyTorch 的 2D 和 3D 面部对齐库。 adrianbulat.com&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/ZijunDeng/pytorch-semantic-segmentation"&gt;pytorch-semantic-segmentation&lt;/a&gt;: 语义分割。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/longcw/RoIAlign.pytorch"&gt;RoIAlign.pytorch&lt;/a&gt;: PyTorch版本的RoIAlign。其实现基于crop_and_resize，支持CPU和GPU上的前向和后向。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/creafz/pytorch-cnn-finetune"&gt;pytorch-cnn-finetune&lt;/a&gt;: 用PyTorch微调预训练卷积神经网络。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ignacio-rocco/detectorch"&gt;detectorch&lt;/a&gt;: Detectorch - PyTorch版detectron框架，目前仅有detectron的推断(inference)和评估(evalutaion)功能，无训练(training)功能。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3500+&lt;/kbd&gt; &lt;a href="https://github.com/mdbloice/Augmentor"&gt;Augmentor&lt;/a&gt;: 用于机器学习的图像增强库。 &lt;a href="http://augmentor.readthedocs.io" rel="nofollow"&gt;http://augmentor.readthedocs.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jonas-koehler/s2cnn"&gt;s2cnn&lt;/a&gt;: Spherical CNNs：球面卷积网络的PyTorch实现。 (e.g. 全方位图像、全球信号)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnyyou/torchcv"&gt;TorchCV&lt;/a&gt;: 基于PyTorch的计算机视觉深度学习框架。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;6800+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/maskrcnn-benchmark"&gt;maskrcnn-benchmark&lt;/a&gt;: 实例分割与对象检测的快速模块化参考实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/osmr/imgclsmob"&gt;image-classification-mobile&lt;/a&gt;: 计算机视觉卷积网络训练沙盒，包含ImageNet-1K上的与训练分类模型集合。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/perone/medicaltorch"&gt;medicaltorch&lt;/a&gt;: 一个医学成像框架。&lt;a href="http://medicaltorch.readthedocs.io" rel="nofollow"&gt;http://medicaltorch.readthedocs.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3800+&lt;/kbd&gt; &lt;a href="https://github.com/albu/albumentations"&gt;albumentations&lt;/a&gt;: 快速图像增强库和其他库的易用包装器。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/arraiyopensource/kornia"&gt;kornia&lt;/a&gt;: 开源可微计算机视觉库。&lt;a href="https://kornia.org" rel="nofollow"&gt;https://kornia.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/s3nh/text-detector"&gt;text-detector&lt;/a&gt;: 检测和翻译文本。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/timesler/facenet-pytorch"&gt;facenet-pytorch&lt;/a&gt;: 预训练Pytorch人脸检测与识别模型，从 &lt;a href="https://github.com/davidsandberg/facenet"&gt;davidsandberg/facenet&lt;/a&gt; 移植而来。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/detectron2"&gt;detectron2&lt;/a&gt;: Detectron2是FAIR的下一代目标检测和分割研究平台。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Media-Smart/vedaseg"&gt;vedaseg&lt;/a&gt;: 基于PyTorch的语义分割工具箱。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/ClassyVision"&gt;ClassyVision&lt;/a&gt;: A用于图像和视频分类的端到端PyTorch框架。&lt;a href="https://classyvision.ai" rel="nofollow"&gt;https://classyvision.ai&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/alankbi/detecto"&gt;detecto&lt;/a&gt;: 用 5 行代码构建功能完备的计算机视觉模型。&lt;a href="https://detecto.readthedocs.io/" rel="nofollow"&gt;https://detecto.readthedocs.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/pytorch3d"&gt;pytorch3d&lt;/a&gt;: PyTorch3d 是一个面向深度学习的高效、可复用的 3D 计算机视觉库。 &lt;a href="https://pytorch3d.org/" rel="nofollow"&gt;https://pytorch3d.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-probabilisticgenerative-libraries概率库和生成库" class="anchor" aria-hidden="true" href="#probabilisticgenerative-libraries概率库和生成库"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Probabilistic/Generative Libraries｜概率库和生成库:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/stepelu/ptstat"&gt;ptstat&lt;/a&gt;: 概率编程和统计推断。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5700+&lt;/kbd&gt; &lt;a href="https://github.com/uber/pyro"&gt;pyro&lt;/a&gt;: 基于 Python 和 PyTorch 的深度通用概率编程库。 &lt;a href="http://pyro.ai" rel="nofollow"&gt;http://pyro.ai&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/probtorch/probtorch"&gt;probtorch&lt;/a&gt;: Probabilistic Torch是一个扩展了PyTorch的深度生成模型的库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/drckf/paysage"&gt;paysage&lt;/a&gt;: 基于Python/PyTorch的非监督学习和生成模型库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ctallec/pyvarinf"&gt;pyvarinf&lt;/a&gt;: Python包，促进了带有变分推断的贝叶斯深度学习方法在pytorch中的应用。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/probprog/pyprob"&gt;pyprob&lt;/a&gt;: 一个基于PyTorch的概率编程与推断编译的库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/spring-epfl/mia"&gt;mia&lt;/a&gt;: 一个运行针对机器学习模型的成员推理攻击的库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/akanimax/pro_gan_pytorch"&gt;pro_gan_pytorch&lt;/a&gt;: 作为PyTorch nn.Module的扩展的ProGAN包。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1300+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/botorch"&gt;botorch&lt;/a&gt;: PyTorch中的贝叶斯优化。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-other-libraries其他库" class="anchor" aria-hidden="true" href="#other-libraries其他库"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other libraries｜其他库:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mrdrozdov/pytorch-extras"&gt;pytorch extras&lt;/a&gt;: PyTorch的额外特性。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/szagoruyko/functional-zoo"&gt;functional zoo&lt;/a&gt;: PyTorch和Tensorflow的模型定义和预训练权重。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1300+&lt;/kbd&gt; &lt;a href="https://github.com/ncullen93/torchsample"&gt;torch-sampling&lt;/a&gt;: Pytorch的采样、高级训练、数据增强和实用程序。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/deepcraft/torchcraft-py"&gt;torchcraft-py&lt;/a&gt;: TorchCraft的Python包装器，TorchCraft是连接Torch和StarCraft的桥梁。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ramon-oliveira/aorun"&gt;aorun&lt;/a&gt;: Aorun试图以PyTorch为后端实现类似于Keras的API。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/oval-group/logger"&gt;logger&lt;/a&gt;: 机器学习记录器（logger）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/iamaziz/PyTorch-docset"&gt;PyTorch-docset&lt;/a&gt;: PyTorch离线文档，结合Dash，Zeal，Velocity或者LovelyDocs使用。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/clcarwin/convert_torch_to_pytorch"&gt;convert_torch_to_pytorch&lt;/a&gt;: 将Torch t7模型转换为PyTorch模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5500+&lt;/kbd&gt; &lt;a href="https://github.com/Cadene/pretrained-models.pytorch"&gt;pretrained-models.pytorch&lt;/a&gt;: PyTorch 预训练卷积神经网络：NASNet, ResNeXt, ResNet, InceptionV4, InceptionResnetV2, Xception, DPN 等等。该项目的目标是帮助复制研究论文结果。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/locuslab/pytorch_fft"&gt;pytorch_fft&lt;/a&gt;: CUDA FFTs的PyTorch包装器。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fanq15/caffe_to_torch_to_pytorch"&gt;caffe_to_torch_to_pytorch&lt;/a&gt;: Caffe模型转PyTorch/Torch模型，Torch模型转PyTorch模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/sniklaus/pytorch-extension"&gt;pytorch-extension&lt;/a&gt;: PyTorch的CUDA扩展示例，计算了两个张量的&lt;a href="https://baike.baidu.com/item/%E5%93%88%E8%BE%BE%E7%8E%9B%E7%A7%AF/18894493?fr=aladdin" rel="nofollow"&gt;哈达玛积(Hadamard product)&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5700+&lt;/kbd&gt; &lt;a href="https://github.com/lanpa/tensorboard-pytorch"&gt;tensorboard-pytorch&lt;/a&gt;: 该模块以tensorboard格式保存PyTorch张量以供检查。目前支持tensorboard中的标量、图像、音频、直方图等特性。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/jrg365/gpytorch"&gt;gpytorch&lt;/a&gt;: GPyTorch是一个用PyTorch实现的高斯过程库。它可以轻松地创建可伸缩、灵活和模块化的高斯过程模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1900+&lt;/kbd&gt; &lt;a href="https://github.com/maciejkula/spotlight"&gt;spotlight&lt;/a&gt;: 深度推荐模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/awentzonline/pytorch-cns"&gt;pytorch-cns&lt;/a&gt;: 基于PyTorch的广义压缩网络搜索（Generalized &lt;a href="http://people.idsia.ch/~juergen/compressednetworksearch.html" rel="nofollow"&gt;Compressed Network Search&lt;/a&gt;）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/szagoruyko/pyinn"&gt;pyinn&lt;/a&gt;: CuPy实现融合PyTorch操作。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/nasimrahaman/inferno"&gt;inferno&lt;/a&gt;: 关于PyTorch的实用程序库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/henryre/pytorch-fitmodule"&gt;pytorch-fitmodule&lt;/a&gt;: 一种用于PyTorch模块的超简单拟合方法。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2600+&lt;/kbd&gt; &lt;a href="https://github.com/dnouri/inferno"&gt;inferno-sklearn&lt;/a&gt;: 一个基于PyTorch封装且兼容scikit-learn的神经网络库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/marvis/pytorch-caffe-darknet-convert"&gt;pytorch-caffe-darknet-convert&lt;/a&gt;: 在 pytorch, caffe prototxt/weights 和 darknet cfg/weights 之间转换。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/longcw/pytorch2caffe"&gt;pytorch2caffe&lt;/a&gt;: 将PyTorch模型转换成Caffe模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/nearai/pytorch-tools"&gt;pytorch-tools&lt;/a&gt;: PyTorch工具。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/taolei87/sru"&gt;sru&lt;/a&gt;: 训练RNNs和训练CNNs一样快。 (arxiv.org/abs/1709.02755)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/prisma-ai/torch2coreml"&gt;torch2coreml&lt;/a&gt;: Torch7 -&amp;gt; CoreML，该工具可将Torch7模型转换为&lt;a href="https://developer.apple.com/documentation/coreml" rel="nofollow"&gt;Apple CoreML&lt;/a&gt;格式以便在Apple设备上运行。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/zhanghang1989/PyTorch-Encoding"&gt;PyTorch-Encoding&lt;/a&gt;: PyTorch 深度纹理编码网络 (Deep Texture Encoding Network) &lt;a href="http://hangzh.com/PyTorch-Encoding" rel="nofollow"&gt;http://hangzh.com/PyTorch-Encoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ryanleary/pytorch-ctc"&gt;pytorch-ctc&lt;/a&gt;: PyTorch-CTC 实现了CTC(联结主义时间分类，Connectionist Temporal Classification)集束搜索（Beam Search）解码。C++代码借鉴了TensorFlow，并通过一些改进增加了灵活性。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/t-vi/candlegp"&gt;candlegp&lt;/a&gt;: Pytorch中的高斯过程。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/loudinthecloud/dpwa"&gt;dpwa&lt;/a&gt;: 基于成对平均（Pair-Wise Averaging）的分布式学习。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/koz4k/dni-pytorch"&gt;dni-pytorch&lt;/a&gt;: 基于合成梯度的PyTorch解耦神经接口。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2600+&lt;/kbd&gt; &lt;a href="https://github.com/dnouri/skorch"&gt;skorch&lt;/a&gt;: 一个基于PyTorch封装且兼容scikit-learn的神经网络库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2300+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/ignite"&gt;ignite&lt;/a&gt;: Ignite是一个高级库，帮助你在PyTorch中训练神经网络。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/glample/Arnold"&gt;Arnold&lt;/a&gt;: Arnold - DOOM 游戏代理。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/albanie/pytorch-mcn"&gt;pytorch-mcn&lt;/a&gt;: 将MatConvNet模型转换为PyTorch模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1900+&lt;/kbd&gt; &lt;a href="https://github.com/chenyuntc/simple-faster-rcnn-pytorch"&gt;simple-faster-rcnn-pytorch&lt;/a&gt;: Faster R-CNN 的简化实现，性能与原始论文相当。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/DL-IT/generative_zoo"&gt;generative_zoo&lt;/a&gt;: generative_zoo提供了PyTorch中一些生成模型的工作实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/szagoruyko/pytorchviz"&gt;pytorchviz&lt;/a&gt;: 可视化PyTorch的运行图。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/cogitare-ai/cogitare"&gt;cogitare&lt;/a&gt;: Cogitare - 一个现代、快速、模块化的深度学习和机器学习框架。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dmarnerides/pydlt"&gt;pydlt&lt;/a&gt;: 基于PyTorch的深度学习工具箱。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wohlert/semi-supervised-pytorch"&gt;semi-supervised-pytorch&lt;/a&gt;: 各种基于VAE的半监督模型和生成模型的实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rusty1s/pytorch_cluster"&gt;pytorch_cluster&lt;/a&gt;: 优化图簇算法的PyTorch扩展库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/aditya-khant/neural-assembly-compiler"&gt;neural-assembly-compiler&lt;/a&gt;: 基于自适应神经编译的PyTorch神经汇编编译器。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/vadimkantorov/caffemodel2pytorch"&gt;caffemodel2pytorch&lt;/a&gt;: 将Caffe模型转换为PyTorch模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/extension-cpp"&gt;extension-cpp&lt;/a&gt;: PyTorch中的C++扩展。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/GRAAL-Research/pytoune"&gt;pytoune&lt;/a&gt;: 类Keras框架和实用程序。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dusty-nv/jetson-reinforcement"&gt;jetson-reinforcement&lt;/a&gt;: 使用PyTorch，OpenAI Gym和Gazebo机器人模拟的NVIDIA Jetson深度强化学习GPU库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/salesforce/matchbox"&gt;matchbox&lt;/a&gt;: 编写单个示例的PyTorch代码，然后小批量地高效运行。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/josipd/torch-two-sample"&gt;torch-two-sample&lt;/a&gt;: PyTorch双样本测试库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/sksq96/pytorch-summary"&gt;pytorch-summary&lt;/a&gt;: PyTorch模型总结，类似于Keras中的&lt;code&gt;model.summary()&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BelBES/mpl.pytorch"&gt;mpl.pytorch&lt;/a&gt;: MaxPoolingLoss的PyTorch实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/YosefLab/scVI-dev"&gt;scVI-dev&lt;/a&gt;: 链接失效。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2800+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/apex"&gt;apex&lt;/a&gt;: 一个PyTorch扩展：面向精简混合精度和分布式训练。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2900+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/ELF"&gt;ELF&lt;/a&gt;: ELF: 游戏研究平台，复现了AlphaGoZero/AlphaZero。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/EKami/Torchlite"&gt;Torchlite&lt;/a&gt;: Pytorch建立在sklearn、Pytorch和Tensorflow等流行机器学习框架上的高水平库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Schlumberger/joint-vae"&gt;joint-vae&lt;/a&gt;: JointVAE的PyTorch实现，一个面向分离连续和离散变异因素的框架 &lt;g-emoji class="g-emoji" alias="star2" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png"&gt;🌟&lt;/g-emoji&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kengz/SLM-Lab"&gt;SLM-Lab&lt;/a&gt;: PyTorch模块化深度强化学习框架。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Hananel-Hazan/bindsnet"&gt;bindsnet&lt;/a&gt;: 一个Python包，可借助PyTorch &lt;code&gt;Tensor&lt;/code&gt; 功能在CPUs或GPUs上模拟脉冲神经网络(SNNs, Spiking Neural Networks)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/akanimax/pro_gan_pytorch"&gt;pro_gan_pytorch&lt;/a&gt;: 作为 PyTorch nn.Module 扩展的 ProGAN 包。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5600+&lt;/kbd&gt; &lt;a href="https://github.com/rusty1s/pytorch_geometric"&gt;pytorch_geometric&lt;/a&gt;: PyTorch几何深度学习扩展库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/knighton/torchplus"&gt;torchplus&lt;/a&gt;: 在 PyTorch modules 上实现 + 运算符，返回序列。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zuoxingdong/lagom"&gt;lagom&lt;/a&gt;: lagom: 用于强化学习算法快速原型构建的轻量级PyTorch架构。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ecs-vlc/torchbearer"&gt;torchbearer&lt;/a&gt;: torchbearer: PyTorch模型拟合库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tristandeleu/pytorch-maml-rl"&gt;pytorch-maml-rl&lt;/a&gt;: 强化学习中的模型不可知元学习(MAML, Model-Agnostic Meta-Learning)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/bharathgs/NALU"&gt;NALU&lt;/a&gt;: 神经算术逻辑单元(Neural Arithmetic Logic Units)的PyTorch基本实现，论文：arxiv.org/pdf/1808.00508.pdf 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/PIQuIL/QuCumber"&gt;QuCumber&lt;/a&gt;: 神经网络多体波函数重构。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/MagNet-DL/magnet"&gt;magnet&lt;/a&gt;: 自我建立的深度学习项目。&lt;a href="http://magnet-dl.readthedocs.io/" rel="nofollow"&gt;http://magnet-dl.readthedocs.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jbohnslav/opencv_transforms"&gt;opencv_transforms&lt;/a&gt;: OpenCV实现Torchvision的图像分割。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;16100+&lt;/kbd&gt; &lt;a href="https://github.com/fastai/fastai"&gt;fastai&lt;/a&gt;: fast.ai 深度学习库、课程和教程。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/RobotLocomotion/pytorch-dense-correspondence"&gt;pytorch-dense-correspondence&lt;/a&gt;: &lt;a href="arxiv.org/pdf/1806.08756.pdf"&gt;《Dense Object Nets: Learning Dense Visual Object Descriptors By and For Robotic Manipulation》&lt;/a&gt; 一文的代码。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/richzhang/colorization-pytorch"&gt;colorization-pytorch&lt;/a&gt;: PyTorch实现交互式深度着色(Interactive Deep Colorization)。 richzhang.github.io/ideepcolor&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/cms-flash/beauty-net"&gt;beauty-net&lt;/a&gt;: PyTorch一个简单、灵活、可扩展的PyTorch模板。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Mariewelt/OpenChem"&gt;OpenChem&lt;/a&gt;: OpenChem: 面向计算化学和药物设计研究的深度学习工具包 mariewelt.github.io/OpenChem 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/aiqm/torchani"&gt;torchani&lt;/a&gt;: PyTorch精确神经网络电位。 aiqm.github.io/torchani&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hjmshi/PyTorch-LBFGS"&gt;PyTorch-LBFGS&lt;/a&gt;: PyTorch实现L-BFGS。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/cornellius-gp/gpytorch"&gt;gpytorch&lt;/a&gt;: PyTorch中对高斯过程的高效且模块化的实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mariogeiger/hessian"&gt;hessian&lt;/a&gt;: PyTorch版hessian。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/MillionIntegrals/vel"&gt;vel&lt;/a&gt;: 深度学习研究中的速度。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/msamogh/nonechucks"&gt;nonechucks&lt;/a&gt;: 动态地处理数据集中的坏样本，使用转换作为过滤器。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Swall0w/torchstat"&gt;torchstat&lt;/a&gt;: PyTorch中的模型分析器。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/QNNPACK"&gt;QNNPACK&lt;/a&gt;: 量化神经网络包—量化神经网络算子的移动优化实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2600+&lt;/kbd&gt; &lt;a href="https://github.com/rtqichen/torchdiffeq"&gt;torchdiffeq&lt;/a&gt;: PyTorch解常微分方程（ODE），使用的是全GPU支持、O(1)内存复杂度的反向传播算法。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BachiLi/redner"&gt;redner&lt;/a&gt;: 可微的 Monte Carlo 路径跟踪器。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/masa-su/pixyz"&gt;pixyz&lt;/a&gt;: 一个库，用来以更简洁、直观和可扩展的方式开发深层生成模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/perone/euclidesdb"&gt;euclidesdb&lt;/a&gt;: 一种多模型机器学习特征嵌入数据库。 &lt;a href="http://euclidesdb.readthedocs.io" rel="nofollow"&gt;http://euclidesdb.readthedocs.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/nerox8664/pytorch2keras"&gt;pytorch2keras&lt;/a&gt;: 将PyTorch模型转换为Keras模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/domainadaptation/salad"&gt;salad&lt;/a&gt;: 域适应和半监督学习工具箱。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Erotemic/netharn"&gt;netharn&lt;/a&gt;: PyTorch的参数化拟合和预测线束（Prediction Harnesses）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3200+&lt;/kbd&gt; &lt;a href="https://github.com/dmlc/dgl"&gt;dgl&lt;/a&gt;: Python包，基于现有的DL框架，用于简化对图形的深度学习。&lt;a href="http://dgl.ai" rel="nofollow"&gt;http://dgl.ai&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/CSAILVision/gandissect"&gt;gandissect&lt;/a&gt;: 基于PyTorch的工具，用于可视化和理解GAN的神经元。gandissect.csail.mit.edu&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/justusschock/delira"&gt;delira&lt;/a&gt;: 基于PyTorch和Tensorlow的快速原型和训练深层神经网络的轻量级框架，用于医疗成像。 delira.rtfd.io&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/AIRLab-POLIMI/mushroom"&gt;mushroom&lt;/a&gt;: 强化学习实验的Python库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/thuml/Xlearn"&gt;Xlearn&lt;/a&gt;: 迁移学习库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ferrine/geoopt"&gt;geoopt&lt;/a&gt;: 基于PyTorch优化的黎曼自适应优化方法。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/unit8co/vegans"&gt;vegans&lt;/a&gt;: 包含多种现有的GANs。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/arraiyopensource/kornia"&gt;kornia&lt;/a&gt;: PyTorch开源可微计算机视觉库。 &lt;a href="https://kornia.org" rel="nofollow"&gt;https://kornia.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BorealisAI/advertorch"&gt;AdverTorch&lt;/a&gt;: 研究对抗鲁棒性的工具箱。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2500+&lt;/kbd&gt; &lt;a href="https://github.com/Luolc/AdaBound"&gt;AdaBound&lt;/a&gt;: 一个优化器，训练速度和Adam一样快，和SGD一样好。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mblondel/fenchel-young-losses"&gt;fenchel-young-losses&lt;/a&gt;: 在PyTorch/TensorFlow/scikit-learn中使用Fenchel-Young损失作为概率分类的损失函数。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/Lyken17/pytorch-OpCounter"&gt;pytorch-OpCounter&lt;/a&gt;: 统计PyTorch模型的MACs/FLOPs。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kaihsin/Tor10"&gt;Tor10&lt;/a&gt;: 基于PyTorch，为量子模拟设计的通用张量网络库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/catalyst-team/catalyst"&gt;Catalyst&lt;/a&gt;: PyTorch DL&amp;amp;RL 研究的高级实用程序。它的开发重点是可重复性、快速实验和代码/思想重用。能够研究/开发新的东西，而不是编写另一个常规的训练循环。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebook/Ax"&gt;Ax&lt;/a&gt;: 自适应实验平台。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/achaiah/pywick"&gt;pywick&lt;/a&gt;: 高水平的PyTorch神经网络训练库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kakaobrain/torchgpipe"&gt;torchgpipe&lt;/a&gt;: PyTorch实现GPipe。 torchgpipe.readthedocs.io&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/hub"&gt;hub&lt;/a&gt;: Pytorch Hub 是一个预训练模型库，用来提升研究的可重复性。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2700+&lt;/kbd&gt; &lt;a href="https://github.com/williamFalcon/pytorch-lightning"&gt;pytorch-lightning&lt;/a&gt;: 面向ML研究人员的轻量级PyTorch包装器。缩放模型，少写样板。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kaihsin/Tor10"&gt;Tor10&lt;/a&gt;: 基于pytorch为量子模拟设计的通用张量网络库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2500+&lt;/kbd&gt; &lt;a href="https://github.com/microsoft/tensorwatch"&gt;tensorwatch&lt;/a&gt;: 针对Python机器学习与数据科学的调试、监控与可视化。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fancompute/wavetorch"&gt;wavetorch&lt;/a&gt;: 波动方程的数值求解与反传播。 arxiv.org/abs/1904.12831&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ag14774/diffdist"&gt;diffdist&lt;/a&gt;: diffdist是一个面向PyTorch的Python库。它扩展了&lt;code&gt;torch.autograd&lt;/code&gt;的默认功能，并增加了对进程间可微通信的支持。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/awwong1/torchprof"&gt;torchprof&lt;/a&gt;: 用于Pytorch模型逐层分析的最小依赖库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/oxfordcontrol/osqpth"&gt;osqpth&lt;/a&gt;: PyTorch可微OSQP求解器。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mctorch/mctorch"&gt;mctorch&lt;/a&gt;: 面向深度学习的流形优化库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/noahgolmant/pytorch-hessian-eigenthings"&gt;pytorch-hessian-eigenthings&lt;/a&gt;: 使用Hessian向量积和随机幂迭代的高效PyTorch Hessian特征分解。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/StanfordVL/MinkowskiEngine"&gt;MinkowskiEngine&lt;/a&gt;: 闵可夫斯基引擎是一个用于广义稀疏卷积和高维稀疏张量的自动微分方法库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Omegastick/pytorch-cpp-rl"&gt;pytorch-cpp-rl&lt;/a&gt;: CppRl是一个强化学习框架，用 PyTorch C++ 前端编写。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BloodAxe/pytorch-toolbelt"&gt;pytorch-toolbelt&lt;/a&gt;: PyTorch扩展，用来进行快速R&amp;amp;D原型开发和Kaggle代码收集。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Fonbet/argus-tensor-stream"&gt;argus-tensor-stream&lt;/a&gt;: 一个库，用来将实时视频流解码至CUDA内存。tensorstream.argus-ai.com&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hal3/macarico"&gt;macarico&lt;/a&gt;: 在 PyTorch 中学习搜索。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/astooke/rlpyt"&gt;rlpyt&lt;/a&gt;: PyTorch 中的强化学习。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/blue-season/pywarm"&gt;pywarm&lt;/a&gt;: 为 PyTorch 建立神经网络的一种更清洁的方法。&lt;a href="https://blue-season.github.io/pywarm/" rel="nofollow"&gt;https://blue-season.github.io/pywarm/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/learnables/learn2learn"&gt;learn2learn&lt;/a&gt;: PyTorch元学习框架。&lt;a href="http://learn2learn.net" rel="nofollow"&gt;http://learn2learn.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/torchbeast"&gt;torchbeast&lt;/a&gt;: 分布式强化学习的PyTorch平台。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/higher"&gt;higher&lt;/a&gt;: higher 是一个PyTorch库，允许用户获得跨越训练循环而不是单个训练步骤的损失的高阶梯度。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Vermeille/Torchelie/"&gt;Torchelie&lt;/a&gt;: Torchélie 是面向PyTorch的一系列工具函数、层、损失、模型、训练器等的合集。 &lt;a href="https://torchelie.readthedocs.org/" rel="nofollow"&gt;https://torchelie.readthedocs.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/CrypTen"&gt;CrypTen&lt;/a&gt;: CrypTen 是一个隐私保护机器学习框架，它使用PyTorch编写，允许研究人员和开发人员使用加密数据训练模型。CrypTen目前支持将安全的多方计算（&lt;a href="https://en.wikipedia.org/wiki/Secure_multi-party_computation" rel="nofollow"&gt;Secure Multiparty Computation&lt;/a&gt;）作为其加密机制。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cvxgrp/cvxpylayers"&gt;cvxpylayers&lt;/a&gt;: cvxpylayers 是一个 Python 库，用于在PyTorch中构造可微凸优化层。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/HobbitLong/RepDistiller"&gt;RepDistiller&lt;/a&gt;: 对比表示蒸馏（CRD）和最新知识蒸馏方法的基准。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/NVIDIAGameWorks/kaolin"&gt;kaolin&lt;/a&gt;: 一个旨在加速3D深度学习研究的PyTorch库。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/BasBuller/PySNN"&gt;PySNN&lt;/a&gt;: 高效的尖峰神经网络框架，建立在PyTorch之上，用于GPU加速。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dmmiller612/sparktorch"&gt;sparktorch&lt;/a&gt;: 在 Apache Spark 上训练和运行 PyTorch 模型。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/KevinMusgrave/pytorch-metric-learning"&gt;pytorch-metric-learning&lt;/a&gt;: 在应用程序中使用度量学习的最简单方法。模块化，灵活，可扩展。用 PyTorch 构建。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cpnota/autonomous-learning-library"&gt;autonomous-learning-library&lt;/a&gt;: 用于建立深度强化学习代理的 PyTorch 库。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/asappresearch/flambe"&gt;flambe&lt;/a&gt;: 一个用于加速研究及其生产路径的ML框架。&lt;a href="https://flambe.ai" rel="nofollow"&gt;https://flambe.ai&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-tutorials--examples教程--示例" class="anchor" aria-hidden="true" href="#tutorials--examples教程--示例"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorials &amp;amp; examples｜教程 &amp;amp; 示例&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;3500+&lt;/kbd&gt; &lt;strong&gt;&lt;a href="https://github.com/spro/practical-pytorch"&gt;Practical Pytorch&lt;/a&gt;&lt;/strong&gt;: 该教程对不同的RNN模型进行了解释。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pytorch.org/tutorials/beginner/deep_learning_nlp_tutorial.html" rel="nofollow"&gt;DeepLearningForNLPInPytorch&lt;/a&gt;: IPython Notebook 深度学习教程，包含对自然语言处理的强调。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;13100+&lt;/kbd&gt; &lt;a href="https://github.com/yunjey/pytorch-tutorial"&gt;pytorch-tutorial&lt;/a&gt;: 面向研究人员的深度学习教程，其中大部分模型的实现代码都少于30行。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/keon/pytorch-exercises"&gt;pytorch-exercises&lt;/a&gt;: PyTorch练习集合。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2600+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/tutorials"&gt;pytorch tutorials&lt;/a&gt;: 各种PyTorch教程。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;9900+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/examples"&gt;pytorch examples&lt;/a&gt;:  PyTorch使用示例，应用场景包括视觉、文本、强化学习等。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/napsternxg/pytorch-practice"&gt;pytorch practice&lt;/a&gt;: PyTorch示例。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/vinhkhuc/PyTorch-Mini-Tutorials"&gt;pytorch mini tutorials&lt;/a&gt;: PyTorch极简教程，改编自Alec Radford的&lt;a href="https://github.com/Newmu/Theano-Tutorials"&gt;Theano教程&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/xiayandi/Pytorch_text_classification"&gt;pytorch text classification&lt;/a&gt;: PyTorch实现基于CNN的文本分类。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/desimone/pytorch-cat-vs-dogs"&gt;cats vs dogs&lt;/a&gt;: Kaggle 竞赛 Dogs vs. Cats Redux: Kernels Edition 的网络微调示例。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/eladhoffer/convNet.pytorch"&gt;convnet&lt;/a&gt;: 深度卷积网络在不同数据集(ImageNet, Cifar10, Cifar100, MNIST)上的完整训练示例。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mailmahee/pytorch-generative-adversarial-networks"&gt;pytorch-generative-adversarial-networks&lt;/a&gt;: 一个简单的对抗生成网络(GAN) 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/amdegroot/pytorch-containers"&gt;pytorch containers&lt;/a&gt;: PyTorch中简化的Torch容器。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/cemoody/topicsne"&gt;T-SNE in pytorch&lt;/a&gt;: t-SNE实验。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fducau/AAE_pytorch"&gt;AAE_pytorch&lt;/a&gt;: PyTorch版对抗自编码器。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/GunhoChoi/Kind_PyTorch_Tutorial"&gt;Kind_PyTorch_Tutorial&lt;/a&gt;: PyTorch新手教程。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/justdark/pytorch-poetry-gen"&gt;pytorch-poetry-gen&lt;/a&gt;: 基于PyTorch的char-RNN（字符级循环神经网络）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/JamesChuanggg/pytorch-REINFORCE"&gt;pytorch-REINFORCE&lt;/a&gt;: PyTorch 实现了 OpenAI gym 下离散和连续控制的 REINFORCE。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3600+&lt;/kbd&gt; &lt;strong&gt;&lt;a href="https://github.com/MorvanZhou/PyTorch-Tutorial"&gt;PyTorch-Tutorial&lt;/a&gt;&lt;/strong&gt;: 简单而快速地搭建你自己的神经网络。 &lt;a href="https://morvanzhou.github.io/tutorials/" rel="nofollow"&gt;https://morvanzhou.github.io/tutorials/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/joansj/pytorch-intro"&gt;pytorch-intro&lt;/a&gt;: 演示如何在PyTorch中实现CNNs和RNNs。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/bearpaw/pytorch-classification"&gt;pytorch-classification&lt;/a&gt;: 一个CIFAR-10/100和ImageNet数据集上的分类框架。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hardmaru/pytorch_notebooks"&gt;pytorch_notebooks - hardmaru&lt;/a&gt;: 用NumPy和PyTorch编写的随机教程。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/soravux/pytorch_tutorial"&gt;pytorch_tutoria-quick&lt;/a&gt;: PyTorch介绍和教程。面向计算机视觉、图形和机器学习领域的研究人员，要求对神经网络理论知识和常用神经网络框架由基本的了解。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Spandan-Madan/Pytorch_fine_tuning_Tutorial"&gt;Pytorch_fine_tuning_Tutorial&lt;/a&gt;: 在PyTorch中进行微调或转移学习的简短教程。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Kyubyong/pytorch_exercises"&gt;pytorch_exercises&lt;/a&gt;: PyTorch练习。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/soumith/traffic-sign-detection-homework"&gt;traffic-sign-detection&lt;/a&gt;: 纽约大学2018年计算机视觉秋季课程示例。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Js-Mim/mss_pytorch"&gt;mss_pytorch&lt;/a&gt;: 无需进行滤波后处理，利用循环推断算法实现歌唱语音分离 - PyTorch 实现。 演示: js-mim.github.io/mss_pytorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2100+&lt;/kbd&gt; &lt;a href="https://github.com/DSKSD/DeepNLP-models-Pytorch"&gt;DeepNLP-models-Pytorch&lt;/a&gt; cs-224n课程中的各种深度NLP模型的PyTorch实现。(Stanford Univ: NLP with Deep Learning)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mila-udem/welcome_tutorials"&gt;Mila introductory tutorials&lt;/a&gt;: 面向MILA新生的各种教程。（&lt;a href="https://mila.quebec/en/mila/" rel="nofollow"&gt;MILA：加拿大蒙特利尔人工智能研究中心&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/moskomule/pytorch.rl.learning"&gt;pytorch.rl.learning&lt;/a&gt;: 使用PyTorch学习强化学习。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/keon/seq2seq"&gt;minimal-seq2seq&lt;/a&gt;: 关注神经机器翻译的最小Seq2Seq模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/JeanKossaifi/tensorly-notebooks"&gt;tensorly-notebooks&lt;/a&gt;: 利用Python和TensorLy实现张量方法。 tensorly.github.io/dev&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jpeg729/pytorch_bits"&gt;pytorch_bits&lt;/a&gt;: 时序预测的相关示例。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/sanyam5/skip-thoughts"&gt;skip-thoughts&lt;/a&gt;: PyTorch实现Skip-Thought词向量模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/xiadingZ/video-caption-pytorch"&gt;video-caption-pytorch&lt;/a&gt;: 利用PyTorch为视频添加字幕。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/higgsfield/Capsule-Network-Tutorial"&gt;Capsule-Network-Tutorial&lt;/a&gt;: 简单易学的胶囊网络（Capsule Network）教程。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch"&gt;code-of-learn-deep-learning-with-pytorch&lt;/a&gt;: 《深度学习入门之PyTorch》书中代码。 item.jd.com/17915495606.html&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/higgsfield/RL-Adventure"&gt;RL-Adventure&lt;/a&gt;: Pytorch 版 Deep Q Learning 教程，简单、易学、代码可读性强，包含 DQN / DDQN / Prioritized replay/ noisy networks/ distributional values/ Rainbow/ hierarchical RL 的 PyTorch 实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hpcgarage/accelerated_dl_pytorch"&gt;accelerated_dl_pytorch&lt;/a&gt;: Jupyter Day Atlanta II 会议上的加速深度学习算法，包含 PyTorch 教程和会议演讲文稿。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1800+&lt;/kbd&gt; &lt;a href="https://github.com/higgsfield/RL-Adventure-2"&gt;RL-Adventure-2&lt;/a&gt;: 以下内容的 PyTorch0.4 版本教程: actor critic / proximal policy optimization / acer / ddpg / twin dueling ddpg / soft actor critic / generative adversarial imitation learning / hindsight experience replay。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f" rel="nofollow"&gt;Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)&lt;/a&gt;: 50行生成对抗网络。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.paperspace.com/adversarial-autoencoders-with-pytorch/" rel="nofollow"&gt;adversarial-autoencoders-with-pytorch&lt;/a&gt;: PyTorch对抗自编码器。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@vishnuvig/transfer-learning-using-pytorch-4c3475f4495" rel="nofollow"&gt;transfer learning using pytorch&lt;/a&gt;: PyTorch迁移学习。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/" rel="nofollow"&gt;how-to-implement-a-yolo-object-detector-in-pytorch&lt;/a&gt;: 如何使用PyTorch实现一个YOLO (v3)物体检测器。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.fastforwardlabs.com/2018/04/10/pytorch-for-recommenders-101.html" rel="nofollow"&gt;pytorch-for-recommenders-101&lt;/a&gt;: 使用PyTorch构建推荐系统。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wkentaro/pytorch-for-numpy-users"&gt;pytorch-for-numpy-users&lt;/a&gt;: 面向Numpy用户的PyTorch。&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pytorchtutorial.com/" rel="nofollow"&gt;PyTorch Tutorial&lt;/a&gt;: PyTorch中文教程（PyTorch中文网）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Kaixhin/grokking-pytorch"&gt;grokking-pytorch&lt;/a&gt;: 手把手教你学会PyTorch。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/Atcold/PyTorch-Deep-Learning-Minicourse"&gt;PyTorch-Deep-Learning-Minicourse&lt;/a&gt;: PyTorch深度学习微型课程。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/utkuozbulak/pytorch-custom-dataset-examples"&gt;pytorch-custom-dataset-examples&lt;/a&gt;: PyTorch的一些自定义数据集示例。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://florianwilhelm.info/2018/08/multiplicative_LSTM_for_sequence_based_recos/" rel="nofollow"&gt;Multiplicative LSTM for sequence-based Recommenders&lt;/a&gt;: 面向基于序列的推荐器的乘法LSTM。/基于LSTM的序列推荐实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/furkanu/deeplearning.ai-pytorch"&gt;deeplearning.ai-pytorch&lt;/a&gt;: Coursera深度学习课程(deeplearning.ai)任务的PyTorch实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tobiascz/MNIST_Pytorch_python_and_capi"&gt;MNIST_Pytorch_python_and_capi&lt;/a&gt;: 示例：如何在Python中训练一个MNIST网络并在C++中用PyTorch1.0运行。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ne7ermore/torch_light"&gt;torch_light&lt;/a&gt;: 教程和示例，包括强化学习、NLP、CV。Logistic、CNN、RNN、LSTM等神经网络模型由数行代码实现，一些高级示例由复杂模型实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dribnet/portrain-gan"&gt;portrain-gan&lt;/a&gt;: 编码（解码尚未实现）art-DCGAN 生成的肖像油画。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/omarsar/mri-analysis-pytorch"&gt;mri-analysis-pytorch&lt;/a&gt;: 使用PyTorch和MedicalTorch进行核磁共振（MRI）分析。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/davidcpage/cifar10-fast"&gt;cifar10-fast&lt;/a&gt;: 在79秒内完成CIFAR10数据集上的ResNet模型的训练并达到94%的测试准确率，相关内容参见 &lt;a href="https://www.myrtle.ai/2018/09/24/how_to_train_your_resnet/" rel="nofollow"&gt;blog series&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://in.udacity.com/course/deep-learning-pytorch--ud188" rel="nofollow"&gt;Intro to Deep Learning with PyTorch&lt;/a&gt;: Udacity和Facebook联合推出的免费课程，包括对PyTorch的介绍和对PyTorch作者之一的Soumith Chintala的采访。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/bentrevett/pytorch-sentiment-analysis"&gt;pytorch-sentiment-analysis&lt;/a&gt;: PyTorch和TorchText语义分析教程。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/rwightman/pytorch-image-models"&gt;pytorch-image-models&lt;/a&gt;: PyTorch图像模型、脚本、与训练权重—— (SE)ResNet/ResNeXT, DPN, EfficientNet, MobileNet-V3/V2/V1, MNASNet, Single-Path NAS, FBNet等等。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BIGBALLON/CIFAR-ZOO"&gt;CIFAR-ZOO&lt;/a&gt;: 以CIFAR为基准的多种CNN架构的PyTorch实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dsgiitr/d2l-pytorch"&gt;d2l-pytorch&lt;/a&gt;: 本项目尝试复制《动手深度学习（Dive into Deep Learning）》(&lt;a href="http://www.d2l.ai" rel="nofollow"&gt;www.d2l.ai&lt;/a&gt;) 一书，将MXnet代码改编为PyTorch版。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/stared/thinking-in-tensors-writing-in-pytorch"&gt;thinking-in-tensors-writing-in-pytorch&lt;/a&gt;:  张量思维，PyTorch实践 (深度学习入门)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/lemonhu/NER-BERT-pytorch"&gt;NER-BERT-pytorch&lt;/a&gt;: 命名试题识别的PyTorch解决方案，使用了Google AI的预训练BERT模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dougsouza/pytorch-sync-batchnorm-example"&gt;pytorch-sync-batchnorm-example&lt;/a&gt;: 如何在 PyTorch 中使用交叉复制（Cross Replica）/同步批标准化（Synchronized Batchnorm）。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/barissayil/SentimentAnalysis"&gt;SentimentAnalysis&lt;/a&gt;: 情绪分析神经网络，在斯坦福情绪树库上用微调BERT训练得到。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-paper-implementations论文实现" class="anchor" aria-hidden="true" href="#paper-implementations论文实现"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Paper implementations｜论文实现&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/neuralix/google_evolution"&gt;google_evolution&lt;/a&gt;: 实现了 &lt;a href="https://arxiv.org/abs/1703.01041" rel="nofollow"&gt;Large-scale evolution of image classifiers&lt;/a&gt; 一文的结果网络之一。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/edouardoyallon/pyscatwave"&gt;pyscatwave&lt;/a&gt;: 基于CuPy/PyTorch的快速散射变换，&lt;a href="https://arxiv.org/abs/1703.08961" rel="nofollow"&gt;Scaling the Scattering Transform: Deep Hybrid Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/edouardoyallon/scalingscattering"&gt;scalingscattering&lt;/a&gt;: 该仓库包含 &lt;a href="https://arxiv.org/abs/1703.08961" rel="nofollow"&gt;Scaling The Scattering Transform : Deep Hybrid Networks&lt;/a&gt; 一文中的实验。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/episodeyang/deep-auto-punctuation"&gt;deep-auto-punctuation&lt;/a&gt;: 通过逐字符学习实现自动添加标点。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation"&gt;Realtime_Multi-Person_Pose_Estimation&lt;/a&gt;: 基于PyTorch的多人人体姿态估计，&lt;a href="https://github.com/ZheC/Realtime_Multi-Person_Pose_Estimation"&gt;原始代码&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/onlytailei/PyTorch-value-iteration-networks"&gt;PyTorch-value-iteration-networks&lt;/a&gt;: PyTorch实现价值迭代网络（&lt;a href="https://arxiv.org/abs/1602.02867" rel="nofollow"&gt;Value Iteration Networks&lt;/a&gt;）（NIPS2016最佳论文奖）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/analvikingur/pytorch_Highway"&gt;pytorch_Highway&lt;/a&gt;: PyTorch实现高速公路网络（&lt;a href="https://arxiv.org/abs/1505.00387" rel="nofollow"&gt;Highway Networks&lt;/a&gt;）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/analvikingur/pytorch_NEG_loss"&gt;pytorch_NEG_loss&lt;/a&gt;: PyTorch实现负采样损失（&lt;a href="https://arxiv.org/abs/1310.4546" rel="nofollow"&gt;Negative Sampling Loss&lt;/a&gt;）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/analvikingur/pytorch_RVAE"&gt;pytorch_RVAE&lt;/a&gt;: 用PyTorch实现的产生序列数据的递归变分自动编码器，相关论文：&lt;a href="https://arxiv.org/abs/1511.06349#" rel="nofollow"&gt;Generating Sentences from a Continuous Space&lt;/a&gt;，&lt;a href="https://arxiv.org/abs/1508.06615" rel="nofollow"&gt;Character-Aware Neural Language Models&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/analvikingur/pytorch_TDNN"&gt;pytorch_TDNN&lt;/a&gt;: 用PyTorch实现时间延迟神经网络（Time Delayed NN）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/moskomule/eve.pytorch"&gt;eve.pytorch&lt;/a&gt;: 一个Eve优化器的实现，相关论文：&lt;a href="https://arxiv.org/abs/1611.01505" rel="nofollow"&gt;Imploving Stochastic Gradient Descent with Feedback&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/locuslab/e2e-model-learning"&gt;e2e-model-learning&lt;/a&gt;: 随机优化中的基于任务的端到端模型，&lt;a href="https://arxiv.org/abs/1703.04529" rel="nofollow"&gt;https://arxiv.org/abs/1703.04529&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mrzhu-cool/pix2pix-pytorch"&gt;pix2pix-pytorch&lt;/a&gt;: PyTorch实现“基于条件对抗网络的图像到图像翻译”。 论文：&lt;a href="https://arxiv.org/pdf/1611.07004v1.pdf" rel="nofollow"&gt;Image-to-Image Translation Using Conditional Adversarial Networks&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2900+&lt;/kbd&gt; &lt;a href="https://github.com/amdegroot/ssd.pytorch"&gt;Single Shot MultiBox Detector&lt;/a&gt;: 单发多盒探测器，论文：&lt;a href="http://arxiv.org/abs/1512.02325" rel="nofollow"&gt;Single Shot MultiBox Detector&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/carpedm20/DiscoGAN-pytorch"&gt;DiscoGAN&lt;/a&gt;: 学习利用生成性对抗网络发现跨域关系。论文：&lt;a href="https://arxiv.org/abs/1703.05192" rel="nofollow"&gt;Learning to Discover Cross-Domain Relations with Generative Adversarial Networks&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/SKTBrain/DiscoGAN"&gt;official DiscoGAN implementation&lt;/a&gt;: 官方实现“学习利用生成性对抗网络发现跨域关系”。 论文：&lt;a href="https://arxiv.org/abs/1703.05192" rel="nofollow"&gt;Learning to Discover Cross-Domain Relations with Generative Adversarial Networks&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/atgambardella/pytorch-es"&gt;pytorch-es&lt;/a&gt;: 进化策略。论文：&lt;a href="https://arxiv.org/abs/1703.03864" rel="nofollow"&gt;Evolution Strategies as a Scalable Alternative to Reinforcement Learning&lt;/a&gt; .&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/bodokaiser/piwise"&gt;piwise&lt;/a&gt;: 使用PyTorch对VOC2012数据集进行像素切割。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/transedward/pytorch-dqn"&gt;pytorch-dqn&lt;/a&gt;: 深度Q学习网络。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ruotianluo/neuraltalk2.pytorch"&gt;neuraltalk2-pytorch&lt;/a&gt;: PyTorch图像字幕代码库(在分支“with_finetune”中有可微调CNN)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mattmacy/vnet.pytorch"&gt;vnet.pytorch&lt;/a&gt;: PyTorch实现V-Net：全卷积神经网络在体医学图像分割中的应用。 &lt;a href="http://mattmacy.io/vnet.pytorch/" rel="nofollow"&gt;http://mattmacy.io/vnet.pytorch/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wkentaro/pytorch-fcn"&gt;pytorch-fcn&lt;/a&gt;: PyTorch 实现完全卷积网络。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/xternalz/WideResNet-pytorch"&gt;WideResNets&lt;/a&gt;: PyTorch实现WideResNets。该实现比官方Torch实现花费更少的GPU内存。实现: &lt;a href="https://github.com/szagoruyko/wide-residual-networks"&gt;https://github.com/szagoruyko/wide-residual-networks&lt;/a&gt; .&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/c0nn3r/pytorch_highway_networks"&gt;pytorch_highway_networks&lt;/a&gt;: PyTorch实现高速公路网络。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ypxie/pytorch-NeuCom"&gt;pytorch-NeuCom&lt;/a&gt;: Pytorch实现DeepMind的可微神经计算机&lt;a href="http://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz" rel="nofollow"&gt;论文&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/eladhoffer/captionGen"&gt;captionGen&lt;/a&gt;: 使用PyTorch为图像生成标注。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jayleicn/animeGAN"&gt;AnimeGAN&lt;/a&gt;: 生成对抗网络的PyTorch简单实现，关注于动漫脸谱绘画。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Shawn1993/cnn-text-classification-pytorch"&gt;Cnn-text classification&lt;/a&gt;: PyTorch 实现 &lt;a href="https://arxiv.org/abs/1408.5882" rel="nofollow"&gt;Kim的基于卷积神经网络的句子分类&lt;/a&gt; 论文。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/SeanNaren/deepspeech.pytorch"&gt;deepspeech2&lt;/a&gt;: 使用 Baidu Warp-CTC 实现DeepSpeech2。创造一个基于 DeepSpeech2 架构的网络，用 CTC 激活函数训练。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/MaximumEntropy/Seq2Seq-PyTorch"&gt;seq2seq&lt;/a&gt;: 包含PyTorch中的Seq2Seq模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rarilurelo/pytorch_a3c"&gt;Asynchronous Advantage Actor-Critic in PyTorch&lt;/a&gt;: PyTorch实现A3C(Asynchronous Advantage Actor-Critic)，论文：&lt;a href="https://arxiv.org/pdf/1602.01783v1.pdf" rel="nofollow"&gt;Asynchronous Methods for Deep Reinforcement Learning&lt;/a&gt;。由于 PyTorch 可以轻松地在多进程内控制共享内存，我们可以轻易实现A3C这样的异步算法。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/bamos/densenet.pytorch"&gt;densenet&lt;/a&gt;: This is a PyTorch 实现 DenseNet-BC 架构，相关论文 &lt;a href="https://arxiv.org/abs/1608.06993" rel="nofollow"&gt;Densely Connected Convolutional Networks&lt;/a&gt;。该实现的 CIFAR-10+ 100层错误率为 4.77 增长率为 12。官方实现和许多第三方库的链接参见 &lt;a href="https://github.com/liuzhuang13/DenseNet"&gt;liuzhuang13/DenseNet&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/alykhantejani/nninit"&gt;nninit&lt;/a&gt;: PyTorch神经网络模块的权值初始化方案，这是 &lt;a href="https://github.com/Kaixhin/nninit"&gt;nninit&lt;/a&gt; 的流行端口。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/longcw/faster_rcnn_pytorch"&gt;faster rcnn&lt;/a&gt;: PyTorch 实现 Faster RCNN。该项目主要基于 py-faster-rcnn 和 TFFRCNN。更多关于 R-CNN 的细节请参考论文 Faster R-CNN：&lt;a href="https://arxiv.org/abs/1506.01497" rel="nofollow"&gt;Towards Real-Time Object Detection with Region Proposal Network&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/akolishchak/doom-net-pytorch"&gt;doomnet&lt;/a&gt;: PyTorch版Doom-net，实现了ViZDoom环境下的RL模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ClementPinard/FlowNetPytorch"&gt;flownet&lt;/a&gt;: 通过Dosovitskiy等完成FlowNet的Pytorch实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/gsp-27/pytorch_Squeezenet"&gt;sqeezenet&lt;/a&gt;: 在CIFAR10数据集上用PyTorch实现Squeezenet模型，&lt;a href="https://arxiv.org/abs/1602.07360" rel="nofollow"&gt;论文&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2400+&lt;/kbd&gt; &lt;a href="https://github.com/martinarjovsky/WassersteinGAN"&gt;WassersteinGAN&lt;/a&gt;: PyTorch实现&lt;a href="https://arxiv.org/abs/1701.07875" rel="nofollow"&gt;WassersteinGAN&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/locuslab/optnet"&gt;optnet&lt;/a&gt;: 该仓库包含PyTorch源码，重现了论文&lt;a href="https://arxiv.org/abs/1703.00443" rel="nofollow"&gt;OptNet: Differentiable Optimization as a Layer in Neural Networks&lt;/a&gt;中的实验。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/locuslab/qpth"&gt;qp solver&lt;/a&gt;: PyTorch的一个快速和可微分的QP求解器。&lt;a href="https://locuslab.github.io/qpth/" rel="nofollow"&gt;https://locuslab.github.io/qpth/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ikostrikov/pytorch-naf"&gt;Continuous Deep Q-Learning with Model-based Acceleration &lt;/a&gt;: &lt;a href="https://arxiv.org/pdf/1603.00748v1.pdf" rel="nofollow"&gt;基于模型加速的连续深度Q学习&lt;/a&gt;的再实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ikostrikov/pytorch-meta-optimizer"&gt;Learning to learn by gradient descent by gradient descent&lt;/a&gt;: PyTorch实现&lt;a href="https://arxiv.org/abs/1606.04474" rel="nofollow"&gt;Learning to learn by gradient descent by gradient descent&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/darkstar112358/fast-neural-style"&gt;fast-neural-style&lt;/a&gt;: PyTorch实现fast-neural-style，论文：&lt;a href="https://arxiv.org/abs/1603.08155" rel="nofollow"&gt;Perceptual Losses for Real-Time Style Transfer and Super-Resolution&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/leongatys/PytorchNeuralStyleTransfer"&gt;PytorchNeuralStyleTransfer&lt;/a&gt;: Pytorch中的神经风格转换。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/bengxy/FastNeuralStyle"&gt;Fast Neural Style for Image Style Transform by Pytorch&lt;/a&gt;: 使用快速神经风格进行图像风格转换。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/alexis-jacq/Pytorch-Tutorials"&gt;neural style transfer&lt;/a&gt;: 通过神经风格算法介绍PyTorch，&lt;a href="https://arxiv.org/abs/1508.06576" rel="nofollow"&gt;Neural-Style algorithm&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zuoxingdong/VIN_PyTorch_Visdom"&gt;VIN_PyTorch_Visdom&lt;/a&gt;: PyTorch实现价值迭代网络(VIN):干净、简单、模块化。利用Visdom进行可视化。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/longcw/yolo2-pytorch"&gt;YOLO2&lt;/a&gt;: PyTorch中的YOLOv2。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/szagoruyko/attention-transfer"&gt;attention-transfer&lt;/a&gt;: 通过注意转移改善卷积网络，&lt;a href="https://arxiv.org/abs/1612.03928" rel="nofollow"&gt;ICLR2017会议论文&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/potterhsu/SVHNClassifier-PyTorch"&gt;SVHNClassifier&lt;/a&gt;: PyTorch实现&lt;a href="https://arxiv.org/pdf/1312.6082.pdf" rel="nofollow"&gt;基于深度卷积神经网络的街景图像多位数识别&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/oeway/pytorch-deform-conv"&gt;pytorch-deform-conv&lt;/a&gt;: PyTorch实现可变形卷积(Deformable Convolution)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/carpedm20/BEGAN-pytorch"&gt;BEGAN-pytorch&lt;/a&gt;: PyTorch实现&lt;a href="https://arxiv.org/abs/1703.10717" rel="nofollow"&gt;边界均衡生成对抗网络（BEGAN）&lt;/a&gt;: Boundary Equilibrium Generative Adversarial Networks.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dasguptar/treelstm.pytorch"&gt;treelstm.pytorch&lt;/a&gt;: PyTorch实现树形结构LSTM。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/DmitryUlyanov/AGE"&gt;AGE&lt;/a&gt;: 论文代码，原文：对抗生成编码器网络（&lt;a href="http://sites.skoltech.ru/app/data/uploads/sites/25/2017/04/AGE.pdf" rel="nofollow"&gt;Adversarial Generator-Encoder Networks&lt;/a&gt;）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/prlz77/ResNeXt.pytorch"&gt;ResNeXt.pytorch&lt;/a&gt;: 再现 ResNet-V3 (深度神经网络的聚集残差变换)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jingweiz/pytorch-rl"&gt;pytorch-rl&lt;/a&gt;: 基于PyTorch和Visdom的深度强化学习。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/sujithv28/Deep-Leafsnap"&gt;Deep-Leafsnap&lt;/a&gt;: 对比传统的计算机视觉方法，使用深度神经网络的&lt;a href="https://neerajkumar.org/base/papers/nk_eccv2012_leafsnap.pdf" rel="nofollow"&gt;LeafSnap&lt;/a&gt;能有效提高测试准确率。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;10100+&lt;/kbd&gt; &lt;a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"&gt;pytorch-CycleGAN-and-pix2pix&lt;/a&gt;: PyTorch 实现图像风格迁移。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/onlytailei/A3C-PyTorch"&gt;A3C-PyTorch&lt;/a&gt;:PyTorch 实现 A3C(Advantage async actor-critic)算法。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kentsommer/pytorch-value-iteration-networks"&gt;pytorch-value-iteration-networks&lt;/a&gt;: PyTorch实现价值迭代网络Value Iteration Networks (NIPS 2016 最佳论文)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zhanghang1989/PyTorch-Style-Transfer"&gt;PyTorch-Style-Transfer&lt;/a&gt;: PyTorch实现实时转换多风格生成网络。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/isht7/pytorch-deeplab-resnet"&gt;pytorch-deeplab-resnet&lt;/a&gt;: PyTorch实现 &lt;a href="https://arxiv.org/abs/1606.00915" rel="nofollow"&gt;DeepLab resnet v2&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fxia22/pointnet.pytorch"&gt;pointnet.pytorch&lt;/a&gt;: PyTorch实现 "PointNet: 基于深度学习的3D点分类和分割模型" &lt;a href="https://arxiv.org/abs/1612.00593" rel="nofollow"&gt;https://arxiv.org/abs/1612.00593&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/aaron-xichen/pytorch-playground"&gt;pytorch-playground&lt;/a&gt;: 包含常见的预训练模型和数据集(MNIST, SVHN, CIFAR10, CIFAR100, STL10, AlexNet, VGG16, VGG19, ResNet, Inception, SqueezeNet)**.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jingweiz/pytorch-dnc"&gt;pytorch-dnc&lt;/a&gt;: PyTorch/Visdom实现的神经机器翻译(NTM)&amp;amp;可微神经计算机(DNC)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jinfagang/pytorch_image_classifier"&gt;pytorch_image_classifier&lt;/a&gt;: 使用PyTorch的最小但实用的图像分类器管道，在ResNet18上进行细化，在自己的小型数据集上获得99%的准确率。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/yunjey/mnist-svhn-transfer"&gt;mnist-svhn-transfer&lt;/a&gt;: PyTorch实现CycleGAN和SGAN。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/marvis/pytorch-yolo2"&gt;pytorch-yolo2&lt;/a&gt;: pytorch-yolo2&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/andrewliao11/dni.pytorch"&gt;dni&lt;/a&gt;: PyTorch实现使用合成梯度的解耦神经接口，论文：&lt;a href="https://arxiv.org/abs/1608.05343" rel="nofollow"&gt;Decoupled Neural Interfaces using Synthetic Gradients&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/caogang/wgan-gp"&gt;wgan-gp&lt;/a&gt;: PyTorch实现论文"&lt;a href="https://arxiv.org/abs/1704.00028v3" rel="nofollow"&gt;Improved Training of Wasserstein GANs&lt;/a&gt;".&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/spro/pytorch-seq2seq-intent-parsing"&gt;pytorch-seq2seq-intent-parsing&lt;/a&gt;:  PyTorch使用seq2seq和注意力模型进行意图分析和空位填充。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/demelin/pyTorch_NCE"&gt;pyTorch_NCE&lt;/a&gt;: 复现噪音对比估计算法，论文：&lt;a href="http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf" rel="nofollow"&gt;Noise-contrastive estimation: A new estimation principle for unnormalized statistical models&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/cxhernandez/molencoder"&gt;molencoder&lt;/a&gt;: 分子自动编码器。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/stormraiser/GAN-weight-norm"&gt;GAN-weight-norm&lt;/a&gt;: 论文代码，"&lt;a href="https://arxiv.org/abs/1704.03971" rel="nofollow"&gt;生成对抗网络中批量和权重归一化的影响&lt;/a&gt;"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rachtsingh/lgamma"&gt;lgamma&lt;/a&gt;: 实现polygamma、lgamma和beta函数。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/eladhoffer/bigBatch"&gt;bigBatch&lt;/a&gt;: 论文代码，论文：“&lt;a href="https://arxiv.org/abs/1705.08741" rel="nofollow"&gt;训练越久，泛化越好：关闭神经网络大批量训练的泛化间隙&lt;/a&gt;”。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dgriff777/rl_a3c_pytorch"&gt;rl_a3c_pytorch&lt;/a&gt;: 针对 Atari 2600 的强化学习，实现了 A3C LSTM 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ahirner/pytorch-retraining"&gt;pytorch-retraining&lt;/a&gt;: PyTorch动物园模型转移学习(torchvision)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/priba/nmp_qc"&gt;nmp_qc&lt;/a&gt;: 用于计算机视觉的神经消息传递。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jacobgil/pytorch-grad-cam"&gt;grad-cam&lt;/a&gt;: PyTorch 实现&lt;a href="https://arxiv.org/pdf/1610.02391v1.pdf" rel="nofollow"&gt;Grad-CAM&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mjacar/pytorch-trpo"&gt;pytorch-trpo&lt;/a&gt;: PyTorch s实现置信域策略优化（&lt;a href="https://arxiv.org/abs/1502.05477" rel="nofollow"&gt;Trust Region Policy Optimization (TRPO)&lt;/a&gt;）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jacobgil/pytorch-explain-black-box"&gt;pytorch-explain-black-box&lt;/a&gt;: PyTorch通过有意义扰动实现黑箱的可解释性解释，&lt;a href="https://arxiv.org/abs/1704.03296" rel="nofollow"&gt;论文&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jmtomczak/vae_vpflows"&gt;vae_vpflows&lt;/a&gt;: 凸组合线性IAF与Householder流 &lt;a href="https://jmtomczak.github.io/deebmed.html" rel="nofollow"&gt;https://jmtomczak.github.io/deebmed.html&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kimhc6028/relational-networks"&gt;relational-networks&lt;/a&gt;: Pytorch实现"&lt;a href="https://arxiv.org/pdf/1706.01427.pdf" rel="nofollow"&gt;用一个简单的神经网络模块来做关系推理&lt;/a&gt;"(关系网络)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Cadene/vqa.pytorch"&gt;vqa.pytorch&lt;/a&gt;: 视觉问答。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/end-to-end-negotiator"&gt;end-to-end-negotiator&lt;/a&gt;: 成交还是不成交？谈判对话的端到端学习。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ShiyuLiang/odin-pytorch"&gt;odin-pytorch&lt;/a&gt;: 神经网络失配实例的原则性检测。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ajbrock/FreezeOut"&gt;FreezeOut&lt;/a&gt;: 一种通过逐步冻结层加速神经网络训练的简单技术。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jakezhaojb/ARAE"&gt;ARAE&lt;/a&gt;: 论文代码，"&lt;a href="https://arxiv.org/abs/1706.04223" rel="nofollow"&gt;对抗性正则化的自动编码器, ARAE&lt;/a&gt;"。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kimhc6028/forward-thinking-pytorch"&gt;forward-thinking-pytorch&lt;/a&gt;: PyTorch实现"&lt;a href="https://arxiv.org/pdf/1706.02480.pdf" rel="nofollow"&gt;前向思考：一次一层地建立和训练神经网络&lt;/a&gt;"。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BoyuanJiang/context_encoder_pytorch"&gt;context_encoder_pytorch&lt;/a&gt;: PyTorch实现上下文编码器(Context Encoders)，可用于图像修复。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3300+&lt;/kbd&gt; &lt;a href="https://github.com/jadore801120/attention-is-all-you-need-pytorch"&gt;attention-is-all-you-need-pytorch&lt;/a&gt;: PyTorch在"Attention is All You Need"中实现转换模型，&lt;a href="https://github.com/thnkim/OpenFacePytorch%E3%80%82"&gt;https://github.com/thnkim/OpenFacePytorch。&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/thnkim/OpenFacePytorch"&gt;OpenFacePytorch&lt;/a&gt;: 使用 OpenFace's nn4.small2.v1.t7 模型的PyTorch模块。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pemami4911/neural-combinatorial-rl-pytorch"&gt;neural-combinatorial-rl-pytorch&lt;/a&gt;:  PyTorch 实现"&lt;a href="https://arxiv.org/abs/1611.09940" rel="nofollow"&gt;通过强化学习实现神经组合优化&lt;/a&gt;"。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mjacar/pytorch-nec"&gt;pytorch-nec&lt;/a&gt;: PyTorch实现神经情景控制(&lt;a href="https://arxiv.org/abs/1703.01988" rel="nofollow"&gt;NEC，Neural Episodic Control&lt;/a&gt;)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/eladhoffer/seq2seq.pytorch"&gt;seq2seq.pytorch&lt;/a&gt;: 使用PyTorch进行Sequence-to-Sequence学习。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/alexis-jacq/Pytorch-Sketch-RNN"&gt;Pytorch-Sketch-RNN&lt;/a&gt;: PyTorch实现 “&lt;a href="arxiv.org/abs/1704.03477"&gt;A Neural Representation of Sketch Drawings&lt;/a&gt;”。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jacobgil/pytorch-pruning"&gt;pytorch-pruning&lt;/a&gt;: PyTorch实现 [1611.06440] &lt;a href="https://arxiv.org/abs/1611.06440" rel="nofollow"&gt;用于资源有效推理的剪枝卷积神经网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hitvoice/DrQA"&gt;DrQA&lt;/a&gt;: PyTorch实现自动阅读维基百科并回答开放领域问题。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/JianGoForIt/YellowFin_Pytorch"&gt;YellowFin_Pytorch&lt;/a&gt;: 基于动量梯度下降（momentum SGD）的自动调优优化器，无需手动指定学习速率和动量。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/deepsound-project/samplernn-pytorch"&gt;samplernn-pytorch&lt;/a&gt;: PyTorch实现SampleRNN: 一种无条件端到端神经音频生成模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tymokvo/AEGeAN"&gt;AEGeAN&lt;/a&gt;: 基于AE稳定的更深的深度卷积生成对抗网络(DCGAN, Deep Convolution Generative Adversarial Networks)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/twtygqyy/pytorch-SRResNet"&gt;/pytorch-SRResNet&lt;/a&gt;: PyTorch实现“&lt;a href="https://arxiv.org/abs/1609.04802" rel="nofollow"&gt;基于生成对抗网络的实感单幅图像超分辨率&lt;/a&gt;”。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fartashf/vsepp"&gt;vsepp&lt;/a&gt;: 论文代码，"&lt;a href="https://arxiv.org/abs/1707.05612" rel="nofollow"&gt;VSE++:使用难分样本(Hard Negative)改善视觉语义联合嵌入&lt;/a&gt;"。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/alexis-jacq/Pytorch-DPPO"&gt;Pytorch-DPPO&lt;/a&gt;: Pytorch实现分布式近端策略优化(&lt;a href="https://arxiv.org/abs/1707.02286" rel="nofollow"&gt;Distributed Proximal Policy Optimization&lt;/a&gt;)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/mingyuliutw/UNIT"&gt;UNIT&lt;/a&gt;: 无监督的图像到图像转换网络，&lt;a href="https://arxiv.org/abs/1703.00848" rel="nofollow"&gt;论文&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/gpleiss/efficient_densenet_pytorch"&gt;efficient_densenet_pytorch&lt;/a&gt;: DenseNets的内存高效实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/yjxiong/tsn-pytorch"&gt;tsn-pytorch&lt;/a&gt;: PyTorch实现时间分割网络(TSN, Temporal Segment Networks)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ajbrock/SMASH"&gt;SMASH&lt;/a&gt;: &lt;a href="https://arxiv.org/abs/1708.05344" rel="nofollow"&gt;SMASH&lt;/a&gt;，一种高效地探索神经体系结构的实验技术。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kuangliu/pytorch-retinanet"&gt;pytorch-retinanet&lt;/a&gt;: RetinaNet。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/aosokin/biogans"&gt;biogans&lt;/a&gt;: 实现 ICCV 2017 论文 "&lt;a href="https://arxiv.org/abs/1708.04692" rel="nofollow"&gt;利用GANs进行生物图像合成&lt;/a&gt;"。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/woozzu/dong_iccv_2017"&gt;Semantic Image Synthesis via Adversarial Learning&lt;/a&gt;: PyTorch 实现 ICCV 2017 论文 "&lt;a href="https://arxiv.org/abs/1707.06873" rel="nofollow"&gt;基于对抗学习的语义图像合成&lt;/a&gt;"。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jmhessel/fmpytorch"&gt;fmpytorch&lt;/a&gt;: PyTorch在Cython中实现分析机（Factorization Machine）模块。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ZhouYanzhao/ORN"&gt;ORN&lt;/a&gt;: PyTorch 实现 CVPR 2017 论文 "&lt;a href="https://arxiv.org/pdf/1701.01833.pdf" rel="nofollow"&gt;Oriented Response Networks&lt;/a&gt;"。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/katerakelly/pytorch-maml"&gt;pytorch-maml&lt;/a&gt;: PyTorch实现 &lt;a href="https://arxiv.org/abs/1703.03400" rel="nofollow"&gt;MAML&lt;/a&gt;（Model-Agnostic Meta-Learning，与模型无关的元学习）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1800+&lt;/kbd&gt; &lt;a href="https://github.com/znxlwm/pytorch-generative-model-collections"&gt;pytorch-generative-model-collections&lt;/a&gt;: PyTorch中的各种生成模型集合。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/markdtw/vqa-winner-cvprw-2017"&gt;vqa-winner-cvprw-2017&lt;/a&gt;: Pytorch 实现 CVPR'17 VQA( Visual Question Answer，视觉问答) 挑战冠军。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/r9y9/tacotron_pytorch"&gt;tacotron_pytorch&lt;/a&gt;:  PyTorch 实现 Tacotron 语音合成模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Lextal/pspnet-pytorch"&gt;pspnet-pytorch&lt;/a&gt;: PyTorch 实现 PSPNet 语义分割网络。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/LiyuanLucasLiu/LM-LSTM-CRF"&gt;LM-LSTM-CRF&lt;/a&gt;: Empower Sequence Labeling with Task-Aware Language Model &lt;a href="http://arxiv.org/abs/1709.04109" rel="nofollow"&gt;http://arxiv.org/abs/1709.04109&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3200+&lt;/kbd&gt; &lt;a href="https://github.com/1adrianb/face-alignment"&gt;face-alignment&lt;/a&gt;: 使用PyTorch构建2D和3D人脸对齐库。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ClementPinard/DepthNet"&gt;DepthNet&lt;/a&gt;: PyTorch 在Still Box数据集上训练DepthNet。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/thstkdgus35/EDSR-PyTorch"&gt;EDSR-PyTorch&lt;/a&gt;: PyTorch version of the paper 'Enhanced Deep Residual Networks for Single Image Super-Resolution' (CVPRW 2017)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ethanluoyc/e2c-pytorch"&gt;e2c-pytorch&lt;/a&gt;: E2C，Embed to Control 实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/kenshohara/3D-ResNets-PyTorch"&gt;3D-ResNets-PyTorch&lt;/a&gt;: 基于3D残差网络的动作识别。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/khanhptnk/bandit-nmt"&gt;bandit-nmt&lt;/a&gt;: This is code repo for our EMNLP 2017 paper "Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback", which implements the A2C algorithm on top of a neural encoder-decoder model and benchmarks the combination under simulated noisy rewards.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1500+&lt;/kbd&gt; &lt;a href="https://github.com/ikostrikov/pytorch-a2c-ppo-acktr"&gt;pytorch-a2c-ppo-acktr&lt;/a&gt;: PyTorch implementation of Advantage Actor Critic (A2C), Proximal Policy Optimization (PPO) and Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation (ACKTR).&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/baldassarreFe/zalando-pytorch"&gt;zalando-pytorch&lt;/a&gt;: &lt;a href="https://github.com/zalandoresearch/fashion-mnist"&gt;Fashion-MNIST&lt;/a&gt;数据集上的各种实验。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/clcarwin/sphereface_pytorch"&gt;sphereface_pytorch&lt;/a&gt;: PyTorch实现SphereFace，人脸识别相关，&lt;a href="https://arxiv.org/abs/1704.08063" rel="nofollow"&gt;https://arxiv.org/abs/1704.08063&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/floringogianu/categorical-dqn"&gt;Categorical DQN&lt;/a&gt;: A PyTorch Implementation of Categorical DQN from &lt;a href="https://arxiv.org/abs/1707.06887" rel="nofollow"&gt;A Distributional Perspective on Reinforcement Learning&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/loudinthecloud/pytorch-ntm"&gt;pytorch-ntm&lt;/a&gt;: 神经网络图灵机。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/felixgwu/mask_rcnn_pytorch"&gt;mask_rcnn_pytorch&lt;/a&gt;: Mask RCNN in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/xbresson/graph_convnets_pytorch"&gt;graph_convnets_pytorch&lt;/a&gt;: PyTorch implementation of graph ConvNets, NIPS’16&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1300+&lt;/kbd&gt; &lt;a href="https://github.com/ruotianluo/pytorch-faster-rcnn"&gt;pytorch-faster-rcnn&lt;/a&gt;: A pytorch implementation of faster RCNN detection framework based on Xinlei Chen's tf-faster-rcnn.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/huggingface/torchMoji"&gt;torchMoji&lt;/a&gt;: A pyTorch implementation of the DeepMoji model: state-of-the-art deep learning model for analyzing sentiment, emotion, sarcasm etc.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2700+&lt;/kbd&gt; &lt;a href="https://github.com/hangzhaomit/semantic-segmentation-pytorch"&gt;semantic-segmentation-pytorch&lt;/a&gt;: 在&lt;a href="http://sceneparsing.csail.mit.edu" rel="nofollow"&gt;MIT ADE20K dataset&lt;/a&gt;数据集上实现语义分割/场景解析。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/salesforce/pytorch-qrnn"&gt;pytorch-qrnn&lt;/a&gt;: PyTorch implementation of the Quasi-Recurrent Neural Network - up to 16 times faster than NVIDIA's cuDNN LSTM&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/theeluwin/pytorch-sgns"&gt;pytorch-sgns&lt;/a&gt;: Skipgram Negative Sampling in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ClementPinard/SfmLearner-Pytorch"&gt;SfmLearner-Pytorch &lt;/a&gt;: Pytorch version of SfmLearner from Tinghui Zhou et al.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/1zb/deformable-convolution-pytorch"&gt;deformable-convolution-pytorch&lt;/a&gt;: PyTorch实现可变形卷积。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fanglanting/skip-gram-pytorch"&gt;skip-gram-pytorch&lt;/a&gt;: A complete pytorch implementation of skipgram model (with subsampling and negative sampling). The embedding result is tested with Spearman's rank correlation.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hanzhanggit/StackGAN-v2"&gt;stackGAN-v2&lt;/a&gt;: Pytorch implementation for reproducing StackGAN_v2 results in the paper StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks by Han Zhang*, Tao Xu*, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, Dimitris Metaxas.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ruotianluo/self-critical.pytorch"&gt;self-critical.pytorch&lt;/a&gt;: 非官方，PyTorch实现基于 self-critical 序列训练的图像标注。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1900+&lt;/kbd&gt; &lt;a href="https://github.com/tkipf/pygcn"&gt;pygcn&lt;/a&gt;: 图卷积网络。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ixaxaar/pytorch-dnc"&gt;dnc&lt;/a&gt;: 可微神经计算机、稀疏存取存储器与稀疏可微神经计算机。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ptrblck/prog_gans_pytorch_inference"&gt;prog_gans_pytorch_inference&lt;/a&gt;: PyTorch inference for "Progressive Growing of GANs" with CelebA snapshot.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/timomernick/pytorch-capsule"&gt;pytorch-capsule&lt;/a&gt;: Pytorch implementation of Hinton's Dynamic Routing Between Capsules.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dyhan0920/PyramidNet-PyTorch"&gt;PyramidNet-PyTorch&lt;/a&gt;: A PyTorch implementation for PyramidNets (Deep Pyramidal Residual Networks, arxiv.org/abs/1610.02915)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/gram-ai/radio-transformer-networks"&gt;radio-transformer-networks&lt;/a&gt;: A PyTorch implementation of Radio Transformer Networks from the paper "An Introduction to Deep Learning for the Physical Layer". arxiv.org/abs/1702.00832&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/castorini/honk"&gt;honk&lt;/a&gt;: PyTorch reimplementation of Google's TensorFlow CNNs for keyword spotting.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/SSARCandy/DeepCORAL"&gt;DeepCORAL&lt;/a&gt;: A PyTorch implementation of 'Deep CORAL: Correlation Alignment for Deep Domain Adaptation.', ECCV 2016&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/bearpaw/pytorch-pose"&gt;pytorch-pose&lt;/a&gt;: PyTorch工具包，用于2D人体姿态估计。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/karandesai-96/lang-emerge-parlai"&gt;lang-emerge-parlai&lt;/a&gt;: Implementation of EMNLP 2017 Paper "Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog" using PyTorch and ParlAI&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Kaixhin/Rainbow"&gt;Rainbow&lt;/a&gt;: Rainbow: Combining Improvements in Deep Reinforcement Learning&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/gdlg/pytorch_compact_bilinear_pooling"&gt;pytorch_compact_bilinear_pooling v1&lt;/a&gt;: This repository has a pure Python implementation of Compact Bilinear Pooling and Count Sketch for PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/DeepInsight-PCALab/CompactBilinearPooling-Pytorch"&gt;CompactBilinearPooling-Pytorch v2&lt;/a&gt;: (Yang Gao, et al.) A Pytorch Implementation for Compact Bilinear Pooling.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/gitabcworld/FewShotLearning"&gt;FewShotLearning&lt;/a&gt;: Pytorch implementation of the paper "Optimization as a Model for Few-Shot Learning"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jklj077/meProp"&gt;meProp&lt;/a&gt;: Codes for "meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting".&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/clcarwin/SFD_pytorch"&gt;SFD_pytorch&lt;/a&gt;: 单镜头尺度不变人脸检测器。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/GradientEpisodicMemory"&gt;GradientEpisodicMemory&lt;/a&gt;: Continuum Learning with GEM: Gradient Episodic Memory. &lt;a href="https://arxiv.org/abs/1706.08840" rel="nofollow"&gt;https://arxiv.org/abs/1706.08840&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/KupynOrest/DeblurGAN"&gt;DeblurGAN&lt;/a&gt;: Pytorch implementation of the paper DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;4200+&lt;/kbd&gt; &lt;a href="https://github.com/yunjey/StarGAN"&gt;StarGAN&lt;/a&gt;: StarGAN: 多领域图像转换 GAN 网络，&lt;a href="https://arxiv.org/abs/1711.09020" rel="nofollow"&gt;https://arxiv.org/abs/1711.09020&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/adambielski/CapsNet-pytorch"&gt;CapsNet-pytorch&lt;/a&gt;: PyTorch 实现 NIPS 2017 论文 “&lt;a href="https://arxiv.org/abs/1710.09829" rel="nofollow"&gt;胶囊间的动态路由&lt;/a&gt;”。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ShichenLiu/CondenseNet"&gt;CondenseNet&lt;/a&gt;: CondenseNet: 面向移动设备的轻量级 CNN。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5300+&lt;/kbd&gt; &lt;a href="https://github.com/DmitryUlyanov/deep-image-prior"&gt;deep-image-prior&lt;/a&gt;: 基于神经网络的图像修复，无学习过程。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/natanielruiz/deep-head-pose"&gt;deep-head-pose&lt;/a&gt;: 使用PyTorch进行深度学习头部姿势估计。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zhunzhong07/Random-Erasing"&gt;Random-Erasing&lt;/a&gt;: 论文代码，论文："&lt;a href="https://arxiv.org/abs/1708.04896" rel="nofollow"&gt;随机擦除数据增强&lt;/a&gt;"。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/FaderNetworks"&gt;FaderNetworks&lt;/a&gt;: Fader Networks: 通过滑动属性重构图像 - NIPS 2017，&lt;a href="https://arxiv.org/pdf/1706.00409.pdf" rel="nofollow"&gt;https://arxiv.org/pdf/1706.00409.pdf&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1500+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/flownet2-pytorch"&gt;FlowNet 2.0&lt;/a&gt;: FlowNet 2.0: 深度网络中光流估计的演化。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;4000+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/pix2pixHD"&gt;pix2pixHD&lt;/a&gt;: 利用条件 GANs 合成和处理 HD 高清图像的 PyTorch 实现，&lt;a href="https://arxiv.org/pdf/1711.11585.pdf%E3%80%82" rel="nofollow"&gt;https://arxiv.org/pdf/1711.11585.pdf。&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pkdn/pytorch-smoothgrad"&gt;pytorch-smoothgrad&lt;/a&gt;: SmoothGrad通过增加噪声来去除噪声。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/c0nn3r/RetinaNet"&gt;RetinaNet&lt;/a&gt;: RetinaNe实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;4300+&lt;/kbd&gt; &lt;a href="https://github.com/jwyang/faster-rcnn.pytorch"&gt;faster-rcnn.pytorch&lt;/a&gt;: This project is a faster faster R-CNN implementation, aimed to accelerating the training of faster R-CNN object detection models.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/leehomyc/mixup_pytorch"&gt;mixup_pytorch&lt;/a&gt;: A PyTorch implementation of the paper Mixup: Beyond Empirical Risk Minimization in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mapillary/inplace_abn"&gt;inplace_abn&lt;/a&gt;: In-Place Activated BatchNorm for Memory-Optimized Training of DNNs&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/xingyizhou/pytorch-pose-hg-3d"&gt;pytorch-pose-hg-3d&lt;/a&gt;: PyTorch implementation for 3D human pose estimation&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/HarshTrivedi/nmn-pytorch"&gt;nmn-pytorch&lt;/a&gt;: Neural Module Network for VQA in Pytorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kefirski/bytenet"&gt;bytenet&lt;/a&gt;: Pytorch implementation of bytenet from "Neural Machine Translation in Linear Time" paper&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hengyuan-hu/bottom-up-attention-vqa"&gt;bottom-up-attention-vqa&lt;/a&gt;: vqa, bottom-up-attention, pytorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ruiminshen/yolo2-pytorch"&gt;yolo2-pytorch&lt;/a&gt;: The YOLOv2 is one of the most popular one-stage object detector. This project adopts PyTorch as the developing framework to increase productivity, and utilize ONNX to convert models into Caffe 2 to benifit engineering deployment.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Wizaron/reseg-pytorch"&gt;reseg-pytorch&lt;/a&gt;: PyTorch 实现ReSeg。 (&lt;a href="https://arxiv.org/pdf/1511.07053.pdf" rel="nofollow"&gt;https://arxiv.org/pdf/1511.07053.pdf&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Wizaron/binary-stochastic-neurons"&gt;binary-stochastic-neurons&lt;/a&gt;: Binary Stochastic Neurons in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/DavexPro/pytorch-pose-estimation"&gt;pytorch-pose-estimation&lt;/a&gt;: PyTorch Implementation of Realtime Multi-Person Pose Estimation project.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/higgsfield/interaction_network_pytorch"&gt;interaction_network_pytorch&lt;/a&gt;: Pytorch Implementation of Interaction Networks for Learning about Objects, Relations and Physics.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wlwkgus/NoisyNaturalGradient"&gt;NoisyNaturalGradient&lt;/a&gt;: Pytorch Implementation of paper "Noisy Natural Gradient as Variational Inference".&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/moskomule/ewc.pytorch"&gt;ewc.pytorch&lt;/a&gt;: An implementation of Elastic Weight Consolidation (EWC), proposed in James Kirkpatrick et al. Overcoming catastrophic forgetting in neural networks 2016(10.1073/pnas.1611835114).&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jacobgil/pytorch-zssr"&gt;pytorch-zssr&lt;/a&gt;: PyTorch implementation of 1712.06087 "Zero-Shot" Super-Resolution using Deep Internal Learning&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/atiyo/deep_image_prior"&gt;deep_image_prior&lt;/a&gt;: 基于未训练神经网络的图像重建算法实现。算法：&lt;a href="https://arxiv.org/abs/1711.10925" rel="nofollow"&gt;Deep Image Prior&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/leviswind/pytorch-transformer"&gt;pytorch-transformer&lt;/a&gt;: PyTorch实现论文&lt;a href="https://arxiv.org/abs/1706.03762" rel="nofollow"&gt;Attention Is All You Need&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/devendrachaplot/DeepRL-Grounding"&gt;DeepRL-Grounding&lt;/a&gt;: PyTorch实现AAAI-18论文&lt;a href="https://arxiv.org/abs/1706.07230" rel="nofollow"&gt;Gated-Attention Architectures for Task-Oriented Language Grounding&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Wizaron/deep-forecast-pytorch"&gt;deep-forecast-pytorch&lt;/a&gt;: 使用LSTMs进行风速预测，论文：&lt;a href="arxiv.org/pdf/1707.08110.pdf"&gt;Deep Forecast: Deep Learning-based Spatio-Temporal Forecasting&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/utiasSTARS/cat-net"&gt;cat-net&lt;/a&gt;:  正则外观变换（&lt;a href="https://arxiv.org/abs/1709.03009" rel="nofollow"&gt;Canonical Appearance Transformations&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tneumann/minimal_glo"&gt;minimal_glo&lt;/a&gt;: Minimal PyTorch implementation of Generative Latent Optimization from the paper "Optimizing the Latent Space of Generative Networks"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dragen1860/LearningToCompare-Pytorch"&gt;LearningToCompare-Pytorch&lt;/a&gt;: Pytorch Implementation for Paper: Learning to Compare: Relation Network for Few-Shot Learning.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/poincare-embeddings"&gt;poincare-embeddings&lt;/a&gt;: PyTorch implementation of the NIPS-17 paper "Poincaré Embeddings for Learning Hierarchical Representations".&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/ikostrikov/pytorch-trpo"&gt;pytorch-trpo(Hessian-vector product version)&lt;/a&gt;: This is a PyTorch implementation of "Trust Region Policy Optimization (TRPO)" with exact Hessian-vector product instead of finite differences approximation.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/JamesChuanggg/ggnn.pytorch"&gt;ggnn.pytorch&lt;/a&gt;: A PyTorch Implementation of Gated Graph Sequence Neural Networks (GGNN).&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Mrgemy95/visual-interaction-networks-pytorch"&gt;visual-interaction-networks-pytorch&lt;/a&gt;: This's an implementation of deepmind Visual Interaction Networks paper using pytorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jhayes14/adversarial-patch"&gt;adversarial-patch&lt;/a&gt;: PyTorch实现对抗补丁。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch"&gt;Prototypical-Networks-for-Few-shot-Learning-PyTorch&lt;/a&gt;: Implementation of Prototypical Networks for Few Shot Learning (arxiv.org/abs/1703.05175) in Pytorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/orobix/Visual-Feature-Attribution-Using-Wasserstein-GANs-Pytorch"&gt;Visual-Feature-Attribution-Using-Wasserstein-GANs-Pytorch&lt;/a&gt;: Implementation of Visual Feature Attribution using Wasserstein GANs (arxiv.org/abs/1711.08998) in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Blade6570/PhotographicImageSynthesiswithCascadedRefinementNetworks-Pytorch"&gt;PhotographicImageSynthesiswithCascadedRefinementNetworks-Pytorch&lt;/a&gt;: 用级联优化网络生成照片级图像，&lt;a href="https://arxiv.org/abs/1707.09405" rel="nofollow"&gt;https://arxiv.org/abs/1707.09405&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1900+&lt;/kbd&gt; &lt;a href="https://github.com/carpedm20/ENAS-pytorch"&gt;ENAS-pytorch&lt;/a&gt;: PyTorch实现"&lt;a href="https://arxiv.org/abs/1802.03268" rel="nofollow"&gt;基于参数共享的高效神经网络结构搜索&lt;/a&gt;"。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kentsyx/Neural-IMage-Assessment"&gt;Neural-IMage-Assessment&lt;/a&gt;: 神经图片评估，&lt;a href="https://arxiv.org/abs/1709.05424" rel="nofollow"&gt;https://arxiv.org/abs/1709.05424&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tfrerix/proxprop"&gt;proxprop&lt;/a&gt;: 近端回传(Proximal Backpropagation) - 隐式梯度代替显式梯度的神经网络训练算法。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;9900+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/FastPhotoStyle"&gt;FastPhotoStyle&lt;/a&gt;: 照片级逼真的图像风格化的一个封闭解。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Ben-Louis/Deep-Image-Analogy-PyTorch"&gt;Deep-Image-Analogy-PyTorch&lt;/a&gt;: 基于PyTorch的深度图像模拟的Python实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/layumi/Person_reID_baseline_pytorch"&gt;Person-reID_pytorch&lt;/a&gt;: 行人再识别Person-reID的PyTorch实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zalandoresearch/pt-dilate-rnn"&gt;pt-dilate-rnn&lt;/a&gt;: 空洞递归神经网络（Dilated RNNs）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jhjacobsen/pytorch-i-revnet"&gt;pytorch-i-revnet&lt;/a&gt;: Pytorch实现i-RevNets。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Orcuslc/OrthNet"&gt;OrthNet&lt;/a&gt;: TensorFlow、PyTorch和Numpy层生成正交多项式。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jt827859032/DRRN-pytorch"&gt;DRRN-pytorch&lt;/a&gt;: "&lt;a href="http://cvlab.cse.msu.edu/pdfs/Tai_Yang_Liu_CVPR2017.pdf" rel="nofollow"&gt;超分辨率的深递归残差网络(DRRN)&lt;/a&gt;", CVPR 2017&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/moskomule/shampoo.pytorch"&gt;shampoo.pytorch&lt;/a&gt;: Shampoo算法实现。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/truskovskiyk/nima.pytorch"&gt;Neural-IMage-Assessment 2&lt;/a&gt;: 神经图片评估，&lt;a href="https://arxiv.org/abs/1709.05424" rel="nofollow"&gt;https://arxiv.org/abs/1709.05424&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1900+&lt;/kbd&gt; &lt;a href="https://github.com/locuslab/TCN"&gt;TCN&lt;/a&gt;: Sequence modeling benchmarks and temporal convolutional networks locuslab/TCN&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/shahsohil/DCC"&gt;DCC&lt;/a&gt;: This repository contains the source code and data for reproducing results of Deep Continuous Clustering paper.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/arunmallya/packnet"&gt;packnet&lt;/a&gt;: Code for PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning arxiv.org/abs/1711.05769&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/github-pengge/PyTorch-progressive_growing_of_gans"&gt;PyTorch-progressive_growing_of_gans&lt;/a&gt;: PyTorch implementation of Progressive Growing of GANs for Improved Quality, Stability, and Variation.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/salesforce/nonauto-nmt"&gt;nonauto-nmt&lt;/a&gt;: PyTorch Implementation of "Non-Autoregressive Neural Machine Translation"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;4500+&lt;/kbd&gt; &lt;a href="https://github.com/eriklindernoren/PyTorch-GAN"&gt;PyTorch-GAN&lt;/a&gt;: PyTorch implementations of Generative Adversarial Networks.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tomrunia/PyTorchWavelets"&gt;PyTorchWavelets&lt;/a&gt;: PyTorch implementation of the wavelet analysis found in Torrence and Compo (1998)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/karpathy/pytorch-made"&gt;pytorch-made&lt;/a&gt;: MADE (Masked Autoencoder Density Estimation) implementation in PyTorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/emited/VariationalRecurrentNeuralNetwork"&gt;VRNN&lt;/a&gt;: Pytorch implementation of the Variational RNN (VRNN), from A Recurrent Latent Variable Model for Sequential Data.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/emited/flow"&gt;flow&lt;/a&gt;: Pytorch implementation of ICLR 2018 paper Deep Learning for Physical Processes: Integrating Prior Scientific Knowledge.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/r9y9/deepvoice3_pytorch"&gt;deepvoice3_pytorch&lt;/a&gt;: PyTorch实现基于卷积神经网络的语音合成模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/elanmart/psmm"&gt;psmm&lt;/a&gt;: imlementation of the the Pointer Sentinel Mixture Model, as described in the paper by Stephen Merity et al.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/tacotron2"&gt;tacotron2&lt;/a&gt;: Tacotron 2 - PyTorch implementation with faster-than-realtime inference.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rahulkidambi/AccSGD"&gt;AccSGD&lt;/a&gt;: Implements pytorch code for the Accelerated SGD algorithm.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hengruo/QANet-pytorch"&gt;QANet-pytorch&lt;/a&gt;: an implementation of QANet with PyTorch (EM/F1 = 70.5/77.2 after 20 epoches for about 20 hours on one 1080Ti card.)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/TimDettmers/ConvE"&gt;ConvE&lt;/a&gt;: Convolutional 2D Knowledge Graph Embeddings&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kaushalshetty/Structured-Self-Attention"&gt;Structured-Self-Attention&lt;/a&gt;: Implementation for the paper A Structured Self-Attentive Sentence Embedding, which is published in ICLR 2017: arxiv.org/abs/1703.03130 .&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/williamleif/graphsage-simple"&gt;graphsage-simple&lt;/a&gt;: Simple reference implementation of GraphSAGE.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2500+&lt;/kbd&gt; &lt;a href="https://github.com/roytseng-tw/Detectron.pytorch"&gt;Detectron.pytorch&lt;/a&gt;: A pytorch implementation of Detectron. Both training from scratch and inferring directly from pretrained Detectron weights are available.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/irhumshafkat/R2Plus1D-PyTorch"&gt;R2Plus1D-PyTorch&lt;/a&gt;: PyTorch implementation of the R2Plus1D convolution based ResNet architecture described in the paper "A Closer Look at Spatiotemporal Convolutions for Action Recognition"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/viking-sudo-rm/StackNN"&gt;StackNN&lt;/a&gt;: A PyTorch implementation of differentiable stacks for use in neural networks.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/translagent"&gt;translagent&lt;/a&gt;: Code for Emergent Translation in Multi-Agent Communication.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jnhwkim/ban-vqa"&gt;ban-vqa&lt;/a&gt;: Bilinear attention networks for visual question answering.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/huggingface/pytorch-openai-transformer-lm"&gt;pytorch-openai-transformer-lm&lt;/a&gt;: This is a PyTorch implementation of the TensorFlow code provided with OpenAI's paper "Improving Language Understanding by Generative Pre-Training" by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/akanimax/T2F"&gt;T2F&lt;/a&gt;: 使用深度学习进行Text-to-Face生成。该项目结合了&lt;a href="https://arxiv.org/abs/1710.10916" rel="nofollow"&gt;StackGAN&lt;/a&gt;和&lt;a href="https://arxiv.org/abs/1710.10196" rel="nofollow"&gt;ProGAN&lt;/a&gt;，这两个模型可以基于文字描述合成人脸。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mseitzer/pytorch-fid"&gt;pytorch - fid&lt;/a&gt;: A Port of Fréchet Inception Distance (FID score) to PyTorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jmtomczak/vae_vpflows"&gt;vae_vpflows&lt;/a&gt;:Code in PyTorch for the convex combination linear IAF and the Householder Flow, J.M. Tomczak &amp;amp; M. Welling jmtomczak.github.io/deebmed.html&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mkocabas/CoordConv-pytorch"&gt;CoordConv-pytorch&lt;/a&gt;: Pytorch implementation of CoordConv introduced in 'An intriguing failing of convolutional neural networks and the CoordConv solution' paper. (arxiv.org/pdf/1807.03247.pdf)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/xternalz/SDPoint"&gt;SDPoint&lt;/a&gt;: Implementation of "Stochastic Downsampling for Cost-Adjustable Inference and Improved Regularization in Convolutional Networks", published in CVPR 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wxywhu/SRDenseNet-pytorch"&gt;SRDenseNet-pytorch&lt;/a&gt;: 极深网络，SRDenseNet-pytorch，论文：&lt;a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Tong_Image_Super-Resolution_Using_ICCV_2017_paper.pdf" rel="nofollow"&gt;基于密集跳跃连接的图像超分辨率（ICCV_2017）&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/LMescheder/GAN_stability"&gt;GAN_stability&lt;/a&gt;: Code for paper "Which Training Methods for GANs do actually Converge? (ICML 2018)"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wannabeOG/Mask-RCNN"&gt;Mask-RCNN&lt;/a&gt;: A PyTorch implementation of the architecture of Mask RCNN, serves as an introduction to working with PyTorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/chaoyuaw/pytorch-coviar"&gt;pytorch-coviar&lt;/a&gt;: Compressed Video Action Recognition&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/chenxi116/PNASNet.pytorch"&gt;PNASNet.pytorch&lt;/a&gt;: PyTorch implementation of PNASNet-5 on ImageNet.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kevinzakka/NALU-pytorch"&gt;NALU-pytorch&lt;/a&gt;: Basic pytorch implementation of NAC/NALU from Neural Arithmetic Logic Units arxiv.org/pdf/1808.00508.pdf&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/alexis-jacq/LOLA_DiCE"&gt;LOLA_DiCE&lt;/a&gt;: Pytorch 使用&lt;a href="arxiv.org/abs/1802.05098"&gt;DiCE&lt;/a&gt;实现&lt;a href="arxiv.org/abs/1709.04326"&gt;LOLA&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wohlert/generative-query-network-pytorch"&gt;generative-query-network-pytorch&lt;/a&gt;: Generative Query Network (GQN) in PyTorch as described in "Neural Scene Representation and Rendering"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wmvanvliet/pytorch_hmax"&gt;pytorch_hmax&lt;/a&gt;: 在PyTorch中实现&lt;a href="https://maxlab.neuro.georgetown.edu/hmax.html#inside" rel="nofollow"&gt;HMAX(Hierarchical Model and X)&lt;/a&gt;视觉模型。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/yunlongdong/FCN-pytorch-easiest"&gt;FCN-pytorch-easiest&lt;/a&gt;: trying to be the most easiest and just get-to-use pytorch implementation of FCN (Fully Convolotional Networks)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/awni/transducer"&gt;transducer&lt;/a&gt;: A Fast Sequence Transducer Implementation with PyTorch Bindings.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/artix41/AVO-pytorch"&gt;AVO-pytorch&lt;/a&gt;: Implementation of Adversarial Variational Optimization in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/huguyuehuhu/HCN-pytorch"&gt;HCN-pytorch&lt;/a&gt;: A pytorch reimplementation of { Co-occurrence Feature Learning from Skeleton Data for Action Recognition and Detection with Hierarchical Aggregation }.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/szagoruyko/binary-wide-resnet"&gt;binary-wide-resnet&lt;/a&gt;: PyTorch implementation of Wide Residual Networks with 1-bit weights by McDonnel (ICLR 2018)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/arunmallya/piggyback"&gt;piggyback&lt;/a&gt;: Code for Piggyback: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights arxiv.org/abs/1801.06519&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;6900+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/vid2vid"&gt;vid2vid&lt;/a&gt;: Pytorch implementation of our method for high-resolution (e.g. 2048x1024) photorealistic video-to-video translation.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/cranmer/poisson-convolution-sum"&gt;poisson-convolution-sum&lt;/a&gt;: Implements an infinite sum of poisson-weighted convolutions&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/davidmascharka/tbd-nets"&gt;tbd-nets&lt;/a&gt;: PyTorch implementation of "Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning" arxiv.org/abs/1803.05268&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/elbayadm/attn2d"&gt;attn2d&lt;/a&gt;: Pervasive Attention: 2D Convolutional Networks for Sequence-to-Sequence Prediction&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2600+&lt;/kbd&gt; &lt;a href="https://github.com/ultralytics/yolov3"&gt;yolov3&lt;/a&gt;: YOLOv3: 训练和推断，&lt;a href="https://www.ultralytics.com" rel="nofollow"&gt;https://www.ultralytics.com&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/duc0/deep-dream-in-pytorch"&gt;deep-dream-in-pytorch&lt;/a&gt;: Pytorch implementation of the DeepDream computer vision algorithm.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ikostrikov/pytorch-flows"&gt;pytorch-flows&lt;/a&gt;: PyTorch implementations of algorithms for density estimation&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ars-ashuha/quantile-regression-dqn-pytorch"&gt;quantile-regression-dqn-pytorch&lt;/a&gt;: Quantile Regression DQN a Minimal Working Example&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/L0SG/relational-rnn-pytorch"&gt;relational-rnn-pytorch&lt;/a&gt;: An implementation of DeepMind's Relational Recurrent Neural Networks in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/scaelles/DEXTR-PyTorch"&gt;DEXTR-PyTorch&lt;/a&gt;: 深度极端切割，&lt;a href="http://www.vision.ee.ethz.ch/~cvlsegmentation/dextr" rel="nofollow"&gt;http://www.vision.ee.ethz.ch/~cvlsegmentation/dextr&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rdspring1/PyTorch_GBW_LM"&gt;PyTorch_GBW_LM&lt;/a&gt;: PyTorch Language Model for Google Billion Word Dataset.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Stonesjtu/Pytorch-NCE"&gt;Pytorch-NCE&lt;/a&gt;: The Noise Contrastive Estimation for softmax output written in Pytorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/shayneobrien/generative-models"&gt;generative-models&lt;/a&gt;: Annotated, understandable, and visually interpretable PyTorch implementations of: VAE, BIRVAE, NSGAN, MMGAN, WGAN, WGANGP, LSGAN, DRAGAN, BEGAN, RaGAN, InfoGAN, fGAN, FisherGAN.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/andreasveit/convnet-aig"&gt;convnet-aig&lt;/a&gt;: PyTorch implementation for Convolutional Networks with Adaptive Inference Graphs.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/TianhongDai/integrated-gradient-pytorch"&gt;integrated-gradient-pytorch&lt;/a&gt;: This is the pytorch implementation of the paper - Axiomatic Attribution for Deep Networks.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Alexander-H-Liu/MalConv-Pytorch"&gt;MalConv-Pytorch&lt;/a&gt;: Pytorch implementation of MalConv.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/locuslab/trellisnet"&gt;trellisnet&lt;/a&gt;: Trellis Networks for Sequence Modeling&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/minqi/learning-to-communicate-pytorch"&gt;Learning to Communicate with Deep Multi-Agent Reinforcement Learning&lt;/a&gt;: pytorch implementation of  Learning to Communicate with Deep Multi-Agent Reinforcement Learning paper.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/michaelklachko/pnn.pytorch"&gt;pnn.pytorch&lt;/a&gt;: PyTorch implementation of CVPR'18 - Perturbative Neural Networks &lt;a href="http://xujuefei.com/pnn.html" rel="nofollow"&gt;http://xujuefei.com/pnn.html&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rainofmine/Face_Attention_Network"&gt;Face_Attention_Network&lt;/a&gt;: Pytorch implementation of face attention network as described in Face Attention Network: An Effective Face Detector for the Occluded Faces.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/waveglow"&gt;waveglow&lt;/a&gt;: 基于流的语音合成生成网络。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/deepfloat"&gt;deepfloat&lt;/a&gt;: This repository contains the SystemVerilog RTL, C++, HLS (Intel FPGA OpenCL to wrap RTL code) and Python needed to reproduce the numerical results in "Rethinking floating point for deep learning"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/subeeshvasu/2018_subeesh_epsr_eccvw"&gt;EPSR&lt;/a&gt;: Pytorch implementation of &lt;a href="https://arxiv.org/pdf/1811.00344.pdf" rel="nofollow"&gt;Analyzing Perception-Distortion Tradeoff using Enhanced Perceptual Super-resolution Network&lt;/a&gt;. This work has won the first place in PIRM2018-SR competition (region 1) held as part of the ECCV 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ksw0306/ClariNet"&gt;ClariNet&lt;/a&gt;: Pytorch实现&lt;a href="https://arxiv.org/abs/1807.07281" rel="nofollow"&gt;ClariNet&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;16600+&lt;/kbd&gt; &lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT"&gt;pytorch-pretrained-BERT&lt;/a&gt;: PyTorch version of Google AI's BERT model with script to load Google's pre-trained models&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/npuichigo/waveglow"&gt;torch_waveglow&lt;/a&gt;: PyTorch实现WaveGlow: 基于流的语音合成生成网络。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2100+&lt;/kbd&gt; &lt;a href="https://github.com/cleardusk/3DDFA"&gt;3DDFA&lt;/a&gt;: The pytorch improved re-implementation of TPAMI 2017 paper: Face Alignment in Full Pose Range: A 3D Total Solution.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/tomgoldstein/loss-landscape"&gt;loss-landscape&lt;/a&gt;: loss-landscape Code for visualizing the loss landscape of neural nets.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zalandoresearch/famos"&gt;famos&lt;/a&gt;:（非）参数图像风格化马赛克的对抗性框架。论文：&lt;a href="http://arxiv.org/abs/1811.09236" rel="nofollow"&gt;http://arxiv.org/abs/1811.09236&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/anuragranj/back2future.pytorch"&gt;back2future.pytorch&lt;/a&gt;: This is a Pytorch implementation of
Janai, J., Güney, F., Ranjan, A., Black, M. and Geiger, A., Unsupervised Learning of Multi-Frame Optical Flow with Occlusions. ECCV 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mozilla/FFTNet"&gt;FFTNet&lt;/a&gt;: Unofficial Implementation of FFTNet vocode paper.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zisianw/FaceBoxes.PyTorch"&gt;FaceBoxes.PyTorch&lt;/a&gt;: PyTorch实现&lt;a href="https://arxiv.org/abs/1708.05234" rel="nofollow"&gt;FaceBoxes&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2100+&lt;/kbd&gt; &lt;a href="https://github.com/kimiyoung/transformer-xl"&gt;Transformer-XL&lt;/a&gt;: Transformer-XL: Attentive Language Models Beyond a Fixed-Length Contexthttps://github.com/kimiyoung/transformer-xl&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jalexvig/associative_compression_networks"&gt;associative_compression_networks&lt;/a&gt;: Associative Compression Networks for Representation Learning.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jolibrain/fluidnet_cxx"&gt;fluidnet_cxx&lt;/a&gt;: FluidNet re-written with ATen tensor lib.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch"&gt;Deep-Reinforcement-Learning-Algorithms-with-PyTorch&lt;/a&gt;: This repository contains PyTorch implementations of deep reinforcement learning algorithms.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ericsun99/Shufflenet-v2-Pytorch"&gt;Shufflenet-v2-Pytorch&lt;/a&gt;: This is a Pytorch implementation of faceplusplus's ShuffleNet-v2.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/GraphWaveletNeuralNetwork"&gt;GraphWaveletNeuralNetwork&lt;/a&gt;: This is a Pytorch implementation of Graph Wavelet Neural Network. ICLR 2019.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/AttentionWalk"&gt;AttentionWalk&lt;/a&gt;: This is a Pytorch implementation of Watch Your Step: Learning Node Embeddings via Graph Attention. NIPS 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/SGCN"&gt;SGCN&lt;/a&gt;: This is a Pytorch implementation of Signed Graph Convolutional Network. ICDM 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/SINE"&gt;SINE&lt;/a&gt;: This is a Pytorch implementation of SINE: Scalable Incomplete Network Embedding. ICDM 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/GAM"&gt;GAM&lt;/a&gt;: This is a Pytorch implementation of Graph Classification using Structural Attention. KDD 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ProGamerGov/neural-style-pt"&gt;neural-style-pt&lt;/a&gt;: PyTorch 实现 Justin Johnson 的神经风格算法。论文：&lt;a href="https://arxiv.org/abs/1508.06576" rel="nofollow"&gt;A Neural Algorithm of Artistic Style&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ibalazevic/TuckER"&gt;TuckER&lt;/a&gt;: TuckER: Tensor Factorization for Knowledge Graph Completion.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BayesWatch/pytorch-prunes"&gt;pytorch-prunes&lt;/a&gt;: Pruning neural networks: is it time to nip it in the bud?&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/SimGNN"&gt;SimGNN&lt;/a&gt;: SimGNN: 一个快速图形相似度计算的神经网络方法。论文：A Neural Network Approach to Fast Graph Similarity Computation.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ahmedbesbes/character-based-cnn"&gt;Character CNN&lt;/a&gt;: PyTorch implementation of the Character-level Convolutional Networks for Text Classification paper.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/XLM"&gt;XLM&lt;/a&gt;: PyTorch original implementation of Cross-lingual Language Model Pretraining.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/eth-sri/diffai"&gt;DiffAI&lt;/a&gt;: A provable defense against adversarial examples and library for building compatible PyTorch models.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/APPNP"&gt;APPNP&lt;/a&gt;: Combining Neural Networks with Personalized PageRank for Classification on Graphs. ICLR 2019.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/MixHop-and-N-GCN"&gt;NGCN&lt;/a&gt;: A Higher-Order Graph Convolutional Layer. NeurIPS 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/graykode/gpt-2-Pytorch"&gt;gpt-2-Pytorch&lt;/a&gt;: Simple Text-Generator with OpenAI gpt-2 Pytorch Implementation&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/Splitter"&gt;Splitter&lt;/a&gt;: Splitter: Learning Node Representations that Capture Multiple Social Contexts. (WWW 2019).&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/CapsGNN"&gt;CapsGNN&lt;/a&gt;: 胶囊图神经网络，&lt;a href="https://openreview.net/forum?id=Byl8BnRcYm" rel="nofollow"&gt;Capsule Graph Neural Network&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/ajbrock/BigGAN-PyTorch"&gt;BigGAN-PyTorch&lt;/a&gt;: PyTorch实现BigGAN（非官方）。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mhubii/ppo_pytorch_cpp"&gt;ppo_pytorch_cpp&lt;/a&gt;: 近端策略优化算法的C++ API。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/seungwonpark/RandWireNN"&gt;RandWireNN&lt;/a&gt;: 基于随机连接神经网络性能的图像识别。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/joel-huang/zeroshot-capsnet-pytorch"&gt;Zero-shot Intent CapsNet&lt;/a&gt;: GPU-accelerated PyTorch implementation of "Zero-shot User Intent Detection via Capsule Neural Networks".&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/SEAL-CI"&gt;SEAL-CI&lt;/a&gt; 半监督图分类：层次图视角，Semi-Supervised Graph Classification: A Hierarchical Graph Perspective. (WWW 2019)。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/MixHop-and-N-GCN"&gt;MixHop&lt;/a&gt;: MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing. ICML 2019.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Lotayou/densebody_pytorch"&gt;densebody_pytorch&lt;/a&gt;: PyTorch implementation of CloudWalk's recent paper DenseBody.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mindslab-ai/voicefilter"&gt;voicefilter&lt;/a&gt;: Unofficial PyTorch implementation of Google AI's VoiceFilter system &lt;a href="http://swpark.me/voicefilter" rel="nofollow"&gt;http://swpark.me/voicefilter&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/semantic-segmentation"&gt;NVIDIA/semantic-segmentation&lt;/a&gt;: PyTorch实现“利用视频传播和标签松弛改进语义分割”。论文：&lt;a href="https://arxiv.org/abs/1812.01593" rel="nofollow"&gt;Improving Semantic Segmentation via Video Propagation and Label Relaxation&lt;/a&gt;, In CVPR2019.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/ClusterGCN"&gt;ClusterGCN&lt;/a&gt;: A PyTorch implementation of "Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks" (KDD 2019).&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/NVlabs/DG-Net"&gt;NVlabs/DG-Net&lt;/a&gt;: A PyTorch implementation of "Joint Discriminative and Generative Learning for Person Re-identification" (CVPR19 Oral).&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/baidu-research/NCRF"&gt;NCRF&lt;/a&gt;: 基于神经网络条件随机场(NCRF)的肿瘤转移检测，相关论文：&lt;a href="https://openreview.net/forum?id=S1aY66iiM%E3%80%82" rel="nofollow"&gt;https://openreview.net/forum?id=S1aY66iiM。&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ducha-aiki/pytorch-sift"&gt;pytorch-sift&lt;/a&gt;: PyTorch实现SIFT（尺度不变特征变换匹配算法，Scale Invariant Feature Transform）描述子。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mateuszbuda/brain-segmentation-pytorch"&gt;brain-segmentation-pytorch&lt;/a&gt;: 深度学习分割网络U-Net的PyTorch模型实现，用于脑核磁共振中FLAIR异常的分割。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rosinality/glow-pytorch"&gt;glow-pytorch&lt;/a&gt;: PyTorch 实现 "&lt;a href="https://arxiv.org/abs/1807.03039" rel="nofollow"&gt;Glow, Generative Flow with Invertible 1x1 Convolutions&lt;/a&gt;"。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zsef123/EfficientNets-PyTorch"&gt;EfficientNets-PyTorch&lt;/a&gt;: PyTorch实现EfficientNet: 卷积神经网络模型尺度的再思考。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/nv-tlabs/STEAL"&gt;STEAL&lt;/a&gt;: STEAL - 从噪声标注中学习语义边界，&lt;a href="https://nv-tlabs.github.io/STEAL/" rel="nofollow"&gt;https://nv-tlabs.github.io/STEAL/&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/alecwangcq/EigenDamage-Pytorch"&gt;EigenDamage-Pytorch&lt;/a&gt;: 官方实现 ICML'19 论文 "&lt;a href="https://arxiv.org/abs/1905.05934" rel="nofollow"&gt;特征损伤：克罗内克分解特征基中的结构剪枝&lt;/a&gt;"。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ruidan/Aspect-level-sentiment"&gt;Aspect-level-sentiment&lt;/a&gt;: 论文代码和数据集，ACL2018论文："&lt;a href="https://arxiv.org/abs/1806.04346" rel="nofollow"&gt;利用文档知识进行体层情感分类&lt;/a&gt;"。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/nyukat/breast_cancer_classifier"&gt;breast_cancer_classifier&lt;/a&gt;: 深层神经网络提高放射科医生乳腺癌筛查的效果，&lt;a href="https://arxiv.org/abs/1903.08297" rel="nofollow"&gt;https://arxiv.org/abs/1903.08297&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/AaltoVision/DGC-Net"&gt;DGC-Net&lt;/a&gt;: PyTorch实现"&lt;a href="https://arxiv.org/abs/1810.08393" rel="nofollow"&gt;DGC-Net: 密集几何对应网络&lt;/a&gt;".&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Eric-Wallace/universal-triggers"&gt;universal-triggers&lt;/a&gt;: Universal Adversarial Triggers for Attacking and Analyzing NLP (EMNLP 2019)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch"&gt;Deep-Reinforcement-Learning-Algorithms-with-PyTorch&lt;/a&gt;: PyTorch implementations of deep reinforcement learning algorithms and environments.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/alibaba-edu/simple-effective-text-matching-pytorch"&gt;simple-effective-text-matching-pytorch&lt;/a&gt;: A pytorch implementation of the ACL2019 paper "Simple and Effective Text Matching with Richer Alignment Features".&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/utkuozbulak/adaptive-segmentation-mask-attack"&gt;Adaptive-segmentation-mask-attack (ASMA)&lt;/a&gt;: A pytorch implementation of the MICCAI2019 paper "Impact of Adversarial Examples on Deep Learning Models for Biomedical Image Segmentation".&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/NVIDIA/unsupervised-video-interpolation"&gt;NVIDIA/unsupervised-video-interpolation&lt;/a&gt;: A PyTorch Implementation of &lt;a href="https://arxiv.org/abs/1906.05928" rel="nofollow"&gt;Unsupervised Video Interpolation Using Cycle Consistency&lt;/a&gt;, In ICCV 2019.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-talks--conferences报告--会议" class="anchor" aria-hidden="true" href="#talks--conferences报告--会议"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Talks &amp;amp; conferences｜报告 &amp;amp; 会议&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://developers.facebook.com/videos/2018/pytorch-developer-conference/" rel="nofollow"&gt;PyTorch Conference 2018&lt;/a&gt;: 2018年首届PyTorch开发者大会。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-pytorch-elsewhere--pytorch相关" class="anchor" aria-hidden="true" href="#pytorch-elsewhere--pytorch相关"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pytorch elsewhere ｜ Pytorch相关&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;4100+&lt;/kbd&gt; &lt;a href="https://github.com/ritchieng/the-incredible-pytorch"&gt;the-incredible-pytorch&lt;/a&gt;**: 不可思议的Pythorch：一份PyTorch相关的教程、论文、项目、社区等的清单。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5500+&lt;/kbd&gt; &lt;a href="https://github.com/wiseodd/generative-models"&gt;generative models&lt;/a&gt;: 各种生成模型，例如基于Pytorch和Tensorflow的GAN、VAE。 &lt;a href="http://wiseodd.github.io" rel="nofollow"&gt;http://wiseodd.github.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/MachineLearning/comments/5w3q74/d_so_pytorch_vs_tensorflow_whats_the_verdict_on/" rel="nofollow"&gt;pytorch vs tensorflow&lt;/a&gt;: Reddit上的PyTorch和TensorFlow的比较文章。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://discuss.pytorch.org/" rel="nofollow"&gt;Pytorch discussion forum&lt;/a&gt;: PyTorch论坛。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://hub.docker.com/r/escong/pytorch-notebook/" rel="nofollow"&gt;pytorch notebook: docker-stack&lt;/a&gt;: 类似于 &lt;a href="https://github.com/jupyter/docker-stacks/tree/master/scipy-notebook"&gt;Jupyter Notebook Scientific Python Stack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kendricktan/drawlikebobross"&gt;drawlikebobross&lt;/a&gt;: 使用神经网络作画！&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/t-vi/pytorch-tvmisc"&gt;pytorch-tvmisc&lt;/a&gt;: 该仓库收集了作者用PyTorch实现的各种玩意儿。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/andrewliao11/pytorch-a3c-mujoco"&gt;pytorch-a3c-mujoco&lt;/a&gt;: 该项目旨在解决Mujoco中的控制问题，高度基于pytorch-a3c。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=nbJ-2G2GXL0&amp;amp;list=WL&amp;amp;index=9" rel="nofollow"&gt;PyTorch in 5 Minutes&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jinfagang/pytorch_chatbot"&gt;pytorch_chatbot&lt;/a&gt;: 用PyTorch实现的聊天机器人。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Kaixhin/malmo-challenge"&gt;malmo-challenge&lt;/a&gt;: Malmo协作人工智能挑战-Pig Catcher团队。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jtoy/sketchnet"&gt;sketchnet&lt;/a&gt;: 指导计算机作画。&lt;a href="http://www.jtoy.net/projects/sketchnet/" rel="nofollow"&gt;http://www.jtoy.net/projects/sketchnet/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/QuantScientist/Deep-Learning-Boot-Camp"&gt;Deep-Learning-Boot-Camp&lt;/a&gt;: 非盈利社区运营的5天深度学习训练营。 &lt;a href="http://deep-ml.com" rel="nofollow"&gt;http://deep-ml.com&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mratsim/Amazon_Forest_Computer_Vision"&gt;Amazon_Forest_Computer_Vision&lt;/a&gt;: 亚马逊森林计算机视觉：使用PyTorch标记卫星图像标记/Keras中的PyTorch技巧。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/junxiaosong/AlphaZero_Gomoku"&gt;AlphaZero_Gomoku&lt;/a&gt;: 用AlphaZero算法玩五子棋。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/youansheng/pytorch-cv"&gt;pytorch-cv&lt;/a&gt;: null.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/KaiyangZhou/deep-person-reid"&gt;deep-person-reid&lt;/a&gt;: Pytorch实现深度学习行人重新识别方法。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1300+&lt;/kbd&gt; &lt;a href="https://github.com/victoresque/pytorch-template"&gt;pytorch-template&lt;/a&gt;: PyTorch深度学习模版。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/svishnu88/DLwithPyTorch"&gt;Deep Learning With Pytorch&lt;/a&gt;: 随书代码《&lt;a href="https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-pytorch" rel="nofollow"&gt;Deep Learning With Pytorch TextBook&lt;/a&gt;》 PyTorch实用指南：使用PyTorch建立文本和视觉神经网络模型。&lt;a href="https://www.amazon.cn/dp/B078THDX3J/ref=sr_1_1?__mk_zh_CN=%E4%BA%9A%E9%A9%AC%E9%80%8A%E7%BD%91%E7%AB%99&amp;amp;keywords=Deep+Learning+with+PyTorch&amp;amp;qid=1568007543&amp;amp;s=gateway&amp;amp;sr=8-1" rel="nofollow"&gt;亚马逊中国电子版&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jalola/compare-tensorflow-pytorch"&gt;compare-tensorflow-pytorch&lt;/a&gt;: 比较用Tensorflow编写的层和用Pytorch编写的层之间的输出。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hasktorch/hasktorch"&gt;hasktorch&lt;/a&gt;: Haskell中的张量与神经网络。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.manning.com/books/deep-learning-with-pytorch" rel="nofollow"&gt;Deep Learning With Pytorch&lt;/a&gt; Deep Learning with PyTorch 教你如何用Python和PyTorch实现深度学习算法。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fragcolor-xyz/nimtorch"&gt;nimtorch&lt;/a&gt;: PyTorch - Python + Nim，PyTorch的Nim前端。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/John-Ellis/derplearning"&gt;derplearning&lt;/a&gt;: 自动驾驶遥控车代码。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tugstugi/pytorch-saltnet"&gt;pytorch-saltnet&lt;/a&gt;: Kaggle | TGS Salt Identification Challenge 第9名解决方案。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/peterjc123/pytorch-scripts"&gt;pytorch-scripts&lt;/a&gt;: 一些脚本，使在Windows上使用PyTorch更加容易。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ptrblck/pytorch_misc"&gt;pytorch_misc&lt;/a&gt;: 为PyTorch讨论板创建的代码片段。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/arnas/awesome-pytorch-scholarship"&gt;awesome-pytorch-scholarship&lt;/a&gt;: 收集了一系列优秀的PyTorch学术文章、指南、博客、课程和其他资源。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mmirman/MentisOculi"&gt;MentisOculi&lt;/a&gt;: PyTorch版raytracer。(raynet?)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2400+&lt;/kbd&gt; &lt;a href="https://github.com/karanchahal/DoodleMaster"&gt;DoodleMaster&lt;/a&gt;: “画出UI！”("Don't code your UI, Draw it !")&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/LaurentMazare/ocaml-torch"&gt;ocaml-torch&lt;/a&gt;: ocaml-torch为PyTorch张量库提供一些ocaml绑定。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/extension-script"&gt;extension-script&lt;/a&gt;: TorchScript自定义C++/CUDA运算符的示例。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zccyman/pytorch-inference"&gt;pytorch-inference&lt;/a&gt;:  Windows10 平台上 Pytorch 1.0在 C++ 中的推断。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Wizaron/pytorch-cpp-inference"&gt;pytorch-cpp-inference&lt;/a&gt;: 包含使用PyTorch C++ API执行推断的各种示例。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/LaurentMazare/tch-rs"&gt;tch-rs&lt;/a&gt;: PyTorch的Rust绑定。&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/interesaaat/TorchSharp"&gt;TorchSharp&lt;/a&gt;: Pytorch引擎的.NET绑定。&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ml-tooling/ml-workspace"&gt;ML Workspace&lt;/a&gt;: 面向机器学习和数据科学的一体化Web IDE。包含Jupyter, VS Code, PyTorch 和许多其他工具或库，这些都集合在一个Docker映像中。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Feedback: If you have any ideas or you want any other content to be added to this list, feel free to contribute.&lt;/strong&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>xavier-zy</author><guid isPermaLink="false">https://github.com/xavier-zy/Awesome-pytorch-list-CNVersion</guid><pubDate>Sun, 09 Feb 2020 00:01:00 GMT</pubDate></item><item><title>Atcold/pytorch-Deep-Learning-Minicourse #2 in Jupyter Notebook, Today</title><link>https://github.com/Atcold/pytorch-Deep-Learning-Minicourse</link><description>&lt;p&gt;&lt;i&gt;Deep Learning with PyTorch&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deep-learning-with-pytorch-" class="anchor" aria-hidden="true" href="#deep-learning-with-pytorch-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning with PyTorch &lt;a href="https://mybinder.org/v2/gh/Atcold/pytorch-Deep-Learning-Minicourse/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/483bae47a175c24dfbfc57390edd8b6982ac5fb3/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge_logo.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;This notebook repository now has a &lt;a href="https://atcold.github.io/pytorch-Deep-Learning-Minicourse/" rel="nofollow"&gt;companion website&lt;/a&gt;, where all the course mateiral can be found in video and textual format.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting started&lt;/h1&gt;
&lt;p&gt;To be able to follow the exercises, you are going to need a laptop with Miniconda (a minimal version of Anaconda) and several Python packages installed.
The following instruction would work as is for Mac or Ubuntu linux users, Windows users would need to install and work in the Gitbash terminal.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-download-and-install-miniconda" class="anchor" aria-hidden="true" href="#download-and-install-miniconda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Download and install Miniconda&lt;/h2&gt;
&lt;p&gt;Please go to the &lt;a href="https://conda.io/miniconda.html" rel="nofollow"&gt;Anaconda website&lt;/a&gt;.
Download and install &lt;em&gt;the latest&lt;/em&gt; Miniconda version for &lt;em&gt;Python&lt;/em&gt; 3.7 for your operating system.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;wget &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;http:// link to miniconda&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
sh &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;miniconda&lt;span class="pl-k"&gt;*&lt;/span&gt;.sh&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After that, type:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda --help&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and read the manual.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-check-out-the-git-repository-with-the-exercise" class="anchor" aria-hidden="true" href="#check-out-the-git-repository-with-the-exercise"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Check-out the git repository with the exercise&lt;/h2&gt;
&lt;p&gt;Once Miniconda is ready, checkout the course repository and and proceed with setting up the environment:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/Atcold/pytorch-Deep-Learning-Minicourse&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-create-isolated-miniconda-environment" class="anchor" aria-hidden="true" href="#create-isolated-miniconda-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Create isolated Miniconda environment&lt;/h2&gt;
&lt;p&gt;Change directory (&lt;code&gt;cd&lt;/code&gt;) into the course folder, then type:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; cd pytorch-Deep-Learning-Minicourse&lt;/span&gt;
conda env create -f environment.yml
&lt;span class="pl-c1"&gt;source&lt;/span&gt; activate dl-minicourse&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-start-jupyter-notebook-or-jupyterlab" class="anchor" aria-hidden="true" href="#start-jupyter-notebook-or-jupyterlab"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Start Jupyter notebook or JupyterLab&lt;/h2&gt;
&lt;p&gt;Start from terminal as usual:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;jupyter lab&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or, for the classic interface:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;jupyter notebook&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-notebooks-visualisation" class="anchor" aria-hidden="true" href="#notebooks-visualisation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notebooks visualisation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Jupyter Notebooks&lt;/em&gt; are used throughout these lectures for interactive data exploration and visualisation.&lt;/p&gt;
&lt;p&gt;We use dark styles for both &lt;em&gt;GitHub&lt;/em&gt; and &lt;em&gt;Jupyter Notebook&lt;/em&gt;.
You should try to do the same, or they will look ugly.
JupyterLab has a built-in selectable dark theme, so you only need to install something if you want to use the classic notebook interface.
To see the content appropriately in the classic interface install the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://userstyles.org/styles/153443/jupyter-notebook-dark" rel="nofollow"&gt;&lt;em&gt;Jupyter Notebook&lt;/em&gt; dark theme&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://userstyles.org/styles/37035/github-dark" rel="nofollow"&gt;&lt;em&gt;GitHub&lt;/em&gt; dark theme&lt;/a&gt; and comment out the &lt;code&gt;invert #fff to #181818&lt;/code&gt; code block.&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Atcold</author><guid isPermaLink="false">https://github.com/Atcold/pytorch-Deep-Learning-Minicourse</guid><pubDate>Sun, 09 Feb 2020 00:02:00 GMT</pubDate></item><item><title>CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers #3 in Jupyter Notebook, Today</title><link>https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</link><description>&lt;p&gt;&lt;i&gt;aka "Bayesian Methods for Hackers": An introduction to Bayesian methods + probabilistic programming with a computation/understanding-first, mathematics-second point of view. All in pure Python ;)  &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-bayesian-methods-for-hackers" class="anchor" aria-hidden="true" href="#bayesian-methods-for-hackers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/" rel="nofollow"&gt;Bayesian Methods for Hackers&lt;/a&gt;&lt;/h1&gt;
&lt;h4&gt;&lt;a id="user-content-using-python-and-pymc" class="anchor" aria-hidden="true" href="#using-python-and-pymc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;em&gt;Using Python and PyMC&lt;/em&gt;&lt;/h4&gt;
&lt;p&gt;The Bayesian method is the natural approach to inference, yet it is hidden from readers behind chapters of slow, mathematical analysis. The typical text on Bayesian inference involves two to three chapters on probability theory, then enters what Bayesian inference is. Unfortunately, due to mathematical intractability of most Bayesian models, the reader is only shown simple, artificial examples. This can leave the user with a &lt;em&gt;so-what&lt;/em&gt; feeling about Bayesian inference. In fact, this was the author's own prior opinion.&lt;/p&gt;
&lt;p&gt;After some recent success of Bayesian methods in machine-learning competitions, I decided to investigate the subject again. Even with my mathematical background, it took me three straight-days of reading examples and trying to put the pieces together to understand the methods. There was simply not enough literature bridging theory to practice. The problem with my misunderstanding was the disconnect between Bayesian mathematics and probabilistic programming. That being said, I suffered then so the reader would not have to now. This book attempts to bridge the gap.&lt;/p&gt;
&lt;p&gt;If Bayesian inference is the destination, then mathematical analysis is a particular path towards it. On the other hand, computing power is cheap enough that we can afford to take an alternate route via probabilistic programming. The latter path is much more useful, as it denies the necessity of mathematical intervention at each step, that is, we remove often-intractable mathematical analysis as a prerequisite to Bayesian inference. Simply put, this latter computational path proceeds via small intermediate jumps from beginning to end, where as the first path proceeds by enormous leaps, often landing far away from our target. Furthermore, without a strong mathematical background, the analysis required by the first path cannot even take place.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Bayesian Methods for Hackers&lt;/em&gt; is designed as an introduction to Bayesian inference from a computational/understanding-first, and mathematics-second, point of view. Of course as an introductory book, we can only leave it at that: an introductory book. For the mathematically trained, they may cure the curiosity this text generates with other texts designed with mathematical analysis in mind. For the enthusiast with less mathematical background, or one who is not interested in the mathematics but simply the practice of Bayesian methods, this text should be sufficient and entertaining.&lt;/p&gt;
&lt;p&gt;The choice of PyMC as the probabilistic programming language is two-fold. As of this writing, there is currently no central resource for examples and explanations in the PyMC universe. The official documentation assumes prior knowledge of Bayesian inference and probabilistic programming. We hope this book encourages users at every level to look at PyMC. Secondly, with recent core developments and popularity of the scientific stack in Python, PyMC is likely to become a core component soon enough.&lt;/p&gt;
&lt;p&gt;PyMC does have dependencies to run, namely NumPy and (optionally) SciPy. To not limit the user, the examples in this book will rely only on PyMC, NumPy, SciPy and Matplotlib.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-printed-version-by-addison-wesley" class="anchor" aria-hidden="true" href="#printed-version-by-addison-wesley"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Printed Version by Addison-Wesley&lt;/h2&gt;
&lt;div&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e991336533f43ff762cbf7713516f4215640d402/687474703a2f2f7777772d66702e70656172736f6e68696768657265642e636f6d2f6173736574732f6869702f696d616765732f626967636f766572732f303133333930323833382e6a7067"&gt;&lt;img title="Bayesian Methods for Hackersg" src="https://camo.githubusercontent.com/e991336533f43ff762cbf7713516f4215640d402/687474703a2f2f7777772d66702e70656172736f6e68696768657265642e636f6d2f6173736574732f6869702f696d616765732f626967636f766572732f303133333930323833382e6a7067" align="right" height="200" data-canonical-src="http://www-fp.pearsonhighered.com/assets/hip/images/bigcovers/0133902838.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Bayesian Methods for Hackers is now available as a printed book!&lt;/strong&gt; You can pick up a copy on &lt;a href="http://www.amazon.com/Bayesian-Methods-Hackers-Probabilistic-Addison-Wesley/dp/0133902838" rel="nofollow"&gt;Amazon&lt;/a&gt;. What are the differences between the online version and the printed version?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Additional Chapter on Bayesian A/B testing&lt;/li&gt;
&lt;li&gt;Updated examples&lt;/li&gt;
&lt;li&gt;Answers to the end of chapter questions&lt;/li&gt;
&lt;li&gt;Additional explanation, and rewritten sections to aid the reader.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h2&gt;
&lt;p&gt;See the project homepage &lt;a href="http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/" rel="nofollow"&gt;here&lt;/a&gt; for examples, too.&lt;/p&gt;
&lt;p&gt;The below chapters are rendered via the &lt;em&gt;nbviewer&lt;/em&gt; at
&lt;a href="http://nbviewer.jupyter.org/" rel="nofollow"&gt;nbviewer.jupyter.org/&lt;/a&gt;, and is read-only and rendered in real-time.
Interactive notebooks + examples can be downloaded by cloning!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-pymc2" class="anchor" aria-hidden="true" href="#pymc2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyMC2&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Prologue/Prologue.ipynb" rel="nofollow"&gt;&lt;strong&gt;Prologue:&lt;/strong&gt;&lt;/a&gt; Why we do it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/Ch1_Introduction_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 1: Introduction to Bayesian Methods&lt;/strong&gt;&lt;/a&gt;
Introduction to the philosophy and practice of Bayesian methods and answering the question, "What is probabilistic programming?" Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Inferring human behaviour changes from text message rates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 2: A little more on PyMC&lt;/strong&gt;&lt;/a&gt;
We explore modeling Bayesian problems using Python's PyMC library through examples. How do we create Bayesian models? Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detecting the frequency of cheating students, while avoiding liars&lt;/li&gt;
&lt;li&gt;Calculating probabilities of the Challenger space-shuttle disaster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter3_MCMC/Ch3_IntroMCMC_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 3: Opening the Black Box of MCMC&lt;/strong&gt;&lt;/a&gt;
We discuss how MCMC operates and diagnostic tools. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bayesian clustering with mixture models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter4_TheGreatestTheoremNeverTold/Ch4_LawOfLargeNumbers_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 4: The Greatest Theorem Never Told&lt;/strong&gt;&lt;/a&gt;
We explore an incredibly useful, and dangerous, theorem: The Law of Large Numbers. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Exploring a Kaggle dataset and the pitfalls of naive analysis&lt;/li&gt;
&lt;li&gt;How to sort Reddit comments from best to worst (not as easy as you think)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter5_LossFunctions/Ch5_LossFunctions_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 5: Would you rather lose an arm or a leg?&lt;/strong&gt;&lt;/a&gt;
The introduction of loss functions and their (awesome) use in Bayesian methods.  Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solving the &lt;em&gt;Price is Right&lt;/em&gt;'s Showdown&lt;/li&gt;
&lt;li&gt;Optimizing financial predictions&lt;/li&gt;
&lt;li&gt;Winning solution to the Kaggle Dark World's competition&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter6_Priorities/Ch6_Priors_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 6: Getting our &lt;em&gt;prior&lt;/em&gt;-ities straight&lt;/strong&gt;&lt;/a&gt;
Probably the most important chapter. We draw on expert opinions to answer questions. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multi-Armed Bandits and the Bayesian Bandit solution.&lt;/li&gt;
&lt;li&gt;What is the relationship between data sample size and prior?&lt;/li&gt;
&lt;li&gt;Estimating financial unknowns using expert priors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We explore useful tips to be objective in analysis as well as common pitfalls of priors.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pymc3" class="anchor" aria-hidden="true" href="#pymc3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyMC3&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Prologue/Prologue.ipynb" rel="nofollow"&gt;&lt;strong&gt;Prologue:&lt;/strong&gt;&lt;/a&gt; Why we do it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/Ch1_Introduction_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 1: Introduction to Bayesian Methods&lt;/strong&gt;&lt;/a&gt;
Introduction to the philosophy and practice of Bayesian methods and answering the question, "What is probabilistic programming?" Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Inferring human behaviour changes from text message rates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 2: A little more on PyMC&lt;/strong&gt;&lt;/a&gt;
We explore modeling Bayesian problems using Python's PyMC library through examples. How do we create Bayesian models? Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detecting the frequency of cheating students, while avoiding liars&lt;/li&gt;
&lt;li&gt;Calculating probabilities of the Challenger space-shuttle disaster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter3_MCMC/Ch3_IntroMCMC_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 3: Opening the Black Box of MCMC&lt;/strong&gt;&lt;/a&gt;
We discuss how MCMC operates and diagnostic tools. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bayesian clustering with mixture models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter4_TheGreatestTheoremNeverTold/Ch4_LawOfLargeNumbers_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 4: The Greatest Theorem Never Told&lt;/strong&gt;&lt;/a&gt;
We explore an incredibly useful, and dangerous, theorem: The Law of Large Numbers. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Exploring a Kaggle dataset and the pitfalls of naive analysis&lt;/li&gt;
&lt;li&gt;How to sort Reddit comments from best to worst (not as easy as you think)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter5_LossFunctions/Ch5_LossFunctions_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 5: Would you rather lose an arm or a leg?&lt;/strong&gt;&lt;/a&gt;
The introduction of loss functions and their (awesome) use in Bayesian methods.  Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solving the &lt;em&gt;Price is Right&lt;/em&gt;'s Showdown&lt;/li&gt;
&lt;li&gt;Optimizing financial predictions&lt;/li&gt;
&lt;li&gt;Winning solution to the Kaggle Dark World's competition&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter6_Priorities/Ch6_Priors_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 6: Getting our &lt;em&gt;prior&lt;/em&gt;-ities straight&lt;/strong&gt;&lt;/a&gt;
Probably the most important chapter. We draw on expert opinions to answer questions. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multi-Armed Bandits and the Bayesian Bandit solution.&lt;/li&gt;
&lt;li&gt;What is the relationship between data sample size and prior?&lt;/li&gt;
&lt;li&gt;Estimating financial unknowns using expert priors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We explore useful tips to be objective in analysis as well as common pitfalls of priors.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;More questions about PyMC?&lt;/strong&gt;
Please post your modeling, convergence, or any other PyMC question on &lt;a href="http://stats.stackexchange.com/" rel="nofollow"&gt;cross-validated&lt;/a&gt;, the statistics stack-exchange.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-the-book" class="anchor" aria-hidden="true" href="#using-the-book"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using the book&lt;/h2&gt;
&lt;p&gt;The book can be read in three different ways, starting from most recommended to least recommended:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The most recommended option is to clone the repository to download the .ipynb files to your local machine. If you have Jupyter installed, you can view the
chapters in your browser &lt;em&gt;plus&lt;/em&gt; edit and run the code provided (and try some practice questions). This is the preferred option to read
this book, though it comes with some dependencies.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jupyter is a requirement to view the ipynb files. It can be downloaded &lt;a href="http://jupyter.org/" rel="nofollow"&gt;here&lt;/a&gt;. Jupyter notebooks can be run by &lt;code&gt;(your-virtualenv) ~/path/to/the/book/Chapter1_Introduction $ jupyter notebook&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;For Linux users, you should not have a problem installing NumPy, SciPy, Matplotlib and PyMC. For Windows users, check out &lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/" rel="nofollow"&gt;pre-compiled versions&lt;/a&gt; if you have difficulty.&lt;/li&gt;
&lt;li&gt;In the styles/ directory are a number of files (.matplotlirc) that used to make things pretty. These are not only designed for the book, but they offer many improvements over the default settings of matplotlib.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second, preferred, option is to use the nbviewer.jupyter.org site, which display Jupyter notebooks in the browser (&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/Ch1_Introduction_PyMC2.ipynb" rel="nofollow"&gt;example&lt;/a&gt;).
The contents are updated synchronously as commits are made to the book. You can use the Contents section above to link to the chapters.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PDFs are the least-preferred method to read the book, as PDFs are static and non-interactive. If PDFs are desired, they can be created dynamically using the &lt;a href="https://github.com/jupyter/nbconvert"&gt;nbconvert&lt;/a&gt; utility.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-installation-and-configuration" class="anchor" aria-hidden="true" href="#installation-and-configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation and configuration&lt;/h2&gt;
&lt;p&gt;If you would like to run the Jupyter notebooks locally, (option 1. above), you'll need to install the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Jupyter is a requirement to view the ipynb files. It can be downloaded &lt;a href="http://jupyter.org/install.html" rel="nofollow"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Necessary packages are PyMC, NumPy, SciPy and Matplotlib.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For Linux/OSX users, you should not have a problem installing the above, &lt;a href="http://www.penandpants.com/2012/02/24/install-python/" rel="nofollow"&gt;&lt;em&gt;except for Matplotlib on OSX&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For Windows users, check out &lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/" rel="nofollow"&gt;pre-compiled versions&lt;/a&gt; if you have difficulty.&lt;/li&gt;
&lt;li&gt;also recommended, for data-mining exercises, are &lt;a href="https://github.com/praw-dev/praw"&gt;PRAW&lt;/a&gt; and &lt;a href="https://github.com/kennethreitz/requests"&gt;requests&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;New to Python or Jupyter, and help with the namespaces? Check out &lt;a href="http://stackoverflow.com/questions/12987624/confusion-between-numpy-scipy-matplotlib-and-pylab" rel="nofollow"&gt;this answer&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the styles/ directory are a number of files that are customized for the notebook.
These are not only designed for the book, but they offer many improvements over the
default settings of matplotlib and the Jupyter notebook. The in notebook style has not been finalized yet.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-development" class="anchor" aria-hidden="true" href="#development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development&lt;/h2&gt;
&lt;p&gt;This book has an unusual development design. The content is open-sourced, meaning anyone can be an author.
Authors submit content or revisions using the GitHub interface.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-how-to-contribute" class="anchor" aria-hidden="true" href="#how-to-contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to contribute&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-what-to-contribute" class="anchor" aria-hidden="true" href="#what-to-contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What to contribute?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The current chapter list is not finalized. If you see something that is missing (MCMC, MAP, Bayesian networks, good prior choices, Potential classes etc.),
feel free to start there.&lt;/li&gt;
&lt;li&gt;Cleaning up Python code and making code more PyMC-esque&lt;/li&gt;
&lt;li&gt;Giving better explanations&lt;/li&gt;
&lt;li&gt;Spelling/grammar mistakes&lt;/li&gt;
&lt;li&gt;Suggestions&lt;/li&gt;
&lt;li&gt;Contributing to the Jupyter notebook styles&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-commiting" class="anchor" aria-hidden="true" href="#commiting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Commiting&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;All commits are welcome, even if they are minor ;)&lt;/li&gt;
&lt;li&gt;If you are unfamiliar with Github, you can email me contributions to the email below.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-reviews" class="anchor" aria-hidden="true" href="#reviews"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reviews&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;these are satirical, but real&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;"No, but it looks good" - &lt;a href="https://twitter.com/JohnDCook/status/359672133695184896" rel="nofollow"&gt;John D. Cook&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"I ... read this book ... I like it!" - &lt;a href="http://www.andrewgelman.com/2013/07/21/bayes-related" rel="nofollow"&gt;Andrew Gelman&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"This book is a godsend, and a direct refutation to that 'hmph! you don't know maths, piss off!' school of thought...
The publishing model is so unusual. Not only is it open source but it relies on pull requests from anyone in order to progress the book. This is ingenious and heartening" - &lt;a href="http://www.reddit.com/r/Python/comments/1alnal/probabilistic_programming_and_bayesian_methods/" rel="nofollow"&gt;excited Reddit user&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributions-and-thanks" class="anchor" aria-hidden="true" href="#contributions-and-thanks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributions and Thanks&lt;/h2&gt;
&lt;p&gt;Thanks to all our contributing authors, including (in chronological order):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Authors&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.camdp.com" rel="nofollow"&gt;Cameron Davidson-Pilon&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://stefgibson.com" rel="nofollow"&gt;Stef Gibson&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bigsnarf.wordpress.com/" rel="nofollow"&gt;Vincent Ohprecio&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/larsman"&gt;Lars Buitinck&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://github.com/pmagwene"&gt;Paul Magwene&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Carreau"&gt;Matthias Bussonnier&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/JensRantil"&gt;Jens Rantil&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/y-p"&gt;y-p&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.etano.net/" rel="nofollow"&gt;Ethan Brown&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://jonathanwhitmore.com/" rel="nofollow"&gt;Jonathan Whitmore&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/matrig"&gt;Mattia Rigotti&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/colibius"&gt;Colby Lemon&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/gustavdelius"&gt;Gustav W Delius&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.mathisonian.com/" rel="nofollow"&gt;Matthew Conlen&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/radford"&gt;Jim Radford&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://baniverso.com/" rel="nofollow"&gt;Vannessa Sabino&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/thomasbratt"&gt;Thomas Bratt&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/nisanharamati"&gt;Nisan Haramati&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/bgrant"&gt;Robert Grant&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/xcthulhu"&gt;Matthew Wampler-Doty&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/yarikoptic"&gt;Yaroslav Halchenko&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/alexgarel"&gt;Alex Garel&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://twitter.com/sash_ko" rel="nofollow"&gt;Oleksandr Lysenko&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/liori"&gt;liori&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/ducky427"&gt;ducky427&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/pablooliveira"&gt;Pablo de Oliveira Castro&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/sergeyfogelson"&gt;sergeyfogelson&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://neurotheory.columbia.edu/~mrigotti/" rel="nofollow"&gt;Mattia Rigotti&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/mbauman"&gt;Matt Bauman&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.andrewduberstein.com/" rel="nofollow"&gt;Andrew Duberstein&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://cebe.cc/" rel="nofollow"&gt;Carsten Brandt&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://web2docx.com" rel="nofollow"&gt;Bob Jansen&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/ugurthemaster"&gt;ugurthemaster&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/williamscott"&gt;William Scott&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://twitter.com/minrk" rel="nofollow"&gt;Min RK&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Bulwersator"&gt;Bulwersator&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/elpres"&gt;elpres&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/hackaugusto"&gt;Augusto Hack&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/michaf"&gt;Michael Feldmann&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Youki"&gt;Youki&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://jensrantil.github.io" rel="nofollow"&gt;Jens Rantil&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kyleam.com" rel="nofollow"&gt;Kyle Meyer&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ericmart.in" rel="nofollow"&gt;Eric Martin&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Inconditus"&gt;Inconditus&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/Kleptine"&gt;Kleptine&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/slayton"&gt;Stuart Layton&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/tritemio"&gt;Antonino Ingargiola&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/vsl9"&gt;vsl9&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/tom-christie"&gt;Tom Christie&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/bclow"&gt;bclow&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://sjp.co.nz/" rel="nofollow"&gt;Simon Potter&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/GarthSnyder"&gt;Garth Snyder&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://twitter.com/pushmatrix" rel="nofollow"&gt;Daniel Beauchamp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.philippsinger.info" rel="nofollow"&gt;Philipp Singer&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/gbenmartin"&gt;gbenmartin&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://twitter.com/Springcoil" rel="nofollow"&gt;Peadar Coyle&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We would like to thank the Python community for building an amazing architecture. We would like to thank the
statistics community for building an amazing architecture.&lt;/p&gt;
&lt;p&gt;Similarly, the book is only possible because of the &lt;a href="http://github.com/pymc-devs/pymc"&gt;PyMC&lt;/a&gt; library. A big thanks to the core devs of PyMC: Chris Fonnesbeck, Anand Patil, David Huard and John Salvatier.&lt;/p&gt;
&lt;p&gt;One final thanks. This book was generated by Jupyter Notebook, a wonderful tool for developing in Python. We thank the IPython/Jupyter
community for developing the Notebook interface. All Jupyter notebook files are available for download on the GitHub repository.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h4&gt;
&lt;p&gt;Contact the main author, Cam Davidson-Pilon at &lt;a href="mailto:cam.davidson.pilon@gmail.com"&gt;cam.davidson.pilon@gmail.com&lt;/a&gt; or &lt;a href="https://twitter.com/cmrn_dp" rel="nofollow"&gt;@cmrndp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/090a62cab61c2a7115a3d8f4f99bffe5f1c75a26/687474703a2f2f692e696d6775722e636f6d2f5a623739515a622e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/090a62cab61c2a7115a3d8f4f99bffe5f1c75a26/687474703a2f2f692e696d6775722e636f6d2f5a623739515a622e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/Zb79QZb.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>CamDavidsonPilon</author><guid isPermaLink="false">https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</guid><pubDate>Sun, 09 Feb 2020 00:03:00 GMT</pubDate></item><item><title>ageron/handson-ml #4 in Jupyter Notebook, Today</title><link>https://github.com/ageron/handson-ml</link><description>&lt;p&gt;&lt;i&gt;A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-notebooks" class="anchor" aria-hidden="true" href="#machine-learning-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning Notebooks&lt;/h1&gt;
&lt;p&gt;This project aims at teaching you the fundamentals of Machine Learning in
python. It contains the example code and solutions to the exercises in my O'Reilly book &lt;a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781491962282/" rel="nofollow"&gt;Hands-on Machine Learning with Scikit-Learn and TensorFlow&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781491962282/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8e10a44b0ddbb9530cc27d877f06db68d9fa1c7d/687474703a2f2f616b616d6169636f766572732e6f7265696c6c792e636f6d2f696d616765732f393738313439313936323238322f6361742e676966" alt="book" data-canonical-src="http://akamaicovers.oreilly.com/images/9781491962282/cat.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Simply open the &lt;a href="http://jupyter.org/" rel="nofollow"&gt;Jupyter&lt;/a&gt; notebooks you are interested in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using &lt;a href="http://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/index.ipynb" rel="nofollow"&gt;jupyter.org's notebook viewer&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;note: &lt;a href="https://github.com/ageron/handson-ml/blob/master/index.ipynb"&gt;github.com's notebook viewer&lt;/a&gt; also works but it is slower and the math formulas are not displayed correctly,&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;by cloning this repository and running Jupyter locally. This option lets you play around with the code. In this case, follow the installation instructions below,&lt;/li&gt;
&lt;li&gt;or by running the notebooks in &lt;a href="https://beta.deepnote.com" rel="nofollow"&gt;Deepnote&lt;/a&gt;. This allows you to play around with the code online in your browser. For example, here's a link to the first chapter: &lt;a href="https://beta.deepnote.com/launch?template=data-science&amp;amp;url=https%3A//github.com/ageron/handson-ml/blob/master/02_end_to_end_machine_learning_project.ipynb" rel="nofollow"&gt;&lt;img height="22" src="https://camo.githubusercontent.com/c3b9bd12a99f8de3301018192105256209bcf800/68747470733a2f2f626574612e646565706e6f74652e636f6d2f627574746f6e732f6c61756e63682d696e2d646565706e6f74652e737667" data-canonical-src="https://beta.deepnote.com/buttons/launch-in-deepnote.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h1&gt;
&lt;p&gt;First, you will need to install &lt;a href="https://git-scm.com/" rel="nofollow"&gt;git&lt;/a&gt;, if you don't have it already.&lt;/p&gt;
&lt;p&gt;Next, clone this repository by opening a terminal and typing the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd $HOME  # or any other development directory you prefer
$ git clone https://github.com/ageron/handson-ml.git
$ cd handson-ml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you do not want to install git, you can instead download &lt;a href="https://github.com/ageron/handson-ml/archive/master.zip"&gt;master.zip&lt;/a&gt;, unzip it, rename the resulting directory to &lt;code&gt;handson-ml&lt;/code&gt; and move it to your development directory.&lt;/p&gt;
&lt;p&gt;If you want to go through chapter 16 on Reinforcement Learning, you will need to &lt;a href="https://gym.openai.com/docs" rel="nofollow"&gt;install OpenAI gym&lt;/a&gt; and its dependencies for Atari simulations.&lt;/p&gt;
&lt;p&gt;If you are familiar with Python and you know how to install Python libraries, go ahead and install the libraries listed in &lt;code&gt;requirements.txt&lt;/code&gt; and jump to the &lt;a href="#starting-jupyter"&gt;Starting Jupyter&lt;/a&gt; section. If you need detailed instructions, please read on.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-python--required-libraries" class="anchor" aria-hidden="true" href="#python--required-libraries"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python &amp;amp; Required Libraries&lt;/h2&gt;
&lt;p&gt;Of course, you obviously need Python. Python 3 is already preinstalled on many systems nowadays. You can check which version you have by typing the following command (you may need to replace &lt;code&gt;python3&lt;/code&gt; with &lt;code&gt;python&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 --version  # for Python 3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Any Python 3 version should be fine, preferably 3.5 or above. If you don't have Python 3, I recommend installing it. To do so, you have several options: on Windows or MacOSX, you can just download it from &lt;a href="https://www.python.org/downloads/" rel="nofollow"&gt;python.org&lt;/a&gt;. On MacOSX, you can alternatively use &lt;a href="https://www.macports.org/" rel="nofollow"&gt;MacPorts&lt;/a&gt; or &lt;a href="https://brew.sh/" rel="nofollow"&gt;Homebrew&lt;/a&gt;. If you are using Python 3.6 on MacOSX, you need to run the following command to install the &lt;code&gt;certifi&lt;/code&gt; package of certificates because Python 3.6 on MacOSX has no certificates to validate SSL connections (see this &lt;a href="https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error" rel="nofollow"&gt;StackOverflow question&lt;/a&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ /Applications/Python\ 3.6/Install\ Certificates.command
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On Linux, unless you know what you are doing, you should use your system's packaging system. For example, on Debian or Ubuntu, type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt-get update
$ sudo apt-get install python3 python3-pip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another option is to download and install &lt;a href="https://www.continuum.io/downloads" rel="nofollow"&gt;Anaconda&lt;/a&gt;. This is a package that includes both Python and many scientific libraries. You should prefer the Python 3 version.&lt;/p&gt;
&lt;p&gt;If you choose to use Anaconda, read the next section, or else jump to the &lt;a href="#using-pip"&gt;Using pip&lt;/a&gt; section.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-anaconda" class="anchor" aria-hidden="true" href="#using-anaconda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using Anaconda&lt;/h2&gt;
&lt;p&gt;Once you have &lt;a href="https://docs.anaconda.com/anaconda/install/" rel="nofollow"&gt;installed Anaconda&lt;/a&gt; (or Miniconda), you can run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda env create -f environment.yml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will give you a conda environment named &lt;code&gt;mlbook&lt;/code&gt;, ready to use! Just activate it and you will have everything setup
for you:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda activate mlbook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You are all set! Next, jump to the &lt;a href="#starting-jupyter"&gt;Starting Jupyter&lt;/a&gt; section.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-pip" class="anchor" aria-hidden="true" href="#using-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using pip&lt;/h2&gt;
&lt;p&gt;If you are not using Anaconda, you need to install several scientific Python libraries that are necessary for this project, in particular NumPy, Matplotlib, Pandas, Jupyter and TensorFlow (and a few others). For this, you can either use Python's integrated packaging system, pip, or you may prefer to use your system's own packaging system (if available, e.g. on Linux, or on MacOSX when using MacPorts or Homebrew). The advantage of using pip is that it is easy to create multiple isolated Python environments with different libraries and different library versions (e.g. one environment for each project). The advantage of using your system's packaging system is that there is less risk of having conflicts between your Python libraries and your system's other packages. Since I have many projects with different library requirements, I prefer to use pip with isolated environments. Moreover, the pip packages are usually the most recent ones available, while Anaconda and system packages often lag behind a bit.&lt;/p&gt;
&lt;p&gt;These are the commands you need to type in a terminal if you want to use pip to install the required libraries. Note: in all the following commands, if you chose to use Python 2 rather than Python 3, you must replace &lt;code&gt;pip3&lt;/code&gt; with &lt;code&gt;pip&lt;/code&gt;, and &lt;code&gt;python3&lt;/code&gt; with &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First you need to make sure you have the latest version of pip installed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --user --upgrade pip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;--user&lt;/code&gt; option will install the latest version of pip only for the current user. If you prefer to install it system wide (i.e. for all users), you must have administrator rights (e.g. use &lt;code&gt;sudo python3&lt;/code&gt; instead of &lt;code&gt;python3&lt;/code&gt; on Linux), and you should remove the &lt;code&gt;--user&lt;/code&gt; option. The same is true of the command below that uses the &lt;code&gt;--user&lt;/code&gt; option.&lt;/p&gt;
&lt;p&gt;Next, you can optionally create an isolated environment. This is recommended as it makes it possible to have a different environment for each project (e.g. one for this project), with potentially very different libraries, and different versions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --user --upgrade virtualenv
$ python3 -m virtualenv -p `which python3` env
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates a new directory called &lt;code&gt;env&lt;/code&gt; in the current directory, containing an isolated Python environment based on Python 3. If you installed multiple versions of Python 3 on your system, you can replace &lt;code&gt;`which python3`&lt;/code&gt; with the path to the Python executable you prefer to use.&lt;/p&gt;
&lt;p&gt;Now you must activate this environment. You will need to run this command every time you want to use this environment.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ source ./env/bin/activate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On Windows, the command is slightly different:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ .\env\Scripts\activate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, use pip to install the required python packages. If you are not using virtualenv, you should add the &lt;code&gt;--user&lt;/code&gt; option (alternatively you could install the libraries system-wide, but this will probably require administrator rights, e.g. using &lt;code&gt;sudo pip3&lt;/code&gt; instead of &lt;code&gt;pip3&lt;/code&gt; on Linux).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --upgrade -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great! You're all set, you just need to start Jupyter now.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-starting-jupyter" class="anchor" aria-hidden="true" href="#starting-jupyter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Starting Jupyter&lt;/h2&gt;
&lt;p&gt;Okay! You can now start Jupyter, simply type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This should open up your browser, and you should see Jupyter's tree view, with the contents of the current directory. If your browser does not open automatically, visit &lt;a href="http://127.0.0.1:8888/tree" rel="nofollow"&gt;127.0.0.1:8888&lt;/a&gt;. Click on &lt;code&gt;index.ipynb&lt;/code&gt; to get started!&lt;/p&gt;
&lt;p&gt;Congrats! You are ready to learn Machine Learning, hands on!&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributors&lt;/h1&gt;
&lt;p&gt;I would like to thank everyone who contributed to this project, either by providing useful feedback, filing issues or submitting Pull Requests. Special thanks go to Steven Bunkley and Ziembla who created the &lt;code&gt;docker&lt;/code&gt; directory.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ageron</author><guid isPermaLink="false">https://github.com/ageron/handson-ml</guid><pubDate>Sun, 09 Feb 2020 00:04:00 GMT</pubDate></item><item><title>snowkylin/tensorflow-handbook #5 in Jupyter Notebook, Today</title><link>https://github.com/snowkylin/tensorflow-handbook</link><description>&lt;p&gt;&lt;i&gt;简单粗暴 TensorFlow 2.0 | A Concise Handbook of TensorFlow 2.0&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="readme.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-简单粗暴tensorflow-20--a-concise-handbook-of-tensorflow-20" class="anchor" aria-hidden="true" href="#简单粗暴tensorflow-20--a-concise-handbook-of-tensorflow-20"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;简单粗暴TensorFlow 2.0 | A Concise Handbook of TensorFlow 2.0&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;基于Eager Execution | Based on Eager Execution&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;在线阅读 | Read online : &lt;a href="https://tf.wiki" rel="nofollow"&gt;https://tf.wiki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;备用地址 | Alternative URL：&lt;a href="https://snowkylin.github.io/tensorflow-handbook/" rel="nofollow"&gt;https://snowkylin.github.io/tensorflow-handbook/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;作者 | Author: Xihan Li (snowkylin), Huan Li, Jinpeng Zhu&lt;/p&gt;
&lt;p&gt;本手册是一篇精简的TensorFlow 2.0入门指导，基于TensorFlow的Eager Execution（动态图）模式，力图让具备一定机器学习及Python基础的开发者们快速上手TensorFlow 2.0。&lt;/p&gt;
&lt;p&gt;本文的所有代码基于TensorFlow 2.0 beta1版本。&lt;/p&gt;
&lt;p&gt;This handbook is a concise introduction to TensorFlow 2.0 based on Eager Execution mode, trying to help developers with some basic machine learning and Python knowledge to get started with TensorFlow 2.0 quickly.&lt;/p&gt;
&lt;p&gt;The code of this handbook is based on TensorFlow 2.0 beta1.&lt;/p&gt;
&lt;p&gt;PDF下载（旧版） | PDF download (old version) :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(中文版 | Chinese): &lt;a href="https://www.tensorflowers.cn/t/6230" rel="nofollow"&gt;https://www.tensorflowers.cn/t/6230&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;(英文版 | English): &lt;a href="https://github.com/snowkylin/tensorflow-handbook/releases"&gt;https://github.com/snowkylin/tensorflow-handbook/releases&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在线答疑区 | Online Q&amp;amp;A area :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(中文 | Chinese): &lt;a href="https://www.tensorflowers.cn/b/48" rel="nofollow"&gt;https://www.tensorflowers.cn/b/48&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;(英文 | English): &lt;a href="https://github.com/snowkylin/tensorflow-handbook/issues"&gt;https://github.com/snowkylin/tensorflow-handbook/issues&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-developing" class="anchor" aria-hidden="true" href="#developing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DEVELOPING&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-install" class="anchor" aria-hidden="true" href="#install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;run &lt;code&gt;make install&lt;/code&gt; for run all the follow commands.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; https://www.ibm.com/developerworks/cn/opensource/os-sphinx-documentation/index.html&lt;/span&gt;
pip install sphinx

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; for theme&lt;/span&gt;
pip install sphinx_rtd_theme

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; for auto build&lt;/span&gt;
pip install sphinx_autobuild&lt;/pre&gt;&lt;/div&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>snowkylin</author><guid isPermaLink="false">https://github.com/snowkylin/tensorflow-handbook</guid><pubDate>Sun, 09 Feb 2020 00:05:00 GMT</pubDate></item><item><title>mitmath/18330 #6 in Jupyter Notebook, Today</title><link>https://github.com/mitmath/18330</link><description>&lt;p&gt;&lt;i&gt;18.330 Intro to Numerical Analysis&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-18330-introduction-to-numerical-analysis" class="anchor" aria-hidden="true" href="#18330-introduction-to-numerical-analysis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;18.330: Introduction to numerical analysis&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-spring-2020" class="anchor" aria-hidden="true" href="#spring-2020"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spring 2020&lt;/h2&gt;
&lt;p&gt;Welcome to 18.330! This is an introductory course on numerical analysis.&lt;/p&gt;
&lt;p&gt;We will be using the &lt;a href="www.julialang.org"&gt;Julia language&lt;/a&gt;. Please follow &lt;a href="installation.md"&gt;these installation instructions&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-logistics" class="anchor" aria-hidden="true" href="#logistics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Logistics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Visiting professor David P. Sanders (&lt;a href="mailto:sandersd@mit.edu"&gt;sandersd@mit.edu&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MWF 1--2, room 2-139.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Office hours: MW 5-6 in the &lt;strong&gt;Julia lab&lt;/strong&gt;, 7th floor of Stata Center (turn left from Gates building elevator)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Piazza forum: &lt;a href="https://piazza.com/class/k65ke8eo9x760n" rel="nofollow"&gt;https://piazza.com/class/k65ke8eo9x760n&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-slides-notebooks-and-recordings-from-lectures" class="anchor" aria-hidden="true" href="#slides-notebooks-and-recordings-from-lectures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Slides, notebooks and recordings from lectures&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slides and notebooks for each lecture are available in the &lt;a href="lectures"&gt;lectures&lt;/a&gt; directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Screen recordings of lectures are available &lt;a href="https://www.dropbox.com/sh/ubkqwrqxnukgllc/AAA2cH9r7YQL7WmYVt-bblxta?dl=0" rel="nofollow"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Summaries of each lecture are &lt;a href="summaries.md"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-evaluation" class="anchor" aria-hidden="true" href="#evaluation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Evaluation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;10 problem sets (50%). No late submissions, but the lowest score will be dropped.&lt;/li&gt;
&lt;li&gt;1 midterm exam (20%): Wednesday, March 18&lt;/li&gt;
&lt;li&gt;Final project (30%): Due Monday, May 11&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Problem sets will consist of a mixture of theory and coding. They will be submitted and graded online.&lt;/p&gt;
&lt;p&gt;The final project will be an exploration of a topic in numerical analysis that we have not covered in class (although at the level of the class), and will include a discussion of the mathematics behind the method, together with your own implementation.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-learning-julia" class="anchor" aria-hidden="true" href="#learning-julia"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learning Julia&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Prof. Steven Johnson will give an introduction to Julia on Friday, Feb 7 from 5-7pm in 32-141. Make sure to install Julia beforehand. See &lt;a href="https://github.com/mitmath/julia-mit"&gt;https://github.com/mitmath/julia-mit&lt;/a&gt; for information and resources on Julia.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For help with Julia you should be able to find people in the Julia lab most of the time (see above for directions)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;More learning resources are available at &lt;a href="https://julialang.org/learning/" rel="nofollow"&gt;https://julialang.org/learning/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-windows-users" class="anchor" aria-hidden="true" href="#windows-users"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Windows users&lt;/h3&gt;
&lt;p&gt;If you use Windows, please download Git for Windows &lt;a href="https://gitforwindows.org" rel="nofollow"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-getting-the-files" class="anchor" aria-hidden="true" href="#getting-the-files"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting the files&lt;/h3&gt;
&lt;p&gt;To get the files, use &lt;code&gt;git&lt;/code&gt; from the command line (or from a GUI), as follows&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Clone the repository once with&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/mitmath/18330
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will create a new directory called &lt;code&gt;18330&lt;/code&gt; with the matierials.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Update it to pull in new changes each time with&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;git pull
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This needs to be executed from within the directory. (Use &lt;code&gt;cd&lt;/code&gt; to change directory.)&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-syllabus" class="anchor" aria-hidden="true" href="#syllabus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Syllabus&lt;/h3&gt;
&lt;p&gt;See &lt;a href="syllabus.md"&gt;here&lt;/a&gt; for the approximate course syllabus.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>mitmath</author><guid isPermaLink="false">https://github.com/mitmath/18330</guid><pubDate>Sun, 09 Feb 2020 00:06:00 GMT</pubDate></item><item><title>mitmath/18335 #7 in Jupyter Notebook, Today</title><link>https://github.com/mitmath/18335</link><description>&lt;p&gt;&lt;i&gt;18.335 - Introduction to Numerical Methods course&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-18335j6337j-introduction-to-numerical-methods" class="anchor" aria-hidden="true" href="#18335j6337j-introduction-to-numerical-methods"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;18.335J/6.337J: Introduction to Numerical Methods&lt;/h1&gt;
&lt;p&gt;This is the repository of course materials for the 18.335J/6.337J course at MIT, taught by Prof. &lt;a href="http://math.mit.edu/~stevenj/" rel="nofollow"&gt;Steven G. Johnson&lt;/a&gt;, in Spring 2020.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-syllabus" class="anchor" aria-hidden="true" href="#syllabus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Syllabus&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Lectures&lt;/strong&gt;: Monday/Wednesday/Friday 3–4pm (2-190). &lt;strong&gt;Office Hours:&lt;/strong&gt; Thursday 4–5pm (2-345).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Topics&lt;/strong&gt;: Advanced introduction to numerical linear algebra and related numerical methods. Topics include direct and iterative methods for linear systems, eigenvalue decompositions and QR/SVD factorizations, stability and accuracy of numerical algorithms, the IEEE floating-point standard, sparse and structured matrices, and linear algebra software. Other topics may include memory hierarchies and the impact of caches on algorithms, nonlinear optimization, numerical integration, FFTs, and sensitivity analysis. Problem sets will involve use of &lt;a href="http://julialang.org/" rel="nofollow"&gt;Julia&lt;/a&gt;, a Matlab-like environment (little or no prior experience required; you will learn as you go).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;: Understanding of linear algebra (&lt;a href="http://web.mit.edu/18.06/www/" rel="nofollow"&gt;18.06&lt;/a&gt;, &lt;a href="http://ocw.mit.edu/OcwWeb/Mathematics/18-700Fall-2005/CourseHome/" rel="nofollow"&gt;18.700&lt;/a&gt;, or equivalents). 18.335 is a graduate-level subject, however, so much more mathematical maturity, ability to deal with abstractions and proofs, and general exposure to mathematics is assumed than for 18.06!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Textbook&lt;/strong&gt;: The primary textbook for the course is &lt;a href="http://www.amazon.com/Numerical-Linear-Algebra-Lloyd-Trefethen/dp/0898713617" rel="nofollow"&gt;&lt;em&gt;Numerical Linear Algebra&lt;/em&gt; by Trefethen and Bau&lt;/a&gt;. (&lt;a href="http://owens.mit.edu/sfx_local?bookid=9436&amp;amp;rft.genre=book&amp;amp;sid=Barton:Books24x7" rel="nofollow"&gt;Readable online&lt;/a&gt; with MIT certificates.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Other Reading&lt;/strong&gt;: Previous terms can be found in &lt;a href="https://github.com/mitmath/18335/branches"&gt;branches of the 18335 git repository&lt;/a&gt;. The &lt;a href="https://ocw.mit.edu/courses/mathematics/18-335j-introduction-to-numerical-methods-fall-2010/" rel="nofollow"&gt;course notes from 18.335 in much earlier terms&lt;/a&gt; can be found on OpenCourseWare. For a review of iterative methods, the online books &lt;a href="http://www.netlib.org/linalg/html_templates/Templates.html" rel="nofollow"&gt;Templates for the Solution of Linear Systems&lt;/a&gt; (Barrett et al.) and &lt;a href="http://www.cs.utk.edu/~dongarra/etemplates/book.html" rel="nofollow"&gt;Templates for the Solution of Algebraic Eigenvalue Problems&lt;/a&gt; are useful surveys.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Grading&lt;/strong&gt;: 33% problem sets (about six, ~biweekly). 33% &lt;strong&gt;take-home mid-term exam&lt;/strong&gt; (posted Monday &lt;strong&gt;Apr. 6&lt;/strong&gt; and due Tuesday &lt;strong&gt;Apr. 7&lt;/strong&gt;), 34% &lt;strong&gt;final project&lt;/strong&gt; (&lt;a href="psets/proposal.md"&gt;one-page proposal&lt;/a&gt; due Friday March 20, project due Tuesday &lt;strong&gt;May 12&lt;/strong&gt;).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Psets will be &lt;a href="https://learning-modules.mit.edu/gradebook/index.html?uuid=/course/18/sp20/18.335" rel="nofollow"&gt;submitted electronically via Stellar&lt;/a&gt;.  Submit a good-quality PDF &lt;em&gt;scan&lt;/em&gt; of any handwritten solutions and &lt;em&gt;also&lt;/em&gt; a PDF &lt;em&gt;printout&lt;/em&gt; of a Julia notebook of your computational solutions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;TA/grader:&lt;/strong&gt; &lt;a href="http://math.mit.edu/directory/profile.php?pid=1714" rel="nofollow"&gt;Jacob Gold&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Collaboration policy&lt;/strong&gt;: Talk to anyone you want to and read anything you want to, with three exceptions: First, you &lt;strong&gt;may not refer to homework solutions from the previous terms&lt;/strong&gt; in which I taught 18.335. Second, make a solid effort to solve a problem on your own before discussing it with classmates or googling. Third, no matter whom you talk to or what you read, write up the solution on your own, without having their answer in front of you.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Final Projects&lt;/strong&gt;: The final project will be a 8–15 page paper (single-column, single-spaced, ideally using the style template from the &lt;a href="http://www.siam.org/journals/auth-info.php" rel="nofollow"&gt;&lt;em&gt;SIAM Journal on Numerical Analysis&lt;/em&gt;&lt;/a&gt;), reviewing some interesting numerical algorithm not covered in the course. [Since this is not a numerical PDE course, the algorithm should &lt;em&gt;not&lt;/em&gt; be an algorithm for turning PDEs into finite/discretized systems; however, your project &lt;em&gt;may&lt;/em&gt; take a PDE discretization as a given "black box" and look at some other aspect of the problem, e.g. iterative solvers.] Your paper should be written for an audience of your peers in the class, and should include example numerical results (by you) from application to a realistic problem (small-scale is fine), discussion of accuracy and performance characteristics (both theoretical and experimental), and a fair comparison to at &lt;strong&gt;least one competing algorithm&lt;/strong&gt; for the same problem. Like any review paper, you should &lt;em&gt;thoroughly reference&lt;/em&gt; the published literature (citing both original articles and authoritative reviews/books where appropriate [rarely web pages]), tracing the historical development of the ideas and giving the reader pointers on where to go for more information and related work and later refinements, with references cited throughout the text (enough to make it clear what references go with what results). (&lt;strong&gt;Note:&lt;/strong&gt; you may re-use diagrams from other sources, but all such usage must be &lt;em&gt;explicitly credited&lt;/em&gt;; not doing so is &lt;a href="http://writing.mit.edu/wcc/avoidingplagiarism" rel="nofollow"&gt;plagiarism&lt;/a&gt;.) Model your paper on academic review articles (e.g. read &lt;em&gt;SIAM Review&lt;/em&gt; and similar journals for examples).&lt;/p&gt;
&lt;p&gt;A good final project will include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;An extensive introduction and bibliography putting the algorithm in context.  Where did it come from, and what motivated its development?  Where is it commonly used (if anywhere)?  What are the main competing algorithms?  Were any variants of the algorithm proposed later?  What do other authors say about it?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A clear description of the algorithm, with a summary of its derivation and key properties.   Don't copy long mathematical derivations or proofs from other sources, but do &lt;em&gt;summarize&lt;/em&gt; the key ideas and results in the literature.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A convincing validation on a representative/quasi-realistic test problem (i.e. show that your code works), along with an informative comparison to important competing algorithms.  For someone who is thinking about using the algorithm, you should strive to give them &lt;em&gt;useful&lt;/em&gt; guidance on how the algorithm compares to competing algorithms: when/where should you consider using it (if ever)?   Almost never rely on actual timing results — see below!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Frequently asked questions about the final project:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Does it have to be about numerical linear algebra?&lt;/em&gt; No. It can be any numerical topic (basically, anything where you are computing a conceptually real result, not integer computations), excluding algorithms for discretizing PDEs.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Can I use a matrix from a discretized PDE?&lt;/em&gt; Yes. You can take a matrix from the PDE as input and then talk about iterative methods to solve it, etcetera. I just don't want the paper to be about the PDE discretization technique itself.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;How formal is the proposal?&lt;/em&gt; Very informal—one page describing what you plan to do, with a couple of references that you are using as starting points. Basically, the proposal is just so that I can verify that what you are planning is reasonable and to give you some early feedback.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;How much code do I need to write?&lt;/em&gt; A typical project (there may be exceptions) will include a working proof-of-concept implementation, e.g. in Julia or Python or Matlab, that you wrote to demonstrate that you understand how the algorithm works. Your code does &lt;em&gt;not&lt;/em&gt; have to be competitive with "serious" implementations, and I encourage you to download and try out existing "serious" implementations (where available) for any large-scale testing and comparisons.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;How should I do performance comparisons?&lt;/em&gt; Be very cautious about timing measurements: unless you are measuring highly optimized code or only care about orders of magnitude, timing measurements are more about implementation quality than algorithms. Better to &lt;em&gt;measure something implementation-independent&lt;/em&gt; (like flop counts, or matrix-vector multiplies for iterative algorithms, or function evaluations for integrators/optimizers), even though such measures have their own weaknesses.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-lecture-summaries-and-handouts" class="anchor" aria-hidden="true" href="#lecture-summaries-and-handouts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lecture Summaries and Handouts&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-lecture-1-feb-3" class="anchor" aria-hidden="true" href="#lecture-1-feb-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lecture 1 (Feb 3)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="psets/pset1.pdf"&gt;pset 1&lt;/a&gt; and accompanying &lt;a href="https://nbviewer.jupyter.org/github/mitmath/18335/blob/master/psets/pset1.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;, due Friday Feb. 14.&lt;/li&gt;
&lt;li&gt;&lt;a href="notes/newton-sqrt.pdf"&gt;Newton's method for square roots&lt;/a&gt; and accompanying &lt;a href="https://nbviewer.jupyter.org/github/mitmath/18335/blob/master/notes/Newton-Square-Roots.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Brief overview of the huge field of numerical methods, and outline of the small portion that this course will cover. Key new concerns in numerical analysis, which don't appear in more abstract mathematics, are (i) performance (traditionally, arithmetic counts, but now memory access often dominates) and (ii) accuracy (both floating-point roundoff errors and also convergence of intrinsic approximations in the algorithms).&lt;/p&gt;
&lt;p&gt;As a starting example, considered the convergence of Newton's method (as applied to square roots); see the handout and Julia notebook above.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Further reading:&lt;/strong&gt; Googling "Newton's method" will find lots of references; as usual, the &lt;a href="https://en.wikipedia.org/wiki/Newton's_method" rel="nofollow"&gt;Wikipedia article on Newton's method&lt;/a&gt; is a reasonable starting point. Beware that the terminology for the &lt;a href="https://en.wikipedia.org/wiki/Rate_of_convergence" rel="nofollow"&gt;convergence order&lt;/a&gt; (linear, quadratic, etc.) is somewhat different in this context from the terminology for discretization schemes (first-order, second-order, etc.); see e.g. the linked Wikipedia article. Homer Reid's &lt;a href="http://homerreid.dyndns.org/teaching/18.330/Notes/RootFinding.pdf" rel="nofollow"&gt;notes on machine arithmetic&lt;/a&gt; for &lt;a href="http://homerreid.dyndns.org/teaching/18.330/" rel="nofollow"&gt;18.330&lt;/a&gt; are an excellent introduction that covers several applications and algorithms for root-finding. For numerical computation in 18.335, we will be using the Julia language: see this &lt;a href="https://github.com/mitmath/julia-mit"&gt;information on Julia at MIT&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-lecture-2-feb-5" class="anchor" aria-hidden="true" href="#lecture-2-feb-5"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lecture 2 (Feb 5)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="notes/lec8handout6pp.pdf"&gt;notes on floating-point&lt;/a&gt; (18.335 Fall 2007; also &lt;a href="notes/lec8.pdf"&gt;slides&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Julia &lt;a href="https://nbviewer.jupyter.org/github/mitmath/18335/blob/master/notes/Floating-Point-Intro.ipynb" rel="nofollow"&gt;floating-point notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;some &lt;a href="notes/fp-myths.pdf"&gt;floating-point myths&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;New topic: &lt;strong&gt;Floating-point arithmetic&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The basic issue is that, for computer arithmetic to be fast, it has to be done in hardware, operating on numbers stored in a fixed, finite number of digits (bits). As a consequence, only a &lt;em&gt;finite subset&lt;/em&gt; of the real numbers can be represented, and the question becomes &lt;em&gt;which subset&lt;/em&gt; to store, how arithmetic on this subset is defined, and how to analyze the errors compared to theoretical exact arithmetic on real numbers.&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;floating-point&lt;/strong&gt; arithmetic, we store both an integer coefficient and an exponent in some base: essentially, scientific notation. This allows large dynamic range and fixed &lt;em&gt;relative&lt;/em&gt; accuracy: if fl(x) is the closest floating-point number to any real x, then |fl(x)-x| &amp;lt; ε|x| where ε is the &lt;em&gt;machine precision&lt;/em&gt;. This makes error analysis much easier and makes algorithms mostly insensitive to overall scaling or units, but has the disadvantage that it requires specialized floating-point hardware to be fast. Nowadays, all general-purpose computers, and even many little computers like your cell phones, have floating-point units.&lt;/p&gt;
&lt;p&gt;Overview of &lt;strong&gt;floating-point&lt;/strong&gt; representations, focusing on the IEEE 754 standard (see also handout from previous lecture). The key point is that the nearest floating-point number to &lt;em&gt;x&lt;/em&gt;, denoted fl(&lt;em&gt;x&lt;/em&gt;), has the property of &lt;em&gt;uniform relative precision&lt;/em&gt; (for |&lt;em&gt;x&lt;/em&gt;| and 1/|&lt;em&gt;x&lt;/em&gt;| &amp;lt; than some &lt;em&gt;range&lt;/em&gt;, ≈10³⁰⁰ for double precision) that |fl(&lt;em&gt;x&lt;/em&gt;)−_x_| ≤ εmachine|&lt;em&gt;x&lt;/em&gt;|, where εmachine is the relative "machine precision" (about 10⁻¹⁶ for double precision). There are also a few special values: ±Inf (e.g. for &lt;a href="https://en.wikipedia.org/wiki/Arithmetic_overflow" rel="nofollow"&gt;overflow&lt;/a&gt;), &lt;a href="https://en.wikipedia.org/wiki/NaN" rel="nofollow"&gt;NaN&lt;/a&gt;, and ±0 (e.g. for &lt;a href="https://en.wikipedia.org/wiki/Arithmetic_underflow" rel="nofollow"&gt;underflow&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Went through some simple examples in Julia (see notebook above), illustrating basic syntax and a few interesting tidbits.  In particular, we looked at two examples of &lt;a href="https://en.wikipedia.org/wiki/Loss_of_significance" rel="nofollow"&gt;catastrophic cancellation&lt;/a&gt; and how it can sometimes be avoided by rearranging a calculation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Further reading:&lt;/strong&gt; Trefethen, lecture 13. &lt;a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.6768" rel="nofollow"&gt;What Every Computer Scientist Should Know About Floating Point Arithmetic&lt;/a&gt; (David Goldberg, ACM 1991). William Kahan, &lt;a href="http://www.cs.berkeley.edu/~wkahan/JAVAhurt.pdf" rel="nofollow"&gt;How Java's floating-point hurts everyone everywhere&lt;/a&gt; (2004): contains a nice discussion of floating-point myths and misconceptions.   A brief but useful summary can be found in &lt;a href="https://discourse.julialang.org/t/psa-floating-point-arithmetic/8678" rel="nofollow"&gt;this Julia-focused floating-point overview&lt;/a&gt; by Prof. John Gibson.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-lecture-3-feb-7" class="anchor" aria-hidden="true" href="#lecture-3-feb-7"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lecture 3 (Feb 7)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;notes on the accuracy and stability of &lt;a href="notes/naivesum.pdf"&gt;floating-point summation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Summation, accuracy, and stability.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Further reading&lt;/strong&gt;: See the further reading from the previous lecture. Trefethen, lectures 14, 15, and 3. See also the Wikipedia article on &lt;a href="https://en.wikipedia.org/wiki/Big_O_notation" rel="nofollow"&gt;asymptotic ("big O") notation&lt;/a&gt;; note that for expressions like O(ε) we are looking in the limit of &lt;em&gt;small&lt;/em&gt; arguments rather than of large arguments (as in complexity theory), but otherwise the ideas are the same.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-julia-tutorial-feb-7-5pm-in-32-141--optional" class="anchor" aria-hidden="true" href="#julia-tutorial-feb-7-5pm-in-32-141--optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Julia tutorial (Feb 7: 5pm in 32-141) — optional&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Handout:&lt;/strong&gt; &lt;a href="https://github.com/mitmath/julia-mit/blob/master/Julia-cheatsheet.pdf"&gt;Julia cheat-sheet&lt;/a&gt;, &lt;a href="https://github.com/mitmath/julia-mit/blob/master/Julia-intro.pdf"&gt;Julia intro slides&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;On Friday, 7 February, at 5pm in 32-141, I will give an (attendance-optional!) Julia tutorial, introducing the &lt;a href="http://julialang.org/" rel="nofollow"&gt;Julia programming language and environment&lt;/a&gt; that we will use this term. Please see the &lt;a href="https://github.com/mitmath/julia-mit/blob/master/README.md"&gt;tutorial notes online&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Please &lt;strong&gt;bring your laptops&lt;/strong&gt;, and try to install Julia and the IJulia interface first via the abovementioned tutorial notes. Several people will be at the tutorial session to help answer installation questions. Alternatively, you can use Julia online at &lt;a href="https://juliabox.com/" rel="nofollow"&gt;JuliaBox&lt;/a&gt; without installing anything (although running things on your own machine is usually faster).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>mitmath</author><guid isPermaLink="false">https://github.com/mitmath/18335</guid><pubDate>Sun, 09 Feb 2020 00:07:00 GMT</pubDate></item><item><title>adashofdata/nlp-in-python-tutorial #8 in Jupyter Notebook, Today</title><link>https://github.com/adashofdata/nlp-in-python-tutorial</link><description>&lt;p&gt;&lt;i&gt;comparing stand up comedians using natural language processing&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-welcome-to-the-natural-language-processing-in-python-tutorial" class="anchor" aria-hidden="true" href="#welcome-to-the-natural-language-processing-in-python-tutorial"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Welcome to the Natural Language Processing in Python Tutorial!&lt;/h2&gt;
&lt;p&gt;We will be going through several Jupyter Notebooks during the tutorial and use a number of data science libraries along the way. The easiest way to get started is to download Anaconda, which is free and open source. When you download this, it comes with the Jupyter  Notebook IDE and many popular data science libraries, so you don’t have to install them one by one.&lt;/p&gt;
&lt;p&gt;Here are the steps you’ll need to take before the start of the tutorial:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-1-download-anaconda" class="anchor" aria-hidden="true" href="#1-download-anaconda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Download Anaconda&lt;/h3&gt;
&lt;p&gt;I highly recommend that you download &lt;a href="https://www.anaconda.com/download/" rel="nofollow"&gt;the Python 3.7 version&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-2-download-the-jupyter-notebooks" class="anchor" aria-hidden="true" href="#2-download-the-jupyter-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Download the Jupyter Notebooks&lt;/h3&gt;
&lt;p&gt;Clone or download this &lt;a href="https://github.com/adashofdata/nlp-in-python-tutorial"&gt;Github repository&lt;/a&gt;, so you have access to all the Jupyter Notebooks (.ipynb extension) in the tutorial. &lt;strong&gt;Note the green button on the right side of the screen that says &lt;code&gt;Clone or download&lt;/code&gt;.&lt;/strong&gt; If you know how to use Github, go ahead and clone the repo. If you don't know how to use Github, you can also just download the zip file and unzip it on your laptop.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-3-launch-anaconda-and-open-a-jupyter-notebook" class="anchor" aria-hidden="true" href="#3-launch-anaconda-and-open-a-jupyter-notebook"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. Launch Anaconda and Open a Jupyter Notebook&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Windows:&lt;/em&gt;
Open the Anaconda Navigator program. You should see the Jupyter Notebook logo. Below the logo, click Launch. A browser window should open up. In the browser window, navigate to the location of the saved Jupyter Notebook files and open 0-Hello-World.ipynb. Follow the instructions in the notebook.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Mac/Linux:&lt;/em&gt;
Open a terminal. Type &lt;code&gt;jupyter notebook&lt;/code&gt;. A browser should open up. In the browser window, navigate to the location of the saved Jupyter Notebook files and open 0-Hello-World.ipynb. Follow the instructions in the notebook.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-4-install-a-few-additional-packages" class="anchor" aria-hidden="true" href="#4-install-a-few-additional-packages"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4. Install a Few Additional Packages&lt;/h3&gt;
&lt;p&gt;There are a few additional packages we'll be using during the tutorial that are not included when you download Anaconda - wordcloud, textblob and gensim.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Windows:&lt;/em&gt;
Open the Anaconda Prompt program. You should see a black window pop up. Type &lt;code&gt;conda install -c conda-forge wordcloud&lt;/code&gt; to download wordcloud. You will be asked whether you want to proceed or not. Type &lt;code&gt;y&lt;/code&gt; for yes. Once that is done, type &lt;code&gt;conda install -c conda-forge textblob&lt;/code&gt; to download textblob and &lt;code&gt;y&lt;/code&gt; to proceed, and type &lt;code&gt;conda install -c conda-forge gensim&lt;/code&gt; to download gensim and &lt;code&gt;y&lt;/code&gt; to proceed.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Mac/Linux:&lt;/em&gt;
Your terminal should already be open. Type command-t to open a new tab. Type &lt;code&gt;conda install -c conda-forge wordcloud&lt;/code&gt; to download wordcloud. You will be asked whether you want to proceed or not. Type &lt;code&gt;y&lt;/code&gt; for yes. Once that is done, type &lt;code&gt;conda install -c conda-forge textblob&lt;/code&gt; to download textblob and &lt;code&gt;y&lt;/code&gt; to proceed, and type &lt;code&gt;conda install -c conda-forge gensim&lt;/code&gt; to download gensim and &lt;code&gt;y&lt;/code&gt; to proceed.&lt;/p&gt;
&lt;p&gt;If you have any issues, please email me at &lt;a href="mailto:adashofdata@gmail.com"&gt;adashofdata@gmail.com&lt;/a&gt; or come talk to me before the start of the tutorial.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>adashofdata</author><guid isPermaLink="false">https://github.com/adashofdata/nlp-in-python-tutorial</guid><pubDate>Sun, 09 Feb 2020 00:08:00 GMT</pubDate></item><item><title>Pierian-Data/Complete-Python-3-Bootcamp #9 in Jupyter Notebook, Today</title><link>https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</link><description>&lt;p&gt;&lt;i&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-complete-python-3-bootcamp" class="anchor" aria-hidden="true" href="#complete-python-3-bootcamp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Complete-Python-3-Bootcamp&lt;/h1&gt;
&lt;p&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/p&gt;
&lt;p&gt;Get it now for 95% off with the link:
&lt;a href="https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB" rel="nofollow"&gt;https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Pierian-Data</author><guid isPermaLink="false">https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</guid><pubDate>Sun, 09 Feb 2020 00:09:00 GMT</pubDate></item><item><title>AtsushiSakai/PythonRobotics #10 in Jupyter Notebook, Today</title><link>https://github.com/AtsushiSakai/PythonRobotics</link><description>&lt;p&gt;&lt;i&gt;Python sample codes for robotics algorithms.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRobotics/raw/master/icon.png?raw=true"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRobotics/raw/master/icon.png?raw=true" align="right" width="300" alt="header pic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-pythonrobotics" class="anchor" aria-hidden="true" href="#pythonrobotics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PythonRobotics&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/AtsushiSakai/PythonRobotics" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/58f87d5d3604646322c28abd8c5a9b2faa05fa51/68747470733a2f2f7472617669732d63692e6f72672f4174737573686953616b61692f507974686f6e526f626f746963732e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/AtsushiSakai/PythonRobotics.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pythonrobotics.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a60f894ef011c8a7e648348c16aabfdfb603613a/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f707974686f6e726f626f746963732f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/pythonrobotics/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/AtsushiSakai/pythonrobotics" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2e66a00c9dcf7ecc1f24189c6055aa7e6da233dc/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f73623237396b787576316265333931673f7376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/sb279kxuv1be391g?svg=true" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://coveralls.io/github/AtsushiSakai/PythonRobotics?branch=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2c26144817eba34b4ee9f9a6aee913e6b466218b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4174737573686953616b61692f507974686f6e526f626f746963732f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/AtsushiSakai/PythonRobotics/badge.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/AtsushiSakai/PythonRobotics/context:python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/4c3af4cd47bb2ea2c71cac274f1f7dd392eea893/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f4174737573686953616b61692f507974686f6e526f626f746963732e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138" alt="Language grade: Python" data-canonical-src="https://img.shields.io/lgtm/grade/python/g/AtsushiSakai/PythonRobotics.svg?logo=lgtm&amp;amp;logoWidth=18" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.codefactor.io/repository/github/atsushisakai/pythonrobotics/overview/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c3cd55e61ef2e22ff00427b50b9e7f1c3547de91/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6174737573686973616b61692f707974686f6e726f626f746963732f62616467652f6d6173746572" alt="CodeFactor" data-canonical-src="https://www.codefactor.io/repository/github/atsushisakai/pythonrobotics/badge/master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/AtsushiSakai/PythonRobotics"&gt;&lt;img src="https://camo.githubusercontent.com/230f0a1eaa529fa727cad2c9d3c1ace4738bd25d/68747470733a2f2f746f6b65692e72732f62312f6769746875622f4174737573686953616b61692f507974686f6e526f626f74696373" alt="tokei" data-canonical-src="https://tokei.rs/b1/github/AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://saythanks.io/to/AtsushiSakai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0c9f6dc1c6a604b58d3c56bc5d7624e44f7eee2b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5361792532305468616e6b732d212d3145414544422e737667" alt="Say Thanks!" data-canonical-src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Python codes for robotics algorithm.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#what-is-this"&gt;What is this?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#requirements"&gt;Requirements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-use"&gt;How to use&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#localization"&gt;Localization&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#extended-kalman-filter-localization"&gt;Extended Kalman Filter localization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#particle-filter-localization"&gt;Particle filter localization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#histogram-filter-localization"&gt;Histogram filter localization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#mapping"&gt;Mapping&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#gaussian-grid-map"&gt;Gaussian grid map&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ray-casting-grid-map"&gt;Ray casting grid map&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lidar-to-grid-map"&gt;Lidar to grid map&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#k-means-object-clustering"&gt;k-means object clustering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rectangle-fitting"&gt;Rectangle fitting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#slam"&gt;SLAM&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#iterative-closest-point-icp-matching"&gt;Iterative Closest Point (ICP) Matching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fastslam-10"&gt;FastSLAM 1.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#path-planning"&gt;Path Planning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#dynamic-window-approach"&gt;Dynamic Window Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#grid-based-search"&gt;Grid based search&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#dijkstra-algorithm"&gt;Dijkstra algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#a-algorithm"&gt;A* algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#potential-field-algorithm"&gt;Potential Field algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#grid-based-coverage-path-planning"&gt;Grid based coverage path planning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#state-lattice-planning"&gt;State Lattice Planning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#biased-polar-sampling"&gt;Biased polar sampling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lane-sampling"&gt;Lane sampling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#probabilistic-road-map-prm-planning"&gt;Probabilistic Road-Map (PRM) planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rapidly-exploring-random-trees-rrt"&gt;Rapidly-Exploring Random Trees (RRT)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#rrt"&gt;RRT*&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rrt-with-reeds-shepp-path"&gt;RRT* with reeds-shepp path&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lqr-rrt"&gt;LQR-RRT*&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#quintic-polynomials-planning"&gt;Quintic polynomials planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#reeds-shepp-planning"&gt;Reeds Shepp planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lqr-based-path-planning"&gt;LQR based path planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#optimal-trajectory-in-a-frenet-frame"&gt;Optimal Trajectory in a Frenet Frame&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#path-tracking"&gt;Path Tracking&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#move-to-a-pose-control"&gt;move to a pose control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#stanley-control"&gt;Stanley control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rear-wheel-feedback-control"&gt;Rear wheel feedback control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#linearquadratic-regulator-lqr-speed-and-steering-control"&gt;Linear–quadratic regulator (LQR) speed and steering control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#model-predictive-speed-and-steering-control"&gt;Model predictive speed and steering control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#nonlinear-model-predictive-control-with-c-gmres"&gt;Nonlinear Model predictive control with C-GMRES&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#arm-navigation"&gt;Arm Navigation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#n-joint-arm-to-point-control"&gt;N joint arm to point control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#arm-navigation-with-obstacle-avoidance"&gt;Arm navigation with obstacle avoidance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#aerial-navigation"&gt;Aerial Navigation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#drone-3d-trajectory-following"&gt;drone 3d trajectory following&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rocket-powered-landing"&gt;rocket powered landing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#bipedal"&gt;Bipedal&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#bipedal-planner-with-inverted-pendulum"&gt;bipedal planner with inverted pendulum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#use-case"&gt;Use-case&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contribution"&gt;Contribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#citing"&gt;Citing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#support"&gt;Support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#authors"&gt;Authors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-what-is-this" class="anchor" aria-hidden="true" href="#what-is-this"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is this?&lt;/h1&gt;
&lt;p&gt;This is a Python code collection of robotics algorithms, especially for autonomous navigation.&lt;/p&gt;
&lt;p&gt;Features:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Easy to read for understanding each algorithm's basic idea.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Widely used and practical algorithms are selected.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Minimum dependency.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;See this paper for more details:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1808.10703" rel="nofollow"&gt;[1808.10703] PythonRobotics: a Python code collection of robotics algorithms&lt;/a&gt; (&lt;a href="https://github.com/AtsushiSakai/PythonRoboticsPaper/blob/master/python_robotics.bib"&gt;BibTeX&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Python 3.7.x (2.7 is not supported)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;numpy&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;scipy&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;matplotlib&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;pandas&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.cvxpy.org/index.html" rel="nofollow"&gt;cvxpy&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h1&gt;
&lt;p&gt;This README only shows some examples of this project.&lt;/p&gt;
&lt;p&gt;If you are interested in other examples or mathematical backgrounds of each algorithm,&lt;/p&gt;
&lt;p&gt;You can check the full documentation online: &lt;a href="https://pythonrobotics.readthedocs.io/" rel="nofollow"&gt;https://pythonrobotics.readthedocs.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All animation gifs are stored here: &lt;a href="https://github.com/AtsushiSakai/PythonRoboticsGifs"&gt;AtsushiSakai/PythonRoboticsGifs: Animation gifs of PythonRobotics&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-how-to-use" class="anchor" aria-hidden="true" href="#how-to-use"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to use&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Clone this repo.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;git clone &lt;a href="https://github.com/AtsushiSakai/PythonRobotics.git"&gt;https://github.com/AtsushiSakai/PythonRobotics.git&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Install the required libraries. You can use environment.yml with conda command.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;conda env create -f environment.yml&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start="3"&gt;
&lt;li&gt;
&lt;p&gt;Execute python script in each directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add star to this repo if you like it &lt;g-emoji class="g-emoji" alias="smiley" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f603.png"&gt;😃&lt;/g-emoji&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;&lt;a id="user-content-localization" class="anchor" aria-hidden="true" href="#localization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Localization&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-extended-kalman-filter-localization" class="anchor" aria-hidden="true" href="#extended-kalman-filter-localization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Extended Kalman Filter localization&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/extended_kalman_filter/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/extended_kalman_filter/animation.gif" width="640" alt="EKF pic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Documentation: &lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/Localization/extended_kalman_filter/extended_kalman_filter_localization.ipynb"&gt;Notebook&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-particle-filter-localization" class="anchor" aria-hidden="true" href="#particle-filter-localization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Particle filter localization&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/particle_filter/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/particle_filter/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a sensor fusion localization with Particle Filter(PF).&lt;/p&gt;
&lt;p&gt;The blue line is true trajectory, the black line is dead reckoning trajectory,&lt;/p&gt;
&lt;p&gt;and the red line is estimated trajectory with PF.&lt;/p&gt;
&lt;p&gt;It is assumed that the robot can measure a distance from landmarks (RFID).&lt;/p&gt;
&lt;p&gt;This measurements are used for PF localization.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.probabilistic-robotics.org/" rel="nofollow"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-histogram-filter-localization" class="anchor" aria-hidden="true" href="#histogram-filter-localization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Histogram filter localization&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/histogram_filter/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/histogram_filter/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a 2D localization example with Histogram filter.&lt;/p&gt;
&lt;p&gt;The red cross is true position, black points are RFID positions.&lt;/p&gt;
&lt;p&gt;The blue grid shows a position probability of histogram filter.&lt;/p&gt;
&lt;p&gt;In this simulation, x,y are unknown, yaw is known.&lt;/p&gt;
&lt;p&gt;The filter integrates speed input and range observations from RFID for localization.&lt;/p&gt;
&lt;p&gt;Initial position is not needed.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.probabilistic-robotics.org/" rel="nofollow"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-mapping" class="anchor" aria-hidden="true" href="#mapping"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Mapping&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-gaussian-grid-map" class="anchor" aria-hidden="true" href="#gaussian-grid-map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gaussian grid map&lt;/h2&gt;
&lt;p&gt;This is a 2D Gaussian grid mapping example.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/gaussian_grid_map/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/gaussian_grid_map/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ray-casting-grid-map" class="anchor" aria-hidden="true" href="#ray-casting-grid-map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ray casting grid map&lt;/h2&gt;
&lt;p&gt;This is a 2D ray casting grid mapping example.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/raycasting_grid_map/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/raycasting_grid_map/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lidar-to-grid-map" class="anchor" aria-hidden="true" href="#lidar-to-grid-map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lidar to grid map&lt;/h2&gt;
&lt;p&gt;This example shows how to convert a 2D range measurement to a grid map.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="Mapping/lidar_to_grid_map/animation.gif"&gt;&lt;img src="Mapping/lidar_to_grid_map/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-k-means-object-clustering" class="anchor" aria-hidden="true" href="#k-means-object-clustering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;k-means object clustering&lt;/h2&gt;
&lt;p&gt;This is a 2D object clustering with k-means algorithm.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/kmeans_clustering/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/kmeans_clustering/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-rectangle-fitting" class="anchor" aria-hidden="true" href="#rectangle-fitting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Rectangle fitting&lt;/h2&gt;
&lt;p&gt;This is a 2D rectangle fitting for vehicle detection.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/rectangle_fitting/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/rectangle_fitting/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-slam" class="anchor" aria-hidden="true" href="#slam"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SLAM&lt;/h1&gt;
&lt;p&gt;Simultaneous Localization and Mapping(SLAM) examples&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-iterative-closest-point-icp-matching" class="anchor" aria-hidden="true" href="#iterative-closest-point-icp-matching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Iterative Closest Point (ICP) Matching&lt;/h2&gt;
&lt;p&gt;This is a 2D ICP matching example with singular value decomposition.&lt;/p&gt;
&lt;p&gt;It can calculate a rotation matrix and a translation vector between points to points.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/iterative_closest_point/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/iterative_closest_point/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cs.gmu.edu/~kosecka/cs685/cs685-icp.pdf" rel="nofollow"&gt;Introduction to Mobile Robotics: Iterative Closest Point Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-fastslam-10" class="anchor" aria-hidden="true" href="#fastslam-10"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FastSLAM 1.0&lt;/h2&gt;
&lt;p&gt;This is a feature based SLAM example using FastSLAM 1.0.&lt;/p&gt;
&lt;p&gt;The blue line is ground truth, the black line is dead reckoning, the red line is the estimated trajectory with FastSLAM.&lt;/p&gt;
&lt;p&gt;The red points are particles of FastSLAM.&lt;/p&gt;
&lt;p&gt;Black points are landmarks, blue crosses are estimated landmark positions by FastSLAM.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/FastSLAM1/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/FastSLAM1/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.probabilistic-robotics.org/" rel="nofollow"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www-personal.acfr.usyd.edu.au/tbailey/software/slam_simulations.htm" rel="nofollow"&gt;SLAM simulations by Tim Bailey&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-path-planning" class="anchor" aria-hidden="true" href="#path-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Path Planning&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-dynamic-window-approach" class="anchor" aria-hidden="true" href="#dynamic-window-approach"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dynamic Window Approach&lt;/h2&gt;
&lt;p&gt;This is a 2D navigation sample code with Dynamic Window Approach.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.ri.cmu.edu/pub_files/pub1/fox_dieter_1997_1/fox_dieter_1997_1.pdf" rel="nofollow"&gt;The Dynamic Window Approach to Collision Avoidance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DynamicWindowApproach/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DynamicWindowApproach/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-grid-based-search" class="anchor" aria-hidden="true" href="#grid-based-search"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Grid based search&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-dijkstra-algorithm" class="anchor" aria-hidden="true" href="#dijkstra-algorithm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dijkstra algorithm&lt;/h3&gt;
&lt;p&gt;This is a 2D grid based shortest path planning with Dijkstra's algorithm.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/Dijkstra/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/Dijkstra/animation.gif" alt="PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the animation, cyan points are searched nodes.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-a-algorithm" class="anchor" aria-hidden="true" href="#a-algorithm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A* algorithm&lt;/h3&gt;
&lt;p&gt;This is a 2D grid based shortest path planning with A star algorithm.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/AStar/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/AStar/animation.gif" alt="PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the animation, cyan points are searched nodes.&lt;/p&gt;
&lt;p&gt;Its heuristic is 2D Euclid distance.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-potential-field-algorithm" class="anchor" aria-hidden="true" href="#potential-field-algorithm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Potential Field algorithm&lt;/h3&gt;
&lt;p&gt;This is a 2D grid based path planning with Potential Field algorithm.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/PotentialFieldPlanning/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/PotentialFieldPlanning/animation.gif" alt="PotentialField" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the animation, the blue heat map shows potential value on each grid.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.cs.cmu.edu/~motionplanning/lecture/Chap4-Potential-Field_howie.pdf" rel="nofollow"&gt;Robotic Motion Planning:Potential Functions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-grid-based-coverage-path-planning" class="anchor" aria-hidden="true" href="#grid-based-coverage-path-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Grid based coverage path planning&lt;/h3&gt;
&lt;p&gt;This is a 2D grid based coverage path planning simulation.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/GridBasedSweepCPP/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/GridBasedSweepCPP/animation.gif" alt="PotentialField" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-state-lattice-planning" class="anchor" aria-hidden="true" href="#state-lattice-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;State Lattice Planning&lt;/h2&gt;
&lt;p&gt;This script is a path planning code with state lattice planning.&lt;/p&gt;
&lt;p&gt;This code uses the model predictive trajectory generator to solve boundary problem.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://journals.sagepub.com/doi/pdf/10.1177/0278364906075328" rel="nofollow"&gt;Optimal rough terrain trajectory generation for wheeled mobile robots&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.frc.ri.cmu.edu/~alonzo/pubs/papers/JFR_08_SS_Sampling.pdf" rel="nofollow"&gt;State Space Sampling of Feasible Motions for High-Performance Mobile Robot Navigation in Complex Environments&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-biased-polar-sampling" class="anchor" aria-hidden="true" href="#biased-polar-sampling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Biased polar sampling&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/BiasedPolarSampling.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/BiasedPolarSampling.gif" alt="PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-lane-sampling" class="anchor" aria-hidden="true" href="#lane-sampling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lane sampling&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/LaneSampling.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/LaneSampling.gif" alt="PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-probabilistic-road-map-prm-planning" class="anchor" aria-hidden="true" href="#probabilistic-road-map-prm-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Probabilistic Road-Map (PRM) planning&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ProbabilisticRoadMap/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ProbabilisticRoadMap/animation.gif" alt="PRM" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This PRM planner uses Dijkstra method for graph search.&lt;/p&gt;
&lt;p&gt;In the animation, blue points are sampled points,&lt;/p&gt;
&lt;p&gt;Cyan crosses means searched points with Dijkstra method,&lt;/p&gt;
&lt;p&gt;The red line is the final path of PRM.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Probabilistic_roadmap" rel="nofollow"&gt;Probabilistic roadmap - Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;　　&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-rapidly-exploring-random-trees-rrt" class="anchor" aria-hidden="true" href="#rapidly-exploring-random-trees-rrt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Rapidly-Exploring Random Trees (RRT)&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-rrt" class="anchor" aria-hidden="true" href="#rrt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RRT*&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTstar/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTstar/animation.gif" alt="PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a path planning code with RRT*&lt;/p&gt;
&lt;p&gt;Black circles are obstacles, green line is a searched tree, red crosses are start and goal positions.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1005.0416" rel="nofollow"&gt;Incremental Sampling-based Algorithms for Optimal Motion Planning&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.419.5503&amp;amp;rep=rep1&amp;amp;type=pdf" rel="nofollow"&gt;Sampling-based Algorithms for Optimal Motion Planning&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-rrt-with-reeds-shepp-path" class="anchor" aria-hidden="true" href="#rrt-with-reeds-shepp-path"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RRT* with reeds-shepp path&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTStarReedsShepp/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTStarReedsShepp/animation.gif" alt="Robotics/animation.gif at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Path planning for a car robot with RRT* and reeds shepp path planner.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-lqr-rrt" class="anchor" aria-hidden="true" href="#lqr-rrt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LQR-RRT*&lt;/h3&gt;
&lt;p&gt;This is a path planning simulation with LQR-RRT*.&lt;/p&gt;
&lt;p&gt;A double integrator motion model is used for LQR local planner.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRRRTStar/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRRRTStar/animation.gif" alt="LQRRRT" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://lis.csail.mit.edu/pubs/perez-icra12.pdf" rel="nofollow"&gt;LQR-RRT*: Optimal Sampling-Based Motion Planning with Automatically Derived Extension Heuristics&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/MahanFathi/LQR-RRTstar"&gt;MahanFathi/LQR-RRTstar: LQR-RRT* method is used for random motion planning of a simple pendulum in its phase plot&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-quintic-polynomials-planning" class="anchor" aria-hidden="true" href="#quintic-polynomials-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quintic polynomials planning&lt;/h2&gt;
&lt;p&gt;Motion planning with quintic polynomials.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/QuinticPolynomialsPlanner/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/QuinticPolynomialsPlanner/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It can calculate 2D path, velocity, and acceleration profile based on quintic polynomials.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ieeexplore.ieee.org/document/637936/" rel="nofollow"&gt;Local Path Planning And Motion Control For Agv In Positioning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-reeds-shepp-planning" class="anchor" aria-hidden="true" href="#reeds-shepp-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reeds Shepp planning&lt;/h2&gt;
&lt;p&gt;A sample code with Reeds Shepp path planning.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ReedsSheppPath/animation.gif?raw=true"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ReedsSheppPath/animation.gif?raw=true" alt="RSPlanning" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://planning.cs.uiuc.edu/node822.html" rel="nofollow"&gt;15.3.2 Reeds-Shepp Curves&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://pdfs.semanticscholar.org/932e/c495b1d0018fd59dee12a0bf74434fac7af4.pdf" rel="nofollow"&gt;optimal paths for a car that goes both forwards and backwards&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/ghliu/pyReedsShepp"&gt;ghliu/pyReedsShepp: Implementation of Reeds Shepp curve.&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-lqr-based-path-planning" class="anchor" aria-hidden="true" href="#lqr-based-path-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LQR based path planning&lt;/h2&gt;
&lt;p&gt;A sample code using LQR based path planning for double integrator model.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRPlanner/animation.gif?raw=true"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRPlanner/animation.gif?raw=true" alt="RSPlanning" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-optimal-trajectory-in-a-frenet-frame" class="anchor" aria-hidden="true" href="#optimal-trajectory-in-a-frenet-frame"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Optimal Trajectory in a Frenet Frame&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/FrenetOptimalTrajectory/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/FrenetOptimalTrajectory/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is optimal trajectory generation in a Frenet Frame.&lt;/p&gt;
&lt;p&gt;The cyan line is the target course and black crosses are obstacles.&lt;/p&gt;
&lt;p&gt;The red line is predicted path.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.researchgate.net/profile/Moritz_Werling/publication/224156269_Optimal_Trajectory_Generation_for_Dynamic_Street_Scenarios_in_a_Frenet_Frame/links/54f749df0cf210398e9277af.pdf" rel="nofollow"&gt;Optimal Trajectory Generation for Dynamic Street Scenarios in a Frenet Frame&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Cj6tAQe7UCY" rel="nofollow"&gt;Optimal trajectory generation for dynamic street scenarios in a Frenet Frame&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-path-tracking" class="anchor" aria-hidden="true" href="#path-tracking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Path Tracking&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-move-to-a-pose-control" class="anchor" aria-hidden="true" href="#move-to-a-pose-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;move to a pose control&lt;/h2&gt;
&lt;p&gt;This is a simulation of moving to a pose control&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/move_to_pose/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/move_to_pose/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://link.springer.com/book/10.1007/978-3-642-20144-8" rel="nofollow"&gt;P. I. Corke, "Robotics, Vision and Control" | SpringerLink p102&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-stanley-control" class="anchor" aria-hidden="true" href="#stanley-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stanley control&lt;/h2&gt;
&lt;p&gt;Path tracking simulation with Stanley steering control and PID speed control.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/stanley_controller/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/stanley_controller/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://robots.stanford.edu/papers/thrun.stanley05.pdf" rel="nofollow"&gt;Stanley: The robot that won the DARPA grand challenge&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.ri.cmu.edu/pub_files/2009/2/Automatic_Steering_Methods_for_Autonomous_Automobile_Path_Tracking.pdf" rel="nofollow"&gt;Automatic Steering Methods for Autonomous Automobile Path Tracking&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-rear-wheel-feedback-control" class="anchor" aria-hidden="true" href="#rear-wheel-feedback-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Rear wheel feedback control&lt;/h2&gt;
&lt;p&gt;Path tracking simulation with rear wheel feedback steering control and PID speed control.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/rear_wheel_feedback/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/rear_wheel_feedback/animation.gif" alt="PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1604.07446" rel="nofollow"&gt;A Survey of Motion Planning and Control Techniques for Self-driving Urban Vehicles&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-linearquadratic-regulator-lqr-speed-and-steering-control" class="anchor" aria-hidden="true" href="#linearquadratic-regulator-lqr-speed-and-steering-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linear–quadratic regulator (LQR) speed and steering control&lt;/h2&gt;
&lt;p&gt;Path tracking simulation with LQR speed and steering control.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/lqr_speed_steer_control/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/lqr_speed_steer_control/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ieeexplore.ieee.org/document/5940562/" rel="nofollow"&gt;Towards fully autonomous driving: Systems and algorithms - IEEE Conference Publication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-model-predictive-speed-and-steering-control" class="anchor" aria-hidden="true" href="#model-predictive-speed-and-steering-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model predictive speed and steering control&lt;/h2&gt;
&lt;p&gt;Path tracking simulation with iterative linear model predictive speed and steering control.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/model_predictive_speed_and_steer_control/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/model_predictive_speed_and_steer_control/animation.gif" width="640" alt="MPC pic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/PathTracking/model_predictive_speed_and_steer_control/Model_predictive_speed_and_steering_control.ipynb"&gt;notebook&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://grauonline.de/wordpress/?page_id=3244" rel="nofollow"&gt;Real-time Model Predictive Control (MPC), ACADO, Python | Work-is-Playing&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-nonlinear-model-predictive-control-with-c-gmres" class="anchor" aria-hidden="true" href="#nonlinear-model-predictive-control-with-c-gmres"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Nonlinear Model predictive control with C-GMRES&lt;/h2&gt;
&lt;p&gt;A motion planning and path tracking simulation with NMPC of C-GMRES&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/cgmres_nmpc/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/cgmres_nmpc/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/PathTracking/cgmres_nmpc/cgmres_nmpc.ipynb"&gt;notebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-arm-navigation" class="anchor" aria-hidden="true" href="#arm-navigation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Arm Navigation&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-n-joint-arm-to-point-control" class="anchor" aria-hidden="true" href="#n-joint-arm-to-point-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;N joint arm to point control&lt;/h2&gt;
&lt;p&gt;N joint arm to a point control simulation.&lt;/p&gt;
&lt;p&gt;This is a interactive simulation.&lt;/p&gt;
&lt;p&gt;You can set the goal position of the end effector with left-click on the ploting area.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/n_joint_arm_to_point_control/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/n_joint_arm_to_point_control/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this simulation N = 10, however, you can change it.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-arm-navigation-with-obstacle-avoidance" class="anchor" aria-hidden="true" href="#arm-navigation-with-obstacle-avoidance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Arm navigation with obstacle avoidance&lt;/h2&gt;
&lt;p&gt;Arm navigation with obstacle avoidance simulation.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/arm_obstacle_navigation/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/arm_obstacle_navigation/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-aerial-navigation" class="anchor" aria-hidden="true" href="#aerial-navigation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Aerial Navigation&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-drone-3d-trajectory-following" class="anchor" aria-hidden="true" href="#drone-3d-trajectory-following"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;drone 3d trajectory following&lt;/h2&gt;
&lt;p&gt;This is a 3d trajectory following simulation for a quadrotor.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/drone_3d_trajectory_following/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/drone_3d_trajectory_following/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-rocket-powered-landing" class="anchor" aria-hidden="true" href="#rocket-powered-landing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;rocket powered landing&lt;/h2&gt;
&lt;p&gt;This is a 3d trajectory generation simulation for a rocket powered landing.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/rocket_powered_landing/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/rocket_powered_landing/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/AerialNavigation/rocket_powered_landing/rocket_powered_landing.ipynb"&gt;notebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-bipedal" class="anchor" aria-hidden="true" href="#bipedal"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bipedal&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-bipedal-planner-with-inverted-pendulum" class="anchor" aria-hidden="true" href="#bipedal-planner-with-inverted-pendulum"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;bipedal planner with inverted pendulum&lt;/h2&gt;
&lt;p&gt;This is a bipedal planner for modifying footsteps with inverted pendulum.&lt;/p&gt;
&lt;p&gt;You can set the footsteps and the planner will modify those automatically.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Bipedal/bipedal_planner/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Bipedal/bipedal_planner/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h1&gt;
&lt;p&gt;MIT&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-use-case" class="anchor" aria-hidden="true" href="#use-case"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Use-case&lt;/h1&gt;
&lt;p&gt;If this project helps your robotics project, please let me know with creating an issue.&lt;/p&gt;
&lt;p&gt;Your robot's video, which is using PythonRobotics, is very welcome!!&lt;/p&gt;
&lt;p&gt;This is a list of other user's comment and references:&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/users_comments.md"&gt;users_comments&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-contribution" class="anchor" aria-hidden="true" href="#contribution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution&lt;/h1&gt;
&lt;p&gt;Any contribution is welcome!!&lt;/p&gt;
&lt;p&gt;If your PR is merged multiple times, I will add your account to the author list.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-citing" class="anchor" aria-hidden="true" href="#citing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citing&lt;/h1&gt;
&lt;p&gt;If you use this project's code for your academic work, we encourage you to cite &lt;a href="https://arxiv.org/abs/1808.10703" rel="nofollow"&gt;our papers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you use this project's code in industry, we'd love to hear from you as well; feel free to reach out to the developers directly.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-support" class="anchor" aria-hidden="true" href="#support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support&lt;/h1&gt;
&lt;p&gt;If you or your company would like to support this project, please consider:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/sponsors/AtsushiSakai"&gt;Sponsor @AtsushiSakai on GitHub Sponsors&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.patreon.com/myenigma" rel="nofollow"&gt;Become a backer or sponsor on Patreon&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.paypal.me/myenigmapay/" rel="nofollow"&gt;One-time donation via PayPal&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authors&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/AtsushiSakai/"&gt;Atsushi Sakai&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/daniel-s-ingram"&gt;Daniel Ingram&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/jwdinius"&gt;Joe Dinius&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/karanchawla"&gt;Karan Chawla&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/araffin"&gt;Antonin RAFFIN&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/AlexisTM"&gt;Alexis Paques&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/rsasaki0109"&gt;Ryohei Sasaki&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/goktug97"&gt;Göktuğ Karakaşlı&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/Gjacquenot"&gt;Guillaume Jacquenot&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>AtsushiSakai</author><guid isPermaLink="false">https://github.com/AtsushiSakai/PythonRobotics</guid><pubDate>Sun, 09 Feb 2020 00:10:00 GMT</pubDate></item><item><title>fengdu78/machine_learning_beginner #11 in Jupyter Notebook, Today</title><link>https://github.com/fengdu78/machine_learning_beginner</link><description>&lt;p&gt;&lt;i&gt;机器学习初学者公众号作品&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-机器学习初学者公众号" class="anchor" aria-hidden="true" href="#机器学习初学者公众号"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习初学者公众号&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/gongzhong.jpg"&gt;&lt;img src="images/gongzhong.jpg" alt="公众号" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本仓库是“机器学习初学者”公众号发布的内容代码。&lt;/p&gt;
&lt;p&gt;机器学习qq群：659697409（我们有9个群，加过一个就不需要加了）&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-这个仓库的内容目录" class="anchor" aria-hidden="true" href="#这个仓库的内容目录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;这个仓库的内容目录&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-2019年精选文章" class="anchor" aria-hidden="true" href="#2019年精选文章"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2019年精选文章&lt;/h4&gt;
&lt;p&gt;&lt;a href="2019/"&gt;2019&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-ai基础" class="anchor" aria-hidden="true" href="#ai基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;AI基础&lt;/h4&gt;
&lt;p&gt;&lt;a href="AI_beginner/"&gt;AI_beginner&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-深度学习内容" class="anchor" aria-hidden="true" href="#深度学习内容"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;深度学习内容&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;1.&lt;a href="PyTorch_beginner/"&gt;PyTorch60分钟入门（中文翻译）&lt;/a&gt;（目录名：PyTorch_beginner）&lt;/li&gt;
&lt;li&gt;2.&lt;a href="deep-learning-with-python-notebooks/"&gt;Python深度学习原书代码中文翻译&lt;/a&gt;（目录名：deep-learning-with-python-notebooks）&lt;/li&gt;
&lt;li&gt;3.&lt;a href="deep-learning-with-tensorflow-keras-pytorch/"&gt;强烈推荐的TensorFlow、Pytorch和Keras的样例资源&lt;/a&gt;（目录名：deep-learning-with-tensorflow-keras-pytorch）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-python基础" class="anchor" aria-hidden="true" href="#python基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python基础&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;1.&lt;a href="python-start/"&gt;两天入门Python&lt;/a&gt;(目录名：python-start)&lt;/li&gt;
&lt;li&gt;2.&lt;a href="numpy/"&gt;适合初学者快速入门的Numpy实战全集&lt;/a&gt;(目录名：numpy)&lt;/li&gt;
&lt;li&gt;3.&lt;a href="matplotlib/"&gt;matplotlib学习之基本使用&lt;/a&gt;(目录名：matplotlib)&lt;/li&gt;
&lt;li&gt;4.&lt;a href="pyparis-2018-sklearn/"&gt;Sklearn入门经典案例&lt;/a&gt;(目录名：pyparis-2018-sklearn)&lt;/li&gt;
&lt;li&gt;5.&lt;a href="pandas/"&gt;两天学会pandas&lt;/a&gt;(目录名：pandas)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-本站的其他开源仓库" class="anchor" aria-hidden="true" href="#本站的其他开源仓库"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;本站的其他开源仓库&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-本人整理" class="anchor" aria-hidden="true" href="#本人整理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;本人整理&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;1.&lt;a href="https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes"&gt;吴恩达老师的机器学习课程个人笔记&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2.&lt;a href="https://github.com/fengdu78/deeplearning_ai_books"&gt;deeplearning.ai（吴恩达老师的深度学习课程笔记及资源）&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;3.&lt;a href="https://github.com/fengdu78/lihang-code"&gt;《统计学习方法的代码实现》&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-大神之作" class="anchor" aria-hidden="true" href="#大神之作"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;大神之作&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;1.&lt;a href="https://github.com/roboticcam/machine-learning-notes"&gt;徐亦达老师的机器学习资料分享&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2.&lt;a href="http://www.huaxiaozhuan.com/" rel="nofollow"&gt;华校专老师的笔记分享&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3.&lt;a href="https://github.com/Doraemonzzz/Learning-from-data"&gt;LFD习题解答（林轩田机器学习课程内容）（作者秦臻）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;以下为是公众号创立以来的精选原创文章，适合初学者入门 AI。本文建议用微信收藏用碎片时间学习。（黄海广）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-一前言" class="anchor" aria-hidden="true" href="#一前言"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;一、前言&lt;/h2&gt;
&lt;p&gt;AI 初学者最大的问题就是：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;资料太多！看不完！！不知道如何取舍！！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我把 公众号创办以来的原创文章进行整理，文章适合&lt;strong&gt;本科、硕士以及刚接触机器学习的博士&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;学完这些文章学完以后，就基本入门了。&lt;/p&gt;
&lt;p&gt;入门以后，遇到问题能上网搜索解决了，也知道接下来应该学什么。&lt;/p&gt;
&lt;p&gt;本文建议用微信收藏，利用碎片时间学习。&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-作者简介" class="anchor" aria-hidden="true" href="#作者简介"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;作者简介：&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484487&amp;amp;idx=1&amp;amp;sn=1df61f5f1ae6838f2eef1f4a3c702733&amp;amp;chksm=97048ffba07306edb4e816f8fc6ef8bdeb33ed644e68b4353649697fa0c11044f26c3bf788e8&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;那些年做的学术公益-你不是一个人在战斗&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-二学习路线" class="anchor" aria-hidden="true" href="#二学习路线"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;二、学习路线&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484737&amp;amp;idx=1&amp;amp;sn=27c52b4bc4ca98d3ab817344b84226cc&amp;amp;chksm=97048efda07307eb78d4f4ec0039a386a658404156b051af0cb715fafa8d2ae66cbe49343bf3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;首发：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484737&amp;amp;idx=1&amp;amp;sn=27c52b4bc4ca98d3ab817344b84226cc&amp;amp;chksm=97048efda07307eb78d4f4ec0039a386a658404156b051af0cb715fafa8d2ae66cbe49343bf3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;适合初学者入门人工智能的路线及资料下载&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这篇文章为初学者提供了入门的路线。包含数学基础、python 入门、机器学习、深度学习、特征工程入门等。并把代码放在了 github 仓库：&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/fengdu78/Data-Science-Notes"&gt;https://github.com/fengdu78/Data-Science-Notes&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247486187&amp;amp;idx=1&amp;amp;sn=3c86ade48695ce102e93fa813c55f126&amp;amp;chksm=97048157a07308419d900bec1ff4699092c62c7ed331a334734a4225db0b2274a7b134153037&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;机器学习在线手册：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247486187&amp;amp;idx=1&amp;amp;sn=3c86ade48695ce102e93fa813c55f126&amp;amp;chksm=97048157a07308419d900bec1ff4699092c62c7ed331a334734a4225db0b2274a7b134153037&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;像背托福单词一样学机器学习&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这篇文章将机器学习的精华部分做成了手册，打开微信就能学习，适合平时时间少的朋友学习机器学习，可以在通勤的时候在手机上学习，建议收藏本文慢慢学习&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-三基础知识" class="anchor" aria-hidden="true" href="#三基础知识"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;三、基础知识&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485787&amp;amp;idx=1&amp;amp;sn=d53e991935fc6def2919b2bed6111f8d&amp;amp;chksm=970482e7a0730bf17c9fc7f5a639a21331be477af74b039ec56c0a4eaf0220259733d9852684&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;带你少走弯路！&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485787&amp;amp;idx=1&amp;amp;sn=d53e991935fc6def2919b2bed6111f8d&amp;amp;chksm=970482e7a0730bf17c9fc7f5a639a21331be477af74b039ec56c0a4eaf0220259733d9852684&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;！&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485787&amp;amp;idx=1&amp;amp;sn=d53e991935fc6def2919b2bed6111f8d&amp;amp;chksm=970482e7a0730bf17c9fc7f5a639a21331be477af74b039ec56c0a4eaf0220259733d9852684&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;黄博整理的机器学习数学基础资料来帮你（可在线阅读）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上面这篇文章是数学基础，也是以下五篇文章的整合版本，可以在线阅读，也可以根据需要分别阅读。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485293&amp;amp;idx=2&amp;amp;sn=2650e61d6268f667333e86cb52ab1df1&amp;amp;chksm=97048cd1a07305c73229a0b3daf887ac4960fcbd3f378bbc0b40b9b38203fca387b29218fcbd&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;首发：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485293&amp;amp;idx=2&amp;amp;sn=2650e61d6268f667333e86cb52ab1df1&amp;amp;chksm=97048cd1a07305c73229a0b3daf887ac4960fcbd3f378bbc0b40b9b38203fca387b29218fcbd&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;吴恩达的 CS229 的数学基础（概率论），有人把它做成了在线翻译版本！&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485221&amp;amp;idx=2&amp;amp;sn=105073d243e1d39e10c7ad3dd22043c8&amp;amp;chksm=97048c99a073058fd51d33990ed476ff34acbe22aa7f52cdcd396f2283b22312feafbffb0e5b&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;首发：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485221&amp;amp;idx=2&amp;amp;sn=105073d243e1d39e10c7ad3dd22043c8&amp;amp;chksm=97048c99a073058fd51d33990ed476ff34acbe22aa7f52cdcd396f2283b22312feafbffb0e5b&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;吴恩达的 CS229 的数学基础（线性代数），有人把它做成了在线翻译版本！&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;在线阅读！&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;！&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;机器学习数学精华：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;高等数学&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;在线阅读！&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;！&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;机器学习数学精华：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;线性代数&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=5&amp;amp;sn=af7c82f85740eac5672080d936869639&amp;amp;chksm=970482b7a0730ba13b6c4be0a40a0dc6c98c500ff9ea29dca61bba592513236144148320636c&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;在线阅读！！机器学习数学精华：概率论与数理统计&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-四机器学习" class="anchor" aria-hidden="true" href="#四机器学习"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;四、机器学习&lt;/h2&gt;
&lt;p&gt;原创作品为以下三个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484544&amp;amp;idx=1&amp;amp;sn=c5b92a7c4a2bdca10d92ff06dbb315c4&amp;amp;chksm=97048f3ca073062a00c2e961daa9c17585d8b5cb8e73229b5b0364a6fc680b242dd7b409bd23&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;吴恩达机器学习课程笔记及资源（github 标星 12000+，提供百度云镜像）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484580&amp;amp;idx=1&amp;amp;sn=7cf0ca2e05fc1ed71dff380bf1f60ff6&amp;amp;chksm=97048f18a073060e85ae439fd458bd976bf21366ca2b36ed3aeefda297b47d5c5a91196a4513&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;《统计学习方法》的 python 代码实现（github 标星 7200+）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484360&amp;amp;idx=1&amp;amp;sn=d1859797428994bdb2b265aa4ddb98b9&amp;amp;chksm=97048874a07301627e89152fd2f84ba82d005348f7f04723a4e10facd463b8607691d6510678&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;推荐：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484360&amp;amp;idx=1&amp;amp;sn=d1859797428994bdb2b265aa4ddb98b9&amp;amp;chksm=97048874a07301627e89152fd2f84ba82d005348f7f04723a4e10facd463b8607691d6510678&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;《机器学习实战：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484360&amp;amp;idx=1&amp;amp;sn=d1859797428994bdb2b265aa4ddb98b9&amp;amp;chksm=97048874a07301627e89152fd2f84ba82d005348f7f04723a4e10facd463b8607691d6510678&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;基于 Scikit-Learn 和 TensorFlow》中文翻译和代码下载&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;后来又制作成了在线阅读版本：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485997&amp;amp;idx=1&amp;amp;sn=975216fdafe7e09bc515c944aaf7a26a&amp;amp;chksm=97048191a0730887950f73c6774921eefd0e26da5b3568f100cf6c45f22e783514076624120d&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;带你少走弯路：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485997&amp;amp;idx=1&amp;amp;sn=975216fdafe7e09bc515c944aaf7a26a&amp;amp;chksm=97048191a0730887950f73c6774921eefd0e26da5b3568f100cf6c45f22e783514076624120d&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;五篇文章学完吴恩达机器学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247486130&amp;amp;idx=2&amp;amp;sn=401a94b7db6e0e531ab3a745d3a1e3ed&amp;amp;chksm=9704810ea073081866aa98753412945734be9e217b8488c26bd0a66d54fbedf9c84f8c07873a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;经典复现：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247486130&amp;amp;idx=2&amp;amp;sn=401a94b7db6e0e531ab3a745d3a1e3ed&amp;amp;chksm=9704810ea073081866aa98753412945734be9e217b8488c26bd0a66d54fbedf9c84f8c07873a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;《统计学习方法》的代码实现（在线阅读！&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247486130&amp;amp;idx=2&amp;amp;sn=401a94b7db6e0e531ab3a745d3a1e3ed&amp;amp;chksm=9704810ea073081866aa98753412945734be9e217b8488c26bd0a66d54fbedf9c84f8c07873a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-机器学习相关" class="anchor" aria-hidden="true" href="#机器学习相关"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习相关&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484828&amp;amp;idx=1&amp;amp;sn=fbd9a75c363580e85d7000fd02ad56af&amp;amp;chksm=97048e20a07307369410f16924178d836587b4407abb4f3e5c9f3017f9adda9b5538fef6f912&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;机器学习练习数据哪里找？&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484828&amp;amp;idx=1&amp;amp;sn=fbd9a75c363580e85d7000fd02ad56af&amp;amp;chksm=97048e20a07307369410f16924178d836587b4407abb4f3e5c9f3017f9adda9b5538fef6f912&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;两行代码搞定！&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484383&amp;amp;idx=1&amp;amp;sn=de695ff5e6a3e36a1c54a4a498e36a95&amp;amp;chksm=97048863a07301759227c74c174f6596c9da6fbf40b2fa276f87b1e845c808cacd70b51c7f6a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;学完可以解决 90%以上的数据分析问题-利用 python 进行数据分析第二版（代码和中文笔记）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484297&amp;amp;idx=1&amp;amp;sn=c862ea44abc4f90c52c5d1e9609bd9d7&amp;amp;chksm=97048835a07301239f1bcfcb1ef0eb66058dcb6cce2acfc8f04bbee6660f20d846fbca79a0f0&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;特征工程的宝典-《Feature Engineering for Machine Learning》翻译及代码实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-五深度学习" class="anchor" aria-hidden="true" href="#五深度学习"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;五、深度学习&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-吴恩达深度学习课程笔记和资源" class="anchor" aria-hidden="true" href="#吴恩达深度学习课程笔记和资源"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;吴恩达深度学习课程笔记和资源&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484558&amp;amp;idx=1&amp;amp;sn=d2033198fa6227a4cd561c70a93f2e2a&amp;amp;chksm=97048f32a07306245660808fe46569d8999491108a3d37eb833a27c8f597cd3a2c18852df014&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;吴恩达深度学习笔记及视频等资源（github 标星 8500+，提供百度云镜像）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-tensorflow-入门" class="anchor" aria-hidden="true" href="#tensorflow-入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow 入门：&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484633&amp;amp;idx=1&amp;amp;sn=adf2dfee2bf09e6dab0a67d329bd0c50&amp;amp;chksm=97048f65a073067365daa419808913b50872a18ef9bb16a5011f90967eb89c335fb204c027d2&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;带你少走弯路：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484633&amp;amp;idx=1&amp;amp;sn=adf2dfee2bf09e6dab0a67d329bd0c50&amp;amp;chksm=97048f65a073067365daa419808913b50872a18ef9bb16a5011f90967eb89c335fb204c027d2&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;强烈推荐的 TensorFlow 快速入门资料和翻译（可下载）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-keras-入门" class="anchor" aria-hidden="true" href="#keras-入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;keras 入门：&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484794&amp;amp;idx=1&amp;amp;sn=9b52adc9138fda3d404dff24e03d14b5&amp;amp;chksm=97048ec6a07307d01ae2c93aa887d3c6ac6ec5f9d2ed5a5b8260182e3f47fae3ea9f08a1a0bf&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;带你少走弯路：强烈推荐的 Keras 快速入门资料和翻译（可下载）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-pytorch入门" class="anchor" aria-hidden="true" href="#pytorch入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pytorch入门：&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484721&amp;amp;idx=2&amp;amp;sn=f2c6084354c912d91fbbb7f09adaf4ac&amp;amp;chksm=97048e8da073079b40d8a4cad5c016d762e1668ffd52f2d04bcb702e4530a9a275d73035ca9c&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;带你少走弯路：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484721&amp;amp;idx=2&amp;amp;sn=f2c6084354c912d91fbbb7f09adaf4ac&amp;amp;chksm=97048e8da073079b40d8a4cad5c016d762e1668ffd52f2d04bcb702e4530a9a275d73035ca9c&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;强烈推荐的 Pytorch 快速入门资料和翻译（可下载）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-其他资料" class="anchor" aria-hidden="true" href="#其他资料"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;其他资料&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484411&amp;amp;idx=1&amp;amp;sn=0f95762a29249ea40b11edd24648c8d0&amp;amp;chksm=97048847a0730151f4bdd1d99ccf454206108fcf7f5b61b100f3dc39a7c46f926fc3da084c72&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;首发：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484411&amp;amp;idx=1&amp;amp;sn=0f95762a29249ea40b11edd24648c8d0&amp;amp;chksm=97048847a0730151f4bdd1d99ccf454206108fcf7f5b61b100f3dc39a7c46f926fc3da084c72&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;深度学习入门宝典-《python 深度学习》原文代码中文注释版及电子书&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484393&amp;amp;idx=1&amp;amp;sn=c22c28eb324e052bdb5a399915c0b1c4&amp;amp;chksm=97048855a073014366257382f64e44b7ef6dcc59a0c3991abe0bb4128c0e471e28cf328ae9e4&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;强烈推荐的 TensorFlow、Pytorch 和 Keras 的样例资源（深度学习初学者必须收藏）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484401&amp;amp;idx=1&amp;amp;sn=73e97612c8a8c6cbb65461f999c024ff&amp;amp;chksm=9704884da073015bfc9e3ee0d5c9765f9a48bee1091da319d024de63bc2d202c9a53ca6057b7&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Ubuntu 18.04 深度学习环境配置（CUDA9.0+CUDDN7.4+TensorFolw1.8）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-六python-相关" class="anchor" aria-hidden="true" href="#六python-相关"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;六、Python 相关&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484426&amp;amp;idx=1&amp;amp;sn=c1971be3d85a8c247a5c77bfd925733d&amp;amp;chksm=97048fb6a07306a0ad6f51f1aa90225c685e46ad5adddf929a110cdd46ed9105ff1c1b1a90e9&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;学习 python 入门的个人建议及资料&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484364&amp;amp;idx=1&amp;amp;sn=2d7cf6b8d8a4647a32459cb3798f3d76&amp;amp;chksm=97048870a0730166a7c2e9be889cb926b98585947d123500d958f2afe5afbfd21a5718684896&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Python 环境的安装（Anaconda+Jupyter notebook+Pycharm）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484361&amp;amp;idx=1&amp;amp;sn=086b8b9cbed37fd1932b6a8e6e517e2d&amp;amp;chksm=97048875a07301633726942278aac93d005fc673dcf740b8f6d6c75c544d0254828dc7e60b58&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Python 代码写得丑怎么办？&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484361&amp;amp;idx=1&amp;amp;sn=086b8b9cbed37fd1932b6a8e6e517e2d&amp;amp;chksm=97048875a07301633726942278aac93d005fc673dcf740b8f6d6c75c544d0254828dc7e60b58&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;推荐几个神器拯救你&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484368&amp;amp;idx=1&amp;amp;sn=9ec8ab2ab1f368b877799c90d0cdc671&amp;amp;chksm=9704886ca073017a452532d35129f4923b895c09e43e9e9debaa8261d895540462ab5dbda239&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Numpy 练习题 100 题-提高你的数据分析技能&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484373&amp;amp;idx=1&amp;amp;sn=e48f845dccdec3c912e6cd16c7e363a8&amp;amp;chksm=97048869a073017fd8d4dd571807dd220940c7c9d729cf9c45fb66bab37ae0bc741272e79135&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Pandas 练习题-提高你的数据分析技能&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484389&amp;amp;idx=1&amp;amp;sn=7ab4f99f76b02a5198740c2b5fde91dc&amp;amp;chksm=97048859a073014f9fda1dc00eef5b47b78c15def4478463bc4bba773790474b225ff9606e8e&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;python 绘图工具基础-matplotlib 学习之基本使用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484376&amp;amp;idx=1&amp;amp;sn=cd3ac06f4a0125eebb317578db3c4ec5&amp;amp;chksm=97048864a0730172f24c35e922573763213f2a2c0da4a6a8d2787d0f09315a3eac6e37634997&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;数据可视化的利器-Seaborn 简易入门&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-七nlp" class="anchor" aria-hidden="true" href="#七nlp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;七、NLP&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484419&amp;amp;idx=1&amp;amp;sn=3a21e26b420fcd52d17cf3e1a456ee10&amp;amp;chksm=97048fbfa07306a9f0454fa330155e16127f6020525986ccc0fcf182c089b08b9b503c888a95&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;一些 NLP 的入门资料参考&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484317&amp;amp;idx=1&amp;amp;sn=83e5d0bc7258c49c2427be4afa6cb588&amp;amp;chksm=97048821a0730137fc9df879f8e0d0ae9cbd88160d40750aaa4b3e5c7accd85e328e7c53c451&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;推荐：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484317&amp;amp;idx=1&amp;amp;sn=83e5d0bc7258c49c2427be4afa6cb588&amp;amp;chksm=97048821a0730137fc9df879f8e0d0ae9cbd88160d40750aaa4b3e5c7accd85e328e7c53c451&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;常见 NLP 模型的代码实现（基于 TensorFlow 和 PyTorch）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484301&amp;amp;idx=1&amp;amp;sn=ef50f185d8c41be4f54e141a9b4d0923&amp;amp;chksm=97048831a073012770f6b7bab14c3ff61e4215f24b38b9e98b701384ac798f2b6fee964816e6&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;图解 word2vec（原文翻译）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-八学术技巧" class="anchor" aria-hidden="true" href="#八学术技巧"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;八、学术技巧&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484301&amp;amp;idx=1&amp;amp;sn=ef50f185d8c41be4f54e141a9b4d0923&amp;amp;chksm=97048831a073012770f6b7bab14c3ff61e4215f24b38b9e98b701384ac798f2b6fee964816e6&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;推荐几个提高工作效率的神器&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484429&amp;amp;idx=1&amp;amp;sn=5663338e5c76374512fa354d68b5a67d&amp;amp;chksm=97048fb1a07306a70bd1259038701cd7aeca49482a593646d1399166b87071b3ddc35ae4df4d&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;科研工作者的神器--zotero 论文管理工具&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484279&amp;amp;idx=1&amp;amp;sn=786aa47073fa3522f4cce1493fba9f11&amp;amp;chksm=970488cba07301dd977fef7b761843dc6b84d26a62daff79e1121433090538b42aa3de5cb0fb&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;分享：&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484279&amp;amp;idx=1&amp;amp;sn=786aa47073fa3522f4cce1493fba9f11&amp;amp;chksm=970488cba07301dd977fef7b761843dc6b84d26a62daff79e1121433090538b42aa3de5cb0fb&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;我是怎么在 github 上找到优秀的仓库的？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-总结" class="anchor" aria-hidden="true" href="#总结"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;总结&lt;/h2&gt;
&lt;p&gt;本文总结了“&lt;strong&gt;机器学习初学者&lt;/strong&gt;”公众号创立以来的精选&lt;strong&gt;原创&lt;/strong&gt;文章，可以作为 AI 入门的宝典，让初学者少走弯路，强烈建议&lt;strong&gt;收藏&lt;/strong&gt;本文！&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;&lt;a id="user-content-本站2018年的所有文章" class="anchor" aria-hidden="true" href="#本站2018年的所有文章"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;本站2018年的所有文章&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;机器学习资源&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247484000&amp;amp;idx=1&amp;amp;sn=92f198b840073e79e1a267d15a48a279&amp;amp;chksm=c0791f79f70e966fccd525bc2ecb11d328a12f566ccdc781132ffeeb41c484c1f7757db03911&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;良心推荐：机器学习入门资料汇总及学习建议（2018版）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483810&amp;amp;idx=1&amp;amp;sn=b35ff5aea7cc2a63c459c7f172263a2d&amp;amp;chksm=c0791cbbf70e95ad2e1cf7109cb50422bc07d0db6cbad502d11d3194aa92c608d5053f218cdd&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;黄海广博士的github镜像下载（机器学习及深度学习资源）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483678&amp;amp;idx=1&amp;amp;sn=da7de252a11a1097e50381a27cb2cfb1&amp;amp;chksm=c0791c07f70e951178054c7d4acc88becfccf953f83a2d616f8508d8bfa3d31d8cdec0c6979f&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;吴恩达老师的机器学习和深度学习课程笔记打印版&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483672&amp;amp;idx=1&amp;amp;sn=1845db207245efc9d33eeede5ea4b99e&amp;amp;chksm=c0791c01f70e9517cfb80b17d0e72836c5c573b33d9bcdc4ec57f02b6b73260d9c3e907a81e0&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;吴恩达老师机器学习教程中文笔记-在线版&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483784&amp;amp;idx=1&amp;amp;sn=6c158b9f13ebc612f0fb967323df16c4&amp;amp;chksm=c0791c91f70e95874606edc1a4a0fc38e5063d2634963c793d85c18e5d396be059176bd8d0d6&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Coursera机器学习课程代码作业-Python版本&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483694&amp;amp;idx=1&amp;amp;sn=f2d7c0be70d0fd17ee6a685cba6f399d&amp;amp;chksm=c0791c37f70e9521daf50bbee06f925505b61ec963397aba08af87925081f019f33ca27ffe5e&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Deeplearning.ai深度学习课程笔记-在线版&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483772&amp;amp;idx=1&amp;amp;sn=7046f9f8d5ae0329c6ab25d1fd8510d3&amp;amp;chksm=c0791c65f70e95734cfb3405658049209036c7097cbb17bc62816523acdc4c2ccca43d1bafdd&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;首发：深度学习测试题中英对照版&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483911&amp;amp;idx=1&amp;amp;sn=0aa891449692d85382a9b2b5016728bb&amp;amp;chksm=c0791f1ef70e960822c7b67b4216f6c7dc55b2c0f3f75ec7527523daea9ad25b3f86b94d5bec&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;机器学习必备宝典-《统计学习方法》的python代码实现、电子书及课件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483778&amp;amp;idx=1&amp;amp;sn=f1fe52a5451eef4e4c6d8463d01621ef&amp;amp;chksm=c0791c9bf70e958d4c57d0f9b2df37ae9cdbed304df030a27161a0ad7f9872926f217e6032d3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;斯坦福大学机器学习课程资料-吴恩达老师主讲（2008版）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483815&amp;amp;idx=1&amp;amp;sn=c220c09741e942b6d402f1090a2d72da&amp;amp;chksm=c0791cbef70e95a88745a8df9b3f2f0e2fe93591a21a3f4c331a920d74cdc6bf564ab33ff8df&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;机器学习训练秘籍完整中文版下载（吴恩达老师新作）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483804&amp;amp;idx=1&amp;amp;sn=9e862f6d127d70c2619e362c499e15b1&amp;amp;chksm=c0791c85f70e9593cd6106679feaac4b1eace9f717b788f9fbbae05c1b198308c45342ea6992&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;首发：深度学习入门宝典-《python深度学习》原文代码中文注释版及电子书&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483961&amp;amp;idx=1&amp;amp;sn=7fa7e3e8a1cd4abf3e3357b2f6448118&amp;amp;chksm=c0791f20f70e9636821676c4302a1113016e547632c8e3872bcf815b41de95a7a5b25f3c5f62&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;强烈推荐的TensorFlow、Pytorch和Keras的样例资源（深度学习初学者必须收藏）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483707&amp;amp;idx=1&amp;amp;sn=2f28175ecea445129a5e62441aeebd37&amp;amp;chksm=c0791c22f70e95340f61a978147314dd02bf8ab1bd9c49f3b86f928e371dac0ead6eda64116a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;机器学习小抄-（像背托福单词一样理解机器学习）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483860&amp;amp;idx=1&amp;amp;sn=514c1c053e31c4ced3bffe75e02f4b05&amp;amp;chksm=c0791ccdf70e95dba8c32d3b12836359159a2045019e8d5fb45ca578a9846f4601439b42bba3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;深度学习初学者的另一份小抄-《一天学懂深度学习（李宏毅）》（中文标注）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483752&amp;amp;idx=1&amp;amp;sn=779b10f781fd7699040d7fcd5889b998&amp;amp;chksm=c0791c71f70e9567c91c9459641bff333c490a3326e0549fbdc58131fcc9fa5245f8785a54d9&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;一些NLP的入门资料参考&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483930&amp;amp;idx=1&amp;amp;sn=31db561b207aed2b488ddb719ec7513f&amp;amp;chksm=c0791f03f70e9615586cf6be32352d0096da71563e87b20e3b115b206c1804d37bd3703fa5fe&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;革命性提升-宇宙最强的NLP预训练BERT模型（附官方代码）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483877&amp;amp;idx=1&amp;amp;sn=ca49142a7bded5c01ce39e25a004b5bd&amp;amp;chksm=c0791cfcf70e95eab42f6565f487c854c803cb072e225e9a30ebf25910ccef7b61ac794990b3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;50个最佳机器学习公共数据集&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;机器学习大师之作&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483886&amp;amp;idx=1&amp;amp;sn=e3a0c27f24446edb67b877d25007aec6&amp;amp;chksm=c0791cf7f70e95e1c601dc184bb681a7150c61fe5c4173e5abee72b1b3d9be71b5774b3d6a1a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;首发：徐亦达老师的机器学习课件及下载（中文目录）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483789&amp;amp;idx=1&amp;amp;sn=c6cebaaede9d87fc2ea2b38532f89a7b&amp;amp;chksm=c0791c94f70e9582ff738a80d0138fbb7644dfa2e23f8ef83b9f09da92d4bc31f44773befbee&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;机器学习的宝典-华校专老师的笔记&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;开源案例和方案&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483984&amp;amp;idx=1&amp;amp;sn=0fc0797e69ef856105bf747a43b4fa1e&amp;amp;chksm=c0791f49f70e965f218747c9ff986f3b702df2d5c4b7be80ab267ed9a4a55303c25fb001a83f&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;首发：台大林轩田《机器学习基石》系列课程教材的习题解答和实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483919&amp;amp;idx=1&amp;amp;sn=5fae97fbf1f94a8dec026f08abf0e9c5&amp;amp;chksm=c0791f16f70e9600a2bd47cade5117ad4a64088fca6fc45c51cd0ef6a41f7652650261f058d9&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;CTR预估系列：DeepCTR 一个基于深度学习的CTR模型包&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483956&amp;amp;idx=1&amp;amp;sn=5074fcdc8d63a6f2e9d89884d3f369ee&amp;amp;chksm=c0791f2df70e963bbde6058789f6d64c428c07c1f228b96b0056751d08e1b4cd5c6c752021e2&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;开源-BDCI2018面向电信行业存量用户的智能套餐个性化匹配模型Top1解决方案和代码&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483986&amp;amp;idx=1&amp;amp;sn=0c2c9e185c8a7afba37a212d2af947d5&amp;amp;chksm=c0791f4bf70e965da27dff285473d5b72dc9c58674da3261114a98c174f5fd480f85c4a7b3cc&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;开源-BDCI2018供应链需求预测模型第一名解决方案和代码&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483767&amp;amp;idx=1&amp;amp;sn=004de7eff7b8c0621ec25a635bec4b17&amp;amp;chksm=c0791c6ef70e95784174194f028477e1ff9e67b74a1a44a5443c5a659750e0a1610969d6d420&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;海洋大数据应用思考（附资料下载）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;机器学习论文&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483820&amp;amp;idx=1&amp;amp;sn=90fcd5fe6262e5a0e22212480e82ed9d&amp;amp;chksm=c0791cb5f70e95a372bc8bf0bfa382bed6a2dd1c0dab036ff4fae2668dccf660f62b2ec3fd07&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;新论文推荐：Auto-Keras:自动搜索深度学习模型的网络架构和超参数&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483746&amp;amp;idx=1&amp;amp;sn=e26b8d4a573f87d28ddef4075d7cbe43&amp;amp;chksm=c0791c7bf70e956d8a3918f5441c85c4228f133b65ab57a1ca05a4a1050c760364e284eec89a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;机器学习新论文推荐-（成对关系约束的非负矩阵分解）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;硬件和环境配置&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483901&amp;amp;idx=1&amp;amp;sn=f02bd7866ad172ef0c9669851dffde2a&amp;amp;chksm=c0791ce4f70e95f2343047e62d513c0106eedebc09cc25d1c45598ede21da8655a974c6a69c5&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Ubuntu 18.04深度学习环境配置（CUDA9.0+CUDNN7.4+TensorFlow1.8）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483665&amp;amp;idx=1&amp;amp;sn=331d52e5b52fd6eb2ba58c16a0fe3458&amp;amp;chksm=c0791c08f70e951e6c47254389112443e9d50ce919a7da25670a636756b090e500bf81580f1c&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;深度学习主机环境配置: Win10+Nvidia GTX1080i+CUDA8.0+CUDDN6 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Python基础&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483690&amp;amp;idx=1&amp;amp;sn=701cc75092e7213b6a9b04b57b5e15f3&amp;amp;chksm=c0791c33f70e9525a1f48179802f17d50fc4deab5333cb8b142df20e15b6a117df353c168a45&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;学习python入门的个人建议及资料&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483926&amp;amp;idx=1&amp;amp;sn=c19ee22819f98022e01da9343ad4cb85&amp;amp;chksm=c0791f0ff70e9619fd5a02a7cea9ae75bda478eedfcf2accc8ed2853a09b325c331bebfeb8ec&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;两天入门Python基础（附代码实现）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247484020&amp;amp;idx=1&amp;amp;sn=c281956f8414f38c48cc8b358f9dcc26&amp;amp;chksm=c0791f6df70e967b33e4f828031dc3f070ca7b8ae855692245cb8f41480686122d56db4600a2&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;学完可以解决90%以上的数据分析问题-利用python进行数据分析第二版（代码和中文笔记）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483988&amp;amp;idx=1&amp;amp;sn=0cb80ff3f91f1bf43b14c968ae709576&amp;amp;chksm=c0791f4df70e965b806993b0fe1ead8dc65fa23a010341d0b2f2c5792a66233975895fc43e9e&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;python绘图工具基础-matplotlib学习之基本使用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247484006&amp;amp;idx=1&amp;amp;sn=1d0b49c0200e901915a99d29f0dadc79&amp;amp;chksm=c0791f7ff70e966929ed3a9b1358beb3b31a1106084f4332176476eafebf3a407fff2150d5b3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;适合初学者快速入门的Numpy实战全集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247484014&amp;amp;idx=1&amp;amp;sn=25a415e5992f9f20c3e4e03dc1678b53&amp;amp;chksm=c0791f77f70e9661dd63cbf156de58fdc906e96f2a02dcef9bed7c35ab8754d9b255fab99aa1&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;python进阶之多进程 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;科研入门&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483685&amp;amp;idx=1&amp;amp;sn=1cc418d56344a222a0b6c9a56bdc5026&amp;amp;chksm=c0791c3cf70e952ada01da3a790baa6325c2656a554566716ad96b83c7d1868770514aca8409&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;机器学习的数学基础&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483979&amp;amp;idx=1&amp;amp;sn=9accf54de60fa6fe8f01cbd22e4df1a8&amp;amp;chksm=c0791f52f70e9644157b1c7a2ac0e3a0ba3e785ce45ff84ca22dbab50f7f0e542d7e6eb24b4f&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;吐血推荐收藏的学位论文排版教程（完整版）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483673&amp;amp;idx=1&amp;amp;sn=013a1171e4c44ce19ffe0ffb743b45a8&amp;amp;chksm=c0791c00f70e9516ca6835acdfefaf539d3e121890354c6aba45fb6802fa8709f3a41cb856a7&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;科研工作者的神器-zotero论文管理工具&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483829&amp;amp;idx=1&amp;amp;sn=75e97f26a4c9112c8efa932f16a63c1a&amp;amp;chksm=c0791cacf70e95ba585cc7bc302107eb5e5a733a58fe927d7016b590e351300306e78513c60b&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;如何做视频教程笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483992&amp;amp;idx=1&amp;amp;sn=06c1765f0eb06fd28888b3625c4ccff1&amp;amp;chksm=c0791f41f70e96576c11aa7c301096f5788931ccb4c6adf532d40e6a5de14ef3024f629f4824&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;给初学者推荐一个摆脱变量命名纠结的神器&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483760&amp;amp;idx=1&amp;amp;sn=60acdd5afac45fc6d17f5c714389079d&amp;amp;chksm=c0791c69f70e957fbf51c1d213b66817e05b9f5edf9ce128131b4697ceb122798d1bed7eed98&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;SQL语法如何入门？（附资料下载）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;项目合作&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483996&amp;amp;idx=1&amp;amp;sn=c0d7eb311071ef1eba98d89e274a35b6&amp;amp;chksm=c0791f45f70e96533089471e6732450739eaa3c07d07e90290652636778eea17e2eac2fa8916&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;公众号合作指南--与本站互相添加长期可转载账号&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483924&amp;amp;idx=1&amp;amp;sn=751c23682abc116ec4c2401e942f4d4d&amp;amp;chksm=c0791f0df70e961bb602b004e70b5c3f780ca56fce49490d6e53cfdbbc374ed1c21c73bcf1a2&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;赠人玫瑰,手有余香-期待协作更新机器学习的公益项目 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;过时文章&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;过时资料指的是新的文章已经涵盖了旧文章内容，不需要再看了。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483872&amp;amp;idx=1&amp;amp;sn=a8d462ba6bbe582fd35d6a1240c15f86&amp;amp;chksm=c0791cf9f70e95ef60751437a698b0bee4188405bc9bedebea34611a96f7207c10a9b7309bfa&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;机器学习简易入门-附推荐学习资料&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483792&amp;amp;idx=1&amp;amp;sn=5fe8d315183102be6f4ad92695d0f475&amp;amp;chksm=c0791c89f70e959fcbeda0ad8290093c8edc70b4fcb310073131bab1d01506795204726b7f07&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;机器学习初学者公众号下载资源汇总（一）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483914&amp;amp;idx=1&amp;amp;sn=cecee99473f6d7d33565389c6de4ed16&amp;amp;chksm=c0791f13f70e9605b69e84ee7e1a1a30ff3b4e78e19b71766831e4fa438d2422fed270b15685&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;深度学习者的入门福利-Keras深度学习笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483701&amp;amp;idx=1&amp;amp;sn=96ac60cf968284a7ae75b733a52df8bd&amp;amp;chksm=c0791c2cf70e953a45690656f2bd68c25287b2ba0a0c31db4debde5a38808c68ad5d82403e81&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;9月国内大数据赛事资讯-奖池1500万 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;杂谈&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483699&amp;amp;idx=1&amp;amp;sn=1518fb758a87a89fdf4614952baf4069&amp;amp;chksm=c0791c2af70e953c0cb2289ccf672b1f2968273ce1b01b41a8a874853668681c0381e629db33&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;你不是一个人在战斗！&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483740&amp;amp;idx=1&amp;amp;sn=e5cc3739911f4feb4c9bffed09de209b&amp;amp;chksm=c0791c45f70e9553b2eb33459ecc116327018013a288e0de5b33c39052f2103390ea2697f2ce&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;与机器学习相关的数学家，你认识几个？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483824&amp;amp;idx=1&amp;amp;sn=36f5cdfe9b3830ccb1566d9a4877ffa7&amp;amp;chksm=c0791ca9f70e95bfa5f49d6e411935766a8c1b17a0d831a41f30115a30bbbde485eeb2cf0c95&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;赚的钱需要有命来花-高薪的互联网从业人员更需要注意身体健康&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fengdu78</author><guid isPermaLink="false">https://github.com/fengdu78/machine_learning_beginner</guid><pubDate>Sun, 09 Feb 2020 00:11:00 GMT</pubDate></item><item><title>bangoc123/learn-machine-learning-in-two-months #12 in Jupyter Notebook, Today</title><link>https://github.com/bangoc123/learn-machine-learning-in-two-months</link><description>&lt;p&gt;&lt;i&gt;Những kiến thức cần thiết để học tốt Machine Learning trong vòng 2 tháng. Essential Knowledge for learning Machine Learning in two months.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="MD" data-path="README.MD"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-lộ-trình-học-machine-learning-deep-learning-cho-người-mới-bắt-đầu" class="anchor" aria-hidden="true" href="#lộ-trình-học-machine-learning-deep-learning-cho-người-mới-bắt-đầu"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lộ trình học Machine Learning, Deep Learning cho người mới bắt đầu&lt;/h2&gt;
&lt;p&gt;Tôi đã từng học Machine Learning trong vòng 2 tháng và tôi tin bạn cũng có thể làm được.&lt;/p&gt;
&lt;p&gt;Lộ trình sẽ giúp bạn nắm chắc công nghệ này từ cơ bản đến nâng cao, xây dựng Machine Learning model từ python thuần cho đến các thư viện cao cấp như TensorFlow hay Keras. Đi sâu phân tích bản chất vấn đề là giá trị cốt lõi của khóa học này.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;P/S:&lt;/strong&gt; Hãy để lại &lt;strong&gt;1 star&lt;/strong&gt; để team có động lực xuất bản các phần tiếp theo và cũng đừng quên chia sẻ tới bạn bè của bạn.&lt;/p&gt;
&lt;p&gt;Tôi là một trong các lecturer của lớp VietAI Hanoi khoá 3 và khoá 4. Hiện tại tôi đã vào Sài Gòn nên không tham gia tiếp để giảng dạy nhưng vẫn đóng vai trò Advisor cho lớp khoá 5.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/8073cb447e2f2da7f44ab32e293189b7b4c5fbc0/68747470733a2f2f6c68332e676f6f676c6575736572636f6e74656e742e636f6d2f2d33415942613769544e54616c576d506b73555a306368356c7648747a4475484d57423641776c476769617059706f61514d575a416d513355426c4d4c504d48715132674c32416b476a433949645341704a3165624c586e3066344f684e782d6b697962636d7a674863614c57545a4c5241355258453353726a52464d776b74316a345551344b31304a5442677052675845555944344b513379536d32456f77774e70584c3841562d6948454251563174684a78494178547233467434764e6c456b6757583542644a556371684d6b665848476f77544e69555454726e3230423757686a55386335535a5576535453716d763543325a79306f52424c6f47527145306b555f7a494c5a71327958655042516b504c2d704c71307459376e75376777617a454c696644444a3169704f4d477276737857457435674649474d4f4a47323537764d6f32667147657a6d4349765337666c483465434b47546d6866556f644a377464717a35553863556c326e5f7a3473585f78765064645f78745f5448766b534a6b5a36714f5a55784d32786d46387065736d67496161414b4c5755736e74764d695179542d4d4c4d6468623744764d4361307a366f4c78664c333761663548746b5a395866494f624b38506d4e426b37545879455573594a4e316d643752644f5241495050557541337673712d72587834454c6f726d4d37535f665442685a424e7331575a3233354775787165455066574e73414d654c544132304b65626b64596d2d5945774e305356704a3657394f47395f3846635f6e35762d78376278576168696b58744a59636454786341574441437647787a552d71564c6b4c3351657533676e377041306e51706d4b66485547656f795f7643474e436f326c6a597039435264796b586f64683935704f6431316e714c485662626172486234544557625a4f53316246347159716a4a654e596176325156476e75784b594d39333369475249713434767a6b59783761755449534437475838316a52307868774f5469754f5a43564d4561304274433d77313136352d683838312d6e6f"&gt;&lt;img src="https://camo.githubusercontent.com/8073cb447e2f2da7f44ab32e293189b7b4c5fbc0/68747470733a2f2f6c68332e676f6f676c6575736572636f6e74656e742e636f6d2f2d33415942613769544e54616c576d506b73555a306368356c7648747a4475484d57423641776c476769617059706f61514d575a416d513355426c4d4c504d48715132674c32416b476a433949645341704a3165624c586e3066344f684e782d6b697962636d7a674863614c57545a4c5241355258453353726a52464d776b74316a345551344b31304a5442677052675845555944344b513379536d32456f77774e70584c3841562d6948454251563174684a78494178547233467434764e6c456b6757583542644a556371684d6b665848476f77544e69555454726e3230423757686a55386335535a5576535453716d763543325a79306f52424c6f47527145306b555f7a494c5a71327958655042516b504c2d704c71307459376e75376777617a454c696644444a3169704f4d477276737857457435674649474d4f4a47323537764d6f32667147657a6d4349765337666c483465434b47546d6866556f644a377464717a35553863556c326e5f7a3473585f78765064645f78745f5448766b534a6b5a36714f5a55784d32786d46387065736d67496161414b4c5755736e74764d695179542d4d4c4d6468623744764d4361307a366f4c78664c333761663548746b5a395866494f624b38506d4e426b37545879455573594a4e316d643752644f5241495050557541337673712d72587834454c6f726d4d37535f665442685a424e7331575a3233354775787165455066574e73414d654c544132304b65626b64596d2d5945774e305356704a3657394f47395f3846635f6e35762d78376278576168696b58744a59636454786341574441437647787a552d71564c6b4c3351657533676e377041306e51706d4b66485547656f795f7643474e436f326c6a597039435264796b586f64683935704f6431316e714c485662626172486234544557625a4f53316246347159716a4a654e596176325156476e75784b594d39333369475249713434767a6b59783761755449534437475838316a52307868774f5469754f5a43564d4561304274433d77313136352d683838312d6e6f" width="500" data-canonical-src="https://lh3.googleusercontent.com/-3AYBa7iTNTalWmPksUZ0ch5lvHtzDuHMWB6AwlGgiapYpoaQMWZAmQ3UBlMLPMHqQ2gL2AkGjC9IdSApJ1ebLXn0f4OhNx-kiybcmzgHcaLWTZLRA5RXE3SrjRFMwkt1j4UQ4K10JTBgpRgXEUYD4KQ3ySm2EowwNpXL8AV-iHEBQV1thJxIAxTr3Ft4vNlEkgWX5BdJUcqhMkfXHGowTNiUTTrn20B7WhjU8c5SZUvSTSqmv5C2Zy0oRBLoGRqE0kU_zILZq2yXePBQkPL-pLq0tY7nu7gwazELifDDJ1ipOMGrvsxWEt5gFIGMOJG257vMo2fqGezmCIvS7flH4eCKGTmhfUodJ7tdqz5U8cUl2n_z4sX_xvPdd_xt_THvkSJkZ6qOZUxM2xmF8pesmgIaaAKLWUsntvMiQyT-MLMdhb7DvMCa0z6oLxfL37af5HtkZ9XfIObK8PmNBk7TXyEUsYJN1md7RdORAIPPUuA3vsq-rXx4ELormM7S_fTBhZBNs1WZ235GuxqeEPfWNsAMeLTA20KebkdYm-YEwN0SVpJ6W9OG9_8Fc_n5v-x7bxWahikXtJYcdTxcAWDACvGxzU-qVLkL3Qeu3gn7pA0nQpmKfHUGeoy_vCGNCo2ljYp9CRdykXodh95pOd11nqLHVbbarHb4TEWbZOS1bF4qYqjJeNYav2QVGnuxKYM933iGRIq44vzkYx7auTISD7GX81jR0xhwOTiuOZCVMEa0BtC=w1165-h881-no" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ngày 10/12/2019, sau 2 vòng phỏng vấn, Google chính thức công nhận tôi là Google Developer Expert in Machine Learning. Tôi nghĩ tôi là ML GDE đầu tiên tại Việt Nam.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./images/gde.png"&gt;&lt;img src="./images/gde.png" width="500" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tìm tôi &lt;a href="https://developers.google.com/community/experts/directory" rel="nofollow"&gt;ở đây&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Bài giảng tôi thích dạy nhất ở VietAI chính là mạng Neural Network.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./images/class.jpg"&gt;&lt;img src="./images/class.jpg" width="500" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Giới thiệu về thành tựu và mục tiêu của VietAI &lt;a href="https://docs.google.com/presentation/d/1A_oDWZyC6NhYPeHNrWJbESxSPUT7f0Gg-PLfXDtVKus/edit?usp=sharing" rel="nofollow"&gt;tại đây&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-mục-lục" class="anchor" aria-hidden="true" href="#mục-lục"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Mục lục&lt;/h3&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/math"&gt;1. Kiến thức toán học cần thiết&lt;/a&gt; (Hoàn tất)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/python-tutorials"&gt;2. Kỹ năng lập trình Python&lt;/a&gt; (Hoàn tất)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/numpy"&gt;3. Thư viện Numpy và TensorFlow&lt;/a&gt; (Hoàn tất)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/blob/master/models/linear-regression/"&gt;4. Bài toán hồi quy (Regression)&lt;/a&gt; (Hoàn tất)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/blob/master/models/logistic-regression"&gt;5. Bài toán phân loại (Classification)&lt;/a&gt; (Hoàn tất)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/blob/master/models/random-forests"&gt;6. Xây dựng mô hình Decision Trees và Random Forests &lt;/a&gt; (Chưa Hoàn tất)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/models/nn"&gt;7. Xây dựng mạng Neural Network&lt;/a&gt; (Đang tiến hành)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/models/cnn"&gt;8. Xây dựng mạng Convolutional Neural Network (CNN)&lt;/a&gt; (Chưa Hoàn tất)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/models/rnn"&gt;9. Xây dựng mạng Recurrent Neural Network (RNN)&lt;/a&gt; (Chưa Hoàn tất)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/gan"&gt;10. Mô hình sinh GAN và CycleGAN&lt;/a&gt; (Đang tiến hành)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/deployment/distributed-tensorflow"&gt;11. Triển khai (Deploy) Machine Learning Model trên Production&lt;/a&gt; (Đang tiến hành)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/deployment/tensorflow-browser"&gt;12. Machine Learning trên trình duyệt và TensorFlowJS&lt;/a&gt; (Hoàn tất)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/tf2.0"&gt;13. Cập nhật mới nhất&lt;/a&gt; (Đang tiến hành)
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/tf2.0"&gt;TensorFlow 2.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/articles/GradientPaperSpace.MD"&gt;Trải nghiệm PaperSpace Gradient Community&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/algorithms"&gt;14. Ôn luyện thuật toán mỗi ngày&lt;/a&gt; (Đang tiến hành)
&lt;ul&gt;
&lt;li&gt;&lt;a href="./algorithms/graph/backtracking/backtracking.MD"&gt;Backtracking Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>bangoc123</author><guid isPermaLink="false">https://github.com/bangoc123/learn-machine-learning-in-two-months</guid><pubDate>Sun, 09 Feb 2020 00:12:00 GMT</pubDate></item><item><title>guipsamora/pandas_exercises #13 in Jupyter Notebook, Today</title><link>https://github.com/guipsamora/pandas_exercises</link><description>&lt;p&gt;&lt;i&gt;Practice your pandas skills!&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pandas-exercises" class="anchor" aria-hidden="true" href="#pandas-exercises"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pandas Exercises&lt;/h1&gt;
&lt;p&gt;Fed up with a ton of tutorials but no easy way to find exercises I decided to create a repo just with exercises to practice pandas.
Don't get me wrong, tutorials are great resources, but to learn is to do. So unless you practice you won't learn.&lt;/p&gt;
&lt;p&gt;There will be three different types of files:&lt;br&gt;
      1. Exercise instructions&lt;br&gt;
      2. Solutions without code&lt;br&gt;
      3. Solutions with code and comments&lt;/p&gt;
&lt;p&gt;My suggestion is that you learn a topic in a tutorial, video or documentation and then do the first exercises.
Learn one more topic and do more exercises. If you are stuck, don't go directly to the solution with code files. Check the solutions only and try to get the correct answer.&lt;/p&gt;
&lt;p&gt;Suggestions and collaborations are more than welcome.&lt;g-emoji class="g-emoji" alias="slightly_smiling_face" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f642.png"&gt;🙂&lt;/g-emoji&gt; Please open an issue or make a PR indicating the exercise and your problem/solution.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-lessons" class="anchor" aria-hidden="true" href="#lessons"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lessons&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="#getting-and-knowing"&gt;Getting and knowing&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#merge"&gt;Merge&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#time-series"&gt;Time Series&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="#filtering-and-sorting"&gt;Filtering and Sorting&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#stats"&gt;Stats&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#deleting"&gt;Deleting&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="#grouping"&gt;Grouping&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#visualization"&gt;Visualization&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Indexing&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="#apply"&gt;Apply&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#creating-series-and-dataframes"&gt;Creating Series and DataFrames&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Exporting&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-getting-and-knowing" class="anchor" aria-hidden="true" href="#getting-and-knowing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data"&gt;Getting and knowing&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data/Chipotle"&gt;Chipotle&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data/Occupation"&gt;Occupation&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data/World%20Food%20Facts"&gt;World Food Facts&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-filtering-and-sorting" class="anchor" aria-hidden="true" href="#filtering-and-sorting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting"&gt;Filtering and Sorting&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting/Chipotle"&gt;Chipotle&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting/Euro12"&gt;Euro12&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting/Fictional%20Army"&gt;Fictional Army&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-grouping" class="anchor" aria-hidden="true" href="#grouping"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping"&gt;Grouping&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping/Alcohol_Consumption"&gt;Alcohol Consumption&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping/Occupation"&gt;Occupation&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping/Regiment"&gt;Regiment&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-apply" class="anchor" aria-hidden="true" href="#apply"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/04_Apply"&gt;Apply&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/04_Apply/Students_Alcohol_Consumption"&gt;Students Alcohol Consumption&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/04_Apply/US_Crime_Rates"&gt;US_Crime_Rates&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-merge" class="anchor" aria-hidden="true" href="#merge"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge"&gt;Merge&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge/Auto_MPG"&gt;Auto_MPG&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge/Fictitous%20Names"&gt;Fictitious Names&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge/Housing%20Market"&gt;House Market&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-stats" class="anchor" aria-hidden="true" href="#stats"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/06_Stats"&gt;Stats&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/06_Stats/US_Baby_Names"&gt;US_Baby_Names&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/06_Stats/Wind_Stats"&gt;Wind_Stats&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-visualization" class="anchor" aria-hidden="true" href="#visualization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization"&gt;Visualization&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Chipotle"&gt;Chipotle&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Titanic_Desaster"&gt;Titanic Disaster&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Scores"&gt;Scores&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Online_Retail"&gt;Online Retail&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Tips"&gt;Tips&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-creating-series-and-dataframes" class="anchor" aria-hidden="true" href="#creating-series-and-dataframes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/08_Creating_Series_and_DataFrames"&gt;Creating Series and DataFrames&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/08_Creating_Series_and_DataFrames/Pokemon"&gt;Pokemon&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-time-series" class="anchor" aria-hidden="true" href="#time-series"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series"&gt;Time Series&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series/Apple_Stock"&gt;Apple_Stock&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series/Getting_Financial_Data"&gt;Getting_Financial_Data&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series/Getting_Financial_Data"&gt;Investor_Flow_of_Funds_US&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-deleting" class="anchor" aria-hidden="true" href="#deleting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/10_Deleting"&gt;Deleting&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/10_Deleting/Iris"&gt;Iris&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/10_Deleting/Wine"&gt;Wine&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-video-solutions" class="anchor" aria-hidden="true" href="#video-solutions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Video Solutions&lt;/h1&gt;
&lt;p&gt;Video tutorials of data scientists working through the above exercises:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=pu3IpU937xs&amp;amp;list=PLgJhDSE2ZLxaY_DigHeiIDC1cD09rXgJv" rel="nofollow"&gt;Data Talks - Pandas Learning By Doing&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>guipsamora</author><guid isPermaLink="false">https://github.com/guipsamora/pandas_exercises</guid><pubDate>Sun, 09 Feb 2020 00:13:00 GMT</pubDate></item><item><title>qiaoxu123/Self-Driving-Cars #14 in Jupyter Notebook, Today</title><link>https://github.com/qiaoxu123/Self-Driving-Cars</link><description>&lt;p&gt;&lt;i&gt;Coursera Open Courses from  University of Toronto&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-thanks" class="anchor" aria-hidden="true" href="#thanks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Thanks&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://www.coursera.org/specializations/self-driving-cars" rel="nofollow"&gt;&lt;strong&gt;Coursera  Self-Driving Cars&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanks to the teachers in this courses very much !!!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I have to say that this courses surprise me a lot , as a postgraduate student aimed at working on automotive motion planning ,it is so hard to find so completed and excited sources, especially in China. So, i think it is beneficial and essential for everyone who aims at working or doing researching work on automotive. and make the decision to take the note and share the all sources of the courses.&lt;/p&gt;
&lt;p&gt;This repository includes all the videos, subtitles and PDFs of this courses. You can download and watch it. Especially, i make a rough notebook based on the subtitles for better review. and i will step by step to complete it. Everyone can read and submit issue , i will try to replay it. Finally, hope everyone can enjoy it !!!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://qiaoxu123.github.io/Self-Driving-Cars/#/" rel="nofollow"&gt;Notebook(Incomplete)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Class links:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/learn/intro-self-driving-cars" rel="nofollow"&gt;1. Introduction to Self-Driving Cars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/learn/state-estimation-localization-self-driving-cars" rel="nofollow"&gt;2. State Estimation and Localization for Self-Driving Cars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/learn/visual-perception-self-driving-cars" rel="nofollow"&gt;3. Visual Perception for Self-Driving Cars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/learn/motion-planning-self-driving-cars" rel="nofollow"&gt;4. Motion Planning for Self-Driving Cars&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-1-overview" class="anchor" aria-hidden="true" href="#1-overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Overview&lt;/h2&gt;
&lt;p&gt;Be at the forefront of the autonomous driving industry. With market researchers predicting a $42-billion market and more than 20 million self-driving cars on the road by 2025, the next big job boom is right around the corner.&lt;/p&gt;
&lt;p&gt;This Specialization gives you a comprehensive understanding of state-of-the-art engineering practices used in the self-driving car industry. You'll get to interact with real data sets from an autonomous vehicle (AV)―all through hands-on projects using the open source simulator CARLA.&lt;/p&gt;
&lt;p&gt;Throughout your courses, you’ll hear from industry experts who work at companies like Oxbotica and Zoox as they share insights about autonomous technology and how that is powering job growth within the field.&lt;/p&gt;
&lt;p&gt;You’ll learn from a highly realistic driving environment that features 3D pedestrian modelling and environmental conditions. When you complete the Specialization successfully, you’ll be able to build your own self-driving software stack and be ready to apply for jobs in the autonomous vehicle industry.&lt;/p&gt;
&lt;p&gt;It is recommended that you have some background in linear algebra, probability, statistics, calculus, physics, control theory, and Python programming. You will need these specifications in order to effectively run the CARLA simulator: Windows 7 64-bit (or later) or Ubuntu 16.04 (or later), Quad-core Intel or AMD processor (2.5 GHz or faster), NVIDIA GeForce 470 GTX or AMD Radeon 6870 HD series card or higher, 8 GB RAM, and OpenGL 3 or greater (for Linux computers).&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-2-learn-objects" class="anchor" aria-hidden="true" href="#2-learn-objects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Learn Objects&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Understand the detailed architecture and components of a self-driving car software stack&lt;/li&gt;
&lt;li&gt;Implement methods for static and dynamic object detection, localization and mapping, behaviour and maneuver planning, and vehicle control&lt;/li&gt;
&lt;li&gt;Use realistic vehicle physics, complete sensor suite: camera, LIDAR, GPS/INS, wheel odometry, depth map, semantic segmentation, object bounding boxes&lt;/li&gt;
&lt;li&gt;Demonstrate skills in CARLA and build programs with Python&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>qiaoxu123</author><guid isPermaLink="false">https://github.com/qiaoxu123/Self-Driving-Cars</guid><pubDate>Sun, 09 Feb 2020 00:14:00 GMT</pubDate></item><item><title>Mikoto10032/DeepLearning #15 in Jupyter Notebook, Today</title><link>https://github.com/Mikoto10032/DeepLearning</link><description>&lt;p&gt;&lt;i&gt;深度学习入门教程&amp;&amp;优秀文章&amp;&amp;Deep Learning Tutorial&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deeplearning-tutorial" class="anchor" aria-hidden="true" href="#deeplearning-tutorial"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DeepLearning Tutorial&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-一-入门资料" class="anchor" aria-hidden="true" href="#一-入门资料"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;一. 入门资料&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/64052743" rel="nofollow"&gt;&lt;strong&gt;完备的 AI 学习路线，最详细的中英文资源整理&lt;/strong&gt;&lt;/a&gt; &lt;g-emoji class="g-emoji" alias="star" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png"&gt;⭐️&lt;/g-emoji&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/apachecn/AiLearning"&gt;AiLearning: 机器学习 - MachineLearning - ML、深度学习 - DeepLearning - DL、自然语言处理 NL&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-数学基础" class="anchor" aria-hidden="true" href="#数学基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数学基础&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="notes/Images/MathematicalBasis.jpg"&gt;&lt;img src="notes/Images/MathematicalBasis.jpg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E7%9F%A9%E9%98%B5%E5%BE%AE%E7%A7%AF%E5%88%86" rel="nofollow"&gt;矩阵微积分&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fengdu78/Data-Science-Notes/tree/master/0.math/0.basic"&gt;机器学习的数学基础&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fengdu78/Data-Science-Notes/tree/master/0.math/1.CS229"&gt;CS229线性代数与概率论基础&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-机器学习基础" class="anchor" aria-hidden="true" href="#机器学习基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习基础&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-快速入门" class="anchor" aria-hidden="true" href="#快速入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;快速入门&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;推荐顺序由前到后&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.tensorinfinity.com/paper_18.html" rel="nofollow"&gt;机器学习算法地图&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%5BML-Coursera%5D%5B2014%5D%5BAndrew%20Ng%5D/%5B2014%5D%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%E5%AE%8C%E6%95%B4%E7%89%88v5.1.pdf"&gt;机器学习 吴恩达 Coursera个人笔记&lt;/a&gt;  &amp;amp;&amp;amp; &lt;a href="https://www.coursera.org/learn/machine-learning" rel="nofollow"&gt;视频（含官方笔记）&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://kivy-cn.github.io/Stanford-CS-229-CN/#/" rel="nofollow"&gt;CS229 课程讲义中文翻译&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%5BML-CS229%5D%5B2011%5D%5BAndrew%20NG%5D/%5B2011%5D%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E4%B8%AA%E4%BA%BA%E7%AC%94.pdf"&gt;机器学习 吴恩达 cs229个人笔记&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="http://cs229.stanford.edu/" rel="nofollow"&gt;官网（笔记）&lt;/a&gt;  &amp;amp;&amp;amp; &lt;a href="http://open.163.com/special/opencourse/machinelearning.html" rel="nofollow"&gt;视频（中文字幕）&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://themlbook.com/wiki/doku.php" rel="nofollow"&gt;百页机器学习&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-深入理解" class="anchor" aria-hidden="true" href="#深入理解"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;深入理解&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;推荐顺序由前到后&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/tree/master/books/%E6%9D%8E%E8%88%AA-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0"&gt;《统计学习方法》李航&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0PRML_Chinese_vision.pdf"&gt;《模式识别与机器学习》 Christopher Bishop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%91%A8%E5%BF%97%E5%8D%8E.pdf"&gt;《机器学习》 周志华&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%20%E4%B8%AD%E6%96%87%E5%8F%8C%E9%A1%B5%E7%89%88.pdf"&gt;《机器学习实战》 PelerHarrington&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s?__biz=MzAxMjcyNjE5MQ==&amp;amp;mid=2650488718&amp;amp;idx=1&amp;amp;sn=815a79d27d500f0fb8db1fe1fc6cfe48&amp;amp;chksm=83a2e54eb4d56c58a0989654f920d64ad2784ce52e4b2bc6883974257cf475c9983f05fb88c1&amp;amp;scene=0&amp;amp;xtrack=1&amp;amp;ascene=14&amp;amp;devicetype=android-28&amp;amp;version=27000339&amp;amp;nettype=WIFI&amp;amp;abtest_cookie=AwABAAoACwATAAQAI5ceAFaZHgDQmR4A3JkeAAAA&amp;amp;lang=zh_CN&amp;amp;pass_ticket=oEB1108Pes6HkdxEITmBjTb2Glju5%2BEGqHZKz50fMg0rgK4l9Fodlbe%2FDm96iX57&amp;amp;wx_header=1" rel="nofollow"&gt;机器学习与深度学习书单&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-深度学习基础" class="anchor" aria-hidden="true" href="#深度学习基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;深度学习基础&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-快速入门-1" class="anchor" aria-hidden="true" href="#快速入门-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;快速入门&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;推荐顺序由前到后&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dformoso/deeplearning-mindmap"&gt;深度学习思维导图&lt;/a&gt;	&amp;amp;&amp;amp; &lt;a href="http://www.tensorinfinity.com/paper_158.html" rel="nofollow"&gt;深度学习算法地图&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B.pdf"&gt;《斯坦福大学深度学习基础教程》 Andrew Ng（吴恩达）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ai-start.com/dl2017/" rel="nofollow"&gt;深度学习 吴恩达 个人笔记&lt;/a&gt;  &amp;amp;&amp;amp; &lt;a href="http://mooc.study.163.com/smartSpec/detail/1001319001.htm" rel="nofollow"&gt;视频&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://deeplearning.mit.edu/" rel="nofollow"&gt;MIT深度学习基础-2019视频课程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/index.html" rel="nofollow"&gt;台湾大学（NTU）李宏毅教授课程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/iamtrask/Grokking-Deep-Learning"&gt;图解深度学习_Grokking-Deep-Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0neural%20networks%20and%20deep-learning-%E4%B8%AD%E6%96%87_ALL.pdf"&gt;《神经网络与深度学习》 Michael Nielsen&lt;/a&gt;    &lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.toronto.edu/~tijmen/csc321/" rel="nofollow"&gt; CS321-Hinton&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://web.stanford.edu/class/cs230/" rel="nofollow"&gt; CS230: Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://rail.eecs.berkeley.edu/deeprlcourse/resources/" rel="nofollow"&gt; CS294-112&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-计算机视觉" class="anchor" aria-hidden="true" href="#计算机视觉"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;计算机视觉&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21930884" rel="nofollow"&gt;CS231 李飞飞 已授权个人翻译笔记&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="http://study.163.com/course/courseMain.htm?courseId=1003223001" rel="nofollow"&gt;视频&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/WNkzfvYtEO5zJoe_-yAPow" rel="nofollow"&gt;计算机视觉研究方向&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-自然语言处理" class="anchor" aria-hidden="true" href="#自然语言处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;自然语言处理&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://web.stanford.edu/class/cs224n/index.html" rel="nofollow"&gt;CS224n: Natural Language Processing with Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/FudanNLP/nlp-beginner"&gt;NLP上手教程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58874484" rel="nofollow"&gt;NLP入门推荐书目（2019版）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-深度强化学习" class="anchor" aria-hidden="true" href="#深度强化学习"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;深度强化学习&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://web.stanford.edu/class/cs234/index.html" rel="nofollow"&gt;CS234: Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-深入理解-1" class="anchor" aria-hidden="true" href="#深入理解-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;深入理解&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.Yoshua%20Bengio%2BIan%20GoodFellow.pdf"&gt;《深度学习》 Yoshua Bengio.Ian GoodFellow&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="star" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png"&gt;⭐️&lt;/g-emoji&gt;       &lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86.Jacob%20Eisenstein.pdf"&gt;《自然语言处理》Jacob Eisenstein&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/Reinforcement%20Learning.Sutton.pdf"&gt;《强化学习》&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="http://incompleteideas.net/book/RLbook2018trimmed.pdf" rel="nofollow"&gt;第二版&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://handong1587.github.io/categories.html#deep_learning-ref" rel="nofollow"&gt;hangdong的深度学习博客,论文推荐&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://course.fast.ai/" rel="nofollow"&gt;Practical Deep Learning for Coders, v3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/Tensorflow%20%E5%AE%9E%E6%88%98Google%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6.pdf"&gt;《Tensorflow实战Google深度学习框架》 郑泽宇 顾思宇&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-一些书单" class="anchor" aria-hidden="true" href="#一些书单"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;一些书单&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/63784033" rel="nofollow"&gt;2019年最新-深度学习、生成对抗、Pytorch优秀教材推荐&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-工程能力" class="anchor" aria-hidden="true" href="#工程能力"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;工程能力&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/df94968056561d8fcd1952cca7b3353c433309ec/68747470733a2f2f706963342e7a68696d672e636f6d2f76322d30303930313332373836383866353230633037306232373931303235356362315f722e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/df94968056561d8fcd1952cca7b3353c433309ec/68747470733a2f2f706963342e7a68696d672e636f6d2f76322d30303930313332373836383866353230633037306232373931303235356362315f722e6a7067" alt="" data-canonical-src="https://pic4.zhimg.com/v2-009013278688f520c070b27910255cb1_r.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/20588261/answer/798928056" rel="nofollow"&gt;如何系统地学习算法？&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://leetcode.com/" rel="nofollow"&gt;LeetCode&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/azl397985856/leetcode"&gt;leetcode题解&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/huaxz1986/cplusplus-_Implementation_Of_Introduction_to_Algorithms"&gt;《算法导论》中算法的C++实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E7%AF%87"&gt;机器学习算法实战&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6"&gt;深度学习框架&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/YMtnBAVDZepsMTO4h-VRtQ" rel="nofollow"&gt;如何成为一名算法工程师&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://mp.weixin.qq.com/s?__biz=MzAxMjcyNjE5MQ==&amp;amp;mid=2650488786&amp;amp;idx=1&amp;amp;sn=68b9536d0b0b3105ab8d79f8efcb0a4b&amp;amp;chksm=83a2e512b4d56c045c6ab0349108842e6a5b26e8f3e507ff5d19ee50e3bd63ef149a36d23eef&amp;amp;scene=0&amp;amp;xtrack=1&amp;amp;ascene=14&amp;amp;devicetype=android-28&amp;amp;version=27000437&amp;amp;nettype=WIFI&amp;amp;abtest_cookie=BAABAAoACwASABMABgAjlx4AVpkeANCZHgDcmR4A8ZkeAAOaHgAAAA%3D%3D&amp;amp;lang=zh_CN&amp;amp;pass_ticket=4yovfEr0v09yZCvvQ1NEy12qGIonnRpGi774X09Mh5EZD2oL%2BRz6FTtX9R5gALB1&amp;amp;wx_header=1" rel="nofollow"&gt;从小白到入门算法，我的经验分享给你～&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/54161673" rel="nofollow"&gt;我的研究生这三年&lt;/a&gt; &lt;g-emoji class="g-emoji" alias="star" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png"&gt;⭐️&lt;/g-emoji&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.huaxiaozhuan.com/" rel="nofollow"&gt;《AI算法工程师手册》&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/76827460" rel="nofollow"&gt;如何准备算法工程师面试，斩获一线互联网公司机器学习岗offer？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/HZ3Cd2jHuikyFN9ydvcMTw" rel="nofollow"&gt;【完结】深度学习CV算法工程师从入门到初级面试有多远，大概是25篇文章的距离&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/CyC2018/CS-Notes"&gt; 计算机相关技术面试必备&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/imhuay/Algorithm_for_Interview-Chinese"&gt;面试算法笔记-中文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DarLiner/Algorithm_Interview_Notes-Chinese"&gt;算法工程师面试&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ShanghaiTechAIClub/DLInterview"&gt;深度学习面试题目&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/scutan90/DeepLearning-500-questions"&gt;深度学习500问&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/amusi/AI-Job-Notes#Strategy"&gt;AI算法岗求职攻略&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Kaggle实战&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;常用算法：
&lt;ul&gt;
&lt;li&gt;Feature Engineering：continue variable &amp;amp;&amp;amp; categorical variable&lt;/li&gt;
&lt;li&gt;Classic machine learning algorithm：LR, KNN, SVM, Random Forest, GBDT(XGBoost&amp;amp;&amp;amp;LightGBM), Factorization Machine, Field-aware Factorization Machine, Neural Network&lt;/li&gt;
&lt;li&gt;Cross validation, model selection：grid search, random search, hyper-opt&lt;/li&gt;
&lt;li&gt;Ensemble learning&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apachecn/kaggle"&gt;Kaggle 项目实战（教程） = 文档 + 代码 + 视频&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29086448" rel="nofollow"&gt;Kaggle入门系列：（一）机器学习环境搭建&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/29417603" rel="nofollow"&gt;Kaggle入门系列：（二）Kaggle简介&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/29086614" rel="nofollow"&gt;Kaggle入门系列（三）Titanic初试身手&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61660061" rel="nofollow"&gt;从 0 到 1 走进 Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25742261" rel="nofollow"&gt;Kaggle 入门指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61657532" rel="nofollow"&gt;一个框架解决几乎所有机器学习问题&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/" rel="nofollow"&gt;Approaching (Almost) Any Machine Learning Problem | Abhishek Thakur&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27424282" rel="nofollow"&gt;分分钟带你杀入Kaggle Top 1%&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/48758045" rel="nofollow"&gt;如何达到Kaggle竞赛top 2%？这里有一篇特征探索经验帖&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27486736" rel="nofollow"&gt;如何在 Kaggle 首战中进入前 10%？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/weixin_33739541/article/details/87565983" rel="nofollow"&gt;大数据&amp;amp;机器学习相关竞赛推荐&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-二-神经网络模型概览" class="anchor" aria-hidden="true" href="#二-神经网络模型概览"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;二. 神经网络模型概览&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_35082030/article/details/73368962" rel="nofollow"&gt;1. 一文看懂25个神经网络模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29141828" rel="nofollow"&gt;2. DNN概述论文：详解前馈、卷积和循环神经网络技术&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://colah.github.io/" rel="nofollow"&gt;3. colah's blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://modelzoo.co/" rel="nofollow"&gt;4. Model Zoom&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29141828" rel="nofollow"&gt;5. DNN概述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59385110" rel="nofollow"&gt;6. 从基本原理到梯度下降，小白都能看懂的神经网络教程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60245227" rel="nofollow"&gt;GitHub上的机器学习/深度学习综述项目合集&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-cnn" class="anchor" aria-hidden="true" href="#cnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CNN&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-发展史" class="anchor" aria-hidden="true" href="#发展史"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;发展史&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35388569" rel="nofollow"&gt;1. 94页论文综述卷积神经网络：从基础技术到研究前景&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/31006686" rel="nofollow"&gt;2. 从LeNet-5到DenseNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/26652657" rel="nofollow"&gt;3. CNN图像分割简史：从R-CNN到Mask R-CNN（译）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32830206" rel="nofollow"&gt;4. 深度学习之目标检测的前世今生（Mask R-CNN）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32746221" rel="nofollow"&gt;5. 纵览轻量化卷积神经网络：SqueezeNet、MobileNet、ShuffleNet、Xception&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29434605" rel="nofollow"&gt;6. 深度学习目标检测模型全面综述：Faster R-CNN、R-FCN和SSD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36801104" rel="nofollow"&gt;7. 图像语义分割(Semantic segmentation) Survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36184131" rel="nofollow"&gt;7. 从RCNN到SSD，这应该是最全的一份目标检测算法盘点&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36801104" rel="nofollow"&gt;8. 图像语义分割(Semantic segmentation) Survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/37618829" rel="nofollow"&gt;9. 语义分割 发展综述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/PeaceInMind/article/details/78079263" rel="nofollow"&gt;深度学习分类网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cnblogs.com/xuanyuyt/p/11329998.html" rel="nofollow"&gt;深度学习笔记（十一）网络 Inception, Xception, MobileNet, ShuffeNet, ResNeXt, SqueezeNet, EfficientNet, MixConv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/68411179" rel="nofollow"&gt;CNN网络结构的发展&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34621135" rel="nofollow"&gt;卷积神经网络结构演变（form Hubel and Wiesel to SENet）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35221368" rel="nofollow"&gt;从VGG到NASNet，一文概览图像分类网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;From RCNN to YOLO&lt;/a&gt;：&lt;a href="https://zhuanlan.zhihu.com/p/35724768" rel="nofollow"&gt;上&lt;/a&gt;，&lt;a href="https://zhuanlan.zhihu.com/p/35731743" rel="nofollow"&gt;下&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/38709522" rel="nofollow"&gt;后 R-CNN时代， Faster R-CNN、SSD、YOLO 各类变体统治下的目标检测综述：Faster R-CNN系列胜了吗？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/37056927" rel="nofollow"&gt;目标检测-20种模型的原味代码汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40047760" rel="nofollow"&gt;目标检测算法综述三部曲&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40047760" rel="nofollow"&gt;基于深度学习的目标检测算法综述（一）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40020809" rel="nofollow"&gt;基于深度学习的目标检测算法综述（二）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40102001" rel="nofollow"&gt;基于深度学习的目标检测算法综述（三）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35295839" rel="nofollow"&gt;如何走近深度学习人脸识别？你需要这篇超长综述 | 附开源代码&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;人脸检测和识别算法综述&lt;/a&gt;      
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36621308" rel="nofollow"&gt;人脸检测算法综述 &lt;/a&gt;          &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32702868" rel="nofollow"&gt;人脸检测背景介绍和发展现状&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36416906" rel="nofollow"&gt;人脸识别算法演化史&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/shuzfan/article/details/50358809" rel="nofollow"&gt;CascadeCNN&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_14845119/article/details/52680940" rel="nofollow"&gt;MTCNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ChanChiChoi/awesome-Face_Recognition"&gt;awesome-Face_Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/64191484" rel="nofollow"&gt;异质人脸识别研究综述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/26431250" rel="nofollow"&gt;老板来了：人脸识别+手机推送，老板来了你立刻知道。&lt;/a&gt;&amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/33456076" rel="nofollow"&gt;手把手教你用Python实现人脸识别&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://www.jianshu.com/p/e57205edc364" rel="nofollow"&gt;人脸识别项目，网络模型，损失函数，数据集相关总结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24816781" rel="nofollow"&gt;基于深度学习的人脸识别技术综述&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/35295839" rel="nofollow"&gt;如何走近深度学习人脸识别？你需要这篇超长综述&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/51324547" rel="nofollow"&gt;人脸识别损失函数综述（附开源实现）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/57564211" rel="nofollow"&gt;深度学习图像超分辨率综述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60590369" rel="nofollow"&gt;目标检测进化史&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61080508" rel="nofollow"&gt;一文看尽21篇目标检测最新论文（腾讯/Google/商汤/旷视/清华/浙大/CMU/华科/中科院等&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Anchor-Free目标检测算法&lt;/a&gt;: &lt;a href="https://zhuanlan.zhihu.com/p/40221183" rel="nofollow"&gt;第一篇：arxiv2015_baidu_DenseBox&lt;/a&gt;， &lt;a href="https://www.zhihu.com/question/319605567/answer/647844997" rel="nofollow"&gt;如何评价最新的anchor-free目标检测模型FoveaBox？&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/61644900" rel="nofollow"&gt;FCOS: 最新的one-stage逐像素目标检测算法&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/62198865" rel="nofollow"&gt;最新的Anchor-Free目标检测模型FCOS，现已开源！&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/62789701" rel="nofollow"&gt;中科院牛津华为诺亚提出CenterNet，one-stage detector可达47AP，已开源！&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/VCBE123/AnchorFreeDetection"&gt;AnchorFreeDetection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62975854" rel="nofollow"&gt;目标检测算法综述之FPN优化篇&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/63273342" rel="nofollow"&gt;聊聊Anchor的"前世今生"（上）&lt;/a&gt;&amp;amp;&amp;amp;&lt;a href="https://zhuanlan.zhihu.com/p/68291859" rel="nofollow"&gt;聊聊Anchor的"前世今生"（下）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62843442" rel="nofollow"&gt;【CVPR2019正式公布】行人重识别论文&lt;/a&gt;，&lt;a href="https://zhuanlan.zhihu.com/p/64004977" rel="nofollow"&gt;2019 行人再识别年度进展回顾&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/67319122" rel="nofollow"&gt;2019CVPR文本检测综述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/31664818" rel="nofollow"&gt;从SRCNN到EDSR，总结深度学习端到端超分辨率方法发展历程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62843442" rel="nofollow"&gt;【CVPR2019正式公布】行人重识别论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&amp;amp;mid=2247485142&amp;amp;idx=1&amp;amp;sn=c0e01da30eb5e750be453eabe4be2bf4&amp;amp;chksm=fdb69b41cac11257ae22c7dac395e9651dab628fc35dd6d3c02d9566a8c7f5f2b56353d58a64&amp;amp;token=1065243837&amp;amp;lang=zh_CN#rd" rel="nofollow"&gt;自然场景文本检测识别技术综述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MarkMoHR/Awesome-Image-Colorization"&gt;Awesome-Image-Colorization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MarkMoHR/Awesome-Edge-Detection-Papers"&gt;Awesome-Edge-Detection-Papers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/65707543" rel="nofollow"&gt;OCR文字处理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/65690433" rel="nofollow"&gt;awesome-point-cloud-analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/65539782" rel="nofollow"&gt;Graph Neural Network（GNN）综述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61215293" rel="nofollow"&gt;小样本学习（Few-shot Learning）综述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/73542103" rel="nofollow"&gt;超全深度学习细粒度图像分析：项目、综述、教程一网打尽&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;图像检索的十年&lt;a href="https://mp.weixin.qq.com/s/sM78DCOK3fuG2JrP2QaSZA" rel="nofollow"&gt;上&lt;/a&gt;、&lt;a href="https://mp.weixin.qq.com/s/yzVMDEpwbXVS0y-CwWSBEA" rel="nofollow"&gt;下&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-教程" class="anchor" aria-hidden="true" href="#教程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;教程&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/39022858" rel="nofollow"&gt;卷积神经网络工作原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/28863709" rel="nofollow"&gt;「七夕的礼物」: 一日搞懂卷积神经网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215" rel="nofollow"&gt;A Comprehensive Introduction to Different Types of Convolutions in Deep Learning&lt;/a&gt; &amp;amp;&amp;amp; 翻译：&lt;a href="https://www.leiphone.com/news/201902/biIqSBpehsaXFwpN.html?uniqueCode=OTEsp9649VqJfUcO" rel="nofollow"&gt;上&lt;/a&gt;、&lt;a href="https://www.leiphone.com/news/201902/D2Mkv61w9IPq9qGh.html" rel="nofollow"&gt;下&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/28749411" rel="nofollow"&gt;变形卷积核、可分离卷积&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/chaolei3/article/details/79374563" rel="nofollow"&gt;对深度可分离卷积、分组卷积、扩张卷积、转置卷积（反卷积）的理解&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cnblogs.com/cvtoEyes/p/8848815.html" rel="nofollow"&gt;各种卷积&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/57575810" rel="nofollow"&gt;卷积有多少种？一文读懂深度学习中的各种卷积&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://buptldy.github.io/2016/10/29/2016-10-29-deconv/" rel="nofollow"&gt;反卷积&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cnblogs.com/yangperasd/p/7071657.html" rel="nofollow"&gt;Convolution Network及其变种（反卷积、扩展卷积、因果卷积、图卷积）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/320462422" rel="nofollow"&gt;如何评价最新的Octave Convolution？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59839551" rel="nofollow"&gt;深度学习基础--卷积类型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/silence2015/article/details/79748729" rel="nofollow"&gt;Dilated/Atrous conv 空洞卷积/多孔卷积&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32304419" rel="nofollow"&gt;CNN模型之ShuffleNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35985680" rel="nofollow"&gt;一文简述ResNet及其多种变体&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/lanran2/article/details/79057994" rel="nofollow"&gt;ResNet解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/23006190" rel="nofollow"&gt;将CNN引入目标检测的开山之作：R-CNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/hjimce/article/details/50187029" rel="nofollow"&gt;深度学习（十八）基于R-CNN的物体检测&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u014696921/article/details/52824097" rel="nofollow"&gt;R-CNN论文详解&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/hjimce/article/details/73382553" rel="nofollow"&gt;深度学习（六十四）Faster R-CNN物体检测&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34816076" rel="nofollow"&gt;先理解Mask R-CNN的工作原理，然后构建颜色填充器应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.codetd.com/article/2554465" rel="nofollow"&gt;实例分割--Mask RCNN详解(ROI Align / Loss Function)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_20084101/article/details/80455877" rel="nofollow"&gt;语义分割卷积神经网络快速入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/38033032" rel="nofollow"&gt;图像语义分割的工作原理和CNN架构变迁&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;amp;mid=2247484099&amp;amp;idx=1&amp;amp;sn=97e209f1a9860c8d8c51e81d98fc8a0a&amp;amp;chksm=eb4ee600dc396f16624a33cdfc0ead905e62ae9447b49b20146020e6cbd7d71f089101512a40&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;CapsNet入门系列&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;amp;mid=2247484099&amp;amp;idx=1&amp;amp;sn=97e209f1a9860c8d8c51e81d98fc8a0a&amp;amp;chksm=eb4ee600dc396f16624a33cdfc0ead905e62ae9447b49b20146020e6cbd7d71f089101512a40&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;CapsNet入门系列之一：胶囊网络背后的直觉&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;amp;mid=2247484165&amp;amp;idx=1&amp;amp;sn=0ca679e3a5f499f8d8addb405fe3df83&amp;amp;chksm=eb4ee7c6dc396ed0a330fcac12690110bcaf9a8a10794dbc5e1a326c69ecbb140140f55fd6ba&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;CapsNet入门系列之二：胶囊如何工作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;amp;mid=2247484433&amp;amp;idx=1&amp;amp;sn=3afe4605bc2501eebbc41c6dd1af9572&amp;amp;chksm=eb4ee0d2dc3969c4619d6c1097d5c949c76c6c854e60d36eba4388da2c3855747818d062c90a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;CapsNet入门系列之三：囊间动态路由算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/6CRSen8P6zKaMGtX8IRfqw" rel="nofollow"&gt;CapsNet入门系列之四：胶囊网络架构&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.mamicode.com/info-detail-2314392.html" rel="nofollow"&gt;YOLO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35325884?group_id=966229905398362112" rel="nofollow"&gt;目标检测|YOLOv2原理与实现(附YOLOv3)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34995629" rel="nofollow"&gt;目标检测模型YOLO v3问世&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cnblogs.com/shouhuxianjian/p/7903097.html" rel="nofollow"&gt;Attention&lt;/a&gt;， &lt;a href="https://zhuanlan.zhihu.com/p/31547842" rel="nofollow"&gt;1&lt;/a&gt;，&lt;a href="https://blog.csdn.net/yideqianfenzhiyi/article/details/79422857" rel="nofollow"&gt;2&lt;/a&gt;，&lt;a href="https://blog.csdn.net/Wayne2019/article/details/78488142" rel="nofollow"&gt;3&lt;/a&gt;，&lt;a href="https://zhuanlan.zhihu.com/p/37601161" rel="nofollow"&gt;4&lt;/a&gt;，&lt;a href="https://blog.csdn.net/bvl10101111/article/details/78470716" rel="nofollow"&gt;5&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40050371" rel="nofollow"&gt;一文读懂卷积神经网络中的1x1卷积核&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1808.01244" rel="nofollow"&gt;目标检测之CornerNet&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/41825737" rel="nofollow"&gt;1&lt;/a&gt;, &lt;a href="https://blog.csdn.net/Hibercraft/article/details/81637451" rel="nofollow"&gt;2&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/41759548" rel="nofollow"&gt;3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/70306015" rel="nofollow"&gt;目标检测的性能评价指标&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/75348108" rel="nofollow"&gt;NMS和计算mAP时的置信度阈值和IoU阈值 &lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/60834912" rel="nofollow"&gt;白话mAP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://chuansong.me/n/443237851736" rel="nofollow"&gt;人群计数&lt;/a&gt;, &lt;a href="https://www.cnblogs.com/wmr95/p/8134692.html" rel="nofollow"&gt;1&lt;/a&gt;, &lt;a href="https://blog.csdn.net/u011285477/article/details/51954989" rel="nofollow"&gt;2&lt;/a&gt;, &lt;a href="https://blog.csdn.net/qingqingdeaini/article/details/79922549" rel="nofollow"&gt;3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/60784169" rel="nofollow"&gt;RelationNetwork&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40980942" rel="nofollow"&gt;ShuffleNet V2和四个网络架构设计准则&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/mao_xiao_feng/article/details/78003476" rel="nofollow"&gt;【Tensorflow】tf.nn.depthwise_conv2d如何实现深度卷积?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/mao_xiao_feng/article/details/78003730" rel="nofollow"&gt;Tensorflow】tf.nn.atrous_conv2d如何实现空洞卷积？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/mao_xiao_feng/article/details/78002811" rel="nofollow"&gt;【Tensorflow】tf.nn.separable_conv2d如何实现深度可分卷积?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/mao_xiao_feng/article/details/71713358" rel="nofollow"&gt;【TensorFlow】tf.nn.conv2d_transpose是怎样实现反卷积的？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32423092" rel="nofollow"&gt;何恺明大神的「Focal Loss」，如何更好地理解？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/65305385" rel="nofollow"&gt;CNN 模型所需的计算力（flops）和参数（parameters）数量是怎么计算的？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-action" class="anchor" aria-hidden="true" href="#action"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Action&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/30753326" rel="nofollow"&gt;先读懂CapsNet架构然后用TensorFlow实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_36148847/article/details/79306762" rel="nofollow"&gt;TensorFlow Object Detection API 教程&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_36148847/article/details/79306762" rel="nofollow"&gt;TensorFlow 对象检测 API 教程1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_36148847/article/details/79307598" rel="nofollow"&gt;TensorFlow 对象检测 API 教程2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_36148847/article/details/79307751" rel="nofollow"&gt;TensorFlow 对象检测 API 教程3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_36148847/article/details/79307931" rel="nofollow"&gt;TensorFlow 对象检测 API 教程 4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_36148847/article/details/79307933" rel="nofollow"&gt;TensorFlow 对象检测 API 教程5&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/65327747" rel="nofollow"&gt;在TensorFlow+Keras环境下使用RoI池化一步步实现注意力机制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://discuss.gluon.ai/t/topic/7216" rel="nofollow"&gt;mxnet如何查看参数数量&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/likelyzhao/CalFLOPS-Mxnet"&gt;mxnet查看FLOPS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-gan" class="anchor" aria-hidden="true" href="#gan"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GAN&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://kexue.fm/category/Big-Data" rel="nofollow"&gt;苏剑林博客，讲解得淋漓尽致&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-发展史-1" class="anchor" aria-hidden="true" href="#发展史-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;发展史&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/26491601" rel="nofollow"&gt;千奇百怪的GAN变体&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1807.04720.pdf" rel="nofollow"&gt;The GAN Landscape：Losses, Architectures, Regularization, and Normalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.leiphone.com/news/201701/Kq6FvnjgbKK8Lh8N.html" rel="nofollow"&gt;深度学习新星：GAN的基本原理、应用和走向&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62746494" rel="nofollow"&gt;GAN生成图像综述&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-教程-1" class="anchor" aria-hidden="true" href="#教程-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;教程&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27295635" rel="nofollow"&gt;1. GAN原理学习笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35783437?group_id=969598777652420608" rel="nofollow"&gt;2. 极端图像压缩的对抗生成网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=0CKeqXl5IY0&amp;amp;feature=youtu.be" rel="nofollow"&gt;3. 台湾大学李宏毅GAN教程&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/GAN-Basic%20Idea%20(2017.04.21).pdf"&gt;Basic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/GAN-Improving%20GAN%20(2017.05.05).pdf"&gt;Improving&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29882709" rel="nofollow"&gt;4. 2017年GAN 计算机视觉相关paper汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35030377" rel="nofollow"&gt;5. 在Keras上实现GAN：构建消除图片模糊的应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34711316" rel="nofollow"&gt;6. CycleGAN：图片风格，想换就换 | ICCV 2017论文解读&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25071913" rel="nofollow"&gt;7. Wasserstein GAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40105143" rel="nofollow"&gt;用变分推断统一理解生成模型（VAE、GAN、AAE、ALI）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-action-1" class="anchor" aria-hidden="true" href="#action-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Action&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24767059" rel="nofollow"&gt;1. GAN学习指南：从原理入门到制作生成Demo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29837245" rel="nofollow"&gt;2. 机器之心GitHub项目：GAN完整理论推导与实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-rnn" class="anchor" aria-hidden="true" href="#rnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RNN&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-发展史-2" class="anchor" aria-hidden="true" href="#发展史-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;发展史&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32668465" rel="nofollow"&gt;从90年代的SRNN开始，纵览循环神经网络27年的研究进展&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-教程-2" class="anchor" aria-hidden="true" href="#教程-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;教程&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/28054589" rel="nofollow"&gt;完全图解RNN、RNN变体、Seq2Seq、Attention机制&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/heyongluoyao8/article/details/48636251" rel="nofollow"&gt;循环神经网络(RNN, Recurrent Neural Networks)介绍&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/Dark_Scope/article/details/47056361" rel="nofollow"&gt;RNN以及LSTM的介绍和公式梳理&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24018768" rel="nofollow"&gt;（译）理解长短期记忆(LSTM) 神经网络&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35878575?group_id=970350175025385472" rel="nofollow"&gt; 一文读懂LSTM和RNN&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27345523" rel="nofollow"&gt;探索LSTM：基本概念到内部结构&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/matrix_space/article/details/53374040" rel="nofollow"&gt; 翻译：深入理解LSTM系列&lt;/a&gt;                      &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/matrix_space/article/details/53374040" rel="nofollow"&gt;深入理解 LSTM 网络 (一)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/matrix_space/article/details/53376870" rel="nofollow"&gt;深入理解 LSTM 网络 (二)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32085405" rel="nofollow"&gt;LSTM&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zybuluo.com/hanbingtao/note/541458" rel="nofollow"&gt;深度学习其五 循环神经网络&lt;/a&gt;                      &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32582764" rel="nofollow"&gt;用循环神经网络进行文件无损压缩：斯坦福大学提出DeepZip&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=""&gt;吴恩达序列建模课程&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34309635" rel="nofollow"&gt;Coursera吴恩达《序列模型》课程笔记（1）-- 循环神经网络（RNN）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34975871" rel="nofollow"&gt;Coursera吴恩达《序列模型》课程笔记（2）-- NLP &amp;amp; Word Embeddings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35532553" rel="nofollow"&gt;Coursera吴恩达《序列模型》课程笔记（3）-- Sequence models &amp;amp; Attention mechanism&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;word2vec&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原理
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/26306795" rel="nofollow"&gt;NLP 秒懂词向量Word2vec的本质&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35500923" rel="nofollow"&gt;一篇通俗易懂的word2vec&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27830489" rel="nofollow"&gt;YJango的Word Embedding--介绍&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56382372" rel="nofollow"&gt;nlp中的词向量对比：word2vec/glove/fastText/elmo/GPT/bert&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zh.diveintodeeplearning.org/chapter_natural-language-processing/word2vec.html" rel="nofollow"&gt;词嵌入（word2vec）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/wangyangzhizhou/article/details/77073023" rel="nofollow"&gt;谈谈谷歌word2vec的原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/67117737" rel="nofollow"&gt;Word2Vec中为什么使用负采样？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;训练词向量
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29200034" rel="nofollow"&gt;练习-word2vec&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/31886824" rel="nofollow"&gt;word2vec方法的实现和应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/wzdjsgf/article/details/79541492" rel="nofollow"&gt;自然语言处理入门 word2vec 使用tensorflow自己训练词向量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/28979653" rel="nofollow"&gt;使用tensorflow实现word2vec中文词向量的训练&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/wangyangzhizhou/article/details/77530479?locationNum=1&amp;amp;fps=1" rel="nofollow"&gt;如何用TensorFlow训练词向量&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/47812375" rel="nofollow"&gt;聊聊 Transformer&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35648927" rel="nofollow"&gt;基于word2vec训练词向量(一)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35889385" rel="nofollow"&gt;基于word2vec训练词向量(二)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35041012" rel="nofollow"&gt;自然语言处理中的自注意力机制（Self-Attention Mechanism）&lt;/a&gt;    &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/54491016" rel="nofollow"&gt;自然语言处理中注意力机制综述&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27830489" rel="nofollow"&gt;YJango的Word Embedding--介绍&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-action-2" class="anchor" aria-hidden="true" href="#action-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Action&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/liuchonge/article/details/78405185?locationNum=8&amp;amp;fps=1" rel="nofollow"&gt;tensorflow中RNNcell源码分析以及自定义RNNCell的方法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/28196873" rel="nofollow"&gt;TensorFlow中RNN实现的正确打开方式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27906426" rel="nofollow"&gt;TensorFlow RNN 代码&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/67031035" rel="nofollow"&gt;Tensorflow实现的深度NLP模型集锦&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/graykode/nlp-tutorial"&gt;nlp-tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/33186759" rel="nofollow"&gt;用tensorflow LSTM如何预测股票价格&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29797089" rel="nofollow"&gt;TensorFlow的多层LSTM实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27087310" rel="nofollow"&gt;《安娜卡列尼娜》文本生成——利用TensorFlow构建LSTM模型&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-gnn" class="anchor" aria-hidden="true" href="#gnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GNN&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-发展史-3" class="anchor" aria-hidden="true" href="#发展史-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;发展史&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/65539782" rel="nofollow"&gt;Graph Neural Network（GNN）综述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650754422&amp;amp;idx=4&amp;amp;sn=0dc881487f362322a875b4ce06e645f7&amp;amp;chksm=871a8908b06d001ef7386ccc752827c20711877a4a23d6a8318978095dd241d118257c607b22&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;深度学习时代的图模型，清华发文综述图网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650754558&amp;amp;idx=2&amp;amp;sn=7d79191b9ed30679d5d40e22d9cabdf8&amp;amp;chksm=871a8980b06d00962e0dbe984e1d3469214db31cb402b4725a0dfe330249a830b45cb26932b5&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;清华大学图神经网络综述：模型与应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/54241746" rel="nofollow"&gt;图神经网络概述第三弹：来自IEEE Fellow的GNN综述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DeepGraphLearning/LiteratureDL4Graph"&gt;GNN最全文献资料整理&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/nnzhan/Awesome-Graph-Neural-Networks"&gt;Awesome-Graph-Neural-Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-教程-3" class="anchor" aria-hidden="true" href="#教程-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;教程&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/54504471/answer/611222866" rel="nofollow"&gt;如何理解 Graph Convolutional Network（GCN）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/54505069" rel="nofollow"&gt;图卷积网络(GCN)新手村完全指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/71200936" rel="nofollow"&gt;何时能懂你的心——图卷积神经网络（GCN）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/90470499" rel="nofollow"&gt;图卷积网络GCN的理解与介绍&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/89503068" rel="nofollow"&gt;一文读懂图卷积GCN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-action-3" class="anchor" aria-hidden="true" href="#action-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Action&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/57235377" rel="nofollow"&gt;图卷积网络到底怎么做，这是一份极简的Numpy实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.dgl.ai/index.html" rel="nofollow"&gt;DGL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-三-深度模型的优化--" class="anchor" aria-hidden="true" href="#三-深度模型的优化--"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;三. 深度模型的优化    &lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://fa.bianp.net/teaching/2018/eecs227at/" rel="nofollow"&gt;1. 优化算法纵览&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27449596" rel="nofollow"&gt;2. 从梯度下降到Adam&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25703402" rel="nofollow"&gt;3. 从梯度下降到拟牛顿法：盘点训练神经网络的五大学习算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35429054?group_id=966442942538444800" rel="nofollow"&gt;4. 正则化技术总结&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35429054?group_id=966442942538444800" rel="nofollow"&gt;史上最全面的正则化技术总结与分析--part1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35432128?group_id=966443101011738624" rel="nofollow"&gt;史上最全面的正则化技术总结与分析--part2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/chunyun0716/article/category/6188191/2" rel="nofollow"&gt;5. 最优化算法系列（math）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25631496" rel="nofollow"&gt;6. 神经网络训练中的梯度消失与梯度爆炸&lt;/a&gt;        &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36050743" rel="nofollow"&gt;7. 神经网络的优化及训练&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35888543" rel="nofollow"&gt;8. 通俗讲解查全率和查准率&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/34079183" rel="nofollow"&gt;全面梳理：准确率,精确率,召回率,查准率,查全率,假阳性,真阳性,PRC,ROC,AUC,F1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/30567264" rel="nofollow"&gt;9. 激活函数一览&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/30922689" rel="nofollow"&gt;10. Coursera吴恩达《优化深度神经网络》课程笔记（3）-- 超参数调试、Batch正则化和编程框架&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35423404" rel="nofollow"&gt;11. 机器学习各种熵&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27305237" rel="nofollow"&gt;12. 距离和相似性度量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29974820" rel="nofollow"&gt;13. 机器学习里的黑色艺术：normalization, standardization, regularization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36101196" rel="nofollow"&gt;14. LSTM系列的梯度问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35027284" rel="nofollow"&gt;15. 损失函数整理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/28124810" rel="nofollow"&gt;16. 详解残差块为何有助于解决梯度弥散问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34858971" rel="nofollow"&gt;17. FAIR何恺明等人提出组归一化：替代批归一化，不受批量大小限制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;18. Batch Normalization（BN）&lt;/a&gt;:&lt;a href="https://zhuanlan.zhihu.com/p/26702482" rel="nofollow"&gt;1 &lt;/a&gt;,&lt;a href="https://blog.csdn.net/hjimce/article/details/50866313" rel="nofollow"&gt;2 &lt;/a&gt;,&lt;a href="http://www.cvmart.net/community/article/detail/368" rel="nofollow"&gt;3 &lt;/a&gt;,&lt;a href="https://blog.csdn.net/edogawachia/article/details/80040456" rel="nofollow"&gt;4 &lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/38176412" rel="nofollow"&gt;5&lt;/a&gt;, &lt;a href="https://www.zhihu.com/question/38102762" rel="nofollow"&gt;6&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/52132614" rel="nofollow"&gt;7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/33173246" rel="nofollow"&gt;19. 详解深度学习中的Normalization，不只是BN&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/69659844" rel="nofollow"&gt;如何区分并记住常见的几种 Normalization 算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/philosophyatmath/article/details/70173128" rel="nofollow"&gt;20. BFGS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/33006526" rel="nofollow"&gt;21. 详解深度学习中的梯度消失、爆炸原因及其解决方法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1207.0580.pdf" rel="nofollow"&gt;22. Dropout&lt;/a&gt;, &lt;a href="https://blog.csdn.net/stdcoutzyx/article/details/49022443" rel="nofollow"&gt;1&lt;/a&gt;, &lt;a href="https://blog.csdn.net/hjimce/article/details/50413257" rel="nofollow"&gt;2&lt;/a&gt;, &lt;a href="https://blog.csdn.net/shuzfan/article/details/50580915" rel="nofollow"&gt;3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/StreamRock/article/details/83590347" rel="nofollow"&gt;23.谱归一化（Spectral Normalization）的理解&lt;/a&gt;，&lt;a href="https://blog.csdn.net/left_la/article/details/9159949" rel="nofollow"&gt;常见向量范数和矩阵范数&lt;/a&gt;，&lt;a href="https://blog.csdn.net/StreamRock/article/details/83539937" rel="nofollow"&gt;谱范数正则（Spectral Norm Regularization）的理解&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35356992" rel="nofollow"&gt;24.L1正则化与L2正则化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61944055" rel="nofollow"&gt;25.为什么选用交叉熵而不是MSE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/xierhacker/article/details/53316138" rel="nofollow"&gt;机器学习笔记四：线性回归回顾与logistic回归&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u014313009/article/details/51039334" rel="nofollow"&gt;反向传播算法（过程及公式推导）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u014313009/article/details/51043064" rel="nofollow"&gt;交叉熵代价函数（作用及公式推导）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Softmax&lt;/strong&gt;：&lt;a href="https://zhuanlan.zhihu.com/p/25723112" rel="nofollow"&gt;详解softmax函数以及相关求导过程&lt;/a&gt;  &amp;amp;&amp;amp;  &lt;a href="https://blog.csdn.net/u014313009/article/details/51045303" rel="nofollow"&gt;softmax的log似然代价函数（公式求导）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;权重初始化&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62850258" rel="nofollow"&gt;神经网络中的权重初始化一览：从基础到Kaiming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61641174" rel="nofollow"&gt;深度学习入门--权重初始值的优化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/75879624" rel="nofollow"&gt;谈谈神经网络权重为什么不能初始化为0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/305340182" rel="nofollow"&gt;神经网络中的偏置（bias）究竟有这么用？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/66894061" rel="nofollow"&gt;深度学习里面的偏置为什么不加正则？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-四-炼丹术士那些事" class="anchor" aria-hidden="true" href="#四-炼丹术士那些事"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;四. 炼丹术士那些事&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-调参经验" class="anchor" aria-hidden="true" href="#调参经验"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;调参经验&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/jiandanjinxin/article/details/77190687" rel="nofollow"&gt;训练的神经网络不工作？一文带你跨过这37个坑&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59918821" rel="nofollow"&gt;神经网络训练trick&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/han_xiaoyang/article/details/50521064" rel="nofollow"&gt;深度学习与计算机视觉系列(8)_神经网络训练与注意点&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/liuweiyuxiang/article/details/80856991" rel="nofollow"&gt;神经网络训练loss不下降原因集合&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/ningyanggege/article/details/82183666" rel="nofollow"&gt;深度学习：欠拟合问题的几种解决方案&lt;/a&gt; &amp;amp;&amp;amp;&lt;a href="https://blog.csdn.net/mzpmzk/article/details/79741682" rel="nofollow"&gt;过拟合和欠拟合问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/whut_ldz/article/details/78882871" rel="nofollow"&gt;机器学习：如何找到最优学习率&lt;/a&gt;及&lt;a href="https://github.com/L1aoXingyu/torchlib"&gt;实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;不平衡数据集处理方法&lt;/a&gt;: &lt;a href="https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/" rel="nofollow"&gt;其一&lt;/a&gt;, &lt;a href="https://www.zhihu.com/question/285824343" rel="nofollow"&gt;其二&lt;/a&gt;, &lt;a href="https://blog.csdn.net/songhk0209/article/details/71484469" rel="nofollow"&gt;其三&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/41841299" rel="nofollow"&gt;同一个神经网络使用不同激活函数的表达能力是否一致&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ruder.io/optimizing-gradient-descent/" rel="nofollow"&gt;梯度下降优化算法纵览&lt;/a&gt;, &lt;a href="https://blog.csdn.net/qq_23269761/article/details/80901411" rel="nofollow"&gt;1&lt;/a&gt;, &lt;a href="https://www.cnblogs.com/guoyaohua/p/8542554.html" rel="nofollow"&gt;2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/ly244855983/article/details/78938667#%E8%AE%A8%E8%AE%BA" rel="nofollow"&gt;论文笔记之数据增广：mixup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/44331706" rel="nofollow"&gt;避坑指南：数据科学家新手常犯的13个错误&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bindog.github.io/blog/2018/02/10/model-explanation/" rel="nofollow"&gt;凭什么相信CNN的结果?--可视化&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://bindog.github.io/blog/2018/02/10/model-explanation/" rel="nofollow"&gt;凭什么相信你，我的CNN模型？（篇一：CAM和Grad-CAM)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://bindog.github.io/blog/2018/02/11/model-explanation-2/" rel="nofollow"&gt;凭什么相信你，我的CNN模型？（篇二：万金油LIME)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jianshu.com/p/294ad9ae2e50" rel="nofollow"&gt;论文笔记:Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_41185868/article/details/80323646" rel="nofollow"&gt;CV：基于Keras利用训练好的hdf5模型进行目标检测实现输出模型中的表情或性别的gradcam(可视化)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;大卷积核还是小卷积核?&lt;/a&gt; &lt;a href="https://www.jianshu.com/p/d75375dd7ebd" rel="nofollow"&gt;1&lt;/a&gt;, &lt;a href="https://blog.csdn.net/kuangtun9713/article/details/79475457" rel="nofollow"&gt;2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://baijiahao.baidu.com/s?id=1608193373391996908" rel="nofollow"&gt;模型可解释性差？你考虑了各种不确定性了吗？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;炼丹笔记系列&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56882616" rel="nofollow"&gt;炼丹笔记一：样本不平衡问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56022212" rel="nofollow"&gt;炼丹笔记二：数据清洗&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56139575" rel="nofollow"&gt;炼丹笔记三：数据增强&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56365469" rel="nofollow"&gt;炼丹笔记四：小样本问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56443169" rel="nofollow"&gt;炼丹笔记五：数据标注&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56745640" rel="nofollow"&gt;炼丹笔记六 : 调参技巧&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/57738934" rel="nofollow"&gt;炼丹笔记七：卷积神经网络模型设计&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-刷排行榜的奇技淫巧" class="anchor" aria-hidden="true" href="#刷排行榜的奇技淫巧"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;刷排行榜的奇技淫巧&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.leiphone.com/news/201803/XBjvQriKTyTMPLcz.html" rel="nofollow"&gt;Kaggle 六大比赛最全面解析（上）&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.leiphone.com/news/201803/chz1DNHqgVWNEm5t.html" rel="nofollow"&gt;Kaggle 六大比赛最全面解析（下）&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-图像分类" class="anchor" aria-hidden="true" href="#图像分类"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;图像分类&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56139575" rel="nofollow"&gt;炼丹笔记三：数据增强&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/41679153" rel="nofollow"&gt;数据增强(Data Augmentation)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/38345420" rel="nofollow"&gt;【技术综述】 深度学习中的数据增强（上）&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/38437739" rel="nofollow"&gt;【技术综述】深度学习中的数据增强（下）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/53324148" rel="nofollow"&gt;《Bag of Tricks for Image Classification with CNN》&lt;/a&gt;&amp;amp;&amp;amp; &lt;a href="https://arxiv.org/pdf/1812.01187.pdf" rel="nofollow"&gt;pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59918821" rel="nofollow"&gt;神经网络训练trick&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Kaggle解决方案分享&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.itcodemonkey.com/article/4898.html" rel="nofollow"&gt;从0上手Kaggle图像分类挑战：冠军解决方案详解&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.leiphone.com/news/201803/u40cjEZWArBfFaBm.html" rel="nofollow"&gt;Kaggle 冰山图像分类大赛近日落幕，看冠军团队方案有何亮点&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/_S8EBBJ-u9g_fHp7I3ChMQ?" rel="nofollow"&gt;【Kaggle冠军分享】图像识别和分类竞赛，数据增强及优化算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58496385" rel="nofollow"&gt;识别座头鲸，Kaggle竞赛第一名解决方案解读&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60953933" rel="nofollow"&gt;kaggle 首战拿金牌总结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/37522227" rel="nofollow"&gt;16岁高中生夺冠Kaggle地标检索挑战赛！而且竟然是Kaggle老兵&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/37663895" rel="nofollow"&gt;6次Kaggle计算机视觉类比赛赛后感&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/63275166" rel="nofollow"&gt;Kaggle首战斩获第三-卫星图像识别&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-目标检测" class="anchor" aria-hidden="true" href="#目标检测"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目标检测&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;ensemble&lt;/li&gt;
&lt;li&gt;deformable&lt;/li&gt;
&lt;li&gt;sync bn&lt;/li&gt;
&lt;li&gt;ms train/test&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56792817" rel="nofollow"&gt;目标检测任务的优化策略tricks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60612064" rel="nofollow"&gt;目标检测小tricks--样本不均衡处理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/39262769" rel="nofollow"&gt;目标检测算法中的常见trick&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jianshu.com/p/50158f8daf0d" rel="nofollow"&gt;Kaggle：肺癌自动诊断系统3D Deep Leaky Noisy-or Network 论文阅读&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://yq.aliyun.com/articles/89312" rel="nofollow"&gt;干货|大神教你如何参加kaggle比赛——根据CT扫描图预测肺癌&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-五-年度总结" class="anchor" aria-hidden="true" href="#五-年度总结"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;五. 年度总结&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/53717510" rel="nofollow"&gt;新年大礼包：机器之心2018高分教程合集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59376548" rel="nofollow"&gt;CVPR2019目标检测方法进展综述&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-六-科研相关" class="anchor" aria-hidden="true" href="#六-科研相关"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;六. 科研相关&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-深度学习框架" class="anchor" aria-hidden="true" href="#深度学习框架"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;深度学习框架&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-python3x先修" class="anchor" aria-hidden="true" href="#python3x先修"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python3.x(先修)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/tutorial/" rel="nofollow"&gt;The Python Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" rel="nofollow"&gt;廖雪峰Python教程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.runoob.com/python3/python3-tutorial.html" rel="nofollow"&gt;菜鸟教程&lt;/a&gt;    &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24162430" rel="nofollow"&gt;给深度学习入门者的Python快速教程 - 基础篇&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jackfrued/Python-100-Days"&gt;Python - 100天从新手到大师&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-numpy先修" class="anchor" aria-hidden="true" href="#numpy先修"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Numpy(先修)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.numpy.org/devdocs/user/quickstart.html" rel="nofollow"&gt;Quickstart tutorial&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.jianshu.com/p/3e566f09a0cf" rel="nofollow"&gt;Numpy快速入门(Numpy 1.14 官方文档中文翻译)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.numpy.org.cn/index.html" rel="nofollow"&gt;Numpy中文文档&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24309547" rel="nofollow"&gt;给深度学习入门者的Python快速教程 - numpy和Matplotlib篇&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-opencv-python" class="anchor" aria-hidden="true" href="#opencv-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Opencv-python&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html" rel="nofollow"&gt;OpenCV-Python Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cnblogs.com/Undo-self-blog/p/8423851.html" rel="nofollow"&gt;OpenCV官方教程中文版（For Python）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/feilong_csdn/article/category/8037591" rel="nofollow"&gt;数字图像处理系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_40962368/article/category/7688903" rel="nofollow"&gt;python+OpenCV图像处理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24425116" rel="nofollow"&gt;给深度学习入门者的Python快速教程 - 番外篇之Python-OpenCV&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-pandas" class="anchor" aria-hidden="true" href="#pandas"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pandas&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.jianshu.com/p/d9774cf1fea5?utm_campaign=maleskine&amp;amp;utm_content=note&amp;amp;utm_medium=seo_notes&amp;amp;utm_source=recommendation" rel="nofollow"&gt;Python 数据科学入门教程：Pandas&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-tensorflow" class="anchor" aria-hidden="true" href="#tensorflow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tensorflow&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/41667903" rel="nofollow"&gt;如何高效地学习 TensorFlow 代码&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.tensorfly.cn/tfdoc/tutorials/overview.html" rel="nofollow"&gt;中文教程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.w3cschool.cn/tensorflow_python/" rel="nofollow"&gt;TensorFlow官方文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://web.stanford.edu/class/cs20si/syllabus.html" rel="nofollow"&gt;CS20:Tensorflow for DeepLearning Research&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62981537" rel="nofollow"&gt;吴恩达TensorFlow专项课程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35515805?group_id=967136289941897216" rel="nofollow"&gt;【干货】史上最全的Tensorflow学习资源汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/hzy46/Deep-Learning-21-Examples"&gt;《21个项目玩转深度学习———基于TensorFlow的实践详解》&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59507137" rel="nofollow"&gt;最全Tensorflow2.0 入门教程持续更新&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/search?o=desc&amp;amp;q=tensorflow+tutorial&amp;amp;s=&amp;amp;type=Repositories"&gt;Github优秀开源教程&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-mxnet" class="anchor" aria-hidden="true" href="#mxnet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MXNet&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://zh.gluon.ai/#" rel="nofollow"&gt;Gluon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gluon-cv.mxnet.io/index.html#" rel="nofollow"&gt;GluonCV&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://gluon-nlp.mxnet.io/" rel="nofollow"&gt;GluonNLP&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-pytorch" class="anchor" aria-hidden="true" href="#pytorch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyTorch&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/ShusenTang/Dive-into-DL-PyTorch"&gt;Pytorch版动手学深度学习&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://pytorch-cn.readthedocs.io/zh/latest/" rel="nofollow"&gt;PyTorch中文文档&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://pytorch.org/tutorials/index.html" rel="nofollow"&gt;WELCOME TO PYTORCH TUTORIALS&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/64895011" rel="nofollow"&gt;史上最全的PyTorch学习资源汇总&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/INTERMT/Awesome-PyTorch-Chinese"&gt;【干货】史上最全的PyTorch学习资源汇总&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://mlelarge.github.io/dataflowr-web/cea_edf_inria.html" rel="nofollow"&gt;Hands-on tour to deep learning with PyTorch&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-python可视化" class="anchor" aria-hidden="true" href="#python可视化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python可视化&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/" rel="nofollow"&gt;Top 50 matplotlib Visualizations – The Master Plots (with full python code)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jianshu.com/p/92e1a4497505" rel="nofollow"&gt;Python之MatPlotLib使用教程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/UfvEdzr-ZGmyT08yKDOchA" rel="nofollow"&gt;十分钟上手matplotlib，开启你的python可视化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24309547" rel="nofollow"&gt;给深度学习入门者的Python快速教程 - numpy和Matplotlib篇&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-标注工具" class="anchor" aria-hidden="true" href="#标注工具"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;标注工具&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;目标检测标注工具
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/tzutalin/labelImg"&gt;labelImg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;语义分割标注工具
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/wkentaro/labelme"&gt;labelme&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-数据集" class="anchor" aria-hidden="true" href="#数据集"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数据集&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35449783" rel="nofollow"&gt;1. 25个深度学习相关公开数据集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35423943" rel="nofollow"&gt;2. 自然语言处理（NLP）数据集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pan.baidu.com/s/1o7QlUhO" rel="nofollow"&gt;3.全唐诗(43030首)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://people.eecs.berkeley.edu/~taesung_park/" rel="nofollow"&gt;4. 伯克利大学公开数据集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36835964" rel="nofollow"&gt;5. ACL 2018资源：100+ 预训练的中文词向量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Embedding/Chinese-Word-Vectors"&gt;6. 预训练中文词向量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://academictorrents.com" rel="nofollow"&gt;7. 公开数据集种子库&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/c20081052/article/details/79814082" rel="nofollow"&gt;8. 计算机视觉，深度学习，数据挖掘数据集整理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/accepthjp/article/details/51831026" rel="nofollow"&gt;9. 计算机视觉著名数据集CV Datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/NNNNNNNNNNNNY/article/details/68485160" rel="nofollow"&gt;10. 计算机视觉相关数据集和比赛&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/43846002" rel="nofollow"&gt;11. 这是一份非常全面的开源数据集，你，真的不想要吗？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/weixin_40516558/article/details/81564464" rel="nofollow"&gt;12. 人群密度估计现有主要数据集特点及其比较&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.gwern.net/Danbooru2017" rel="nofollow"&gt;13. DANBOORU2017: A LARGE-SCALE CROWDSOURCED AND TAGGED ANIME ILLUSTRATION DATASET&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://robustsystems.coe.neu.edu/sites/robustsystems.coe.neu.edu/files/systems/projectpages/reiddataset.html" rel="nofollow"&gt;14. 行人重识别数据集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56144877" rel="nofollow"&gt;15. 自然语言处理常见数据集、论文最全整理分享&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://paperswithcode.com/" rel="nofollow"&gt;16. paper, code, sota&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/55627416" rel="nofollow"&gt;17. 旷视RPC大型商品数据集发布！&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60617001" rel="nofollow"&gt;18. CVPR 2019「准满分」论文：英伟达推出首个跨摄像头汽车跟踪数据集(汽车Re-ID)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59052013" rel="nofollow"&gt;19.【OCR技术】大批量生成文字训练集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/msra-nlc/MSParS"&gt;20. 语义分析数据集-MSRA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-会议列表" class="anchor" aria-hidden="true" href="#会议列表"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;会议列表&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/JackieTseng/conference_call_for_paper"&gt;国际会议日期表&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/abhshkdz/ai-deadlines/"&gt;ai-deadlines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://handong1587.github.io/deep_learning/2017/12/18/keep-up-with-new-trends.html" rel="nofollow"&gt;Keep Up With New Trends&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/cserchen/article/details/40508181" rel="nofollow"&gt;计算机会议排名等级&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ccf.org.cn/xspj/rgzn/" rel="nofollow"&gt;中国计算机学会(CCF)推荐国际学术刊物和会议&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-论文写作工具" class="anchor" aria-hidden="true" href="#论文写作工具"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;论文写作工具&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://jingyan.baidu.com/article/b2c186c83c9b40c46ff6ff4f.html" rel="nofollow"&gt;Windows: Texlive+Texstudio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jingyan.baidu.com/article/7c6fb4280b024180642c90e4.html" rel="nofollow"&gt;Ubuntu: Texlive+Texmaker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-论文画图工具" class="anchor" aria-hidden="true" href="#论文画图工具"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;论文画图工具&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Visio2016&lt;/li&gt;
&lt;li&gt;&lt;a href="#Python%E5%8F%AF%E8%A7%86%E5%8C%96"&gt;Matplotlib&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-论文写作教程" class="anchor" aria-hidden="true" href="#论文写作教程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;论文写作教程&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58752815" rel="nofollow"&gt;刘知远_如何写一篇合格的NLP论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nlp.csai.tsinghua.edu.cn/~ly/talks/cwmt14_tut.pdf" rel="nofollow"&gt;刘洋_如何写论文_V7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://xpqiu.github.io/slides/20181019-PaperWriting.pdf" rel="nofollow"&gt;如何端到端地写科研论文-邱锡鹏&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/33876355" rel="nofollow"&gt;论文Introduction写作其一&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/52494933" rel="nofollow"&gt;论文Introduction写作其二&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/52494879" rel="nofollow"&gt;论文Introduction写作其三&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/c_179195484" rel="nofollow"&gt;毕业论文怎么写&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-researchgo" class="anchor" aria-hidden="true" href="#researchgo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ResearchGo&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22323250?refer=wjdml" rel="nofollow"&gt;ResearchGo:研究生活第一帖——文献检索与管理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22402393?refer=wjdml" rel="nofollow"&gt;ResearchGo:研究生活第二贴——文献阅读&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22622502?refer=wjdml" rel="nofollow"&gt;ResearchGo:研究生活第三帖——阅读辅助&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/23178836?refer=wjdml" rel="nofollow"&gt;ResearchGo:研究生活第四帖——文献调研&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/23356843?refer=wjdml" rel="nofollow"&gt;ResearchGo:研究生活第五帖——文献综述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/23872063?refer=wjdml" rel="nofollow"&gt;ResearchGo:研究生活第六帖——如何讲论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25191025" rel="nofollow"&gt;ResearchGo:研究生活第七帖——专利检索与申请&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62100815" rel="nofollow"&gt;ResearchGo:研究生活第八帖——写论文、做PPT、写文档必备工具集锦&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-毕业论文排版" class="anchor" aria-hidden="true" href="#毕业论文排版"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;毕业论文排版&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/52495345" rel="nofollow"&gt;吐血推荐收藏的学位论文排版教程（完整版）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35951260" rel="nofollow"&gt;论文怎么写——如何修改毕业论文格式&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-机器学习理论与实战" class="anchor" aria-hidden="true" href="#机器学习理论与实战"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习理论与实战&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/shunliz/Machine-Learning"&gt;机器学习原理&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="star" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png"&gt;⭐️&lt;/g-emoji&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34534004" rel="nofollow"&gt;ID3、C4.5、CART、随机森林、bagging、boosting、Adaboost、GBDT、xgboost算法总结&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.cnblogs.com/en-heng/p/5013995.html" rel="nofollow"&gt;数据挖掘十大算法简要说明&lt;/a&gt;，&lt;a href="https://blog.csdn.net/qq_42379006/article/details/80741808" rel="nofollow"&gt;机器学习十大经典算法入门&lt;/a&gt;， &lt;a href="https://www.cnblogs.com/ljt1412451704/p/9678248.html" rel="nofollow"&gt;【算法模型】轻松看懂机器学习十大常用算法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=""&gt;AdaBoost到GBDT系列&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25096501?refer=data-miner" rel="nofollow"&gt;当我们在谈论GBDT：从 AdaBoost 到 Gradient Boosting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25257856?refer=data-miner" rel="nofollow"&gt;当我们在谈论GBDT：Gradient Boosting 用于分类与回归&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25443980" rel="nofollow"&gt;当我们在谈论GBDT：其他 Ensemble Learning 算法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/41809927" rel="nofollow"&gt;集成学习之bagging,stacking,boosting概念理解&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;番外篇之傅里叶变换&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/19763358" rel="nofollow"&gt;傅里叶分析之掐死教程（完整版）更新于2014.06.06&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/34899574/answer/612923473" rel="nofollow"&gt;如何简明的总结傅里叶变换？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/clover13/article/details/79469851" rel="nofollow"&gt;从连续时间傅里叶级数到快速傅里叶变换&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/enjoy_pascal/article/details/81478582" rel="nofollow"&gt;十分简明易懂的FFT（快速傅里叶变换）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/hanxiaohu88/article/details/8245687" rel="nofollow"&gt;傅里叶级数推导过程&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-机器学习理论篇之经典算法" class="anchor" aria-hidden="true" href="#机器学习理论篇之经典算法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习理论篇之经典算法&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-信息论" class="anchor" aria-hidden="true" href="#信息论"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;信息论&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35423404" rel="nofollow"&gt;1. 机器学习中的各种熵&lt;/a&gt;    &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32985487" rel="nofollow"&gt;2. 从香农熵到手推KL散度：纵览机器学习中的信息论&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-多层感知机mlp" class="anchor" aria-hidden="true" href="#多层感知机mlp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;多层感知机(MLP)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/baidu_33718858/article/details/84972537" rel="nofollow"&gt;多层感知机（MLP）学习与总结博客&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-k近邻knn" class="anchor" aria-hidden="true" href="#k近邻knn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;k近邻(KNN)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/sinat_30353259/article/details/80901746" rel="nofollow"&gt;机器学习之KNN（k近邻）算法详解&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-k均值k-means" class="anchor" aria-hidden="true" href="#k均值k-means"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;k均值(K-means)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_32892383/article/details/80107795" rel="nofollow"&gt;Kmeans聚类算法详解&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-朴素贝叶斯naive-bayesian" class="anchor" aria-hidden="true" href="#朴素贝叶斯naive-bayesian"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;朴素贝叶斯(Naive Bayesian)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/qq_32690999/article/details/78737393" rel="nofollow"&gt;朴素贝叶斯分类器（Naive Bayesian Classifier）&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/qq_17073497/article/details/81076250" rel="nofollow"&gt;朴素贝叶斯分类器 详细解析&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-决策树decision-tree" class="anchor" aria-hidden="true" href="#决策树decision-tree"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;决策树(Decision Tree)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/c406495762/article/details/75663451" rel="nofollow"&gt;Python3《机器学习实战》学习笔记（二）：决策树基础篇之让我们从相亲说起&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/c406495762/article/details/76262487" rel="nofollow"&gt;Python3《机器学习实战》学习笔记（三）：决策树实战篇之为自己配个隐形眼镜&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cuijiahua.com/blog/2017/12/ml_13_regtree_1.html" rel="nofollow"&gt;机器学习实战教程（十三）：树回归基础篇之CART算法与树剪枝&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/gamer_gyt/article/details/51242815" rel="nofollow"&gt;《机器学习实战》基于信息论的三种决策树算法(ID3,C4.5,CART)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/31404571" rel="nofollow"&gt;说说决策树剪枝算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/namelessml/article/details/52595066" rel="nofollow"&gt;机器学习实战 第九章 树回归&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u014688145/article/details/53212112" rel="nofollow"&gt;决策树值ID3、C4.5实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u014688145/article/details/53326910" rel="nofollow"&gt;决策树值CART实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-随机森林random-forest" class="anchor" aria-hidden="true" href="#随机森林random-forest"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;随机森林(Random Forest)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/sb19931201/article/details/52601058" rel="nofollow"&gt;随机森林（Random Forest）入门与实战&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-逻辑回归logistic-regression" class="anchor" aria-hidden="true" href="#逻辑回归logistic-regression"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;逻辑回归(Logistic Regression)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62653034" rel="nofollow"&gt;【机器学习面试题】逻辑回归篇&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-支持向量机svm" class="anchor" aria-hidden="true" href="#支持向量机svm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;支持向量机(SVM)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E9%80%9A%E4%BF%97%E5%AF%BC%E8%AE%BA%EF%BC%88%E7%90%86%E8%A7%A3SVM%E7%9A%84%E4%B8%89%E5%B1%82%E5%A2%83%E7%95%8C%EF%BC%89LaTeX%E6%9C%80%E6%96%B0%E7%89%88_2015.1.9.pdf"&gt;SVM通俗导论 July&lt;/a&gt;      &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/c406495762/article/details/78072313" rel="nofollow"&gt;Python3《机器学习实战》学习笔记（八）：支持向量机原理篇之手撕线性SVM （SMO训练过程总结得清晰易懂）&lt;/a&gt;      &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/leonis_v/article/details/50688766" rel="nofollow"&gt;svm核函数的理解和选择&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/huang1024rui/article/details/51510611" rel="nofollow"&gt;核函数和径向基核函数 (Radial Basis Function)--RBF&lt;/a&gt;                        &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/xiaowei_cqu/article/details/35993729" rel="nofollow"&gt;SVM核函数&lt;/a&gt;      &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-提升方法adaboost" class="anchor" aria-hidden="true" href="#提升方法adaboost"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;提升方法(Adaboost)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25096501" rel="nofollow"&gt;当我们在谈论GBDT：从 AdaBoost 到 Gradient Boosting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-梯度提升决策树gbdt" class="anchor" aria-hidden="true" href="#梯度提升决策树gbdt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;梯度提升决策树(GBDT)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35645973" rel="nofollow"&gt;LightGBM大战XGBoost&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34698733" rel="nofollow"&gt;概述XGBoost、Light GBM和CatBoost的同与不同&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36339161" rel="nofollow"&gt;梯度提升决策树&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/30339807" rel="nofollow"&gt;GBDT原理及应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/31654000" rel="nofollow"&gt;XGBOOST原理篇&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/sb19931201/article/details/52557382" rel="nofollow"&gt;xgboost入门与实战（原理篇）&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://blog.csdn.net/sb19931201/article/details/52577592" rel="nofollow"&gt;xgboost入门与实战（实战调参篇）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/41417638" rel="nofollow"&gt;【干货合集】通俗理解kaggle比赛大杀器xgboost&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/bf02jgtrs00xktcx/article/details/82719765" rel="nofollow"&gt;GBDT分类的原理及Python实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/shine19930820/article/details/71713680" rel="nofollow"&gt;GBDT原理及利用GBDT构造新的特征-Python实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jianshu.com/p/47e73a985ba1" rel="nofollow"&gt;Python+GBDT算法实战——预测实现100%准确率&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-em期望最大化" class="anchor" aria-hidden="true" href="#em期望最大化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;EM(期望最大化)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36331115" rel="nofollow"&gt;人人都懂的EM算法 &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61768577" rel="nofollow"&gt;EM算法入门文章&lt;/a&gt;                      &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-高斯混合模型gmm" class="anchor" aria-hidden="true" href="#高斯混合模型gmm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;高斯混合模型(GMM)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/67107370" rel="nofollow"&gt;高斯混合模型与EM算法的数学原理及应用实例&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/30483076" rel="nofollow"&gt;高斯混合模型（GMM）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-马尔科夫决策过程mdp" class="anchor" aria-hidden="true" href="#马尔科夫决策过程mdp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;马尔科夫决策过程(MDP)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35124726" rel="nofollow"&gt;马尔科夫决策过程之Markov Processes（马尔科夫过程）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35231424" rel="nofollow"&gt;马尔科夫决策过程之Markov Reward Process（马尔科夫奖励过程）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35261164" rel="nofollow"&gt;马尔科夫决策过程之Bellman Equation（贝尔曼方程）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35354956" rel="nofollow"&gt;马尔科夫决策过程之Markov Decision Process(马尔科夫决策过程)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35373905" rel="nofollow"&gt;马尔科夫决策过程之最优价值函数与最优策略&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-条件随机场crf-判别式模型" class="anchor" aria-hidden="true" href="#条件随机场crf-判别式模型"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;条件随机场(CRF, 判别式模型)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.jianshu.com/p/55755fc649b1" rel="nofollow"&gt;如何轻松愉快地理解条件随机场&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/35866596" rel="nofollow"&gt;如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u013378306/article/details/55213029" rel="nofollow"&gt;HMM ,MHMM,CRF 优缺点与区别&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-降维算法" class="anchor" aria-hidden="true" href="#降维算法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;降维算法&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62470700" rel="nofollow"&gt;数据降维算法-从PCA到LargeVis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-主成分分析pca" class="anchor" aria-hidden="true" href="#主成分分析pca"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;主成分分析(PCA)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/program_developer/article/details/80632779" rel="nofollow"&gt;主成分分析（PCA）原理详解&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/hustqb/article/details/78394058" rel="nofollow"&gt;图文并茂的PCA教程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.360doc.com/content/13/1124/02/9482_331688889.shtml" rel="nofollow"&gt;PCA数学原理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-奇异值分解svd" class="anchor" aria-hidden="true" href="#奇异值分解svd"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;奇异值分解(SVD)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html" rel="nofollow"&gt;强大的矩阵奇异值分解(SVD)及其应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29846048" rel="nofollow"&gt;奇异值分解（SVD）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/zhongkejingwang/article/details/43053513" rel="nofollow"&gt;奇异值分解(SVD)原理详解及推导&lt;/a&gt;    &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/zhongkejingwang/article/details/43083603" rel="nofollow"&gt;SVD在推荐系统中的应用详解以及算法推导&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-线性判别分析lda" class="anchor" aria-hidden="true" href="#线性判别分析lda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;线性判别分析(LDA)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/42238953" rel="nofollow"&gt;教科书上的LDA为什么长这个样子？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-标签传播算法label-propagation-algorithm--" class="anchor" aria-hidden="true" href="#标签传播算法label-propagation-algorithm--"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;标签传播算法(Label Propagation Algorithm)    &lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/zouxy09/article/details/49105265" rel="nofollow"&gt;标签传播算法（Label Propagation）及Python实现&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/Semi-Supervised%20Learning%20with%20Graphs.pdf"&gt;参考资料&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-蒙塔卡罗树搜索mcts" class="anchor" aria-hidden="true" href="#蒙塔卡罗树搜索mcts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;蒙塔卡罗树搜索(MCTS)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34950988" rel="nofollow"&gt;蒙特卡洛树搜索入门指南&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-集成ensemble" class="anchor" aria-hidden="true" href="#集成ensemble"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;集成(Ensemble)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_30189255/article/details/51532442" rel="nofollow"&gt;集成学习法之bagging方法和boosting方法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/Mr_tyting/article/details/72957853" rel="nofollow"&gt;Bagging,Boosting,Stacking&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/65888174" rel="nofollow"&gt;常用的模型集成方法介绍：bagging、boosting 、stacking&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-t分布随机邻居嵌入tsne" class="anchor" aria-hidden="true" href="#t分布随机邻居嵌入tsne"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;t分布随机邻居嵌入(TSNE)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u012162613/article/details/45920827" rel="nofollow"&gt;流形学习-高维数据的降维与可视化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/flyingzhan/article/details/79521765" rel="nofollow"&gt;tSNE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-谱聚类spectral-clustering" class="anchor" aria-hidden="true" href="#谱聚类spectral-clustering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;谱聚类(Spectral Clustering)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_24519677/article/details/82291867" rel="nofollow"&gt;谱聚类（Spectral Clustering）算法介绍&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/xueyingxue001/article/details/51966980" rel="nofollow"&gt;聚类5--谱和谱聚类&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-异常点检测" class="anchor" aria-hidden="true" href="#异常点检测"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;异常点检测&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/280696035/answer/417091151" rel="nofollow"&gt;数据挖掘中常见的「异常检测」算法有哪些？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/30169110" rel="nofollow"&gt;异常点检测算法综述&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-机器学习实战篇" class="anchor" aria-hidden="true" href="#机器学习实战篇"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习实战篇&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247484110&amp;amp;idx=1&amp;amp;sn=b016e270d7b7707e6ad41a81ca45fc28&amp;amp;chksm=c0791fd7f70e96c103a8a2aebee166ce14f5648b3b889dd85dd9786f48b6b8269f11e5e27e1c&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;15分钟带你入门sklearn与机器学习——分类算法篇&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/62034592" rel="nofollow"&gt;如何为你的回归问题选择最合适的机器学习方法？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blackblog.tech/2018/02/05/%E5%8D%81%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8Bsklearn-1/" rel="nofollow"&gt;十分钟上手sklearn：安装，获取数据，数据预处理&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="http://blackblog.tech/2018/02/05/%E5%8D%81%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8Bsklearn-2/" rel="nofollow"&gt;十分钟上手sklearn：特征提取，常用模型，交叉验证&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/machinelearningmindset/machine-learning-course"&gt;Machine Learning Course with Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/c406495762/column/info/16415" rel="nofollow"&gt;Python3机器学习&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-机器学习深度学习的一些研究方向" class="anchor" aria-hidden="true" href="#机器学习深度学习的一些研究方向"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习、深度学习的一些研究方向&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-多任务学习" class="anchor" aria-hidden="true" href="#多任务学习"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;多任务学习&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27421983" rel="nofollow"&gt;模型汇总-14 多任务学习-Multitask Learning概述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cnblogs.com/shuzirank/p/7141017.html" rel="nofollow"&gt;(译)深度神经网络的多任务学习概览(An Overview of Multi-task Learning in Deep Neural Networks)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-零次学习zero-shot-learning" class="anchor" aria-hidden="true" href="#零次学习zero-shot-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;零次学习(Zero Shot Learning)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34656727" rel="nofollow"&gt;零次学习（Zero-Shot Learning）入门&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-小样本学习few-shot-learning" class="anchor" aria-hidden="true" href="#小样本学习few-shot-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;小样本学习(Few-Shot Learning)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/xhw205/article/details/79491649" rel="nofollow"&gt;few-shot learning是什么&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34656727" rel="nofollow"&gt;零次学习（Zero-Shot Learning）入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61215293" rel="nofollow"&gt;小样本学习（Few-shot Learning）综述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/few-shot-learning-in-cvpr19-6c6892fc8c5" rel="nofollow"&gt;Few-Shot Learning in CVPR 2019&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/mao_feng/article/details/78939864" rel="nofollow"&gt;当小样本遇上机器学习 fewshot learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-多视觉学习multi-view-learning" class="anchor" aria-hidden="true" href="#多视觉学习multi-view-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;多视觉学习(Multi-View Learning)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/danliwoo/article/details/79278574" rel="nofollow"&gt;Multi-view Learning 多视角学习入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/shine19930820/article/details/77426599" rel="nofollow"&gt;多视角学习 (Multi-View Learning)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-embedding" class="anchor" aria-hidden="true" href="#embedding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Embedding&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/53194407" rel="nofollow"&gt;万物皆Embedding，从经典的word2vec到深度学习基本操作item2vec&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27830489" rel="nofollow"&gt;YJango的Word Embedding--介绍&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-迁移学习" class="anchor" aria-hidden="true" href="#迁移学习"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;迁移学习&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/linolzhang/article/details/73358219" rel="nofollow"&gt;1. 迁移学习：经典算法解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/41979241" rel="nofollow"&gt;2. 什么是迁移学习 (Transfer Learning)？这个领域历史发展前景如何？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/notes/%E6%97%A5%E5%B8%B8%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/2018_4_12_%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0.pdf"&gt;3. 迁移学习个人笔记&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/XJTU_NOC_Wei/article/details/77850221" rel="nofollow"&gt;迁移学习总结(One Shot Learning, Zero Shot Learning)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-域自适应" class="anchor" aria-hidden="true" href="#域自适应"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;域自适应&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27519182" rel="nofollow"&gt;Domain Adaptation视频教程（附PPT）及经典论文分享&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27449079" rel="nofollow"&gt;模型汇总15 领域适应性Domain Adaptation、One-shot/zero-shot Learning概述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/mao_xiao_feng/article/details/54426101" rel="nofollow"&gt;【深度学习】论文导读：无监督域适应（Deep Transfer Network: Unsupervised Domain Adaptation）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/37298073" rel="nofollow"&gt;【论文阅读笔记】基于反向传播的无监督域自适应研究&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21441807" rel="nofollow"&gt;【Valse大会首发】领域自适应及其在人脸识别中的应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/41126114" rel="nofollow"&gt;CVPR 2018：基于域适应弱监督学习的目标检测&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-元学习" class="anchor" aria-hidden="true" href="#元学习"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;元学习&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35869158?group_id=970310501209645056" rel="nofollow"&gt;OpenAI提出新型元学习方法EPG，调整损失函数实现新任务上的快速训练&lt;/a&gt;      &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-强化学习" class="anchor" aria-hidden="true" href="#强化学习"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;强化学习&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25498081" rel="nofollow"&gt;强化学习（Reinforcement Learning）知识整理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34918639" rel="nofollow"&gt;强化学习从入门到放弃的资料&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25498081" rel="nofollow"&gt;强化学习入门&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25498081" rel="nofollow"&gt;强化学习入门 第一讲 MDP&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35882937" rel="nofollow"&gt;强化学习——从Q-Learning到DQN到底发生了什么？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35688924" rel="nofollow"&gt;从强化学习到深度强化学习（上）&lt;/a&gt;                  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35965070" rel="nofollow"&gt;从强化学习到深度强化学习（下）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/37048004" rel="nofollow"&gt;一文带你理解Q-Learning的搜索策略&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-推荐系统" class="anchor" aria-hidden="true" href="#推荐系统"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;推荐系统&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29969721" rel="nofollow"&gt;推荐算法相关的文档整理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58805184" rel="nofollow"&gt;Embedding从入门到专家必读的十篇论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;推荐系统之路
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650760136&amp;amp;idx=2&amp;amp;sn=afc75d6bf614bc7929b6ea9cb1abb260&amp;amp;chksm=871aa7b6b06d2ea0129ec7b06bf7b2448c3a55d485d6b80a066d622709066242fe7c925160c3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;推荐系统之路 (1)：走上推荐系统这条路&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/64722876" rel="nofollow"&gt;推荐系统之路 (2)：产品聚类&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-语义分割相关算法" class="anchor" aria-hidden="true" href="#语义分割相关算法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;语义分割相关算法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_20084101/article/details/80432960" rel="nofollow"&gt;干货 | 一文概览主要语义分割网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/iamoldpan/article/details/78799857" rel="nofollow"&gt;深度学习中IU、IoU(Intersection over Union)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/" rel="nofollow"&gt;Selective Search for Object Detection &lt;/a&gt;&lt;a href="https://blog.csdn.net/guoyunfei20/article/details/78723646" rel="nofollow"&gt;（译文）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/shuzfan/article/details/52711706" rel="nofollow"&gt;NMS——非极大值抑制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/zijin0802034/article/details/77685438" rel="nofollow"&gt;边框回归(Bounding Box Regression)详解&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-一些计划" class="anchor" aria-hidden="true" href="#一些计划"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;一些计划&lt;/h2&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 有空再整理下整个列表的结构, 再收集下深度学习和机器学习入门的系列教程, 并附以代码实现, 争取全面而简单上手&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; 本学期学完《docker_practice》&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Mikoto10032</author><guid isPermaLink="false">https://github.com/Mikoto10032/DeepLearning</guid><pubDate>Sun, 09 Feb 2020 00:15:00 GMT</pubDate></item><item><title>jeffmli/TinderAutomation #16 in Jupyter Notebook, Today</title><link>https://github.com/jeffmli/TinderAutomation</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tinderautomation" class="anchor" aria-hidden="true" href="#tinderautomation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TinderAutomation&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/tinder.png?raw=true"&gt;&lt;img src="/img/tinder.png?raw=true" alt="Alt text" title="Optional Title" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-1-introduction" class="anchor" aria-hidden="true" href="#1-introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;The other day, while I sat on the toilet to take a &lt;em&gt;poop&lt;/em&gt;, I whipped out my phone, opened up the king of all toilet apps: Tinder. I clicked open the application and started the mindless swiping. &lt;em&gt;Left&lt;/em&gt; &lt;em&gt;Right&lt;/em&gt; &lt;em&gt;Left&lt;/em&gt; &lt;em&gt;Right&lt;/em&gt; &lt;em&gt;Left&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Now that we have dating apps, everyone suddenly has access to exponentially more people to date compared to the pre-app era. The Bay Area tends to lean more men than women. The Bay Area also attracts uber-successful, smart men from all around the world. As a big-foreheaded, 5 foot 9 asian man who doesn't take many pictures, there's fierce competition within the San Francisco dating sphere.&lt;/p&gt;
&lt;p&gt;From talking to female friends using dating apps, females in San Francisco can get a match almost every other swipe. Assuming females get 20 matches in an hour, they do not have the time to go out with every man that messages them. Obviously, they'll pick the man they like most based off their profile + initial message.&lt;/p&gt;
&lt;p&gt;I'm an above-average looking guy. However, in a sea of asian men, based purely on looks, my face wouldn't pop out the page. In a stock exchange, we have buyers and sellers. The top investors earn a profit through informational advantages. At the poker table, you become profitable if you have a skill advantage over the other people on your table. If we think of dating as a "competitive marketplace", how do you give yourself the edge over the competition? A competitive advantage could be: amazing looks, career success, social-charm, adventurous, proximity, great social circle etc.&lt;/p&gt;
&lt;p&gt;On dating apps, men &amp;amp; women who have a competitive advantage in photos &amp;amp; texting skills will reap the highest ROI from the app. As a result, I've broken down the reward system from dating apps down to a formula, assuming we normalize message quality from a 0 to 1 scale:&lt;/p&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/formula.gif"&gt;&lt;img src="/img/formula.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The better photos/good looking you are you have, the less you need to write a quality message. If you have bad photos, it doesn't matter how good your message is, nobody will respond. If you have great photos, a witty message will significantly boost your ROI. If you don't do any swiping, you'll have zero ROI.&lt;/p&gt;
&lt;p&gt;While I don't have the BEST pictures, my main bottleneck is that I just don't have a high-enough swipe volume. I just think that the mindless swiping is a waste of my time and prefer to meet people in person. However, the problem with this, is that this strategy severely limits the range of people that I could date. To solve this swipe volume problem, I decided to build an AI that automates tinder called: THE DATE-A MINER.&lt;/p&gt;
&lt;p&gt;The DATE-A MINER is an artificial intelligence that learns the dating profiles I like. Once it finished learning what I like, the DATE-A MINER will automatically swipe left or right on each profile on my Tinder application. As a result, this will significantly increase swipe volume, therefore, increasing my projected Tinder ROI. Once I attain a match, the AI will automatically send a message to the matchee.&lt;/p&gt;
&lt;p&gt;While this doesn't give me a competitive advantage in photos, this does give me an advantage in swipe volume &amp;amp; initial message. Let's dive into my methodology:&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-2-data-collection" class="anchor" aria-hidden="true" href="#2-data-collection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Data Collection&lt;/h2&gt;
&lt;p&gt;To build the DATE-A MINER, I needed to feed her A LOT of images. As a result, I accessed the Tinder API using pynder. What this API allows me to do, is use Tinder through my terminal interface rather than the app:&lt;/p&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/sample_bot.png"&gt;&lt;img src="/img/sample_bot.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I wrote a script where I could swipe through each profile, and save each image to a "likes" folder or a "dislikes" folder. I spent hours and hours swiping and collected about 10,000 images.&lt;/p&gt;
&lt;p&gt;One problem I noticed, was I swiped left for about 80% of the profiles. As a result, I had about 8000 in dislikes and 2000 in the likes folder. This is a severely imbalanced dataset. Because I have such few images for the likes folder, the date-ta miner won't be well-trained to know what I like. It'll only know what I dislike.&lt;/p&gt;
&lt;p&gt;To fix this problem, I found images on google of people I found attractive. Then I scraped these images and used them within my dataset.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-3-data-pre-processing" class="anchor" aria-hidden="true" href="#3-data-pre-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. Data Pre-Processing&lt;/h2&gt;
&lt;p&gt;Now that I have the images, there are a number of problems. There is a wide range of images on Tinder. Some profiles have images with multiple friends. Some images are zoomed out. Some images are low quality. It would difficult to extract information from such a high variation of images.&lt;/p&gt;
&lt;p&gt;To solve this problem, I used a &lt;a href="https://docs.opencv.org/3.4.1/d7/d8b/tutorial_py_face_detection.html" rel="nofollow"&gt;Haars Cascade Classifier Algorithm&lt;/a&gt; to extract the faces from images and then saved it.&lt;/p&gt;
&lt;p&gt;The Algorithm failed to detect the faces for about 70% of the data. As a result, my dataset was sliced into a dataset of 3,000 images.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-4-modeling" class="anchor" aria-hidden="true" href="#4-modeling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4. Modeling&lt;/h2&gt;
&lt;p&gt;To model this data, I used a Convolutional Neural Network. Because my classification problem was extremely detailed &amp;amp; subjective, I needed an algorithm that could extract a large enough amount of features to detect a difference between the profiles I liked and disliked. A cNN was also built for image classification problems.&lt;/p&gt;
&lt;p&gt;To model this data, I used two approaches:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3-Layer Model&lt;/strong&gt;: I didn't expect the three layer model to perform very well. Whenever I build any model, my goal is to get a dumb model working first. This was my dumb model. I used a very basic architecture:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;model &lt;span class="pl-k"&gt;=&lt;/span&gt; Sequential()
model.add(Convolution2D(&lt;span class="pl-c1"&gt;32&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;relu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;input_shape&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(img_size, img_size, &lt;span class="pl-c1"&gt;3&lt;/span&gt;)))
model.add(MaxPooling2D(&lt;span class="pl-v"&gt;pool_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;,&lt;span class="pl-c1"&gt;2&lt;/span&gt;)))

model.add(Convolution2D(&lt;span class="pl-c1"&gt;32&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;relu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;))
model.add(MaxPooling2D(&lt;span class="pl-v"&gt;pool_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;,&lt;span class="pl-c1"&gt;2&lt;/span&gt;)))

model.add(Convolution2D(&lt;span class="pl-c1"&gt;64&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;relu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;))
model.add(MaxPooling2D(&lt;span class="pl-v"&gt;pool_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;,&lt;span class="pl-c1"&gt;2&lt;/span&gt;)))
          
model.add(Flatten())
model.add(Dense(&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;relu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;))
model.add(Dropout(&lt;span class="pl-c1"&gt;0.5&lt;/span&gt;))
model.add(Dense(&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;softmax&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;))

adam &lt;span class="pl-k"&gt;=&lt;/span&gt; optimizers.SGD(&lt;span class="pl-v"&gt;lr&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1e-4&lt;/span&gt;, &lt;span class="pl-v"&gt;decay&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1e-6&lt;/span&gt;, &lt;span class="pl-v"&gt;momentum&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0.9&lt;/span&gt;, &lt;span class="pl-v"&gt;nesterov&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
model.compile(&lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;categorical_crossentropy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
              &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt; adam,
              &lt;span class="pl-v"&gt;metrics&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;accuracy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The resulting accuracy was about 67%.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transfer Learning using VGG19&lt;/strong&gt;: The problem with the 3-Layer model, is that I'm training the cNN on a SUPER small dataset: 3000 images. The best performing cNN's train on millions of images.&lt;/p&gt;
&lt;p&gt;As a result, I used a technique called "Transfer Learning." Transfer learning, is basically taking a model someone else built and using it on your own data. This is usually the way to go when you have an extremely small dataset.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accuracy&lt;/strong&gt;:73% accuracy&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Precision&lt;/strong&gt; 59%&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recall:&lt;/strong&gt; 44.61%&lt;/p&gt;
&lt;p&gt;Accuracy is just predicting whether I liked or disliked the image correctly.&lt;/p&gt;
&lt;p&gt;Precision, tells us "out of all the profiles that my algorithm predicted were true, how many did I actually like?" A low precision score would mean my algorithm wouldn't be useful since most of the matches I get are profiles I don't like.&lt;/p&gt;
&lt;p&gt;Recall, tells us "out of all the profiles that I actually like, how many did the algorithm predict correctly?" If this score is low, it means the algorithm is being overly picky.&lt;/p&gt;
&lt;p&gt;You can see here the algorithm predicting on Scarlet Johansson:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/scarlet_v2.png?raw=true"&gt;&lt;img src="/img/scarlet_v2.png?raw=true" alt="Alt text" title="Optional Title" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-5-running-the-bot" class="anchor" aria-hidden="true" href="#5-running-the-bot"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;5. Running the Bot&lt;/h2&gt;
&lt;p&gt;Now that I have the algorithm built, I needed to connect it to the bot. Builting the bot wasn't too difficult. Here, you can see the bot in action:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/baetamining_bot.gif?raw=true"&gt;&lt;img src="/img/baetamining_bot.gif?raw=true" alt="Alt text" title="Optional Title" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I intentionally added a 3 to 15 second delay on each swipe so Tinder wouldn't find out that it was a bot running on my profile. Unfortunately, I did not have time to add a GUI to this program.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-6-future-work" class="anchor" aria-hidden="true" href="#6-future-work"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;6. Future Work&lt;/h2&gt;
&lt;p&gt;I gave myself only a month of part-time work to complete this project. In reality, there's an infinite number of additional things I could do:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Natural Language Processing on Profile text/interest&lt;/strong&gt;: I could extract the profile description and facebook interests and incorporate this into a scoring metric to develop more accurate swipes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Create a "total profile score"&lt;/strong&gt;: Rather than make a swipe decision off the first valid picture, I could have the algorithm look at every picture and compile the cumulative swipe decisions into one scoring metric to decide if she should swipe right or left.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;More Data&lt;/strong&gt;: I only trained on 3,000 images. If I could train on 150,000 Tinder images, I'm confident I'd have an 80-90% performing algorithm. In addition, I could also improve the facial extraction program, so I'm not losing 70% of my data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Adapt to Hinge, Coffee Meets Bagel, Bumble:&lt;/strong&gt; To widen my quantity, adapt the algorithm to hit multiple channels:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A/B Testing&lt;/strong&gt;: Having a framework to AB test different messages, profile pictures and have analytics supporting these different decisions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Google's Inception, VGG16&lt;/strong&gt;: These are different pre-trained cNN's. I wanted to try these but I ran out of time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Add GUI/Turn into a user-friendly app&lt;/strong&gt;: This would allow non-technical people to use this.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-7-installation" class="anchor" aria-hidden="true" href="#7-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;7. Installation&lt;/h2&gt;
&lt;p&gt;To install everything, follow these instructions:&lt;/p&gt;
&lt;p&gt;You must have the correct packages installed. To install the packages run the following command on the commandline:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Once you have the requirements installed, you'll need to get your FB authentication token &amp;amp; ID and store it in the &lt;code&gt;auth.json&lt;/code&gt; file. I have a script in here to extract the token called helpers.py so run that script.&lt;/p&gt;
&lt;p&gt;If you're running into issues. Read &lt;a href="https://github.com/charliewolf/pynder/issues/136"&gt;this&lt;/a&gt; to get your ID. Read &lt;a href="https://github.com/charliewolf/pynder/issues/171"&gt;this&lt;/a&gt; to get your Token. If you really have trouble, you can message me.&lt;/p&gt;
&lt;p&gt;If you want to use the model trained on my female preferences, you can now just run &lt;code&gt;bot.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you want to train your own model, there are additional steps you'll need to follow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Use img_scrape.py to access Tinder through your terminal. When running the program, press 1 to dislike or 2 to like. Do this for thousands of images.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once you have your dataset, run &lt;code&gt;prepare_data.ipynb&lt;/code&gt; to extract the faces from the images. Save as a numpy file. Aim for 3000 use-able images for decent performance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I wouldn't recommend training the cNN on your PC. You'll need to start a deep learning server using AWS or Google Cloud. On AWS, I used the Deep Learning AMI t2.medium.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once you're done training, you need to export your model as an h5 file. Transport this h5 file into the bot. Within &lt;code&gt;bot.py&lt;/code&gt;, find the &lt;code&gt;load_model()&lt;/code&gt; function and plug the name of your file into that functino.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Voila, you should be good to go!&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jeffmli</author><guid isPermaLink="false">https://github.com/jeffmli/TinderAutomation</guid><pubDate>Sun, 09 Feb 2020 00:16:00 GMT</pubDate></item><item><title>maplezzz/NTU_ML2017_Hung-yi-Lee_HW #17 in Jupyter Notebook, Today</title><link>https://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HW</link><description>&lt;p&gt;&lt;i&gt;NTU ML2017 Spring and Fall Homework Hung-yi_Li 李宏毅老师 机器学习课程作业&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-ml2017sf_hung-yi-lee_hw" class="anchor" aria-hidden="true" href="#ml2017sf_hung-yi-lee_hw"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ML2017S+F_Hung-yi-Lee_HW&lt;/h1&gt;
&lt;p&gt;NTU ML2017 Spring and Fall Homework Hung-yi_Li 李宏毅老师&lt;/p&gt;
&lt;p&gt;&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17.html" title="NTU ML17S" rel="nofollow"&gt;&lt;strong&gt;2017SCourse Website&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17_2.html" title="NTU ML17F" rel="nofollow"&gt;&lt;strong&gt;2017FCourse Website&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NTU Mechine Learning 2017 Spring and Fall total Homework&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/maplezzz/ML2017S_Hung-yi-Lee_HW/tree/master/HW0"&gt;HW0 Prerequisite&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;矩阵乘法&lt;/li&gt;
&lt;li&gt;图像提取&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/maplezzz/ML2017S_Hung-yi-Lee_HW/tree/master/HW1"&gt;HW1 PM2.5 Prediction&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;linear regression&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/maplezzz/ML2017S_Hung-yi-Lee_HW/tree/master/HW2"&gt;HW2 Income Prediction&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;logestic regression&lt;/li&gt;
&lt;li&gt;probabilistic generative model&lt;/li&gt;
&lt;li&gt;keras&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/maplezzz/ML2017S_Hung-yi-Lee_HW/tree/master/HW3"&gt;HW3 Image Sentiment Classification&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Convolution Neural Network&lt;/li&gt;
&lt;li&gt;Deep Neural Network&lt;/li&gt;
&lt;li&gt;Confusion Matrix&lt;/li&gt;
&lt;li&gt;Saliency Map&lt;/li&gt;
&lt;li&gt;Visualizing Filters&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/maplezzz/ML2017S_Hung-yi-Lee_HW/tree/master/HW4"&gt;HW4 Text Sentiment Classification&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Processing the Sentence&lt;/li&gt;
&lt;li&gt;Word Embedding&lt;/li&gt;
&lt;li&gt;Semi-Supervised learning&lt;/li&gt;
&lt;li&gt;RNN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>maplezzz</author><guid isPermaLink="false">https://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HW</guid><pubDate>Sun, 09 Feb 2020 00:17:00 GMT</pubDate></item><item><title>jakevdp/PythonDataScienceHandbook #18 in Jupyter Notebook, Today</title><link>https://github.com/jakevdp/PythonDataScienceHandbook</link><description>&lt;p&gt;&lt;i&gt;Python Data Science Handbook: full text in Jupyter Notebooks&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-python-data-science-handbook" class="anchor" aria-hidden="true" href="#python-data-science-handbook"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python Data Science Handbook&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://mybinder.org/v2/gh/jakevdp/PythonDataScienceHandbook/master?filepath=notebooks%2FIndex.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repository contains the entire &lt;a href="http://shop.oreilly.com/product/0636920034919.do" rel="nofollow"&gt;Python Data Science Handbook&lt;/a&gt;, in the form of (free!) Jupyter notebooks.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="notebooks/figures/PDSH-cover.png"&gt;&lt;img src="notebooks/figures/PDSH-cover.png" alt="cover image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-use-this-book" class="anchor" aria-hidden="true" href="#how-to-use-this-book"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to Use this Book&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Read the book in its entirety online at &lt;a href="https://jakevdp.github.io/PythonDataScienceHandbook/" rel="nofollow"&gt;https://jakevdp.github.io/PythonDataScienceHandbook/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the code using the Jupyter notebooks available in this repository's &lt;a href="notebooks"&gt;notebooks&lt;/a&gt; directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Launch executable versions of these notebooks using &lt;a href="http://colab.research.google.com" rel="nofollow"&gt;Google Colab&lt;/a&gt;: &lt;a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Launch a live notebook server with these notebooks using &lt;a href="https://beta.mybinder.org/" rel="nofollow"&gt;binder&lt;/a&gt;: &lt;a href="https://mybinder.org/v2/gh/jakevdp/PythonDataScienceHandbook/master?filepath=notebooks%2FIndex.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Buy the printed book through &lt;a href="http://shop.oreilly.com/product/0636920034919.do" rel="nofollow"&gt;O'Reilly Media&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-about" class="anchor" aria-hidden="true" href="#about"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About&lt;/h2&gt;
&lt;p&gt;The book was written and tested with Python 3.5, though other Python versions (including Python 2.7) should work in nearly all cases.&lt;/p&gt;
&lt;p&gt;The book introduces the core libraries essential for working with data in Python: particularly &lt;a href="http://ipython.org" rel="nofollow"&gt;IPython&lt;/a&gt;, &lt;a href="http://numpy.org" rel="nofollow"&gt;NumPy&lt;/a&gt;, &lt;a href="http://pandas.pydata.org" rel="nofollow"&gt;Pandas&lt;/a&gt;, &lt;a href="http://matplotlib.org" rel="nofollow"&gt;Matplotlib&lt;/a&gt;, &lt;a href="http://scikit-learn.org" rel="nofollow"&gt;Scikit-Learn&lt;/a&gt;, and related packages.
Familiarity with Python as a language is assumed; if you need a quick introduction to the language itself, see the free companion project,
&lt;a href="https://github.com/jakevdp/WhirlwindTourOfPython"&gt;A Whirlwind Tour of Python&lt;/a&gt;: it's a fast-paced introduction to the Python language aimed at researchers and scientists.&lt;/p&gt;
&lt;p&gt;See &lt;a href="http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;Index.ipynb&lt;/a&gt; for an index of the notebooks available to accompany the text.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-software" class="anchor" aria-hidden="true" href="#software"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Software&lt;/h2&gt;
&lt;p&gt;The code in the book was tested with Python 3.5, though most (but not all) will also work correctly with Python 2.7 and other older Python versions.&lt;/p&gt;
&lt;p&gt;The packages I used to run the code in the book are listed in &lt;a href="requirements.txt"&gt;requirements.txt&lt;/a&gt; (Note that some of these exact version numbers may not be available on your platform: you may have to tweak them for your own use).
To install the requirements using &lt;a href="http://conda.pydata.org" rel="nofollow"&gt;conda&lt;/a&gt;, run the following at the command-line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda install --file requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To create a stand-alone environment named &lt;code&gt;PDSH&lt;/code&gt; with Python 3.5 and all the required package versions, run the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda create -n PDSH python=3.5 --file requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can read more about using conda environments in the &lt;a href="http://conda.pydata.org/docs/using/envs.html" rel="nofollow"&gt;Managing Environments&lt;/a&gt; section of the conda documentation.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-code" class="anchor" aria-hidden="true" href="#code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code&lt;/h3&gt;
&lt;p&gt;The code in this repository, including all code samples in the notebooks listed above, is released under the &lt;a href="LICENSE-CODE"&gt;MIT license&lt;/a&gt;. Read more at the &lt;a href="https://opensource.org/licenses/MIT" rel="nofollow"&gt;Open Source Initiative&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-text" class="anchor" aria-hidden="true" href="#text"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Text&lt;/h3&gt;
&lt;p&gt;The text content of the book is released under the &lt;a href="LICENSE-TEXT"&gt;CC-BY-NC-ND license&lt;/a&gt;. Read more at &lt;a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode" rel="nofollow"&gt;Creative Commons&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jakevdp</author><guid isPermaLink="false">https://github.com/jakevdp/PythonDataScienceHandbook</guid><pubDate>Sun, 09 Feb 2020 00:18:00 GMT</pubDate></item><item><title>jessevig/bertviz #19 in Jupyter Notebook, Today</title><link>https://github.com/jessevig/bertviz</link><description>&lt;p&gt;&lt;i&gt;Tool for visualizing attention in the Transformer model (BERT, GPT-2, Albert, XLNet, RoBERTa, CTRL, etc.)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-bertviz" class="anchor" aria-hidden="true" href="#bertviz"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;BertViz&lt;/h1&gt;
&lt;p&gt;BertViz is a tool for visualizing attention in the Transformer model, supporting all models from the &lt;a href="https://github.com/huggingface/transformers"&gt;transformers&lt;/a&gt; library (BERT, GPT-2, XLNet, RoBERTa, XLM, CTRL, etc.). It extends the &lt;a href="https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/visualization"&gt;Tensor2Tensor visualization tool&lt;/a&gt; by &lt;a href="https://medium.com/@llionj" rel="nofollow"&gt;Llion Jones&lt;/a&gt; and the &lt;a href="https://github.com/huggingface/transformers"&gt;transformers&lt;/a&gt; library from &lt;a href="https://github.com/huggingface"&gt;HuggingFace&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Blog posts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1" rel="nofollow"&gt;Deconstructing BERT, Part 2: Visualizing the Inner Workings of Attention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/openai-gpt-2-understanding-language-generation-through-visualization-8252f683b2f8" rel="nofollow"&gt;OpenAI GPT-2: Understanding Language Generation through Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/deconstructing-bert-distilling-6-patterns-from-100-million-parameters-b49113672f77" rel="nofollow"&gt;Deconstructing BERT: Distilling 6 Patterns from 100 Million Parameters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Paper:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1906.05714.pdf" rel="nofollow"&gt;A Multiscale Visualization of Attention in the Transformer Model&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-attention-head-view" class="anchor" aria-hidden="true" href="#attention-head-view"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Attention-head view&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;attention-head view&lt;/em&gt; visualizes the attention patterns produced by one or more attention heads in a given transformer layer.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_left.png"&gt;&lt;img src="https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_left.png" alt="Attention-head view" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_right.gif"&gt;&lt;img src="https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_right.gif" alt="Attention-head view animated" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The attention view supports all models from the Transformers library, including:&lt;br&gt;
BERT:
&lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_bert.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1PEHWRHrvxQvYr9NFRC-E_fr3xDq1htCj" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
GPT-2:
&lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_gpt2.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1c9kBsbvSqpKkmd62u7nfqVhvWr0W8_Lx" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
XLNet: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_xlnet.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
RoBERTa: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_roberta.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
XLM: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_xlm.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
Albert: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_albert.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
DistilBert: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_distilbert.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
(and others)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-model-view" class="anchor" aria-hidden="true" href="#model-view"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model view&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;model view&lt;/em&gt; provides a birds-eye view of attention across all of the model’s layers  and heads.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jessevig/bertviz/master/images/model_thumbnail.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jessevig/bertviz/master/images/model_thumbnail.jpg" alt="Model view" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The model view supports all models from the Transformers library, including:&lt;br&gt;
BERT: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_bert.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1c73DtKNdl66B0_HF7QXuPenraDp0jHRS" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
GPT2: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_gpt2.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1y-wfC95Z0aASawYqA34LQeV0_qC9mOto" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
XLNet: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_xlnet.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
RoBERTa: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_roberta.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
XLM: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_xlm.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
Albert: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_albert.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
DistilBert: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_distilbert.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
(and others)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-neuron-view" class="anchor" aria-hidden="true" href="#neuron-view"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Neuron view&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;neuron view&lt;/em&gt; visualizes the individual neurons in the query and key vectors and shows how they are used to compute attention.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jessevig/bertviz/master/images/neuron_thumbnail.png"&gt;&lt;img src="https://raw.githubusercontent.com/jessevig/bertviz/master/images/neuron_thumbnail.png" alt="Neuron view" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The neuron view supports the following three models:&lt;br&gt;
BERT: &lt;a href="https://github.com/jessevig/bertviz/blob/master/neuron_view_bert.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1m37iotFeubMrp9qIf9yscXEL1zhxTN2b" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
GPT-2
&lt;a href="https://github.com/jessevig/bertviz/blob/master/neuron_view_gpt2.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1s8XCCyxsKvNRWNzjWi5Nl8ZAYZ5YkLm_" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
RoBERTa
&lt;a href="https://github.com/jessevig/bertviz/blob/master/neuron_view_roberta.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/transformers/" rel="nofollow"&gt;Transformers&lt;/a&gt; (version required depends on models used)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pytorch.org/" rel="nofollow"&gt;PyTorch&lt;/a&gt; &amp;gt;=1.0.0&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jupyter.org/install" rel="nofollow"&gt;Jupyter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/tqdm/" rel="nofollow"&gt;tqdm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/boto3/" rel="nofollow"&gt;boto3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/ipython/" rel="nofollow"&gt;IPython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/requests/" rel="nofollow"&gt;requests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/regex/" rel="nofollow"&gt;regex&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/sentencepiece/" rel="nofollow"&gt;sentencepiece&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(See &lt;a href="https://github.com/jessevig/bertviz/blob/master/requirements.txt"&gt;requirements.txt&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-execution" class="anchor" aria-hidden="true" href="#execution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Execution&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/jessevig/bertviz.git
cd bertviz
jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;NOTE: If you wish to run BertViz using Colab, please see the example Colab scripts above, as they differ slightly from the Jupyter notebook versions.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authors&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://twitter.com/jesse_vig" rel="nofollow"&gt;Jesse Vig&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;When referencing BertViz, please cite &lt;a href="https://arxiv.org/abs/1906.05714" rel="nofollow"&gt;this paper&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{vig2019transformervis,
  author    = {Jesse Vig},
  title     = {A Multiscale Visualization of Attention in the Transformer Model},
  journal   = {arXiv preprint arXiv:1906.05714},
  year      = {2019},
  url       = {https://arxiv.org/abs/1906.05714}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href="LICENSE"&gt;LICENSE&lt;/a&gt; file for details&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;This project incorporates code from the following repos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tensor2tensor"&gt;https://github.com/tensorflow/tensor2tensor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT"&gt;https://github.com/huggingface/pytorch-pretrained-BERT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jessevig</author><guid isPermaLink="false">https://github.com/jessevig/bertviz</guid><pubDate>Sun, 09 Feb 2020 00:19:00 GMT</pubDate></item><item><title>blue-yonder/tsfresh #20 in Jupyter Notebook, Today</title><link>https://github.com/blue-yonder/tsfresh</link><description>&lt;p&gt;&lt;i&gt;Automatic extraction of relevant features from time series:&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://tsfresh.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/36acd223668ed9b8757d4b53b31463c5052e705f/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f747366726573682f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/tsfresh/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.org/blue-yonder/tsfresh" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9d7ac3b7a4be38dda0e1acb1e2df0a452e132ab8/68747470733a2f2f7472617669732d63692e6f72672f626c75652d796f6e6465722f747366726573682e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/blue-yonder/tsfresh.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://coveralls.io/github/blue-yonder/tsfresh?branch=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d600de5532fa69596b8e6c08d848381f3d1fae78/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f626c75652d796f6e6465722f747366726573682f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/blue-yonder/tsfresh/badge.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/blue-yonder/tsfresh/blob/master/LICENSE.txt"&gt;&lt;img src="https://camo.githubusercontent.com/b0224997019dec4e51d692c722ea9bee2818c837/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6173686170652f6170697374617475732e737667" alt="license" data-canonical-src="https://img.shields.io/github/license/mashape/apistatus.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/tsfresh/Lobby?utm_source=share-link&amp;amp;utm_medium=link&amp;amp;utm_campaign=share-link" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e3f3756ed14ab89e92954154ae3210ee867e5bf3/68747470733a2f2f6261646765732e6769747465722e696d2f747366726573682f4c6f6262792e737667" alt="Gitter chat" data-canonical-src="https://badges.gitter.im/tsfresh/Lobby.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/blue-yonder/tsfresh/issues/8"&gt;&lt;img src="https://camo.githubusercontent.com/848b334aabca64e10f1535e7b6a8dd952a025db0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e332e352e322d737570706f727465642d677265656e2e737667" alt="py352 status" data-canonical-src="https://img.shields.io/badge/python3.5.2-supported-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://mybinder.org/v2/gh/blue-yonder/tsfresh/master?filepath=notebooks" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pepy.tech/project/tsfresh" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5e21bea1727201bd2b3270bd63d7d29796444bb9/68747470733a2f2f706570792e746563682f62616467652f74736672657368" alt="Downloads" data-canonical-src="https://pepy.tech/badge/tsfresh" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-tsfresh" class="anchor" aria-hidden="true" href="#tsfresh"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;tsfresh&lt;/h1&gt;
&lt;p&gt;This repository contains the &lt;em&gt;TSFRESH&lt;/em&gt; python package. The abbreviation stands for&lt;/p&gt;
&lt;p&gt;&lt;em&gt;"Time Series Feature extraction based on scalable hypothesis tests"&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The package contains many feature extraction methods and a robust feature selection algorithm.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-spend-less-time-on-feature-engineering" class="anchor" aria-hidden="true" href="#spend-less-time-on-feature-engineering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spend less time on feature engineering&lt;/h2&gt;
&lt;p&gt;Data Scientists often spend most of their time either cleaning data or building features.
While we cannot change the first thing, the second can be automated.
&lt;em&gt;TSFRESH&lt;/em&gt; frees your time spent on building features by extracting them automatically.
Hence, you have more time to study the newest deep learning paper, read hacker news or build better models.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-automatic-extraction-of-100s-of-features" class="anchor" aria-hidden="true" href="#automatic-extraction-of-100s-of-features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Automatic extraction of 100s of features&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;TSFRESH&lt;/em&gt; automatically extracts 100s of features from time series.
Those features describe basic characteristics of the time series such as the number of peaks, the average or maximal value or more complex features such as the time reversal symmetry statistic.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="docs/images/introduction_ts_exa_features.png"&gt;&lt;img src="docs/images/introduction_ts_exa_features.png" alt="The features extracted from a exemplary time series" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The set of features can then be used to construct statistical or machine learning models on the time series to be used for example in regression or
classification tasks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-forget-irrelevant-features" class="anchor" aria-hidden="true" href="#forget-irrelevant-features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Forget irrelevant features&lt;/h2&gt;
&lt;p&gt;Time series often contain noise, redundancies or irrelevant information.
As a result most of the extracted features will not be useful for the machine learning task at hand.&lt;/p&gt;
&lt;p&gt;To avoid extracting irrelevant features, the &lt;em&gt;TSFRESH&lt;/em&gt; package has a built-in filtering procedure.
This filtering procedure evaluates the explaining power and importance of each characteristic for the regression or classification tasks at hand.&lt;/p&gt;
&lt;p&gt;It is based on the well developed theory of hypothesis testing and uses a multiple test procedure.
As a result the filtering process mathematically controls the percentage of irrelevant extracted features.&lt;/p&gt;
&lt;p&gt;The  &lt;em&gt;TSFRESH&lt;/em&gt; package is described in the following open access paper&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Christ, M., Braun, N., Neuffer, J. and Kempa-Liehr A.W. (2018).
&lt;em&gt;Time Series FeatuRe Extraction on basis of Scalable Hypothesis tests (tsfresh -- A Python package).&lt;/em&gt;
Neurocomputing 307 (2018) 72-77, &lt;a href="https://doi.org/10.1016/j.neucom.2018.03.067" rel="nofollow"&gt;doi:10.1016/j.neucom.2018.03.067&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The FRESH algorithm is described in the following whitepaper&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Christ, M., Kempa-Liehr, A.W. and Feindt, M. (2017).&lt;br&gt;
&lt;em&gt;Distributed and parallel time series feature extraction for industrial big data applications.&lt;/em&gt;&lt;br&gt;
ArXiv e-print 1610.07717,  &lt;a href="https://arxiv.org/abs/1610.07717" rel="nofollow"&gt;https://arxiv.org/abs/1610.07717&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-advantages-of-tsfresh" class="anchor" aria-hidden="true" href="#advantages-of-tsfresh"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Advantages of tsfresh&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;TSFRESH&lt;/em&gt; has several selling points, for example&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;it is field tested&lt;/li&gt;
&lt;li&gt;it is unit tested&lt;/li&gt;
&lt;li&gt;the filtering process is statistically/mathematically correct&lt;/li&gt;
&lt;li&gt;it has a comprehensive documentation&lt;/li&gt;
&lt;li&gt;it is compatible with sklearn, pandas and numpy&lt;/li&gt;
&lt;li&gt;it allows anyone to easily add their favorite features&lt;/li&gt;
&lt;li&gt;it both runs on your local machine or even on a cluster&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-next-steps" class="anchor" aria-hidden="true" href="#next-steps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Next steps&lt;/h2&gt;
&lt;p&gt;If you are interested in the technical workings, go to see our comprehensive Read-The-Docs documentation at &lt;a href="http://tsfresh.readthedocs.io" rel="nofollow"&gt;http://tsfresh.readthedocs.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The algorithm, especially the filtering part are also described in the paper mentioned above.&lt;/p&gt;
&lt;p&gt;If you have some questions or feedback you can find the developers in the &lt;a href="https://gitter.im/tsfresh/Lobby?utm_source=share-link&amp;amp;utm_medium=link&amp;amp;utm_campaign=share-link" rel="nofollow"&gt;gitter chatroom.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We appreciate any contributions, if you are interested in helping us to make &lt;em&gt;TSFRESH&lt;/em&gt; the biggest archive of feature extraction methods in python, just head over to our &lt;a href="http://tsfresh.readthedocs.io/en/latest/text/how_to_contribute.html" rel="nofollow"&gt;How-To-Contribute&lt;/a&gt; instructions.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;The research and development of &lt;em&gt;TSFRESH&lt;/em&gt; was funded in part by the German Federal Ministry of Education and Research under grant number 01IS14004 (project iPRODICT).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>blue-yonder</author><guid isPermaLink="false">https://github.com/blue-yonder/tsfresh</guid><pubDate>Sun, 09 Feb 2020 00:20:00 GMT</pubDate></item><item><title>AllenDowney/ThinkDSP #21 in Jupyter Notebook, Today</title><link>https://github.com/AllenDowney/ThinkDSP</link><description>&lt;p&gt;&lt;i&gt;Think DSP: Digital Signal Processing in Python, by Allen B. Downey.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-thinkdsp" class="anchor" aria-hidden="true" href="#thinkdsp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ThinkDSP&lt;/h1&gt;
&lt;p&gt;LaTeX source and Python code for &lt;em&gt;Think DSP: Digital Signal Processing in Python&lt;/em&gt;, by Allen B. Downey.&lt;/p&gt;
&lt;p&gt;The premise of this book (and the other books in the &lt;em&gt;Think X&lt;/em&gt; series) is that if you know how to program,
you can use that skill to learn other things.  I am writing this book because I think the conventional
approach to digital signal processing is backward: most books (and the classes that use them) present
the material bottom-up, starting with mathematical abstractions like phasors.&lt;/p&gt;
&lt;p&gt;With a programming-based approach, I can go top-down, which means I can present the most important
ideas right away.  By the end of the first chapter, you can break down a sound into its harmonics, modify the harmonics, and generate new sounds.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-running-the-code" class="anchor" aria-hidden="true" href="#running-the-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running the code&lt;/h2&gt;
&lt;p&gt;Most of the code for this book is in Jupyter notebooks.
If you are not familiar with Jupyter, you can run a tutorial by &lt;a href="https://jupyter.org/try" rel="nofollow"&gt;clicking here&lt;/a&gt;.  Then select "Try Classic Notebook".  It will open a notebook with instructions for getting started.&lt;/p&gt;
&lt;p&gt;To run the ThinkDSP code, you have two options:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The simplest option is to run the code on Binder.  The drawback is that the notebooks run in a temporary environment; if you leave a notebook idle for a while, the temporary environment goes away and you lose any changes you made.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The other option is to install Python, Jupyter, and the other packages you need on your computer, and download my code from GitHub.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following two sections explain these options in detail.&lt;/p&gt;
&lt;p&gt;Note: I have heard from a few people who tried to run the code in Spyder.  Apparently there were problems, so I don't recommend it.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-option-1-run-on-binder" class="anchor" aria-hidden="true" href="#option-1-run-on-binder"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 1: Run on Binder&lt;/h3&gt;
&lt;p&gt;To run the code for this book on Binder, press this button:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://mybinder.org/repo/AllenDowney/ThinkDSP" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/70c5b4d050d4019f4f20b170d75679a9316ac5e5/687474703a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="http://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It takes a minute or so to start up, but then you should see the Jupyter home page with a list of files.  Click on &lt;code&gt;code&lt;/code&gt; to open the folder with the notebooks, then click on one of the notebooks (with the .ipynb extension).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-option-2-install-pythonjupyter" class="anchor" aria-hidden="true" href="#option-2-install-pythonjupyter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 2: Install Python+Jupyter&lt;/h3&gt;
&lt;p&gt;First, download the files from this repository.  If you are a Git user, you can run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone --depth 1 https://github.com/AllenDowney/ThinkDSP.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Otherwise you can &lt;a href="https://github.com/AllenDowney/ThinkDSP/archive/master.zip"&gt;download this Zip file&lt;/a&gt; and unzip it.
Either way, you should end up with a directory called &lt;code&gt;ThinkDSP&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now, if you don't already have Jupyter, I highly recommend installing Anaconda, which is a Python distribution that contains everything you need to run the ThinkDSP code.  It is easy to install on Windows, Mac, and Linux, and because it does a
user-level install, it will not interfere with other Python installations.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.anaconda.com/distribution/" rel="nofollow"&gt;Information about installing Anaconda is here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have the choice of Python 2 or 3, choose 3.&lt;/p&gt;
&lt;p&gt;There are two ways to get the packages you need for ThinkDSP.  You can install them by hand or create a Conda environment.&lt;/p&gt;
&lt;p&gt;To install them by hand run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install jupyter numpy scipy pandas matplotlib seaborn
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or, to create a conda environment, run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd ThinkDSP
conda env create -f environment.yml
conda activate ThinkDSP
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To start Jupyter, run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Jupyter should launch your default browser or open a tab in an existing browser window.
If not, the Jupyter server should print a URL you can use.  For example, when I launch Jupyter, I get&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~/ThinkComplexity2$ jupyter notebook
[I 10:03:20.115 NotebookApp] Serving notebooks from local directory: /home/downey/ThinkDSP
[I 10:03:20.115 NotebookApp] 0 active kernels
[I 10:03:20.115 NotebookApp] The Jupyter Notebook is running at: http://localhost:8888/
[I 10:03:20.115 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case, the URL is &lt;a href="http://localhost:8888" rel="nofollow"&gt;http://localhost:8888&lt;/a&gt;.&lt;br&gt;
When you start your server, you might get a different URL.
Whatever it is, if you paste it into a browser, you should should see a home page with a list of directories.&lt;/p&gt;
&lt;p&gt;Click on &lt;code&gt;code&lt;/code&gt; to open the folder with the notebooks, then click on one of the notebooks (with the .ipynb extension).&lt;/p&gt;
&lt;p&gt;Select the cell with the import statements and press "Shift-Enter" to run the code in the cell.
If it works and you get no error messages, &lt;strong&gt;you are all set&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If you get error messages about missing packages, you can install the packages you need using your
package manager, or install Anaconda.&lt;/p&gt;
&lt;p&gt;If you run into problems with these instructions, let me know and I will make corrections.  Good luck!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-freesound" class="anchor" aria-hidden="true" href="#freesound"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Freesound&lt;/h2&gt;
&lt;p&gt;Special thanks to Freesound (&lt;a href="http://freesound.org" rel="nofollow"&gt;http://freesound.org&lt;/a&gt;), which is the source of many of the
sound samples I use in this book, and to the Freesound users who
uploaded those sounds.  I include some of their wave files in
the GitHub repository for this book, using the original file
names, so it should be easy to find their sources.&lt;/p&gt;
&lt;p&gt;Unfortunately, most Freesound users don't make their real names
available, so I can only thank them using their user names.  Samples
used in this book were contributed by Freesound users: iluppai,
wcfl10, thirsk, docquesting, kleeb, landup, zippi1, themusicalnomad,
bcjordan, rockwehrmann, marchascon7, jcveliz.  Thank you all!&lt;/p&gt;
&lt;p&gt;Here are links to the sources:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/iluppai/sounds/100475/" rel="nofollow"&gt;http://www.freesound.org/people/iluppai/sounds/100475/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/wcfl10/sounds/105977/" rel="nofollow"&gt;http://www.freesound.org/people/wcfl10/sounds/105977/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/Thirsk/sounds/120994/" rel="nofollow"&gt;http://www.freesound.org/people/Thirsk/sounds/120994/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/ciccarelli/sounds/132736/" rel="nofollow"&gt;http://www.freesound.org/people/ciccarelli/sounds/132736/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/Kleeb/sounds/180960/" rel="nofollow"&gt;http://www.freesound.org/people/Kleeb/sounds/180960/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/zippi1/sounds/18871/" rel="nofollow"&gt;http://www.freesound.org/people/zippi1/sounds/18871/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/themusicalnomad/sounds/253887/" rel="nofollow"&gt;http://www.freesound.org/people/themusicalnomad/sounds/253887/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/bcjordan/sounds/28042/" rel="nofollow"&gt;http://www.freesound.org/people/bcjordan/sounds/28042/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/rockwehrmann/sounds/72475/" rel="nofollow"&gt;http://www.freesound.org/people/rockwehrmann/sounds/72475/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/marcgascon7/sounds/87778/" rel="nofollow"&gt;http://www.freesound.org/people/marcgascon7/sounds/87778/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/jcveliz/sounds/92002/" rel="nofollow"&gt;http://www.freesound.org/people/jcveliz/sounds/92002/&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>AllenDowney</author><guid isPermaLink="false">https://github.com/AllenDowney/ThinkDSP</guid><pubDate>Sun, 09 Feb 2020 00:21:00 GMT</pubDate></item><item><title>kavgan/nlp-in-practice #22 in Jupyter Notebook, Today</title><link>https://github.com/kavgan/nlp-in-practice</link><description>&lt;p&gt;&lt;i&gt;NLP, Text Mining and Machine Learning starter code to solve real world text data problems. Includes: Gensim Word2Vec, phrase embeddings, keyword extraction with TFIDF,  Text Classification with Logistic Regression, word count with pyspark, simple text preprocessing, pre-trained embeddings and more.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-nlp-in-practice" class="anchor" aria-hidden="true" href="#nlp-in-practice"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NLP-IN-PRACTICE&lt;/h1&gt;
&lt;p&gt;Use these NLP, Text Mining and Machine Learning code samples and tools to solve real world text data problems.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-notebooks--source" class="anchor" aria-hidden="true" href="#notebooks--source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notebooks / Source&lt;/h2&gt;
&lt;p&gt;Links in the first column take you to the subfolder/repository with the source code.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Task&lt;/th&gt;
&lt;th&gt;Related Article&lt;/th&gt;
&lt;th&gt;Source Type&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/kavgan/phrase-at-scale"&gt;Large Scale Phrase Extraction&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/how-to-generate-phrase-embeddings-using-word2vec-in-3-easy-steps/" rel="nofollow"&gt;phrase2vec article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;python script&lt;/td&gt;
&lt;td&gt;Extract phrases for large amounts of data using PySpark. Annotate text using these phrases or use the phrases for other downstream tasks.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/kavgan/word_cloud"&gt;Word Cloud for Jupyter Notebook and Python Web Apps &lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/word-cloud-for-data-scientists/#.W867cBNKj65" rel="nofollow"&gt;word_cloud article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;python script + notebook&lt;/td&gt;
&lt;td&gt;Visualize top keywords using word counts or tfidf&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="word2vec/"&gt;Gensim Word2Vec (with dataset)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/" rel="nofollow"&gt;word2vec article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;How to work correctly with Word2Vec to get desired results&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="spark_wordcount/"&gt;Reading files and word count with Spark&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/reading-csv-and-json-files-in-spark/" rel="nofollow"&gt;spark article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;python script&lt;/td&gt;
&lt;td&gt;How to read files of different formats using PySpark with a word count example&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="tf-idf"&gt;Extracting Keywords with TF-IDF and SKLearn (with dataset)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/extracting-keywords-from-text-with-tf-idf-and-pythons-scikit-learn/#.W2TlD9hKhhE" rel="nofollow"&gt;tfidf article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;How to extract interesting keywords from text using TF-IDF and Python's SKLEARN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="text-pre-processing"&gt;Text Preprocessing&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/getting-started-with-text-preprocessing/#.XHa4-ZNKhuU" rel="nofollow"&gt;text preprocessing article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;A few code snippets on how to perform text preprocessing. Includes stemming, noise removal, lemmatization and stop word removal.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="tfidftransformer/"&gt;TFIDFTransformer vs. TFIDFVectorizer&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/how-to-use-tfidftransformer-tfidfvectorizer-and-whats-the-difference/" rel="nofollow"&gt;tfidftransformer and tfidfvectorizer usage article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;How to use TFIDFTransformer and TFIDFVectorizer correctly and the difference between the two and what to use when.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="pre-trained-embeddings/"&gt;Accessing Pre-trained Word Embeddings with Gensim&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/easily-access-pre-trained-word-embeddings-with-gensim/#.XQCYP9NKhhE" rel="nofollow"&gt;Pre-trained word embeddings article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;How to access pre-trained GloVe and Word2Vec Embeddings using Gensim and an example of how these embeddings can be leveraged for text similarity&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="text-classification/"&gt;Text Classification in Python (with news dataset)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://kavita-ganesan.com/news-classifier-with-logistic-regression-in-python/#.XT95_5NKhgc" rel="nofollow"&gt;Text classification with Logistic Regression article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;Get started with text classification. Learn how to build and evaluate a text classifier for news classification using Logistic Regression.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="CountVectorizer/"&gt;CountVectorizer Usage Examples&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://kavita-ganesan.com/how-to-use-countvectorizer/#.XeqMhpNKhhE" rel="nofollow"&gt;How to Correctly Use CountVectorizer? An In-Depth Look article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;Learn how to maximize the use of CountVectorizer such that you are not just computing counts of words, but also preprocessing your text data appropriately as well as extracting additional features from your text dataset.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-notes" class="anchor" aria-hidden="true" href="#notes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notes&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;For more articles, please &lt;a href="http://kavita-ganesan.com/kavitas-tutorials/#.WvIizNMvyog" rel="nofollow"&gt;see this list&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If you would like to receive articles via email &lt;a href="https://kavita-ganesan.com/subscribe/#.XTThjZNKhgc" rel="nofollow"&gt;subscribe to my mailing list&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h1&gt;
&lt;p&gt;This repository is maintained by &lt;a href="https://kavita-ganesan.com/about-me/#.XTTh6ZNKhgc" rel="nofollow"&gt;Kavita Ganesan&lt;/a&gt;. Connect with me on &lt;a href="https://www.linkedin.com/in/kavita-ganesan/" rel="nofollow"&gt;LinkedIn&lt;/a&gt; or &lt;a href="https://twitter.com/kav_gan" rel="nofollow"&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>kavgan</author><guid isPermaLink="false">https://github.com/kavgan/nlp-in-practice</guid><pubDate>Sun, 09 Feb 2020 00:22:00 GMT</pubDate></item><item><title>NLP-LOVE/ML-NLP #23 in Jupyter Notebook, Today</title><link>https://github.com/NLP-LOVE/ML-NLP</link><description>&lt;p&gt;&lt;i&gt;此项目是机器学习(Machine Learning)、深度学习(Deep Learning)、NLP面试中常考到的知识点和代码实现，也是作为一个算法工程师必会的理论基础知识。&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-项目介绍" class="anchor" aria-hidden="true" href="#项目介绍"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目介绍&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;此项目是&lt;strong&gt;机器学习、NLP面试&lt;/strong&gt;中常考到的&lt;strong&gt;知识点和代码实现&lt;/strong&gt;，也是作为一个算法工程师必会的理论基础知识。&lt;/li&gt;
&lt;li&gt;既然是以面试为主要目的，亦不可以篇概全，请谅解，有问题可提出。&lt;/li&gt;
&lt;li&gt;此项目以各个模块为切入点，让大家有一个清晰的知识体系。&lt;/li&gt;
&lt;li&gt;此项目亦可拿来常读、常记以及面试时复习之用。&lt;/li&gt;
&lt;li&gt;每一章里的问题都是面试时有可能问到的知识点，如有遗漏可联系我进行补充，结尾处都有算法的&lt;strong&gt;实战代码案例&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;思维导图，&lt;strong&gt;请关注 AIArea 公众号并回复：NLP思维导图&lt;/strong&gt; ，即能下载高清大图。&lt;/li&gt;
&lt;li&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/NLP-LOVE/Introduction-NLP/raw/master/img/2020-2-3_16-0-25.png?raw=true"&gt;&lt;img src="https://github.com/NLP-LOVE/Introduction-NLP/raw/master/img/2020-2-3_16-0-25.png?raw=true" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-目录" class="anchor" aria-hidden="true" href="#目录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;项目持续更新中......&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;章节&lt;/th&gt;
&lt;th&gt;负责人(GitHub)&lt;/th&gt;
&lt;th&gt;联系QQ&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/Liner%20Regression/1.Liner%20Regression.md"&gt;1. 线性回归(Liner Regression)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/2.Logistics%20Regression/2.Logistics%20Regression.md"&gt;2. 逻辑回归(Logistics Regression)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.Desition%20Tree/Desition%20Tree.md"&gt;3. 决策树(Desision Tree)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.1%20Random%20Forest/3.1%20Random%20Forest.md"&gt;3.1 随机森林(Random Forest)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.2%20GBDT/3.2%20GBDT.md"&gt;3.2 梯度提升决策树(GBDT)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.3%20XGBoost/3.3%20XGBoost.md"&gt;3.3 XGBoost&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.4%20LightGBM/3.4%20LightGBM.md"&gt;3.4 LightGBM&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/4.%20SVM/4.%20SVM.md"&gt;4. 支持向量机(SVM)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;5. 概率图模型(Probabilistic Graphical Model)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/5.1%20Bayes%20Network/5.1%20Bayes%20Network.md"&gt;5.1 贝叶斯网络(Bayesian Network)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/5.2%20Markov/5.2%20Markov.md"&gt;5.2 马尔科夫(Markov)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/5.3%20Topic%20Model"&gt;5.3 主题模型(Topic Model)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/6.%20EM"&gt;6.最大期望算法(EM)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/7.%20Clustering"&gt;7.聚类(Clustering)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/8.%20ML%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"&gt;8.ML特征工程和优化方法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/9.%20KNN"&gt;9.K近邻算法(KNN)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/10.%20Neural%20Network"&gt;10.神经网络(Neural Network)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/11.%20CNN"&gt;11. 卷积神经网络(CNN)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/12.%20RNN"&gt;12. 循环神经网络(RNN)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/12.1%20GRU"&gt;12.1 门控循环单元(GRU)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/12.2%20LSTM"&gt;12.2 长短期记忆(LSTM)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/13.%20Transfer%20Learning"&gt;13.迁移学习(Transfer)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/14.%20Reinforcement%20Learning"&gt;14.强化学习(Reinforcement) &amp;amp; 多任务&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/15.%20DL%20Optimizer"&gt;15. 深度学习的优化方法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.%20NLP"&gt;16. 自然语言处理(NLP)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.1%20Word%20Embedding"&gt;16.1 词嵌入(Word2Vec)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.2%20fastText"&gt;16.2 子词嵌入(fastText)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.3%20GloVe"&gt;16.3 全局向量词嵌入(GloVe)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.4%20textRNN%20%26%20textCNN"&gt;16.4 textRNN &amp;amp; textCNN&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.5%20seq2seq"&gt;16.5 序列到序列模型(seq2seq)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.6%20Attention"&gt;16.6 注意力机制(Attention Mechanism)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.7%20Transformer"&gt;16.7 Transformer模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.8%20BERT"&gt;16.8 BERT模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.9%20XLNet"&gt;16.9 XLNet模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;项目&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System"&gt;17. 推荐系统(Recommendation System)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;项目&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/18.%20Intelligent%20Customer%20Service"&gt;18. 智能客服(Intelligent Customer Service)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;项目&lt;/td&gt;
&lt;td&gt;19. 知识图谱(Knowledge Graph)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;项目&lt;/td&gt;
&lt;td&gt;20. 评论分析&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;欢迎大家加入！共同完善此项目！NLP学习QQ2群【207576902】&lt;a href="http://shang.qq.com/wpa/qunwpa?idkey=1defd70810d9e67ca6ab3a30e1425a8a358139315a186dd2192d82a4c0ca1ce9" rel="nofollow"&gt;&lt;img border="0" src="https://camo.githubusercontent.com/615c9901677f501582b6057efc9396b3ed27dc29/687474703a2f2f7075622e69647171696d672e636f6d2f7770612f696d616765732f67726f75702e706e67" alt="NLP学习群②" title="NLP学习群②" data-canonical-src="http://pub.idqqimg.com/wpa/images/group.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>NLP-LOVE</author><guid isPermaLink="false">https://github.com/NLP-LOVE/ML-NLP</guid><pubDate>Sun, 09 Feb 2020 00:23:00 GMT</pubDate></item><item><title>empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks #24 in Jupyter Notebook, Today</title><link>https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks</link><description>&lt;p&gt;&lt;i&gt;A series of Python Jupyter notebooks that help you better understand "The Elements of Statistical Learning" book&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-the-elements-of-statistical-learning-notebooks" class="anchor" aria-hidden="true" href="#the-elements-of-statistical-learning-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;"The Elements of Statistical Learning" Notebooks&lt;/h1&gt;
&lt;p&gt;Reproducing examples from the "The Elements of Statistical Learning" by Trevor Hastie, Robert Tibshirani and Jerome Friedman with Python and its popular libraries:
&lt;strong&gt;numpy&lt;/strong&gt;, &lt;strong&gt;math&lt;/strong&gt;, &lt;strong&gt;scipy&lt;/strong&gt;, &lt;strong&gt;sklearn&lt;/strong&gt;, &lt;strong&gt;pandas&lt;/strong&gt;, &lt;strong&gt;tensorflow&lt;/strong&gt;, &lt;strong&gt;statsmodels&lt;/strong&gt;, &lt;strong&gt;sympy&lt;/strong&gt;, &lt;strong&gt;catboost&lt;/strong&gt;, &lt;strong&gt;pyearth&lt;/strong&gt;, &lt;strong&gt;mlxtend&lt;/strong&gt;, &lt;strong&gt;cvxpy&lt;/strong&gt;. Almost all plotting is done using &lt;strong&gt;matplotlib&lt;/strong&gt;, sometimes using &lt;strong&gt;seaborn&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;p&gt;The documented Jupyter Notebooks are in the &lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/tree/master/examples"&gt;examples&lt;/a&gt; folder:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesmixtureipynb" class="anchor" aria-hidden="true" href="#examplesmixtureipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Mixture.ipynb"&gt;examples/Mixture.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Classifying the points from a mixture of "gaussians" using linear regression, nearest-neighbor, logistic regression with natural cubic splines basis expansion, neural networks, support vector machines, flexible discriminant analysis over MARS regression, mixture discriminant analysis, k-Means clustering, Gaussian mixture model and random forests.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/mixture.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/mixture.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesprostate-canceripynb" class="anchor" aria-hidden="true" href="#examplesprostate-canceripynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Prostate%20Cancer.ipynb"&gt;examples/Prostate Cancer.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Predicting prostate specific antigen using ordinary least squares, ridge/lasso regularized linear regression, principal components regression, partial least squares and best subset regression. Model parameters are selected by K-folds cross-validation.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/cancer.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/cancer.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplessouth-african-heart-diseaseipynb" class="anchor" aria-hidden="true" href="#examplessouth-african-heart-diseaseipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/South%20African%20Heart%20Disease.ipynb"&gt;examples/South African Heart Disease.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Understanding the risk factors using logistic regression, L1 regularized logistic regression, natural cubic splines basis expansion for nonlinearities, thin-plate spline for mutual dependency, local logistic regression, kernel density estimation and gaussian mixture models.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/chd.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/chd.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesvowelipynb" class="anchor" aria-hidden="true" href="#examplesvowelipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Vowel.ipynb"&gt;examples/Vowel.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Vowel speech recognition using regression of an indicator matrix, linear/quadratic/regularized/reduced-rank discriminant analysis and logistic regression.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/vowel.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/vowel.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesbone-mineral-densityipynb" class="anchor" aria-hidden="true" href="#examplesbone-mineral-densityipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Bone%20Mineral%20Density.ipynb"&gt;examples/Bone Mineral Density.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Comparing patterns of bone mineral density relative change for men and women using smoothing splines.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/bone.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/bone.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesair-pollution-dataipynb" class="anchor" aria-hidden="true" href="#examplesair-pollution-dataipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Air%20Pollution.ipynb"&gt;examples/Air Pollution Data.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing Los Angeles pollution data using smoothing splines.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/ozone_vs_pressure_gradient.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/ozone_vs_pressure_gradient.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesphoneme-recognitionipynb" class="anchor" aria-hidden="true" href="#examplesphoneme-recognitionipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Phoneme%20Recognition.ipynb"&gt;examples/Phoneme Recognition.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Phonemes speech recognition using reduced flexibility logistic regression.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/phoneme.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/phoneme.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesgalaxyipynb" class="anchor" aria-hidden="true" href="#examplesgalaxyipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Galaxy.ipynb"&gt;examples/Galaxy.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing radial velocity of galaxy NGC7531 using local regression in multidimentional space.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/galaxy.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/galaxy.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesozoneipynb" class="anchor" aria-hidden="true" href="#examplesozoneipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Ozone.ipynb"&gt;examples/Ozone.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing the factors influencing ozone concentration using local regression and trellis plot.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/ozone.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/ozone.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesspamipynb" class="anchor" aria-hidden="true" href="#examplesspamipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Spam.ipynb"&gt;examples/Spam.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Detecting email spam using logistic regression, generalized additive logistic model, decision tree, multivariate adaptive regression splines, boosting and random forest.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/spam.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/spam.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplescalifornia-housingipynb" class="anchor" aria-hidden="true" href="#examplescalifornia-housingipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/California%20Housing.ipynb"&gt;examples/California Housing.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing the factors influencing California houses prices using boosting over decision trees and partial dependance plots.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/california.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/california.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesdemographicsipynb" class="anchor" aria-hidden="true" href="#examplesdemographicsipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Demographics.ipynb"&gt;examples/Demographics.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Predicting shopping mall customers occupation, and hence identifying demographic variables that discriminate between different occupational categories using boosting and market basket analysis.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/demographics.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/demographics.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-exampleszip-codeipynb" class="anchor" aria-hidden="true" href="#exampleszip-codeipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/ZIP%20Code.ipynb"&gt;examples/ZIP Code.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Recognizing small hand-drawn digits using LeCun's Net-1 - Net-5 neural networks.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/zip1.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/zip1.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Analysing of the number three variation in ZIP codes using principal component and archetypal analysis.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/zip2.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/zip2.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-exampleshuman-tumor-microarray-dataipynb" class="anchor" aria-hidden="true" href="#exampleshuman-tumor-microarray-dataipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Human%20Tumor%20Microarray%20Data.ipynb"&gt;examples/Human Tumor Microarray Data.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing microarray data using K-means clustring and hierarchical clustering.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/tumor.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/tumor.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplescountry-dissimilaritiesipynb" class="anchor" aria-hidden="true" href="#examplescountry-dissimilaritiesipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Country%20Dissimilarities.ipynb"&gt;examples/Country Dissimilarities.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing country dissimilarities using K-medoids clustering and multidimensional scaling.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/country.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/country.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplessignatureipynb" class="anchor" aria-hidden="true" href="#examplessignatureipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Signature.ipynb"&gt;examples/Signature.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing signature shapes using Procrustes transformation.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/signature.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/signature.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-exampleswaveformipynb" class="anchor" aria-hidden="true" href="#exampleswaveformipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Waveform.ipynb"&gt;examples/Waveform.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Recognizing wave classes using linear, quadratic, flexible (over MARS regression), mixture discriminant analysis and decision trees.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/waveform.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/waveform.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesprotein-flow-cytometryipynb" class="anchor" aria-hidden="true" href="#examplesprotein-flow-cytometryipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Protein%20Flow%20Cytometry.ipynb"&gt;examples/Protein Flow-Cytometry.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing protein flow-cytometry data using graphical-lasso undirected graphical model for continuous variables.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/cytometry.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/cytometry.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplessrbct-microarrayipynb" class="anchor" aria-hidden="true" href="#examplessrbct-microarrayipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/SRBCT%20Microarray.ipynb"&gt;examples/SRBCT Microarray.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing microarray data of 2308 genes and selecting the most significant genes for cancer classification using nearest shrunken centroids.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/srbct.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/srbct.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examples14-cancer-microarrayipynb" class="anchor" aria-hidden="true" href="#examples14-cancer-microarrayipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/14%20Cancer.ipynb"&gt;examples/14 Cancer Microarray.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing microarray data of 16,063 genes gathered by Ramaswamy et al. (2001) and selecting the most significant genes for cancer classification using nearest shrunken centroids, L2-penalized discriminant analysis, support vector classifier, k-nearest neighbors, L2-penalized multinominal, L1-penalized multinominal and elastic-net penalized multinominal. It is a difficult classification problem with p&amp;gt;&amp;gt;N (only 144 training observations).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesskin-of-the-orangeipynb" class="anchor" aria-hidden="true" href="#examplesskin-of-the-orangeipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Skin%20of%20the%20Orange.ipynb"&gt;examples/Skin of the Orange.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Solving a synthetic classification problem using Support Vector Machines and multivariate adaptive regression splines to show the influence of additional noise features.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesradiation-sensitivityipynb" class="anchor" aria-hidden="true" href="#examplesradiation-sensitivityipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Radiation%20Sensitivity.ipynb"&gt;examples/Radiation Sensitivity.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Assessing the significance of 12,625 genes from microarray study of radiation sensitivity using Benjamini-Hochberg method and the significane analysis of microarrays (SAM) approach.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/radiation.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/radiation.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>empathy87</author><guid isPermaLink="false">https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks</guid><pubDate>Sun, 09 Feb 2020 00:24:00 GMT</pubDate></item><item><title>ypwhs/captcha_break #25 in Jupyter Notebook, Today</title><link>https://github.com/ypwhs/captcha_break</link><description>&lt;p&gt;&lt;i&gt;验证码识别&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-使用深度学习来破解-captcha-验证码" class="anchor" aria-hidden="true" href="#使用深度学习来破解-captcha-验证码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;使用深度学习来破解 captcha 验证码&lt;/h1&gt;
&lt;p&gt;本项目会通过 Keras 搭建一个深度卷积神经网络来识别 captcha 验证码，建议使用显卡来运行该项目。&lt;/p&gt;
&lt;p&gt;下面的可视化代码都是在 &lt;code&gt;jupyter notebook&lt;/code&gt; 中完成的，如果你希望写成 python 脚本，稍加修改即可正常运行，当然也可以去掉这些可视化代码。&lt;/p&gt;
&lt;p&gt;2019 年更新了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;适配了新版 API&lt;/li&gt;
&lt;li&gt;提高了数据生成器的效率&lt;/li&gt;
&lt;li&gt;使用了 CuDNNGRU 提高了训练和预测效率&lt;/li&gt;
&lt;li&gt;更新了文档&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-环境" class="anchor" aria-hidden="true" href="#环境"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;环境&lt;/h1&gt;
&lt;p&gt;本项目使用的环境如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;captcha 0.3&lt;/li&gt;
&lt;li&gt;tensorflow-gpu 1.13.1&lt;/li&gt;
&lt;li&gt;numpy 1.16.4&lt;/li&gt;
&lt;li&gt;tqdm 4.28.1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面几个包是用于可视化的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;matplotlib 2.2.2&lt;/li&gt;
&lt;li&gt;pandas 0.23.0&lt;/li&gt;
&lt;li&gt;pydot 1.4.1&lt;/li&gt;
&lt;li&gt;graphviz 2.38.0-12ubuntu2.1&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-captcha" class="anchor" aria-hidden="true" href="#captcha"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;captcha&lt;/h1&gt;
&lt;p&gt;captcha 是用 python 写的生成验证码的库，它支持图片验证码和语音验证码，我们使用的是它生成图片验证码的功能。&lt;/p&gt;
&lt;p&gt;首先我们设置我们的验证码格式为数字加大写字母，生成一串验证码试试看：&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; captcha.image &lt;span class="pl-k"&gt;import&lt;/span&gt; ImageCaptcha
&lt;span class="pl-k"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class="pl-k"&gt;as&lt;/span&gt; plt
&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np
&lt;span class="pl-k"&gt;import&lt;/span&gt; random

&lt;span class="pl-k"&gt;%&lt;/span&gt;matplotlib inline
&lt;span class="pl-k"&gt;%&lt;/span&gt;config InlineBackend.figure_format &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;retina&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;

&lt;span class="pl-k"&gt;import&lt;/span&gt; string
characters &lt;span class="pl-k"&gt;=&lt;/span&gt; string.digits &lt;span class="pl-k"&gt;+&lt;/span&gt; string.ascii_uppercase
&lt;span class="pl-c1"&gt;print&lt;/span&gt;(characters)

width, height, n_len, n_class &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;170&lt;/span&gt;, &lt;span class="pl-c1"&gt;80&lt;/span&gt;, &lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-c1"&gt;len&lt;/span&gt;(characters)

generator &lt;span class="pl-k"&gt;=&lt;/span&gt; ImageCaptcha(&lt;span class="pl-v"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;width, &lt;span class="pl-v"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;height)
random_str &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([random.choice(characters) &lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;4&lt;/span&gt;)])
img &lt;span class="pl-k"&gt;=&lt;/span&gt; generator.generate_image(random_str)

plt.imshow(img)
plt.title(random_str)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/captcha.png"&gt;&lt;img src="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/captcha.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-防止-tensorflow-占用所有显存" class="anchor" aria-hidden="true" href="#防止-tensorflow-占用所有显存"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;防止 tensorflow 占用所有显存&lt;/h1&gt;
&lt;p&gt;众所周知 tensorflow 默认占用所有显存，这样不利于我们同时进行多项实验，因此我们可以使用下面的代码当 tensorflow 使用它需要的显存，而不是直接占用所有显存。&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow &lt;span class="pl-k"&gt;as&lt;/span&gt; tf
&lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow.keras.backend &lt;span class="pl-k"&gt;as&lt;/span&gt; K

config &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.ConfigProto()
config.gpu_options.allow_growth&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;
sess &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.Session(&lt;span class="pl-v"&gt;config&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;config)
K.set_session(sess)&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-数据生成器" class="anchor" aria-hidden="true" href="#数据生成器"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数据生成器&lt;/h1&gt;
&lt;p&gt;训练模型的时候，我们可以选择两种方式来生成我们的训练数据，一种是一次性生成几万张图，然后开始训练，一种是定义一个数据生成器，然后利用 &lt;code&gt;fit_generator&lt;/code&gt; 函数来训练。&lt;/p&gt;
&lt;p&gt;第一种方式的好处是训练的时候显卡利用率高，如果你需要经常调参，可以一次生成，多次使用；第二种方式的好处是你不需要生成大量数据，训练过程中可以利用 CPU 生成数据，而且还有一个好处是你可以无限生成数据。&lt;/p&gt;
&lt;p&gt;我们的数据格式如下：&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-x" class="anchor" aria-hidden="true" href="#x"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;X&lt;/h2&gt;
&lt;p&gt;X 的形状是 &lt;code&gt;(batch_size, height, width, 3)&lt;/code&gt;，比如一批生成 128 个样本，图片宽度为170，高度为80，那么 X 的形状就是 &lt;code&gt;(128, 64, 128, 3)&lt;/code&gt;，如果你想取第一张图，代码可以这样写 &lt;code&gt;X[0]&lt;/code&gt;。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-y" class="anchor" aria-hidden="true" href="#y"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;y&lt;/h2&gt;
&lt;p&gt;y 的形状是四个 &lt;code&gt;(batch_size, n_class)&lt;/code&gt;，如果转换成 numpy 的格式，则是 &lt;code&gt;(n_len, batch_size, n_class)&lt;/code&gt;，比如一批生成 128 个样本，验证码的字符有 36 种，长度是 4 位，那么它的形状就是 4 个 &lt;code&gt;(128, 36)&lt;/code&gt; 的矩阵，也可以说是 &lt;code&gt;(4, 32, 36)&lt;/code&gt;。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-数据生成器-1" class="anchor" aria-hidden="true" href="#数据生成器-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数据生成器&lt;/h2&gt;
&lt;p&gt;为了让 Keras 能够使用多进程并行生成数据，我们需要使用 Keras 的 Sequence 类实现一个我们自己的数据类。&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;__init__&lt;/code&gt; 初始化函数里，我们定义数据所需的参数，然后这个数据的长度就是 steps 数。在 &lt;code&gt;__getitem__&lt;/code&gt; 里，我们不用理会索引号，直接随机生成一批样本送去训练即可。&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.utils &lt;span class="pl-k"&gt;import&lt;/span&gt; Sequence

&lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;CaptchaSequence&lt;/span&gt;(&lt;span class="pl-e"&gt;Sequence&lt;/span&gt;):
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__init__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;characters&lt;/span&gt;, &lt;span class="pl-smi"&gt;batch_size&lt;/span&gt;, &lt;span class="pl-smi"&gt;steps&lt;/span&gt;, &lt;span class="pl-smi"&gt;n_len&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-smi"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-smi"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;64&lt;/span&gt;):
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.characters &lt;span class="pl-k"&gt;=&lt;/span&gt; characters
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size &lt;span class="pl-k"&gt;=&lt;/span&gt; batch_size
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.steps &lt;span class="pl-k"&gt;=&lt;/span&gt; steps
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_len &lt;span class="pl-k"&gt;=&lt;/span&gt; n_len
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.width &lt;span class="pl-k"&gt;=&lt;/span&gt; width
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.height &lt;span class="pl-k"&gt;=&lt;/span&gt; height
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_class &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;len&lt;/span&gt;(characters)
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.generator &lt;span class="pl-k"&gt;=&lt;/span&gt; ImageCaptcha(&lt;span class="pl-v"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;width, &lt;span class="pl-v"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;height)
    
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__len__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;):
        &lt;span class="pl-k"&gt;return&lt;/span&gt; &lt;span class="pl-c1"&gt;self&lt;/span&gt;.steps

    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__getitem__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;idx&lt;/span&gt;):
        X &lt;span class="pl-k"&gt;=&lt;/span&gt; np.zeros((&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.height, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.width, &lt;span class="pl-c1"&gt;3&lt;/span&gt;), &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.float32)
        y &lt;span class="pl-k"&gt;=&lt;/span&gt; [np.zeros((&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_class), &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.uint8) &lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_len)]
        &lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size):
            random_str &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([random.choice(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.characters) &lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_len)])
            X[i] &lt;span class="pl-k"&gt;=&lt;/span&gt; np.array(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.generator.generate_image(random_str)) &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255.0&lt;/span&gt;
            &lt;span class="pl-k"&gt;for&lt;/span&gt; j, ch &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;enumerate&lt;/span&gt;(random_str):
                y[j][i, :] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;
                y[j][i, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.characters.find(ch)] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1&lt;/span&gt;
        &lt;span class="pl-k"&gt;return&lt;/span&gt; X, y&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-使用生成器" class="anchor" aria-hidden="true" href="#使用生成器"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;使用生成器&lt;/h1&gt;
&lt;p&gt;生成器的使用方法很简单，只需要用对它取第一个 batch 即可。下面是一个例子，初始化一个数据集，设置 batch_size 和 steps 都为 1，然后取出来第一个数据，对它可视化。&lt;/p&gt;
&lt;p&gt;在这里我们对生成的  One-Hot 编码后的标签进行了解码，首先将它转为 numpy 数组，然后取36个字符中最大的数字的位置（axis=2代表字符的轴），实际上神经网络会输出36个字符的概率，我们需要将概率最大的四个字符的编号取出来，转换为字符串。&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;decode&lt;/span&gt;(&lt;span class="pl-smi"&gt;y&lt;/span&gt;):
    y &lt;span class="pl-k"&gt;=&lt;/span&gt; np.argmax(np.array(y), &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;)[:,&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
    &lt;span class="pl-k"&gt;return&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([characters[x] &lt;span class="pl-k"&gt;for&lt;/span&gt; x &lt;span class="pl-k"&gt;in&lt;/span&gt; y])

data &lt;span class="pl-k"&gt;=&lt;/span&gt; CaptchaSequence(characters, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-v"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;)
X, y &lt;span class="pl-k"&gt;=&lt;/span&gt; data[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
plt.imshow(X[&lt;span class="pl-c1"&gt;0&lt;/span&gt;])
plt.title(decode(y))&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-构建深度卷积神经网络" class="anchor" aria-hidden="true" href="#构建深度卷积神经网络"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;构建深度卷积神经网络&lt;/h1&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.models &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;
&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.layers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

input_tensor &lt;span class="pl-k"&gt;=&lt;/span&gt; Input((height, width, &lt;span class="pl-c1"&gt;3&lt;/span&gt;))
x &lt;span class="pl-k"&gt;=&lt;/span&gt; input_tensor
&lt;span class="pl-k"&gt;for&lt;/span&gt; i, n_cnn &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;enumerate&lt;/span&gt;([&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;]):
    &lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(n_cnn):
        x &lt;span class="pl-k"&gt;=&lt;/span&gt; Conv2D(&lt;span class="pl-c1"&gt;32&lt;/span&gt;&lt;span class="pl-k"&gt;*&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;&lt;span class="pl-k"&gt;**&lt;/span&gt;&lt;span class="pl-c1"&gt;min&lt;/span&gt;(i, &lt;span class="pl-c1"&gt;3&lt;/span&gt;), &lt;span class="pl-v"&gt;kernel_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-v"&gt;padding&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;same&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;kernel_initializer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;he_uniform&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)(x)
        x &lt;span class="pl-k"&gt;=&lt;/span&gt; BatchNormalization()(x)
        x &lt;span class="pl-k"&gt;=&lt;/span&gt; Activation(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;relu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)(x)
    x &lt;span class="pl-k"&gt;=&lt;/span&gt; MaxPooling2D(&lt;span class="pl-c1"&gt;2&lt;/span&gt;)(x)

x &lt;span class="pl-k"&gt;=&lt;/span&gt; Flatten()(x)
x &lt;span class="pl-k"&gt;=&lt;/span&gt; [Dense(n_class, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;softmax&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;c&lt;span class="pl-c1"&gt;%d&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-k"&gt;%&lt;/span&gt;(i&lt;span class="pl-k"&gt;+&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;))(x) &lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(n_len)]
model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(&lt;span class="pl-v"&gt;inputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;input_tensor, &lt;span class="pl-v"&gt;outputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;x)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;模型结构很简单，特征提取部分使用的是两个卷积，一个池化的结构，这个结构是学的 VGG16 的结构。我们重复五个 block，然后我们将它 Flatten，连接四个分类器，每个分类器是36个神经元，输出36个字符的概率。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-模型可视化" class="anchor" aria-hidden="true" href="#模型可视化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;模型可视化&lt;/h1&gt;
&lt;p&gt;得益于 Keras 自带的可视化，我们可以使用几句代码来可视化模型的结构：&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.utils &lt;span class="pl-k"&gt;import&lt;/span&gt; plot_model
&lt;span class="pl-k"&gt;from&lt;/span&gt; IPython.display &lt;span class="pl-k"&gt;import&lt;/span&gt; Image

plot_model(model, &lt;span class="pl-v"&gt;to_file&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn.png&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;show_shapes&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
Image(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn.png&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里需要使用 pydot 这个库，以及 graphviz 这个库，在 macOS 系统上安装方法如下：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;brew install graphviz
pip install pydot-ng&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="imgs/cnn.png"&gt;&lt;img src="imgs/cnn.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我们可以看到最后一层卷积层输出的形状是 &lt;code&gt;(1, 6, 256)&lt;/code&gt;，已经不能再加卷积层了。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-训练模型" class="anchor" aria-hidden="true" href="#训练模型"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;训练模型&lt;/h1&gt;
&lt;p&gt;训练模型反而是所有步骤里面最简单的一个，直接使用 &lt;code&gt;model.fit_generator&lt;/code&gt; 即可，这里的验证集使用了同样的生成器，由于数据是通过生成器随机生成的，所以我们不用考虑数据是否会重复。&lt;/p&gt;
&lt;p&gt;为了避免手动调参，我们使用了 Adam 优化器，它的学习率是自动设置的，我们只需要给一个较好的初始学习率即可。&lt;/p&gt;
&lt;p&gt;EarlyStopping 是一个 Keras 的 Callback，它可以在 loss 超过多少个 epoch 没有下降以后，就自动终止训练，避免浪费时间。&lt;/p&gt;
&lt;p&gt;ModelCheckpoint 是另一个好用的 Callback，它可以保存训练过程中最好的模型。&lt;/p&gt;
&lt;p&gt;CSVLogger 可以记录 loss 为 CSV 文件，这样我们就可以在训练完成以后绘制训练过程中的 loss 曲线。&lt;/p&gt;
&lt;p&gt;注意，这段代码在笔记本电脑上可能要较长时间，建议使用带有 NVIDIA 显卡的机器运行。注意我们这里使用了一个小技巧，添加 &lt;code&gt;workers=4&lt;/code&gt; 参数让 Keras 自动实现多进程生成数据，摆脱 python 单线程效率低的缺点。&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.callbacks &lt;span class="pl-k"&gt;import&lt;/span&gt; EarlyStopping, CSVLogger, ModelCheckpoint
&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.optimizers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

train_data &lt;span class="pl-k"&gt;=&lt;/span&gt; CaptchaSequence(characters, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1000&lt;/span&gt;)
valid_data &lt;span class="pl-k"&gt;=&lt;/span&gt; CaptchaSequence(characters, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;)
callbacks &lt;span class="pl-k"&gt;=&lt;/span&gt; [EarlyStopping(&lt;span class="pl-v"&gt;patience&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;3&lt;/span&gt;), CSVLogger(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn.csv&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;), ModelCheckpoint(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn_best.h5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;save_best_only&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)]

model.compile(&lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;categorical_crossentropy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
              &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;Adam(&lt;span class="pl-c1"&gt;1e-3&lt;/span&gt;, &lt;span class="pl-v"&gt;amsgrad&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;), 
              &lt;span class="pl-v"&gt;metrics&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;accuracy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])
model.fit_generator(train_data, &lt;span class="pl-v"&gt;epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;validation_data&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;valid_data, &lt;span class="pl-v"&gt;workers&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-v"&gt;use_multiprocessing&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;,
                    &lt;span class="pl-v"&gt;callbacks&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;callbacks)&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-载入最好的模型继续训练一会" class="anchor" aria-hidden="true" href="#载入最好的模型继续训练一会"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;载入最好的模型继续训练一会&lt;/h3&gt;
&lt;p&gt;为了让模型充分训练，我们可以载入之前最好的模型权值，然后降低学习率为原来的十分之一，继续训练，这样可以让模型收敛得更好。&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;model.load_weights(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn_best.h5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

callbacks &lt;span class="pl-k"&gt;=&lt;/span&gt; [EarlyStopping(&lt;span class="pl-v"&gt;patience&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;3&lt;/span&gt;), CSVLogger(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn.csv&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;append&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;), 
             ModelCheckpoint(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn_best.h5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;save_best_only&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)]

model.compile(&lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;categorical_crossentropy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
              &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;Adam(&lt;span class="pl-c1"&gt;1e-4&lt;/span&gt;, &lt;span class="pl-v"&gt;amsgrad&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;), 
              &lt;span class="pl-v"&gt;metrics&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;accuracy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])
model.fit_generator(train_data, &lt;span class="pl-v"&gt;epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;validation_data&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;valid_data, &lt;span class="pl-v"&gt;workers&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-v"&gt;use_multiprocessing&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;,
                    &lt;span class="pl-v"&gt;callbacks&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;callbacks)&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-测试模型" class="anchor" aria-hidden="true" href="#测试模型"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;测试模型&lt;/h1&gt;
&lt;p&gt;当我们训练完成以后，可以识别一个验证码试试看：&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;X, y &lt;span class="pl-k"&gt;=&lt;/span&gt; data[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
y_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict(X)
plt.title(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;real: &lt;span class="pl-c1"&gt;%s&lt;/span&gt;&lt;span class="pl-cce"&gt;\n&lt;/span&gt;pred:&lt;span class="pl-c1"&gt;%s&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-k"&gt;%&lt;/span&gt;(decode(y), decode(y_pred)))
plt.imshow(X[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], &lt;span class="pl-v"&gt;cmap&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;gray&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
plt.axis(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;off&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/test_model.png"&gt;&lt;img src="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/test_model.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-计算模型总体准确率" class="anchor" aria-hidden="true" href="#计算模型总体准确率"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;计算模型总体准确率&lt;/h1&gt;
&lt;p&gt;模型在训练的时候只会显示每一个字符的准确率，为了统计模型的总体准确率，我们可以写下面的函数：&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tqdm &lt;span class="pl-k"&gt;import&lt;/span&gt; tqdm
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;evaluate&lt;/span&gt;(&lt;span class="pl-smi"&gt;model&lt;/span&gt;, &lt;span class="pl-smi"&gt;batch_num&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;):
    batch_acc &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;
    &lt;span class="pl-k"&gt;with&lt;/span&gt; tqdm(CaptchaSequence(characters, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;)) &lt;span class="pl-k"&gt;as&lt;/span&gt; pbar:
        &lt;span class="pl-k"&gt;for&lt;/span&gt; X, y &lt;span class="pl-k"&gt;in&lt;/span&gt; pbar:
            y_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict(X)
            y_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; np.argmax(y_pred, &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;).T
            y_true &lt;span class="pl-k"&gt;=&lt;/span&gt; np.argmax(y, &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;).T

            batch_acc &lt;span class="pl-k"&gt;+=&lt;/span&gt; (y_true &lt;span class="pl-k"&gt;==&lt;/span&gt; y_pred).all(&lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;).mean()
    &lt;span class="pl-k"&gt;return&lt;/span&gt; batch_acc &lt;span class="pl-k"&gt;/&lt;/span&gt; batch_num

evaluate(model)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里用到了一个库叫做 tqdm，它是一个进度条的库，为的是能够实时反馈进度。然后我们通过一些 numpy 计算去统计我们的准确率，这里计算规则是只要有一个错，那么就不算它对。经过计算，我们的模型的总体准确率在经过充分训练以后，可以达到 98.26% 的总体准确率。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-模型总结" class="anchor" aria-hidden="true" href="#模型总结"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;模型总结&lt;/h1&gt;
&lt;p&gt;模型的大小是10.7MB，总体准确率是 98.26%，基本上可以确定破解了此类验证码。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-改进" class="anchor" aria-hidden="true" href="#改进"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;改进&lt;/h1&gt;
&lt;p&gt;对于这种按顺序书写的文字，我们还有一种方法可以使用，那就是循环神经网络来识别序列。下面我们来了解一下如何使用循环神经网络来识别这类验证码。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-ctc-loss" class="anchor" aria-hidden="true" href="#ctc-loss"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CTC Loss&lt;/h1&gt;
&lt;p&gt;这个 loss 是一个特别神奇的 loss，它可以在只知道序列的顺序，不知道具体位置的情况下，让模型收敛。这里有一个非常好的文章介绍了 CTC Loss: &lt;a href="https://distill.pub/2017/ctc/" rel="nofollow"&gt;Sequence Modeling
With CTC&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/deep-speech-ctc-small.png"&gt;&lt;img src="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/deep-speech-ctc-small.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在 Keras 里面已经内置了 CTC Loss ，我们实现下面的代码即可在模型里使用 CTC Loss。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;y_pred&lt;/code&gt; 是模型的输出，是按顺序输出的37个字符的概率，因为我们这里用到了循环神经网络，所以需要一个空白字符的概念；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;labels&lt;/code&gt; 是验证码，是四个数字，每个数字代表字符在字符集里的位置&lt;/li&gt;
&lt;li&gt;&lt;code&gt;input_length&lt;/code&gt; 表示 &lt;code&gt;y_pred&lt;/code&gt; 的长度，我们这里是16&lt;/li&gt;
&lt;li&gt;&lt;code&gt;label_length&lt;/code&gt; 表示 &lt;code&gt;labels&lt;/code&gt; 的长度，我们这里是4&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow.keras.backend &lt;span class="pl-k"&gt;as&lt;/span&gt; K

&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;ctc_lambda_func&lt;/span&gt;(&lt;span class="pl-smi"&gt;args&lt;/span&gt;):
    y_pred, labels, input_length, label_length &lt;span class="pl-k"&gt;=&lt;/span&gt; args
    &lt;span class="pl-k"&gt;return&lt;/span&gt; K.ctc_batch_cost(labels, y_pred, input_length, label_length)&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-模型结构" class="anchor" aria-hidden="true" href="#模型结构"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;模型结构&lt;/h1&gt;
&lt;p&gt;我们的模型结构是这样设计的，首先通过卷积神经网络去识别特征，然后按水平顺序输入到 GRU 进行序列建模，最后使用一个分类器对每个时刻输出的特征进行分类。&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.models &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;
&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.layers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

input_tensor &lt;span class="pl-k"&gt;=&lt;/span&gt; Input((height, width, &lt;span class="pl-c1"&gt;3&lt;/span&gt;))
x &lt;span class="pl-k"&gt;=&lt;/span&gt; input_tensor
&lt;span class="pl-k"&gt;for&lt;/span&gt; i, n_cnn &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;enumerate&lt;/span&gt;([&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;]):
    &lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(n_cnn):
        x &lt;span class="pl-k"&gt;=&lt;/span&gt; Conv2D(&lt;span class="pl-c1"&gt;32&lt;/span&gt;&lt;span class="pl-k"&gt;*&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;&lt;span class="pl-k"&gt;**&lt;/span&gt;&lt;span class="pl-c1"&gt;min&lt;/span&gt;(i, &lt;span class="pl-c1"&gt;3&lt;/span&gt;), &lt;span class="pl-v"&gt;kernel_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-v"&gt;padding&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;same&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;kernel_initializer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;he_uniform&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)(x)
        x &lt;span class="pl-k"&gt;=&lt;/span&gt; BatchNormalization()(x)
        x &lt;span class="pl-k"&gt;=&lt;/span&gt; Activation(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;relu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)(x)
    x &lt;span class="pl-k"&gt;=&lt;/span&gt; MaxPooling2D(&lt;span class="pl-c1"&gt;2&lt;/span&gt; &lt;span class="pl-k"&gt;if&lt;/span&gt; i &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;3&lt;/span&gt; &lt;span class="pl-k"&gt;else&lt;/span&gt; (&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;1&lt;/span&gt;))(x)

x &lt;span class="pl-k"&gt;=&lt;/span&gt; Permute((&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;))(x)
x &lt;span class="pl-k"&gt;=&lt;/span&gt; TimeDistributed(Flatten())(x)

rnn_size &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;128&lt;/span&gt;
x &lt;span class="pl-k"&gt;=&lt;/span&gt; Bidirectional(CuDNNGRU(rnn_size, &lt;span class="pl-v"&gt;return_sequences&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;))(x)
x &lt;span class="pl-k"&gt;=&lt;/span&gt; Bidirectional(CuDNNGRU(rnn_size, &lt;span class="pl-v"&gt;return_sequences&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;))(x)
x &lt;span class="pl-k"&gt;=&lt;/span&gt; Dense(n_class, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;softmax&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)(x)

base_model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(&lt;span class="pl-v"&gt;inputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;input_tensor, &lt;span class="pl-v"&gt;outputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;x)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;为了训练这个模型，我们还需要搭建一个 loss 计算网络，代码如下：&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;labels &lt;span class="pl-k"&gt;=&lt;/span&gt; Input(&lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;the_labels&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;shape&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[n_len], &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;float32&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
input_length &lt;span class="pl-k"&gt;=&lt;/span&gt; Input(&lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;input_length&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;shape&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-c1"&gt;1&lt;/span&gt;], &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;int64&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
label_length &lt;span class="pl-k"&gt;=&lt;/span&gt; Input(&lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;label_length&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;shape&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-c1"&gt;1&lt;/span&gt;], &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;int64&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
loss_out &lt;span class="pl-k"&gt;=&lt;/span&gt; Lambda(ctc_lambda_func, &lt;span class="pl-v"&gt;output_shape&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;,), &lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)([x, labels, input_length, label_length])

model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(&lt;span class="pl-v"&gt;inputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[input_tensor, labels, input_length, label_length], &lt;span class="pl-v"&gt;outputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;loss_out)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;真正训练出来的模型是 &lt;code&gt;base_model&lt;/code&gt;，由于 Keras 的限制，我们没办法直接使用 &lt;code&gt;base_model&lt;/code&gt; 搭建 CTCLoss，所以我们只能按照上面的方法，让模型直接输出 loss。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-模型可视化-1" class="anchor" aria-hidden="true" href="#模型可视化-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;模型可视化&lt;/h1&gt;
&lt;p&gt;可视化的代码同上，这里只贴图。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="imgs/ctc.png"&gt;&lt;img src="imgs/ctc.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以看到模型比上一个模型复杂了许多，但实际上只是因为输入比较多，所以它显得很大。&lt;/p&gt;
&lt;p&gt;首先模型输入一个 &lt;code&gt;(height, width, 3)&lt;/code&gt; 维度的图片，然后经过一系列的层降维到了 &lt;code&gt;(2, 16, 256)&lt;/code&gt;，之后我们使用 Permute 把 width 轴调整到第一个维度以适配 RNN 的输入格式。调整以后的维度是 &lt;code&gt;(16, 2, 256)&lt;/code&gt;，然后使用 &lt;code&gt;TimeDistributed(Flatten())&lt;/code&gt; 把后两个维度压成一维，也就是 &lt;code&gt;(16, 512)&lt;/code&gt;，之后经过 2 层双向的 GRU 对序列横向建模，最后经过 Dense 分类器输出水平方向上每个字符的概率分布。&lt;/p&gt;
&lt;p&gt;使用 CuDNNGRU 是因为它在 NVIDIA 显卡上可以加速非常多倍，如果你使用的是 CPU，改为 GRU 即可。&lt;/p&gt;
&lt;p&gt;使用 RNN 的原因是，如果你看到一句话是 &lt;code&gt;今天我*了一个非常好吃的苹果&lt;/code&gt;，有一个字看不清，你很容易猜到这个字是“吃”，但是使用 CNN，你就很难有这么大的感受野，从苹果推测出前面的字是吃。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-数据生成器-2" class="anchor" aria-hidden="true" href="#数据生成器-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数据生成器&lt;/h1&gt;
&lt;p&gt;数据生成器和 CNN 的差不多，这里需要多几个矩阵，一个是 input_length，代表序列长度，一个是 label_length，代表验证码长度，还有一个 np.ones，没有意义，只是为了适配 Keras 训练需要的矩阵输入。&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.utils &lt;span class="pl-k"&gt;import&lt;/span&gt; Sequence

&lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;CaptchaSequence&lt;/span&gt;(&lt;span class="pl-e"&gt;Sequence&lt;/span&gt;):
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__init__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;characters&lt;/span&gt;, &lt;span class="pl-smi"&gt;batch_size&lt;/span&gt;, &lt;span class="pl-smi"&gt;steps&lt;/span&gt;, &lt;span class="pl-smi"&gt;n_len&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-smi"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-smi"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;64&lt;/span&gt;, 
                 &lt;span class="pl-smi"&gt;input_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;16&lt;/span&gt;, &lt;span class="pl-smi"&gt;label_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;):
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.characters &lt;span class="pl-k"&gt;=&lt;/span&gt; characters
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size &lt;span class="pl-k"&gt;=&lt;/span&gt; batch_size
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.steps &lt;span class="pl-k"&gt;=&lt;/span&gt; steps
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_len &lt;span class="pl-k"&gt;=&lt;/span&gt; n_len
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.width &lt;span class="pl-k"&gt;=&lt;/span&gt; width
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.height &lt;span class="pl-k"&gt;=&lt;/span&gt; height
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.input_length &lt;span class="pl-k"&gt;=&lt;/span&gt; input_length
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.label_length &lt;span class="pl-k"&gt;=&lt;/span&gt; label_length
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_class &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;len&lt;/span&gt;(characters)
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.generator &lt;span class="pl-k"&gt;=&lt;/span&gt; ImageCaptcha(&lt;span class="pl-v"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;width, &lt;span class="pl-v"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;height)
    
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__len__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;):
        &lt;span class="pl-k"&gt;return&lt;/span&gt; &lt;span class="pl-c1"&gt;self&lt;/span&gt;.steps

    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__getitem__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;idx&lt;/span&gt;):
        X &lt;span class="pl-k"&gt;=&lt;/span&gt; np.zeros((&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.height, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.width, &lt;span class="pl-c1"&gt;3&lt;/span&gt;), &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.float32)
        y &lt;span class="pl-k"&gt;=&lt;/span&gt; np.zeros((&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_len), &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.uint8)
        input_length &lt;span class="pl-k"&gt;=&lt;/span&gt; np.ones(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size)&lt;span class="pl-k"&gt;*&lt;/span&gt;&lt;span class="pl-c1"&gt;self&lt;/span&gt;.input_length
        label_length &lt;span class="pl-k"&gt;=&lt;/span&gt; np.ones(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size)&lt;span class="pl-k"&gt;*&lt;/span&gt;&lt;span class="pl-c1"&gt;self&lt;/span&gt;.label_length
        &lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size):
            random_str &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([random.choice(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.characters) &lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_len)])
            X[i] &lt;span class="pl-k"&gt;=&lt;/span&gt; np.array(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.generator.generate_image(random_str)) &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255.0&lt;/span&gt;
            y[i] &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-c1"&gt;self&lt;/span&gt;.characters.find(x) &lt;span class="pl-k"&gt;for&lt;/span&gt; x &lt;span class="pl-k"&gt;in&lt;/span&gt; random_str]
        &lt;span class="pl-k"&gt;return&lt;/span&gt; [X, y, input_length, label_length], np.ones(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size)&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-评估模型" class="anchor" aria-hidden="true" href="#评估模型"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;评估模型&lt;/h1&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tqdm &lt;span class="pl-k"&gt;import&lt;/span&gt; tqdm

&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;evaluate&lt;/span&gt;(&lt;span class="pl-smi"&gt;model&lt;/span&gt;, &lt;span class="pl-smi"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-smi"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;20&lt;/span&gt;):
    batch_acc &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;
    valid_data &lt;span class="pl-k"&gt;=&lt;/span&gt; CaptchaSequence(characters, batch_size, steps)
    &lt;span class="pl-k"&gt;for&lt;/span&gt; [X_test, y_test, _, _], _ &lt;span class="pl-k"&gt;in&lt;/span&gt; valid_data:
        y_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; base_model.predict(X_test)
        shape &lt;span class="pl-k"&gt;=&lt;/span&gt; y_pred.shape
        out &lt;span class="pl-k"&gt;=&lt;/span&gt; K.get_value(K.ctc_decode(y_pred, &lt;span class="pl-v"&gt;input_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.ones(shape[&lt;span class="pl-c1"&gt;0&lt;/span&gt;])&lt;span class="pl-k"&gt;*&lt;/span&gt;shape[&lt;span class="pl-c1"&gt;1&lt;/span&gt;])[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;0&lt;/span&gt;])[:, :&lt;span class="pl-c1"&gt;4&lt;/span&gt;]
        &lt;span class="pl-k"&gt;if&lt;/span&gt; out.shape[&lt;span class="pl-c1"&gt;1&lt;/span&gt;] &lt;span class="pl-k"&gt;==&lt;/span&gt; &lt;span class="pl-c1"&gt;4&lt;/span&gt;:
            batch_acc &lt;span class="pl-k"&gt;+=&lt;/span&gt; (y_test &lt;span class="pl-k"&gt;==&lt;/span&gt; out).all(&lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;).mean()
    &lt;span class="pl-k"&gt;return&lt;/span&gt; batch_acc &lt;span class="pl-k"&gt;/&lt;/span&gt; steps&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我们会通过这个函数来评估我们的模型，和上面的评估标准一样，只有全部正确，我们才算预测正确，中间有个坑，就是模型最开始训练的时候，并不一定会输出四个字符，所以我们如果遇到所有的字符都不到四个的时候，就不计算了，相当于加0，遇到多于4个字符的时候，只取前四个。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-评估回调" class="anchor" aria-hidden="true" href="#评估回调"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;评估回调&lt;/h1&gt;
&lt;p&gt;因为 Keras 没有针对这种输出计算准确率的选项，因此我们需要自定义一个回调函数，它会在每一代训练完成的时候计算模型的准确率。&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.callbacks &lt;span class="pl-k"&gt;import&lt;/span&gt; Callback

&lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;Evaluate&lt;/span&gt;(&lt;span class="pl-e"&gt;Callback&lt;/span&gt;):
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__init__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;):
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.accs &lt;span class="pl-k"&gt;=&lt;/span&gt; []
    
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;on_epoch_end&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;epoch&lt;/span&gt;, &lt;span class="pl-smi"&gt;logs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;None&lt;/span&gt;):
        logs &lt;span class="pl-k"&gt;=&lt;/span&gt; logs &lt;span class="pl-k"&gt;or&lt;/span&gt; {}
        acc &lt;span class="pl-k"&gt;=&lt;/span&gt; evaluate(base_model)
        logs[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;val_acc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; acc
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.accs.append(acc)
        &lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;f&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-cce"&gt;\n&lt;/span&gt;&lt;span class="pl-s"&gt;acc: &lt;/span&gt;&lt;span class="pl-c1"&gt;{&lt;/span&gt;acc&lt;span class="pl-k"&gt;*&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;&lt;span class="pl-k"&gt;:.4f&lt;/span&gt;&lt;span class="pl-c1"&gt;}&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-训练模型-1" class="anchor" aria-hidden="true" href="#训练模型-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;训练模型&lt;/h1&gt;
&lt;p&gt;我们还是按照之前的训练策略，先训练 100 代，等 loss 不降低以后，降低学习率，再训练 100 代，代码如下：&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.callbacks &lt;span class="pl-k"&gt;import&lt;/span&gt; EarlyStopping, CSVLogger, ModelCheckpoint
&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.optimizers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

train_data &lt;span class="pl-k"&gt;=&lt;/span&gt; CaptchaSequence(characters, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1000&lt;/span&gt;)
valid_data &lt;span class="pl-k"&gt;=&lt;/span&gt; CaptchaSequence(characters, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;)
callbacks &lt;span class="pl-k"&gt;=&lt;/span&gt; [EarlyStopping(&lt;span class="pl-v"&gt;patience&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;5&lt;/span&gt;), Evaluate(), 
             CSVLogger(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc.csv&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;), ModelCheckpoint(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc_best.h5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;save_best_only&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)]

model.compile(&lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-k"&gt;lambda&lt;/span&gt; &lt;span class="pl-smi"&gt;y_true&lt;/span&gt;, &lt;span class="pl-smi"&gt;y_pred&lt;/span&gt;: y_pred}, &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;Adam(&lt;span class="pl-c1"&gt;1e-3&lt;/span&gt;, &lt;span class="pl-v"&gt;amsgrad&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;))
model.fit_generator(train_data, &lt;span class="pl-v"&gt;epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;validation_data&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;valid_data, &lt;span class="pl-v"&gt;workers&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-v"&gt;use_multiprocessing&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;,
                    &lt;span class="pl-v"&gt;callbacks&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;callbacks)&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;model.load_weights(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc_best.h5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

callbacks &lt;span class="pl-k"&gt;=&lt;/span&gt; [EarlyStopping(&lt;span class="pl-v"&gt;patience&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;5&lt;/span&gt;), Evaluate(), 
             CSVLogger(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc.csv&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;append&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;), ModelCheckpoint(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc_best.h5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;save_best_only&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)]

model.compile(&lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-k"&gt;lambda&lt;/span&gt; &lt;span class="pl-smi"&gt;y_true&lt;/span&gt;, &lt;span class="pl-smi"&gt;y_pred&lt;/span&gt;: y_pred}, &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;Adam(&lt;span class="pl-c1"&gt;1e-4&lt;/span&gt;, &lt;span class="pl-v"&gt;amsgrad&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;))
model.fit_generator(train_data, &lt;span class="pl-v"&gt;epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;validation_data&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;valid_data, &lt;span class="pl-v"&gt;workers&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-v"&gt;use_multiprocessing&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;,
                    &lt;span class="pl-v"&gt;callbacks&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;callbacks)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="imgs/vis.png"&gt;&lt;img src="imgs/vis.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以看到 loss 一开始下降很快，后面就很平了，但是我们把在对数尺度下绘制 loss 图的话，还是能看到 loss 一直在下降的。acc 上升得也很快，虽然前期训练的时候 acc 很抖动，但是后期学习率降下来以后就不会再跌下来了。&lt;/p&gt;
&lt;p&gt;最终模型的准确率达到了 99.21%，训练过程中的准确率最高达到了 99.49%。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-测试模型-1" class="anchor" aria-hidden="true" href="#测试模型-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;测试模型&lt;/h1&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;characters2 &lt;span class="pl-k"&gt;=&lt;/span&gt; characters &lt;span class="pl-k"&gt;+&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt; &lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
[X_test, y_test, _, _], _  &lt;span class="pl-k"&gt;=&lt;/span&gt; data[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
y_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; base_model.predict(X_test)
out &lt;span class="pl-k"&gt;=&lt;/span&gt; K.get_value(K.ctc_decode(y_pred, &lt;span class="pl-v"&gt;input_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.ones(y_pred.shape[&lt;span class="pl-c1"&gt;0&lt;/span&gt;])&lt;span class="pl-k"&gt;*&lt;/span&gt;y_pred.shape[&lt;span class="pl-c1"&gt;1&lt;/span&gt;], )[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;0&lt;/span&gt;])[:, :&lt;span class="pl-c1"&gt;4&lt;/span&gt;]
out &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([characters[x] &lt;span class="pl-k"&gt;for&lt;/span&gt; x &lt;span class="pl-k"&gt;in&lt;/span&gt; out[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]])
y_true &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([characters[x] &lt;span class="pl-k"&gt;for&lt;/span&gt; x &lt;span class="pl-k"&gt;in&lt;/span&gt; y_test[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]])

plt.imshow(X_test[&lt;span class="pl-c1"&gt;0&lt;/span&gt;])
plt.title(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pred:&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;+&lt;/span&gt; &lt;span class="pl-c1"&gt;str&lt;/span&gt;(out) &lt;span class="pl-k"&gt;+&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-cce"&gt;\n&lt;/span&gt;true: &lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;+&lt;/span&gt; &lt;span class="pl-c1"&gt;str&lt;/span&gt;(y_true))

argmax &lt;span class="pl-k"&gt;=&lt;/span&gt; np.argmax(y_pred, &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;)[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
&lt;span class="pl-c1"&gt;list&lt;/span&gt;(&lt;span class="pl-c1"&gt;zip&lt;/span&gt;(argmax, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([characters2[x] &lt;span class="pl-k"&gt;for&lt;/span&gt; x &lt;span class="pl-k"&gt;in&lt;/span&gt; argmax])))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里随机出来的验证码很厉害，是&lt;code&gt;O0OP&lt;/code&gt;，不过更厉害的是模型认出来了。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/O0OP.png"&gt;&lt;img src="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/O0OP.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-有趣的问题" class="anchor" aria-hidden="true" href="#有趣的问题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;有趣的问题&lt;/h1&gt;
&lt;p&gt;我又用之前的模型做了个测试，对于 &lt;code&gt;O0O0&lt;/code&gt; 这样丧心病狂的验证码，模型偶尔也能正确识别，这让我非常惊讶，它是真的能识别 O 与 0 的差别呢，还是猜出来的呢？这很难说。&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;generator &lt;span class="pl-k"&gt;=&lt;/span&gt; ImageCaptcha(&lt;span class="pl-v"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;width, &lt;span class="pl-v"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;height)
random_str &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;O0O0&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
X &lt;span class="pl-k"&gt;=&lt;/span&gt; generator.generate_image(random_str)
X &lt;span class="pl-k"&gt;=&lt;/span&gt; np.expand_dims(X, &lt;span class="pl-c1"&gt;0&lt;/span&gt;) &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255.0&lt;/span&gt;

y_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; base_model.predict(X)
out &lt;span class="pl-k"&gt;=&lt;/span&gt; K.get_value(K.ctc_decode(y_pred, &lt;span class="pl-v"&gt;input_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.ones(y_pred.shape[&lt;span class="pl-c1"&gt;0&lt;/span&gt;])&lt;span class="pl-k"&gt;*&lt;/span&gt;y_pred.shape[&lt;span class="pl-c1"&gt;1&lt;/span&gt;], )[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;0&lt;/span&gt;])[:, :&lt;span class="pl-c1"&gt;4&lt;/span&gt;]
out &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([characters[x] &lt;span class="pl-k"&gt;for&lt;/span&gt; x &lt;span class="pl-k"&gt;in&lt;/span&gt; out[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]])

plt.title(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;real: &lt;span class="pl-c1"&gt;%s&lt;/span&gt;&lt;span class="pl-cce"&gt;\n&lt;/span&gt;pred:&lt;span class="pl-c1"&gt;%s&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-k"&gt;%&lt;/span&gt;(random_str, out))
plt.imshow(X[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], &lt;span class="pl-v"&gt;cmap&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;gray&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/O0O0.png"&gt;&lt;img src="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/O0O0.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-总结" class="anchor" aria-hidden="true" href="#总结"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;总结&lt;/h1&gt;
&lt;p&gt;模型的大小是12.8MB，准确率达到了惊人的 99.21%，即使连 0 和 O 都能精准区分，非常成功。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-扩展" class="anchor" aria-hidden="true" href="#扩展"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;扩展&lt;/h1&gt;
&lt;p&gt;如果你比较喜欢 PyTorch，可以看 &lt;a href="ctc_pytorch.ipynb"&gt;ctc_pytorch.ipynb&lt;/a&gt;，精度更高，达到了 99.57%。&lt;/p&gt;
&lt;p&gt;如果你想查看更多经验，可以看看我在百度云魅族深度学习应用大赛的代码和思路：&lt;a href="https://github.com/ypwhs/baiduyun_deeplearning_competition"&gt;https://github.com/ypwhs/baiduyun_deeplearning_competition&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-参考链接" class="anchor" aria-hidden="true" href="#参考链接"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;参考链接&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://keras.io/getting-started/functional-api-guide/" rel="nofollow"&gt;https://keras.io/getting-started/functional-api-guide/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss" rel="nofollow"&gt;https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/keras-team/keras/blob/master/examples/image_ocr.py"&gt;https://github.com/keras-team/keras/blob/master/examples/image_ocr.py&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cs231n.github.io/convolutional-networks/" rel="nofollow"&gt;https://cs231n.github.io/convolutional-networks/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://distill.pub/2017/ctc/" rel="nofollow"&gt;https://distill.pub/2017/ctc/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ypwhs</author><guid isPermaLink="false">https://github.com/ypwhs/captcha_break</guid><pubDate>Sun, 09 Feb 2020 00:25:00 GMT</pubDate></item></channel></rss>