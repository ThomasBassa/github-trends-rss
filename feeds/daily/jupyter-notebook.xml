<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Jupyter Notebook, Today</title><link>https://github.com/trending/jupyter-notebook?since=daily</link><description>The top repositories on GitHub for jupyter-notebook, measured daily</description><pubDate>Sun, 09 Feb 2020 01:09:46 GMT</pubDate><lastBuildDate>Sun, 09 Feb 2020 01:09:46 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>xavier-zy/Awesome-pytorch-list-CNVersion #1 in Jupyter Notebook, Today</title><link>https://github.com/xavier-zy/Awesome-pytorch-list-CNVersion</link><description>&lt;p&gt;&lt;i&gt;Awesome-pytorch-list ç¿»è¯‘å·¥ä½œè¿›è¡Œä¸­......&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-awesome-pytorch-listå‰å®³çš„pytorché¡¹ç›®" class="anchor" aria-hidden="true" href="#awesome-pytorch-listå‰å®³çš„pytorché¡¹ç›®"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Awesome-Pytorch-listï½œå‰å®³çš„Pytorché¡¹ç›®&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/pytorch/pytorch/master/docs/source/_static/img/pytorch-logo-dark.png"&gt;&lt;img src="https://raw.githubusercontent.com/pytorch/pytorch/master/docs/source/_static/img/pytorch-logo-dark.png" alt="pytorch-logo-dark" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-english-version" class="anchor" aria-hidden="true" href="#english-version"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/bharathgs/Awesome-pytorch-list"&gt;English Version&lt;/a&gt;&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-contentså†…å®¹" class="anchor" aria-hidden="true" href="#contentså†…å®¹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contentsï½œå†…å®¹&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#awesome-pytorch-list%EF%BD%9C%E5%8E%89%E5%AE%B3%E7%9A%84pytorch%E9%A1%B9%E7%9B%AE"&gt;Awesome-Pytorch-listï½œå‰å®³çš„Pytorché¡¹ç›®&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#english-version"&gt;English Version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contents%EF%BD%9C%E5%86%85%E5%AE%B9"&gt;Contentsï½œå†…å®¹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pytorch-related-libraries%EF%BD%9Cpytorch-%E7%9B%B8%E5%85%B3%E5%BA%93"&gt;Pytorch &amp;amp; related librariesï½œPytorch &amp;amp; ç›¸å…³åº“&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#nlp-speech-processing%EF%BD%9C%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-%E8%AF%AD%E9%9F%B3%E5%A4%84%E7%90%86"&gt;NLP &amp;amp; Speech Processingï½œè‡ªç„¶è¯­è¨€å¤„ç† &amp;amp; è¯­éŸ³å¤„ç†:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cv%EF%BD%9C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"&gt;CVï½œè®¡ç®—æœºè§†è§‰:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#probabilisticgenerative-libraries%EF%BD%9C%E6%A6%82%E7%8E%87%E5%BA%93%E5%92%8C%E7%94%9F%E6%88%90%E5%BA%93"&gt;Probabilistic/Generative Librariesï½œæ¦‚ç‡åº“å’Œç”Ÿæˆåº“:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other-libraries%EF%BD%9C%E5%85%B6%E4%BB%96%E5%BA%93"&gt;Other librariesï½œå…¶ä»–åº“:&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#tutorials-examples%EF%BD%9C%E6%95%99%E7%A8%8B-%E7%A4%BA%E4%BE%8B"&gt;Tutorials &amp;amp; examplesï½œæ•™ç¨‹ &amp;amp; ç¤ºä¾‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#paper-implementations%EF%BD%9C%E8%AE%BA%E6%96%87%E5%AE%9E%E7%8E%B0"&gt;Paper implementationsï½œè®ºæ–‡å®ç°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#talks-conferences%EF%BD%9C%E6%8A%A5%E5%91%8A-%E4%BC%9A%E8%AE%AE"&gt;Talks &amp;amp; conferencesï½œæŠ¥å‘Š &amp;amp; ä¼šè®®&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pytorch-elsewhere-%EF%BD%9C-pytorch%E7%9B%B8%E5%85%B3"&gt;Pytorch elsewhere ï½œ Pytorchç›¸å…³&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-pytorch--related-librariespytorch--ç›¸å…³åº“" class="anchor" aria-hidden="true" href="#pytorch--related-librariespytorch--ç›¸å…³åº“"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pytorch &amp;amp; related librariesï½œPytorch &amp;amp; ç›¸å…³åº“&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://pytorch.org" rel="nofollow"&gt;pytorch&lt;/a&gt;: Tensors and Dynamic neural networks in Python with strong GPU acceleration | ä½¿ç”¨å¼ºGPUåŠ é€Ÿçš„Pythonå¼ é‡è®¡ç®—å’ŒåŠ¨æ€ç¥ç»ç½‘ç»œ.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-nlp--speech-processingè‡ªç„¶è¯­è¨€å¤„ç†--è¯­éŸ³å¤„ç†" class="anchor" aria-hidden="true" href="#nlp--speech-processingè‡ªç„¶è¯­è¨€å¤„ç†--è¯­éŸ³å¤„ç†"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NLP &amp;amp; Speech Processingï½œè‡ªç„¶è¯­è¨€å¤„ç† &amp;amp; è¯­éŸ³å¤„ç†:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;2000+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/text"&gt;text&lt;/a&gt;: é’ˆå¯¹æ–‡æœ¬æ•°æ®å’ŒNLPæ•°æ®é›†çš„æ•°æ®åŠ è½½å’ŒæŠ½è±¡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/IBM/pytorch-seq2seq"&gt;pytorch-seq2seq&lt;/a&gt;: Pytorchä¸­å¤„ç†seq2seqçš„å¼€æºæ¡†æ¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Sandeep42/anuvada"&gt;anuvada&lt;/a&gt;: NLPå¯è§£é‡Šæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/audio"&gt;audio&lt;/a&gt;: ç®€å•çš„éŸ³é¢‘I/Oã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/loop"&gt;loop&lt;/a&gt;:  ä¸€ç§è·¨å¤šè¯´è¯è€…çš„è¯­éŸ³ç”Ÿæˆæ–¹æ³•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;6000+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/fairseq-py"&gt;fairseq&lt;/a&gt;: Facebookå¼€å‘çš„Sequence-to-Sequence pythonå·¥å…·åŒ…ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/awni/speech"&gt;speech&lt;/a&gt;: è¯­éŸ³è½¬æ–‡å­—çš„ç«¯åˆ°ç«¯æ¨¡å‹å®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3500+&lt;/kbd&gt; &lt;a href="https://github.com/OpenNMT/OpenNMT-py"&gt;OpenNMT-py&lt;/a&gt;: å¼€æºç¥ç»æœºå™¨ç¿»è¯‘ &lt;a href="http://opennmt.net" rel="nofollow"&gt;http://opennmt.net&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/huggingface/neuralcoref"&gt;neuralcoref&lt;/a&gt;: åœ¨spaCyä¸­ä½¿ç”¨ç¥ç»ç½‘ç»œå®ç°å¿«é€Ÿå…±æŒ‡æ¶ˆè§£ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/sentiment-discovery"&gt;sentiment-discovery&lt;/a&gt;: åŸºäºè§„æ¨¡çš„æ— ç›‘ç£è¯­è¨€æ¨¡å‹åœ¨ç¨³å¥æƒ…ç»ªåˆ†ç±»ä¸­çš„åº”ç”¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2200+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/MUSE"&gt;MUSE&lt;/a&gt;: ä¸€ä¸ªå¤šè¯­è¨€æ— ç›‘ç£æˆ–æœ‰ç›‘ç£è¯è¯­åµŒå…¥åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/lium-lst/nmtpytorch"&gt;nmtpytorch&lt;/a&gt;: PyTorchä¸­çš„Sequence-to-Sequenceæ¡†æ¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/vincentherrmann/pytorch-wavenet"&gt;pytorch-wavenet&lt;/a&gt;: å¿«é€Ÿç”ŸæˆWaveNetçš„å®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/soobinseo/Tacotron-pytorch"&gt;Tacotron-pytorch&lt;/a&gt;: Tacotron: ç«¯åˆ°ç«¯è¯­éŸ³åˆæˆã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;7400+&lt;/kbd&gt; &lt;a href="https://github.com/allenai/allennlp"&gt;AllenNLP&lt;/a&gt;: å¼€æºNLPç ”ç©¶åº“ï¼ŒåŸºäºPyTorchã€‚&lt;a href="https://allennlp.org" rel="nofollow"&gt;http://www.allennlp.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1500+&lt;/kbd&gt; &lt;a href="https://github.com/PetrochukM/PyTorch-NLP"&gt;PyTorch-NLP&lt;/a&gt;: ä¸ºåŠ é€ŸNLPç ”ç©¶è®¾ç«‹çš„ä¸€ä¸ªåº“ï¼ŒåŒ…å«ç¥ç»ç½‘ç»œå±‚ã€æ–‡æœ¬å¤„ç†æ¨¡å—å’Œä¼—å¤šæ•°æ®é›†ã€‚ pytorchnlp.readthedocs.io&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/outcastofmusic/quick-nlp"&gt;quick-nlp&lt;/a&gt;: åŸºäºFastAIçš„Pytorch NLPåº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/mozilla/TTS"&gt;TTS&lt;/a&gt;: æ–‡æœ¬è½¬è¯­éŸ³çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2000+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/LASER"&gt;LASER&lt;/a&gt;: LASERæ˜¯ä¸€ä¸ªç”¨æ¥è®¡ç®—å’Œä½¿ç”¨å¤šè¯­è¨€è¯­å¥åµŒå…¥çš„åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pyannote/pyannote-audio"&gt;pyannote-audio&lt;/a&gt;: ç”¨äºè¯´è¯äººåˆ†ç±»çš„ç¥ç»æ„å»ºå—ï¼šè¯­éŸ³æ´»åŠ¨æ£€æµ‹, è¯´è¯äººå˜åŒ–æ£€æµ‹, è¯´è¯äººåµŒå…¥ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Maluuba/gensen"&gt;gensen&lt;/a&gt;: åŸºäºå¤§è§„æ¨¡å¤šä»»åŠ¡å­¦ä¹ çš„é€šç”¨å¥å­è¡¨ç¤ºã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/translate"&gt;translate&lt;/a&gt;: ç¿»è¯‘â€”â€”ä¸€ä¸ªPyTorchè¯­è¨€åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1500+&lt;/kbd&gt; &lt;a href="https://github.com/espnet/espnet"&gt;espnet&lt;/a&gt;: ç«¯åˆ°ç«¯è¯­éŸ³å¤„ç†å·¥å…·é›†ã€‚ espnet.github.io/espnet&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2800+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/pythia"&gt;pythia&lt;/a&gt;: æºäºFAIR(Facebook AI Research)çš„è§†è§‰ä¸è¯­è¨€å¤šæ¨¡æ€ç ”ç©¶çš„æ¨¡å—åŒ–æ¡†æ¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/UnsupervisedMT"&gt;UnsupervisedMT&lt;/a&gt;: åŸºäºçŸ­è¯­çš„ç¥ç»æ— ç›‘ç£æœºå™¨ç¿»è¯‘ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jsalt18-sentence-repl/jiant"&gt;jiant&lt;/a&gt;: é€šç”¨æ–‡æœ¬ç†è§£æ¨¡å‹çš„jiantå·¥å…·åŒ…ã€‚&lt;a href="https://jiant.info" rel="nofollow"&gt;https://jiant.info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2900+&lt;/kbd&gt; &lt;a href="https://github.com/codertimo/BERT-pytorch"&gt;BERT-PyTorch&lt;/a&gt;: Google AI 2018 BERT çš„ Pytorch å®ç°ï¼Œä¼´æœ‰ç®€å•æ³¨é‡Šã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/InferSent"&gt;InferSent&lt;/a&gt;: NLIçš„å¥å­åµŒå…¥(InferSent)å’Œè®­ç»ƒä»£ç ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/google/uis-rnn"&gt;uis-rnn&lt;/a&gt;:æ— é™äº¤é”™çŠ¶æ€é€’å½’ç¥ç»ç½‘ç»œ(UIS-RNN)ç®—æ³•ï¼Œèƒ½å¤Ÿä»å˜ˆæ‚çš„ç¯å¢ƒä¸­åˆ†è¾¨å£°éŸ³ï¼Œå¯¹åº”è®ºæ–‡ Fully Supervised Speaker Diarization. arxiv.org/abs/1810.04719&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;7500+&lt;/kbd&gt; &lt;a href="https://github.com/zalandoresearch/flair"&gt;flair&lt;/a&gt;: ä¸€ä¸ªé’ˆå¯¹æœ€å…ˆè¿›çš„NLPçš„ç®€å•æ¡†æ¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5500+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/pytext"&gt;pytext&lt;/a&gt;: åŸºäºPyTorchçš„è‡ªç„¶è¯­è¨€å»ºæ¨¡æ¡†æ¶ã€‚ fb.me/pytextdocs&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/mindslab-ai/voicefilter"&gt;voicefilter&lt;/a&gt;: è°·æ­ŒAIçš„VoiceFilterçš„éå®˜æ–¹å®ç°ã€‚ &lt;a href="http://swpark.me/voicefilter" rel="nofollow"&gt;http://swpark.me/voicefilter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kamalkraj/BERT-NER"&gt;BERT-NER&lt;/a&gt;: åŸºäºBERTçš„å‘½åä½“è¯†åˆ«(Named-Entity-Recognition)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/feedly/transfer-nlp"&gt;transfer-nlp&lt;/a&gt;: ä¸ºå¯å¤åˆ¶å®éªŒç®¡ç†è€Œè®¾è®¡çš„NLPåº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/asyml/texar-pytorch"&gt;texar-pytorch&lt;/a&gt;: æœºå™¨å­¦ä¹ å’Œæ–‡æœ¬ç”Ÿæˆå·¥å…·åŒ…ã€‚ texar.io&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/mravanelli/pytorch-kaldi"&gt;pytorch-kaldi&lt;/a&gt;: pytorch-kaldi æ˜¯ä¸€ä¸ªå¼€å‘ä¸­çš„æœ€å…ˆè¿›çš„dnn/rnnæ··åˆè¯­éŸ³è¯†åˆ«ç³»ç»Ÿã€‚å…¶DNNéƒ¨åˆ†ç”±PyTorchå®ç°ï¼Œè€Œç‰¹å¾æå–ã€æ ‡ç­¾è®¡ç®—å’Œè§£ç ç”±kaldiå·¥å…·åŒ…å®Œæˆã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/NVIDIA/NeMo"&gt;NeMo&lt;/a&gt;: ç¥ç»æ¨¡å—ï¼šå¯¹è¯å¼AIï¼ˆconversational AIï¼‰å·¥å…·é›† nvidia.github.io/NeMo&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/harvardnlp/pytorch-struct"&gt;pytorch-struct&lt;/a&gt;: ç»è¿‡æµ‹è¯•çš„GPUå®ç°åº“ï¼Œå®ç°äº†æ·±åº¦å­¦ä¹ ä¸­çš„ä¸€äº›æ ¸å¿ƒçš„ç»“æ„åŒ–ç®—æ³•ï¼Œå¦‚HMM, Dep Trees, CKY, ...&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/freewym/espresso"&gt;espresso&lt;/a&gt;: Espresso: å¿«é€Ÿçš„ç«¯åˆ°ç«¯ç¥ç»è¯­éŸ³è¯†åˆ«å·¥å…·é›†ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huggingface/transformers"&gt;transformers&lt;/a&gt;: huggingface Transformers: TensorFlow 2.0  å’Œ PyTorch ä¸Šæœ€å…ˆè¿›çš„NLPå·¥å…·ã€‚huggingface.co/transformers&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lucidrains/reformer-pytorch"&gt;reformer-pytorch&lt;/a&gt;: &lt;a href="https://openreview.net/pdf?id=rkgNKkHtvB" rel="nofollow"&gt;Reformer&lt;/a&gt; çš„ PyTorch ç‰ˆã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-cvè®¡ç®—æœºè§†è§‰" class="anchor" aria-hidden="true" href="#cvè®¡ç®—æœºè§†è§‰"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CVï½œè®¡ç®—æœºè§†è§‰:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;4800+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/vision"&gt;pytorch vision&lt;/a&gt;: TorchVisionåŒ…å«æµè¡Œçš„æ•°æ®é›†ã€æ¨¡å‹æ¶æ„ã€è®¡ç®—æœºè§†è§‰ä¸­å¸¸ç”¨çš„å›¾åƒå˜æ¢ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tymokvo/pt-styletransfer"&gt;pt-styletransfer&lt;/a&gt;: ä½œä¸ºPyTorchä¸­ä¸€ä¸ªç±»çš„ç¥ç»é£æ ¼è½¬ç§»ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/thnkim/OpenFacePytorch"&gt;OpenFacePytorch&lt;/a&gt;: ä½¿ç”¨OpenFaceçš„nn4.small2.v1.t7æ¨¡å‹çš„PyTorchæ¨¡å—ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/felixgwu/img_classification_pk_pytorch"&gt;img_classification_pk_pytorch&lt;/a&gt;: å°†ä½ çš„å›¾åƒåˆ†ç±»æ¨¡å‹å’Œæœ€å…ˆè¿›çš„æ¨¡å‹è¿›è¡Œå¿«é€Ÿæ¯”è¾ƒ (æ¯”å¦‚DenseNet, ResNet, ...)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/SparseConvNet"&gt;SparseConvNet&lt;/a&gt;: å­æµå½¢ç¨€ç–å·ç§¯ç¥ç»ç½‘ç»œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/automan000/Convolution_LSTM_pytorch"&gt;Convolution_LSTM_pytorch&lt;/a&gt;: å¤šå±‚å·ç§¯LSTM(é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ)æ¨¡å—ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3200+&lt;/kbd&gt; &lt;a href="https://github.com/1adrianb/face-alignment"&gt;face-alignment&lt;/a&gt;: &lt;g-emoji class="g-emoji" alias="fire" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png"&gt;ğŸ”¥&lt;/g-emoji&gt; åŸºäº PyTorch çš„ 2D å’Œ 3D é¢éƒ¨å¯¹é½åº“ã€‚ adrianbulat.com&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/ZijunDeng/pytorch-semantic-segmentation"&gt;pytorch-semantic-segmentation&lt;/a&gt;: è¯­ä¹‰åˆ†å‰²ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/longcw/RoIAlign.pytorch"&gt;RoIAlign.pytorch&lt;/a&gt;: PyTorchç‰ˆæœ¬çš„RoIAlignã€‚å…¶å®ç°åŸºäºcrop_and_resizeï¼Œæ”¯æŒCPUå’ŒGPUä¸Šçš„å‰å‘å’Œåå‘ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/creafz/pytorch-cnn-finetune"&gt;pytorch-cnn-finetune&lt;/a&gt;: ç”¨PyTorchå¾®è°ƒé¢„è®­ç»ƒå·ç§¯ç¥ç»ç½‘ç»œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ignacio-rocco/detectorch"&gt;detectorch&lt;/a&gt;: Detectorch - PyTorchç‰ˆdetectronæ¡†æ¶ï¼Œç›®å‰ä»…æœ‰detectronçš„æ¨æ–­(inference)å’Œè¯„ä¼°(evalutaion)åŠŸèƒ½ï¼Œæ— è®­ç»ƒ(training)åŠŸèƒ½ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3500+&lt;/kbd&gt; &lt;a href="https://github.com/mdbloice/Augmentor"&gt;Augmentor&lt;/a&gt;: ç”¨äºæœºå™¨å­¦ä¹ çš„å›¾åƒå¢å¼ºåº“ã€‚ &lt;a href="http://augmentor.readthedocs.io" rel="nofollow"&gt;http://augmentor.readthedocs.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jonas-koehler/s2cnn"&gt;s2cnn&lt;/a&gt;: Spherical CNNsï¼šçƒé¢å·ç§¯ç½‘ç»œçš„PyTorchå®ç°ã€‚ (e.g. å…¨æ–¹ä½å›¾åƒã€å…¨çƒä¿¡å·)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnyyou/torchcv"&gt;TorchCV&lt;/a&gt;: åŸºäºPyTorchçš„è®¡ç®—æœºè§†è§‰æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;6800+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/maskrcnn-benchmark"&gt;maskrcnn-benchmark&lt;/a&gt;: å®ä¾‹åˆ†å‰²ä¸å¯¹è±¡æ£€æµ‹çš„å¿«é€Ÿæ¨¡å—åŒ–å‚è€ƒå®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/osmr/imgclsmob"&gt;image-classification-mobile&lt;/a&gt;: è®¡ç®—æœºè§†è§‰å·ç§¯ç½‘ç»œè®­ç»ƒæ²™ç›’ï¼ŒåŒ…å«ImageNet-1Kä¸Šçš„ä¸è®­ç»ƒåˆ†ç±»æ¨¡å‹é›†åˆã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/perone/medicaltorch"&gt;medicaltorch&lt;/a&gt;: ä¸€ä¸ªåŒ»å­¦æˆåƒæ¡†æ¶ã€‚&lt;a href="http://medicaltorch.readthedocs.io" rel="nofollow"&gt;http://medicaltorch.readthedocs.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3800+&lt;/kbd&gt; &lt;a href="https://github.com/albu/albumentations"&gt;albumentations&lt;/a&gt;: å¿«é€Ÿå›¾åƒå¢å¼ºåº“å’Œå…¶ä»–åº“çš„æ˜“ç”¨åŒ…è£…å™¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/arraiyopensource/kornia"&gt;kornia&lt;/a&gt;: å¼€æºå¯å¾®è®¡ç®—æœºè§†è§‰åº“ã€‚&lt;a href="https://kornia.org" rel="nofollow"&gt;https://kornia.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/s3nh/text-detector"&gt;text-detector&lt;/a&gt;: æ£€æµ‹å’Œç¿»è¯‘æ–‡æœ¬ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/timesler/facenet-pytorch"&gt;facenet-pytorch&lt;/a&gt;: é¢„è®­ç»ƒPytorchäººè„¸æ£€æµ‹ä¸è¯†åˆ«æ¨¡å‹ï¼Œä» &lt;a href="https://github.com/davidsandberg/facenet"&gt;davidsandberg/facenet&lt;/a&gt; ç§»æ¤è€Œæ¥ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/detectron2"&gt;detectron2&lt;/a&gt;: Detectron2æ˜¯FAIRçš„ä¸‹ä¸€ä»£ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²ç ”ç©¶å¹³å°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Media-Smart/vedaseg"&gt;vedaseg&lt;/a&gt;: åŸºäºPyTorchçš„è¯­ä¹‰åˆ†å‰²å·¥å…·ç®±ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/ClassyVision"&gt;ClassyVision&lt;/a&gt;: Aç”¨äºå›¾åƒå’Œè§†é¢‘åˆ†ç±»çš„ç«¯åˆ°ç«¯PyTorchæ¡†æ¶ã€‚&lt;a href="https://classyvision.ai" rel="nofollow"&gt;https://classyvision.ai&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/alankbi/detecto"&gt;detecto&lt;/a&gt;: ç”¨ 5 è¡Œä»£ç æ„å»ºåŠŸèƒ½å®Œå¤‡çš„è®¡ç®—æœºè§†è§‰æ¨¡å‹ã€‚&lt;a href="https://detecto.readthedocs.io/" rel="nofollow"&gt;https://detecto.readthedocs.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/pytorch3d"&gt;pytorch3d&lt;/a&gt;: PyTorch3d æ˜¯ä¸€ä¸ªé¢å‘æ·±åº¦å­¦ä¹ çš„é«˜æ•ˆã€å¯å¤ç”¨çš„ 3D è®¡ç®—æœºè§†è§‰åº“ã€‚ &lt;a href="https://pytorch3d.org/" rel="nofollow"&gt;https://pytorch3d.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-probabilisticgenerative-librariesæ¦‚ç‡åº“å’Œç”Ÿæˆåº“" class="anchor" aria-hidden="true" href="#probabilisticgenerative-librariesæ¦‚ç‡åº“å’Œç”Ÿæˆåº“"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Probabilistic/Generative Librariesï½œæ¦‚ç‡åº“å’Œç”Ÿæˆåº“:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/stepelu/ptstat"&gt;ptstat&lt;/a&gt;: æ¦‚ç‡ç¼–ç¨‹å’Œç»Ÿè®¡æ¨æ–­ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5700+&lt;/kbd&gt; &lt;a href="https://github.com/uber/pyro"&gt;pyro&lt;/a&gt;: åŸºäº Python å’Œ PyTorch çš„æ·±åº¦é€šç”¨æ¦‚ç‡ç¼–ç¨‹åº“ã€‚ &lt;a href="http://pyro.ai" rel="nofollow"&gt;http://pyro.ai&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/probtorch/probtorch"&gt;probtorch&lt;/a&gt;: Probabilistic Torchæ˜¯ä¸€ä¸ªæ‰©å±•äº†PyTorchçš„æ·±åº¦ç”Ÿæˆæ¨¡å‹çš„åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/drckf/paysage"&gt;paysage&lt;/a&gt;: åŸºäºPython/PyTorchçš„éç›‘ç£å­¦ä¹ å’Œç”Ÿæˆæ¨¡å‹åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ctallec/pyvarinf"&gt;pyvarinf&lt;/a&gt;: PythonåŒ…ï¼Œä¿ƒè¿›äº†å¸¦æœ‰å˜åˆ†æ¨æ–­çš„è´å¶æ–¯æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨pytorchä¸­çš„åº”ç”¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/probprog/pyprob"&gt;pyprob&lt;/a&gt;: ä¸€ä¸ªåŸºäºPyTorchçš„æ¦‚ç‡ç¼–ç¨‹ä¸æ¨æ–­ç¼–è¯‘çš„åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/spring-epfl/mia"&gt;mia&lt;/a&gt;: ä¸€ä¸ªè¿è¡Œé’ˆå¯¹æœºå™¨å­¦ä¹ æ¨¡å‹çš„æˆå‘˜æ¨ç†æ”»å‡»çš„åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/akanimax/pro_gan_pytorch"&gt;pro_gan_pytorch&lt;/a&gt;: ä½œä¸ºPyTorch nn.Moduleçš„æ‰©å±•çš„ProGANåŒ…ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1300+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/botorch"&gt;botorch&lt;/a&gt;: PyTorchä¸­çš„è´å¶æ–¯ä¼˜åŒ–ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-other-librarieså…¶ä»–åº“" class="anchor" aria-hidden="true" href="#other-librarieså…¶ä»–åº“"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other librariesï½œå…¶ä»–åº“:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mrdrozdov/pytorch-extras"&gt;pytorch extras&lt;/a&gt;: PyTorchçš„é¢å¤–ç‰¹æ€§ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/szagoruyko/functional-zoo"&gt;functional zoo&lt;/a&gt;: PyTorchå’ŒTensorflowçš„æ¨¡å‹å®šä¹‰å’Œé¢„è®­ç»ƒæƒé‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1300+&lt;/kbd&gt; &lt;a href="https://github.com/ncullen93/torchsample"&gt;torch-sampling&lt;/a&gt;: Pytorchçš„é‡‡æ ·ã€é«˜çº§è®­ç»ƒã€æ•°æ®å¢å¼ºå’Œå®ç”¨ç¨‹åºã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/deepcraft/torchcraft-py"&gt;torchcraft-py&lt;/a&gt;: TorchCraftçš„PythonåŒ…è£…å™¨ï¼ŒTorchCraftæ˜¯è¿æ¥Torchå’ŒStarCraftçš„æ¡¥æ¢ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ramon-oliveira/aorun"&gt;aorun&lt;/a&gt;: Aorunè¯•å›¾ä»¥PyTorchä¸ºåç«¯å®ç°ç±»ä¼¼äºKerasçš„APIã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/oval-group/logger"&gt;logger&lt;/a&gt;: æœºå™¨å­¦ä¹ è®°å½•å™¨ï¼ˆloggerï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/iamaziz/PyTorch-docset"&gt;PyTorch-docset&lt;/a&gt;: PyTorchç¦»çº¿æ–‡æ¡£ï¼Œç»“åˆDashï¼ŒZealï¼ŒVelocityæˆ–è€…LovelyDocsä½¿ç”¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/clcarwin/convert_torch_to_pytorch"&gt;convert_torch_to_pytorch&lt;/a&gt;: å°†Torch t7æ¨¡å‹è½¬æ¢ä¸ºPyTorchæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5500+&lt;/kbd&gt; &lt;a href="https://github.com/Cadene/pretrained-models.pytorch"&gt;pretrained-models.pytorch&lt;/a&gt;: PyTorch é¢„è®­ç»ƒå·ç§¯ç¥ç»ç½‘ç»œï¼šNASNet, ResNeXt, ResNet, InceptionV4, InceptionResnetV2, Xception, DPN ç­‰ç­‰ã€‚è¯¥é¡¹ç›®çš„ç›®æ ‡æ˜¯å¸®åŠ©å¤åˆ¶ç ”ç©¶è®ºæ–‡ç»“æœã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/locuslab/pytorch_fft"&gt;pytorch_fft&lt;/a&gt;: CUDA FFTsçš„PyTorchåŒ…è£…å™¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fanq15/caffe_to_torch_to_pytorch"&gt;caffe_to_torch_to_pytorch&lt;/a&gt;: Caffeæ¨¡å‹è½¬PyTorch/Torchæ¨¡å‹ï¼ŒTorchæ¨¡å‹è½¬PyTorchæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/sniklaus/pytorch-extension"&gt;pytorch-extension&lt;/a&gt;: PyTorchçš„CUDAæ‰©å±•ç¤ºä¾‹ï¼Œè®¡ç®—äº†ä¸¤ä¸ªå¼ é‡çš„&lt;a href="https://baike.baidu.com/item/%E5%93%88%E8%BE%BE%E7%8E%9B%E7%A7%AF/18894493?fr=aladdin" rel="nofollow"&gt;å“ˆè¾¾ç›ç§¯(Hadamard product)&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5700+&lt;/kbd&gt; &lt;a href="https://github.com/lanpa/tensorboard-pytorch"&gt;tensorboard-pytorch&lt;/a&gt;: è¯¥æ¨¡å—ä»¥tensorboardæ ¼å¼ä¿å­˜PyTorchå¼ é‡ä»¥ä¾›æ£€æŸ¥ã€‚ç›®å‰æ”¯æŒtensorboardä¸­çš„æ ‡é‡ã€å›¾åƒã€éŸ³é¢‘ã€ç›´æ–¹å›¾ç­‰ç‰¹æ€§ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/jrg365/gpytorch"&gt;gpytorch&lt;/a&gt;: GPyTorchæ˜¯ä¸€ä¸ªç”¨PyTorchå®ç°çš„é«˜æ–¯è¿‡ç¨‹åº“ã€‚å®ƒå¯ä»¥è½»æ¾åœ°åˆ›å»ºå¯ä¼¸ç¼©ã€çµæ´»å’Œæ¨¡å—åŒ–çš„é«˜æ–¯è¿‡ç¨‹æ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1900+&lt;/kbd&gt; &lt;a href="https://github.com/maciejkula/spotlight"&gt;spotlight&lt;/a&gt;: æ·±åº¦æ¨èæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/awentzonline/pytorch-cns"&gt;pytorch-cns&lt;/a&gt;: åŸºäºPyTorchçš„å¹¿ä¹‰å‹ç¼©ç½‘ç»œæœç´¢ï¼ˆGeneralized &lt;a href="http://people.idsia.ch/~juergen/compressednetworksearch.html" rel="nofollow"&gt;Compressed Network Search&lt;/a&gt;ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/szagoruyko/pyinn"&gt;pyinn&lt;/a&gt;: CuPyå®ç°èåˆPyTorchæ“ä½œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/nasimrahaman/inferno"&gt;inferno&lt;/a&gt;: å…³äºPyTorchçš„å®ç”¨ç¨‹åºåº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/henryre/pytorch-fitmodule"&gt;pytorch-fitmodule&lt;/a&gt;: ä¸€ç§ç”¨äºPyTorchæ¨¡å—çš„è¶…ç®€å•æ‹Ÿåˆæ–¹æ³•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2600+&lt;/kbd&gt; &lt;a href="https://github.com/dnouri/inferno"&gt;inferno-sklearn&lt;/a&gt;: ä¸€ä¸ªåŸºäºPyTorchå°è£…ä¸”å…¼å®¹scikit-learnçš„ç¥ç»ç½‘ç»œåº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/marvis/pytorch-caffe-darknet-convert"&gt;pytorch-caffe-darknet-convert&lt;/a&gt;: åœ¨ pytorch, caffe prototxt/weights å’Œ darknet cfg/weights ä¹‹é—´è½¬æ¢ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/longcw/pytorch2caffe"&gt;pytorch2caffe&lt;/a&gt;: å°†PyTorchæ¨¡å‹è½¬æ¢æˆCaffeæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/nearai/pytorch-tools"&gt;pytorch-tools&lt;/a&gt;: PyTorchå·¥å…·ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/taolei87/sru"&gt;sru&lt;/a&gt;: è®­ç»ƒRNNså’Œè®­ç»ƒCNNsä¸€æ ·å¿«ã€‚ (arxiv.org/abs/1709.02755)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/prisma-ai/torch2coreml"&gt;torch2coreml&lt;/a&gt;: Torch7 -&amp;gt; CoreMLï¼Œè¯¥å·¥å…·å¯å°†Torch7æ¨¡å‹è½¬æ¢ä¸º&lt;a href="https://developer.apple.com/documentation/coreml" rel="nofollow"&gt;Apple CoreML&lt;/a&gt;æ ¼å¼ä»¥ä¾¿åœ¨Appleè®¾å¤‡ä¸Šè¿è¡Œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/zhanghang1989/PyTorch-Encoding"&gt;PyTorch-Encoding&lt;/a&gt;: PyTorch æ·±åº¦çº¹ç†ç¼–ç ç½‘ç»œ (Deep Texture Encoding Network) &lt;a href="http://hangzh.com/PyTorch-Encoding" rel="nofollow"&gt;http://hangzh.com/PyTorch-Encoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ryanleary/pytorch-ctc"&gt;pytorch-ctc&lt;/a&gt;: PyTorch-CTC å®ç°äº†CTC(è”ç»“ä¸»ä¹‰æ—¶é—´åˆ†ç±»ï¼ŒConnectionist Temporal Classification)é›†æŸæœç´¢ï¼ˆBeam Searchï¼‰è§£ç ã€‚C++ä»£ç å€Ÿé‰´äº†TensorFlowï¼Œå¹¶é€šè¿‡ä¸€äº›æ”¹è¿›å¢åŠ äº†çµæ´»æ€§ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/t-vi/candlegp"&gt;candlegp&lt;/a&gt;: Pytorchä¸­çš„é«˜æ–¯è¿‡ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/loudinthecloud/dpwa"&gt;dpwa&lt;/a&gt;: åŸºäºæˆå¯¹å¹³å‡ï¼ˆPair-Wise Averagingï¼‰çš„åˆ†å¸ƒå¼å­¦ä¹ ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/koz4k/dni-pytorch"&gt;dni-pytorch&lt;/a&gt;: åŸºäºåˆæˆæ¢¯åº¦çš„PyTorchè§£è€¦ç¥ç»æ¥å£ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2600+&lt;/kbd&gt; &lt;a href="https://github.com/dnouri/skorch"&gt;skorch&lt;/a&gt;: ä¸€ä¸ªåŸºäºPyTorchå°è£…ä¸”å…¼å®¹scikit-learnçš„ç¥ç»ç½‘ç»œåº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2300+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/ignite"&gt;ignite&lt;/a&gt;: Igniteæ˜¯ä¸€ä¸ªé«˜çº§åº“ï¼Œå¸®åŠ©ä½ åœ¨PyTorchä¸­è®­ç»ƒç¥ç»ç½‘ç»œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/glample/Arnold"&gt;Arnold&lt;/a&gt;: Arnold - DOOM æ¸¸æˆä»£ç†ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/albanie/pytorch-mcn"&gt;pytorch-mcn&lt;/a&gt;: å°†MatConvNetæ¨¡å‹è½¬æ¢ä¸ºPyTorchæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1900+&lt;/kbd&gt; &lt;a href="https://github.com/chenyuntc/simple-faster-rcnn-pytorch"&gt;simple-faster-rcnn-pytorch&lt;/a&gt;: Faster R-CNN çš„ç®€åŒ–å®ç°ï¼Œæ€§èƒ½ä¸åŸå§‹è®ºæ–‡ç›¸å½“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/DL-IT/generative_zoo"&gt;generative_zoo&lt;/a&gt;: generative_zooæä¾›äº†PyTorchä¸­ä¸€äº›ç”Ÿæˆæ¨¡å‹çš„å·¥ä½œå®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/szagoruyko/pytorchviz"&gt;pytorchviz&lt;/a&gt;: å¯è§†åŒ–PyTorchçš„è¿è¡Œå›¾ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/cogitare-ai/cogitare"&gt;cogitare&lt;/a&gt;: Cogitare - ä¸€ä¸ªç°ä»£ã€å¿«é€Ÿã€æ¨¡å—åŒ–çš„æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ æ¡†æ¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dmarnerides/pydlt"&gt;pydlt&lt;/a&gt;: åŸºäºPyTorchçš„æ·±åº¦å­¦ä¹ å·¥å…·ç®±ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wohlert/semi-supervised-pytorch"&gt;semi-supervised-pytorch&lt;/a&gt;: å„ç§åŸºäºVAEçš„åŠç›‘ç£æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹çš„å®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rusty1s/pytorch_cluster"&gt;pytorch_cluster&lt;/a&gt;: ä¼˜åŒ–å›¾ç°‡ç®—æ³•çš„PyTorchæ‰©å±•åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/aditya-khant/neural-assembly-compiler"&gt;neural-assembly-compiler&lt;/a&gt;: åŸºäºè‡ªé€‚åº”ç¥ç»ç¼–è¯‘çš„PyTorchç¥ç»æ±‡ç¼–ç¼–è¯‘å™¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/vadimkantorov/caffemodel2pytorch"&gt;caffemodel2pytorch&lt;/a&gt;: å°†Caffeæ¨¡å‹è½¬æ¢ä¸ºPyTorchæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/extension-cpp"&gt;extension-cpp&lt;/a&gt;: PyTorchä¸­çš„C++æ‰©å±•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/GRAAL-Research/pytoune"&gt;pytoune&lt;/a&gt;: ç±»Kerasæ¡†æ¶å’Œå®ç”¨ç¨‹åºã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dusty-nv/jetson-reinforcement"&gt;jetson-reinforcement&lt;/a&gt;: ä½¿ç”¨PyTorchï¼ŒOpenAI Gymå’ŒGazeboæœºå™¨äººæ¨¡æ‹Ÿçš„NVIDIA Jetsonæ·±åº¦å¼ºåŒ–å­¦ä¹ GPUåº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/salesforce/matchbox"&gt;matchbox&lt;/a&gt;: ç¼–å†™å•ä¸ªç¤ºä¾‹çš„PyTorchä»£ç ï¼Œç„¶åå°æ‰¹é‡åœ°é«˜æ•ˆè¿è¡Œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/josipd/torch-two-sample"&gt;torch-two-sample&lt;/a&gt;: PyTorchåŒæ ·æœ¬æµ‹è¯•åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/sksq96/pytorch-summary"&gt;pytorch-summary&lt;/a&gt;: PyTorchæ¨¡å‹æ€»ç»“ï¼Œç±»ä¼¼äºKerasä¸­çš„&lt;code&gt;model.summary()&lt;/code&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BelBES/mpl.pytorch"&gt;mpl.pytorch&lt;/a&gt;: MaxPoolingLossçš„PyTorchå®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/YosefLab/scVI-dev"&gt;scVI-dev&lt;/a&gt;: é“¾æ¥å¤±æ•ˆã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2800+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/apex"&gt;apex&lt;/a&gt;: ä¸€ä¸ªPyTorchæ‰©å±•ï¼šé¢å‘ç²¾ç®€æ··åˆç²¾åº¦å’Œåˆ†å¸ƒå¼è®­ç»ƒã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2900+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/ELF"&gt;ELF&lt;/a&gt;: ELF: æ¸¸æˆç ”ç©¶å¹³å°ï¼Œå¤ç°äº†AlphaGoZero/AlphaZeroã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/EKami/Torchlite"&gt;Torchlite&lt;/a&gt;: Pytorchå»ºç«‹åœ¨sklearnã€Pytorchå’ŒTensorflowç­‰æµè¡Œæœºå™¨å­¦ä¹ æ¡†æ¶ä¸Šçš„é«˜æ°´å¹³åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Schlumberger/joint-vae"&gt;joint-vae&lt;/a&gt;: JointVAEçš„PyTorchå®ç°ï¼Œä¸€ä¸ªé¢å‘åˆ†ç¦»è¿ç»­å’Œç¦»æ•£å˜å¼‚å› ç´ çš„æ¡†æ¶ &lt;g-emoji class="g-emoji" alias="star2" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png"&gt;ğŸŒŸ&lt;/g-emoji&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kengz/SLM-Lab"&gt;SLM-Lab&lt;/a&gt;: PyTorchæ¨¡å—åŒ–æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Hananel-Hazan/bindsnet"&gt;bindsnet&lt;/a&gt;: ä¸€ä¸ªPythonåŒ…ï¼Œå¯å€ŸåŠ©PyTorch &lt;code&gt;Tensor&lt;/code&gt; åŠŸèƒ½åœ¨CPUsæˆ–GPUsä¸Šæ¨¡æ‹Ÿè„‰å†²ç¥ç»ç½‘ç»œ(SNNs, Spiking Neural Networks)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/akanimax/pro_gan_pytorch"&gt;pro_gan_pytorch&lt;/a&gt;: ä½œä¸º PyTorch nn.Module æ‰©å±•çš„ ProGAN åŒ…ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5600+&lt;/kbd&gt; &lt;a href="https://github.com/rusty1s/pytorch_geometric"&gt;pytorch_geometric&lt;/a&gt;: PyTorchå‡ ä½•æ·±åº¦å­¦ä¹ æ‰©å±•åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/knighton/torchplus"&gt;torchplus&lt;/a&gt;: åœ¨ PyTorch modules ä¸Šå®ç° + è¿ç®—ç¬¦ï¼Œè¿”å›åºåˆ—ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zuoxingdong/lagom"&gt;lagom&lt;/a&gt;: lagom: ç”¨äºå¼ºåŒ–å­¦ä¹ ç®—æ³•å¿«é€ŸåŸå‹æ„å»ºçš„è½»é‡çº§PyTorchæ¶æ„ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ecs-vlc/torchbearer"&gt;torchbearer&lt;/a&gt;: torchbearer: PyTorchæ¨¡å‹æ‹Ÿåˆåº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tristandeleu/pytorch-maml-rl"&gt;pytorch-maml-rl&lt;/a&gt;: å¼ºåŒ–å­¦ä¹ ä¸­çš„æ¨¡å‹ä¸å¯çŸ¥å…ƒå­¦ä¹ (MAML, Model-Agnostic Meta-Learning)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/bharathgs/NALU"&gt;NALU&lt;/a&gt;: ç¥ç»ç®—æœ¯é€»è¾‘å•å…ƒ(Neural Arithmetic Logic Units)çš„PyTorchåŸºæœ¬å®ç°ï¼Œè®ºæ–‡ï¼šarxiv.org/pdf/1808.00508.pdf ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/PIQuIL/QuCumber"&gt;QuCumber&lt;/a&gt;: ç¥ç»ç½‘ç»œå¤šä½“æ³¢å‡½æ•°é‡æ„ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/MagNet-DL/magnet"&gt;magnet&lt;/a&gt;: è‡ªæˆ‘å»ºç«‹çš„æ·±åº¦å­¦ä¹ é¡¹ç›®ã€‚&lt;a href="http://magnet-dl.readthedocs.io/" rel="nofollow"&gt;http://magnet-dl.readthedocs.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jbohnslav/opencv_transforms"&gt;opencv_transforms&lt;/a&gt;: OpenCVå®ç°Torchvisionçš„å›¾åƒåˆ†å‰²ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;16100+&lt;/kbd&gt; &lt;a href="https://github.com/fastai/fastai"&gt;fastai&lt;/a&gt;: fast.ai æ·±åº¦å­¦ä¹ åº“ã€è¯¾ç¨‹å’Œæ•™ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/RobotLocomotion/pytorch-dense-correspondence"&gt;pytorch-dense-correspondence&lt;/a&gt;: &lt;a href="arxiv.org/pdf/1806.08756.pdf"&gt;ã€ŠDense Object Nets: Learning Dense Visual Object Descriptors By and For Robotic Manipulationã€‹&lt;/a&gt; ä¸€æ–‡çš„ä»£ç ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/richzhang/colorization-pytorch"&gt;colorization-pytorch&lt;/a&gt;: PyTorchå®ç°äº¤äº’å¼æ·±åº¦ç€è‰²(Interactive Deep Colorization)ã€‚ richzhang.github.io/ideepcolor&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/cms-flash/beauty-net"&gt;beauty-net&lt;/a&gt;: PyTorchä¸€ä¸ªç®€å•ã€çµæ´»ã€å¯æ‰©å±•çš„PyTorchæ¨¡æ¿ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Mariewelt/OpenChem"&gt;OpenChem&lt;/a&gt;: OpenChem: é¢å‘è®¡ç®—åŒ–å­¦å’Œè¯ç‰©è®¾è®¡ç ”ç©¶çš„æ·±åº¦å­¦ä¹ å·¥å…·åŒ… mariewelt.github.io/OpenChem ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/aiqm/torchani"&gt;torchani&lt;/a&gt;: PyTorchç²¾ç¡®ç¥ç»ç½‘ç»œç”µä½ã€‚ aiqm.github.io/torchani&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hjmshi/PyTorch-LBFGS"&gt;PyTorch-LBFGS&lt;/a&gt;: PyTorchå®ç°L-BFGSã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/cornellius-gp/gpytorch"&gt;gpytorch&lt;/a&gt;: PyTorchä¸­å¯¹é«˜æ–¯è¿‡ç¨‹çš„é«˜æ•ˆä¸”æ¨¡å—åŒ–çš„å®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mariogeiger/hessian"&gt;hessian&lt;/a&gt;: PyTorchç‰ˆhessianã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/MillionIntegrals/vel"&gt;vel&lt;/a&gt;: æ·±åº¦å­¦ä¹ ç ”ç©¶ä¸­çš„é€Ÿåº¦ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/msamogh/nonechucks"&gt;nonechucks&lt;/a&gt;: åŠ¨æ€åœ°å¤„ç†æ•°æ®é›†ä¸­çš„åæ ·æœ¬ï¼Œä½¿ç”¨è½¬æ¢ä½œä¸ºè¿‡æ»¤å™¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Swall0w/torchstat"&gt;torchstat&lt;/a&gt;: PyTorchä¸­çš„æ¨¡å‹åˆ†æå™¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/QNNPACK"&gt;QNNPACK&lt;/a&gt;: é‡åŒ–ç¥ç»ç½‘ç»œåŒ…â€”é‡åŒ–ç¥ç»ç½‘ç»œç®—å­çš„ç§»åŠ¨ä¼˜åŒ–å®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2600+&lt;/kbd&gt; &lt;a href="https://github.com/rtqichen/torchdiffeq"&gt;torchdiffeq&lt;/a&gt;: PyTorchè§£å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEï¼‰ï¼Œä½¿ç”¨çš„æ˜¯å…¨GPUæ”¯æŒã€O(1)å†…å­˜å¤æ‚åº¦çš„åå‘ä¼ æ’­ç®—æ³•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BachiLi/redner"&gt;redner&lt;/a&gt;: å¯å¾®çš„ Monte Carlo è·¯å¾„è·Ÿè¸ªå™¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/masa-su/pixyz"&gt;pixyz&lt;/a&gt;: ä¸€ä¸ªåº“ï¼Œç”¨æ¥ä»¥æ›´ç®€æ´ã€ç›´è§‚å’Œå¯æ‰©å±•çš„æ–¹å¼å¼€å‘æ·±å±‚ç”Ÿæˆæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/perone/euclidesdb"&gt;euclidesdb&lt;/a&gt;: ä¸€ç§å¤šæ¨¡å‹æœºå™¨å­¦ä¹ ç‰¹å¾åµŒå…¥æ•°æ®åº“ã€‚ &lt;a href="http://euclidesdb.readthedocs.io" rel="nofollow"&gt;http://euclidesdb.readthedocs.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/nerox8664/pytorch2keras"&gt;pytorch2keras&lt;/a&gt;: å°†PyTorchæ¨¡å‹è½¬æ¢ä¸ºKerasæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/domainadaptation/salad"&gt;salad&lt;/a&gt;: åŸŸé€‚åº”å’ŒåŠç›‘ç£å­¦ä¹ å·¥å…·ç®±ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Erotemic/netharn"&gt;netharn&lt;/a&gt;: PyTorchçš„å‚æ•°åŒ–æ‹Ÿåˆå’Œé¢„æµ‹çº¿æŸï¼ˆPrediction Harnessesï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3200+&lt;/kbd&gt; &lt;a href="https://github.com/dmlc/dgl"&gt;dgl&lt;/a&gt;: PythonåŒ…ï¼ŒåŸºäºç°æœ‰çš„DLæ¡†æ¶ï¼Œç”¨äºç®€åŒ–å¯¹å›¾å½¢çš„æ·±åº¦å­¦ä¹ ã€‚&lt;a href="http://dgl.ai" rel="nofollow"&gt;http://dgl.ai&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/CSAILVision/gandissect"&gt;gandissect&lt;/a&gt;: åŸºäºPyTorchçš„å·¥å…·ï¼Œç”¨äºå¯è§†åŒ–å’Œç†è§£GANçš„ç¥ç»å…ƒã€‚gandissect.csail.mit.edu&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/justusschock/delira"&gt;delira&lt;/a&gt;: åŸºäºPyTorchå’ŒTensorlowçš„å¿«é€ŸåŸå‹å’Œè®­ç»ƒæ·±å±‚ç¥ç»ç½‘ç»œçš„è½»é‡çº§æ¡†æ¶ï¼Œç”¨äºåŒ»ç–—æˆåƒã€‚ delira.rtfd.io&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/AIRLab-POLIMI/mushroom"&gt;mushroom&lt;/a&gt;: å¼ºåŒ–å­¦ä¹ å®éªŒçš„Pythonåº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/thuml/Xlearn"&gt;Xlearn&lt;/a&gt;: è¿ç§»å­¦ä¹ åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ferrine/geoopt"&gt;geoopt&lt;/a&gt;: åŸºäºPyTorchä¼˜åŒ–çš„é»æ›¼è‡ªé€‚åº”ä¼˜åŒ–æ–¹æ³•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/unit8co/vegans"&gt;vegans&lt;/a&gt;: åŒ…å«å¤šç§ç°æœ‰çš„GANsã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/arraiyopensource/kornia"&gt;kornia&lt;/a&gt;: PyTorchå¼€æºå¯å¾®è®¡ç®—æœºè§†è§‰åº“ã€‚ &lt;a href="https://kornia.org" rel="nofollow"&gt;https://kornia.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BorealisAI/advertorch"&gt;AdverTorch&lt;/a&gt;: ç ”ç©¶å¯¹æŠ—é²æ£’æ€§çš„å·¥å…·ç®±ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2500+&lt;/kbd&gt; &lt;a href="https://github.com/Luolc/AdaBound"&gt;AdaBound&lt;/a&gt;: ä¸€ä¸ªä¼˜åŒ–å™¨ï¼Œè®­ç»ƒé€Ÿåº¦å’ŒAdamä¸€æ ·å¿«ï¼Œå’ŒSGDä¸€æ ·å¥½ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mblondel/fenchel-young-losses"&gt;fenchel-young-losses&lt;/a&gt;: åœ¨PyTorch/TensorFlow/scikit-learnä¸­ä½¿ç”¨Fenchel-YoungæŸå¤±ä½œä¸ºæ¦‚ç‡åˆ†ç±»çš„æŸå¤±å‡½æ•°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/Lyken17/pytorch-OpCounter"&gt;pytorch-OpCounter&lt;/a&gt;: ç»Ÿè®¡PyTorchæ¨¡å‹çš„MACs/FLOPsã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kaihsin/Tor10"&gt;Tor10&lt;/a&gt;: åŸºäºPyTorchï¼Œä¸ºé‡å­æ¨¡æ‹Ÿè®¾è®¡çš„é€šç”¨å¼ é‡ç½‘ç»œåº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/catalyst-team/catalyst"&gt;Catalyst&lt;/a&gt;: PyTorch DL&amp;amp;RL ç ”ç©¶çš„é«˜çº§å®ç”¨ç¨‹åºã€‚å®ƒçš„å¼€å‘é‡ç‚¹æ˜¯å¯é‡å¤æ€§ã€å¿«é€Ÿå®éªŒå’Œä»£ç /æ€æƒ³é‡ç”¨ã€‚èƒ½å¤Ÿç ”ç©¶/å¼€å‘æ–°çš„ä¸œè¥¿ï¼Œè€Œä¸æ˜¯ç¼–å†™å¦ä¸€ä¸ªå¸¸è§„çš„è®­ç»ƒå¾ªç¯ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebook/Ax"&gt;Ax&lt;/a&gt;: è‡ªé€‚åº”å®éªŒå¹³å°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/achaiah/pywick"&gt;pywick&lt;/a&gt;: é«˜æ°´å¹³çš„PyTorchç¥ç»ç½‘ç»œè®­ç»ƒåº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kakaobrain/torchgpipe"&gt;torchgpipe&lt;/a&gt;: PyTorchå®ç°GPipeã€‚ torchgpipe.readthedocs.io&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/hub"&gt;hub&lt;/a&gt;: Pytorch Hub æ˜¯ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹åº“ï¼Œç”¨æ¥æå‡ç ”ç©¶çš„å¯é‡å¤æ€§ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2700+&lt;/kbd&gt; &lt;a href="https://github.com/williamFalcon/pytorch-lightning"&gt;pytorch-lightning&lt;/a&gt;: é¢å‘MLç ”ç©¶äººå‘˜çš„è½»é‡çº§PyTorchåŒ…è£…å™¨ã€‚ç¼©æ”¾æ¨¡å‹ï¼Œå°‘å†™æ ·æ¿ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kaihsin/Tor10"&gt;Tor10&lt;/a&gt;: åŸºäºpytorchä¸ºé‡å­æ¨¡æ‹Ÿè®¾è®¡çš„é€šç”¨å¼ é‡ç½‘ç»œåº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2500+&lt;/kbd&gt; &lt;a href="https://github.com/microsoft/tensorwatch"&gt;tensorwatch&lt;/a&gt;: é’ˆå¯¹Pythonæœºå™¨å­¦ä¹ ä¸æ•°æ®ç§‘å­¦çš„è°ƒè¯•ã€ç›‘æ§ä¸å¯è§†åŒ–ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fancompute/wavetorch"&gt;wavetorch&lt;/a&gt;: æ³¢åŠ¨æ–¹ç¨‹çš„æ•°å€¼æ±‚è§£ä¸åä¼ æ’­ã€‚ arxiv.org/abs/1904.12831&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ag14774/diffdist"&gt;diffdist&lt;/a&gt;: diffdistæ˜¯ä¸€ä¸ªé¢å‘PyTorchçš„Pythonåº“ã€‚å®ƒæ‰©å±•äº†&lt;code&gt;torch.autograd&lt;/code&gt;çš„é»˜è®¤åŠŸèƒ½ï¼Œå¹¶å¢åŠ äº†å¯¹è¿›ç¨‹é—´å¯å¾®é€šä¿¡çš„æ”¯æŒã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/awwong1/torchprof"&gt;torchprof&lt;/a&gt;: ç”¨äºPytorchæ¨¡å‹é€å±‚åˆ†æçš„æœ€å°ä¾èµ–åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/oxfordcontrol/osqpth"&gt;osqpth&lt;/a&gt;: PyTorchå¯å¾®OSQPæ±‚è§£å™¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mctorch/mctorch"&gt;mctorch&lt;/a&gt;: é¢å‘æ·±åº¦å­¦ä¹ çš„æµå½¢ä¼˜åŒ–åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/noahgolmant/pytorch-hessian-eigenthings"&gt;pytorch-hessian-eigenthings&lt;/a&gt;: ä½¿ç”¨Hessianå‘é‡ç§¯å’Œéšæœºå¹‚è¿­ä»£çš„é«˜æ•ˆPyTorch Hessianç‰¹å¾åˆ†è§£ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/StanfordVL/MinkowskiEngine"&gt;MinkowskiEngine&lt;/a&gt;: é—µå¯å¤«æ–¯åŸºå¼•æ“æ˜¯ä¸€ä¸ªç”¨äºå¹¿ä¹‰ç¨€ç–å·ç§¯å’Œé«˜ç»´ç¨€ç–å¼ é‡çš„è‡ªåŠ¨å¾®åˆ†æ–¹æ³•åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Omegastick/pytorch-cpp-rl"&gt;pytorch-cpp-rl&lt;/a&gt;: CppRlæ˜¯ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç”¨ PyTorch C++ å‰ç«¯ç¼–å†™ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BloodAxe/pytorch-toolbelt"&gt;pytorch-toolbelt&lt;/a&gt;: PyTorchæ‰©å±•ï¼Œç”¨æ¥è¿›è¡Œå¿«é€ŸR&amp;amp;DåŸå‹å¼€å‘å’ŒKaggleä»£ç æ”¶é›†ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Fonbet/argus-tensor-stream"&gt;argus-tensor-stream&lt;/a&gt;: ä¸€ä¸ªåº“ï¼Œç”¨æ¥å°†å®æ—¶è§†é¢‘æµè§£ç è‡³CUDAå†…å­˜ã€‚tensorstream.argus-ai.com&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hal3/macarico"&gt;macarico&lt;/a&gt;: åœ¨ PyTorch ä¸­å­¦ä¹ æœç´¢ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/astooke/rlpyt"&gt;rlpyt&lt;/a&gt;: PyTorch ä¸­çš„å¼ºåŒ–å­¦ä¹ ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/blue-season/pywarm"&gt;pywarm&lt;/a&gt;: ä¸º PyTorch å»ºç«‹ç¥ç»ç½‘ç»œçš„ä¸€ç§æ›´æ¸…æ´çš„æ–¹æ³•ã€‚&lt;a href="https://blue-season.github.io/pywarm/" rel="nofollow"&gt;https://blue-season.github.io/pywarm/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/learnables/learn2learn"&gt;learn2learn&lt;/a&gt;: PyTorchå…ƒå­¦ä¹ æ¡†æ¶ã€‚&lt;a href="http://learn2learn.net" rel="nofollow"&gt;http://learn2learn.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/torchbeast"&gt;torchbeast&lt;/a&gt;: åˆ†å¸ƒå¼å¼ºåŒ–å­¦ä¹ çš„PyTorchå¹³å°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/higher"&gt;higher&lt;/a&gt;: higher æ˜¯ä¸€ä¸ªPyTorchåº“ï¼Œå…è®¸ç”¨æˆ·è·å¾—è·¨è¶Šè®­ç»ƒå¾ªç¯è€Œä¸æ˜¯å•ä¸ªè®­ç»ƒæ­¥éª¤çš„æŸå¤±çš„é«˜é˜¶æ¢¯åº¦ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Vermeille/Torchelie/"&gt;Torchelie&lt;/a&gt;: TorchÃ©lie æ˜¯é¢å‘PyTorchçš„ä¸€ç³»åˆ—å·¥å…·å‡½æ•°ã€å±‚ã€æŸå¤±ã€æ¨¡å‹ã€è®­ç»ƒå™¨ç­‰çš„åˆé›†ã€‚ &lt;a href="https://torchelie.readthedocs.org/" rel="nofollow"&gt;https://torchelie.readthedocs.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/CrypTen"&gt;CrypTen&lt;/a&gt;: CrypTen æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤æœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œå®ƒä½¿ç”¨PyTorchç¼–å†™ï¼Œå…è®¸ç ”ç©¶äººå‘˜å’Œå¼€å‘äººå‘˜ä½¿ç”¨åŠ å¯†æ•°æ®è®­ç»ƒæ¨¡å‹ã€‚CrypTenç›®å‰æ”¯æŒå°†å®‰å…¨çš„å¤šæ–¹è®¡ç®—ï¼ˆ&lt;a href="https://en.wikipedia.org/wiki/Secure_multi-party_computation" rel="nofollow"&gt;Secure Multiparty Computation&lt;/a&gt;ï¼‰ä½œä¸ºå…¶åŠ å¯†æœºåˆ¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cvxgrp/cvxpylayers"&gt;cvxpylayers&lt;/a&gt;: cvxpylayers æ˜¯ä¸€ä¸ª Python åº“ï¼Œç”¨äºåœ¨PyTorchä¸­æ„é€ å¯å¾®å‡¸ä¼˜åŒ–å±‚ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/HobbitLong/RepDistiller"&gt;RepDistiller&lt;/a&gt;: å¯¹æ¯”è¡¨ç¤ºè’¸é¦ï¼ˆCRDï¼‰å’Œæœ€æ–°çŸ¥è¯†è’¸é¦æ–¹æ³•çš„åŸºå‡†ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/NVIDIAGameWorks/kaolin"&gt;kaolin&lt;/a&gt;: ä¸€ä¸ªæ—¨åœ¨åŠ é€Ÿ3Dæ·±åº¦å­¦ä¹ ç ”ç©¶çš„PyTorchåº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/BasBuller/PySNN"&gt;PySNN&lt;/a&gt;: é«˜æ•ˆçš„å°–å³°ç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œå»ºç«‹åœ¨PyTorchä¹‹ä¸Šï¼Œç”¨äºGPUåŠ é€Ÿã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dmmiller612/sparktorch"&gt;sparktorch&lt;/a&gt;: åœ¨ Apache Spark ä¸Šè®­ç»ƒå’Œè¿è¡Œ PyTorch æ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/KevinMusgrave/pytorch-metric-learning"&gt;pytorch-metric-learning&lt;/a&gt;: åœ¨åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨åº¦é‡å­¦ä¹ çš„æœ€ç®€å•æ–¹æ³•ã€‚æ¨¡å—åŒ–ï¼Œçµæ´»ï¼Œå¯æ‰©å±•ã€‚ç”¨ PyTorch æ„å»ºã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cpnota/autonomous-learning-library"&gt;autonomous-learning-library&lt;/a&gt;: ç”¨äºå»ºç«‹æ·±åº¦å¼ºåŒ–å­¦ä¹ ä»£ç†çš„ PyTorch åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/asappresearch/flambe"&gt;flambe&lt;/a&gt;: ä¸€ä¸ªç”¨äºåŠ é€Ÿç ”ç©¶åŠå…¶ç”Ÿäº§è·¯å¾„çš„MLæ¡†æ¶ã€‚&lt;a href="https://flambe.ai" rel="nofollow"&gt;https://flambe.ai&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-tutorials--examplesæ•™ç¨‹--ç¤ºä¾‹" class="anchor" aria-hidden="true" href="#tutorials--examplesæ•™ç¨‹--ç¤ºä¾‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorials &amp;amp; examplesï½œæ•™ç¨‹ &amp;amp; ç¤ºä¾‹&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;3500+&lt;/kbd&gt; &lt;strong&gt;&lt;a href="https://github.com/spro/practical-pytorch"&gt;Practical Pytorch&lt;/a&gt;&lt;/strong&gt;: è¯¥æ•™ç¨‹å¯¹ä¸åŒçš„RNNæ¨¡å‹è¿›è¡Œäº†è§£é‡Šã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pytorch.org/tutorials/beginner/deep_learning_nlp_tutorial.html" rel="nofollow"&gt;DeepLearningForNLPInPytorch&lt;/a&gt;: IPython Notebook æ·±åº¦å­¦ä¹ æ•™ç¨‹ï¼ŒåŒ…å«å¯¹è‡ªç„¶è¯­è¨€å¤„ç†çš„å¼ºè°ƒã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;13100+&lt;/kbd&gt; &lt;a href="https://github.com/yunjey/pytorch-tutorial"&gt;pytorch-tutorial&lt;/a&gt;: é¢å‘ç ”ç©¶äººå‘˜çš„æ·±åº¦å­¦ä¹ æ•™ç¨‹ï¼Œå…¶ä¸­å¤§éƒ¨åˆ†æ¨¡å‹çš„å®ç°ä»£ç éƒ½å°‘äº30è¡Œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/keon/pytorch-exercises"&gt;pytorch-exercises&lt;/a&gt;: PyTorchç»ƒä¹ é›†åˆã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2600+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/tutorials"&gt;pytorch tutorials&lt;/a&gt;: å„ç§PyTorchæ•™ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;9900+&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/examples"&gt;pytorch examples&lt;/a&gt;:  PyTorchä½¿ç”¨ç¤ºä¾‹ï¼Œåº”ç”¨åœºæ™¯åŒ…æ‹¬è§†è§‰ã€æ–‡æœ¬ã€å¼ºåŒ–å­¦ä¹ ç­‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/napsternxg/pytorch-practice"&gt;pytorch practice&lt;/a&gt;: PyTorchç¤ºä¾‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/vinhkhuc/PyTorch-Mini-Tutorials"&gt;pytorch mini tutorials&lt;/a&gt;: PyTorchæç®€æ•™ç¨‹ï¼Œæ”¹ç¼–è‡ªAlec Radfordçš„&lt;a href="https://github.com/Newmu/Theano-Tutorials"&gt;Theanoæ•™ç¨‹&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/xiayandi/Pytorch_text_classification"&gt;pytorch text classification&lt;/a&gt;: PyTorchå®ç°åŸºäºCNNçš„æ–‡æœ¬åˆ†ç±»ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/desimone/pytorch-cat-vs-dogs"&gt;cats vs dogs&lt;/a&gt;: Kaggle ç«èµ› Dogs vs. Cats Redux: Kernels Edition çš„ç½‘ç»œå¾®è°ƒç¤ºä¾‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/eladhoffer/convNet.pytorch"&gt;convnet&lt;/a&gt;: æ·±åº¦å·ç§¯ç½‘ç»œåœ¨ä¸åŒæ•°æ®é›†(ImageNet, Cifar10, Cifar100, MNIST)ä¸Šçš„å®Œæ•´è®­ç»ƒç¤ºä¾‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mailmahee/pytorch-generative-adversarial-networks"&gt;pytorch-generative-adversarial-networks&lt;/a&gt;: ä¸€ä¸ªç®€å•çš„å¯¹æŠ—ç”Ÿæˆç½‘ç»œ(GAN) ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/amdegroot/pytorch-containers"&gt;pytorch containers&lt;/a&gt;: PyTorchä¸­ç®€åŒ–çš„Torchå®¹å™¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/cemoody/topicsne"&gt;T-SNE in pytorch&lt;/a&gt;: t-SNEå®éªŒã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fducau/AAE_pytorch"&gt;AAE_pytorch&lt;/a&gt;: PyTorchç‰ˆå¯¹æŠ—è‡ªç¼–ç å™¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/GunhoChoi/Kind_PyTorch_Tutorial"&gt;Kind_PyTorch_Tutorial&lt;/a&gt;: PyTorchæ–°æ‰‹æ•™ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/justdark/pytorch-poetry-gen"&gt;pytorch-poetry-gen&lt;/a&gt;: åŸºäºPyTorchçš„char-RNNï¼ˆå­—ç¬¦çº§å¾ªç¯ç¥ç»ç½‘ç»œï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/JamesChuanggg/pytorch-REINFORCE"&gt;pytorch-REINFORCE&lt;/a&gt;: PyTorch å®ç°äº† OpenAI gym ä¸‹ç¦»æ•£å’Œè¿ç»­æ§åˆ¶çš„ REINFORCEã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3600+&lt;/kbd&gt; &lt;strong&gt;&lt;a href="https://github.com/MorvanZhou/PyTorch-Tutorial"&gt;PyTorch-Tutorial&lt;/a&gt;&lt;/strong&gt;: ç®€å•è€Œå¿«é€Ÿåœ°æ­å»ºä½ è‡ªå·±çš„ç¥ç»ç½‘ç»œã€‚ &lt;a href="https://morvanzhou.github.io/tutorials/" rel="nofollow"&gt;https://morvanzhou.github.io/tutorials/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/joansj/pytorch-intro"&gt;pytorch-intro&lt;/a&gt;: æ¼”ç¤ºå¦‚ä½•åœ¨PyTorchä¸­å®ç°CNNså’ŒRNNsã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/bearpaw/pytorch-classification"&gt;pytorch-classification&lt;/a&gt;: ä¸€ä¸ªCIFAR-10/100å’ŒImageNetæ•°æ®é›†ä¸Šçš„åˆ†ç±»æ¡†æ¶ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hardmaru/pytorch_notebooks"&gt;pytorch_notebooks - hardmaru&lt;/a&gt;: ç”¨NumPyå’ŒPyTorchç¼–å†™çš„éšæœºæ•™ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/soravux/pytorch_tutorial"&gt;pytorch_tutoria-quick&lt;/a&gt;: PyTorchä»‹ç»å’Œæ•™ç¨‹ã€‚é¢å‘è®¡ç®—æœºè§†è§‰ã€å›¾å½¢å’Œæœºå™¨å­¦ä¹ é¢†åŸŸçš„ç ”ç©¶äººå‘˜ï¼Œè¦æ±‚å¯¹ç¥ç»ç½‘ç»œç†è®ºçŸ¥è¯†å’Œå¸¸ç”¨ç¥ç»ç½‘ç»œæ¡†æ¶ç”±åŸºæœ¬çš„äº†è§£ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Spandan-Madan/Pytorch_fine_tuning_Tutorial"&gt;Pytorch_fine_tuning_Tutorial&lt;/a&gt;: åœ¨PyTorchä¸­è¿›è¡Œå¾®è°ƒæˆ–è½¬ç§»å­¦ä¹ çš„ç®€çŸ­æ•™ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Kyubyong/pytorch_exercises"&gt;pytorch_exercises&lt;/a&gt;: PyTorchç»ƒä¹ ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/soumith/traffic-sign-detection-homework"&gt;traffic-sign-detection&lt;/a&gt;: çº½çº¦å¤§å­¦2018å¹´è®¡ç®—æœºè§†è§‰ç§‹å­£è¯¾ç¨‹ç¤ºä¾‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Js-Mim/mss_pytorch"&gt;mss_pytorch&lt;/a&gt;: æ— éœ€è¿›è¡Œæ»¤æ³¢åå¤„ç†ï¼Œåˆ©ç”¨å¾ªç¯æ¨æ–­ç®—æ³•å®ç°æ­Œå”±è¯­éŸ³åˆ†ç¦» - PyTorch å®ç°ã€‚ æ¼”ç¤º: js-mim.github.io/mss_pytorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2100+&lt;/kbd&gt; &lt;a href="https://github.com/DSKSD/DeepNLP-models-Pytorch"&gt;DeepNLP-models-Pytorch&lt;/a&gt; cs-224nè¯¾ç¨‹ä¸­çš„å„ç§æ·±åº¦NLPæ¨¡å‹çš„PyTorchå®ç°ã€‚(Stanford Univ: NLP with Deep Learning)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mila-udem/welcome_tutorials"&gt;Mila introductory tutorials&lt;/a&gt;: é¢å‘MILAæ–°ç”Ÿçš„å„ç§æ•™ç¨‹ã€‚ï¼ˆ&lt;a href="https://mila.quebec/en/mila/" rel="nofollow"&gt;MILAï¼šåŠ æ‹¿å¤§è’™ç‰¹åˆ©å°”äººå·¥æ™ºèƒ½ç ”ç©¶ä¸­å¿ƒ&lt;/a&gt;ï¼‰&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/moskomule/pytorch.rl.learning"&gt;pytorch.rl.learning&lt;/a&gt;: ä½¿ç”¨PyTorchå­¦ä¹ å¼ºåŒ–å­¦ä¹ ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/keon/seq2seq"&gt;minimal-seq2seq&lt;/a&gt;: å…³æ³¨ç¥ç»æœºå™¨ç¿»è¯‘çš„æœ€å°Seq2Seqæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/JeanKossaifi/tensorly-notebooks"&gt;tensorly-notebooks&lt;/a&gt;: åˆ©ç”¨Pythonå’ŒTensorLyå®ç°å¼ é‡æ–¹æ³•ã€‚ tensorly.github.io/dev&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jpeg729/pytorch_bits"&gt;pytorch_bits&lt;/a&gt;: æ—¶åºé¢„æµ‹çš„ç›¸å…³ç¤ºä¾‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/sanyam5/skip-thoughts"&gt;skip-thoughts&lt;/a&gt;: PyTorchå®ç°Skip-Thoughtè¯å‘é‡æ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/xiadingZ/video-caption-pytorch"&gt;video-caption-pytorch&lt;/a&gt;: åˆ©ç”¨PyTorchä¸ºè§†é¢‘æ·»åŠ å­—å¹•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/higgsfield/Capsule-Network-Tutorial"&gt;Capsule-Network-Tutorial&lt;/a&gt;: ç®€å•æ˜“å­¦çš„èƒ¶å›Šç½‘ç»œï¼ˆCapsule Networkï¼‰æ•™ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch"&gt;code-of-learn-deep-learning-with-pytorch&lt;/a&gt;: ã€Šæ·±åº¦å­¦ä¹ å…¥é—¨ä¹‹PyTorchã€‹ä¹¦ä¸­ä»£ç ã€‚ item.jd.com/17915495606.html&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/higgsfield/RL-Adventure"&gt;RL-Adventure&lt;/a&gt;: Pytorch ç‰ˆ Deep Q Learning æ•™ç¨‹ï¼Œç®€å•ã€æ˜“å­¦ã€ä»£ç å¯è¯»æ€§å¼ºï¼ŒåŒ…å« DQN / DDQN / Prioritized replay/ noisy networks/ distributional values/ Rainbow/ hierarchical RL çš„ PyTorch å®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hpcgarage/accelerated_dl_pytorch"&gt;accelerated_dl_pytorch&lt;/a&gt;: Jupyter Day Atlanta II ä¼šè®®ä¸Šçš„åŠ é€Ÿæ·±åº¦å­¦ä¹ ç®—æ³•ï¼ŒåŒ…å« PyTorch æ•™ç¨‹å’Œä¼šè®®æ¼”è®²æ–‡ç¨¿ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1800+&lt;/kbd&gt; &lt;a href="https://github.com/higgsfield/RL-Adventure-2"&gt;RL-Adventure-2&lt;/a&gt;: ä»¥ä¸‹å†…å®¹çš„ PyTorch0.4 ç‰ˆæœ¬æ•™ç¨‹: actor critic / proximal policy optimization / acer / ddpg / twin dueling ddpg / soft actor critic / generative adversarial imitation learning / hindsight experience replayã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f" rel="nofollow"&gt;Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)&lt;/a&gt;: 50è¡Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.paperspace.com/adversarial-autoencoders-with-pytorch/" rel="nofollow"&gt;adversarial-autoencoders-with-pytorch&lt;/a&gt;: PyTorchå¯¹æŠ—è‡ªç¼–ç å™¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@vishnuvig/transfer-learning-using-pytorch-4c3475f4495" rel="nofollow"&gt;transfer learning using pytorch&lt;/a&gt;: PyTorchè¿ç§»å­¦ä¹ ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/" rel="nofollow"&gt;how-to-implement-a-yolo-object-detector-in-pytorch&lt;/a&gt;: å¦‚ä½•ä½¿ç”¨PyTorchå®ç°ä¸€ä¸ªYOLO (v3)ç‰©ä½“æ£€æµ‹å™¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.fastforwardlabs.com/2018/04/10/pytorch-for-recommenders-101.html" rel="nofollow"&gt;pytorch-for-recommenders-101&lt;/a&gt;: ä½¿ç”¨PyTorchæ„å»ºæ¨èç³»ç»Ÿã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wkentaro/pytorch-for-numpy-users"&gt;pytorch-for-numpy-users&lt;/a&gt;: é¢å‘Numpyç”¨æˆ·çš„PyTorchã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pytorchtutorial.com/" rel="nofollow"&gt;PyTorch Tutorial&lt;/a&gt;: PyTorchä¸­æ–‡æ•™ç¨‹ï¼ˆPyTorchä¸­æ–‡ç½‘ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Kaixhin/grokking-pytorch"&gt;grokking-pytorch&lt;/a&gt;: æ‰‹æŠŠæ‰‹æ•™ä½ å­¦ä¼šPyTorchã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/Atcold/PyTorch-Deep-Learning-Minicourse"&gt;PyTorch-Deep-Learning-Minicourse&lt;/a&gt;: PyTorchæ·±åº¦å­¦ä¹ å¾®å‹è¯¾ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/utkuozbulak/pytorch-custom-dataset-examples"&gt;pytorch-custom-dataset-examples&lt;/a&gt;: PyTorchçš„ä¸€äº›è‡ªå®šä¹‰æ•°æ®é›†ç¤ºä¾‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://florianwilhelm.info/2018/08/multiplicative_LSTM_for_sequence_based_recos/" rel="nofollow"&gt;Multiplicative LSTM for sequence-based Recommenders&lt;/a&gt;: é¢å‘åŸºäºåºåˆ—çš„æ¨èå™¨çš„ä¹˜æ³•LSTMã€‚/åŸºäºLSTMçš„åºåˆ—æ¨èå®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/furkanu/deeplearning.ai-pytorch"&gt;deeplearning.ai-pytorch&lt;/a&gt;: Courseraæ·±åº¦å­¦ä¹ è¯¾ç¨‹(deeplearning.ai)ä»»åŠ¡çš„PyTorchå®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tobiascz/MNIST_Pytorch_python_and_capi"&gt;MNIST_Pytorch_python_and_capi&lt;/a&gt;: ç¤ºä¾‹ï¼šå¦‚ä½•åœ¨Pythonä¸­è®­ç»ƒä¸€ä¸ªMNISTç½‘ç»œå¹¶åœ¨C++ä¸­ç”¨PyTorch1.0è¿è¡Œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ne7ermore/torch_light"&gt;torch_light&lt;/a&gt;: æ•™ç¨‹å’Œç¤ºä¾‹ï¼ŒåŒ…æ‹¬å¼ºåŒ–å­¦ä¹ ã€NLPã€CVã€‚Logisticã€CNNã€RNNã€LSTMç­‰ç¥ç»ç½‘ç»œæ¨¡å‹ç”±æ•°è¡Œä»£ç å®ç°ï¼Œä¸€äº›é«˜çº§ç¤ºä¾‹ç”±å¤æ‚æ¨¡å‹å®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dribnet/portrain-gan"&gt;portrain-gan&lt;/a&gt;: ç¼–ç ï¼ˆè§£ç å°šæœªå®ç°ï¼‰art-DCGAN ç”Ÿæˆçš„è‚–åƒæ²¹ç”»ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/omarsar/mri-analysis-pytorch"&gt;mri-analysis-pytorch&lt;/a&gt;: ä½¿ç”¨PyTorchå’ŒMedicalTorchè¿›è¡Œæ ¸ç£å…±æŒ¯ï¼ˆMRIï¼‰åˆ†æã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/davidcpage/cifar10-fast"&gt;cifar10-fast&lt;/a&gt;: åœ¨79ç§’å†…å®ŒæˆCIFAR10æ•°æ®é›†ä¸Šçš„ResNetæ¨¡å‹çš„è®­ç»ƒå¹¶è¾¾åˆ°94%çš„æµ‹è¯•å‡†ç¡®ç‡ï¼Œç›¸å…³å†…å®¹å‚è§ &lt;a href="https://www.myrtle.ai/2018/09/24/how_to_train_your_resnet/" rel="nofollow"&gt;blog series&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://in.udacity.com/course/deep-learning-pytorch--ud188" rel="nofollow"&gt;Intro to Deep Learning with PyTorch&lt;/a&gt;: Udacityå’ŒFacebookè”åˆæ¨å‡ºçš„å…è´¹è¯¾ç¨‹ï¼ŒåŒ…æ‹¬å¯¹PyTorchçš„ä»‹ç»å’Œå¯¹PyTorchä½œè€…ä¹‹ä¸€çš„Soumith Chintalaçš„é‡‡è®¿ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/bentrevett/pytorch-sentiment-analysis"&gt;pytorch-sentiment-analysis&lt;/a&gt;: PyTorchå’ŒTorchTextè¯­ä¹‰åˆ†ææ•™ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/rwightman/pytorch-image-models"&gt;pytorch-image-models&lt;/a&gt;: PyTorchå›¾åƒæ¨¡å‹ã€è„šæœ¬ã€ä¸è®­ç»ƒæƒé‡â€”â€” (SE)ResNet/ResNeXT, DPN, EfficientNet, MobileNet-V3/V2/V1, MNASNet, Single-Path NAS, FBNetç­‰ç­‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BIGBALLON/CIFAR-ZOO"&gt;CIFAR-ZOO&lt;/a&gt;: ä»¥CIFARä¸ºåŸºå‡†çš„å¤šç§CNNæ¶æ„çš„PyTorchå®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dsgiitr/d2l-pytorch"&gt;d2l-pytorch&lt;/a&gt;: æœ¬é¡¹ç›®å°è¯•å¤åˆ¶ã€ŠåŠ¨æ‰‹æ·±åº¦å­¦ä¹ ï¼ˆDive into Deep Learningï¼‰ã€‹(&lt;a href="http://www.d2l.ai" rel="nofollow"&gt;www.d2l.ai&lt;/a&gt;) ä¸€ä¹¦ï¼Œå°†MXnetä»£ç æ”¹ç¼–ä¸ºPyTorchç‰ˆã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/stared/thinking-in-tensors-writing-in-pytorch"&gt;thinking-in-tensors-writing-in-pytorch&lt;/a&gt;:  å¼ é‡æ€ç»´ï¼ŒPyTorchå®è·µ (æ·±åº¦å­¦ä¹ å…¥é—¨)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/lemonhu/NER-BERT-pytorch"&gt;NER-BERT-pytorch&lt;/a&gt;: å‘½åè¯•é¢˜è¯†åˆ«çš„PyTorchè§£å†³æ–¹æ¡ˆï¼Œä½¿ç”¨äº†Google AIçš„é¢„è®­ç»ƒBERTæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dougsouza/pytorch-sync-batchnorm-example"&gt;pytorch-sync-batchnorm-example&lt;/a&gt;: å¦‚ä½•åœ¨ PyTorch ä¸­ä½¿ç”¨äº¤å‰å¤åˆ¶ï¼ˆCross Replicaï¼‰/åŒæ­¥æ‰¹æ ‡å‡†åŒ–ï¼ˆSynchronized Batchnormï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/barissayil/SentimentAnalysis"&gt;SentimentAnalysis&lt;/a&gt;: æƒ…ç»ªåˆ†æç¥ç»ç½‘ç»œï¼Œåœ¨æ–¯å¦ç¦æƒ…ç»ªæ ‘åº“ä¸Šç”¨å¾®è°ƒBERTè®­ç»ƒå¾—åˆ°ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-paper-implementationsè®ºæ–‡å®ç°" class="anchor" aria-hidden="true" href="#paper-implementationsè®ºæ–‡å®ç°"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Paper implementationsï½œè®ºæ–‡å®ç°&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/neuralix/google_evolution"&gt;google_evolution&lt;/a&gt;: å®ç°äº† &lt;a href="https://arxiv.org/abs/1703.01041" rel="nofollow"&gt;Large-scale evolution of image classifiers&lt;/a&gt; ä¸€æ–‡çš„ç»“æœç½‘ç»œä¹‹ä¸€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/edouardoyallon/pyscatwave"&gt;pyscatwave&lt;/a&gt;: åŸºäºCuPy/PyTorchçš„å¿«é€Ÿæ•£å°„å˜æ¢ï¼Œ&lt;a href="https://arxiv.org/abs/1703.08961" rel="nofollow"&gt;Scaling the Scattering Transform: Deep Hybrid Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/edouardoyallon/scalingscattering"&gt;scalingscattering&lt;/a&gt;: è¯¥ä»“åº“åŒ…å« &lt;a href="https://arxiv.org/abs/1703.08961" rel="nofollow"&gt;Scaling The Scattering Transform : Deep Hybrid Networks&lt;/a&gt; ä¸€æ–‡ä¸­çš„å®éªŒã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/episodeyang/deep-auto-punctuation"&gt;deep-auto-punctuation&lt;/a&gt;: é€šè¿‡é€å­—ç¬¦å­¦ä¹ å®ç°è‡ªåŠ¨æ·»åŠ æ ‡ç‚¹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation"&gt;Realtime_Multi-Person_Pose_Estimation&lt;/a&gt;: åŸºäºPyTorchçš„å¤šäººäººä½“å§¿æ€ä¼°è®¡ï¼Œ&lt;a href="https://github.com/ZheC/Realtime_Multi-Person_Pose_Estimation"&gt;åŸå§‹ä»£ç &lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/onlytailei/PyTorch-value-iteration-networks"&gt;PyTorch-value-iteration-networks&lt;/a&gt;: PyTorchå®ç°ä»·å€¼è¿­ä»£ç½‘ç»œï¼ˆ&lt;a href="https://arxiv.org/abs/1602.02867" rel="nofollow"&gt;Value Iteration Networks&lt;/a&gt;ï¼‰ï¼ˆNIPS2016æœ€ä½³è®ºæ–‡å¥–ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/analvikingur/pytorch_Highway"&gt;pytorch_Highway&lt;/a&gt;: PyTorchå®ç°é«˜é€Ÿå…¬è·¯ç½‘ç»œï¼ˆ&lt;a href="https://arxiv.org/abs/1505.00387" rel="nofollow"&gt;Highway Networks&lt;/a&gt;ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/analvikingur/pytorch_NEG_loss"&gt;pytorch_NEG_loss&lt;/a&gt;: PyTorchå®ç°è´Ÿé‡‡æ ·æŸå¤±ï¼ˆ&lt;a href="https://arxiv.org/abs/1310.4546" rel="nofollow"&gt;Negative Sampling Loss&lt;/a&gt;ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/analvikingur/pytorch_RVAE"&gt;pytorch_RVAE&lt;/a&gt;: ç”¨PyTorchå®ç°çš„äº§ç”Ÿåºåˆ—æ•°æ®çš„é€’å½’å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼Œç›¸å…³è®ºæ–‡ï¼š&lt;a href="https://arxiv.org/abs/1511.06349#" rel="nofollow"&gt;Generating Sentences from a Continuous Space&lt;/a&gt;ï¼Œ&lt;a href="https://arxiv.org/abs/1508.06615" rel="nofollow"&gt;Character-Aware Neural Language Models&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/analvikingur/pytorch_TDNN"&gt;pytorch_TDNN&lt;/a&gt;: ç”¨PyTorchå®ç°æ—¶é—´å»¶è¿Ÿç¥ç»ç½‘ç»œï¼ˆTime Delayed NNï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/moskomule/eve.pytorch"&gt;eve.pytorch&lt;/a&gt;: ä¸€ä¸ªEveä¼˜åŒ–å™¨çš„å®ç°ï¼Œç›¸å…³è®ºæ–‡ï¼š&lt;a href="https://arxiv.org/abs/1611.01505" rel="nofollow"&gt;Imploving Stochastic Gradient Descent with Feedback&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/locuslab/e2e-model-learning"&gt;e2e-model-learning&lt;/a&gt;: éšæœºä¼˜åŒ–ä¸­çš„åŸºäºä»»åŠ¡çš„ç«¯åˆ°ç«¯æ¨¡å‹ï¼Œ&lt;a href="https://arxiv.org/abs/1703.04529" rel="nofollow"&gt;https://arxiv.org/abs/1703.04529&lt;/a&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mrzhu-cool/pix2pix-pytorch"&gt;pix2pix-pytorch&lt;/a&gt;: PyTorchå®ç°â€œåŸºäºæ¡ä»¶å¯¹æŠ—ç½‘ç»œçš„å›¾åƒåˆ°å›¾åƒç¿»è¯‘â€ã€‚ è®ºæ–‡ï¼š&lt;a href="https://arxiv.org/pdf/1611.07004v1.pdf" rel="nofollow"&gt;Image-to-Image Translation Using Conditional Adversarial Networks&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2900+&lt;/kbd&gt; &lt;a href="https://github.com/amdegroot/ssd.pytorch"&gt;Single Shot MultiBox Detector&lt;/a&gt;: å•å‘å¤šç›’æ¢æµ‹å™¨ï¼Œè®ºæ–‡ï¼š&lt;a href="http://arxiv.org/abs/1512.02325" rel="nofollow"&gt;Single Shot MultiBox Detector&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/carpedm20/DiscoGAN-pytorch"&gt;DiscoGAN&lt;/a&gt;: å­¦ä¹ åˆ©ç”¨ç”Ÿæˆæ€§å¯¹æŠ—ç½‘ç»œå‘ç°è·¨åŸŸå…³ç³»ã€‚è®ºæ–‡ï¼š&lt;a href="https://arxiv.org/abs/1703.05192" rel="nofollow"&gt;Learning to Discover Cross-Domain Relations with Generative Adversarial Networks&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/SKTBrain/DiscoGAN"&gt;official DiscoGAN implementation&lt;/a&gt;: å®˜æ–¹å®ç°â€œå­¦ä¹ åˆ©ç”¨ç”Ÿæˆæ€§å¯¹æŠ—ç½‘ç»œå‘ç°è·¨åŸŸå…³ç³»â€ã€‚ è®ºæ–‡ï¼š&lt;a href="https://arxiv.org/abs/1703.05192" rel="nofollow"&gt;Learning to Discover Cross-Domain Relations with Generative Adversarial Networks&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/atgambardella/pytorch-es"&gt;pytorch-es&lt;/a&gt;: è¿›åŒ–ç­–ç•¥ã€‚è®ºæ–‡ï¼š&lt;a href="https://arxiv.org/abs/1703.03864" rel="nofollow"&gt;Evolution Strategies as a Scalable Alternative to Reinforcement Learning&lt;/a&gt; .&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/bodokaiser/piwise"&gt;piwise&lt;/a&gt;: ä½¿ç”¨PyTorchå¯¹VOC2012æ•°æ®é›†è¿›è¡Œåƒç´ åˆ‡å‰²ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/transedward/pytorch-dqn"&gt;pytorch-dqn&lt;/a&gt;: æ·±åº¦Qå­¦ä¹ ç½‘ç»œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ruotianluo/neuraltalk2.pytorch"&gt;neuraltalk2-pytorch&lt;/a&gt;: PyTorchå›¾åƒå­—å¹•ä»£ç åº“(åœ¨åˆ†æ”¯â€œwith_finetuneâ€ä¸­æœ‰å¯å¾®è°ƒCNN)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mattmacy/vnet.pytorch"&gt;vnet.pytorch&lt;/a&gt;: PyTorchå®ç°V-Netï¼šå…¨å·ç§¯ç¥ç»ç½‘ç»œåœ¨ä½“åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„åº”ç”¨ã€‚ &lt;a href="http://mattmacy.io/vnet.pytorch/" rel="nofollow"&gt;http://mattmacy.io/vnet.pytorch/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wkentaro/pytorch-fcn"&gt;pytorch-fcn&lt;/a&gt;: PyTorch å®ç°å®Œå…¨å·ç§¯ç½‘ç»œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/xternalz/WideResNet-pytorch"&gt;WideResNets&lt;/a&gt;: PyTorchå®ç°WideResNetsã€‚è¯¥å®ç°æ¯”å®˜æ–¹Torchå®ç°èŠ±è´¹æ›´å°‘çš„GPUå†…å­˜ã€‚å®ç°: &lt;a href="https://github.com/szagoruyko/wide-residual-networks"&gt;https://github.com/szagoruyko/wide-residual-networks&lt;/a&gt; .&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/c0nn3r/pytorch_highway_networks"&gt;pytorch_highway_networks&lt;/a&gt;: PyTorchå®ç°é«˜é€Ÿå…¬è·¯ç½‘ç»œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ypxie/pytorch-NeuCom"&gt;pytorch-NeuCom&lt;/a&gt;: Pytorchå®ç°DeepMindçš„å¯å¾®ç¥ç»è®¡ç®—æœº&lt;a href="http://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz" rel="nofollow"&gt;è®ºæ–‡&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/eladhoffer/captionGen"&gt;captionGen&lt;/a&gt;: ä½¿ç”¨PyTorchä¸ºå›¾åƒç”Ÿæˆæ ‡æ³¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jayleicn/animeGAN"&gt;AnimeGAN&lt;/a&gt;: ç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„PyTorchç®€å•å®ç°ï¼Œå…³æ³¨äºåŠ¨æ¼«è„¸è°±ç»˜ç”»ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Shawn1993/cnn-text-classification-pytorch"&gt;Cnn-text classification&lt;/a&gt;: PyTorch å®ç° &lt;a href="https://arxiv.org/abs/1408.5882" rel="nofollow"&gt;Kimçš„åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„å¥å­åˆ†ç±»&lt;/a&gt; è®ºæ–‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/SeanNaren/deepspeech.pytorch"&gt;deepspeech2&lt;/a&gt;: ä½¿ç”¨ Baidu Warp-CTC å®ç°DeepSpeech2ã€‚åˆ›é€ ä¸€ä¸ªåŸºäº DeepSpeech2 æ¶æ„çš„ç½‘ç»œï¼Œç”¨ CTC æ¿€æ´»å‡½æ•°è®­ç»ƒã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/MaximumEntropy/Seq2Seq-PyTorch"&gt;seq2seq&lt;/a&gt;: åŒ…å«PyTorchä¸­çš„Seq2Seqæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rarilurelo/pytorch_a3c"&gt;Asynchronous Advantage Actor-Critic in PyTorch&lt;/a&gt;: PyTorchå®ç°A3C(Asynchronous Advantage Actor-Critic)ï¼Œè®ºæ–‡ï¼š&lt;a href="https://arxiv.org/pdf/1602.01783v1.pdf" rel="nofollow"&gt;Asynchronous Methods for Deep Reinforcement Learning&lt;/a&gt;ã€‚ç”±äº PyTorch å¯ä»¥è½»æ¾åœ°åœ¨å¤šè¿›ç¨‹å†…æ§åˆ¶å…±äº«å†…å­˜ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ˜“å®ç°A3Cè¿™æ ·çš„å¼‚æ­¥ç®—æ³•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/bamos/densenet.pytorch"&gt;densenet&lt;/a&gt;: This is a PyTorch å®ç° DenseNet-BC æ¶æ„ï¼Œç›¸å…³è®ºæ–‡ &lt;a href="https://arxiv.org/abs/1608.06993" rel="nofollow"&gt;Densely Connected Convolutional Networks&lt;/a&gt;ã€‚è¯¥å®ç°çš„ CIFAR-10+ 100å±‚é”™è¯¯ç‡ä¸º 4.77 å¢é•¿ç‡ä¸º 12ã€‚å®˜æ–¹å®ç°å’Œè®¸å¤šç¬¬ä¸‰æ–¹åº“çš„é“¾æ¥å‚è§ &lt;a href="https://github.com/liuzhuang13/DenseNet"&gt;liuzhuang13/DenseNet&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/alykhantejani/nninit"&gt;nninit&lt;/a&gt;: PyTorchç¥ç»ç½‘ç»œæ¨¡å—çš„æƒå€¼åˆå§‹åŒ–æ–¹æ¡ˆï¼Œè¿™æ˜¯ &lt;a href="https://github.com/Kaixhin/nninit"&gt;nninit&lt;/a&gt; çš„æµè¡Œç«¯å£ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/longcw/faster_rcnn_pytorch"&gt;faster rcnn&lt;/a&gt;: PyTorch å®ç° Faster RCNNã€‚è¯¥é¡¹ç›®ä¸»è¦åŸºäº py-faster-rcnn å’Œ TFFRCNNã€‚æ›´å¤šå…³äº R-CNN çš„ç»†èŠ‚è¯·å‚è€ƒè®ºæ–‡ Faster R-CNNï¼š&lt;a href="https://arxiv.org/abs/1506.01497" rel="nofollow"&gt;Towards Real-Time Object Detection with Region Proposal Network&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/akolishchak/doom-net-pytorch"&gt;doomnet&lt;/a&gt;: PyTorchç‰ˆDoom-netï¼Œå®ç°äº†ViZDoomç¯å¢ƒä¸‹çš„RLæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ClementPinard/FlowNetPytorch"&gt;flownet&lt;/a&gt;: é€šè¿‡Dosovitskiyç­‰å®ŒæˆFlowNetçš„Pytorchå®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/gsp-27/pytorch_Squeezenet"&gt;sqeezenet&lt;/a&gt;: åœ¨CIFAR10æ•°æ®é›†ä¸Šç”¨PyTorchå®ç°Squeezenetæ¨¡å‹ï¼Œ&lt;a href="https://arxiv.org/abs/1602.07360" rel="nofollow"&gt;è®ºæ–‡&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2400+&lt;/kbd&gt; &lt;a href="https://github.com/martinarjovsky/WassersteinGAN"&gt;WassersteinGAN&lt;/a&gt;: PyTorchå®ç°&lt;a href="https://arxiv.org/abs/1701.07875" rel="nofollow"&gt;WassersteinGAN&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/locuslab/optnet"&gt;optnet&lt;/a&gt;: è¯¥ä»“åº“åŒ…å«PyTorchæºç ï¼Œé‡ç°äº†è®ºæ–‡&lt;a href="https://arxiv.org/abs/1703.00443" rel="nofollow"&gt;OptNet: Differentiable Optimization as a Layer in Neural Networks&lt;/a&gt;ä¸­çš„å®éªŒã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/locuslab/qpth"&gt;qp solver&lt;/a&gt;: PyTorchçš„ä¸€ä¸ªå¿«é€Ÿå’Œå¯å¾®åˆ†çš„QPæ±‚è§£å™¨ã€‚&lt;a href="https://locuslab.github.io/qpth/" rel="nofollow"&gt;https://locuslab.github.io/qpth/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ikostrikov/pytorch-naf"&gt;Continuous Deep Q-Learning with Model-based Acceleration &lt;/a&gt;: &lt;a href="https://arxiv.org/pdf/1603.00748v1.pdf" rel="nofollow"&gt;åŸºäºæ¨¡å‹åŠ é€Ÿçš„è¿ç»­æ·±åº¦Qå­¦ä¹ &lt;/a&gt;çš„å†å®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ikostrikov/pytorch-meta-optimizer"&gt;Learning to learn by gradient descent by gradient descent&lt;/a&gt;: PyTorchå®ç°&lt;a href="https://arxiv.org/abs/1606.04474" rel="nofollow"&gt;Learning to learn by gradient descent by gradient descent&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/darkstar112358/fast-neural-style"&gt;fast-neural-style&lt;/a&gt;: PyTorchå®ç°fast-neural-styleï¼Œè®ºæ–‡ï¼š&lt;a href="https://arxiv.org/abs/1603.08155" rel="nofollow"&gt;Perceptual Losses for Real-Time Style Transfer and Super-Resolution&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/leongatys/PytorchNeuralStyleTransfer"&gt;PytorchNeuralStyleTransfer&lt;/a&gt;: Pytorchä¸­çš„ç¥ç»é£æ ¼è½¬æ¢ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/bengxy/FastNeuralStyle"&gt;Fast Neural Style for Image Style Transform by Pytorch&lt;/a&gt;: ä½¿ç”¨å¿«é€Ÿç¥ç»é£æ ¼è¿›è¡Œå›¾åƒé£æ ¼è½¬æ¢ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/alexis-jacq/Pytorch-Tutorials"&gt;neural style transfer&lt;/a&gt;: é€šè¿‡ç¥ç»é£æ ¼ç®—æ³•ä»‹ç»PyTorchï¼Œ&lt;a href="https://arxiv.org/abs/1508.06576" rel="nofollow"&gt;Neural-Style algorithm&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zuoxingdong/VIN_PyTorch_Visdom"&gt;VIN_PyTorch_Visdom&lt;/a&gt;: PyTorchå®ç°ä»·å€¼è¿­ä»£ç½‘ç»œ(VIN):å¹²å‡€ã€ç®€å•ã€æ¨¡å—åŒ–ã€‚åˆ©ç”¨Visdomè¿›è¡Œå¯è§†åŒ–ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/longcw/yolo2-pytorch"&gt;YOLO2&lt;/a&gt;: PyTorchä¸­çš„YOLOv2ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/szagoruyko/attention-transfer"&gt;attention-transfer&lt;/a&gt;: é€šè¿‡æ³¨æ„è½¬ç§»æ”¹å–„å·ç§¯ç½‘ç»œï¼Œ&lt;a href="https://arxiv.org/abs/1612.03928" rel="nofollow"&gt;ICLR2017ä¼šè®®è®ºæ–‡&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/potterhsu/SVHNClassifier-PyTorch"&gt;SVHNClassifier&lt;/a&gt;: PyTorchå®ç°&lt;a href="https://arxiv.org/pdf/1312.6082.pdf" rel="nofollow"&gt;åŸºäºæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œçš„è¡—æ™¯å›¾åƒå¤šä½æ•°è¯†åˆ«&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/oeway/pytorch-deform-conv"&gt;pytorch-deform-conv&lt;/a&gt;: PyTorchå®ç°å¯å˜å½¢å·ç§¯(Deformable Convolution)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/carpedm20/BEGAN-pytorch"&gt;BEGAN-pytorch&lt;/a&gt;: PyTorchå®ç°&lt;a href="https://arxiv.org/abs/1703.10717" rel="nofollow"&gt;è¾¹ç•Œå‡è¡¡ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆBEGANï¼‰&lt;/a&gt;: Boundary Equilibrium Generative Adversarial Networks.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dasguptar/treelstm.pytorch"&gt;treelstm.pytorch&lt;/a&gt;: PyTorchå®ç°æ ‘å½¢ç»“æ„LSTMã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/DmitryUlyanov/AGE"&gt;AGE&lt;/a&gt;: è®ºæ–‡ä»£ç ï¼ŒåŸæ–‡ï¼šå¯¹æŠ—ç”Ÿæˆç¼–ç å™¨ç½‘ç»œï¼ˆ&lt;a href="http://sites.skoltech.ru/app/data/uploads/sites/25/2017/04/AGE.pdf" rel="nofollow"&gt;Adversarial Generator-Encoder Networks&lt;/a&gt;ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/prlz77/ResNeXt.pytorch"&gt;ResNeXt.pytorch&lt;/a&gt;: å†ç° ResNet-V3 (æ·±åº¦ç¥ç»ç½‘ç»œçš„èšé›†æ®‹å·®å˜æ¢)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jingweiz/pytorch-rl"&gt;pytorch-rl&lt;/a&gt;: åŸºäºPyTorchå’ŒVisdomçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/sujithv28/Deep-Leafsnap"&gt;Deep-Leafsnap&lt;/a&gt;: å¯¹æ¯”ä¼ ç»Ÿçš„è®¡ç®—æœºè§†è§‰æ–¹æ³•ï¼Œä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œçš„&lt;a href="https://neerajkumar.org/base/papers/nk_eccv2012_leafsnap.pdf" rel="nofollow"&gt;LeafSnap&lt;/a&gt;èƒ½æœ‰æ•ˆæé«˜æµ‹è¯•å‡†ç¡®ç‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;10100+&lt;/kbd&gt; &lt;a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"&gt;pytorch-CycleGAN-and-pix2pix&lt;/a&gt;: PyTorch å®ç°å›¾åƒé£æ ¼è¿ç§»ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/onlytailei/A3C-PyTorch"&gt;A3C-PyTorch&lt;/a&gt;:PyTorch å®ç° A3C(Advantage async actor-critic)ç®—æ³•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kentsommer/pytorch-value-iteration-networks"&gt;pytorch-value-iteration-networks&lt;/a&gt;: PyTorchå®ç°ä»·å€¼è¿­ä»£ç½‘ç»œValue Iteration Networks (NIPS 2016 æœ€ä½³è®ºæ–‡)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zhanghang1989/PyTorch-Style-Transfer"&gt;PyTorch-Style-Transfer&lt;/a&gt;: PyTorchå®ç°å®æ—¶è½¬æ¢å¤šé£æ ¼ç”Ÿæˆç½‘ç»œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/isht7/pytorch-deeplab-resnet"&gt;pytorch-deeplab-resnet&lt;/a&gt;: PyTorchå®ç° &lt;a href="https://arxiv.org/abs/1606.00915" rel="nofollow"&gt;DeepLab resnet v2&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fxia22/pointnet.pytorch"&gt;pointnet.pytorch&lt;/a&gt;: PyTorchå®ç° "PointNet: åŸºäºæ·±åº¦å­¦ä¹ çš„3Dç‚¹åˆ†ç±»å’Œåˆ†å‰²æ¨¡å‹" &lt;a href="https://arxiv.org/abs/1612.00593" rel="nofollow"&gt;https://arxiv.org/abs/1612.00593&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/aaron-xichen/pytorch-playground"&gt;pytorch-playground&lt;/a&gt;: åŒ…å«å¸¸è§çš„é¢„è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†(MNIST, SVHN, CIFAR10, CIFAR100, STL10, AlexNet, VGG16, VGG19, ResNet, Inception, SqueezeNet)**.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jingweiz/pytorch-dnc"&gt;pytorch-dnc&lt;/a&gt;: PyTorch/Visdomå®ç°çš„ç¥ç»æœºå™¨ç¿»è¯‘(NTM)&amp;amp;å¯å¾®ç¥ç»è®¡ç®—æœº(DNC)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jinfagang/pytorch_image_classifier"&gt;pytorch_image_classifier&lt;/a&gt;: ä½¿ç”¨PyTorchçš„æœ€å°ä½†å®ç”¨çš„å›¾åƒåˆ†ç±»å™¨ç®¡é“ï¼Œåœ¨ResNet18ä¸Šè¿›è¡Œç»†åŒ–ï¼Œåœ¨è‡ªå·±çš„å°å‹æ•°æ®é›†ä¸Šè·å¾—99%çš„å‡†ç¡®ç‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/yunjey/mnist-svhn-transfer"&gt;mnist-svhn-transfer&lt;/a&gt;: PyTorchå®ç°CycleGANå’ŒSGANã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/marvis/pytorch-yolo2"&gt;pytorch-yolo2&lt;/a&gt;: pytorch-yolo2&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/andrewliao11/dni.pytorch"&gt;dni&lt;/a&gt;: PyTorchå®ç°ä½¿ç”¨åˆæˆæ¢¯åº¦çš„è§£è€¦ç¥ç»æ¥å£ï¼Œè®ºæ–‡ï¼š&lt;a href="https://arxiv.org/abs/1608.05343" rel="nofollow"&gt;Decoupled Neural Interfaces using Synthetic Gradients&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/caogang/wgan-gp"&gt;wgan-gp&lt;/a&gt;: PyTorchå®ç°è®ºæ–‡"&lt;a href="https://arxiv.org/abs/1704.00028v3" rel="nofollow"&gt;Improved Training of Wasserstein GANs&lt;/a&gt;".&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/spro/pytorch-seq2seq-intent-parsing"&gt;pytorch-seq2seq-intent-parsing&lt;/a&gt;:  PyTorchä½¿ç”¨seq2seqå’Œæ³¨æ„åŠ›æ¨¡å‹è¿›è¡Œæ„å›¾åˆ†æå’Œç©ºä½å¡«å……ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/demelin/pyTorch_NCE"&gt;pyTorch_NCE&lt;/a&gt;: å¤ç°å™ªéŸ³å¯¹æ¯”ä¼°è®¡ç®—æ³•ï¼Œè®ºæ–‡ï¼š&lt;a href="http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf" rel="nofollow"&gt;Noise-contrastive estimation: A new estimation principle for unnormalized statistical models&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/cxhernandez/molencoder"&gt;molencoder&lt;/a&gt;: åˆ†å­è‡ªåŠ¨ç¼–ç å™¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/stormraiser/GAN-weight-norm"&gt;GAN-weight-norm&lt;/a&gt;: è®ºæ–‡ä»£ç ï¼Œ"&lt;a href="https://arxiv.org/abs/1704.03971" rel="nofollow"&gt;ç”Ÿæˆå¯¹æŠ—ç½‘ç»œä¸­æ‰¹é‡å’Œæƒé‡å½’ä¸€åŒ–çš„å½±å“&lt;/a&gt;"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rachtsingh/lgamma"&gt;lgamma&lt;/a&gt;: å®ç°polygammaã€lgammaå’Œbetaå‡½æ•°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/eladhoffer/bigBatch"&gt;bigBatch&lt;/a&gt;: è®ºæ–‡ä»£ç ï¼Œè®ºæ–‡ï¼šâ€œ&lt;a href="https://arxiv.org/abs/1705.08741" rel="nofollow"&gt;è®­ç»ƒè¶Šä¹…ï¼Œæ³›åŒ–è¶Šå¥½ï¼šå…³é—­ç¥ç»ç½‘ç»œå¤§æ‰¹é‡è®­ç»ƒçš„æ³›åŒ–é—´éš™&lt;/a&gt;â€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dgriff777/rl_a3c_pytorch"&gt;rl_a3c_pytorch&lt;/a&gt;: é’ˆå¯¹ Atari 2600 çš„å¼ºåŒ–å­¦ä¹ ï¼Œå®ç°äº† A3C LSTM ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ahirner/pytorch-retraining"&gt;pytorch-retraining&lt;/a&gt;: PyTorchåŠ¨ç‰©å›­æ¨¡å‹è½¬ç§»å­¦ä¹ (torchvision)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/priba/nmp_qc"&gt;nmp_qc&lt;/a&gt;: ç”¨äºè®¡ç®—æœºè§†è§‰çš„ç¥ç»æ¶ˆæ¯ä¼ é€’ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jacobgil/pytorch-grad-cam"&gt;grad-cam&lt;/a&gt;: PyTorch å®ç°&lt;a href="https://arxiv.org/pdf/1610.02391v1.pdf" rel="nofollow"&gt;Grad-CAM&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mjacar/pytorch-trpo"&gt;pytorch-trpo&lt;/a&gt;: PyTorch så®ç°ç½®ä¿¡åŸŸç­–ç•¥ä¼˜åŒ–ï¼ˆ&lt;a href="https://arxiv.org/abs/1502.05477" rel="nofollow"&gt;Trust Region Policy Optimization (TRPO)&lt;/a&gt;ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jacobgil/pytorch-explain-black-box"&gt;pytorch-explain-black-box&lt;/a&gt;: PyTorché€šè¿‡æœ‰æ„ä¹‰æ‰°åŠ¨å®ç°é»‘ç®±çš„å¯è§£é‡Šæ€§è§£é‡Šï¼Œ&lt;a href="https://arxiv.org/abs/1704.03296" rel="nofollow"&gt;è®ºæ–‡&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jmtomczak/vae_vpflows"&gt;vae_vpflows&lt;/a&gt;: å‡¸ç»„åˆçº¿æ€§IAFä¸Householderæµ &lt;a href="https://jmtomczak.github.io/deebmed.html" rel="nofollow"&gt;https://jmtomczak.github.io/deebmed.html&lt;/a&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kimhc6028/relational-networks"&gt;relational-networks&lt;/a&gt;: Pytorchå®ç°"&lt;a href="https://arxiv.org/pdf/1706.01427.pdf" rel="nofollow"&gt;ç”¨ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œæ¨¡å—æ¥åšå…³ç³»æ¨ç†&lt;/a&gt;"(å…³ç³»ç½‘ç»œ)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Cadene/vqa.pytorch"&gt;vqa.pytorch&lt;/a&gt;: è§†è§‰é—®ç­”ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/end-to-end-negotiator"&gt;end-to-end-negotiator&lt;/a&gt;: æˆäº¤è¿˜æ˜¯ä¸æˆäº¤ï¼Ÿè°ˆåˆ¤å¯¹è¯çš„ç«¯åˆ°ç«¯å­¦ä¹ ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ShiyuLiang/odin-pytorch"&gt;odin-pytorch&lt;/a&gt;: ç¥ç»ç½‘ç»œå¤±é…å®ä¾‹çš„åŸåˆ™æ€§æ£€æµ‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ajbrock/FreezeOut"&gt;FreezeOut&lt;/a&gt;: ä¸€ç§é€šè¿‡é€æ­¥å†»ç»“å±‚åŠ é€Ÿç¥ç»ç½‘ç»œè®­ç»ƒçš„ç®€å•æŠ€æœ¯ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jakezhaojb/ARAE"&gt;ARAE&lt;/a&gt;: è®ºæ–‡ä»£ç ï¼Œ"&lt;a href="https://arxiv.org/abs/1706.04223" rel="nofollow"&gt;å¯¹æŠ—æ€§æ­£åˆ™åŒ–çš„è‡ªåŠ¨ç¼–ç å™¨, ARAE&lt;/a&gt;"ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kimhc6028/forward-thinking-pytorch"&gt;forward-thinking-pytorch&lt;/a&gt;: PyTorchå®ç°"&lt;a href="https://arxiv.org/pdf/1706.02480.pdf" rel="nofollow"&gt;å‰å‘æ€è€ƒï¼šä¸€æ¬¡ä¸€å±‚åœ°å»ºç«‹å’Œè®­ç»ƒç¥ç»ç½‘ç»œ&lt;/a&gt;"ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BoyuanJiang/context_encoder_pytorch"&gt;context_encoder_pytorch&lt;/a&gt;: PyTorchå®ç°ä¸Šä¸‹æ–‡ç¼–ç å™¨(Context Encoders)ï¼Œå¯ç”¨äºå›¾åƒä¿®å¤ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3300+&lt;/kbd&gt; &lt;a href="https://github.com/jadore801120/attention-is-all-you-need-pytorch"&gt;attention-is-all-you-need-pytorch&lt;/a&gt;: PyTorchåœ¨"Attention is All You Need"ä¸­å®ç°è½¬æ¢æ¨¡å‹ï¼Œ&lt;a href="https://github.com/thnkim/OpenFacePytorch%E3%80%82"&gt;https://github.com/thnkim/OpenFacePytorchã€‚&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/thnkim/OpenFacePytorch"&gt;OpenFacePytorch&lt;/a&gt;: ä½¿ç”¨ OpenFace's nn4.small2.v1.t7 æ¨¡å‹çš„PyTorchæ¨¡å—ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pemami4911/neural-combinatorial-rl-pytorch"&gt;neural-combinatorial-rl-pytorch&lt;/a&gt;:  PyTorch å®ç°"&lt;a href="https://arxiv.org/abs/1611.09940" rel="nofollow"&gt;é€šè¿‡å¼ºåŒ–å­¦ä¹ å®ç°ç¥ç»ç»„åˆä¼˜åŒ–&lt;/a&gt;"ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mjacar/pytorch-nec"&gt;pytorch-nec&lt;/a&gt;: PyTorchå®ç°ç¥ç»æƒ…æ™¯æ§åˆ¶(&lt;a href="https://arxiv.org/abs/1703.01988" rel="nofollow"&gt;NECï¼ŒNeural Episodic Control&lt;/a&gt;)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/eladhoffer/seq2seq.pytorch"&gt;seq2seq.pytorch&lt;/a&gt;: ä½¿ç”¨PyTorchè¿›è¡ŒSequence-to-Sequenceå­¦ä¹ ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/alexis-jacq/Pytorch-Sketch-RNN"&gt;Pytorch-Sketch-RNN&lt;/a&gt;: PyTorchå®ç° â€œ&lt;a href="arxiv.org/abs/1704.03477"&gt;A Neural Representation of Sketch Drawings&lt;/a&gt;â€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jacobgil/pytorch-pruning"&gt;pytorch-pruning&lt;/a&gt;: PyTorchå®ç° [1611.06440] &lt;a href="https://arxiv.org/abs/1611.06440" rel="nofollow"&gt;ç”¨äºèµ„æºæœ‰æ•ˆæ¨ç†çš„å‰ªæå·ç§¯ç¥ç»ç½‘ç»œ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hitvoice/DrQA"&gt;DrQA&lt;/a&gt;: PyTorchå®ç°è‡ªåŠ¨é˜…è¯»ç»´åŸºç™¾ç§‘å¹¶å›ç­”å¼€æ”¾é¢†åŸŸé—®é¢˜ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/JianGoForIt/YellowFin_Pytorch"&gt;YellowFin_Pytorch&lt;/a&gt;: åŸºäºåŠ¨é‡æ¢¯åº¦ä¸‹é™ï¼ˆmomentum SGDï¼‰çš„è‡ªåŠ¨è°ƒä¼˜ä¼˜åŒ–å™¨ï¼Œæ— éœ€æ‰‹åŠ¨æŒ‡å®šå­¦ä¹ é€Ÿç‡å’ŒåŠ¨é‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/deepsound-project/samplernn-pytorch"&gt;samplernn-pytorch&lt;/a&gt;: PyTorchå®ç°SampleRNN: ä¸€ç§æ— æ¡ä»¶ç«¯åˆ°ç«¯ç¥ç»éŸ³é¢‘ç”Ÿæˆæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tymokvo/AEGeAN"&gt;AEGeAN&lt;/a&gt;: åŸºäºAEç¨³å®šçš„æ›´æ·±çš„æ·±åº¦å·ç§¯ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(DCGAN, Deep Convolution Generative Adversarial Networks)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/twtygqyy/pytorch-SRResNet"&gt;/pytorch-SRResNet&lt;/a&gt;: PyTorchå®ç°â€œ&lt;a href="https://arxiv.org/abs/1609.04802" rel="nofollow"&gt;åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„å®æ„Ÿå•å¹…å›¾åƒè¶…åˆ†è¾¨ç‡&lt;/a&gt;â€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fartashf/vsepp"&gt;vsepp&lt;/a&gt;: è®ºæ–‡ä»£ç ï¼Œ"&lt;a href="https://arxiv.org/abs/1707.05612" rel="nofollow"&gt;VSE++:ä½¿ç”¨éš¾åˆ†æ ·æœ¬(Hard Negative)æ”¹å–„è§†è§‰è¯­ä¹‰è”åˆåµŒå…¥&lt;/a&gt;"ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/alexis-jacq/Pytorch-DPPO"&gt;Pytorch-DPPO&lt;/a&gt;: Pytorchå®ç°åˆ†å¸ƒå¼è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(&lt;a href="https://arxiv.org/abs/1707.02286" rel="nofollow"&gt;Distributed Proximal Policy Optimization&lt;/a&gt;)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/mingyuliutw/UNIT"&gt;UNIT&lt;/a&gt;: æ— ç›‘ç£çš„å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œï¼Œ&lt;a href="https://arxiv.org/abs/1703.00848" rel="nofollow"&gt;è®ºæ–‡&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/gpleiss/efficient_densenet_pytorch"&gt;efficient_densenet_pytorch&lt;/a&gt;: DenseNetsçš„å†…å­˜é«˜æ•ˆå®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/yjxiong/tsn-pytorch"&gt;tsn-pytorch&lt;/a&gt;: PyTorchå®ç°æ—¶é—´åˆ†å‰²ç½‘ç»œ(TSN, Temporal Segment Networks)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ajbrock/SMASH"&gt;SMASH&lt;/a&gt;: &lt;a href="https://arxiv.org/abs/1708.05344" rel="nofollow"&gt;SMASH&lt;/a&gt;ï¼Œä¸€ç§é«˜æ•ˆåœ°æ¢ç´¢ç¥ç»ä½“ç³»ç»“æ„çš„å®éªŒæŠ€æœ¯ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kuangliu/pytorch-retinanet"&gt;pytorch-retinanet&lt;/a&gt;: RetinaNetã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/aosokin/biogans"&gt;biogans&lt;/a&gt;: å®ç° ICCV 2017 è®ºæ–‡ "&lt;a href="https://arxiv.org/abs/1708.04692" rel="nofollow"&gt;åˆ©ç”¨GANsè¿›è¡Œç”Ÿç‰©å›¾åƒåˆæˆ&lt;/a&gt;"ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/woozzu/dong_iccv_2017"&gt;Semantic Image Synthesis via Adversarial Learning&lt;/a&gt;: PyTorch å®ç° ICCV 2017 è®ºæ–‡ "&lt;a href="https://arxiv.org/abs/1707.06873" rel="nofollow"&gt;åŸºäºå¯¹æŠ—å­¦ä¹ çš„è¯­ä¹‰å›¾åƒåˆæˆ&lt;/a&gt;"ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jmhessel/fmpytorch"&gt;fmpytorch&lt;/a&gt;: PyTorchåœ¨Cythonä¸­å®ç°åˆ†ææœºï¼ˆFactorization Machineï¼‰æ¨¡å—ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ZhouYanzhao/ORN"&gt;ORN&lt;/a&gt;: PyTorch å®ç° CVPR 2017 è®ºæ–‡ "&lt;a href="https://arxiv.org/pdf/1701.01833.pdf" rel="nofollow"&gt;Oriented Response Networks&lt;/a&gt;"ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/katerakelly/pytorch-maml"&gt;pytorch-maml&lt;/a&gt;: PyTorchå®ç° &lt;a href="https://arxiv.org/abs/1703.03400" rel="nofollow"&gt;MAML&lt;/a&gt;ï¼ˆModel-Agnostic Meta-Learningï¼Œä¸æ¨¡å‹æ— å…³çš„å…ƒå­¦ä¹ ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1800+&lt;/kbd&gt; &lt;a href="https://github.com/znxlwm/pytorch-generative-model-collections"&gt;pytorch-generative-model-collections&lt;/a&gt;: PyTorchä¸­çš„å„ç§ç”Ÿæˆæ¨¡å‹é›†åˆã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/markdtw/vqa-winner-cvprw-2017"&gt;vqa-winner-cvprw-2017&lt;/a&gt;: Pytorch å®ç° CVPR'17 VQA( Visual Question Answerï¼Œè§†è§‰é—®ç­”) æŒ‘æˆ˜å† å†›ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/r9y9/tacotron_pytorch"&gt;tacotron_pytorch&lt;/a&gt;:  PyTorch å®ç° Tacotron è¯­éŸ³åˆæˆæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Lextal/pspnet-pytorch"&gt;pspnet-pytorch&lt;/a&gt;: PyTorch å®ç° PSPNet è¯­ä¹‰åˆ†å‰²ç½‘ç»œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/LiyuanLucasLiu/LM-LSTM-CRF"&gt;LM-LSTM-CRF&lt;/a&gt;: Empower Sequence Labeling with Task-Aware Language Model &lt;a href="http://arxiv.org/abs/1709.04109" rel="nofollow"&gt;http://arxiv.org/abs/1709.04109&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;3200+&lt;/kbd&gt; &lt;a href="https://github.com/1adrianb/face-alignment"&gt;face-alignment&lt;/a&gt;: ä½¿ç”¨PyTorchæ„å»º2Då’Œ3Däººè„¸å¯¹é½åº“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ClementPinard/DepthNet"&gt;DepthNet&lt;/a&gt;: PyTorch åœ¨Still Boxæ•°æ®é›†ä¸Šè®­ç»ƒDepthNetã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/thstkdgus35/EDSR-PyTorch"&gt;EDSR-PyTorch&lt;/a&gt;: PyTorch version of the paper 'Enhanced Deep Residual Networks for Single Image Super-Resolution' (CVPRW 2017)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ethanluoyc/e2c-pytorch"&gt;e2c-pytorch&lt;/a&gt;: E2Cï¼ŒEmbed to Control å®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/kenshohara/3D-ResNets-PyTorch"&gt;3D-ResNets-PyTorch&lt;/a&gt;: åŸºäº3Dæ®‹å·®ç½‘ç»œçš„åŠ¨ä½œè¯†åˆ«ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/khanhptnk/bandit-nmt"&gt;bandit-nmt&lt;/a&gt;: This is code repo for our EMNLP 2017 paper "Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback", which implements the A2C algorithm on top of a neural encoder-decoder model and benchmarks the combination under simulated noisy rewards.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1500+&lt;/kbd&gt; &lt;a href="https://github.com/ikostrikov/pytorch-a2c-ppo-acktr"&gt;pytorch-a2c-ppo-acktr&lt;/a&gt;: PyTorch implementation of Advantage Actor Critic (A2C), Proximal Policy Optimization (PPO) and Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation (ACKTR).&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/baldassarreFe/zalando-pytorch"&gt;zalando-pytorch&lt;/a&gt;: &lt;a href="https://github.com/zalandoresearch/fashion-mnist"&gt;Fashion-MNIST&lt;/a&gt;æ•°æ®é›†ä¸Šçš„å„ç§å®éªŒã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/clcarwin/sphereface_pytorch"&gt;sphereface_pytorch&lt;/a&gt;: PyTorchå®ç°SphereFaceï¼Œäººè„¸è¯†åˆ«ç›¸å…³ï¼Œ&lt;a href="https://arxiv.org/abs/1704.08063" rel="nofollow"&gt;https://arxiv.org/abs/1704.08063&lt;/a&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/floringogianu/categorical-dqn"&gt;Categorical DQN&lt;/a&gt;: A PyTorch Implementation of Categorical DQN from &lt;a href="https://arxiv.org/abs/1707.06887" rel="nofollow"&gt;A Distributional Perspective on Reinforcement Learning&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/loudinthecloud/pytorch-ntm"&gt;pytorch-ntm&lt;/a&gt;: ç¥ç»ç½‘ç»œå›¾çµæœºã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/felixgwu/mask_rcnn_pytorch"&gt;mask_rcnn_pytorch&lt;/a&gt;: Mask RCNN in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/xbresson/graph_convnets_pytorch"&gt;graph_convnets_pytorch&lt;/a&gt;: PyTorch implementation of graph ConvNets, NIPSâ€™16&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1300+&lt;/kbd&gt; &lt;a href="https://github.com/ruotianluo/pytorch-faster-rcnn"&gt;pytorch-faster-rcnn&lt;/a&gt;: A pytorch implementation of faster RCNN detection framework based on Xinlei Chen's tf-faster-rcnn.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/huggingface/torchMoji"&gt;torchMoji&lt;/a&gt;: A pyTorch implementation of the DeepMoji model: state-of-the-art deep learning model for analyzing sentiment, emotion, sarcasm etc.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2700+&lt;/kbd&gt; &lt;a href="https://github.com/hangzhaomit/semantic-segmentation-pytorch"&gt;semantic-segmentation-pytorch&lt;/a&gt;: åœ¨&lt;a href="http://sceneparsing.csail.mit.edu" rel="nofollow"&gt;MIT ADE20K dataset&lt;/a&gt;æ•°æ®é›†ä¸Šå®ç°è¯­ä¹‰åˆ†å‰²/åœºæ™¯è§£æã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000+&lt;/kbd&gt; &lt;a href="https://github.com/salesforce/pytorch-qrnn"&gt;pytorch-qrnn&lt;/a&gt;: PyTorch implementation of the Quasi-Recurrent Neural Network - up to 16 times faster than NVIDIA's cuDNN LSTM&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/theeluwin/pytorch-sgns"&gt;pytorch-sgns&lt;/a&gt;: Skipgram Negative Sampling in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ClementPinard/SfmLearner-Pytorch"&gt;SfmLearner-Pytorch &lt;/a&gt;: Pytorch version of SfmLearner from Tinghui Zhou et al.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/1zb/deformable-convolution-pytorch"&gt;deformable-convolution-pytorch&lt;/a&gt;: PyTorchå®ç°å¯å˜å½¢å·ç§¯ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fanglanting/skip-gram-pytorch"&gt;skip-gram-pytorch&lt;/a&gt;: A complete pytorch implementation of skipgram model (with subsampling and negative sampling). The embedding result is tested with Spearman's rank correlation.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hanzhanggit/StackGAN-v2"&gt;stackGAN-v2&lt;/a&gt;: Pytorch implementation for reproducing StackGAN_v2 results in the paper StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks by Han Zhang*, Tao Xu*, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, Dimitris Metaxas.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ruotianluo/self-critical.pytorch"&gt;self-critical.pytorch&lt;/a&gt;: éå®˜æ–¹ï¼ŒPyTorchå®ç°åŸºäº self-critical åºåˆ—è®­ç»ƒçš„å›¾åƒæ ‡æ³¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1900+&lt;/kbd&gt; &lt;a href="https://github.com/tkipf/pygcn"&gt;pygcn&lt;/a&gt;: å›¾å·ç§¯ç½‘ç»œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ixaxaar/pytorch-dnc"&gt;dnc&lt;/a&gt;: å¯å¾®ç¥ç»è®¡ç®—æœºã€ç¨€ç–å­˜å–å­˜å‚¨å™¨ä¸ç¨€ç–å¯å¾®ç¥ç»è®¡ç®—æœºã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ptrblck/prog_gans_pytorch_inference"&gt;prog_gans_pytorch_inference&lt;/a&gt;: PyTorch inference for "Progressive Growing of GANs" with CelebA snapshot.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/timomernick/pytorch-capsule"&gt;pytorch-capsule&lt;/a&gt;: Pytorch implementation of Hinton's Dynamic Routing Between Capsules.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dyhan0920/PyramidNet-PyTorch"&gt;PyramidNet-PyTorch&lt;/a&gt;: A PyTorch implementation for PyramidNets (Deep Pyramidal Residual Networks, arxiv.org/abs/1610.02915)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/gram-ai/radio-transformer-networks"&gt;radio-transformer-networks&lt;/a&gt;: A PyTorch implementation of Radio Transformer Networks from the paper "An Introduction to Deep Learning for the Physical Layer". arxiv.org/abs/1702.00832&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/castorini/honk"&gt;honk&lt;/a&gt;: PyTorch reimplementation of Google's TensorFlow CNNs for keyword spotting.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/SSARCandy/DeepCORAL"&gt;DeepCORAL&lt;/a&gt;: A PyTorch implementation of 'Deep CORAL: Correlation Alignment for Deep Domain Adaptation.', ECCV 2016&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/bearpaw/pytorch-pose"&gt;pytorch-pose&lt;/a&gt;: PyTorchå·¥å…·åŒ…ï¼Œç”¨äº2Däººä½“å§¿æ€ä¼°è®¡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/karandesai-96/lang-emerge-parlai"&gt;lang-emerge-parlai&lt;/a&gt;: Implementation of EMNLP 2017 Paper "Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog" using PyTorch and ParlAI&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Kaixhin/Rainbow"&gt;Rainbow&lt;/a&gt;: Rainbow: Combining Improvements in Deep Reinforcement Learning&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/gdlg/pytorch_compact_bilinear_pooling"&gt;pytorch_compact_bilinear_pooling v1&lt;/a&gt;: This repository has a pure Python implementation of Compact Bilinear Pooling and Count Sketch for PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/DeepInsight-PCALab/CompactBilinearPooling-Pytorch"&gt;CompactBilinearPooling-Pytorch v2&lt;/a&gt;: (Yang Gao, et al.) A Pytorch Implementation for Compact Bilinear Pooling.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/gitabcworld/FewShotLearning"&gt;FewShotLearning&lt;/a&gt;: Pytorch implementation of the paper "Optimization as a Model for Few-Shot Learning"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jklj077/meProp"&gt;meProp&lt;/a&gt;: Codes for "meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting".&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/clcarwin/SFD_pytorch"&gt;SFD_pytorch&lt;/a&gt;: å•é•œå¤´å°ºåº¦ä¸å˜äººè„¸æ£€æµ‹å™¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/GradientEpisodicMemory"&gt;GradientEpisodicMemory&lt;/a&gt;: Continuum Learning with GEM: Gradient Episodic Memory. &lt;a href="https://arxiv.org/abs/1706.08840" rel="nofollow"&gt;https://arxiv.org/abs/1706.08840&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1400+&lt;/kbd&gt; &lt;a href="https://github.com/KupynOrest/DeblurGAN"&gt;DeblurGAN&lt;/a&gt;: Pytorch implementation of the paper DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;4200+&lt;/kbd&gt; &lt;a href="https://github.com/yunjey/StarGAN"&gt;StarGAN&lt;/a&gt;: StarGAN: å¤šé¢†åŸŸå›¾åƒè½¬æ¢ GAN ç½‘ç»œï¼Œ&lt;a href="https://arxiv.org/abs/1711.09020" rel="nofollow"&gt;https://arxiv.org/abs/1711.09020&lt;/a&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/adambielski/CapsNet-pytorch"&gt;CapsNet-pytorch&lt;/a&gt;: PyTorch å®ç° NIPS 2017 è®ºæ–‡ â€œ&lt;a href="https://arxiv.org/abs/1710.09829" rel="nofollow"&gt;èƒ¶å›Šé—´çš„åŠ¨æ€è·¯ç”±&lt;/a&gt;â€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ShichenLiu/CondenseNet"&gt;CondenseNet&lt;/a&gt;: CondenseNet: é¢å‘ç§»åŠ¨è®¾å¤‡çš„è½»é‡çº§ CNNã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5300+&lt;/kbd&gt; &lt;a href="https://github.com/DmitryUlyanov/deep-image-prior"&gt;deep-image-prior&lt;/a&gt;: åŸºäºç¥ç»ç½‘ç»œçš„å›¾åƒä¿®å¤ï¼Œæ— å­¦ä¹ è¿‡ç¨‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/natanielruiz/deep-head-pose"&gt;deep-head-pose&lt;/a&gt;: ä½¿ç”¨PyTorchè¿›è¡Œæ·±åº¦å­¦ä¹ å¤´éƒ¨å§¿åŠ¿ä¼°è®¡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zhunzhong07/Random-Erasing"&gt;Random-Erasing&lt;/a&gt;: è®ºæ–‡ä»£ç ï¼Œè®ºæ–‡ï¼š"&lt;a href="https://arxiv.org/abs/1708.04896" rel="nofollow"&gt;éšæœºæ“¦é™¤æ•°æ®å¢å¼º&lt;/a&gt;"ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/FaderNetworks"&gt;FaderNetworks&lt;/a&gt;: Fader Networks: é€šè¿‡æ»‘åŠ¨å±æ€§é‡æ„å›¾åƒ - NIPS 2017ï¼Œ&lt;a href="https://arxiv.org/pdf/1706.00409.pdf" rel="nofollow"&gt;https://arxiv.org/pdf/1706.00409.pdf&lt;/a&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1500+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/flownet2-pytorch"&gt;FlowNet 2.0&lt;/a&gt;: FlowNet 2.0: æ·±åº¦ç½‘ç»œä¸­å…‰æµä¼°è®¡çš„æ¼”åŒ–ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;4000+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/pix2pixHD"&gt;pix2pixHD&lt;/a&gt;: åˆ©ç”¨æ¡ä»¶ GANs åˆæˆå’Œå¤„ç† HD é«˜æ¸…å›¾åƒçš„ PyTorch å®ç°ï¼Œ&lt;a href="https://arxiv.org/pdf/1711.11585.pdf%E3%80%82" rel="nofollow"&gt;https://arxiv.org/pdf/1711.11585.pdfã€‚&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pkdn/pytorch-smoothgrad"&gt;pytorch-smoothgrad&lt;/a&gt;: SmoothGradé€šè¿‡å¢åŠ å™ªå£°æ¥å»é™¤å™ªå£°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/c0nn3r/RetinaNet"&gt;RetinaNet&lt;/a&gt;: RetinaNeå®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;4300+&lt;/kbd&gt; &lt;a href="https://github.com/jwyang/faster-rcnn.pytorch"&gt;faster-rcnn.pytorch&lt;/a&gt;: This project is a faster faster R-CNN implementation, aimed to accelerating the training of faster R-CNN object detection models.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/leehomyc/mixup_pytorch"&gt;mixup_pytorch&lt;/a&gt;: A PyTorch implementation of the paper Mixup: Beyond Empirical Risk Minimization in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mapillary/inplace_abn"&gt;inplace_abn&lt;/a&gt;: In-Place Activated BatchNorm for Memory-Optimized Training of DNNs&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/xingyizhou/pytorch-pose-hg-3d"&gt;pytorch-pose-hg-3d&lt;/a&gt;: PyTorch implementation for 3D human pose estimation&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/HarshTrivedi/nmn-pytorch"&gt;nmn-pytorch&lt;/a&gt;: Neural Module Network for VQA in Pytorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kefirski/bytenet"&gt;bytenet&lt;/a&gt;: Pytorch implementation of bytenet from "Neural Machine Translation in Linear Time" paper&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hengyuan-hu/bottom-up-attention-vqa"&gt;bottom-up-attention-vqa&lt;/a&gt;: vqa, bottom-up-attention, pytorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ruiminshen/yolo2-pytorch"&gt;yolo2-pytorch&lt;/a&gt;: The YOLOv2 is one of the most popular one-stage object detector. This project adopts PyTorch as the developing framework to increase productivity, and utilize ONNX to convert models into Caffe 2 to benifit engineering deployment.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Wizaron/reseg-pytorch"&gt;reseg-pytorch&lt;/a&gt;: PyTorch å®ç°ReSegã€‚ (&lt;a href="https://arxiv.org/pdf/1511.07053.pdf" rel="nofollow"&gt;https://arxiv.org/pdf/1511.07053.pdf&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Wizaron/binary-stochastic-neurons"&gt;binary-stochastic-neurons&lt;/a&gt;: Binary Stochastic Neurons in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/DavexPro/pytorch-pose-estimation"&gt;pytorch-pose-estimation&lt;/a&gt;: PyTorch Implementation of Realtime Multi-Person Pose Estimation project.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/higgsfield/interaction_network_pytorch"&gt;interaction_network_pytorch&lt;/a&gt;: Pytorch Implementation of Interaction Networks for Learning about Objects, Relations and Physics.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wlwkgus/NoisyNaturalGradient"&gt;NoisyNaturalGradient&lt;/a&gt;: Pytorch Implementation of paper "Noisy Natural Gradient as Variational Inference".&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/moskomule/ewc.pytorch"&gt;ewc.pytorch&lt;/a&gt;: An implementation of Elastic Weight Consolidation (EWC), proposed in James Kirkpatrick et al. Overcoming catastrophic forgetting in neural networks 2016(10.1073/pnas.1611835114).&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jacobgil/pytorch-zssr"&gt;pytorch-zssr&lt;/a&gt;: PyTorch implementation of 1712.06087 "Zero-Shot" Super-Resolution using Deep Internal Learning&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/atiyo/deep_image_prior"&gt;deep_image_prior&lt;/a&gt;: åŸºäºæœªè®­ç»ƒç¥ç»ç½‘ç»œçš„å›¾åƒé‡å»ºç®—æ³•å®ç°ã€‚ç®—æ³•ï¼š&lt;a href="https://arxiv.org/abs/1711.10925" rel="nofollow"&gt;Deep Image Prior&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/leviswind/pytorch-transformer"&gt;pytorch-transformer&lt;/a&gt;: PyTorchå®ç°è®ºæ–‡&lt;a href="https://arxiv.org/abs/1706.03762" rel="nofollow"&gt;Attention Is All You Need&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/devendrachaplot/DeepRL-Grounding"&gt;DeepRL-Grounding&lt;/a&gt;: PyTorchå®ç°AAAI-18è®ºæ–‡&lt;a href="https://arxiv.org/abs/1706.07230" rel="nofollow"&gt;Gated-Attention Architectures for Task-Oriented Language Grounding&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Wizaron/deep-forecast-pytorch"&gt;deep-forecast-pytorch&lt;/a&gt;: ä½¿ç”¨LSTMsè¿›è¡Œé£é€Ÿé¢„æµ‹ï¼Œè®ºæ–‡ï¼š&lt;a href="arxiv.org/pdf/1707.08110.pdf"&gt;Deep Forecast: Deep Learning-based Spatio-Temporal Forecasting&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/utiasSTARS/cat-net"&gt;cat-net&lt;/a&gt;:  æ­£åˆ™å¤–è§‚å˜æ¢ï¼ˆ&lt;a href="https://arxiv.org/abs/1709.03009" rel="nofollow"&gt;Canonical Appearance Transformations&lt;/a&gt;ï¼‰&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tneumann/minimal_glo"&gt;minimal_glo&lt;/a&gt;: Minimal PyTorch implementation of Generative Latent Optimization from the paper "Optimizing the Latent Space of Generative Networks"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/dragen1860/LearningToCompare-Pytorch"&gt;LearningToCompare-Pytorch&lt;/a&gt;: Pytorch Implementation for Paper: Learning to Compare: Relation Network for Few-Shot Learning.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/poincare-embeddings"&gt;poincare-embeddings&lt;/a&gt;: PyTorch implementation of the NIPS-17 paper "PoincarÃ© Embeddings for Learning Hierarchical Representations".&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/ikostrikov/pytorch-trpo"&gt;pytorch-trpo(Hessian-vector product version)&lt;/a&gt;: This is a PyTorch implementation of "Trust Region Policy Optimization (TRPO)" with exact Hessian-vector product instead of finite differences approximation.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/JamesChuanggg/ggnn.pytorch"&gt;ggnn.pytorch&lt;/a&gt;: A PyTorch Implementation of Gated Graph Sequence Neural Networks (GGNN).&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Mrgemy95/visual-interaction-networks-pytorch"&gt;visual-interaction-networks-pytorch&lt;/a&gt;: This's an implementation of deepmind Visual Interaction Networks paper using pytorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jhayes14/adversarial-patch"&gt;adversarial-patch&lt;/a&gt;: PyTorchå®ç°å¯¹æŠ—è¡¥ä¸ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch"&gt;Prototypical-Networks-for-Few-shot-Learning-PyTorch&lt;/a&gt;: Implementation of Prototypical Networks for Few Shot Learning (arxiv.org/abs/1703.05175) in Pytorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/orobix/Visual-Feature-Attribution-Using-Wasserstein-GANs-Pytorch"&gt;Visual-Feature-Attribution-Using-Wasserstein-GANs-Pytorch&lt;/a&gt;: Implementation of Visual Feature Attribution using Wasserstein GANs (arxiv.org/abs/1711.08998) in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Blade6570/PhotographicImageSynthesiswithCascadedRefinementNetworks-Pytorch"&gt;PhotographicImageSynthesiswithCascadedRefinementNetworks-Pytorch&lt;/a&gt;: ç”¨çº§è”ä¼˜åŒ–ç½‘ç»œç”Ÿæˆç…§ç‰‡çº§å›¾åƒï¼Œ&lt;a href="https://arxiv.org/abs/1707.09405" rel="nofollow"&gt;https://arxiv.org/abs/1707.09405&lt;/a&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1900+&lt;/kbd&gt; &lt;a href="https://github.com/carpedm20/ENAS-pytorch"&gt;ENAS-pytorch&lt;/a&gt;: PyTorchå®ç°"&lt;a href="https://arxiv.org/abs/1802.03268" rel="nofollow"&gt;åŸºäºå‚æ•°å…±äº«çš„é«˜æ•ˆç¥ç»ç½‘ç»œç»“æ„æœç´¢&lt;/a&gt;"ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kentsyx/Neural-IMage-Assessment"&gt;Neural-IMage-Assessment&lt;/a&gt;: ç¥ç»å›¾ç‰‡è¯„ä¼°ï¼Œ&lt;a href="https://arxiv.org/abs/1709.05424" rel="nofollow"&gt;https://arxiv.org/abs/1709.05424&lt;/a&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tfrerix/proxprop"&gt;proxprop&lt;/a&gt;: è¿‘ç«¯å›ä¼ (Proximal Backpropagation) - éšå¼æ¢¯åº¦ä»£æ›¿æ˜¾å¼æ¢¯åº¦çš„ç¥ç»ç½‘ç»œè®­ç»ƒç®—æ³•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;9900+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/FastPhotoStyle"&gt;FastPhotoStyle&lt;/a&gt;: ç…§ç‰‡çº§é€¼çœŸçš„å›¾åƒé£æ ¼åŒ–çš„ä¸€ä¸ªå°é—­è§£ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Ben-Louis/Deep-Image-Analogy-PyTorch"&gt;Deep-Image-Analogy-PyTorch&lt;/a&gt;: åŸºäºPyTorchçš„æ·±åº¦å›¾åƒæ¨¡æ‹Ÿçš„Pythonå®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/layumi/Person_reID_baseline_pytorch"&gt;Person-reID_pytorch&lt;/a&gt;: è¡Œäººå†è¯†åˆ«Person-reIDçš„PyTorchå®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zalandoresearch/pt-dilate-rnn"&gt;pt-dilate-rnn&lt;/a&gt;: ç©ºæ´é€’å½’ç¥ç»ç½‘ç»œï¼ˆDilated RNNsï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jhjacobsen/pytorch-i-revnet"&gt;pytorch-i-revnet&lt;/a&gt;: Pytorchå®ç°i-RevNetsã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Orcuslc/OrthNet"&gt;OrthNet&lt;/a&gt;: TensorFlowã€PyTorchå’ŒNumpyå±‚ç”Ÿæˆæ­£äº¤å¤šé¡¹å¼ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jt827859032/DRRN-pytorch"&gt;DRRN-pytorch&lt;/a&gt;: "&lt;a href="http://cvlab.cse.msu.edu/pdfs/Tai_Yang_Liu_CVPR2017.pdf" rel="nofollow"&gt;è¶…åˆ†è¾¨ç‡çš„æ·±é€’å½’æ®‹å·®ç½‘ç»œ(DRRN)&lt;/a&gt;", CVPR 2017&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/moskomule/shampoo.pytorch"&gt;shampoo.pytorch&lt;/a&gt;: Shampooç®—æ³•å®ç°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/truskovskiyk/nima.pytorch"&gt;Neural-IMage-Assessment 2&lt;/a&gt;: ç¥ç»å›¾ç‰‡è¯„ä¼°ï¼Œ&lt;a href="https://arxiv.org/abs/1709.05424" rel="nofollow"&gt;https://arxiv.org/abs/1709.05424&lt;/a&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1900+&lt;/kbd&gt; &lt;a href="https://github.com/locuslab/TCN"&gt;TCN&lt;/a&gt;: Sequence modeling benchmarks and temporal convolutional networks locuslab/TCN&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/shahsohil/DCC"&gt;DCC&lt;/a&gt;: This repository contains the source code and data for reproducing results of Deep Continuous Clustering paper.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/arunmallya/packnet"&gt;packnet&lt;/a&gt;: Code for PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning arxiv.org/abs/1711.05769&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/github-pengge/PyTorch-progressive_growing_of_gans"&gt;PyTorch-progressive_growing_of_gans&lt;/a&gt;: PyTorch implementation of Progressive Growing of GANs for Improved Quality, Stability, and Variation.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/salesforce/nonauto-nmt"&gt;nonauto-nmt&lt;/a&gt;: PyTorch Implementation of "Non-Autoregressive Neural Machine Translation"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;4500+&lt;/kbd&gt; &lt;a href="https://github.com/eriklindernoren/PyTorch-GAN"&gt;PyTorch-GAN&lt;/a&gt;: PyTorch implementations of Generative Adversarial Networks.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tomrunia/PyTorchWavelets"&gt;PyTorchWavelets&lt;/a&gt;: PyTorch implementation of the wavelet analysis found in Torrence and Compo (1998)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/karpathy/pytorch-made"&gt;pytorch-made&lt;/a&gt;: MADE (Masked Autoencoder Density Estimation) implementation in PyTorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/emited/VariationalRecurrentNeuralNetwork"&gt;VRNN&lt;/a&gt;: Pytorch implementation of the Variational RNN (VRNN), from A Recurrent Latent Variable Model for Sequential Data.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/emited/flow"&gt;flow&lt;/a&gt;: Pytorch implementation of ICLR 2018 paper Deep Learning for Physical Processes: Integrating Prior Scientific Knowledge.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/r9y9/deepvoice3_pytorch"&gt;deepvoice3_pytorch&lt;/a&gt;: PyTorchå®ç°åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„è¯­éŸ³åˆæˆæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/elanmart/psmm"&gt;psmm&lt;/a&gt;: imlementation of the the Pointer Sentinel Mixture Model, as described in the paper by Stephen Merity et al.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/tacotron2"&gt;tacotron2&lt;/a&gt;: Tacotron 2 - PyTorch implementation with faster-than-realtime inference.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rahulkidambi/AccSGD"&gt;AccSGD&lt;/a&gt;: Implements pytorch code for the Accelerated SGD algorithm.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hengruo/QANet-pytorch"&gt;QANet-pytorch&lt;/a&gt;: an implementation of QANet with PyTorch (EM/F1 = 70.5/77.2 after 20 epoches for about 20 hours on one 1080Ti card.)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/TimDettmers/ConvE"&gt;ConvE&lt;/a&gt;: Convolutional 2D Knowledge Graph Embeddings&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kaushalshetty/Structured-Self-Attention"&gt;Structured-Self-Attention&lt;/a&gt;: Implementation for the paper A Structured Self-Attentive Sentence Embedding, which is published in ICLR 2017: arxiv.org/abs/1703.03130 .&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/williamleif/graphsage-simple"&gt;graphsage-simple&lt;/a&gt;: Simple reference implementation of GraphSAGE.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2500+&lt;/kbd&gt; &lt;a href="https://github.com/roytseng-tw/Detectron.pytorch"&gt;Detectron.pytorch&lt;/a&gt;: A pytorch implementation of Detectron. Both training from scratch and inferring directly from pretrained Detectron weights are available.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/irhumshafkat/R2Plus1D-PyTorch"&gt;R2Plus1D-PyTorch&lt;/a&gt;: PyTorch implementation of the R2Plus1D convolution based ResNet architecture described in the paper "A Closer Look at Spatiotemporal Convolutions for Action Recognition"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/viking-sudo-rm/StackNN"&gt;StackNN&lt;/a&gt;: A PyTorch implementation of differentiable stacks for use in neural networks.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/translagent"&gt;translagent&lt;/a&gt;: Code for Emergent Translation in Multi-Agent Communication.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jnhwkim/ban-vqa"&gt;ban-vqa&lt;/a&gt;: Bilinear attention networks for visual question answering.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/huggingface/pytorch-openai-transformer-lm"&gt;pytorch-openai-transformer-lm&lt;/a&gt;: This is a PyTorch implementation of the TensorFlow code provided with OpenAI's paper "Improving Language Understanding by Generative Pre-Training" by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/akanimax/T2F"&gt;T2F&lt;/a&gt;: ä½¿ç”¨æ·±åº¦å­¦ä¹ è¿›è¡ŒText-to-Faceç”Ÿæˆã€‚è¯¥é¡¹ç›®ç»“åˆäº†&lt;a href="https://arxiv.org/abs/1710.10916" rel="nofollow"&gt;StackGAN&lt;/a&gt;å’Œ&lt;a href="https://arxiv.org/abs/1710.10196" rel="nofollow"&gt;ProGAN&lt;/a&gt;ï¼Œè¿™ä¸¤ä¸ªæ¨¡å‹å¯ä»¥åŸºäºæ–‡å­—æè¿°åˆæˆäººè„¸ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mseitzer/pytorch-fid"&gt;pytorch - fid&lt;/a&gt;: A Port of FrÃ©chet Inception Distance (FID score) to PyTorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jmtomczak/vae_vpflows"&gt;vae_vpflows&lt;/a&gt;:Code in PyTorch for the convex combination linear IAF and the Householder Flow, J.M. Tomczak &amp;amp; M. Welling jmtomczak.github.io/deebmed.html&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mkocabas/CoordConv-pytorch"&gt;CoordConv-pytorch&lt;/a&gt;: Pytorch implementation of CoordConv introduced in 'An intriguing failing of convolutional neural networks and the CoordConv solution' paper. (arxiv.org/pdf/1807.03247.pdf)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/xternalz/SDPoint"&gt;SDPoint&lt;/a&gt;: Implementation of "Stochastic Downsampling for Cost-Adjustable Inference and Improved Regularization in Convolutional Networks", published in CVPR 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wxywhu/SRDenseNet-pytorch"&gt;SRDenseNet-pytorch&lt;/a&gt;: ææ·±ç½‘ç»œï¼ŒSRDenseNet-pytorchï¼Œè®ºæ–‡ï¼š&lt;a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Tong_Image_Super-Resolution_Using_ICCV_2017_paper.pdf" rel="nofollow"&gt;åŸºäºå¯†é›†è·³è·ƒè¿æ¥çš„å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆICCV_2017ï¼‰&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/LMescheder/GAN_stability"&gt;GAN_stability&lt;/a&gt;: Code for paper "Which Training Methods for GANs do actually Converge? (ICML 2018)"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wannabeOG/Mask-RCNN"&gt;Mask-RCNN&lt;/a&gt;: A PyTorch implementation of the architecture of Mask RCNN, serves as an introduction to working with PyTorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/chaoyuaw/pytorch-coviar"&gt;pytorch-coviar&lt;/a&gt;: Compressed Video Action Recognition&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/chenxi116/PNASNet.pytorch"&gt;PNASNet.pytorch&lt;/a&gt;: PyTorch implementation of PNASNet-5 on ImageNet.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kevinzakka/NALU-pytorch"&gt;NALU-pytorch&lt;/a&gt;: Basic pytorch implementation of NAC/NALU from Neural Arithmetic Logic Units arxiv.org/pdf/1808.00508.pdf&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/alexis-jacq/LOLA_DiCE"&gt;LOLA_DiCE&lt;/a&gt;: Pytorch ä½¿ç”¨&lt;a href="arxiv.org/abs/1802.05098"&gt;DiCE&lt;/a&gt;å®ç°&lt;a href="arxiv.org/abs/1709.04326"&gt;LOLA&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wohlert/generative-query-network-pytorch"&gt;generative-query-network-pytorch&lt;/a&gt;: Generative Query Network (GQN) in PyTorch as described in "Neural Scene Representation and Rendering"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/wmvanvliet/pytorch_hmax"&gt;pytorch_hmax&lt;/a&gt;: åœ¨PyTorchä¸­å®ç°&lt;a href="https://maxlab.neuro.georgetown.edu/hmax.html#inside" rel="nofollow"&gt;HMAX(Hierarchical Model and X)&lt;/a&gt;è§†è§‰æ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/yunlongdong/FCN-pytorch-easiest"&gt;FCN-pytorch-easiest&lt;/a&gt;: trying to be the most easiest and just get-to-use pytorch implementation of FCN (Fully Convolotional Networks)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/awni/transducer"&gt;transducer&lt;/a&gt;: A Fast Sequence Transducer Implementation with PyTorch Bindings.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/artix41/AVO-pytorch"&gt;AVO-pytorch&lt;/a&gt;: Implementation of Adversarial Variational Optimization in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/huguyuehuhu/HCN-pytorch"&gt;HCN-pytorch&lt;/a&gt;: A pytorch reimplementation of { Co-occurrence Feature Learning from Skeleton Data for Action Recognition and Detection with Hierarchical Aggregation }.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/szagoruyko/binary-wide-resnet"&gt;binary-wide-resnet&lt;/a&gt;: PyTorch implementation of Wide Residual Networks with 1-bit weights by McDonnel (ICLR 2018)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/arunmallya/piggyback"&gt;piggyback&lt;/a&gt;: Code for Piggyback: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights arxiv.org/abs/1801.06519&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;6900+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/vid2vid"&gt;vid2vid&lt;/a&gt;: Pytorch implementation of our method for high-resolution (e.g. 2048x1024) photorealistic video-to-video translation.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/cranmer/poisson-convolution-sum"&gt;poisson-convolution-sum&lt;/a&gt;: Implements an infinite sum of poisson-weighted convolutions&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/davidmascharka/tbd-nets"&gt;tbd-nets&lt;/a&gt;: PyTorch implementation of "Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning" arxiv.org/abs/1803.05268&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/elbayadm/attn2d"&gt;attn2d&lt;/a&gt;: Pervasive Attention: 2D Convolutional Networks for Sequence-to-Sequence Prediction&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2600+&lt;/kbd&gt; &lt;a href="https://github.com/ultralytics/yolov3"&gt;yolov3&lt;/a&gt;: YOLOv3: è®­ç»ƒå’Œæ¨æ–­ï¼Œ&lt;a href="https://www.ultralytics.com" rel="nofollow"&gt;https://www.ultralytics.com&lt;/a&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/duc0/deep-dream-in-pytorch"&gt;deep-dream-in-pytorch&lt;/a&gt;: Pytorch implementation of the DeepDream computer vision algorithm.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ikostrikov/pytorch-flows"&gt;pytorch-flows&lt;/a&gt;: PyTorch implementations of algorithms for density estimation&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ars-ashuha/quantile-regression-dqn-pytorch"&gt;quantile-regression-dqn-pytorch&lt;/a&gt;: Quantile Regression DQN a Minimal Working Example&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/L0SG/relational-rnn-pytorch"&gt;relational-rnn-pytorch&lt;/a&gt;: An implementation of DeepMind's Relational Recurrent Neural Networks in PyTorch.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/scaelles/DEXTR-PyTorch"&gt;DEXTR-PyTorch&lt;/a&gt;: æ·±åº¦æç«¯åˆ‡å‰²ï¼Œ&lt;a href="http://www.vision.ee.ethz.ch/~cvlsegmentation/dextr" rel="nofollow"&gt;http://www.vision.ee.ethz.ch/~cvlsegmentation/dextr&lt;/a&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rdspring1/PyTorch_GBW_LM"&gt;PyTorch_GBW_LM&lt;/a&gt;: PyTorch Language Model for Google Billion Word Dataset.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Stonesjtu/Pytorch-NCE"&gt;Pytorch-NCE&lt;/a&gt;: The Noise Contrastive Estimation for softmax output written in Pytorch&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/shayneobrien/generative-models"&gt;generative-models&lt;/a&gt;: Annotated, understandable, and visually interpretable PyTorch implementations of: VAE, BIRVAE, NSGAN, MMGAN, WGAN, WGANGP, LSGAN, DRAGAN, BEGAN, RaGAN, InfoGAN, fGAN, FisherGAN.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/andreasveit/convnet-aig"&gt;convnet-aig&lt;/a&gt;: PyTorch implementation for Convolutional Networks with Adaptive Inference Graphs.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/TianhongDai/integrated-gradient-pytorch"&gt;integrated-gradient-pytorch&lt;/a&gt;: This is the pytorch implementation of the paper - Axiomatic Attribution for Deep Networks.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Alexander-H-Liu/MalConv-Pytorch"&gt;MalConv-Pytorch&lt;/a&gt;: Pytorch implementation of MalConv.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/locuslab/trellisnet"&gt;trellisnet&lt;/a&gt;: Trellis Networks for Sequence Modeling&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/minqi/learning-to-communicate-pytorch"&gt;Learning to Communicate with Deep Multi-Agent Reinforcement Learning&lt;/a&gt;: pytorch implementation of  Learning to Communicate with Deep Multi-Agent Reinforcement Learning paper.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/michaelklachko/pnn.pytorch"&gt;pnn.pytorch&lt;/a&gt;: PyTorch implementation of CVPR'18 - Perturbative Neural Networks &lt;a href="http://xujuefei.com/pnn.html" rel="nofollow"&gt;http://xujuefei.com/pnn.html&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rainofmine/Face_Attention_Network"&gt;Face_Attention_Network&lt;/a&gt;: Pytorch implementation of face attention network as described in Face Attention Network: An Effective Face Detector for the Occluded Faces.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1200+&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/waveglow"&gt;waveglow&lt;/a&gt;: åŸºäºæµçš„è¯­éŸ³åˆæˆç”Ÿæˆç½‘ç»œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/deepfloat"&gt;deepfloat&lt;/a&gt;: This repository contains the SystemVerilog RTL, C++, HLS (Intel FPGA OpenCL to wrap RTL code) and Python needed to reproduce the numerical results in "Rethinking floating point for deep learning"&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/subeeshvasu/2018_subeesh_epsr_eccvw"&gt;EPSR&lt;/a&gt;: Pytorch implementation of &lt;a href="https://arxiv.org/pdf/1811.00344.pdf" rel="nofollow"&gt;Analyzing Perception-Distortion Tradeoff using Enhanced Perceptual Super-resolution Network&lt;/a&gt;. This work has won the first place in PIRM2018-SR competition (region 1) held as part of the ECCV 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ksw0306/ClariNet"&gt;ClariNet&lt;/a&gt;: Pytorchå®ç°&lt;a href="https://arxiv.org/abs/1807.07281" rel="nofollow"&gt;ClariNet&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;16600+&lt;/kbd&gt; &lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT"&gt;pytorch-pretrained-BERT&lt;/a&gt;: PyTorch version of Google AI's BERT model with script to load Google's pre-trained models&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/npuichigo/waveglow"&gt;torch_waveglow&lt;/a&gt;: PyTorchå®ç°WaveGlow: åŸºäºæµçš„è¯­éŸ³åˆæˆç”Ÿæˆç½‘ç»œã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2100+&lt;/kbd&gt; &lt;a href="https://github.com/cleardusk/3DDFA"&gt;3DDFA&lt;/a&gt;: The pytorch improved re-implementation of TPAMI 2017 paper: Face Alignment in Full Pose Range: A 3D Total Solution.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/tomgoldstein/loss-landscape"&gt;loss-landscape&lt;/a&gt;: loss-landscape Code for visualizing the loss landscape of neural nets.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zalandoresearch/famos"&gt;famos&lt;/a&gt;:ï¼ˆéï¼‰å‚æ•°å›¾åƒé£æ ¼åŒ–é©¬èµ›å…‹çš„å¯¹æŠ—æ€§æ¡†æ¶ã€‚è®ºæ–‡ï¼š&lt;a href="http://arxiv.org/abs/1811.09236" rel="nofollow"&gt;http://arxiv.org/abs/1811.09236&lt;/a&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/anuragranj/back2future.pytorch"&gt;back2future.pytorch&lt;/a&gt;: This is a Pytorch implementation of
Janai, J., GÃ¼ney, F., Ranjan, A., Black, M. and Geiger, A., Unsupervised Learning of Multi-Frame Optical Flow with Occlusions. ECCV 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mozilla/FFTNet"&gt;FFTNet&lt;/a&gt;: Unofficial Implementation of FFTNet vocode paper.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zisianw/FaceBoxes.PyTorch"&gt;FaceBoxes.PyTorch&lt;/a&gt;: PyTorchå®ç°&lt;a href="https://arxiv.org/abs/1708.05234" rel="nofollow"&gt;FaceBoxes&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2100+&lt;/kbd&gt; &lt;a href="https://github.com/kimiyoung/transformer-xl"&gt;Transformer-XL&lt;/a&gt;: Transformer-XL: Attentive Language Models Beyond a Fixed-Length Contexthttps://github.com/kimiyoung/transformer-xl&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jalexvig/associative_compression_networks"&gt;associative_compression_networks&lt;/a&gt;: Associative Compression Networks for Representation Learning.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jolibrain/fluidnet_cxx"&gt;fluidnet_cxx&lt;/a&gt;: FluidNet re-written with ATen tensor lib.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch"&gt;Deep-Reinforcement-Learning-Algorithms-with-PyTorch&lt;/a&gt;: This repository contains PyTorch implementations of deep reinforcement learning algorithms.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ericsun99/Shufflenet-v2-Pytorch"&gt;Shufflenet-v2-Pytorch&lt;/a&gt;: This is a Pytorch implementation of faceplusplus's ShuffleNet-v2.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/GraphWaveletNeuralNetwork"&gt;GraphWaveletNeuralNetwork&lt;/a&gt;: This is a Pytorch implementation of Graph Wavelet Neural Network. ICLR 2019.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/AttentionWalk"&gt;AttentionWalk&lt;/a&gt;: This is a Pytorch implementation of Watch Your Step: Learning Node Embeddings via Graph Attention. NIPS 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/SGCN"&gt;SGCN&lt;/a&gt;: This is a Pytorch implementation of Signed Graph Convolutional Network. ICDM 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/SINE"&gt;SINE&lt;/a&gt;: This is a Pytorch implementation of SINE: Scalable Incomplete Network Embedding. ICDM 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/GAM"&gt;GAM&lt;/a&gt;: This is a Pytorch implementation of Graph Classification using Structural Attention. KDD 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ProGamerGov/neural-style-pt"&gt;neural-style-pt&lt;/a&gt;: PyTorch å®ç° Justin Johnson çš„ç¥ç»é£æ ¼ç®—æ³•ã€‚è®ºæ–‡ï¼š&lt;a href="https://arxiv.org/abs/1508.06576" rel="nofollow"&gt;A Neural Algorithm of Artistic Style&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ibalazevic/TuckER"&gt;TuckER&lt;/a&gt;: TuckER: Tensor Factorization for Knowledge Graph Completion.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/BayesWatch/pytorch-prunes"&gt;pytorch-prunes&lt;/a&gt;: Pruning neural networks: is it time to nip it in the bud?&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/SimGNN"&gt;SimGNN&lt;/a&gt;: SimGNN: ä¸€ä¸ªå¿«é€Ÿå›¾å½¢ç›¸ä¼¼åº¦è®¡ç®—çš„ç¥ç»ç½‘ç»œæ–¹æ³•ã€‚è®ºæ–‡ï¼šA Neural Network Approach to Fast Graph Similarity Computation.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ahmedbesbes/character-based-cnn"&gt;Character CNN&lt;/a&gt;: PyTorch implementation of the Character-level Convolutional Networks for Text Classification paper.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/facebookresearch/XLM"&gt;XLM&lt;/a&gt;: PyTorch original implementation of Cross-lingual Language Model Pretraining.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/eth-sri/diffai"&gt;DiffAI&lt;/a&gt;: A provable defense against adversarial examples and library for building compatible PyTorch models.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/APPNP"&gt;APPNP&lt;/a&gt;: Combining Neural Networks with Personalized PageRank for Classification on Graphs. ICLR 2019.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/MixHop-and-N-GCN"&gt;NGCN&lt;/a&gt;: A Higher-Order Graph Convolutional Layer. NeurIPS 2018.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/graykode/gpt-2-Pytorch"&gt;gpt-2-Pytorch&lt;/a&gt;: Simple Text-Generator with OpenAI gpt-2 Pytorch Implementation&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/Splitter"&gt;Splitter&lt;/a&gt;: Splitter: Learning Node Representations that Capture Multiple Social Contexts. (WWW 2019).&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/CapsGNN"&gt;CapsGNN&lt;/a&gt;: èƒ¶å›Šå›¾ç¥ç»ç½‘ç»œï¼Œ&lt;a href="https://openreview.net/forum?id=Byl8BnRcYm" rel="nofollow"&gt;Capsule Graph Neural Network&lt;/a&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/ajbrock/BigGAN-PyTorch"&gt;BigGAN-PyTorch&lt;/a&gt;: PyTorchå®ç°BigGANï¼ˆéå®˜æ–¹ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mhubii/ppo_pytorch_cpp"&gt;ppo_pytorch_cpp&lt;/a&gt;: è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ç®—æ³•çš„C++ APIã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/seungwonpark/RandWireNN"&gt;RandWireNN&lt;/a&gt;: åŸºäºéšæœºè¿æ¥ç¥ç»ç½‘ç»œæ€§èƒ½çš„å›¾åƒè¯†åˆ«ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/joel-huang/zeroshot-capsnet-pytorch"&gt;Zero-shot Intent CapsNet&lt;/a&gt;: GPU-accelerated PyTorch implementation of "Zero-shot User Intent Detection via Capsule Neural Networks".&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/SEAL-CI"&gt;SEAL-CI&lt;/a&gt; åŠç›‘ç£å›¾åˆ†ç±»ï¼šå±‚æ¬¡å›¾è§†è§’ï¼ŒSemi-Supervised Graph Classification: A Hierarchical Graph Perspective. (WWW 2019)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/MixHop-and-N-GCN"&gt;MixHop&lt;/a&gt;: MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing. ICML 2019.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Lotayou/densebody_pytorch"&gt;densebody_pytorch&lt;/a&gt;: PyTorch implementation of CloudWalk's recent paper DenseBody.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mindslab-ai/voicefilter"&gt;voicefilter&lt;/a&gt;: Unofficial PyTorch implementation of Google AI's VoiceFilter system &lt;a href="http://swpark.me/voicefilter" rel="nofollow"&gt;http://swpark.me/voicefilter&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/NVIDIA/semantic-segmentation"&gt;NVIDIA/semantic-segmentation&lt;/a&gt;: PyTorchå®ç°â€œåˆ©ç”¨è§†é¢‘ä¼ æ’­å’Œæ ‡ç­¾æ¾å¼›æ”¹è¿›è¯­ä¹‰åˆ†å‰²â€ã€‚è®ºæ–‡ï¼š&lt;a href="https://arxiv.org/abs/1812.01593" rel="nofollow"&gt;Improving Semantic Segmentation via Video Propagation and Label Relaxation&lt;/a&gt;, In CVPR2019.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/benedekrozemberczki/ClusterGCN"&gt;ClusterGCN&lt;/a&gt;: A PyTorch implementation of "Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks" (KDD 2019).&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/NVlabs/DG-Net"&gt;NVlabs/DG-Net&lt;/a&gt;: A PyTorch implementation of "Joint Discriminative and Generative Learning for Person Re-identification" (CVPR19 Oral).&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/baidu-research/NCRF"&gt;NCRF&lt;/a&gt;: åŸºäºç¥ç»ç½‘ç»œæ¡ä»¶éšæœºåœº(NCRF)çš„è‚¿ç˜¤è½¬ç§»æ£€æµ‹ï¼Œç›¸å…³è®ºæ–‡ï¼š&lt;a href="https://openreview.net/forum?id=S1aY66iiM%E3%80%82" rel="nofollow"&gt;https://openreview.net/forum?id=S1aY66iiMã€‚&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ducha-aiki/pytorch-sift"&gt;pytorch-sift&lt;/a&gt;: PyTorchå®ç°SIFTï¼ˆå°ºåº¦ä¸å˜ç‰¹å¾å˜æ¢åŒ¹é…ç®—æ³•ï¼ŒScale Invariant Feature Transformï¼‰æè¿°å­ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mateuszbuda/brain-segmentation-pytorch"&gt;brain-segmentation-pytorch&lt;/a&gt;: æ·±åº¦å­¦ä¹ åˆ†å‰²ç½‘ç»œU-Netçš„PyTorchæ¨¡å‹å®ç°ï¼Œç”¨äºè„‘æ ¸ç£å…±æŒ¯ä¸­FLAIRå¼‚å¸¸çš„åˆ†å‰²ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/rosinality/glow-pytorch"&gt;glow-pytorch&lt;/a&gt;: PyTorch å®ç° "&lt;a href="https://arxiv.org/abs/1807.03039" rel="nofollow"&gt;Glow, Generative Flow with Invertible 1x1 Convolutions&lt;/a&gt;"ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zsef123/EfficientNets-PyTorch"&gt;EfficientNets-PyTorch&lt;/a&gt;: PyTorchå®ç°EfficientNet: å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹å°ºåº¦çš„å†æ€è€ƒã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/nv-tlabs/STEAL"&gt;STEAL&lt;/a&gt;: STEAL - ä»å™ªå£°æ ‡æ³¨ä¸­å­¦ä¹ è¯­ä¹‰è¾¹ç•Œï¼Œ&lt;a href="https://nv-tlabs.github.io/STEAL/" rel="nofollow"&gt;https://nv-tlabs.github.io/STEAL/&lt;/a&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/alecwangcq/EigenDamage-Pytorch"&gt;EigenDamage-Pytorch&lt;/a&gt;: å®˜æ–¹å®ç° ICML'19 è®ºæ–‡ "&lt;a href="https://arxiv.org/abs/1905.05934" rel="nofollow"&gt;ç‰¹å¾æŸä¼¤ï¼šå…‹ç½—å†…å…‹åˆ†è§£ç‰¹å¾åŸºä¸­çš„ç»“æ„å‰ªæ&lt;/a&gt;"ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ruidan/Aspect-level-sentiment"&gt;Aspect-level-sentiment&lt;/a&gt;: è®ºæ–‡ä»£ç å’Œæ•°æ®é›†ï¼ŒACL2018è®ºæ–‡ï¼š"&lt;a href="https://arxiv.org/abs/1806.04346" rel="nofollow"&gt;åˆ©ç”¨æ–‡æ¡£çŸ¥è¯†è¿›è¡Œä½“å±‚æƒ…æ„Ÿåˆ†ç±»&lt;/a&gt;"ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/nyukat/breast_cancer_classifier"&gt;breast_cancer_classifier&lt;/a&gt;: æ·±å±‚ç¥ç»ç½‘ç»œæé«˜æ”¾å°„ç§‘åŒ»ç”Ÿä¹³è…ºç™Œç­›æŸ¥çš„æ•ˆæœï¼Œ&lt;a href="https://arxiv.org/abs/1903.08297" rel="nofollow"&gt;https://arxiv.org/abs/1903.08297&lt;/a&gt; ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/AaltoVision/DGC-Net"&gt;DGC-Net&lt;/a&gt;: PyTorchå®ç°"&lt;a href="https://arxiv.org/abs/1810.08393" rel="nofollow"&gt;DGC-Net: å¯†é›†å‡ ä½•å¯¹åº”ç½‘ç»œ&lt;/a&gt;".&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Eric-Wallace/universal-triggers"&gt;universal-triggers&lt;/a&gt;: Universal Adversarial Triggers for Attacking and Analyzing NLP (EMNLP 2019)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch"&gt;Deep-Reinforcement-Learning-Algorithms-with-PyTorch&lt;/a&gt;: PyTorch implementations of deep reinforcement learning algorithms and environments.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/alibaba-edu/simple-effective-text-matching-pytorch"&gt;simple-effective-text-matching-pytorch&lt;/a&gt;: A pytorch implementation of the ACL2019 paper "Simple and Effective Text Matching with Richer Alignment Features".&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/utkuozbulak/adaptive-segmentation-mask-attack"&gt;Adaptive-segmentation-mask-attack (ASMA)&lt;/a&gt;: A pytorch implementation of the MICCAI2019 paper "Impact of Adversarial Examples on Deep Learning Models for Biomedical Image Segmentation".&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/NVIDIA/unsupervised-video-interpolation"&gt;NVIDIA/unsupervised-video-interpolation&lt;/a&gt;: A PyTorch Implementation of &lt;a href="https://arxiv.org/abs/1906.05928" rel="nofollow"&gt;Unsupervised Video Interpolation Using Cycle Consistency&lt;/a&gt;, In ICCV 2019.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-talks--conferencesæŠ¥å‘Š--ä¼šè®®" class="anchor" aria-hidden="true" href="#talks--conferencesæŠ¥å‘Š--ä¼šè®®"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Talks &amp;amp; conferencesï½œæŠ¥å‘Š &amp;amp; ä¼šè®®&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://developers.facebook.com/videos/2018/pytorch-developer-conference/" rel="nofollow"&gt;PyTorch Conference 2018&lt;/a&gt;: 2018å¹´é¦–å±ŠPyTorchå¼€å‘è€…å¤§ä¼šã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-pytorch-elsewhere--pytorchç›¸å…³" class="anchor" aria-hidden="true" href="#pytorch-elsewhere--pytorchç›¸å…³"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pytorch elsewhere ï½œ Pytorchç›¸å…³&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;kbd&gt;4100+&lt;/kbd&gt; &lt;a href="https://github.com/ritchieng/the-incredible-pytorch"&gt;the-incredible-pytorch&lt;/a&gt;**: ä¸å¯æ€è®®çš„Pythorchï¼šä¸€ä»½PyTorchç›¸å…³çš„æ•™ç¨‹ã€è®ºæ–‡ã€é¡¹ç›®ã€ç¤¾åŒºç­‰çš„æ¸…å•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;5500+&lt;/kbd&gt; &lt;a href="https://github.com/wiseodd/generative-models"&gt;generative models&lt;/a&gt;: å„ç§ç”Ÿæˆæ¨¡å‹ï¼Œä¾‹å¦‚åŸºäºPytorchå’ŒTensorflowçš„GANã€VAEã€‚ &lt;a href="http://wiseodd.github.io" rel="nofollow"&gt;http://wiseodd.github.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/MachineLearning/comments/5w3q74/d_so_pytorch_vs_tensorflow_whats_the_verdict_on/" rel="nofollow"&gt;pytorch vs tensorflow&lt;/a&gt;: Redditä¸Šçš„PyTorchå’ŒTensorFlowçš„æ¯”è¾ƒæ–‡ç« ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://discuss.pytorch.org/" rel="nofollow"&gt;Pytorch discussion forum&lt;/a&gt;: PyTorchè®ºå›ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://hub.docker.com/r/escong/pytorch-notebook/" rel="nofollow"&gt;pytorch notebook: docker-stack&lt;/a&gt;: ç±»ä¼¼äº &lt;a href="https://github.com/jupyter/docker-stacks/tree/master/scipy-notebook"&gt;Jupyter Notebook Scientific Python Stack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/kendricktan/drawlikebobross"&gt;drawlikebobross&lt;/a&gt;: ä½¿ç”¨ç¥ç»ç½‘ç»œä½œç”»ï¼&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/t-vi/pytorch-tvmisc"&gt;pytorch-tvmisc&lt;/a&gt;: è¯¥ä»“åº“æ”¶é›†äº†ä½œè€…ç”¨PyTorchå®ç°çš„å„ç§ç©æ„å„¿ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/andrewliao11/pytorch-a3c-mujoco"&gt;pytorch-a3c-mujoco&lt;/a&gt;: è¯¥é¡¹ç›®æ—¨åœ¨è§£å†³Mujocoä¸­çš„æ§åˆ¶é—®é¢˜ï¼Œé«˜åº¦åŸºäºpytorch-a3cã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=nbJ-2G2GXL0&amp;amp;list=WL&amp;amp;index=9" rel="nofollow"&gt;PyTorch in 5 Minutes&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jinfagang/pytorch_chatbot"&gt;pytorch_chatbot&lt;/a&gt;: ç”¨PyTorchå®ç°çš„èŠå¤©æœºå™¨äººã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Kaixhin/malmo-challenge"&gt;malmo-challenge&lt;/a&gt;: Malmoåä½œäººå·¥æ™ºèƒ½æŒ‘æˆ˜-Pig Catcherå›¢é˜Ÿã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jtoy/sketchnet"&gt;sketchnet&lt;/a&gt;: æŒ‡å¯¼è®¡ç®—æœºä½œç”»ã€‚&lt;a href="http://www.jtoy.net/projects/sketchnet/" rel="nofollow"&gt;http://www.jtoy.net/projects/sketchnet/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1100+&lt;/kbd&gt; &lt;a href="https://github.com/QuantScientist/Deep-Learning-Boot-Camp"&gt;Deep-Learning-Boot-Camp&lt;/a&gt;: éç›ˆåˆ©ç¤¾åŒºè¿è¥çš„5å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥ã€‚ &lt;a href="http://deep-ml.com" rel="nofollow"&gt;http://deep-ml.com&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mratsim/Amazon_Forest_Computer_Vision"&gt;Amazon_Forest_Computer_Vision&lt;/a&gt;: äºšé©¬é€Šæ£®æ—è®¡ç®—æœºè§†è§‰ï¼šä½¿ç”¨PyTorchæ ‡è®°å«æ˜Ÿå›¾åƒæ ‡è®°/Kerasä¸­çš„PyTorchæŠ€å·§ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1700+&lt;/kbd&gt; &lt;a href="https://github.com/junxiaosong/AlphaZero_Gomoku"&gt;AlphaZero_Gomoku&lt;/a&gt;: ç”¨AlphaZeroç®—æ³•ç©äº”å­æ£‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;null&lt;/kbd&gt; &lt;a href="https://github.com/youansheng/pytorch-cv"&gt;pytorch-cv&lt;/a&gt;: null.&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1600+&lt;/kbd&gt; &lt;a href="https://github.com/KaiyangZhou/deep-person-reid"&gt;deep-person-reid&lt;/a&gt;: Pytorchå®ç°æ·±åº¦å­¦ä¹ è¡Œäººé‡æ–°è¯†åˆ«æ–¹æ³•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1300+&lt;/kbd&gt; &lt;a href="https://github.com/victoresque/pytorch-template"&gt;pytorch-template&lt;/a&gt;: PyTorchæ·±åº¦å­¦ä¹ æ¨¡ç‰ˆã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/svishnu88/DLwithPyTorch"&gt;Deep Learning With Pytorch&lt;/a&gt;: éšä¹¦ä»£ç ã€Š&lt;a href="https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-pytorch" rel="nofollow"&gt;Deep Learning With Pytorch TextBook&lt;/a&gt;ã€‹ PyTorchå®ç”¨æŒ‡å—ï¼šä½¿ç”¨PyTorchå»ºç«‹æ–‡æœ¬å’Œè§†è§‰ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚&lt;a href="https://www.amazon.cn/dp/B078THDX3J/ref=sr_1_1?__mk_zh_CN=%E4%BA%9A%E9%A9%AC%E9%80%8A%E7%BD%91%E7%AB%99&amp;amp;keywords=Deep+Learning+with+PyTorch&amp;amp;qid=1568007543&amp;amp;s=gateway&amp;amp;sr=8-1" rel="nofollow"&gt;äºšé©¬é€Šä¸­å›½ç”µå­ç‰ˆ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/jalola/compare-tensorflow-pytorch"&gt;compare-tensorflow-pytorch&lt;/a&gt;: æ¯”è¾ƒç”¨Tensorflowç¼–å†™çš„å±‚å’Œç”¨Pytorchç¼–å†™çš„å±‚ä¹‹é—´çš„è¾“å‡ºã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/hasktorch/hasktorch"&gt;hasktorch&lt;/a&gt;: Haskellä¸­çš„å¼ é‡ä¸ç¥ç»ç½‘ç»œã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.manning.com/books/deep-learning-with-pytorch" rel="nofollow"&gt;Deep Learning With Pytorch&lt;/a&gt; Deep Learning with PyTorch æ•™ä½ å¦‚ä½•ç”¨Pythonå’ŒPyTorchå®ç°æ·±åº¦å­¦ä¹ ç®—æ³•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/fragcolor-xyz/nimtorch"&gt;nimtorch&lt;/a&gt;: PyTorch - Python + Nimï¼ŒPyTorchçš„Nimå‰ç«¯ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/John-Ellis/derplearning"&gt;derplearning&lt;/a&gt;: è‡ªåŠ¨é©¾é©¶é¥æ§è½¦ä»£ç ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/tugstugi/pytorch-saltnet"&gt;pytorch-saltnet&lt;/a&gt;: Kaggle | TGS Salt Identification Challenge ç¬¬9åè§£å†³æ–¹æ¡ˆã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/peterjc123/pytorch-scripts"&gt;pytorch-scripts&lt;/a&gt;: ä¸€äº›è„šæœ¬ï¼Œä½¿åœ¨Windowsä¸Šä½¿ç”¨PyTorchæ›´åŠ å®¹æ˜“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/ptrblck/pytorch_misc"&gt;pytorch_misc&lt;/a&gt;: ä¸ºPyTorchè®¨è®ºæ¿åˆ›å»ºçš„ä»£ç ç‰‡æ®µã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/arnas/awesome-pytorch-scholarship"&gt;awesome-pytorch-scholarship&lt;/a&gt;: æ”¶é›†äº†ä¸€ç³»åˆ—ä¼˜ç§€çš„PyTorchå­¦æœ¯æ–‡ç« ã€æŒ‡å—ã€åšå®¢ã€è¯¾ç¨‹å’Œå…¶ä»–èµ„æºã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/mmirman/MentisOculi"&gt;MentisOculi&lt;/a&gt;: PyTorchç‰ˆraytracerã€‚(raynet?)&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;2400+&lt;/kbd&gt; &lt;a href="https://github.com/karanchahal/DoodleMaster"&gt;DoodleMaster&lt;/a&gt;: â€œç”»å‡ºUIï¼â€("Don't code your UI, Draw it !")&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/LaurentMazare/ocaml-torch"&gt;ocaml-torch&lt;/a&gt;: ocaml-torchä¸ºPyTorchå¼ é‡åº“æä¾›ä¸€äº›ocamlç»‘å®šã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/pytorch/extension-script"&gt;extension-script&lt;/a&gt;: TorchScriptè‡ªå®šä¹‰C++/CUDAè¿ç®—ç¬¦çš„ç¤ºä¾‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/zccyman/pytorch-inference"&gt;pytorch-inference&lt;/a&gt;:  Windows10 å¹³å°ä¸Š Pytorch 1.0åœ¨ C++ ä¸­çš„æ¨æ–­ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/Wizaron/pytorch-cpp-inference"&gt;pytorch-cpp-inference&lt;/a&gt;: åŒ…å«ä½¿ç”¨PyTorch C++ APIæ‰§è¡Œæ¨æ–­çš„å„ç§ç¤ºä¾‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/LaurentMazare/tch-rs"&gt;tch-rs&lt;/a&gt;: PyTorchçš„Rustç»‘å®šã€‚&lt;/li&gt;
&lt;li&gt;&lt;kbd&gt;1000-&lt;/kbd&gt; &lt;a href="https://github.com/interesaaat/TorchSharp"&gt;TorchSharp&lt;/a&gt;: Pytorchå¼•æ“çš„.NETç»‘å®šã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ml-tooling/ml-workspace"&gt;ML Workspace&lt;/a&gt;: é¢å‘æœºå™¨å­¦ä¹ å’Œæ•°æ®ç§‘å­¦çš„ä¸€ä½“åŒ–Web IDEã€‚åŒ…å«Jupyter, VS Code, PyTorch å’Œè®¸å¤šå…¶ä»–å·¥å…·æˆ–åº“ï¼Œè¿™äº›éƒ½é›†åˆåœ¨ä¸€ä¸ªDockeræ˜ åƒä¸­ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Feedback: If you have any ideas or you want any other content to be added to this list, feel free to contribute.&lt;/strong&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>xavier-zy</author><guid isPermaLink="false">https://github.com/xavier-zy/Awesome-pytorch-list-CNVersion</guid><pubDate>Sun, 09 Feb 2020 00:01:00 GMT</pubDate></item><item><title>Atcold/pytorch-Deep-Learning-Minicourse #2 in Jupyter Notebook, Today</title><link>https://github.com/Atcold/pytorch-Deep-Learning-Minicourse</link><description>&lt;p&gt;&lt;i&gt;Deep Learning with PyTorch&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deep-learning-with-pytorch-" class="anchor" aria-hidden="true" href="#deep-learning-with-pytorch-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning with PyTorch &lt;a href="https://mybinder.org/v2/gh/Atcold/pytorch-Deep-Learning-Minicourse/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/483bae47a175c24dfbfc57390edd8b6982ac5fb3/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge_logo.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;This notebook repository now has a &lt;a href="https://atcold.github.io/pytorch-Deep-Learning-Minicourse/" rel="nofollow"&gt;companion website&lt;/a&gt;, where all the course mateiral can be found in video and textual format.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting started&lt;/h1&gt;
&lt;p&gt;To be able to follow the exercises, you are going to need a laptop with Miniconda (a minimal version of Anaconda) and several Python packages installed.
The following instruction would work as is for Mac or Ubuntu linux users, Windows users would need to install and work in the Gitbash terminal.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-download-and-install-miniconda" class="anchor" aria-hidden="true" href="#download-and-install-miniconda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Download and install Miniconda&lt;/h2&gt;
&lt;p&gt;Please go to the &lt;a href="https://conda.io/miniconda.html" rel="nofollow"&gt;Anaconda website&lt;/a&gt;.
Download and install &lt;em&gt;the latest&lt;/em&gt; Miniconda version for &lt;em&gt;Python&lt;/em&gt; 3.7 for your operating system.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;wget &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;http:// link to miniconda&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;
sh &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;miniconda&lt;span class="pl-k"&gt;*&lt;/span&gt;.sh&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After that, type:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda --help&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and read the manual.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-check-out-the-git-repository-with-the-exercise" class="anchor" aria-hidden="true" href="#check-out-the-git-repository-with-the-exercise"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Check-out the git repository with the exercise&lt;/h2&gt;
&lt;p&gt;Once Miniconda is ready, checkout the course repository and and proceed with setting up the environment:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/Atcold/pytorch-Deep-Learning-Minicourse&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-create-isolated-miniconda-environment" class="anchor" aria-hidden="true" href="#create-isolated-miniconda-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Create isolated Miniconda environment&lt;/h2&gt;
&lt;p&gt;Change directory (&lt;code&gt;cd&lt;/code&gt;) into the course folder, then type:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; cd pytorch-Deep-Learning-Minicourse&lt;/span&gt;
conda env create -f environment.yml
&lt;span class="pl-c1"&gt;source&lt;/span&gt; activate dl-minicourse&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-start-jupyter-notebook-or-jupyterlab" class="anchor" aria-hidden="true" href="#start-jupyter-notebook-or-jupyterlab"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Start Jupyter notebook or JupyterLab&lt;/h2&gt;
&lt;p&gt;Start from terminal as usual:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;jupyter lab&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or, for the classic interface:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;jupyter notebook&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-notebooks-visualisation" class="anchor" aria-hidden="true" href="#notebooks-visualisation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notebooks visualisation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Jupyter Notebooks&lt;/em&gt; are used throughout these lectures for interactive data exploration and visualisation.&lt;/p&gt;
&lt;p&gt;We use dark styles for both &lt;em&gt;GitHub&lt;/em&gt; and &lt;em&gt;Jupyter Notebook&lt;/em&gt;.
You should try to do the same, or they will look ugly.
JupyterLab has a built-in selectable dark theme, so you only need to install something if you want to use the classic notebook interface.
To see the content appropriately in the classic interface install the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://userstyles.org/styles/153443/jupyter-notebook-dark" rel="nofollow"&gt;&lt;em&gt;Jupyter Notebook&lt;/em&gt; dark theme&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://userstyles.org/styles/37035/github-dark" rel="nofollow"&gt;&lt;em&gt;GitHub&lt;/em&gt; dark theme&lt;/a&gt; and comment out the &lt;code&gt;invert #fff to #181818&lt;/code&gt; code block.&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Atcold</author><guid isPermaLink="false">https://github.com/Atcold/pytorch-Deep-Learning-Minicourse</guid><pubDate>Sun, 09 Feb 2020 00:02:00 GMT</pubDate></item><item><title>CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers #3 in Jupyter Notebook, Today</title><link>https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</link><description>&lt;p&gt;&lt;i&gt;aka "Bayesian Methods for Hackers": An introduction to Bayesian methods + probabilistic programming with a computation/understanding-first, mathematics-second point of view. All in pure Python ;)  &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-bayesian-methods-for-hackers" class="anchor" aria-hidden="true" href="#bayesian-methods-for-hackers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/" rel="nofollow"&gt;Bayesian Methods for Hackers&lt;/a&gt;&lt;/h1&gt;
&lt;h4&gt;&lt;a id="user-content-using-python-and-pymc" class="anchor" aria-hidden="true" href="#using-python-and-pymc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;em&gt;Using Python and PyMC&lt;/em&gt;&lt;/h4&gt;
&lt;p&gt;The Bayesian method is the natural approach to inference, yet it is hidden from readers behind chapters of slow, mathematical analysis. The typical text on Bayesian inference involves two to three chapters on probability theory, then enters what Bayesian inference is. Unfortunately, due to mathematical intractability of most Bayesian models, the reader is only shown simple, artificial examples. This can leave the user with a &lt;em&gt;so-what&lt;/em&gt; feeling about Bayesian inference. In fact, this was the author's own prior opinion.&lt;/p&gt;
&lt;p&gt;After some recent success of Bayesian methods in machine-learning competitions, I decided to investigate the subject again. Even with my mathematical background, it took me three straight-days of reading examples and trying to put the pieces together to understand the methods. There was simply not enough literature bridging theory to practice. The problem with my misunderstanding was the disconnect between Bayesian mathematics and probabilistic programming. That being said, I suffered then so the reader would not have to now. This book attempts to bridge the gap.&lt;/p&gt;
&lt;p&gt;If Bayesian inference is the destination, then mathematical analysis is a particular path towards it. On the other hand, computing power is cheap enough that we can afford to take an alternate route via probabilistic programming. The latter path is much more useful, as it denies the necessity of mathematical intervention at each step, that is, we remove often-intractable mathematical analysis as a prerequisite to Bayesian inference. Simply put, this latter computational path proceeds via small intermediate jumps from beginning to end, where as the first path proceeds by enormous leaps, often landing far away from our target. Furthermore, without a strong mathematical background, the analysis required by the first path cannot even take place.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Bayesian Methods for Hackers&lt;/em&gt; is designed as an introduction to Bayesian inference from a computational/understanding-first, and mathematics-second, point of view. Of course as an introductory book, we can only leave it at that: an introductory book. For the mathematically trained, they may cure the curiosity this text generates with other texts designed with mathematical analysis in mind. For the enthusiast with less mathematical background, or one who is not interested in the mathematics but simply the practice of Bayesian methods, this text should be sufficient and entertaining.&lt;/p&gt;
&lt;p&gt;The choice of PyMC as the probabilistic programming language is two-fold. As of this writing, there is currently no central resource for examples and explanations in the PyMC universe. The official documentation assumes prior knowledge of Bayesian inference and probabilistic programming. We hope this book encourages users at every level to look at PyMC. Secondly, with recent core developments and popularity of the scientific stack in Python, PyMC is likely to become a core component soon enough.&lt;/p&gt;
&lt;p&gt;PyMC does have dependencies to run, namely NumPy and (optionally) SciPy. To not limit the user, the examples in this book will rely only on PyMC, NumPy, SciPy and Matplotlib.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-printed-version-by-addison-wesley" class="anchor" aria-hidden="true" href="#printed-version-by-addison-wesley"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Printed Version by Addison-Wesley&lt;/h2&gt;
&lt;div&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e991336533f43ff762cbf7713516f4215640d402/687474703a2f2f7777772d66702e70656172736f6e68696768657265642e636f6d2f6173736574732f6869702f696d616765732f626967636f766572732f303133333930323833382e6a7067"&gt;&lt;img title="Bayesian Methods for Hackersg" src="https://camo.githubusercontent.com/e991336533f43ff762cbf7713516f4215640d402/687474703a2f2f7777772d66702e70656172736f6e68696768657265642e636f6d2f6173736574732f6869702f696d616765732f626967636f766572732f303133333930323833382e6a7067" align="right" height="200" data-canonical-src="http://www-fp.pearsonhighered.com/assets/hip/images/bigcovers/0133902838.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Bayesian Methods for Hackers is now available as a printed book!&lt;/strong&gt; You can pick up a copy on &lt;a href="http://www.amazon.com/Bayesian-Methods-Hackers-Probabilistic-Addison-Wesley/dp/0133902838" rel="nofollow"&gt;Amazon&lt;/a&gt;. What are the differences between the online version and the printed version?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Additional Chapter on Bayesian A/B testing&lt;/li&gt;
&lt;li&gt;Updated examples&lt;/li&gt;
&lt;li&gt;Answers to the end of chapter questions&lt;/li&gt;
&lt;li&gt;Additional explanation, and rewritten sections to aid the reader.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h2&gt;
&lt;p&gt;See the project homepage &lt;a href="http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/" rel="nofollow"&gt;here&lt;/a&gt; for examples, too.&lt;/p&gt;
&lt;p&gt;The below chapters are rendered via the &lt;em&gt;nbviewer&lt;/em&gt; at
&lt;a href="http://nbviewer.jupyter.org/" rel="nofollow"&gt;nbviewer.jupyter.org/&lt;/a&gt;, and is read-only and rendered in real-time.
Interactive notebooks + examples can be downloaded by cloning!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-pymc2" class="anchor" aria-hidden="true" href="#pymc2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyMC2&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Prologue/Prologue.ipynb" rel="nofollow"&gt;&lt;strong&gt;Prologue:&lt;/strong&gt;&lt;/a&gt; Why we do it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/Ch1_Introduction_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 1: Introduction to Bayesian Methods&lt;/strong&gt;&lt;/a&gt;
Introduction to the philosophy and practice of Bayesian methods and answering the question, "What is probabilistic programming?" Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Inferring human behaviour changes from text message rates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 2: A little more on PyMC&lt;/strong&gt;&lt;/a&gt;
We explore modeling Bayesian problems using Python's PyMC library through examples. How do we create Bayesian models? Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detecting the frequency of cheating students, while avoiding liars&lt;/li&gt;
&lt;li&gt;Calculating probabilities of the Challenger space-shuttle disaster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter3_MCMC/Ch3_IntroMCMC_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 3: Opening the Black Box of MCMC&lt;/strong&gt;&lt;/a&gt;
We discuss how MCMC operates and diagnostic tools. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bayesian clustering with mixture models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter4_TheGreatestTheoremNeverTold/Ch4_LawOfLargeNumbers_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 4: The Greatest Theorem Never Told&lt;/strong&gt;&lt;/a&gt;
We explore an incredibly useful, and dangerous, theorem: The Law of Large Numbers. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Exploring a Kaggle dataset and the pitfalls of naive analysis&lt;/li&gt;
&lt;li&gt;How to sort Reddit comments from best to worst (not as easy as you think)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter5_LossFunctions/Ch5_LossFunctions_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 5: Would you rather lose an arm or a leg?&lt;/strong&gt;&lt;/a&gt;
The introduction of loss functions and their (awesome) use in Bayesian methods.  Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solving the &lt;em&gt;Price is Right&lt;/em&gt;'s Showdown&lt;/li&gt;
&lt;li&gt;Optimizing financial predictions&lt;/li&gt;
&lt;li&gt;Winning solution to the Kaggle Dark World's competition&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter6_Priorities/Ch6_Priors_PyMC2.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 6: Getting our &lt;em&gt;prior&lt;/em&gt;-ities straight&lt;/strong&gt;&lt;/a&gt;
Probably the most important chapter. We draw on expert opinions to answer questions. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multi-Armed Bandits and the Bayesian Bandit solution.&lt;/li&gt;
&lt;li&gt;What is the relationship between data sample size and prior?&lt;/li&gt;
&lt;li&gt;Estimating financial unknowns using expert priors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We explore useful tips to be objective in analysis as well as common pitfalls of priors.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pymc3" class="anchor" aria-hidden="true" href="#pymc3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyMC3&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Prologue/Prologue.ipynb" rel="nofollow"&gt;&lt;strong&gt;Prologue:&lt;/strong&gt;&lt;/a&gt; Why we do it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/Ch1_Introduction_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 1: Introduction to Bayesian Methods&lt;/strong&gt;&lt;/a&gt;
Introduction to the philosophy and practice of Bayesian methods and answering the question, "What is probabilistic programming?" Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Inferring human behaviour changes from text message rates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 2: A little more on PyMC&lt;/strong&gt;&lt;/a&gt;
We explore modeling Bayesian problems using Python's PyMC library through examples. How do we create Bayesian models? Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detecting the frequency of cheating students, while avoiding liars&lt;/li&gt;
&lt;li&gt;Calculating probabilities of the Challenger space-shuttle disaster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter3_MCMC/Ch3_IntroMCMC_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 3: Opening the Black Box of MCMC&lt;/strong&gt;&lt;/a&gt;
We discuss how MCMC operates and diagnostic tools. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bayesian clustering with mixture models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter4_TheGreatestTheoremNeverTold/Ch4_LawOfLargeNumbers_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 4: The Greatest Theorem Never Told&lt;/strong&gt;&lt;/a&gt;
We explore an incredibly useful, and dangerous, theorem: The Law of Large Numbers. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Exploring a Kaggle dataset and the pitfalls of naive analysis&lt;/li&gt;
&lt;li&gt;How to sort Reddit comments from best to worst (not as easy as you think)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter5_LossFunctions/Ch5_LossFunctions_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 5: Would you rather lose an arm or a leg?&lt;/strong&gt;&lt;/a&gt;
The introduction of loss functions and their (awesome) use in Bayesian methods.  Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solving the &lt;em&gt;Price is Right&lt;/em&gt;'s Showdown&lt;/li&gt;
&lt;li&gt;Optimizing financial predictions&lt;/li&gt;
&lt;li&gt;Winning solution to the Kaggle Dark World's competition&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter6_Priorities/Ch6_Priors_PyMC3.ipynb" rel="nofollow"&gt;&lt;strong&gt;Chapter 6: Getting our &lt;em&gt;prior&lt;/em&gt;-ities straight&lt;/strong&gt;&lt;/a&gt;
Probably the most important chapter. We draw on expert opinions to answer questions. Examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multi-Armed Bandits and the Bayesian Bandit solution.&lt;/li&gt;
&lt;li&gt;What is the relationship between data sample size and prior?&lt;/li&gt;
&lt;li&gt;Estimating financial unknowns using expert priors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We explore useful tips to be objective in analysis as well as common pitfalls of priors.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;More questions about PyMC?&lt;/strong&gt;
Please post your modeling, convergence, or any other PyMC question on &lt;a href="http://stats.stackexchange.com/" rel="nofollow"&gt;cross-validated&lt;/a&gt;, the statistics stack-exchange.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-the-book" class="anchor" aria-hidden="true" href="#using-the-book"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using the book&lt;/h2&gt;
&lt;p&gt;The book can be read in three different ways, starting from most recommended to least recommended:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The most recommended option is to clone the repository to download the .ipynb files to your local machine. If you have Jupyter installed, you can view the
chapters in your browser &lt;em&gt;plus&lt;/em&gt; edit and run the code provided (and try some practice questions). This is the preferred option to read
this book, though it comes with some dependencies.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jupyter is a requirement to view the ipynb files. It can be downloaded &lt;a href="http://jupyter.org/" rel="nofollow"&gt;here&lt;/a&gt;. Jupyter notebooks can be run by &lt;code&gt;(your-virtualenv) ~/path/to/the/book/Chapter1_Introduction $ jupyter notebook&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;For Linux users, you should not have a problem installing NumPy, SciPy, Matplotlib and PyMC. For Windows users, check out &lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/" rel="nofollow"&gt;pre-compiled versions&lt;/a&gt; if you have difficulty.&lt;/li&gt;
&lt;li&gt;In the styles/ directory are a number of files (.matplotlirc) that used to make things pretty. These are not only designed for the book, but they offer many improvements over the default settings of matplotlib.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second, preferred, option is to use the nbviewer.jupyter.org site, which display Jupyter notebooks in the browser (&lt;a href="http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/Ch1_Introduction_PyMC2.ipynb" rel="nofollow"&gt;example&lt;/a&gt;).
The contents are updated synchronously as commits are made to the book. You can use the Contents section above to link to the chapters.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PDFs are the least-preferred method to read the book, as PDFs are static and non-interactive. If PDFs are desired, they can be created dynamically using the &lt;a href="https://github.com/jupyter/nbconvert"&gt;nbconvert&lt;/a&gt; utility.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-installation-and-configuration" class="anchor" aria-hidden="true" href="#installation-and-configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation and configuration&lt;/h2&gt;
&lt;p&gt;If you would like to run the Jupyter notebooks locally, (option 1. above), you'll need to install the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Jupyter is a requirement to view the ipynb files. It can be downloaded &lt;a href="http://jupyter.org/install.html" rel="nofollow"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Necessary packages are PyMC, NumPy, SciPy and Matplotlib.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For Linux/OSX users, you should not have a problem installing the above, &lt;a href="http://www.penandpants.com/2012/02/24/install-python/" rel="nofollow"&gt;&lt;em&gt;except for Matplotlib on OSX&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For Windows users, check out &lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/" rel="nofollow"&gt;pre-compiled versions&lt;/a&gt; if you have difficulty.&lt;/li&gt;
&lt;li&gt;also recommended, for data-mining exercises, are &lt;a href="https://github.com/praw-dev/praw"&gt;PRAW&lt;/a&gt; and &lt;a href="https://github.com/kennethreitz/requests"&gt;requests&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;New to Python or Jupyter, and help with the namespaces? Check out &lt;a href="http://stackoverflow.com/questions/12987624/confusion-between-numpy-scipy-matplotlib-and-pylab" rel="nofollow"&gt;this answer&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the styles/ directory are a number of files that are customized for the notebook.
These are not only designed for the book, but they offer many improvements over the
default settings of matplotlib and the Jupyter notebook. The in notebook style has not been finalized yet.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-development" class="anchor" aria-hidden="true" href="#development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development&lt;/h2&gt;
&lt;p&gt;This book has an unusual development design. The content is open-sourced, meaning anyone can be an author.
Authors submit content or revisions using the GitHub interface.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-how-to-contribute" class="anchor" aria-hidden="true" href="#how-to-contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to contribute&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-what-to-contribute" class="anchor" aria-hidden="true" href="#what-to-contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What to contribute?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The current chapter list is not finalized. If you see something that is missing (MCMC, MAP, Bayesian networks, good prior choices, Potential classes etc.),
feel free to start there.&lt;/li&gt;
&lt;li&gt;Cleaning up Python code and making code more PyMC-esque&lt;/li&gt;
&lt;li&gt;Giving better explanations&lt;/li&gt;
&lt;li&gt;Spelling/grammar mistakes&lt;/li&gt;
&lt;li&gt;Suggestions&lt;/li&gt;
&lt;li&gt;Contributing to the Jupyter notebook styles&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-commiting" class="anchor" aria-hidden="true" href="#commiting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Commiting&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;All commits are welcome, even if they are minor ;)&lt;/li&gt;
&lt;li&gt;If you are unfamiliar with Github, you can email me contributions to the email below.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-reviews" class="anchor" aria-hidden="true" href="#reviews"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reviews&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;these are satirical, but real&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;"No, but it looks good" - &lt;a href="https://twitter.com/JohnDCook/status/359672133695184896" rel="nofollow"&gt;John D. Cook&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"I ... read this book ... I like it!" - &lt;a href="http://www.andrewgelman.com/2013/07/21/bayes-related" rel="nofollow"&gt;Andrew Gelman&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"This book is a godsend, and a direct refutation to that 'hmph! you don't know maths, piss off!' school of thought...
The publishing model is so unusual. Not only is it open source but it relies on pull requests from anyone in order to progress the book. This is ingenious and heartening" - &lt;a href="http://www.reddit.com/r/Python/comments/1alnal/probabilistic_programming_and_bayesian_methods/" rel="nofollow"&gt;excited Reddit user&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributions-and-thanks" class="anchor" aria-hidden="true" href="#contributions-and-thanks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributions and Thanks&lt;/h2&gt;
&lt;p&gt;Thanks to all our contributing authors, including (in chronological order):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Authors&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.camdp.com" rel="nofollow"&gt;Cameron Davidson-Pilon&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://stefgibson.com" rel="nofollow"&gt;Stef Gibson&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://bigsnarf.wordpress.com/" rel="nofollow"&gt;Vincent Ohprecio&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/larsman"&gt;Lars Buitinck&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://github.com/pmagwene"&gt;Paul Magwene&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Carreau"&gt;Matthias Bussonnier&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/JensRantil"&gt;Jens Rantil&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/y-p"&gt;y-p&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.etano.net/" rel="nofollow"&gt;Ethan Brown&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://jonathanwhitmore.com/" rel="nofollow"&gt;Jonathan Whitmore&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/matrig"&gt;Mattia Rigotti&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/colibius"&gt;Colby Lemon&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/gustavdelius"&gt;Gustav W Delius&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.mathisonian.com/" rel="nofollow"&gt;Matthew Conlen&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/radford"&gt;Jim Radford&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://baniverso.com/" rel="nofollow"&gt;Vannessa Sabino&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/thomasbratt"&gt;Thomas Bratt&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/nisanharamati"&gt;Nisan Haramati&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/bgrant"&gt;Robert Grant&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/xcthulhu"&gt;Matthew Wampler-Doty&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/yarikoptic"&gt;Yaroslav Halchenko&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/alexgarel"&gt;Alex Garel&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://twitter.com/sash_ko" rel="nofollow"&gt;Oleksandr Lysenko&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/liori"&gt;liori&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/ducky427"&gt;ducky427&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/pablooliveira"&gt;Pablo de Oliveira Castro&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/sergeyfogelson"&gt;sergeyfogelson&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://neurotheory.columbia.edu/~mrigotti/" rel="nofollow"&gt;Mattia Rigotti&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/mbauman"&gt;Matt Bauman&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.andrewduberstein.com/" rel="nofollow"&gt;Andrew Duberstein&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://cebe.cc/" rel="nofollow"&gt;Carsten Brandt&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://web2docx.com" rel="nofollow"&gt;Bob Jansen&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/ugurthemaster"&gt;ugurthemaster&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/williamscott"&gt;William Scott&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://twitter.com/minrk" rel="nofollow"&gt;Min RK&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Bulwersator"&gt;Bulwersator&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/elpres"&gt;elpres&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/hackaugusto"&gt;Augusto Hack&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/michaf"&gt;Michael Feldmann&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Youki"&gt;Youki&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://jensrantil.github.io" rel="nofollow"&gt;Jens Rantil&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kyleam.com" rel="nofollow"&gt;Kyle Meyer&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ericmart.in" rel="nofollow"&gt;Eric Martin&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Inconditus"&gt;Inconditus&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/Kleptine"&gt;Kleptine&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/slayton"&gt;Stuart Layton&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/tritemio"&gt;Antonino Ingargiola&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/vsl9"&gt;vsl9&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/tom-christie"&gt;Tom Christie&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/bclow"&gt;bclow&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://sjp.co.nz/" rel="nofollow"&gt;Simon Potter&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/GarthSnyder"&gt;Garth Snyder&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://twitter.com/pushmatrix" rel="nofollow"&gt;Daniel Beauchamp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.philippsinger.info" rel="nofollow"&gt;Philipp Singer&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/gbenmartin"&gt;gbenmartin&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://twitter.com/Springcoil" rel="nofollow"&gt;Peadar Coyle&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We would like to thank the Python community for building an amazing architecture. We would like to thank the
statistics community for building an amazing architecture.&lt;/p&gt;
&lt;p&gt;Similarly, the book is only possible because of the &lt;a href="http://github.com/pymc-devs/pymc"&gt;PyMC&lt;/a&gt; library. A big thanks to the core devs of PyMC: Chris Fonnesbeck, Anand Patil, David Huard and John Salvatier.&lt;/p&gt;
&lt;p&gt;One final thanks. This book was generated by Jupyter Notebook, a wonderful tool for developing in Python. We thank the IPython/Jupyter
community for developing the Notebook interface. All Jupyter notebook files are available for download on the GitHub repository.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h4&gt;
&lt;p&gt;Contact the main author, Cam Davidson-Pilon at &lt;a href="mailto:cam.davidson.pilon@gmail.com"&gt;cam.davidson.pilon@gmail.com&lt;/a&gt; or &lt;a href="https://twitter.com/cmrn_dp" rel="nofollow"&gt;@cmrndp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/090a62cab61c2a7115a3d8f4f99bffe5f1c75a26/687474703a2f2f692e696d6775722e636f6d2f5a623739515a622e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/090a62cab61c2a7115a3d8f4f99bffe5f1c75a26/687474703a2f2f692e696d6775722e636f6d2f5a623739515a622e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/Zb79QZb.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>CamDavidsonPilon</author><guid isPermaLink="false">https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</guid><pubDate>Sun, 09 Feb 2020 00:03:00 GMT</pubDate></item><item><title>ageron/handson-ml #4 in Jupyter Notebook, Today</title><link>https://github.com/ageron/handson-ml</link><description>&lt;p&gt;&lt;i&gt;A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-notebooks" class="anchor" aria-hidden="true" href="#machine-learning-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning Notebooks&lt;/h1&gt;
&lt;p&gt;This project aims at teaching you the fundamentals of Machine Learning in
python. It contains the example code and solutions to the exercises in my O'Reilly book &lt;a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781491962282/" rel="nofollow"&gt;Hands-on Machine Learning with Scikit-Learn and TensorFlow&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781491962282/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8e10a44b0ddbb9530cc27d877f06db68d9fa1c7d/687474703a2f2f616b616d6169636f766572732e6f7265696c6c792e636f6d2f696d616765732f393738313439313936323238322f6361742e676966" alt="book" data-canonical-src="http://akamaicovers.oreilly.com/images/9781491962282/cat.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Simply open the &lt;a href="http://jupyter.org/" rel="nofollow"&gt;Jupyter&lt;/a&gt; notebooks you are interested in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using &lt;a href="http://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/index.ipynb" rel="nofollow"&gt;jupyter.org's notebook viewer&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;note: &lt;a href="https://github.com/ageron/handson-ml/blob/master/index.ipynb"&gt;github.com's notebook viewer&lt;/a&gt; also works but it is slower and the math formulas are not displayed correctly,&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;by cloning this repository and running Jupyter locally. This option lets you play around with the code. In this case, follow the installation instructions below,&lt;/li&gt;
&lt;li&gt;or by running the notebooks in &lt;a href="https://beta.deepnote.com" rel="nofollow"&gt;Deepnote&lt;/a&gt;. This allows you to play around with the code online in your browser. For example, here's a link to the first chapter: &lt;a href="https://beta.deepnote.com/launch?template=data-science&amp;amp;url=https%3A//github.com/ageron/handson-ml/blob/master/02_end_to_end_machine_learning_project.ipynb" rel="nofollow"&gt;&lt;img height="22" src="https://camo.githubusercontent.com/c3b9bd12a99f8de3301018192105256209bcf800/68747470733a2f2f626574612e646565706e6f74652e636f6d2f627574746f6e732f6c61756e63682d696e2d646565706e6f74652e737667" data-canonical-src="https://beta.deepnote.com/buttons/launch-in-deepnote.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h1&gt;
&lt;p&gt;First, you will need to install &lt;a href="https://git-scm.com/" rel="nofollow"&gt;git&lt;/a&gt;, if you don't have it already.&lt;/p&gt;
&lt;p&gt;Next, clone this repository by opening a terminal and typing the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd $HOME  # or any other development directory you prefer
$ git clone https://github.com/ageron/handson-ml.git
$ cd handson-ml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you do not want to install git, you can instead download &lt;a href="https://github.com/ageron/handson-ml/archive/master.zip"&gt;master.zip&lt;/a&gt;, unzip it, rename the resulting directory to &lt;code&gt;handson-ml&lt;/code&gt; and move it to your development directory.&lt;/p&gt;
&lt;p&gt;If you want to go through chapter 16 on Reinforcement Learning, you will need to &lt;a href="https://gym.openai.com/docs" rel="nofollow"&gt;install OpenAI gym&lt;/a&gt; and its dependencies for Atari simulations.&lt;/p&gt;
&lt;p&gt;If you are familiar with Python and you know how to install Python libraries, go ahead and install the libraries listed in &lt;code&gt;requirements.txt&lt;/code&gt; and jump to the &lt;a href="#starting-jupyter"&gt;Starting Jupyter&lt;/a&gt; section. If you need detailed instructions, please read on.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-python--required-libraries" class="anchor" aria-hidden="true" href="#python--required-libraries"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python &amp;amp; Required Libraries&lt;/h2&gt;
&lt;p&gt;Of course, you obviously need Python. Python 3 is already preinstalled on many systems nowadays. You can check which version you have by typing the following command (you may need to replace &lt;code&gt;python3&lt;/code&gt; with &lt;code&gt;python&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 --version  # for Python 3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Any Python 3 version should be fine, preferably 3.5 or above. If you don't have Python 3, I recommend installing it. To do so, you have several options: on Windows or MacOSX, you can just download it from &lt;a href="https://www.python.org/downloads/" rel="nofollow"&gt;python.org&lt;/a&gt;. On MacOSX, you can alternatively use &lt;a href="https://www.macports.org/" rel="nofollow"&gt;MacPorts&lt;/a&gt; or &lt;a href="https://brew.sh/" rel="nofollow"&gt;Homebrew&lt;/a&gt;. If you are using Python 3.6 on MacOSX, you need to run the following command to install the &lt;code&gt;certifi&lt;/code&gt; package of certificates because Python 3.6 on MacOSX has no certificates to validate SSL connections (see this &lt;a href="https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error" rel="nofollow"&gt;StackOverflow question&lt;/a&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ /Applications/Python\ 3.6/Install\ Certificates.command
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On Linux, unless you know what you are doing, you should use your system's packaging system. For example, on Debian or Ubuntu, type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt-get update
$ sudo apt-get install python3 python3-pip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another option is to download and install &lt;a href="https://www.continuum.io/downloads" rel="nofollow"&gt;Anaconda&lt;/a&gt;. This is a package that includes both Python and many scientific libraries. You should prefer the Python 3 version.&lt;/p&gt;
&lt;p&gt;If you choose to use Anaconda, read the next section, or else jump to the &lt;a href="#using-pip"&gt;Using pip&lt;/a&gt; section.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-anaconda" class="anchor" aria-hidden="true" href="#using-anaconda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using Anaconda&lt;/h2&gt;
&lt;p&gt;Once you have &lt;a href="https://docs.anaconda.com/anaconda/install/" rel="nofollow"&gt;installed Anaconda&lt;/a&gt; (or Miniconda), you can run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda env create -f environment.yml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will give you a conda environment named &lt;code&gt;mlbook&lt;/code&gt;, ready to use! Just activate it and you will have everything setup
for you:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda activate mlbook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You are all set! Next, jump to the &lt;a href="#starting-jupyter"&gt;Starting Jupyter&lt;/a&gt; section.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-pip" class="anchor" aria-hidden="true" href="#using-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using pip&lt;/h2&gt;
&lt;p&gt;If you are not using Anaconda, you need to install several scientific Python libraries that are necessary for this project, in particular NumPy, Matplotlib, Pandas, Jupyter and TensorFlow (and a few others). For this, you can either use Python's integrated packaging system, pip, or you may prefer to use your system's own packaging system (if available, e.g. on Linux, or on MacOSX when using MacPorts or Homebrew). The advantage of using pip is that it is easy to create multiple isolated Python environments with different libraries and different library versions (e.g. one environment for each project). The advantage of using your system's packaging system is that there is less risk of having conflicts between your Python libraries and your system's other packages. Since I have many projects with different library requirements, I prefer to use pip with isolated environments. Moreover, the pip packages are usually the most recent ones available, while Anaconda and system packages often lag behind a bit.&lt;/p&gt;
&lt;p&gt;These are the commands you need to type in a terminal if you want to use pip to install the required libraries. Note: in all the following commands, if you chose to use Python 2 rather than Python 3, you must replace &lt;code&gt;pip3&lt;/code&gt; with &lt;code&gt;pip&lt;/code&gt;, and &lt;code&gt;python3&lt;/code&gt; with &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First you need to make sure you have the latest version of pip installed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --user --upgrade pip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;--user&lt;/code&gt; option will install the latest version of pip only for the current user. If you prefer to install it system wide (i.e. for all users), you must have administrator rights (e.g. use &lt;code&gt;sudo python3&lt;/code&gt; instead of &lt;code&gt;python3&lt;/code&gt; on Linux), and you should remove the &lt;code&gt;--user&lt;/code&gt; option. The same is true of the command below that uses the &lt;code&gt;--user&lt;/code&gt; option.&lt;/p&gt;
&lt;p&gt;Next, you can optionally create an isolated environment. This is recommended as it makes it possible to have a different environment for each project (e.g. one for this project), with potentially very different libraries, and different versions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --user --upgrade virtualenv
$ python3 -m virtualenv -p `which python3` env
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates a new directory called &lt;code&gt;env&lt;/code&gt; in the current directory, containing an isolated Python environment based on Python 3. If you installed multiple versions of Python 3 on your system, you can replace &lt;code&gt;`which python3`&lt;/code&gt; with the path to the Python executable you prefer to use.&lt;/p&gt;
&lt;p&gt;Now you must activate this environment. You will need to run this command every time you want to use this environment.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ source ./env/bin/activate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On Windows, the command is slightly different:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ .\env\Scripts\activate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, use pip to install the required python packages. If you are not using virtualenv, you should add the &lt;code&gt;--user&lt;/code&gt; option (alternatively you could install the libraries system-wide, but this will probably require administrator rights, e.g. using &lt;code&gt;sudo pip3&lt;/code&gt; instead of &lt;code&gt;pip3&lt;/code&gt; on Linux).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --upgrade -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great! You're all set, you just need to start Jupyter now.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-starting-jupyter" class="anchor" aria-hidden="true" href="#starting-jupyter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Starting Jupyter&lt;/h2&gt;
&lt;p&gt;Okay! You can now start Jupyter, simply type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This should open up your browser, and you should see Jupyter's tree view, with the contents of the current directory. If your browser does not open automatically, visit &lt;a href="http://127.0.0.1:8888/tree" rel="nofollow"&gt;127.0.0.1:8888&lt;/a&gt;. Click on &lt;code&gt;index.ipynb&lt;/code&gt; to get started!&lt;/p&gt;
&lt;p&gt;Congrats! You are ready to learn Machine Learning, hands on!&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributors&lt;/h1&gt;
&lt;p&gt;I would like to thank everyone who contributed to this project, either by providing useful feedback, filing issues or submitting Pull Requests. Special thanks go to Steven Bunkley and Ziembla who created the &lt;code&gt;docker&lt;/code&gt; directory.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ageron</author><guid isPermaLink="false">https://github.com/ageron/handson-ml</guid><pubDate>Sun, 09 Feb 2020 00:04:00 GMT</pubDate></item><item><title>snowkylin/tensorflow-handbook #5 in Jupyter Notebook, Today</title><link>https://github.com/snowkylin/tensorflow-handbook</link><description>&lt;p&gt;&lt;i&gt;ç®€å•ç²—æš´ TensorFlow 2.0 | A Concise Handbook of TensorFlow 2.0&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="readme.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-ç®€å•ç²—æš´tensorflow-20--a-concise-handbook-of-tensorflow-20" class="anchor" aria-hidden="true" href="#ç®€å•ç²—æš´tensorflow-20--a-concise-handbook-of-tensorflow-20"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ç®€å•ç²—æš´TensorFlow 2.0 | A Concise Handbook of TensorFlow 2.0&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;åŸºäºEager Execution | Based on Eager Execution&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;åœ¨çº¿é˜…è¯» | Read online : &lt;a href="https://tf.wiki" rel="nofollow"&gt;https://tf.wiki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;å¤‡ç”¨åœ°å€ | Alternative URLï¼š&lt;a href="https://snowkylin.github.io/tensorflow-handbook/" rel="nofollow"&gt;https://snowkylin.github.io/tensorflow-handbook/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ä½œè€… | Author: Xihan Li (snowkylin), Huan Li, Jinpeng Zhu&lt;/p&gt;
&lt;p&gt;æœ¬æ‰‹å†Œæ˜¯ä¸€ç¯‡ç²¾ç®€çš„TensorFlow 2.0å…¥é—¨æŒ‡å¯¼ï¼ŒåŸºäºTensorFlowçš„Eager Executionï¼ˆåŠ¨æ€å›¾ï¼‰æ¨¡å¼ï¼ŒåŠ›å›¾è®©å…·å¤‡ä¸€å®šæœºå™¨å­¦ä¹ åŠPythonåŸºç¡€çš„å¼€å‘è€…ä»¬å¿«é€Ÿä¸Šæ‰‹TensorFlow 2.0ã€‚&lt;/p&gt;
&lt;p&gt;æœ¬æ–‡çš„æ‰€æœ‰ä»£ç åŸºäºTensorFlow 2.0 beta1ç‰ˆæœ¬ã€‚&lt;/p&gt;
&lt;p&gt;This handbook is a concise introduction to TensorFlow 2.0 based on Eager Execution mode, trying to help developers with some basic machine learning and Python knowledge to get started with TensorFlow 2.0 quickly.&lt;/p&gt;
&lt;p&gt;The code of this handbook is based on TensorFlow 2.0 beta1.&lt;/p&gt;
&lt;p&gt;PDFä¸‹è½½ï¼ˆæ—§ç‰ˆï¼‰ | PDF download (old version) :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(ä¸­æ–‡ç‰ˆ | Chinese): &lt;a href="https://www.tensorflowers.cn/t/6230" rel="nofollow"&gt;https://www.tensorflowers.cn/t/6230&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;(è‹±æ–‡ç‰ˆ | English): &lt;a href="https://github.com/snowkylin/tensorflow-handbook/releases"&gt;https://github.com/snowkylin/tensorflow-handbook/releases&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;åœ¨çº¿ç­”ç–‘åŒº | Online Q&amp;amp;A area :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(ä¸­æ–‡ | Chinese): &lt;a href="https://www.tensorflowers.cn/b/48" rel="nofollow"&gt;https://www.tensorflowers.cn/b/48&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;(è‹±æ–‡ | English): &lt;a href="https://github.com/snowkylin/tensorflow-handbook/issues"&gt;https://github.com/snowkylin/tensorflow-handbook/issues&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-developing" class="anchor" aria-hidden="true" href="#developing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DEVELOPING&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-install" class="anchor" aria-hidden="true" href="#install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;run &lt;code&gt;make install&lt;/code&gt; for run all the follow commands.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; https://www.ibm.com/developerworks/cn/opensource/os-sphinx-documentation/index.html&lt;/span&gt;
pip install sphinx

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; for theme&lt;/span&gt;
pip install sphinx_rtd_theme

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; for auto build&lt;/span&gt;
pip install sphinx_autobuild&lt;/pre&gt;&lt;/div&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>snowkylin</author><guid isPermaLink="false">https://github.com/snowkylin/tensorflow-handbook</guid><pubDate>Sun, 09 Feb 2020 00:05:00 GMT</pubDate></item><item><title>mitmath/18330 #6 in Jupyter Notebook, Today</title><link>https://github.com/mitmath/18330</link><description>&lt;p&gt;&lt;i&gt;18.330 Intro to Numerical Analysis&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-18330-introduction-to-numerical-analysis" class="anchor" aria-hidden="true" href="#18330-introduction-to-numerical-analysis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;18.330: Introduction to numerical analysis&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-spring-2020" class="anchor" aria-hidden="true" href="#spring-2020"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spring 2020&lt;/h2&gt;
&lt;p&gt;Welcome to 18.330! This is an introductory course on numerical analysis.&lt;/p&gt;
&lt;p&gt;We will be using the &lt;a href="www.julialang.org"&gt;Julia language&lt;/a&gt;. Please follow &lt;a href="installation.md"&gt;these installation instructions&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-logistics" class="anchor" aria-hidden="true" href="#logistics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Logistics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Visiting professor David P. Sanders (&lt;a href="mailto:sandersd@mit.edu"&gt;sandersd@mit.edu&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MWF 1--2, room 2-139.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Office hours: MW 5-6 in the &lt;strong&gt;Julia lab&lt;/strong&gt;, 7th floor of Stata Center (turn left from Gates building elevator)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Piazza forum: &lt;a href="https://piazza.com/class/k65ke8eo9x760n" rel="nofollow"&gt;https://piazza.com/class/k65ke8eo9x760n&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-slides-notebooks-and-recordings-from-lectures" class="anchor" aria-hidden="true" href="#slides-notebooks-and-recordings-from-lectures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Slides, notebooks and recordings from lectures&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slides and notebooks for each lecture are available in the &lt;a href="lectures"&gt;lectures&lt;/a&gt; directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Screen recordings of lectures are available &lt;a href="https://www.dropbox.com/sh/ubkqwrqxnukgllc/AAA2cH9r7YQL7WmYVt-bblxta?dl=0" rel="nofollow"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Summaries of each lecture are &lt;a href="summaries.md"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-evaluation" class="anchor" aria-hidden="true" href="#evaluation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Evaluation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;10 problem sets (50%). No late submissions, but the lowest score will be dropped.&lt;/li&gt;
&lt;li&gt;1 midterm exam (20%): Wednesday, March 18&lt;/li&gt;
&lt;li&gt;Final project (30%): Due Monday, May 11&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Problem sets will consist of a mixture of theory and coding. They will be submitted and graded online.&lt;/p&gt;
&lt;p&gt;The final project will be an exploration of a topic in numerical analysis that we have not covered in class (although at the level of the class), and will include a discussion of the mathematics behind the method, together with your own implementation.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-learning-julia" class="anchor" aria-hidden="true" href="#learning-julia"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learning Julia&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Prof. Steven Johnson will give an introduction to Julia on Friday, Feb 7 from 5-7pm in 32-141. Make sure to install Julia beforehand. See &lt;a href="https://github.com/mitmath/julia-mit"&gt;https://github.com/mitmath/julia-mit&lt;/a&gt; for information and resources on Julia.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For help with Julia you should be able to find people in the Julia lab most of the time (see above for directions)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;More learning resources are available at &lt;a href="https://julialang.org/learning/" rel="nofollow"&gt;https://julialang.org/learning/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-windows-users" class="anchor" aria-hidden="true" href="#windows-users"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Windows users&lt;/h3&gt;
&lt;p&gt;If you use Windows, please download Git for Windows &lt;a href="https://gitforwindows.org" rel="nofollow"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-getting-the-files" class="anchor" aria-hidden="true" href="#getting-the-files"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting the files&lt;/h3&gt;
&lt;p&gt;To get the files, use &lt;code&gt;git&lt;/code&gt; from the command line (or from a GUI), as follows&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Clone the repository once with&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/mitmath/18330
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will create a new directory called &lt;code&gt;18330&lt;/code&gt; with the matierials.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Update it to pull in new changes each time with&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;git pull
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This needs to be executed from within the directory. (Use &lt;code&gt;cd&lt;/code&gt; to change directory.)&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-syllabus" class="anchor" aria-hidden="true" href="#syllabus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Syllabus&lt;/h3&gt;
&lt;p&gt;See &lt;a href="syllabus.md"&gt;here&lt;/a&gt; for the approximate course syllabus.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>mitmath</author><guid isPermaLink="false">https://github.com/mitmath/18330</guid><pubDate>Sun, 09 Feb 2020 00:06:00 GMT</pubDate></item><item><title>mitmath/18335 #7 in Jupyter Notebook, Today</title><link>https://github.com/mitmath/18335</link><description>&lt;p&gt;&lt;i&gt;18.335 - Introduction to Numerical Methods course&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-18335j6337j-introduction-to-numerical-methods" class="anchor" aria-hidden="true" href="#18335j6337j-introduction-to-numerical-methods"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;18.335J/6.337J: Introduction to Numerical Methods&lt;/h1&gt;
&lt;p&gt;This is the repository of course materials for the 18.335J/6.337J course at MIT, taught by Prof. &lt;a href="http://math.mit.edu/~stevenj/" rel="nofollow"&gt;Steven G. Johnson&lt;/a&gt;, in Spring 2020.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-syllabus" class="anchor" aria-hidden="true" href="#syllabus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Syllabus&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Lectures&lt;/strong&gt;: Monday/Wednesday/Friday 3â€“4pm (2-190). &lt;strong&gt;Office Hours:&lt;/strong&gt; Thursday 4â€“5pm (2-345).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Topics&lt;/strong&gt;: Advanced introduction to numerical linear algebra and related numerical methods. Topics include direct and iterative methods for linear systems, eigenvalue decompositions and QR/SVD factorizations, stability and accuracy of numerical algorithms, the IEEE floating-point standard, sparse and structured matrices, and linear algebra software. Other topics may include memory hierarchies and the impact of caches on algorithms, nonlinear optimization, numerical integration, FFTs, and sensitivity analysis. Problem sets will involve use of &lt;a href="http://julialang.org/" rel="nofollow"&gt;Julia&lt;/a&gt;, a Matlab-like environment (little or no prior experience required; you will learn as you go).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;: Understanding of linear algebra (&lt;a href="http://web.mit.edu/18.06/www/" rel="nofollow"&gt;18.06&lt;/a&gt;, &lt;a href="http://ocw.mit.edu/OcwWeb/Mathematics/18-700Fall-2005/CourseHome/" rel="nofollow"&gt;18.700&lt;/a&gt;, or equivalents). 18.335 is a graduate-level subject, however, so much more mathematical maturity, ability to deal with abstractions and proofs, and general exposure to mathematics is assumed than for 18.06!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Textbook&lt;/strong&gt;: The primary textbook for the course is &lt;a href="http://www.amazon.com/Numerical-Linear-Algebra-Lloyd-Trefethen/dp/0898713617" rel="nofollow"&gt;&lt;em&gt;Numerical Linear Algebra&lt;/em&gt; by Trefethen and Bau&lt;/a&gt;. (&lt;a href="http://owens.mit.edu/sfx_local?bookid=9436&amp;amp;rft.genre=book&amp;amp;sid=Barton:Books24x7" rel="nofollow"&gt;Readable online&lt;/a&gt; with MIT certificates.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Other Reading&lt;/strong&gt;: Previous terms can be found in &lt;a href="https://github.com/mitmath/18335/branches"&gt;branches of the 18335 git repository&lt;/a&gt;. The &lt;a href="https://ocw.mit.edu/courses/mathematics/18-335j-introduction-to-numerical-methods-fall-2010/" rel="nofollow"&gt;course notes from 18.335 in much earlier terms&lt;/a&gt; can be found on OpenCourseWare. For a review of iterative methods, the online books &lt;a href="http://www.netlib.org/linalg/html_templates/Templates.html" rel="nofollow"&gt;Templates for the Solution of Linear Systems&lt;/a&gt; (Barrett et al.) and &lt;a href="http://www.cs.utk.edu/~dongarra/etemplates/book.html" rel="nofollow"&gt;Templates for the Solution of Algebraic Eigenvalue Problems&lt;/a&gt; are useful surveys.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Grading&lt;/strong&gt;: 33% problem sets (about six, ~biweekly). 33% &lt;strong&gt;take-home mid-term exam&lt;/strong&gt; (posted Monday &lt;strong&gt;Apr. 6&lt;/strong&gt; and due Tuesday &lt;strong&gt;Apr. 7&lt;/strong&gt;), 34% &lt;strong&gt;final project&lt;/strong&gt; (&lt;a href="psets/proposal.md"&gt;one-page proposal&lt;/a&gt; due Friday March 20, project due Tuesday &lt;strong&gt;May 12&lt;/strong&gt;).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Psets will be &lt;a href="https://learning-modules.mit.edu/gradebook/index.html?uuid=/course/18/sp20/18.335" rel="nofollow"&gt;submitted electronically via Stellar&lt;/a&gt;.  Submit a good-quality PDF &lt;em&gt;scan&lt;/em&gt; of any handwritten solutions and &lt;em&gt;also&lt;/em&gt; a PDF &lt;em&gt;printout&lt;/em&gt; of a Julia notebook of your computational solutions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;TA/grader:&lt;/strong&gt; &lt;a href="http://math.mit.edu/directory/profile.php?pid=1714" rel="nofollow"&gt;Jacob Gold&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Collaboration policy&lt;/strong&gt;: Talk to anyone you want to and read anything you want to, with three exceptions: First, you &lt;strong&gt;may not refer to homework solutions from the previous terms&lt;/strong&gt; in which I taught 18.335. Second, make a solid effort to solve a problem on your own before discussing it with classmates or googling. Third, no matter whom you talk to or what you read, write up the solution on your own, without having their answer in front of you.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Final Projects&lt;/strong&gt;: The final project will be a 8â€“15 page paper (single-column, single-spaced, ideally using the style template from the &lt;a href="http://www.siam.org/journals/auth-info.php" rel="nofollow"&gt;&lt;em&gt;SIAM Journal on Numerical Analysis&lt;/em&gt;&lt;/a&gt;), reviewing some interesting numerical algorithm not covered in the course. [Since this is not a numerical PDE course, the algorithm should &lt;em&gt;not&lt;/em&gt; be an algorithm for turning PDEs into finite/discretized systems; however, your project &lt;em&gt;may&lt;/em&gt; take a PDE discretization as a given "black box" and look at some other aspect of the problem, e.g. iterative solvers.] Your paper should be written for an audience of your peers in the class, and should include example numerical results (by you) from application to a realistic problem (small-scale is fine), discussion of accuracy and performance characteristics (both theoretical and experimental), and a fair comparison to at &lt;strong&gt;least one competing algorithm&lt;/strong&gt; for the same problem. Like any review paper, you should &lt;em&gt;thoroughly reference&lt;/em&gt; the published literature (citing both original articles and authoritative reviews/books where appropriate [rarely web pages]), tracing the historical development of the ideas and giving the reader pointers on where to go for more information and related work and later refinements, with references cited throughout the text (enough to make it clear what references go with what results). (&lt;strong&gt;Note:&lt;/strong&gt; you may re-use diagrams from other sources, but all such usage must be &lt;em&gt;explicitly credited&lt;/em&gt;; not doing so is &lt;a href="http://writing.mit.edu/wcc/avoidingplagiarism" rel="nofollow"&gt;plagiarism&lt;/a&gt;.) Model your paper on academic review articles (e.g. read &lt;em&gt;SIAM Review&lt;/em&gt; and similar journals for examples).&lt;/p&gt;
&lt;p&gt;A good final project will include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;An extensive introduction and bibliography putting the algorithm in context.  Where did it come from, and what motivated its development?  Where is it commonly used (if anywhere)?  What are the main competing algorithms?  Were any variants of the algorithm proposed later?  What do other authors say about it?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A clear description of the algorithm, with a summary of its derivation and key properties.   Don't copy long mathematical derivations or proofs from other sources, but do &lt;em&gt;summarize&lt;/em&gt; the key ideas and results in the literature.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A convincing validation on a representative/quasi-realistic test problem (i.e. show that your code works), along with an informative comparison to important competing algorithms.  For someone who is thinking about using the algorithm, you should strive to give them &lt;em&gt;useful&lt;/em&gt; guidance on how the algorithm compares to competing algorithms: when/where should you consider using it (if ever)?   Almost never rely on actual timing results â€” see below!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Frequently asked questions about the final project:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Does it have to be about numerical linear algebra?&lt;/em&gt; No. It can be any numerical topic (basically, anything where you are computing a conceptually real result, not integer computations), excluding algorithms for discretizing PDEs.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Can I use a matrix from a discretized PDE?&lt;/em&gt; Yes. You can take a matrix from the PDE as input and then talk about iterative methods to solve it, etcetera. I just don't want the paper to be about the PDE discretization technique itself.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;How formal is the proposal?&lt;/em&gt; Very informalâ€”one page describing what you plan to do, with a couple of references that you are using as starting points. Basically, the proposal is just so that I can verify that what you are planning is reasonable and to give you some early feedback.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;How much code do I need to write?&lt;/em&gt; A typical project (there may be exceptions) will include a working proof-of-concept implementation, e.g. in Julia or Python or Matlab, that you wrote to demonstrate that you understand how the algorithm works. Your code does &lt;em&gt;not&lt;/em&gt; have to be competitive with "serious" implementations, and I encourage you to download and try out existing "serious" implementations (where available) for any large-scale testing and comparisons.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;How should I do performance comparisons?&lt;/em&gt; Be very cautious about timing measurements: unless you are measuring highly optimized code or only care about orders of magnitude, timing measurements are more about implementation quality than algorithms. Better to &lt;em&gt;measure something implementation-independent&lt;/em&gt; (like flop counts, or matrix-vector multiplies for iterative algorithms, or function evaluations for integrators/optimizers), even though such measures have their own weaknesses.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-lecture-summaries-and-handouts" class="anchor" aria-hidden="true" href="#lecture-summaries-and-handouts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lecture Summaries and Handouts&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-lecture-1-feb-3" class="anchor" aria-hidden="true" href="#lecture-1-feb-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lecture 1 (Feb 3)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="psets/pset1.pdf"&gt;pset 1&lt;/a&gt; and accompanying &lt;a href="https://nbviewer.jupyter.org/github/mitmath/18335/blob/master/psets/pset1.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;, due Friday Feb. 14.&lt;/li&gt;
&lt;li&gt;&lt;a href="notes/newton-sqrt.pdf"&gt;Newton's method for square roots&lt;/a&gt; and accompanying &lt;a href="https://nbviewer.jupyter.org/github/mitmath/18335/blob/master/notes/Newton-Square-Roots.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Brief overview of the huge field of numerical methods, and outline of the small portion that this course will cover. Key new concerns in numerical analysis, which don't appear in more abstract mathematics, are (i) performance (traditionally, arithmetic counts, but now memory access often dominates) and (ii) accuracy (both floating-point roundoff errors and also convergence of intrinsic approximations in the algorithms).&lt;/p&gt;
&lt;p&gt;As a starting example, considered the convergence of Newton's method (as applied to square roots); see the handout and Julia notebook above.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Further reading:&lt;/strong&gt; Googling "Newton's method" will find lots of references; as usual, the &lt;a href="https://en.wikipedia.org/wiki/Newton's_method" rel="nofollow"&gt;Wikipedia article on Newton's method&lt;/a&gt; is a reasonable starting point. Beware that the terminology for the &lt;a href="https://en.wikipedia.org/wiki/Rate_of_convergence" rel="nofollow"&gt;convergence order&lt;/a&gt; (linear, quadratic, etc.) is somewhat different in this context from the terminology for discretization schemes (first-order, second-order, etc.); see e.g. the linked Wikipedia article. Homer Reid's &lt;a href="http://homerreid.dyndns.org/teaching/18.330/Notes/RootFinding.pdf" rel="nofollow"&gt;notes on machine arithmetic&lt;/a&gt; for &lt;a href="http://homerreid.dyndns.org/teaching/18.330/" rel="nofollow"&gt;18.330&lt;/a&gt; are an excellent introduction that covers several applications and algorithms for root-finding. For numerical computation in 18.335, we will be using the Julia language: see this &lt;a href="https://github.com/mitmath/julia-mit"&gt;information on Julia at MIT&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-lecture-2-feb-5" class="anchor" aria-hidden="true" href="#lecture-2-feb-5"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lecture 2 (Feb 5)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="notes/lec8handout6pp.pdf"&gt;notes on floating-point&lt;/a&gt; (18.335 Fall 2007; also &lt;a href="notes/lec8.pdf"&gt;slides&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Julia &lt;a href="https://nbviewer.jupyter.org/github/mitmath/18335/blob/master/notes/Floating-Point-Intro.ipynb" rel="nofollow"&gt;floating-point notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;some &lt;a href="notes/fp-myths.pdf"&gt;floating-point myths&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;New topic: &lt;strong&gt;Floating-point arithmetic&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The basic issue is that, for computer arithmetic to be fast, it has to be done in hardware, operating on numbers stored in a fixed, finite number of digits (bits). As a consequence, only a &lt;em&gt;finite subset&lt;/em&gt; of the real numbers can be represented, and the question becomes &lt;em&gt;which subset&lt;/em&gt; to store, how arithmetic on this subset is defined, and how to analyze the errors compared to theoretical exact arithmetic on real numbers.&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;floating-point&lt;/strong&gt; arithmetic, we store both an integer coefficient and an exponent in some base: essentially, scientific notation. This allows large dynamic range and fixed &lt;em&gt;relative&lt;/em&gt; accuracy: if fl(x) is the closest floating-point number to any real x, then |fl(x)-x| &amp;lt; Îµ|x| where Îµ is the &lt;em&gt;machine precision&lt;/em&gt;. This makes error analysis much easier and makes algorithms mostly insensitive to overall scaling or units, but has the disadvantage that it requires specialized floating-point hardware to be fast. Nowadays, all general-purpose computers, and even many little computers like your cell phones, have floating-point units.&lt;/p&gt;
&lt;p&gt;Overview of &lt;strong&gt;floating-point&lt;/strong&gt; representations, focusing on the IEEE 754 standard (see also handout from previous lecture). The key point is that the nearest floating-point number to &lt;em&gt;x&lt;/em&gt;, denoted fl(&lt;em&gt;x&lt;/em&gt;), has the property of &lt;em&gt;uniform relative precision&lt;/em&gt; (for |&lt;em&gt;x&lt;/em&gt;| and 1/|&lt;em&gt;x&lt;/em&gt;| &amp;lt; than some &lt;em&gt;range&lt;/em&gt;, â‰ˆ10Â³â°â° for double precision) that |fl(&lt;em&gt;x&lt;/em&gt;)âˆ’_x_|Â â‰¤Â Îµmachine|&lt;em&gt;x&lt;/em&gt;|, where Îµmachine is the relative "machine precision" (about 10â»Â¹â¶ for double precision). There are also a few special values: Â±Inf (e.g. for &lt;a href="https://en.wikipedia.org/wiki/Arithmetic_overflow" rel="nofollow"&gt;overflow&lt;/a&gt;), &lt;a href="https://en.wikipedia.org/wiki/NaN" rel="nofollow"&gt;NaN&lt;/a&gt;, and Â±0 (e.g. for &lt;a href="https://en.wikipedia.org/wiki/Arithmetic_underflow" rel="nofollow"&gt;underflow&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Went through some simple examples in Julia (see notebook above), illustrating basic syntax and a few interesting tidbits.  In particular, we looked at two examples of &lt;a href="https://en.wikipedia.org/wiki/Loss_of_significance" rel="nofollow"&gt;catastrophic cancellation&lt;/a&gt; and how it can sometimes be avoided by rearranging a calculation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Further reading:&lt;/strong&gt; Trefethen, lecture 13. &lt;a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.6768" rel="nofollow"&gt;What Every Computer Scientist Should Know About Floating Point Arithmetic&lt;/a&gt; (David Goldberg, ACM 1991). William Kahan, &lt;a href="http://www.cs.berkeley.edu/~wkahan/JAVAhurt.pdf" rel="nofollow"&gt;How Java's floating-point hurts everyone everywhere&lt;/a&gt; (2004): contains a nice discussion of floating-point myths and misconceptions.   A brief but useful summary can be found in &lt;a href="https://discourse.julialang.org/t/psa-floating-point-arithmetic/8678" rel="nofollow"&gt;this Julia-focused floating-point overview&lt;/a&gt; by Prof. John Gibson.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-lecture-3-feb-7" class="anchor" aria-hidden="true" href="#lecture-3-feb-7"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lecture 3 (Feb 7)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;notes on the accuracy and stability of &lt;a href="notes/naivesum.pdf"&gt;floating-point summation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Summation, accuracy, and stability.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Further reading&lt;/strong&gt;: See the further reading from the previous lecture. Trefethen, lectures 14, 15, and 3. See also the Wikipedia article on &lt;a href="https://en.wikipedia.org/wiki/Big_O_notation" rel="nofollow"&gt;asymptotic ("big O") notation&lt;/a&gt;; note that for expressions like O(Îµ) we are looking in the limit of &lt;em&gt;small&lt;/em&gt; arguments rather than of large arguments (as in complexity theory), but otherwise the ideas are the same.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-julia-tutorial-feb-7-5pm-in-32-141--optional" class="anchor" aria-hidden="true" href="#julia-tutorial-feb-7-5pm-in-32-141--optional"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Julia tutorial (Feb 7: 5pm in 32-141) â€” optional&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Handout:&lt;/strong&gt; &lt;a href="https://github.com/mitmath/julia-mit/blob/master/Julia-cheatsheet.pdf"&gt;Julia cheat-sheet&lt;/a&gt;, &lt;a href="https://github.com/mitmath/julia-mit/blob/master/Julia-intro.pdf"&gt;Julia intro slides&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;On Friday, 7 February, at 5pm in 32-141, I will give an (attendance-optional!) Julia tutorial, introducing the &lt;a href="http://julialang.org/" rel="nofollow"&gt;Julia programming language and environment&lt;/a&gt; that we will use this term. Please see the &lt;a href="https://github.com/mitmath/julia-mit/blob/master/README.md"&gt;tutorial notes online&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Please &lt;strong&gt;bring your laptops&lt;/strong&gt;, and try to install Julia and the IJulia interface first via the abovementioned tutorial notes. Several people will be at the tutorial session to help answer installation questions. Alternatively, you can use Julia online at &lt;a href="https://juliabox.com/" rel="nofollow"&gt;JuliaBox&lt;/a&gt; without installing anything (although running things on your own machine is usually faster).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>mitmath</author><guid isPermaLink="false">https://github.com/mitmath/18335</guid><pubDate>Sun, 09 Feb 2020 00:07:00 GMT</pubDate></item><item><title>adashofdata/nlp-in-python-tutorial #8 in Jupyter Notebook, Today</title><link>https://github.com/adashofdata/nlp-in-python-tutorial</link><description>&lt;p&gt;&lt;i&gt;comparing stand up comedians using natural language processing&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-welcome-to-the-natural-language-processing-in-python-tutorial" class="anchor" aria-hidden="true" href="#welcome-to-the-natural-language-processing-in-python-tutorial"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Welcome to the Natural Language Processing in Python Tutorial!&lt;/h2&gt;
&lt;p&gt;We will be going through several Jupyter Notebooks during the tutorial and use a number of data science libraries along the way. The easiest way to get started is to download Anaconda, which is free and open source. When you download this, it comes with the Jupyter  Notebook IDE and many popular data science libraries, so you donâ€™t have to install them one by one.&lt;/p&gt;
&lt;p&gt;Here are the steps youâ€™ll need to take before the start of the tutorial:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-1-download-anaconda" class="anchor" aria-hidden="true" href="#1-download-anaconda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Download Anaconda&lt;/h3&gt;
&lt;p&gt;I highly recommend that you download &lt;a href="https://www.anaconda.com/download/" rel="nofollow"&gt;the Python 3.7 version&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-2-download-the-jupyter-notebooks" class="anchor" aria-hidden="true" href="#2-download-the-jupyter-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Download the Jupyter Notebooks&lt;/h3&gt;
&lt;p&gt;Clone or download this &lt;a href="https://github.com/adashofdata/nlp-in-python-tutorial"&gt;Github repository&lt;/a&gt;, so you have access to all the Jupyter Notebooks (.ipynb extension) in the tutorial. &lt;strong&gt;Note the green button on the right side of the screen that says &lt;code&gt;Clone or download&lt;/code&gt;.&lt;/strong&gt; If you know how to use Github, go ahead and clone the repo. If you don't know how to use Github, you can also just download the zip file and unzip it on your laptop.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-3-launch-anaconda-and-open-a-jupyter-notebook" class="anchor" aria-hidden="true" href="#3-launch-anaconda-and-open-a-jupyter-notebook"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. Launch Anaconda and Open a Jupyter Notebook&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Windows:&lt;/em&gt;
Open the Anaconda Navigator program. You should see the Jupyter Notebook logo. Below the logo, click Launch. A browser window should open up. In the browser window, navigate to the location of the saved Jupyter Notebook files and open 0-Hello-World.ipynb. Follow the instructions in the notebook.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Mac/Linux:&lt;/em&gt;
Open a terminal. Type &lt;code&gt;jupyter notebook&lt;/code&gt;. A browser should open up. In the browser window, navigate to the location of the saved Jupyter Notebook files and open 0-Hello-World.ipynb. Follow the instructions in the notebook.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-4-install-a-few-additional-packages" class="anchor" aria-hidden="true" href="#4-install-a-few-additional-packages"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4. Install a Few Additional Packages&lt;/h3&gt;
&lt;p&gt;There are a few additional packages we'll be using during the tutorial that are not included when you download Anaconda - wordcloud, textblob and gensim.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Windows:&lt;/em&gt;
Open the Anaconda Prompt program. You should see a black window pop up. Type &lt;code&gt;conda install -c conda-forge wordcloud&lt;/code&gt; to download wordcloud. You will be asked whether you want to proceed or not. Type &lt;code&gt;y&lt;/code&gt; for yes. Once that is done, type &lt;code&gt;conda install -c conda-forge textblob&lt;/code&gt; to download textblob and &lt;code&gt;y&lt;/code&gt; to proceed, and type &lt;code&gt;conda install -c conda-forge gensim&lt;/code&gt; to download gensim and &lt;code&gt;y&lt;/code&gt; to proceed.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Mac/Linux:&lt;/em&gt;
Your terminal should already be open. Type command-t to open a new tab. Type &lt;code&gt;conda install -c conda-forge wordcloud&lt;/code&gt; to download wordcloud. You will be asked whether you want to proceed or not. Type &lt;code&gt;y&lt;/code&gt; for yes. Once that is done, type &lt;code&gt;conda install -c conda-forge textblob&lt;/code&gt; to download textblob and &lt;code&gt;y&lt;/code&gt; to proceed, and type &lt;code&gt;conda install -c conda-forge gensim&lt;/code&gt; to download gensim and &lt;code&gt;y&lt;/code&gt; to proceed.&lt;/p&gt;
&lt;p&gt;If you have any issues, please email me at &lt;a href="mailto:adashofdata@gmail.com"&gt;adashofdata@gmail.com&lt;/a&gt; or come talk to me before the start of the tutorial.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>adashofdata</author><guid isPermaLink="false">https://github.com/adashofdata/nlp-in-python-tutorial</guid><pubDate>Sun, 09 Feb 2020 00:08:00 GMT</pubDate></item><item><title>Pierian-Data/Complete-Python-3-Bootcamp #9 in Jupyter Notebook, Today</title><link>https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</link><description>&lt;p&gt;&lt;i&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-complete-python-3-bootcamp" class="anchor" aria-hidden="true" href="#complete-python-3-bootcamp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Complete-Python-3-Bootcamp&lt;/h1&gt;
&lt;p&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/p&gt;
&lt;p&gt;Get it now for 95% off with the link:
&lt;a href="https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB" rel="nofollow"&gt;https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Pierian-Data</author><guid isPermaLink="false">https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</guid><pubDate>Sun, 09 Feb 2020 00:09:00 GMT</pubDate></item><item><title>AtsushiSakai/PythonRobotics #10 in Jupyter Notebook, Today</title><link>https://github.com/AtsushiSakai/PythonRobotics</link><description>&lt;p&gt;&lt;i&gt;Python sample codes for robotics algorithms.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRobotics/raw/master/icon.png?raw=true"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRobotics/raw/master/icon.png?raw=true" align="right" width="300" alt="header pic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-pythonrobotics" class="anchor" aria-hidden="true" href="#pythonrobotics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PythonRobotics&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/AtsushiSakai/PythonRobotics" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/58f87d5d3604646322c28abd8c5a9b2faa05fa51/68747470733a2f2f7472617669732d63692e6f72672f4174737573686953616b61692f507974686f6e526f626f746963732e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/AtsushiSakai/PythonRobotics.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pythonrobotics.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a60f894ef011c8a7e648348c16aabfdfb603613a/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f707974686f6e726f626f746963732f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/pythonrobotics/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/AtsushiSakai/pythonrobotics" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2e66a00c9dcf7ecc1f24189c6055aa7e6da233dc/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f73623237396b787576316265333931673f7376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/sb279kxuv1be391g?svg=true" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://coveralls.io/github/AtsushiSakai/PythonRobotics?branch=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2c26144817eba34b4ee9f9a6aee913e6b466218b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4174737573686953616b61692f507974686f6e526f626f746963732f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/AtsushiSakai/PythonRobotics/badge.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/AtsushiSakai/PythonRobotics/context:python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/4c3af4cd47bb2ea2c71cac274f1f7dd392eea893/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f4174737573686953616b61692f507974686f6e526f626f746963732e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138" alt="Language grade: Python" data-canonical-src="https://img.shields.io/lgtm/grade/python/g/AtsushiSakai/PythonRobotics.svg?logo=lgtm&amp;amp;logoWidth=18" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.codefactor.io/repository/github/atsushisakai/pythonrobotics/overview/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c3cd55e61ef2e22ff00427b50b9e7f1c3547de91/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6174737573686973616b61692f707974686f6e726f626f746963732f62616467652f6d6173746572" alt="CodeFactor" data-canonical-src="https://www.codefactor.io/repository/github/atsushisakai/pythonrobotics/badge/master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/AtsushiSakai/PythonRobotics"&gt;&lt;img src="https://camo.githubusercontent.com/230f0a1eaa529fa727cad2c9d3c1ace4738bd25d/68747470733a2f2f746f6b65692e72732f62312f6769746875622f4174737573686953616b61692f507974686f6e526f626f74696373" alt="tokei" data-canonical-src="https://tokei.rs/b1/github/AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://saythanks.io/to/AtsushiSakai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0c9f6dc1c6a604b58d3c56bc5d7624e44f7eee2b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5361792532305468616e6b732d212d3145414544422e737667" alt="Say Thanks!" data-canonical-src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Python codes for robotics algorithm.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#what-is-this"&gt;What is this?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#requirements"&gt;Requirements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-use"&gt;How to use&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#localization"&gt;Localization&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#extended-kalman-filter-localization"&gt;Extended Kalman Filter localization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#particle-filter-localization"&gt;Particle filter localization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#histogram-filter-localization"&gt;Histogram filter localization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#mapping"&gt;Mapping&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#gaussian-grid-map"&gt;Gaussian grid map&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ray-casting-grid-map"&gt;Ray casting grid map&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lidar-to-grid-map"&gt;Lidar to grid map&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#k-means-object-clustering"&gt;k-means object clustering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rectangle-fitting"&gt;Rectangle fitting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#slam"&gt;SLAM&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#iterative-closest-point-icp-matching"&gt;Iterative Closest Point (ICP) Matching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fastslam-10"&gt;FastSLAM 1.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#path-planning"&gt;Path Planning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#dynamic-window-approach"&gt;Dynamic Window Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#grid-based-search"&gt;Grid based search&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#dijkstra-algorithm"&gt;Dijkstra algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#a-algorithm"&gt;A* algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#potential-field-algorithm"&gt;Potential Field algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#grid-based-coverage-path-planning"&gt;Grid based coverage path planning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#state-lattice-planning"&gt;State Lattice Planning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#biased-polar-sampling"&gt;Biased polar sampling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lane-sampling"&gt;Lane sampling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#probabilistic-road-map-prm-planning"&gt;Probabilistic Road-Map (PRM) planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rapidly-exploring-random-trees-rrt"&gt;Rapidly-Exploring Random Trees (RRT)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#rrt"&gt;RRT*&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rrt-with-reeds-shepp-path"&gt;RRT* with reeds-shepp path&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lqr-rrt"&gt;LQR-RRT*&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#quintic-polynomials-planning"&gt;Quintic polynomials planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#reeds-shepp-planning"&gt;Reeds Shepp planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lqr-based-path-planning"&gt;LQR based path planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#optimal-trajectory-in-a-frenet-frame"&gt;Optimal Trajectory in a Frenet Frame&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#path-tracking"&gt;Path Tracking&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#move-to-a-pose-control"&gt;move to a pose control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#stanley-control"&gt;Stanley control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rear-wheel-feedback-control"&gt;Rear wheel feedback control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#linearquadratic-regulator-lqr-speed-and-steering-control"&gt;Linearâ€“quadratic regulator (LQR) speed and steering control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#model-predictive-speed-and-steering-control"&gt;Model predictive speed and steering control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#nonlinear-model-predictive-control-with-c-gmres"&gt;Nonlinear Model predictive control with C-GMRES&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#arm-navigation"&gt;Arm Navigation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#n-joint-arm-to-point-control"&gt;N joint arm to point control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#arm-navigation-with-obstacle-avoidance"&gt;Arm navigation with obstacle avoidance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#aerial-navigation"&gt;Aerial Navigation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#drone-3d-trajectory-following"&gt;drone 3d trajectory following&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rocket-powered-landing"&gt;rocket powered landing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#bipedal"&gt;Bipedal&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#bipedal-planner-with-inverted-pendulum"&gt;bipedal planner with inverted pendulum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#use-case"&gt;Use-case&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contribution"&gt;Contribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#citing"&gt;Citing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#support"&gt;Support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#authors"&gt;Authors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-what-is-this" class="anchor" aria-hidden="true" href="#what-is-this"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is this?&lt;/h1&gt;
&lt;p&gt;This is a Python code collection of robotics algorithms, especially for autonomous navigation.&lt;/p&gt;
&lt;p&gt;Features:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Easy to read for understanding each algorithm's basic idea.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Widely used and practical algorithms are selected.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Minimum dependency.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;See this paper for more details:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1808.10703" rel="nofollow"&gt;[1808.10703] PythonRobotics: a Python code collection of robotics algorithms&lt;/a&gt; (&lt;a href="https://github.com/AtsushiSakai/PythonRoboticsPaper/blob/master/python_robotics.bib"&gt;BibTeX&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Python 3.7.x (2.7 is not supported)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;numpy&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;scipy&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;matplotlib&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;pandas&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.cvxpy.org/index.html" rel="nofollow"&gt;cvxpy&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h1&gt;
&lt;p&gt;This README only shows some examples of this project.&lt;/p&gt;
&lt;p&gt;If you are interested in other examples or mathematical backgrounds of each algorithm,&lt;/p&gt;
&lt;p&gt;You can check the full documentation online: &lt;a href="https://pythonrobotics.readthedocs.io/" rel="nofollow"&gt;https://pythonrobotics.readthedocs.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All animation gifs are stored here: &lt;a href="https://github.com/AtsushiSakai/PythonRoboticsGifs"&gt;AtsushiSakai/PythonRoboticsGifs: Animation gifs of PythonRobotics&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-how-to-use" class="anchor" aria-hidden="true" href="#how-to-use"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to use&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Clone this repo.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;git clone &lt;a href="https://github.com/AtsushiSakai/PythonRobotics.git"&gt;https://github.com/AtsushiSakai/PythonRobotics.git&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Install the required libraries. You can use environment.yml with conda command.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;conda env create -f environment.yml&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start="3"&gt;
&lt;li&gt;
&lt;p&gt;Execute python script in each directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add star to this repo if you like it &lt;g-emoji class="g-emoji" alias="smiley" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f603.png"&gt;ğŸ˜ƒ&lt;/g-emoji&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;&lt;a id="user-content-localization" class="anchor" aria-hidden="true" href="#localization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Localization&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-extended-kalman-filter-localization" class="anchor" aria-hidden="true" href="#extended-kalman-filter-localization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Extended Kalman Filter localization&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/extended_kalman_filter/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/extended_kalman_filter/animation.gif" width="640" alt="EKF pic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Documentation: &lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/Localization/extended_kalman_filter/extended_kalman_filter_localization.ipynb"&gt;Notebook&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-particle-filter-localization" class="anchor" aria-hidden="true" href="#particle-filter-localization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Particle filter localization&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/particle_filter/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/particle_filter/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a sensor fusion localization with Particle Filter(PF).&lt;/p&gt;
&lt;p&gt;The blue line is true trajectory, the black line is dead reckoning trajectory,&lt;/p&gt;
&lt;p&gt;and the red line is estimated trajectory with PF.&lt;/p&gt;
&lt;p&gt;It is assumed that the robot can measure a distance from landmarks (RFID).&lt;/p&gt;
&lt;p&gt;This measurements are used for PF localization.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.probabilistic-robotics.org/" rel="nofollow"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-histogram-filter-localization" class="anchor" aria-hidden="true" href="#histogram-filter-localization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Histogram filter localization&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/histogram_filter/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/histogram_filter/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a 2D localization example with Histogram filter.&lt;/p&gt;
&lt;p&gt;The red cross is true position, black points are RFID positions.&lt;/p&gt;
&lt;p&gt;The blue grid shows a position probability of histogram filter.&lt;/p&gt;
&lt;p&gt;In this simulation, x,y are unknown, yaw is known.&lt;/p&gt;
&lt;p&gt;The filter integrates speed input and range observations from RFID for localization.&lt;/p&gt;
&lt;p&gt;Initial position is not needed.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.probabilistic-robotics.org/" rel="nofollow"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-mapping" class="anchor" aria-hidden="true" href="#mapping"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Mapping&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-gaussian-grid-map" class="anchor" aria-hidden="true" href="#gaussian-grid-map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gaussian grid map&lt;/h2&gt;
&lt;p&gt;This is a 2D Gaussian grid mapping example.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/gaussian_grid_map/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/gaussian_grid_map/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ray-casting-grid-map" class="anchor" aria-hidden="true" href="#ray-casting-grid-map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ray casting grid map&lt;/h2&gt;
&lt;p&gt;This is a 2D ray casting grid mapping example.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/raycasting_grid_map/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/raycasting_grid_map/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lidar-to-grid-map" class="anchor" aria-hidden="true" href="#lidar-to-grid-map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lidar to grid map&lt;/h2&gt;
&lt;p&gt;This example shows how to convert a 2D range measurement to a grid map.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="Mapping/lidar_to_grid_map/animation.gif"&gt;&lt;img src="Mapping/lidar_to_grid_map/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-k-means-object-clustering" class="anchor" aria-hidden="true" href="#k-means-object-clustering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;k-means object clustering&lt;/h2&gt;
&lt;p&gt;This is a 2D object clustering with k-means algorithm.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/kmeans_clustering/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/kmeans_clustering/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-rectangle-fitting" class="anchor" aria-hidden="true" href="#rectangle-fitting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Rectangle fitting&lt;/h2&gt;
&lt;p&gt;This is a 2D rectangle fitting for vehicle detection.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/rectangle_fitting/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/rectangle_fitting/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-slam" class="anchor" aria-hidden="true" href="#slam"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SLAM&lt;/h1&gt;
&lt;p&gt;Simultaneous Localization and Mapping(SLAM) examples&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-iterative-closest-point-icp-matching" class="anchor" aria-hidden="true" href="#iterative-closest-point-icp-matching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Iterative Closest Point (ICP) Matching&lt;/h2&gt;
&lt;p&gt;This is a 2D ICP matching example with singular value decomposition.&lt;/p&gt;
&lt;p&gt;It can calculate a rotation matrix and a translation vector between points to points.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/iterative_closest_point/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/iterative_closest_point/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cs.gmu.edu/~kosecka/cs685/cs685-icp.pdf" rel="nofollow"&gt;Introduction to Mobile Robotics: Iterative Closest Point Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-fastslam-10" class="anchor" aria-hidden="true" href="#fastslam-10"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FastSLAM 1.0&lt;/h2&gt;
&lt;p&gt;This is a feature based SLAM example using FastSLAM 1.0.&lt;/p&gt;
&lt;p&gt;The blue line is ground truth, the black line is dead reckoning, the red line is the estimated trajectory with FastSLAM.&lt;/p&gt;
&lt;p&gt;The red points are particles of FastSLAM.&lt;/p&gt;
&lt;p&gt;Black points are landmarks, blue crosses are estimated landmark positions by FastSLAM.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/FastSLAM1/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/FastSLAM1/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.probabilistic-robotics.org/" rel="nofollow"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www-personal.acfr.usyd.edu.au/tbailey/software/slam_simulations.htm" rel="nofollow"&gt;SLAM simulations by Tim Bailey&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-path-planning" class="anchor" aria-hidden="true" href="#path-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Path Planning&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-dynamic-window-approach" class="anchor" aria-hidden="true" href="#dynamic-window-approach"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dynamic Window Approach&lt;/h2&gt;
&lt;p&gt;This is a 2D navigation sample code with Dynamic Window Approach.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.ri.cmu.edu/pub_files/pub1/fox_dieter_1997_1/fox_dieter_1997_1.pdf" rel="nofollow"&gt;The Dynamic Window Approach to Collision Avoidance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DynamicWindowApproach/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DynamicWindowApproach/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-grid-based-search" class="anchor" aria-hidden="true" href="#grid-based-search"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Grid based search&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-dijkstra-algorithm" class="anchor" aria-hidden="true" href="#dijkstra-algorithm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dijkstra algorithm&lt;/h3&gt;
&lt;p&gt;This is a 2D grid based shortest path planning with Dijkstra's algorithm.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/Dijkstra/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/Dijkstra/animation.gif" alt="PythonRobotics/figure_1.png at master Â· AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the animation, cyan points are searched nodes.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-a-algorithm" class="anchor" aria-hidden="true" href="#a-algorithm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A* algorithm&lt;/h3&gt;
&lt;p&gt;This is a 2D grid based shortest path planning with A star algorithm.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/AStar/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/AStar/animation.gif" alt="PythonRobotics/figure_1.png at master Â· AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the animation, cyan points are searched nodes.&lt;/p&gt;
&lt;p&gt;Its heuristic is 2D Euclid distance.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-potential-field-algorithm" class="anchor" aria-hidden="true" href="#potential-field-algorithm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Potential Field algorithm&lt;/h3&gt;
&lt;p&gt;This is a 2D grid based path planning with Potential Field algorithm.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/PotentialFieldPlanning/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/PotentialFieldPlanning/animation.gif" alt="PotentialField" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the animation, the blue heat map shows potential value on each grid.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.cs.cmu.edu/~motionplanning/lecture/Chap4-Potential-Field_howie.pdf" rel="nofollow"&gt;Robotic Motion Planning:Potential Functions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-grid-based-coverage-path-planning" class="anchor" aria-hidden="true" href="#grid-based-coverage-path-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Grid based coverage path planning&lt;/h3&gt;
&lt;p&gt;This is a 2D grid based coverage path planning simulation.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/GridBasedSweepCPP/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/GridBasedSweepCPP/animation.gif" alt="PotentialField" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-state-lattice-planning" class="anchor" aria-hidden="true" href="#state-lattice-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;State Lattice Planning&lt;/h2&gt;
&lt;p&gt;This script is a path planning code with state lattice planning.&lt;/p&gt;
&lt;p&gt;This code uses the model predictive trajectory generator to solve boundary problem.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://journals.sagepub.com/doi/pdf/10.1177/0278364906075328" rel="nofollow"&gt;Optimal rough terrain trajectory generation for wheeled mobile robots&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.frc.ri.cmu.edu/~alonzo/pubs/papers/JFR_08_SS_Sampling.pdf" rel="nofollow"&gt;State Space Sampling of Feasible Motions for High-Performance Mobile Robot Navigation in Complex Environments&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-biased-polar-sampling" class="anchor" aria-hidden="true" href="#biased-polar-sampling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Biased polar sampling&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/BiasedPolarSampling.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/BiasedPolarSampling.gif" alt="PythonRobotics/figure_1.png at master Â· AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-lane-sampling" class="anchor" aria-hidden="true" href="#lane-sampling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lane sampling&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/LaneSampling.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/LaneSampling.gif" alt="PythonRobotics/figure_1.png at master Â· AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-probabilistic-road-map-prm-planning" class="anchor" aria-hidden="true" href="#probabilistic-road-map-prm-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Probabilistic Road-Map (PRM) planning&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ProbabilisticRoadMap/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ProbabilisticRoadMap/animation.gif" alt="PRM" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This PRM planner uses Dijkstra method for graph search.&lt;/p&gt;
&lt;p&gt;In the animation, blue points are sampled points,&lt;/p&gt;
&lt;p&gt;Cyan crosses means searched points with Dijkstra method,&lt;/p&gt;
&lt;p&gt;The red line is the final path of PRM.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Probabilistic_roadmap" rel="nofollow"&gt;Probabilistic roadmap - Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã€€ã€€&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-rapidly-exploring-random-trees-rrt" class="anchor" aria-hidden="true" href="#rapidly-exploring-random-trees-rrt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Rapidly-Exploring Random Trees (RRT)&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-rrt" class="anchor" aria-hidden="true" href="#rrt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RRT*&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTstar/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTstar/animation.gif" alt="PythonRobotics/figure_1.png at master Â· AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a path planning code with RRT*&lt;/p&gt;
&lt;p&gt;Black circles are obstacles, green line is a searched tree, red crosses are start and goal positions.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1005.0416" rel="nofollow"&gt;Incremental Sampling-based Algorithms for Optimal Motion Planning&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.419.5503&amp;amp;rep=rep1&amp;amp;type=pdf" rel="nofollow"&gt;Sampling-based Algorithms for Optimal Motion Planning&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-rrt-with-reeds-shepp-path" class="anchor" aria-hidden="true" href="#rrt-with-reeds-shepp-path"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RRT* with reeds-shepp path&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTStarReedsShepp/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTStarReedsShepp/animation.gif" alt="Robotics/animation.gif at master Â· AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Path planning for a car robot with RRT* and reeds shepp path planner.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-lqr-rrt" class="anchor" aria-hidden="true" href="#lqr-rrt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LQR-RRT*&lt;/h3&gt;
&lt;p&gt;This is a path planning simulation with LQR-RRT*.&lt;/p&gt;
&lt;p&gt;A double integrator motion model is used for LQR local planner.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRRRTStar/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRRRTStar/animation.gif" alt="LQRRRT" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://lis.csail.mit.edu/pubs/perez-icra12.pdf" rel="nofollow"&gt;LQR-RRT*: Optimal Sampling-Based Motion Planning with Automatically Derived Extension Heuristics&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/MahanFathi/LQR-RRTstar"&gt;MahanFathi/LQR-RRTstar: LQR-RRT* method is used for random motion planning of a simple pendulum in its phase plot&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-quintic-polynomials-planning" class="anchor" aria-hidden="true" href="#quintic-polynomials-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quintic polynomials planning&lt;/h2&gt;
&lt;p&gt;Motion planning with quintic polynomials.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/QuinticPolynomialsPlanner/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/QuinticPolynomialsPlanner/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It can calculate 2D path, velocity, and acceleration profile based on quintic polynomials.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ieeexplore.ieee.org/document/637936/" rel="nofollow"&gt;Local Path Planning And Motion Control For Agv In Positioning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-reeds-shepp-planning" class="anchor" aria-hidden="true" href="#reeds-shepp-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reeds Shepp planning&lt;/h2&gt;
&lt;p&gt;A sample code with Reeds Shepp path planning.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ReedsSheppPath/animation.gif?raw=true"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ReedsSheppPath/animation.gif?raw=true" alt="RSPlanning" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://planning.cs.uiuc.edu/node822.html" rel="nofollow"&gt;15.3.2 Reeds-Shepp Curves&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://pdfs.semanticscholar.org/932e/c495b1d0018fd59dee12a0bf74434fac7af4.pdf" rel="nofollow"&gt;optimal paths for a car that goes both forwards and backwards&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/ghliu/pyReedsShepp"&gt;ghliu/pyReedsShepp: Implementation of Reeds Shepp curve.&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-lqr-based-path-planning" class="anchor" aria-hidden="true" href="#lqr-based-path-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LQR based path planning&lt;/h2&gt;
&lt;p&gt;A sample code using LQR based path planning for double integrator model.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRPlanner/animation.gif?raw=true"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRPlanner/animation.gif?raw=true" alt="RSPlanning" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-optimal-trajectory-in-a-frenet-frame" class="anchor" aria-hidden="true" href="#optimal-trajectory-in-a-frenet-frame"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Optimal Trajectory in a Frenet Frame&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/FrenetOptimalTrajectory/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/FrenetOptimalTrajectory/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is optimal trajectory generation in a Frenet Frame.&lt;/p&gt;
&lt;p&gt;The cyan line is the target course and black crosses are obstacles.&lt;/p&gt;
&lt;p&gt;The red line is predicted path.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.researchgate.net/profile/Moritz_Werling/publication/224156269_Optimal_Trajectory_Generation_for_Dynamic_Street_Scenarios_in_a_Frenet_Frame/links/54f749df0cf210398e9277af.pdf" rel="nofollow"&gt;Optimal Trajectory Generation for Dynamic Street Scenarios in a Frenet Frame&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Cj6tAQe7UCY" rel="nofollow"&gt;Optimal trajectory generation for dynamic street scenarios in a Frenet Frame&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-path-tracking" class="anchor" aria-hidden="true" href="#path-tracking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Path Tracking&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-move-to-a-pose-control" class="anchor" aria-hidden="true" href="#move-to-a-pose-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;move to a pose control&lt;/h2&gt;
&lt;p&gt;This is a simulation of moving to a pose control&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/move_to_pose/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/move_to_pose/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://link.springer.com/book/10.1007/978-3-642-20144-8" rel="nofollow"&gt;P. I. Corke, "Robotics, Vision and Control" | SpringerLink p102&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-stanley-control" class="anchor" aria-hidden="true" href="#stanley-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stanley control&lt;/h2&gt;
&lt;p&gt;Path tracking simulation with Stanley steering control and PID speed control.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/stanley_controller/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/stanley_controller/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://robots.stanford.edu/papers/thrun.stanley05.pdf" rel="nofollow"&gt;Stanley: The robot that won the DARPA grand challenge&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.ri.cmu.edu/pub_files/2009/2/Automatic_Steering_Methods_for_Autonomous_Automobile_Path_Tracking.pdf" rel="nofollow"&gt;Automatic Steering Methods for Autonomous Automobile Path Tracking&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-rear-wheel-feedback-control" class="anchor" aria-hidden="true" href="#rear-wheel-feedback-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Rear wheel feedback control&lt;/h2&gt;
&lt;p&gt;Path tracking simulation with rear wheel feedback steering control and PID speed control.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/rear_wheel_feedback/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/rear_wheel_feedback/animation.gif" alt="PythonRobotics/figure_1.png at master Â· AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1604.07446" rel="nofollow"&gt;A Survey of Motion Planning and Control Techniques for Self-driving Urban Vehicles&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-linearquadratic-regulator-lqr-speed-and-steering-control" class="anchor" aria-hidden="true" href="#linearquadratic-regulator-lqr-speed-and-steering-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linearâ€“quadratic regulator (LQR) speed and steering control&lt;/h2&gt;
&lt;p&gt;Path tracking simulation with LQR speed and steering control.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/lqr_speed_steer_control/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/lqr_speed_steer_control/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ieeexplore.ieee.org/document/5940562/" rel="nofollow"&gt;Towards fully autonomous driving: Systems and algorithms - IEEE Conference Publication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-model-predictive-speed-and-steering-control" class="anchor" aria-hidden="true" href="#model-predictive-speed-and-steering-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model predictive speed and steering control&lt;/h2&gt;
&lt;p&gt;Path tracking simulation with iterative linear model predictive speed and steering control.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/model_predictive_speed_and_steer_control/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/model_predictive_speed_and_steer_control/animation.gif" width="640" alt="MPC pic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/PathTracking/model_predictive_speed_and_steer_control/Model_predictive_speed_and_steering_control.ipynb"&gt;notebook&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://grauonline.de/wordpress/?page_id=3244" rel="nofollow"&gt;Real-time Model Predictive Control (MPC), ACADO, Python | Work-is-Playing&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-nonlinear-model-predictive-control-with-c-gmres" class="anchor" aria-hidden="true" href="#nonlinear-model-predictive-control-with-c-gmres"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Nonlinear Model predictive control with C-GMRES&lt;/h2&gt;
&lt;p&gt;A motion planning and path tracking simulation with NMPC of C-GMRES&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/cgmres_nmpc/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/cgmres_nmpc/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/PathTracking/cgmres_nmpc/cgmres_nmpc.ipynb"&gt;notebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-arm-navigation" class="anchor" aria-hidden="true" href="#arm-navigation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Arm Navigation&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-n-joint-arm-to-point-control" class="anchor" aria-hidden="true" href="#n-joint-arm-to-point-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;N joint arm to point control&lt;/h2&gt;
&lt;p&gt;N joint arm to a point control simulation.&lt;/p&gt;
&lt;p&gt;This is a interactive simulation.&lt;/p&gt;
&lt;p&gt;You can set the goal position of the end effector with left-click on the ploting area.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/n_joint_arm_to_point_control/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/n_joint_arm_to_point_control/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this simulation N = 10, however, you can change it.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-arm-navigation-with-obstacle-avoidance" class="anchor" aria-hidden="true" href="#arm-navigation-with-obstacle-avoidance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Arm navigation with obstacle avoidance&lt;/h2&gt;
&lt;p&gt;Arm navigation with obstacle avoidance simulation.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/arm_obstacle_navigation/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/arm_obstacle_navigation/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-aerial-navigation" class="anchor" aria-hidden="true" href="#aerial-navigation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Aerial Navigation&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-drone-3d-trajectory-following" class="anchor" aria-hidden="true" href="#drone-3d-trajectory-following"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;drone 3d trajectory following&lt;/h2&gt;
&lt;p&gt;This is a 3d trajectory following simulation for a quadrotor.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/drone_3d_trajectory_following/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/drone_3d_trajectory_following/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-rocket-powered-landing" class="anchor" aria-hidden="true" href="#rocket-powered-landing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;rocket powered landing&lt;/h2&gt;
&lt;p&gt;This is a 3d trajectory generation simulation for a rocket powered landing.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/rocket_powered_landing/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/rocket_powered_landing/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/AerialNavigation/rocket_powered_landing/rocket_powered_landing.ipynb"&gt;notebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-bipedal" class="anchor" aria-hidden="true" href="#bipedal"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bipedal&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-bipedal-planner-with-inverted-pendulum" class="anchor" aria-hidden="true" href="#bipedal-planner-with-inverted-pendulum"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;bipedal planner with inverted pendulum&lt;/h2&gt;
&lt;p&gt;This is a bipedal planner for modifying footsteps with inverted pendulum.&lt;/p&gt;
&lt;p&gt;You can set the footsteps and the planner will modify those automatically.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Bipedal/bipedal_planner/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Bipedal/bipedal_planner/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h1&gt;
&lt;p&gt;MIT&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-use-case" class="anchor" aria-hidden="true" href="#use-case"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Use-case&lt;/h1&gt;
&lt;p&gt;If this project helps your robotics project, please let me know with creating an issue.&lt;/p&gt;
&lt;p&gt;Your robot's video, which is using PythonRobotics, is very welcome!!&lt;/p&gt;
&lt;p&gt;This is a list of other user's comment and references:&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/users_comments.md"&gt;users_comments&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-contribution" class="anchor" aria-hidden="true" href="#contribution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution&lt;/h1&gt;
&lt;p&gt;Any contribution is welcome!!&lt;/p&gt;
&lt;p&gt;If your PR is merged multiple times, I will add your account to the author list.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-citing" class="anchor" aria-hidden="true" href="#citing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citing&lt;/h1&gt;
&lt;p&gt;If you use this project's code for your academic work, we encourage you to cite &lt;a href="https://arxiv.org/abs/1808.10703" rel="nofollow"&gt;our papers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you use this project's code in industry, we'd love to hear from you as well; feel free to reach out to the developers directly.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-support" class="anchor" aria-hidden="true" href="#support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support&lt;/h1&gt;
&lt;p&gt;If you or your company would like to support this project, please consider:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/sponsors/AtsushiSakai"&gt;Sponsor @AtsushiSakai on GitHub Sponsors&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.patreon.com/myenigma" rel="nofollow"&gt;Become a backer or sponsor on Patreon&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.paypal.me/myenigmapay/" rel="nofollow"&gt;One-time donation via PayPal&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authors&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/AtsushiSakai/"&gt;Atsushi Sakai&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/daniel-s-ingram"&gt;Daniel Ingram&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/jwdinius"&gt;Joe Dinius&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/karanchawla"&gt;Karan Chawla&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/araffin"&gt;Antonin RAFFIN&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/AlexisTM"&gt;Alexis Paques&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/rsasaki0109"&gt;Ryohei Sasaki&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/goktug97"&gt;GÃ¶ktuÄŸ KarakaÅŸlÄ±&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/Gjacquenot"&gt;Guillaume Jacquenot&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>AtsushiSakai</author><guid isPermaLink="false">https://github.com/AtsushiSakai/PythonRobotics</guid><pubDate>Sun, 09 Feb 2020 00:10:00 GMT</pubDate></item><item><title>fengdu78/machine_learning_beginner #11 in Jupyter Notebook, Today</title><link>https://github.com/fengdu78/machine_learning_beginner</link><description>&lt;p&gt;&lt;i&gt;æœºå™¨å­¦ä¹ åˆå­¦è€…å…¬ä¼—å·ä½œå“&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-æœºå™¨å­¦ä¹ åˆå­¦è€…å…¬ä¼—å·" class="anchor" aria-hidden="true" href="#æœºå™¨å­¦ä¹ åˆå­¦è€…å…¬ä¼—å·"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æœºå™¨å­¦ä¹ åˆå­¦è€…å…¬ä¼—å·&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/gongzhong.jpg"&gt;&lt;img src="images/gongzhong.jpg" alt="å…¬ä¼—å·" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æœ¬ä»“åº“æ˜¯â€œæœºå™¨å­¦ä¹ åˆå­¦è€…â€å…¬ä¼—å·å‘å¸ƒçš„å†…å®¹ä»£ç ã€‚&lt;/p&gt;
&lt;p&gt;æœºå™¨å­¦ä¹ qqç¾¤ï¼š659697409ï¼ˆæˆ‘ä»¬æœ‰9ä¸ªç¾¤ï¼ŒåŠ è¿‡ä¸€ä¸ªå°±ä¸éœ€è¦åŠ äº†ï¼‰&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-è¿™ä¸ªä»“åº“çš„å†…å®¹ç›®å½•" class="anchor" aria-hidden="true" href="#è¿™ä¸ªä»“åº“çš„å†…å®¹ç›®å½•"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è¿™ä¸ªä»“åº“çš„å†…å®¹ç›®å½•&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-2019å¹´ç²¾é€‰æ–‡ç« " class="anchor" aria-hidden="true" href="#2019å¹´ç²¾é€‰æ–‡ç« "&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2019å¹´ç²¾é€‰æ–‡ç« &lt;/h4&gt;
&lt;p&gt;&lt;a href="2019/"&gt;2019&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-aiåŸºç¡€" class="anchor" aria-hidden="true" href="#aiåŸºç¡€"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;AIåŸºç¡€&lt;/h4&gt;
&lt;p&gt;&lt;a href="AI_beginner/"&gt;AI_beginner&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-æ·±åº¦å­¦ä¹ å†…å®¹" class="anchor" aria-hidden="true" href="#æ·±åº¦å­¦ä¹ å†…å®¹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ·±åº¦å­¦ä¹ å†…å®¹&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;1.&lt;a href="PyTorch_beginner/"&gt;PyTorch60åˆ†é’Ÿå…¥é—¨ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰&lt;/a&gt;ï¼ˆç›®å½•åï¼šPyTorch_beginnerï¼‰&lt;/li&gt;
&lt;li&gt;2.&lt;a href="deep-learning-with-python-notebooks/"&gt;Pythonæ·±åº¦å­¦ä¹ åŸä¹¦ä»£ç ä¸­æ–‡ç¿»è¯‘&lt;/a&gt;ï¼ˆç›®å½•åï¼šdeep-learning-with-python-notebooksï¼‰&lt;/li&gt;
&lt;li&gt;3.&lt;a href="deep-learning-with-tensorflow-keras-pytorch/"&gt;å¼ºçƒˆæ¨èçš„TensorFlowã€Pytorchå’ŒKerasçš„æ ·ä¾‹èµ„æº&lt;/a&gt;ï¼ˆç›®å½•åï¼šdeep-learning-with-tensorflow-keras-pytorchï¼‰&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-pythonåŸºç¡€" class="anchor" aria-hidden="true" href="#pythonåŸºç¡€"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PythonåŸºç¡€&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;1.&lt;a href="python-start/"&gt;ä¸¤å¤©å…¥é—¨Python&lt;/a&gt;(ç›®å½•åï¼špython-start)&lt;/li&gt;
&lt;li&gt;2.&lt;a href="numpy/"&gt;é€‚åˆåˆå­¦è€…å¿«é€Ÿå…¥é—¨çš„Numpyå®æˆ˜å…¨é›†&lt;/a&gt;(ç›®å½•åï¼šnumpy)&lt;/li&gt;
&lt;li&gt;3.&lt;a href="matplotlib/"&gt;matplotlibå­¦ä¹ ä¹‹åŸºæœ¬ä½¿ç”¨&lt;/a&gt;(ç›®å½•åï¼šmatplotlib)&lt;/li&gt;
&lt;li&gt;4.&lt;a href="pyparis-2018-sklearn/"&gt;Sklearnå…¥é—¨ç»å…¸æ¡ˆä¾‹&lt;/a&gt;(ç›®å½•åï¼špyparis-2018-sklearn)&lt;/li&gt;
&lt;li&gt;5.&lt;a href="pandas/"&gt;ä¸¤å¤©å­¦ä¼špandas&lt;/a&gt;(ç›®å½•åï¼špandas)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-æœ¬ç«™çš„å…¶ä»–å¼€æºä»“åº“" class="anchor" aria-hidden="true" href="#æœ¬ç«™çš„å…¶ä»–å¼€æºä»“åº“"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æœ¬ç«™çš„å…¶ä»–å¼€æºä»“åº“&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-æœ¬äººæ•´ç†" class="anchor" aria-hidden="true" href="#æœ¬äººæ•´ç†"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æœ¬äººæ•´ç†&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;1.&lt;a href="https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes"&gt;å´æ©è¾¾è€å¸ˆçš„æœºå™¨å­¦ä¹ è¯¾ç¨‹ä¸ªäººç¬”è®°&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2.&lt;a href="https://github.com/fengdu78/deeplearning_ai_books"&gt;deeplearning.aiï¼ˆå´æ©è¾¾è€å¸ˆçš„æ·±åº¦å­¦ä¹ è¯¾ç¨‹ç¬”è®°åŠèµ„æºï¼‰&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;3.&lt;a href="https://github.com/fengdu78/lihang-code"&gt;ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•çš„ä»£ç å®ç°ã€‹&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-å¤§ç¥ä¹‹ä½œ" class="anchor" aria-hidden="true" href="#å¤§ç¥ä¹‹ä½œ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å¤§ç¥ä¹‹ä½œ&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;1.&lt;a href="https://github.com/roboticcam/machine-learning-notes"&gt;å¾äº¦è¾¾è€å¸ˆçš„æœºå™¨å­¦ä¹ èµ„æ–™åˆ†äº«&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2.&lt;a href="http://www.huaxiaozhuan.com/" rel="nofollow"&gt;åæ ¡ä¸“è€å¸ˆçš„ç¬”è®°åˆ†äº«&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3.&lt;a href="https://github.com/Doraemonzzz/Learning-from-data"&gt;LFDä¹ é¢˜è§£ç­”ï¼ˆæ—è½©ç”°æœºå™¨å­¦ä¹ è¯¾ç¨‹å†…å®¹ï¼‰ï¼ˆä½œè€…ç§¦è‡»ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;ä»¥ä¸‹ä¸ºæ˜¯å…¬ä¼—å·åˆ›ç«‹ä»¥æ¥çš„ç²¾é€‰åŸåˆ›æ–‡ç« ï¼Œé€‚åˆåˆå­¦è€…å…¥é—¨ AIã€‚æœ¬æ–‡å»ºè®®ç”¨å¾®ä¿¡æ”¶è—ç”¨ç¢ç‰‡æ—¶é—´å­¦ä¹ ã€‚ï¼ˆé»„æµ·å¹¿ï¼‰&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-ä¸€å‰è¨€" class="anchor" aria-hidden="true" href="#ä¸€å‰è¨€"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä¸€ã€å‰è¨€&lt;/h2&gt;
&lt;p&gt;AI åˆå­¦è€…æœ€å¤§çš„é—®é¢˜å°±æ˜¯ï¼š&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;èµ„æ–™å¤ªå¤šï¼çœ‹ä¸å®Œï¼ï¼ä¸çŸ¥é“å¦‚ä½•å–èˆï¼ï¼&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;æˆ‘æŠŠ å…¬ä¼—å·åˆ›åŠä»¥æ¥çš„åŸåˆ›æ–‡ç« è¿›è¡Œæ•´ç†ï¼Œæ–‡ç« é€‚åˆ&lt;strong&gt;æœ¬ç§‘ã€ç¡•å£«ä»¥åŠåˆšæ¥è§¦æœºå™¨å­¦ä¹ çš„åšå£«&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;p&gt;å­¦å®Œè¿™äº›æ–‡ç« å­¦å®Œä»¥åï¼Œå°±åŸºæœ¬å…¥é—¨äº†ã€‚&lt;/p&gt;
&lt;p&gt;å…¥é—¨ä»¥åï¼Œé‡åˆ°é—®é¢˜èƒ½ä¸Šç½‘æœç´¢è§£å†³äº†ï¼Œä¹ŸçŸ¥é“æ¥ä¸‹æ¥åº”è¯¥å­¦ä»€ä¹ˆã€‚&lt;/p&gt;
&lt;p&gt;æœ¬æ–‡å»ºè®®ç”¨å¾®ä¿¡æ”¶è—ï¼Œåˆ©ç”¨ç¢ç‰‡æ—¶é—´å­¦ä¹ ã€‚&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-ä½œè€…ç®€ä»‹" class="anchor" aria-hidden="true" href="#ä½œè€…ç®€ä»‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä½œè€…ç®€ä»‹ï¼š&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484487&amp;amp;idx=1&amp;amp;sn=1df61f5f1ae6838f2eef1f4a3c702733&amp;amp;chksm=97048ffba07306edb4e816f8fc6ef8bdeb33ed644e68b4353649697fa0c11044f26c3bf788e8&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é‚£äº›å¹´åšçš„å­¦æœ¯å…¬ç›Š-ä½ ä¸æ˜¯ä¸€ä¸ªäººåœ¨æˆ˜æ–—&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-äºŒå­¦ä¹ è·¯çº¿" class="anchor" aria-hidden="true" href="#äºŒå­¦ä¹ è·¯çº¿"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;äºŒã€å­¦ä¹ è·¯çº¿&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484737&amp;amp;idx=1&amp;amp;sn=27c52b4bc4ca98d3ab817344b84226cc&amp;amp;chksm=97048efda07307eb78d4f4ec0039a386a658404156b051af0cb715fafa8d2ae66cbe49343bf3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é¦–å‘ï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484737&amp;amp;idx=1&amp;amp;sn=27c52b4bc4ca98d3ab817344b84226cc&amp;amp;chksm=97048efda07307eb78d4f4ec0039a386a658404156b051af0cb715fafa8d2ae66cbe49343bf3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é€‚åˆåˆå­¦è€…å…¥é—¨äººå·¥æ™ºèƒ½çš„è·¯çº¿åŠèµ„æ–™ä¸‹è½½&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¿™ç¯‡æ–‡ç« ä¸ºåˆå­¦è€…æä¾›äº†å…¥é—¨çš„è·¯çº¿ã€‚åŒ…å«æ•°å­¦åŸºç¡€ã€python å…¥é—¨ã€æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€ç‰¹å¾å·¥ç¨‹å…¥é—¨ç­‰ã€‚å¹¶æŠŠä»£ç æ”¾åœ¨äº† github ä»“åº“ï¼š&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/fengdu78/Data-Science-Notes"&gt;https://github.com/fengdu78/Data-Science-Notes&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247486187&amp;amp;idx=1&amp;amp;sn=3c86ade48695ce102e93fa813c55f126&amp;amp;chksm=97048157a07308419d900bec1ff4699092c62c7ed331a334734a4225db0b2274a7b134153037&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æœºå™¨å­¦ä¹ åœ¨çº¿æ‰‹å†Œï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247486187&amp;amp;idx=1&amp;amp;sn=3c86ade48695ce102e93fa813c55f126&amp;amp;chksm=97048157a07308419d900bec1ff4699092c62c7ed331a334734a4225db0b2274a7b134153037&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;åƒèƒŒæ‰˜ç¦å•è¯ä¸€æ ·å­¦æœºå™¨å­¦ä¹ &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¿™ç¯‡æ–‡ç« å°†æœºå™¨å­¦ä¹ çš„ç²¾åéƒ¨åˆ†åšæˆäº†æ‰‹å†Œï¼Œæ‰“å¼€å¾®ä¿¡å°±èƒ½å­¦ä¹ ï¼Œé€‚åˆå¹³æ—¶æ—¶é—´å°‘çš„æœ‹å‹å­¦ä¹ æœºå™¨å­¦ä¹ ï¼Œå¯ä»¥åœ¨é€šå‹¤çš„æ—¶å€™åœ¨æ‰‹æœºä¸Šå­¦ä¹ ï¼Œå»ºè®®æ”¶è—æœ¬æ–‡æ…¢æ…¢å­¦ä¹ &lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ä¸‰åŸºç¡€çŸ¥è¯†" class="anchor" aria-hidden="true" href="#ä¸‰åŸºç¡€çŸ¥è¯†"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä¸‰ã€åŸºç¡€çŸ¥è¯†&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485787&amp;amp;idx=1&amp;amp;sn=d53e991935fc6def2919b2bed6111f8d&amp;amp;chksm=970482e7a0730bf17c9fc7f5a639a21331be477af74b039ec56c0a4eaf0220259733d9852684&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å¸¦ä½ å°‘èµ°å¼¯è·¯ï¼&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485787&amp;amp;idx=1&amp;amp;sn=d53e991935fc6def2919b2bed6111f8d&amp;amp;chksm=970482e7a0730bf17c9fc7f5a639a21331be477af74b039ec56c0a4eaf0220259733d9852684&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ï¼&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485787&amp;amp;idx=1&amp;amp;sn=d53e991935fc6def2919b2bed6111f8d&amp;amp;chksm=970482e7a0730bf17c9fc7f5a639a21331be477af74b039ec56c0a4eaf0220259733d9852684&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é»„åšæ•´ç†çš„æœºå™¨å­¦ä¹ æ•°å­¦åŸºç¡€èµ„æ–™æ¥å¸®ä½ ï¼ˆå¯åœ¨çº¿é˜…è¯»ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä¸Šé¢è¿™ç¯‡æ–‡ç« æ˜¯æ•°å­¦åŸºç¡€ï¼Œä¹Ÿæ˜¯ä»¥ä¸‹äº”ç¯‡æ–‡ç« çš„æ•´åˆç‰ˆæœ¬ï¼Œå¯ä»¥åœ¨çº¿é˜…è¯»ï¼Œä¹Ÿå¯ä»¥æ ¹æ®éœ€è¦åˆ†åˆ«é˜…è¯»ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485293&amp;amp;idx=2&amp;amp;sn=2650e61d6268f667333e86cb52ab1df1&amp;amp;chksm=97048cd1a07305c73229a0b3daf887ac4960fcbd3f378bbc0b40b9b38203fca387b29218fcbd&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é¦–å‘ï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485293&amp;amp;idx=2&amp;amp;sn=2650e61d6268f667333e86cb52ab1df1&amp;amp;chksm=97048cd1a07305c73229a0b3daf887ac4960fcbd3f378bbc0b40b9b38203fca387b29218fcbd&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å´æ©è¾¾çš„ CS229 çš„æ•°å­¦åŸºç¡€ï¼ˆæ¦‚ç‡è®ºï¼‰ï¼Œæœ‰äººæŠŠå®ƒåšæˆäº†åœ¨çº¿ç¿»è¯‘ç‰ˆæœ¬ï¼&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485221&amp;amp;idx=2&amp;amp;sn=105073d243e1d39e10c7ad3dd22043c8&amp;amp;chksm=97048c99a073058fd51d33990ed476ff34acbe22aa7f52cdcd396f2283b22312feafbffb0e5b&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é¦–å‘ï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485221&amp;amp;idx=2&amp;amp;sn=105073d243e1d39e10c7ad3dd22043c8&amp;amp;chksm=97048c99a073058fd51d33990ed476ff34acbe22aa7f52cdcd396f2283b22312feafbffb0e5b&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å´æ©è¾¾çš„ CS229 çš„æ•°å­¦åŸºç¡€ï¼ˆçº¿æ€§ä»£æ•°ï¼‰ï¼Œæœ‰äººæŠŠå®ƒåšæˆäº†åœ¨çº¿ç¿»è¯‘ç‰ˆæœ¬ï¼&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;åœ¨çº¿é˜…è¯»ï¼&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ï¼&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æœºå™¨å­¦ä¹ æ•°å­¦ç²¾åï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é«˜ç­‰æ•°å­¦&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;åœ¨çº¿é˜…è¯»ï¼&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ï¼&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æœºå™¨å­¦ä¹ æ•°å­¦ç²¾åï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=3&amp;amp;sn=7d785108792eb64126812de876245387&amp;amp;chksm=970482b7a0730ba1099dcc3e2b05342907c0057d3d61eb125aa99c8649f186a49cad9e8a4660&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;çº¿æ€§ä»£æ•°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485707&amp;amp;idx=5&amp;amp;sn=af7c82f85740eac5672080d936869639&amp;amp;chksm=970482b7a0730ba13b6c4be0a40a0dc6c98c500ff9ea29dca61bba592513236144148320636c&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;åœ¨çº¿é˜…è¯»ï¼ï¼æœºå™¨å­¦ä¹ æ•°å­¦ç²¾åï¼šæ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-å››æœºå™¨å­¦ä¹ " class="anchor" aria-hidden="true" href="#å››æœºå™¨å­¦ä¹ "&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å››ã€æœºå™¨å­¦ä¹ &lt;/h2&gt;
&lt;p&gt;åŸåˆ›ä½œå“ä¸ºä»¥ä¸‹ä¸‰ä¸ªï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484544&amp;amp;idx=1&amp;amp;sn=c5b92a7c4a2bdca10d92ff06dbb315c4&amp;amp;chksm=97048f3ca073062a00c2e961daa9c17585d8b5cb8e73229b5b0364a6fc680b242dd7b409bd23&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å´æ©è¾¾æœºå™¨å­¦ä¹ è¯¾ç¨‹ç¬”è®°åŠèµ„æºï¼ˆgithub æ ‡æ˜Ÿ 12000+ï¼Œæä¾›ç™¾åº¦äº‘é•œåƒï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484580&amp;amp;idx=1&amp;amp;sn=7cf0ca2e05fc1ed71dff380bf1f60ff6&amp;amp;chksm=97048f18a073060e85ae439fd458bd976bf21366ca2b36ed3aeefda297b47d5c5a91196a4513&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹çš„ python ä»£ç å®ç°ï¼ˆgithub æ ‡æ˜Ÿ 7200+ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484360&amp;amp;idx=1&amp;amp;sn=d1859797428994bdb2b265aa4ddb98b9&amp;amp;chksm=97048874a07301627e89152fd2f84ba82d005348f7f04723a4e10facd463b8607691d6510678&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ¨èï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484360&amp;amp;idx=1&amp;amp;sn=d1859797428994bdb2b265aa4ddb98b9&amp;amp;chksm=97048874a07301627e89152fd2f84ba82d005348f7f04723a4e10facd463b8607691d6510678&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484360&amp;amp;idx=1&amp;amp;sn=d1859797428994bdb2b265aa4ddb98b9&amp;amp;chksm=97048874a07301627e89152fd2f84ba82d005348f7f04723a4e10facd463b8607691d6510678&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;åŸºäº Scikit-Learn å’Œ TensorFlowã€‹ä¸­æ–‡ç¿»è¯‘å’Œä»£ç ä¸‹è½½&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;åæ¥åˆåˆ¶ä½œæˆäº†åœ¨çº¿é˜…è¯»ç‰ˆæœ¬ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485997&amp;amp;idx=1&amp;amp;sn=975216fdafe7e09bc515c944aaf7a26a&amp;amp;chksm=97048191a0730887950f73c6774921eefd0e26da5b3568f100cf6c45f22e783514076624120d&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å¸¦ä½ å°‘èµ°å¼¯è·¯ï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247485997&amp;amp;idx=1&amp;amp;sn=975216fdafe7e09bc515c944aaf7a26a&amp;amp;chksm=97048191a0730887950f73c6774921eefd0e26da5b3568f100cf6c45f22e783514076624120d&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;äº”ç¯‡æ–‡ç« å­¦å®Œå´æ©è¾¾æœºå™¨å­¦ä¹ &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247486130&amp;amp;idx=2&amp;amp;sn=401a94b7db6e0e531ab3a745d3a1e3ed&amp;amp;chksm=9704810ea073081866aa98753412945734be9e217b8488c26bd0a66d54fbedf9c84f8c07873a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ç»å…¸å¤ç°ï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247486130&amp;amp;idx=2&amp;amp;sn=401a94b7db6e0e531ab3a745d3a1e3ed&amp;amp;chksm=9704810ea073081866aa98753412945734be9e217b8488c26bd0a66d54fbedf9c84f8c07873a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹çš„ä»£ç å®ç°ï¼ˆåœ¨çº¿é˜…è¯»ï¼&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247486130&amp;amp;idx=2&amp;amp;sn=401a94b7db6e0e531ab3a745d3a1e3ed&amp;amp;chksm=9704810ea073081866aa98753412945734be9e217b8488c26bd0a66d54fbedf9c84f8c07873a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-æœºå™¨å­¦ä¹ ç›¸å…³" class="anchor" aria-hidden="true" href="#æœºå™¨å­¦ä¹ ç›¸å…³"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æœºå™¨å­¦ä¹ ç›¸å…³&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484828&amp;amp;idx=1&amp;amp;sn=fbd9a75c363580e85d7000fd02ad56af&amp;amp;chksm=97048e20a07307369410f16924178d836587b4407abb4f3e5c9f3017f9adda9b5538fef6f912&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æœºå™¨å­¦ä¹ ç»ƒä¹ æ•°æ®å“ªé‡Œæ‰¾ï¼Ÿ&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484828&amp;amp;idx=1&amp;amp;sn=fbd9a75c363580e85d7000fd02ad56af&amp;amp;chksm=97048e20a07307369410f16924178d836587b4407abb4f3e5c9f3017f9adda9b5538fef6f912&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ä¸¤è¡Œä»£ç æå®šï¼&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484383&amp;amp;idx=1&amp;amp;sn=de695ff5e6a3e36a1c54a4a498e36a95&amp;amp;chksm=97048863a07301759227c74c174f6596c9da6fbf40b2fa276f87b1e845c808cacd70b51c7f6a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å­¦å®Œå¯ä»¥è§£å†³ 90%ä»¥ä¸Šçš„æ•°æ®åˆ†æé—®é¢˜-åˆ©ç”¨ python è¿›è¡Œæ•°æ®åˆ†æç¬¬äºŒç‰ˆï¼ˆä»£ç å’Œä¸­æ–‡ç¬”è®°ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484297&amp;amp;idx=1&amp;amp;sn=c862ea44abc4f90c52c5d1e9609bd9d7&amp;amp;chksm=97048835a07301239f1bcfcb1ef0eb66058dcb6cce2acfc8f04bbee6660f20d846fbca79a0f0&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ç‰¹å¾å·¥ç¨‹çš„å®å…¸-ã€ŠFeature Engineering for Machine Learningã€‹ç¿»è¯‘åŠä»£ç å®ç°&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-äº”æ·±åº¦å­¦ä¹ " class="anchor" aria-hidden="true" href="#äº”æ·±åº¦å­¦ä¹ "&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;äº”ã€æ·±åº¦å­¦ä¹ &lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-å´æ©è¾¾æ·±åº¦å­¦ä¹ è¯¾ç¨‹ç¬”è®°å’Œèµ„æº" class="anchor" aria-hidden="true" href="#å´æ©è¾¾æ·±åº¦å­¦ä¹ è¯¾ç¨‹ç¬”è®°å’Œèµ„æº"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å´æ©è¾¾æ·±åº¦å­¦ä¹ è¯¾ç¨‹ç¬”è®°å’Œèµ„æº&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484558&amp;amp;idx=1&amp;amp;sn=d2033198fa6227a4cd561c70a93f2e2a&amp;amp;chksm=97048f32a07306245660808fe46569d8999491108a3d37eb833a27c8f597cd3a2c18852df014&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å´æ©è¾¾æ·±åº¦å­¦ä¹ ç¬”è®°åŠè§†é¢‘ç­‰èµ„æºï¼ˆgithub æ ‡æ˜Ÿ 8500+ï¼Œæä¾›ç™¾åº¦äº‘é•œåƒï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-tensorflow-å…¥é—¨" class="anchor" aria-hidden="true" href="#tensorflow-å…¥é—¨"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow å…¥é—¨ï¼š&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484633&amp;amp;idx=1&amp;amp;sn=adf2dfee2bf09e6dab0a67d329bd0c50&amp;amp;chksm=97048f65a073067365daa419808913b50872a18ef9bb16a5011f90967eb89c335fb204c027d2&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å¸¦ä½ å°‘èµ°å¼¯è·¯ï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484633&amp;amp;idx=1&amp;amp;sn=adf2dfee2bf09e6dab0a67d329bd0c50&amp;amp;chksm=97048f65a073067365daa419808913b50872a18ef9bb16a5011f90967eb89c335fb204c027d2&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å¼ºçƒˆæ¨èçš„ TensorFlow å¿«é€Ÿå…¥é—¨èµ„æ–™å’Œç¿»è¯‘ï¼ˆå¯ä¸‹è½½ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-keras-å…¥é—¨" class="anchor" aria-hidden="true" href="#keras-å…¥é—¨"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;keras å…¥é—¨ï¼š&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484794&amp;amp;idx=1&amp;amp;sn=9b52adc9138fda3d404dff24e03d14b5&amp;amp;chksm=97048ec6a07307d01ae2c93aa887d3c6ac6ec5f9d2ed5a5b8260182e3f47fae3ea9f08a1a0bf&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å¸¦ä½ å°‘èµ°å¼¯è·¯ï¼šå¼ºçƒˆæ¨èçš„ Keras å¿«é€Ÿå…¥é—¨èµ„æ–™å’Œç¿»è¯‘ï¼ˆå¯ä¸‹è½½ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-pytorchå…¥é—¨" class="anchor" aria-hidden="true" href="#pytorchå…¥é—¨"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pytorchå…¥é—¨ï¼š&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484721&amp;amp;idx=2&amp;amp;sn=f2c6084354c912d91fbbb7f09adaf4ac&amp;amp;chksm=97048e8da073079b40d8a4cad5c016d762e1668ffd52f2d04bcb702e4530a9a275d73035ca9c&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å¸¦ä½ å°‘èµ°å¼¯è·¯ï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484721&amp;amp;idx=2&amp;amp;sn=f2c6084354c912d91fbbb7f09adaf4ac&amp;amp;chksm=97048e8da073079b40d8a4cad5c016d762e1668ffd52f2d04bcb702e4530a9a275d73035ca9c&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å¼ºçƒˆæ¨èçš„ Pytorch å¿«é€Ÿå…¥é—¨èµ„æ–™å’Œç¿»è¯‘ï¼ˆå¯ä¸‹è½½ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-å…¶ä»–èµ„æ–™" class="anchor" aria-hidden="true" href="#å…¶ä»–èµ„æ–™"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å…¶ä»–èµ„æ–™&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484411&amp;amp;idx=1&amp;amp;sn=0f95762a29249ea40b11edd24648c8d0&amp;amp;chksm=97048847a0730151f4bdd1d99ccf454206108fcf7f5b61b100f3dc39a7c46f926fc3da084c72&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é¦–å‘ï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484411&amp;amp;idx=1&amp;amp;sn=0f95762a29249ea40b11edd24648c8d0&amp;amp;chksm=97048847a0730151f4bdd1d99ccf454206108fcf7f5b61b100f3dc39a7c46f926fc3da084c72&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ å…¥é—¨å®å…¸-ã€Špython æ·±åº¦å­¦ä¹ ã€‹åŸæ–‡ä»£ç ä¸­æ–‡æ³¨é‡Šç‰ˆåŠç”µå­ä¹¦&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484393&amp;amp;idx=1&amp;amp;sn=c22c28eb324e052bdb5a399915c0b1c4&amp;amp;chksm=97048855a073014366257382f64e44b7ef6dcc59a0c3991abe0bb4128c0e471e28cf328ae9e4&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å¼ºçƒˆæ¨èçš„ TensorFlowã€Pytorch å’Œ Keras çš„æ ·ä¾‹èµ„æºï¼ˆæ·±åº¦å­¦ä¹ åˆå­¦è€…å¿…é¡»æ”¶è—ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484401&amp;amp;idx=1&amp;amp;sn=73e97612c8a8c6cbb65461f999c024ff&amp;amp;chksm=9704884da073015bfc9e3ee0d5c9765f9a48bee1091da319d024de63bc2d202c9a53ca6057b7&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Ubuntu 18.04 æ·±åº¦å­¦ä¹ ç¯å¢ƒé…ç½®ï¼ˆCUDA9.0+CUDDN7.4+TensorFolw1.8ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-å…­python-ç›¸å…³" class="anchor" aria-hidden="true" href="#å…­python-ç›¸å…³"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å…­ã€Python ç›¸å…³&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484426&amp;amp;idx=1&amp;amp;sn=c1971be3d85a8c247a5c77bfd925733d&amp;amp;chksm=97048fb6a07306a0ad6f51f1aa90225c685e46ad5adddf929a110cdd46ed9105ff1c1b1a90e9&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å­¦ä¹  python å…¥é—¨çš„ä¸ªäººå»ºè®®åŠèµ„æ–™&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484364&amp;amp;idx=1&amp;amp;sn=2d7cf6b8d8a4647a32459cb3798f3d76&amp;amp;chksm=97048870a0730166a7c2e9be889cb926b98585947d123500d958f2afe5afbfd21a5718684896&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Python ç¯å¢ƒçš„å®‰è£…ï¼ˆAnaconda+Jupyter notebook+Pycharmï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484361&amp;amp;idx=1&amp;amp;sn=086b8b9cbed37fd1932b6a8e6e517e2d&amp;amp;chksm=97048875a07301633726942278aac93d005fc673dcf740b8f6d6c75c544d0254828dc7e60b58&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Python ä»£ç å†™å¾—ä¸‘æ€ä¹ˆåŠï¼Ÿ&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484361&amp;amp;idx=1&amp;amp;sn=086b8b9cbed37fd1932b6a8e6e517e2d&amp;amp;chksm=97048875a07301633726942278aac93d005fc673dcf740b8f6d6c75c544d0254828dc7e60b58&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ¨èå‡ ä¸ªç¥å™¨æ‹¯æ•‘ä½ &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484368&amp;amp;idx=1&amp;amp;sn=9ec8ab2ab1f368b877799c90d0cdc671&amp;amp;chksm=9704886ca073017a452532d35129f4923b895c09e43e9e9debaa8261d895540462ab5dbda239&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Numpy ç»ƒä¹ é¢˜ 100 é¢˜-æé«˜ä½ çš„æ•°æ®åˆ†ææŠ€èƒ½&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484373&amp;amp;idx=1&amp;amp;sn=e48f845dccdec3c912e6cd16c7e363a8&amp;amp;chksm=97048869a073017fd8d4dd571807dd220940c7c9d729cf9c45fb66bab37ae0bc741272e79135&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Pandas ç»ƒä¹ é¢˜-æé«˜ä½ çš„æ•°æ®åˆ†ææŠ€èƒ½&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484389&amp;amp;idx=1&amp;amp;sn=7ab4f99f76b02a5198740c2b5fde91dc&amp;amp;chksm=97048859a073014f9fda1dc00eef5b47b78c15def4478463bc4bba773790474b225ff9606e8e&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;python ç»˜å›¾å·¥å…·åŸºç¡€-matplotlib å­¦ä¹ ä¹‹åŸºæœ¬ä½¿ç”¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484376&amp;amp;idx=1&amp;amp;sn=cd3ac06f4a0125eebb317578db3c4ec5&amp;amp;chksm=97048864a0730172f24c35e922573763213f2a2c0da4a6a8d2787d0f09315a3eac6e37634997&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ•°æ®å¯è§†åŒ–çš„åˆ©å™¨-Seaborn ç®€æ˜“å…¥é—¨&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-ä¸ƒnlp" class="anchor" aria-hidden="true" href="#ä¸ƒnlp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä¸ƒã€NLP&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484419&amp;amp;idx=1&amp;amp;sn=3a21e26b420fcd52d17cf3e1a456ee10&amp;amp;chksm=97048fbfa07306a9f0454fa330155e16127f6020525986ccc0fcf182c089b08b9b503c888a95&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ä¸€äº› NLP çš„å…¥é—¨èµ„æ–™å‚è€ƒ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484317&amp;amp;idx=1&amp;amp;sn=83e5d0bc7258c49c2427be4afa6cb588&amp;amp;chksm=97048821a0730137fc9df879f8e0d0ae9cbd88160d40750aaa4b3e5c7accd85e328e7c53c451&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ¨èï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484317&amp;amp;idx=1&amp;amp;sn=83e5d0bc7258c49c2427be4afa6cb588&amp;amp;chksm=97048821a0730137fc9df879f8e0d0ae9cbd88160d40750aaa4b3e5c7accd85e328e7c53c451&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å¸¸è§ NLP æ¨¡å‹çš„ä»£ç å®ç°ï¼ˆåŸºäº TensorFlow å’Œ PyTorchï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484301&amp;amp;idx=1&amp;amp;sn=ef50f185d8c41be4f54e141a9b4d0923&amp;amp;chksm=97048831a073012770f6b7bab14c3ff61e4215f24b38b9e98b701384ac798f2b6fee964816e6&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å›¾è§£ word2vecï¼ˆåŸæ–‡ç¿»è¯‘ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-å…«å­¦æœ¯æŠ€å·§" class="anchor" aria-hidden="true" href="#å…«å­¦æœ¯æŠ€å·§"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å…«ã€å­¦æœ¯æŠ€å·§&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484301&amp;amp;idx=1&amp;amp;sn=ef50f185d8c41be4f54e141a9b4d0923&amp;amp;chksm=97048831a073012770f6b7bab14c3ff61e4215f24b38b9e98b701384ac798f2b6fee964816e6&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ¨èå‡ ä¸ªæé«˜å·¥ä½œæ•ˆç‡çš„ç¥å™¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484429&amp;amp;idx=1&amp;amp;sn=5663338e5c76374512fa354d68b5a67d&amp;amp;chksm=97048fb1a07306a70bd1259038701cd7aeca49482a593646d1399166b87071b3ddc35ae4df4d&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ç§‘ç ”å·¥ä½œè€…çš„ç¥å™¨--zotero è®ºæ–‡ç®¡ç†å·¥å…·&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484279&amp;amp;idx=1&amp;amp;sn=786aa47073fa3522f4cce1493fba9f11&amp;amp;chksm=970488cba07301dd977fef7b761843dc6b84d26a62daff79e1121433090538b42aa3de5cb0fb&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;åˆ†äº«ï¼š&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&amp;amp;mid=2247484279&amp;amp;idx=1&amp;amp;sn=786aa47073fa3522f4cce1493fba9f11&amp;amp;chksm=970488cba07301dd977fef7b761843dc6b84d26a62daff79e1121433090538b42aa3de5cb0fb&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æˆ‘æ˜¯æ€ä¹ˆåœ¨ github ä¸Šæ‰¾åˆ°ä¼˜ç§€çš„ä»“åº“çš„ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-æ€»ç»“" class="anchor" aria-hidden="true" href="#æ€»ç»“"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ€»ç»“&lt;/h2&gt;
&lt;p&gt;æœ¬æ–‡æ€»ç»“äº†â€œ&lt;strong&gt;æœºå™¨å­¦ä¹ åˆå­¦è€…&lt;/strong&gt;â€å…¬ä¼—å·åˆ›ç«‹ä»¥æ¥çš„ç²¾é€‰&lt;strong&gt;åŸåˆ›&lt;/strong&gt;æ–‡ç« ï¼Œå¯ä»¥ä½œä¸º AI å…¥é—¨çš„å®å…¸ï¼Œè®©åˆå­¦è€…å°‘èµ°å¼¯è·¯ï¼Œå¼ºçƒˆå»ºè®®&lt;strong&gt;æ”¶è—&lt;/strong&gt;æœ¬æ–‡ï¼&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;&lt;a id="user-content-æœ¬ç«™2018å¹´çš„æ‰€æœ‰æ–‡ç« " class="anchor" aria-hidden="true" href="#æœ¬ç«™2018å¹´çš„æ‰€æœ‰æ–‡ç« "&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æœ¬ç«™2018å¹´çš„æ‰€æœ‰æ–‡ç« &lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;æœºå™¨å­¦ä¹ èµ„æº&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247484000&amp;amp;idx=1&amp;amp;sn=92f198b840073e79e1a267d15a48a279&amp;amp;chksm=c0791f79f70e966fccd525bc2ecb11d328a12f566ccdc781132ffeeb41c484c1f7757db03911&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;è‰¯å¿ƒæ¨èï¼šæœºå™¨å­¦ä¹ å…¥é—¨èµ„æ–™æ±‡æ€»åŠå­¦ä¹ å»ºè®®ï¼ˆ2018ç‰ˆï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483810&amp;amp;idx=1&amp;amp;sn=b35ff5aea7cc2a63c459c7f172263a2d&amp;amp;chksm=c0791cbbf70e95ad2e1cf7109cb50422bc07d0db6cbad502d11d3194aa92c608d5053f218cdd&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é»„æµ·å¹¿åšå£«çš„githubé•œåƒä¸‹è½½ï¼ˆæœºå™¨å­¦ä¹ åŠæ·±åº¦å­¦ä¹ èµ„æºï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483678&amp;amp;idx=1&amp;amp;sn=da7de252a11a1097e50381a27cb2cfb1&amp;amp;chksm=c0791c07f70e951178054c7d4acc88becfccf953f83a2d616f8508d8bfa3d31d8cdec0c6979f&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å´æ©è¾¾è€å¸ˆçš„æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ è¯¾ç¨‹ç¬”è®°æ‰“å°ç‰ˆ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483672&amp;amp;idx=1&amp;amp;sn=1845db207245efc9d33eeede5ea4b99e&amp;amp;chksm=c0791c01f70e9517cfb80b17d0e72836c5c573b33d9bcdc4ec57f02b6b73260d9c3e907a81e0&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å´æ©è¾¾è€å¸ˆæœºå™¨å­¦ä¹ æ•™ç¨‹ä¸­æ–‡ç¬”è®°-åœ¨çº¿ç‰ˆ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483784&amp;amp;idx=1&amp;amp;sn=6c158b9f13ebc612f0fb967323df16c4&amp;amp;chksm=c0791c91f70e95874606edc1a4a0fc38e5063d2634963c793d85c18e5d396be059176bd8d0d6&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Courseraæœºå™¨å­¦ä¹ è¯¾ç¨‹ä»£ç ä½œä¸š-Pythonç‰ˆæœ¬&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483694&amp;amp;idx=1&amp;amp;sn=f2d7c0be70d0fd17ee6a685cba6f399d&amp;amp;chksm=c0791c37f70e9521daf50bbee06f925505b61ec963397aba08af87925081f019f33ca27ffe5e&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Deeplearning.aiæ·±åº¦å­¦ä¹ è¯¾ç¨‹ç¬”è®°-åœ¨çº¿ç‰ˆ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483772&amp;amp;idx=1&amp;amp;sn=7046f9f8d5ae0329c6ab25d1fd8510d3&amp;amp;chksm=c0791c65f70e95734cfb3405658049209036c7097cbb17bc62816523acdc4c2ccca43d1bafdd&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é¦–å‘ï¼šæ·±åº¦å­¦ä¹ æµ‹è¯•é¢˜ä¸­è‹±å¯¹ç…§ç‰ˆ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483911&amp;amp;idx=1&amp;amp;sn=0aa891449692d85382a9b2b5016728bb&amp;amp;chksm=c0791f1ef70e960822c7b67b4216f6c7dc55b2c0f3f75ec7527523daea9ad25b3f86b94d5bec&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æœºå™¨å­¦ä¹ å¿…å¤‡å®å…¸-ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹çš„pythonä»£ç å®ç°ã€ç”µå­ä¹¦åŠè¯¾ä»¶&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483778&amp;amp;idx=1&amp;amp;sn=f1fe52a5451eef4e4c6d8463d01621ef&amp;amp;chksm=c0791c9bf70e958d4c57d0f9b2df37ae9cdbed304df030a27161a0ad7f9872926f217e6032d3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ–¯å¦ç¦å¤§å­¦æœºå™¨å­¦ä¹ è¯¾ç¨‹èµ„æ–™-å´æ©è¾¾è€å¸ˆä¸»è®²ï¼ˆ2008ç‰ˆï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483815&amp;amp;idx=1&amp;amp;sn=c220c09741e942b6d402f1090a2d72da&amp;amp;chksm=c0791cbef70e95a88745a8df9b3f2f0e2fe93591a21a3f4c331a920d74cdc6bf564ab33ff8df&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æœºå™¨å­¦ä¹ è®­ç»ƒç§˜ç±å®Œæ•´ä¸­æ–‡ç‰ˆä¸‹è½½ï¼ˆå´æ©è¾¾è€å¸ˆæ–°ä½œï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483804&amp;amp;idx=1&amp;amp;sn=9e862f6d127d70c2619e362c499e15b1&amp;amp;chksm=c0791c85f70e9593cd6106679feaac4b1eace9f717b788f9fbbae05c1b198308c45342ea6992&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é¦–å‘ï¼šæ·±åº¦å­¦ä¹ å…¥é—¨å®å…¸-ã€Špythonæ·±åº¦å­¦ä¹ ã€‹åŸæ–‡ä»£ç ä¸­æ–‡æ³¨é‡Šç‰ˆåŠç”µå­ä¹¦&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483961&amp;amp;idx=1&amp;amp;sn=7fa7e3e8a1cd4abf3e3357b2f6448118&amp;amp;chksm=c0791f20f70e9636821676c4302a1113016e547632c8e3872bcf815b41de95a7a5b25f3c5f62&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å¼ºçƒˆæ¨èçš„TensorFlowã€Pytorchå’ŒKerasçš„æ ·ä¾‹èµ„æºï¼ˆæ·±åº¦å­¦ä¹ åˆå­¦è€…å¿…é¡»æ”¶è—ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483707&amp;amp;idx=1&amp;amp;sn=2f28175ecea445129a5e62441aeebd37&amp;amp;chksm=c0791c22f70e95340f61a978147314dd02bf8ab1bd9c49f3b86f928e371dac0ead6eda64116a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æœºå™¨å­¦ä¹ å°æŠ„-ï¼ˆåƒèƒŒæ‰˜ç¦å•è¯ä¸€æ ·ç†è§£æœºå™¨å­¦ä¹ ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483860&amp;amp;idx=1&amp;amp;sn=514c1c053e31c4ced3bffe75e02f4b05&amp;amp;chksm=c0791ccdf70e95dba8c32d3b12836359159a2045019e8d5fb45ca578a9846f4601439b42bba3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ åˆå­¦è€…çš„å¦ä¸€ä»½å°æŠ„-ã€Šä¸€å¤©å­¦æ‡‚æ·±åº¦å­¦ä¹ ï¼ˆæå®æ¯…ï¼‰ã€‹ï¼ˆä¸­æ–‡æ ‡æ³¨ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483752&amp;amp;idx=1&amp;amp;sn=779b10f781fd7699040d7fcd5889b998&amp;amp;chksm=c0791c71f70e9567c91c9459641bff333c490a3326e0549fbdc58131fcc9fa5245f8785a54d9&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ä¸€äº›NLPçš„å…¥é—¨èµ„æ–™å‚è€ƒ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483930&amp;amp;idx=1&amp;amp;sn=31db561b207aed2b488ddb719ec7513f&amp;amp;chksm=c0791f03f70e9615586cf6be32352d0096da71563e87b20e3b115b206c1804d37bd3703fa5fe&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é©å‘½æ€§æå‡-å®‡å®™æœ€å¼ºçš„NLPé¢„è®­ç»ƒBERTæ¨¡å‹ï¼ˆé™„å®˜æ–¹ä»£ç ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483877&amp;amp;idx=1&amp;amp;sn=ca49142a7bded5c01ce39e25a004b5bd&amp;amp;chksm=c0791cfcf70e95eab42f6565f487c854c803cb072e225e9a30ebf25910ccef7b61ac794990b3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;50ä¸ªæœ€ä½³æœºå™¨å­¦ä¹ å…¬å…±æ•°æ®é›†&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;æœºå™¨å­¦ä¹ å¤§å¸ˆä¹‹ä½œ&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483886&amp;amp;idx=1&amp;amp;sn=e3a0c27f24446edb67b877d25007aec6&amp;amp;chksm=c0791cf7f70e95e1c601dc184bb681a7150c61fe5c4173e5abee72b1b3d9be71b5774b3d6a1a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é¦–å‘ï¼šå¾äº¦è¾¾è€å¸ˆçš„æœºå™¨å­¦ä¹ è¯¾ä»¶åŠä¸‹è½½ï¼ˆä¸­æ–‡ç›®å½•ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483789&amp;amp;idx=1&amp;amp;sn=c6cebaaede9d87fc2ea2b38532f89a7b&amp;amp;chksm=c0791c94f70e9582ff738a80d0138fbb7644dfa2e23f8ef83b9f09da92d4bc31f44773befbee&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æœºå™¨å­¦ä¹ çš„å®å…¸-åæ ¡ä¸“è€å¸ˆçš„ç¬”è®°&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;å¼€æºæ¡ˆä¾‹å’Œæ–¹æ¡ˆ&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483984&amp;amp;idx=1&amp;amp;sn=0fc0797e69ef856105bf747a43b4fa1e&amp;amp;chksm=c0791f49f70e965f218747c9ff986f3b702df2d5c4b7be80ab267ed9a4a55303c25fb001a83f&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é¦–å‘ï¼šå°å¤§æ—è½©ç”°ã€Šæœºå™¨å­¦ä¹ åŸºçŸ³ã€‹ç³»åˆ—è¯¾ç¨‹æ•™æçš„ä¹ é¢˜è§£ç­”å’Œå®ç°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483919&amp;amp;idx=1&amp;amp;sn=5fae97fbf1f94a8dec026f08abf0e9c5&amp;amp;chksm=c0791f16f70e9600a2bd47cade5117ad4a64088fca6fc45c51cd0ef6a41f7652650261f058d9&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;CTRé¢„ä¼°ç³»åˆ—ï¼šDeepCTR ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„CTRæ¨¡å‹åŒ…&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483956&amp;amp;idx=1&amp;amp;sn=5074fcdc8d63a6f2e9d89884d3f369ee&amp;amp;chksm=c0791f2df70e963bbde6058789f6d64c428c07c1f228b96b0056751d08e1b4cd5c6c752021e2&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å¼€æº-BDCI2018é¢å‘ç”µä¿¡è¡Œä¸šå­˜é‡ç”¨æˆ·çš„æ™ºèƒ½å¥—é¤ä¸ªæ€§åŒ–åŒ¹é…æ¨¡å‹Top1è§£å†³æ–¹æ¡ˆå’Œä»£ç &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483986&amp;amp;idx=1&amp;amp;sn=0c2c9e185c8a7afba37a212d2af947d5&amp;amp;chksm=c0791f4bf70e965da27dff285473d5b72dc9c58674da3261114a98c174f5fd480f85c4a7b3cc&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å¼€æº-BDCI2018ä¾›åº”é“¾éœ€æ±‚é¢„æµ‹æ¨¡å‹ç¬¬ä¸€åè§£å†³æ–¹æ¡ˆå’Œä»£ç &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483767&amp;amp;idx=1&amp;amp;sn=004de7eff7b8c0621ec25a635bec4b17&amp;amp;chksm=c0791c6ef70e95784174194f028477e1ff9e67b74a1a44a5443c5a659750e0a1610969d6d420&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æµ·æ´‹å¤§æ•°æ®åº”ç”¨æ€è€ƒï¼ˆé™„èµ„æ–™ä¸‹è½½ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;æœºå™¨å­¦ä¹ è®ºæ–‡&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483820&amp;amp;idx=1&amp;amp;sn=90fcd5fe6262e5a0e22212480e82ed9d&amp;amp;chksm=c0791cb5f70e95a372bc8bf0bfa382bed6a2dd1c0dab036ff4fae2668dccf660f62b2ec3fd07&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ–°è®ºæ–‡æ¨èï¼šAuto-Keras:è‡ªåŠ¨æœç´¢æ·±åº¦å­¦ä¹ æ¨¡å‹çš„ç½‘ç»œæ¶æ„å’Œè¶…å‚æ•°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483746&amp;amp;idx=1&amp;amp;sn=e26b8d4a573f87d28ddef4075d7cbe43&amp;amp;chksm=c0791c7bf70e956d8a3918f5441c85c4228f133b65ab57a1ca05a4a1050c760364e284eec89a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æœºå™¨å­¦ä¹ æ–°è®ºæ–‡æ¨è-ï¼ˆæˆå¯¹å…³ç³»çº¦æŸçš„éè´ŸçŸ©é˜µåˆ†è§£ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ç¡¬ä»¶å’Œç¯å¢ƒé…ç½®&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483901&amp;amp;idx=1&amp;amp;sn=f02bd7866ad172ef0c9669851dffde2a&amp;amp;chksm=c0791ce4f70e95f2343047e62d513c0106eedebc09cc25d1c45598ede21da8655a974c6a69c5&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;Ubuntu 18.04æ·±åº¦å­¦ä¹ ç¯å¢ƒé…ç½®ï¼ˆCUDA9.0+CUDNN7.4+TensorFlow1.8ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483665&amp;amp;idx=1&amp;amp;sn=331d52e5b52fd6eb2ba58c16a0fe3458&amp;amp;chksm=c0791c08f70e951e6c47254389112443e9d50ce919a7da25670a636756b090e500bf81580f1c&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ ä¸»æœºç¯å¢ƒé…ç½®: Win10+Nvidia GTX1080i+CUDA8.0+CUDDN6 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;PythonåŸºç¡€&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483690&amp;amp;idx=1&amp;amp;sn=701cc75092e7213b6a9b04b57b5e15f3&amp;amp;chksm=c0791c33f70e9525a1f48179802f17d50fc4deab5333cb8b142df20e15b6a117df353c168a45&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å­¦ä¹ pythonå…¥é—¨çš„ä¸ªäººå»ºè®®åŠèµ„æ–™&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483926&amp;amp;idx=1&amp;amp;sn=c19ee22819f98022e01da9343ad4cb85&amp;amp;chksm=c0791f0ff70e9619fd5a02a7cea9ae75bda478eedfcf2accc8ed2853a09b325c331bebfeb8ec&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ä¸¤å¤©å…¥é—¨PythonåŸºç¡€ï¼ˆé™„ä»£ç å®ç°ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247484020&amp;amp;idx=1&amp;amp;sn=c281956f8414f38c48cc8b358f9dcc26&amp;amp;chksm=c0791f6df70e967b33e4f828031dc3f070ca7b8ae855692245cb8f41480686122d56db4600a2&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å­¦å®Œå¯ä»¥è§£å†³90%ä»¥ä¸Šçš„æ•°æ®åˆ†æé—®é¢˜-åˆ©ç”¨pythonè¿›è¡Œæ•°æ®åˆ†æç¬¬äºŒç‰ˆï¼ˆä»£ç å’Œä¸­æ–‡ç¬”è®°ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483988&amp;amp;idx=1&amp;amp;sn=0cb80ff3f91f1bf43b14c968ae709576&amp;amp;chksm=c0791f4df70e965b806993b0fe1ead8dc65fa23a010341d0b2f2c5792a66233975895fc43e9e&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;pythonç»˜å›¾å·¥å…·åŸºç¡€-matplotlibå­¦ä¹ ä¹‹åŸºæœ¬ä½¿ç”¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247484006&amp;amp;idx=1&amp;amp;sn=1d0b49c0200e901915a99d29f0dadc79&amp;amp;chksm=c0791f7ff70e966929ed3a9b1358beb3b31a1106084f4332176476eafebf3a407fff2150d5b3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;é€‚åˆåˆå­¦è€…å¿«é€Ÿå…¥é—¨çš„Numpyå®æˆ˜å…¨é›†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247484014&amp;amp;idx=1&amp;amp;sn=25a415e5992f9f20c3e4e03dc1678b53&amp;amp;chksm=c0791f77f70e9661dd63cbf156de58fdc906e96f2a02dcef9bed7c35ab8754d9b255fab99aa1&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;pythonè¿›é˜¶ä¹‹å¤šè¿›ç¨‹ &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ç§‘ç ”å…¥é—¨&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483685&amp;amp;idx=1&amp;amp;sn=1cc418d56344a222a0b6c9a56bdc5026&amp;amp;chksm=c0791c3cf70e952ada01da3a790baa6325c2656a554566716ad96b83c7d1868770514aca8409&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æœºå™¨å­¦ä¹ çš„æ•°å­¦åŸºç¡€&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483979&amp;amp;idx=1&amp;amp;sn=9accf54de60fa6fe8f01cbd22e4df1a8&amp;amp;chksm=c0791f52f70e9644157b1c7a2ac0e3a0ba3e785ce45ff84ca22dbab50f7f0e542d7e6eb24b4f&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;åè¡€æ¨èæ”¶è—çš„å­¦ä½è®ºæ–‡æ’ç‰ˆæ•™ç¨‹ï¼ˆå®Œæ•´ç‰ˆï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483673&amp;amp;idx=1&amp;amp;sn=013a1171e4c44ce19ffe0ffb743b45a8&amp;amp;chksm=c0791c00f70e9516ca6835acdfefaf539d3e121890354c6aba45fb6802fa8709f3a41cb856a7&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ç§‘ç ”å·¥ä½œè€…çš„ç¥å™¨-zoteroè®ºæ–‡ç®¡ç†å·¥å…·&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483829&amp;amp;idx=1&amp;amp;sn=75e97f26a4c9112c8efa932f16a63c1a&amp;amp;chksm=c0791cacf70e95ba585cc7bc302107eb5e5a733a58fe927d7016b590e351300306e78513c60b&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å¦‚ä½•åšè§†é¢‘æ•™ç¨‹ç¬”è®°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483992&amp;amp;idx=1&amp;amp;sn=06c1765f0eb06fd28888b3625c4ccff1&amp;amp;chksm=c0791f41f70e96576c11aa7c301096f5788931ccb4c6adf532d40e6a5de14ef3024f629f4824&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ç»™åˆå­¦è€…æ¨èä¸€ä¸ªæ‘†è„±å˜é‡å‘½åçº ç»“çš„ç¥å™¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483760&amp;amp;idx=1&amp;amp;sn=60acdd5afac45fc6d17f5c714389079d&amp;amp;chksm=c0791c69f70e957fbf51c1d213b66817e05b9f5edf9ce128131b4697ceb122798d1bed7eed98&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;SQLè¯­æ³•å¦‚ä½•å…¥é—¨ï¼Ÿï¼ˆé™„èµ„æ–™ä¸‹è½½ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;é¡¹ç›®åˆä½œ&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483996&amp;amp;idx=1&amp;amp;sn=c0d7eb311071ef1eba98d89e274a35b6&amp;amp;chksm=c0791f45f70e96533089471e6732450739eaa3c07d07e90290652636778eea17e2eac2fa8916&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;å…¬ä¼—å·åˆä½œæŒ‡å—--ä¸æœ¬ç«™äº’ç›¸æ·»åŠ é•¿æœŸå¯è½¬è½½è´¦å·&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483924&amp;amp;idx=1&amp;amp;sn=751c23682abc116ec4c2401e942f4d4d&amp;amp;chksm=c0791f0df70e961bb602b004e70b5c3f780ca56fce49490d6e53cfdbbc374ed1c21c73bcf1a2&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;èµ äººç«ç‘°,æ‰‹æœ‰ä½™é¦™-æœŸå¾…åä½œæ›´æ–°æœºå™¨å­¦ä¹ çš„å…¬ç›Šé¡¹ç›® &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;è¿‡æ—¶æ–‡ç« &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;è¿‡æ—¶èµ„æ–™æŒ‡çš„æ˜¯æ–°çš„æ–‡ç« å·²ç»æ¶µç›–äº†æ—§æ–‡ç« å†…å®¹ï¼Œä¸éœ€è¦å†çœ‹äº†ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483872&amp;amp;idx=1&amp;amp;sn=a8d462ba6bbe582fd35d6a1240c15f86&amp;amp;chksm=c0791cf9f70e95ef60751437a698b0bee4188405bc9bedebea34611a96f7207c10a9b7309bfa&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æœºå™¨å­¦ä¹ ç®€æ˜“å…¥é—¨-é™„æ¨èå­¦ä¹ èµ„æ–™&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483792&amp;amp;idx=1&amp;amp;sn=5fe8d315183102be6f4ad92695d0f475&amp;amp;chksm=c0791c89f70e959fcbeda0ad8290093c8edc70b4fcb310073131bab1d01506795204726b7f07&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æœºå™¨å­¦ä¹ åˆå­¦è€…å…¬ä¼—å·ä¸‹è½½èµ„æºæ±‡æ€»ï¼ˆä¸€ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483914&amp;amp;idx=1&amp;amp;sn=cecee99473f6d7d33565389c6de4ed16&amp;amp;chksm=c0791f13f70e9605b69e84ee7e1a1a30ff3b4e78e19b71766831e4fa438d2422fed270b15685&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ è€…çš„å…¥é—¨ç¦åˆ©-Kerasæ·±åº¦å­¦ä¹ ç¬”è®°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483701&amp;amp;idx=1&amp;amp;sn=96ac60cf968284a7ae75b733a52df8bd&amp;amp;chksm=c0791c2cf70e953a45690656f2bd68c25287b2ba0a0c31db4debde5a38808c68ad5d82403e81&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;9æœˆå›½å†…å¤§æ•°æ®èµ›äº‹èµ„è®¯-å¥–æ± 1500ä¸‡ &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;æ‚è°ˆ&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483699&amp;amp;idx=1&amp;amp;sn=1518fb758a87a89fdf4614952baf4069&amp;amp;chksm=c0791c2af70e953c0cb2289ccf672b1f2968273ce1b01b41a8a874853668681c0381e629db33&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ä½ ä¸æ˜¯ä¸€ä¸ªäººåœ¨æˆ˜æ–—ï¼&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483740&amp;amp;idx=1&amp;amp;sn=e5cc3739911f4feb4c9bffed09de209b&amp;amp;chksm=c0791c45f70e9553b2eb33459ecc116327018013a288e0de5b33c39052f2103390ea2697f2ce&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;ä¸æœºå™¨å­¦ä¹ ç›¸å…³çš„æ•°å­¦å®¶ï¼Œä½ è®¤è¯†å‡ ä¸ªï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247483824&amp;amp;idx=1&amp;amp;sn=36f5cdfe9b3830ccb1566d9a4877ffa7&amp;amp;chksm=c0791ca9f70e95bfa5f49d6e411935766a8c1b17a0d831a41f30115a30bbbde485eeb2cf0c95&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;èµšçš„é’±éœ€è¦æœ‰å‘½æ¥èŠ±-é«˜è–ªçš„äº’è”ç½‘ä»ä¸šäººå‘˜æ›´éœ€è¦æ³¨æ„èº«ä½“å¥åº·&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fengdu78</author><guid isPermaLink="false">https://github.com/fengdu78/machine_learning_beginner</guid><pubDate>Sun, 09 Feb 2020 00:11:00 GMT</pubDate></item><item><title>bangoc123/learn-machine-learning-in-two-months #12 in Jupyter Notebook, Today</title><link>https://github.com/bangoc123/learn-machine-learning-in-two-months</link><description>&lt;p&gt;&lt;i&gt;Nhá»¯ng kiáº¿n thá»©c cáº§n thiáº¿t Ä‘á»ƒ há»c tá»‘t Machine Learning trong vÃ²ng 2 thÃ¡ng. Essential Knowledge for learning Machine Learning in two months.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="MD" data-path="README.MD"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-lá»™-trÃ¬nh-há»c-machine-learning-deep-learning-cho-ngÆ°á»i-má»›i-báº¯t-Ä‘áº§u" class="anchor" aria-hidden="true" href="#lá»™-trÃ¬nh-há»c-machine-learning-deep-learning-cho-ngÆ°á»i-má»›i-báº¯t-Ä‘áº§u"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lá»™ trÃ¬nh há»c Machine Learning, Deep Learning cho ngÆ°á»i má»›i báº¯t Ä‘áº§u&lt;/h2&gt;
&lt;p&gt;TÃ´i Ä‘Ã£ tá»«ng há»c Machine Learning trong vÃ²ng 2 thÃ¡ng vÃ  tÃ´i tin báº¡n cÅ©ng cÃ³ thá»ƒ lÃ m Ä‘Æ°á»£c.&lt;/p&gt;
&lt;p&gt;Lá»™ trÃ¬nh sáº½ giÃºp báº¡n náº¯m cháº¯c cÃ´ng nghá»‡ nÃ y tá»« cÆ¡ báº£n Ä‘áº¿n nÃ¢ng cao, xÃ¢y dá»±ng Machine Learning model tá»« python thuáº§n cho Ä‘áº¿n cÃ¡c thÆ° viá»‡n cao cáº¥p nhÆ° TensorFlow hay Keras. Äi sÃ¢u phÃ¢n tÃ­ch báº£n cháº¥t váº¥n Ä‘á» lÃ  giÃ¡ trá»‹ cá»‘t lÃµi cá»§a khÃ³a há»c nÃ y.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;P/S:&lt;/strong&gt; HÃ£y Ä‘á»ƒ láº¡i &lt;strong&gt;1 star&lt;/strong&gt; Ä‘á»ƒ team cÃ³ Ä‘á»™ng lá»±c xuáº¥t báº£n cÃ¡c pháº§n tiáº¿p theo vÃ  cÅ©ng Ä‘á»«ng quÃªn chia sáº» tá»›i báº¡n bÃ¨ cá»§a báº¡n.&lt;/p&gt;
&lt;p&gt;TÃ´i lÃ  má»™t trong cÃ¡c lecturer cá»§a lá»›p VietAI Hanoi khoÃ¡ 3 vÃ  khoÃ¡ 4. Hiá»‡n táº¡i tÃ´i Ä‘Ã£ vÃ o SÃ i GÃ²n nÃªn khÃ´ng tham gia tiáº¿p Ä‘á»ƒ giáº£ng dáº¡y nhÆ°ng váº«n Ä‘Ã³ng vai trÃ² Advisor cho lá»›p khoÃ¡ 5.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/8073cb447e2f2da7f44ab32e293189b7b4c5fbc0/68747470733a2f2f6c68332e676f6f676c6575736572636f6e74656e742e636f6d2f2d33415942613769544e54616c576d506b73555a306368356c7648747a4475484d57423641776c476769617059706f61514d575a416d513355426c4d4c504d48715132674c32416b476a433949645341704a3165624c586e3066344f684e782d6b697962636d7a674863614c57545a4c5241355258453353726a52464d776b74316a345551344b31304a5442677052675845555944344b513379536d32456f77774e70584c3841562d6948454251563174684a78494178547233467434764e6c456b6757583542644a556371684d6b665848476f77544e69555454726e3230423757686a55386335535a5576535453716d763543325a79306f52424c6f47527145306b555f7a494c5a71327958655042516b504c2d704c71307459376e75376777617a454c696644444a3169704f4d477276737857457435674649474d4f4a47323537764d6f32667147657a6d4349765337666c483465434b47546d6866556f644a377464717a35553863556c326e5f7a3473585f78765064645f78745f5448766b534a6b5a36714f5a55784d32786d46387065736d67496161414b4c5755736e74764d695179542d4d4c4d6468623744764d4361307a366f4c78664c333761663548746b5a395866494f624b38506d4e426b37545879455573594a4e316d643752644f5241495050557541337673712d72587834454c6f726d4d37535f665442685a424e7331575a3233354775787165455066574e73414d654c544132304b65626b64596d2d5945774e305356704a3657394f47395f3846635f6e35762d78376278576168696b58744a59636454786341574441437647787a552d71564c6b4c3351657533676e377041306e51706d4b66485547656f795f7643474e436f326c6a597039435264796b586f64683935704f6431316e714c485662626172486234544557625a4f53316246347159716a4a654e596176325156476e75784b594d39333369475249713434767a6b59783761755449534437475838316a52307868774f5469754f5a43564d4561304274433d77313136352d683838312d6e6f"&gt;&lt;img src="https://camo.githubusercontent.com/8073cb447e2f2da7f44ab32e293189b7b4c5fbc0/68747470733a2f2f6c68332e676f6f676c6575736572636f6e74656e742e636f6d2f2d33415942613769544e54616c576d506b73555a306368356c7648747a4475484d57423641776c476769617059706f61514d575a416d513355426c4d4c504d48715132674c32416b476a433949645341704a3165624c586e3066344f684e782d6b697962636d7a674863614c57545a4c5241355258453353726a52464d776b74316a345551344b31304a5442677052675845555944344b513379536d32456f77774e70584c3841562d6948454251563174684a78494178547233467434764e6c456b6757583542644a556371684d6b665848476f77544e69555454726e3230423757686a55386335535a5576535453716d763543325a79306f52424c6f47527145306b555f7a494c5a71327958655042516b504c2d704c71307459376e75376777617a454c696644444a3169704f4d477276737857457435674649474d4f4a47323537764d6f32667147657a6d4349765337666c483465434b47546d6866556f644a377464717a35553863556c326e5f7a3473585f78765064645f78745f5448766b534a6b5a36714f5a55784d32786d46387065736d67496161414b4c5755736e74764d695179542d4d4c4d6468623744764d4361307a366f4c78664c333761663548746b5a395866494f624b38506d4e426b37545879455573594a4e316d643752644f5241495050557541337673712d72587834454c6f726d4d37535f665442685a424e7331575a3233354775787165455066574e73414d654c544132304b65626b64596d2d5945774e305356704a3657394f47395f3846635f6e35762d78376278576168696b58744a59636454786341574441437647787a552d71564c6b4c3351657533676e377041306e51706d4b66485547656f795f7643474e436f326c6a597039435264796b586f64683935704f6431316e714c485662626172486234544557625a4f53316246347159716a4a654e596176325156476e75784b594d39333369475249713434767a6b59783761755449534437475838316a52307868774f5469754f5a43564d4561304274433d77313136352d683838312d6e6f" width="500" data-canonical-src="https://lh3.googleusercontent.com/-3AYBa7iTNTalWmPksUZ0ch5lvHtzDuHMWB6AwlGgiapYpoaQMWZAmQ3UBlMLPMHqQ2gL2AkGjC9IdSApJ1ebLXn0f4OhNx-kiybcmzgHcaLWTZLRA5RXE3SrjRFMwkt1j4UQ4K10JTBgpRgXEUYD4KQ3ySm2EowwNpXL8AV-iHEBQV1thJxIAxTr3Ft4vNlEkgWX5BdJUcqhMkfXHGowTNiUTTrn20B7WhjU8c5SZUvSTSqmv5C2Zy0oRBLoGRqE0kU_zILZq2yXePBQkPL-pLq0tY7nu7gwazELifDDJ1ipOMGrvsxWEt5gFIGMOJG257vMo2fqGezmCIvS7flH4eCKGTmhfUodJ7tdqz5U8cUl2n_z4sX_xvPdd_xt_THvkSJkZ6qOZUxM2xmF8pesmgIaaAKLWUsntvMiQyT-MLMdhb7DvMCa0z6oLxfL37af5HtkZ9XfIObK8PmNBk7TXyEUsYJN1md7RdORAIPPUuA3vsq-rXx4ELormM7S_fTBhZBNs1WZ235GuxqeEPfWNsAMeLTA20KebkdYm-YEwN0SVpJ6W9OG9_8Fc_n5v-x7bxWahikXtJYcdTxcAWDACvGxzU-qVLkL3Qeu3gn7pA0nQpmKfHUGeoy_vCGNCo2ljYp9CRdykXodh95pOd11nqLHVbbarHb4TEWbZOS1bF4qYqjJeNYav2QVGnuxKYM933iGRIq44vzkYx7auTISD7GX81jR0xhwOTiuOZCVMEa0BtC=w1165-h881-no" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;NgÃ y 10/12/2019, sau 2 vÃ²ng phá»ng váº¥n, Google chÃ­nh thá»©c cÃ´ng nháº­n tÃ´i lÃ  Google Developer Expert in Machine Learning. TÃ´i nghÄ© tÃ´i lÃ  ML GDE Ä‘áº§u tiÃªn táº¡i Viá»‡t Nam.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./images/gde.png"&gt;&lt;img src="./images/gde.png" width="500" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;TÃ¬m tÃ´i &lt;a href="https://developers.google.com/community/experts/directory" rel="nofollow"&gt;á»Ÿ Ä‘Ã¢y&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;BÃ i giáº£ng tÃ´i thÃ­ch dáº¡y nháº¥t á»Ÿ VietAI chÃ­nh lÃ  máº¡ng Neural Network.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./images/class.jpg"&gt;&lt;img src="./images/class.jpg" width="500" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Giá»›i thiá»‡u vá» thÃ nh tá»±u vÃ  má»¥c tiÃªu cá»§a VietAI &lt;a href="https://docs.google.com/presentation/d/1A_oDWZyC6NhYPeHNrWJbESxSPUT7f0Gg-PLfXDtVKus/edit?usp=sharing" rel="nofollow"&gt;táº¡i Ä‘Ã¢y&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-má»¥c-lá»¥c" class="anchor" aria-hidden="true" href="#má»¥c-lá»¥c"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Má»¥c lá»¥c&lt;/h3&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/math"&gt;1. Kiáº¿n thá»©c toÃ¡n há»c cáº§n thiáº¿t&lt;/a&gt; (HoÃ n táº¥t)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/python-tutorials"&gt;2. Ká»¹ nÄƒng láº­p trÃ¬nh Python&lt;/a&gt; (HoÃ n táº¥t)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/numpy"&gt;3. ThÆ° viá»‡n Numpy vÃ  TensorFlow&lt;/a&gt; (HoÃ n táº¥t)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/blob/master/models/linear-regression/"&gt;4. BÃ i toÃ¡n há»“i quy (Regression)&lt;/a&gt; (HoÃ n táº¥t)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/blob/master/models/logistic-regression"&gt;5. BÃ i toÃ¡n phÃ¢n loáº¡i (Classification)&lt;/a&gt; (HoÃ n táº¥t)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/blob/master/models/random-forests"&gt;6. XÃ¢y dá»±ng mÃ´ hÃ¬nh Decision Trees vÃ  Random Forests &lt;/a&gt; (ChÆ°a HoÃ n táº¥t)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/models/nn"&gt;7. XÃ¢y dá»±ng máº¡ng Neural Network&lt;/a&gt; (Äang tiáº¿n hÃ nh)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/models/cnn"&gt;8. XÃ¢y dá»±ng máº¡ng Convolutional Neural Network (CNN)&lt;/a&gt; (ChÆ°a HoÃ n táº¥t)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/models/rnn"&gt;9. XÃ¢y dá»±ng máº¡ng Recurrent Neural Network (RNN)&lt;/a&gt; (ChÆ°a HoÃ n táº¥t)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/gan"&gt;10. MÃ´ hÃ¬nh sinh GAN vÃ  CycleGAN&lt;/a&gt; (Äang tiáº¿n hÃ nh)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/deployment/distributed-tensorflow"&gt;11. Triá»ƒn khai (Deploy) Machine Learning Model trÃªn Production&lt;/a&gt; (Äang tiáº¿n hÃ nh)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/deployment/tensorflow-browser"&gt;12. Machine Learning trÃªn trÃ¬nh duyá»‡t vÃ  TensorFlowJS&lt;/a&gt; (HoÃ n táº¥t)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/tf2.0"&gt;13. Cáº­p nháº­t má»›i nháº¥t&lt;/a&gt; (Äang tiáº¿n hÃ nh)
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/tf2.0"&gt;TensorFlow 2.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/articles/GradientPaperSpace.MD"&gt;Tráº£i nghiá»‡m PaperSpace Gradient Community&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bangoc123/learn-machine-learning-in-two-months/tree/master/algorithms"&gt;14. Ã”n luyá»‡n thuáº­t toÃ¡n má»—i ngÃ y&lt;/a&gt; (Äang tiáº¿n hÃ nh)
&lt;ul&gt;
&lt;li&gt;&lt;a href="./algorithms/graph/backtracking/backtracking.MD"&gt;Backtracking Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>bangoc123</author><guid isPermaLink="false">https://github.com/bangoc123/learn-machine-learning-in-two-months</guid><pubDate>Sun, 09 Feb 2020 00:12:00 GMT</pubDate></item><item><title>guipsamora/pandas_exercises #13 in Jupyter Notebook, Today</title><link>https://github.com/guipsamora/pandas_exercises</link><description>&lt;p&gt;&lt;i&gt;Practice your pandas skills!&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pandas-exercises" class="anchor" aria-hidden="true" href="#pandas-exercises"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pandas Exercises&lt;/h1&gt;
&lt;p&gt;Fed up with a ton of tutorials but no easy way to find exercises I decided to create a repo just with exercises to practice pandas.
Don't get me wrong, tutorials are great resources, but to learn is to do. So unless you practice you won't learn.&lt;/p&gt;
&lt;p&gt;There will be three different types of files:&lt;br&gt;
Â Â Â Â Â Â 1. Exercise instructions&lt;br&gt;
Â Â Â Â Â Â 2. Solutions without code&lt;br&gt;
Â Â Â Â Â Â 3. Solutions with code and comments&lt;/p&gt;
&lt;p&gt;My suggestion is that you learn a topic in a tutorial, video or documentation and then do the first exercises.
Learn one more topic and do more exercises. If you are stuck, don't go directly to the solution with code files. Check the solutions only and try to get the correct answer.&lt;/p&gt;
&lt;p&gt;Suggestions and collaborations are more than welcome.&lt;g-emoji class="g-emoji" alias="slightly_smiling_face" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f642.png"&gt;ğŸ™‚&lt;/g-emoji&gt; Please open an issue or make a PR indicating the exercise and your problem/solution.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-lessons" class="anchor" aria-hidden="true" href="#lessons"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lessons&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="#getting-and-knowing"&gt;Getting and knowing&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#merge"&gt;Merge&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#time-series"&gt;Time Series&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="#filtering-and-sorting"&gt;Filtering and Sorting&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#stats"&gt;Stats&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#deleting"&gt;Deleting&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="#grouping"&gt;Grouping&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#visualization"&gt;Visualization&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Indexing&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="#apply"&gt;Apply&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#creating-series-and-dataframes"&gt;Creating Series and DataFrames&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Exporting&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-getting-and-knowing" class="anchor" aria-hidden="true" href="#getting-and-knowing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data"&gt;Getting and knowing&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data/Chipotle"&gt;Chipotle&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data/Occupation"&gt;Occupation&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data/World%20Food%20Facts"&gt;World Food Facts&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-filtering-and-sorting" class="anchor" aria-hidden="true" href="#filtering-and-sorting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting"&gt;Filtering and Sorting&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting/Chipotle"&gt;Chipotle&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting/Euro12"&gt;Euro12&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting/Fictional%20Army"&gt;Fictional Army&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-grouping" class="anchor" aria-hidden="true" href="#grouping"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping"&gt;Grouping&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping/Alcohol_Consumption"&gt;Alcohol Consumption&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping/Occupation"&gt;Occupation&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping/Regiment"&gt;Regiment&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-apply" class="anchor" aria-hidden="true" href="#apply"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/04_Apply"&gt;Apply&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/04_Apply/Students_Alcohol_Consumption"&gt;Students Alcohol Consumption&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/04_Apply/US_Crime_Rates"&gt;US_Crime_Rates&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-merge" class="anchor" aria-hidden="true" href="#merge"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge"&gt;Merge&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge/Auto_MPG"&gt;Auto_MPG&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge/Fictitous%20Names"&gt;Fictitious Names&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge/Housing%20Market"&gt;House Market&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-stats" class="anchor" aria-hidden="true" href="#stats"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/06_Stats"&gt;Stats&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/06_Stats/US_Baby_Names"&gt;US_Baby_Names&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/06_Stats/Wind_Stats"&gt;Wind_Stats&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-visualization" class="anchor" aria-hidden="true" href="#visualization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization"&gt;Visualization&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Chipotle"&gt;Chipotle&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Titanic_Desaster"&gt;Titanic Disaster&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Scores"&gt;Scores&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Online_Retail"&gt;Online Retail&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Tips"&gt;Tips&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-creating-series-and-dataframes" class="anchor" aria-hidden="true" href="#creating-series-and-dataframes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/08_Creating_Series_and_DataFrames"&gt;Creating Series and DataFrames&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/08_Creating_Series_and_DataFrames/Pokemon"&gt;Pokemon&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-time-series" class="anchor" aria-hidden="true" href="#time-series"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series"&gt;Time Series&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series/Apple_Stock"&gt;Apple_Stock&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series/Getting_Financial_Data"&gt;Getting_Financial_Data&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series/Getting_Financial_Data"&gt;Investor_Flow_of_Funds_US&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-deleting" class="anchor" aria-hidden="true" href="#deleting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/10_Deleting"&gt;Deleting&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/10_Deleting/Iris"&gt;Iris&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/guipsamora/pandas_exercises/tree/master/10_Deleting/Wine"&gt;Wine&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-video-solutions" class="anchor" aria-hidden="true" href="#video-solutions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Video Solutions&lt;/h1&gt;
&lt;p&gt;Video tutorials of data scientists working through the above exercises:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=pu3IpU937xs&amp;amp;list=PLgJhDSE2ZLxaY_DigHeiIDC1cD09rXgJv" rel="nofollow"&gt;Data Talks - Pandas Learning By Doing&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>guipsamora</author><guid isPermaLink="false">https://github.com/guipsamora/pandas_exercises</guid><pubDate>Sun, 09 Feb 2020 00:13:00 GMT</pubDate></item><item><title>qiaoxu123/Self-Driving-Cars #14 in Jupyter Notebook, Today</title><link>https://github.com/qiaoxu123/Self-Driving-Cars</link><description>&lt;p&gt;&lt;i&gt;Coursera Open Courses from  University of Toronto&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-thanks" class="anchor" aria-hidden="true" href="#thanks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Thanks&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://www.coursera.org/specializations/self-driving-cars" rel="nofollow"&gt;&lt;strong&gt;Coursera  Self-Driving Cars&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanks to the teachers in this courses very much !!!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I have to say that this courses surprise me a lot , as a postgraduate student aimed at working on automotive motion planning ,it is so hard to find so completed and excited sources, especially in China. So, i think it is beneficial and essential for everyone who aims at working or doing researching work on automotive. and make the decision to take the note and share the all sources of the courses.&lt;/p&gt;
&lt;p&gt;This repository includes all the videos, subtitles and PDFs of this courses. You can download and watch it. Especially, i make a rough notebook based on the subtitles for better review. and i will step by step to complete it. Everyone can read and submit issue , i will try to replay it. Finally, hope everyone can enjoy it !!!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://qiaoxu123.github.io/Self-Driving-Cars/#/" rel="nofollow"&gt;Notebook(Incomplete)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Class links:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/learn/intro-self-driving-cars" rel="nofollow"&gt;1. Introduction to Self-Driving Cars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/learn/state-estimation-localization-self-driving-cars" rel="nofollow"&gt;2. State Estimation and Localization for Self-Driving Cars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/learn/visual-perception-self-driving-cars" rel="nofollow"&gt;3. Visual Perception for Self-Driving Cars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/learn/motion-planning-self-driving-cars" rel="nofollow"&gt;4. Motion Planning for Self-Driving Cars&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-1-overview" class="anchor" aria-hidden="true" href="#1-overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Overview&lt;/h2&gt;
&lt;p&gt;Be at the forefront of the autonomous driving industry. With market researchers predicting a $42-billion market and more than 20 million self-driving cars on the road by 2025, the next big job boom is right around the corner.&lt;/p&gt;
&lt;p&gt;This Specialization gives you a comprehensive understanding of state-of-the-art engineering practices used in the self-driving car industry. You'll get to interact with real data sets from an autonomous vehicle (AV)â€•all through hands-on projects using the open source simulator CARLA.&lt;/p&gt;
&lt;p&gt;Throughout your courses, youâ€™ll hear from industry experts who work at companies like Oxbotica and Zoox as they share insights about autonomous technology and how that is powering job growth within the field.&lt;/p&gt;
&lt;p&gt;Youâ€™ll learn from a highly realistic driving environment that features 3D pedestrian modelling and environmental conditions. When you complete the Specialization successfully, youâ€™ll be able to build your own self-driving software stack and be ready to apply for jobs in the autonomous vehicle industry.&lt;/p&gt;
&lt;p&gt;It is recommended that you have some background in linear algebra, probability, statistics, calculus, physics, control theory, and Python programming. You will need these specifications in order to effectively run the CARLA simulator: Windows 7 64-bit (or later) or Ubuntu 16.04 (or later), Quad-core Intel or AMD processor (2.5 GHz or faster), NVIDIA GeForce 470 GTX or AMD Radeon 6870 HD series card or higher, 8 GB RAM, and OpenGL 3 or greater (for Linux computers).&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-2-learn-objects" class="anchor" aria-hidden="true" href="#2-learn-objects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Learn Objects&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Understand the detailed architecture and components of a self-driving car software stack&lt;/li&gt;
&lt;li&gt;Implement methods for static and dynamic object detection, localization and mapping, behaviour and maneuver planning, and vehicle control&lt;/li&gt;
&lt;li&gt;Use realistic vehicle physics, complete sensor suite: camera, LIDAR, GPS/INS, wheel odometry, depth map, semantic segmentation, object bounding boxes&lt;/li&gt;
&lt;li&gt;Demonstrate skills in CARLA and build programs with Python&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>qiaoxu123</author><guid isPermaLink="false">https://github.com/qiaoxu123/Self-Driving-Cars</guid><pubDate>Sun, 09 Feb 2020 00:14:00 GMT</pubDate></item><item><title>Mikoto10032/DeepLearning #15 in Jupyter Notebook, Today</title><link>https://github.com/Mikoto10032/DeepLearning</link><description>&lt;p&gt;&lt;i&gt;æ·±åº¦å­¦ä¹ å…¥é—¨æ•™ç¨‹&amp;&amp;ä¼˜ç§€æ–‡ç« &amp;&amp;Deep Learning Tutorial&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deeplearning-tutorial" class="anchor" aria-hidden="true" href="#deeplearning-tutorial"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DeepLearning Tutorial&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-ä¸€-å…¥é—¨èµ„æ–™" class="anchor" aria-hidden="true" href="#ä¸€-å…¥é—¨èµ„æ–™"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä¸€. å…¥é—¨èµ„æ–™&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/64052743" rel="nofollow"&gt;&lt;strong&gt;å®Œå¤‡çš„ AI å­¦ä¹ è·¯çº¿ï¼Œæœ€è¯¦ç»†çš„ä¸­è‹±æ–‡èµ„æºæ•´ç†&lt;/strong&gt;&lt;/a&gt; &lt;g-emoji class="g-emoji" alias="star" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png"&gt;â­ï¸&lt;/g-emoji&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/apachecn/AiLearning"&gt;AiLearning: æœºå™¨å­¦ä¹  - MachineLearning - MLã€æ·±åº¦å­¦ä¹  - DeepLearning - DLã€è‡ªç„¶è¯­è¨€å¤„ç† NL&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-æ•°å­¦åŸºç¡€" class="anchor" aria-hidden="true" href="#æ•°å­¦åŸºç¡€"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ•°å­¦åŸºç¡€&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="notes/Images/MathematicalBasis.jpg"&gt;&lt;img src="notes/Images/MathematicalBasis.jpg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E7%9F%A9%E9%98%B5%E5%BE%AE%E7%A7%AF%E5%88%86" rel="nofollow"&gt;çŸ©é˜µå¾®ç§¯åˆ†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fengdu78/Data-Science-Notes/tree/master/0.math/0.basic"&gt;æœºå™¨å­¦ä¹ çš„æ•°å­¦åŸºç¡€&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fengdu78/Data-Science-Notes/tree/master/0.math/1.CS229"&gt;CS229çº¿æ€§ä»£æ•°ä¸æ¦‚ç‡è®ºåŸºç¡€&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-æœºå™¨å­¦ä¹ åŸºç¡€" class="anchor" aria-hidden="true" href="#æœºå™¨å­¦ä¹ åŸºç¡€"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æœºå™¨å­¦ä¹ åŸºç¡€&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-å¿«é€Ÿå…¥é—¨" class="anchor" aria-hidden="true" href="#å¿«é€Ÿå…¥é—¨"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å¿«é€Ÿå…¥é—¨&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;æ¨èé¡ºåºç”±å‰åˆ°å&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.tensorinfinity.com/paper_18.html" rel="nofollow"&gt;æœºå™¨å­¦ä¹ ç®—æ³•åœ°å›¾&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%5BML-Coursera%5D%5B2014%5D%5BAndrew%20Ng%5D/%5B2014%5D%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%E5%AE%8C%E6%95%B4%E7%89%88v5.1.pdf"&gt;æœºå™¨å­¦ä¹  å´æ©è¾¾ Courseraä¸ªäººç¬”è®°&lt;/a&gt; Â &amp;amp;&amp;amp; &lt;a href="https://www.coursera.org/learn/machine-learning" rel="nofollow"&gt;è§†é¢‘ï¼ˆå«å®˜æ–¹ç¬”è®°ï¼‰&lt;/a&gt; Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://kivy-cn.github.io/Stanford-CS-229-CN/#/" rel="nofollow"&gt;CS229 è¯¾ç¨‹è®²ä¹‰ä¸­æ–‡ç¿»è¯‘&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%5BML-CS229%5D%5B2011%5D%5BAndrew%20NG%5D/%5B2011%5D%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E4%B8%AA%E4%BA%BA%E7%AC%94.pdf"&gt;æœºå™¨å­¦ä¹  å´æ©è¾¾ cs229ä¸ªäººç¬”è®°&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="http://cs229.stanford.edu/" rel="nofollow"&gt;å®˜ç½‘ï¼ˆç¬”è®°ï¼‰&lt;/a&gt; Â &amp;amp;&amp;amp; &lt;a href="http://open.163.com/special/opencourse/machinelearning.html" rel="nofollow"&gt;è§†é¢‘ï¼ˆä¸­æ–‡å­—å¹•ï¼‰&lt;/a&gt; Â &lt;/li&gt;
&lt;li&gt;&lt;a href="http://themlbook.com/wiki/doku.php" rel="nofollow"&gt;ç™¾é¡µæœºå™¨å­¦ä¹ &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-æ·±å…¥ç†è§£" class="anchor" aria-hidden="true" href="#æ·±å…¥ç†è§£"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ·±å…¥ç†è§£&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;æ¨èé¡ºåºç”±å‰åˆ°å&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/tree/master/books/%E6%9D%8E%E8%88%AA-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0"&gt;ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹æèˆª&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0PRML_Chinese_vision.pdf"&gt;ã€Šæ¨¡å¼è¯†åˆ«ä¸æœºå™¨å­¦ä¹ ã€‹ Christopher Bishop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%91%A8%E5%BF%97%E5%8D%8E.pdf"&gt;ã€Šæœºå™¨å­¦ä¹ ã€‹ å‘¨å¿—å&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%20%E4%B8%AD%E6%96%87%E5%8F%8C%E9%A1%B5%E7%89%88.pdf"&gt;ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹ PelerHarrington&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s?__biz=MzAxMjcyNjE5MQ==&amp;amp;mid=2650488718&amp;amp;idx=1&amp;amp;sn=815a79d27d500f0fb8db1fe1fc6cfe48&amp;amp;chksm=83a2e54eb4d56c58a0989654f920d64ad2784ce52e4b2bc6883974257cf475c9983f05fb88c1&amp;amp;scene=0&amp;amp;xtrack=1&amp;amp;ascene=14&amp;amp;devicetype=android-28&amp;amp;version=27000339&amp;amp;nettype=WIFI&amp;amp;abtest_cookie=AwABAAoACwATAAQAI5ceAFaZHgDQmR4A3JkeAAAA&amp;amp;lang=zh_CN&amp;amp;pass_ticket=oEB1108Pes6HkdxEITmBjTb2Glju5%2BEGqHZKz50fMg0rgK4l9Fodlbe%2FDm96iX57&amp;amp;wx_header=1" rel="nofollow"&gt;æœºå™¨å­¦ä¹ ä¸æ·±åº¦å­¦ä¹ ä¹¦å•&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-æ·±åº¦å­¦ä¹ åŸºç¡€" class="anchor" aria-hidden="true" href="#æ·±åº¦å­¦ä¹ åŸºç¡€"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ·±åº¦å­¦ä¹ åŸºç¡€&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-å¿«é€Ÿå…¥é—¨-1" class="anchor" aria-hidden="true" href="#å¿«é€Ÿå…¥é—¨-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å¿«é€Ÿå…¥é—¨&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;æ¨èé¡ºåºç”±å‰åˆ°å&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dformoso/deeplearning-mindmap"&gt;æ·±åº¦å­¦ä¹ æ€ç»´å¯¼å›¾&lt;/a&gt;	&amp;amp;&amp;amp; &lt;a href="http://www.tensorinfinity.com/paper_158.html" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ ç®—æ³•åœ°å›¾&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B.pdf"&gt;ã€Šæ–¯å¦ç¦å¤§å­¦æ·±åº¦å­¦ä¹ åŸºç¡€æ•™ç¨‹ã€‹ Andrew Ngï¼ˆå´æ©è¾¾ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ai-start.com/dl2017/" rel="nofollow"&gt;æ·±åº¦å­¦ä¹  å´æ©è¾¾ ä¸ªäººç¬”è®°&lt;/a&gt; Â &amp;amp;&amp;amp; &lt;a href="http://mooc.study.163.com/smartSpec/detail/1001319001.htm" rel="nofollow"&gt;è§†é¢‘&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://deeplearning.mit.edu/" rel="nofollow"&gt;MITæ·±åº¦å­¦ä¹ åŸºç¡€-2019è§†é¢‘è¯¾ç¨‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/index.html" rel="nofollow"&gt;å°æ¹¾å¤§å­¦ï¼ˆNTUï¼‰æå®æ¯…æ•™æˆè¯¾ç¨‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/iamtrask/Grokking-Deep-Learning"&gt;å›¾è§£æ·±åº¦å­¦ä¹ _Grokking-Deep-Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0neural%20networks%20and%20deep-learning-%E4%B8%AD%E6%96%87_ALL.pdf"&gt;ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹ Michael Nielsen&lt;/a&gt; Â  Â &lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.toronto.edu/~tijmen/csc321/" rel="nofollow"&gt; CS321-Hinton&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://web.stanford.edu/class/cs230/" rel="nofollow"&gt; CS230: Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://rail.eecs.berkeley.edu/deeprlcourse/resources/" rel="nofollow"&gt; CS294-112&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-è®¡ç®—æœºè§†è§‰" class="anchor" aria-hidden="true" href="#è®¡ç®—æœºè§†è§‰"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è®¡ç®—æœºè§†è§‰&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21930884" rel="nofollow"&gt;CS231 æé£é£ å·²æˆæƒä¸ªäººç¿»è¯‘ç¬”è®°&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="http://study.163.com/course/courseMain.htm?courseId=1003223001" rel="nofollow"&gt;è§†é¢‘&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/WNkzfvYtEO5zJoe_-yAPow" rel="nofollow"&gt;è®¡ç®—æœºè§†è§‰ç ”ç©¶æ–¹å‘&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-è‡ªç„¶è¯­è¨€å¤„ç†" class="anchor" aria-hidden="true" href="#è‡ªç„¶è¯­è¨€å¤„ç†"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è‡ªç„¶è¯­è¨€å¤„ç†&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://web.stanford.edu/class/cs224n/index.html" rel="nofollow"&gt;CS224n: Natural Language Processing with Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/FudanNLP/nlp-beginner"&gt;NLPä¸Šæ‰‹æ•™ç¨‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58874484" rel="nofollow"&gt;NLPå…¥é—¨æ¨èä¹¦ç›®ï¼ˆ2019ç‰ˆï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-æ·±åº¦å¼ºåŒ–å­¦ä¹ " class="anchor" aria-hidden="true" href="#æ·±åº¦å¼ºåŒ–å­¦ä¹ "&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ·±åº¦å¼ºåŒ–å­¦ä¹ &lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://web.stanford.edu/class/cs234/index.html" rel="nofollow"&gt;CS234: Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-æ·±å…¥ç†è§£-1" class="anchor" aria-hidden="true" href="#æ·±å…¥ç†è§£-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ·±å…¥ç†è§£&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.Yoshua%20Bengio%2BIan%20GoodFellow.pdf"&gt;ã€Šæ·±åº¦å­¦ä¹ ã€‹ Yoshua Bengio.Ian GoodFellow&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="star" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png"&gt;â­ï¸&lt;/g-emoji&gt;      Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86.Jacob%20Eisenstein.pdf"&gt;ã€Šè‡ªç„¶è¯­è¨€å¤„ç†ã€‹Jacob Eisenstein&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/Reinforcement%20Learning.Sutton.pdf"&gt;ã€Šå¼ºåŒ–å­¦ä¹ ã€‹&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="http://incompleteideas.net/book/RLbook2018trimmed.pdf" rel="nofollow"&gt;ç¬¬äºŒç‰ˆ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://handong1587.github.io/categories.html#deep_learning-ref" rel="nofollow"&gt;hangdongçš„æ·±åº¦å­¦ä¹ åšå®¢,è®ºæ–‡æ¨è&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://course.fast.ai/" rel="nofollow"&gt;Practical Deep Learning for Coders, v3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/Tensorflow%20%E5%AE%9E%E6%88%98Google%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6.pdf"&gt;ã€ŠTensorflowå®æˆ˜Googleæ·±åº¦å­¦ä¹ æ¡†æ¶ã€‹ éƒ‘æ³½å®‡ é¡¾æ€å®‡&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-ä¸€äº›ä¹¦å•" class="anchor" aria-hidden="true" href="#ä¸€äº›ä¹¦å•"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä¸€äº›ä¹¦å•&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/63784033" rel="nofollow"&gt;2019å¹´æœ€æ–°-æ·±åº¦å­¦ä¹ ã€ç”Ÿæˆå¯¹æŠ—ã€Pytorchä¼˜ç§€æ•™ææ¨è&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-å·¥ç¨‹èƒ½åŠ›" class="anchor" aria-hidden="true" href="#å·¥ç¨‹èƒ½åŠ›"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å·¥ç¨‹èƒ½åŠ›&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/df94968056561d8fcd1952cca7b3353c433309ec/68747470733a2f2f706963342e7a68696d672e636f6d2f76322d30303930313332373836383866353230633037306232373931303235356362315f722e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/df94968056561d8fcd1952cca7b3353c433309ec/68747470733a2f2f706963342e7a68696d672e636f6d2f76322d30303930313332373836383866353230633037306232373931303235356362315f722e6a7067" alt="" data-canonical-src="https://pic4.zhimg.com/v2-009013278688f520c070b27910255cb1_r.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/20588261/answer/798928056" rel="nofollow"&gt;å¦‚ä½•ç³»ç»Ÿåœ°å­¦ä¹ ç®—æ³•ï¼Ÿ&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://leetcode.com/" rel="nofollow"&gt;LeetCode&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/azl397985856/leetcode"&gt;leetcodeé¢˜è§£&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/huaxz1986/cplusplus-_Implementation_Of_Introduction_to_Algorithms"&gt;ã€Šç®—æ³•å¯¼è®ºã€‹ä¸­ç®—æ³•çš„C++å®ç°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E7%AF%87"&gt;æœºå™¨å­¦ä¹ ç®—æ³•å®æˆ˜&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6"&gt;æ·±åº¦å­¦ä¹ æ¡†æ¶&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/YMtnBAVDZepsMTO4h-VRtQ" rel="nofollow"&gt;å¦‚ä½•æˆä¸ºä¸€åç®—æ³•å·¥ç¨‹å¸ˆ&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://mp.weixin.qq.com/s?__biz=MzAxMjcyNjE5MQ==&amp;amp;mid=2650488786&amp;amp;idx=1&amp;amp;sn=68b9536d0b0b3105ab8d79f8efcb0a4b&amp;amp;chksm=83a2e512b4d56c045c6ab0349108842e6a5b26e8f3e507ff5d19ee50e3bd63ef149a36d23eef&amp;amp;scene=0&amp;amp;xtrack=1&amp;amp;ascene=14&amp;amp;devicetype=android-28&amp;amp;version=27000437&amp;amp;nettype=WIFI&amp;amp;abtest_cookie=BAABAAoACwASABMABgAjlx4AVpkeANCZHgDcmR4A8ZkeAAOaHgAAAA%3D%3D&amp;amp;lang=zh_CN&amp;amp;pass_ticket=4yovfEr0v09yZCvvQ1NEy12qGIonnRpGi774X09Mh5EZD2oL%2BRz6FTtX9R5gALB1&amp;amp;wx_header=1" rel="nofollow"&gt;ä»å°ç™½åˆ°å…¥é—¨ç®—æ³•ï¼Œæˆ‘çš„ç»éªŒåˆ†äº«ç»™ä½ ï½&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/54161673" rel="nofollow"&gt;æˆ‘çš„ç ”ç©¶ç”Ÿè¿™ä¸‰å¹´&lt;/a&gt; &lt;g-emoji class="g-emoji" alias="star" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png"&gt;â­ï¸&lt;/g-emoji&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.huaxiaozhuan.com/" rel="nofollow"&gt;ã€ŠAIç®—æ³•å·¥ç¨‹å¸ˆæ‰‹å†Œã€‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/76827460" rel="nofollow"&gt;å¦‚ä½•å‡†å¤‡ç®—æ³•å·¥ç¨‹å¸ˆé¢è¯•ï¼Œæ–©è·ä¸€çº¿äº’è”ç½‘å…¬å¸æœºå™¨å­¦ä¹ å²—offerï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/HZ3Cd2jHuikyFN9ydvcMTw" rel="nofollow"&gt;ã€å®Œç»“ã€‘æ·±åº¦å­¦ä¹ CVç®—æ³•å·¥ç¨‹å¸ˆä»å…¥é—¨åˆ°åˆçº§é¢è¯•æœ‰å¤šè¿œï¼Œå¤§æ¦‚æ˜¯25ç¯‡æ–‡ç« çš„è·ç¦»&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/CyC2018/CS-Notes"&gt; è®¡ç®—æœºç›¸å…³æŠ€æœ¯é¢è¯•å¿…å¤‡&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/imhuay/Algorithm_for_Interview-Chinese"&gt;é¢è¯•ç®—æ³•ç¬”è®°-ä¸­æ–‡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DarLiner/Algorithm_Interview_Notes-Chinese"&gt;ç®—æ³•å·¥ç¨‹å¸ˆé¢è¯•&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ShanghaiTechAIClub/DLInterview"&gt;æ·±åº¦å­¦ä¹ é¢è¯•é¢˜ç›®&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/scutan90/DeepLearning-500-questions"&gt;æ·±åº¦å­¦ä¹ 500é—®&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/amusi/AI-Job-Notes#Strategy"&gt;AIç®—æ³•å²—æ±‚èŒæ”»ç•¥&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Kaggleå®æˆ˜&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;å¸¸ç”¨ç®—æ³•ï¼š
&lt;ul&gt;
&lt;li&gt;Feature Engineeringï¼šcontinue variable &amp;amp;&amp;amp; categorical variable&lt;/li&gt;
&lt;li&gt;Classic machine learning algorithmï¼šLR, KNN, SVM, Random Forest, GBDT(XGBoost&amp;amp;&amp;amp;LightGBM), Factorization Machine, Field-aware Factorization Machine, Neural Network&lt;/li&gt;
&lt;li&gt;Cross validation, model selectionï¼šgrid search, random search, hyper-opt&lt;/li&gt;
&lt;li&gt;Ensemble learning&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apachecn/kaggle"&gt;Kaggle é¡¹ç›®å®æˆ˜ï¼ˆæ•™ç¨‹ï¼‰ = æ–‡æ¡£ + ä»£ç  + è§†é¢‘&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29086448" rel="nofollow"&gt;Kaggleå…¥é—¨ç³»åˆ—ï¼šï¼ˆä¸€ï¼‰æœºå™¨å­¦ä¹ ç¯å¢ƒæ­å»º&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/29417603" rel="nofollow"&gt;Kaggleå…¥é—¨ç³»åˆ—ï¼šï¼ˆäºŒï¼‰Kaggleç®€ä»‹&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/29086614" rel="nofollow"&gt;Kaggleå…¥é—¨ç³»åˆ—ï¼ˆä¸‰ï¼‰Titanicåˆè¯•èº«æ‰‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61660061" rel="nofollow"&gt;ä» 0 åˆ° 1 èµ°è¿› Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25742261" rel="nofollow"&gt;Kaggle å…¥é—¨æŒ‡å—&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61657532" rel="nofollow"&gt;ä¸€ä¸ªæ¡†æ¶è§£å†³å‡ ä¹æ‰€æœ‰æœºå™¨å­¦ä¹ é—®é¢˜&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/" rel="nofollow"&gt;Approaching (Almost) Any Machine Learning Problem | Abhishek Thakur&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27424282" rel="nofollow"&gt;åˆ†åˆ†é’Ÿå¸¦ä½ æ€å…¥Kaggle Top 1%&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/48758045" rel="nofollow"&gt;å¦‚ä½•è¾¾åˆ°Kaggleç«èµ›top 2%ï¼Ÿè¿™é‡Œæœ‰ä¸€ç¯‡ç‰¹å¾æ¢ç´¢ç»éªŒå¸–&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27486736" rel="nofollow"&gt;å¦‚ä½•åœ¨ Kaggle é¦–æˆ˜ä¸­è¿›å…¥å‰ 10%ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/weixin_33739541/article/details/87565983" rel="nofollow"&gt;å¤§æ•°æ®&amp;amp;æœºå™¨å­¦ä¹ ç›¸å…³ç«èµ›æ¨è&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-äºŒ-ç¥ç»ç½‘ç»œæ¨¡å‹æ¦‚è§ˆ" class="anchor" aria-hidden="true" href="#äºŒ-ç¥ç»ç½‘ç»œæ¨¡å‹æ¦‚è§ˆ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;äºŒ. ç¥ç»ç½‘ç»œæ¨¡å‹æ¦‚è§ˆ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_35082030/article/details/73368962" rel="nofollow"&gt;1. ä¸€æ–‡çœ‹æ‡‚25ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29141828" rel="nofollow"&gt;2. DNNæ¦‚è¿°è®ºæ–‡ï¼šè¯¦è§£å‰é¦ˆã€å·ç§¯å’Œå¾ªç¯ç¥ç»ç½‘ç»œæŠ€æœ¯&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://colah.github.io/" rel="nofollow"&gt;3. colah's blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://modelzoo.co/" rel="nofollow"&gt;4. Model Zoom&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29141828" rel="nofollow"&gt;5. DNNæ¦‚è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59385110" rel="nofollow"&gt;6. ä»åŸºæœ¬åŸç†åˆ°æ¢¯åº¦ä¸‹é™ï¼Œå°ç™½éƒ½èƒ½çœ‹æ‡‚çš„ç¥ç»ç½‘ç»œæ•™ç¨‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60245227" rel="nofollow"&gt;GitHubä¸Šçš„æœºå™¨å­¦ä¹ /æ·±åº¦å­¦ä¹ ç»¼è¿°é¡¹ç›®åˆé›†&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-cnn" class="anchor" aria-hidden="true" href="#cnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CNN&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-å‘å±•å²" class="anchor" aria-hidden="true" href="#å‘å±•å²"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å‘å±•å²&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35388569" rel="nofollow"&gt;1. 94é¡µè®ºæ–‡ç»¼è¿°å·ç§¯ç¥ç»ç½‘ç»œï¼šä»åŸºç¡€æŠ€æœ¯åˆ°ç ”ç©¶å‰æ™¯&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/31006686" rel="nofollow"&gt;2. ä»LeNet-5åˆ°DenseNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/26652657" rel="nofollow"&gt;3. CNNå›¾åƒåˆ†å‰²ç®€å²ï¼šä»R-CNNåˆ°Mask R-CNNï¼ˆè¯‘ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32830206" rel="nofollow"&gt;4. æ·±åº¦å­¦ä¹ ä¹‹ç›®æ ‡æ£€æµ‹çš„å‰ä¸–ä»Šç”Ÿï¼ˆMask R-CNNï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32746221" rel="nofollow"&gt;5. çºµè§ˆè½»é‡åŒ–å·ç§¯ç¥ç»ç½‘ç»œï¼šSqueezeNetã€MobileNetã€ShuffleNetã€Xception&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29434605" rel="nofollow"&gt;6. æ·±åº¦å­¦ä¹ ç›®æ ‡æ£€æµ‹æ¨¡å‹å…¨é¢ç»¼è¿°ï¼šFaster R-CNNã€R-FCNå’ŒSSD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36801104" rel="nofollow"&gt;7. å›¾åƒè¯­ä¹‰åˆ†å‰²(Semantic segmentation) Survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36184131" rel="nofollow"&gt;7. ä»RCNNåˆ°SSDï¼Œè¿™åº”è¯¥æ˜¯æœ€å…¨çš„ä¸€ä»½ç›®æ ‡æ£€æµ‹ç®—æ³•ç›˜ç‚¹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36801104" rel="nofollow"&gt;8. å›¾åƒè¯­ä¹‰åˆ†å‰²(Semantic segmentation) Survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/37618829" rel="nofollow"&gt;9. è¯­ä¹‰åˆ†å‰² å‘å±•ç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/PeaceInMind/article/details/78079263" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ åˆ†ç±»ç½‘ç»œ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cnblogs.com/xuanyuyt/p/11329998.html" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ ç¬”è®°ï¼ˆåä¸€ï¼‰ç½‘ç»œ Inception, Xception, MobileNet, ShuffeNet, ResNeXt, SqueezeNet, EfficientNet, MixConv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/68411179" rel="nofollow"&gt;CNNç½‘ç»œç»“æ„çš„å‘å±•&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34621135" rel="nofollow"&gt;å·ç§¯ç¥ç»ç½‘ç»œç»“æ„æ¼”å˜ï¼ˆform Hubel and Wiesel to SENetï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35221368" rel="nofollow"&gt;ä»VGGåˆ°NASNetï¼Œä¸€æ–‡æ¦‚è§ˆå›¾åƒåˆ†ç±»ç½‘ç»œ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;From RCNN to YOLO&lt;/a&gt;ï¼š&lt;a href="https://zhuanlan.zhihu.com/p/35724768" rel="nofollow"&gt;ä¸Š&lt;/a&gt;ï¼Œ&lt;a href="https://zhuanlan.zhihu.com/p/35731743" rel="nofollow"&gt;ä¸‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/38709522" rel="nofollow"&gt;å R-CNNæ—¶ä»£ï¼Œ Faster R-CNNã€SSDã€YOLO å„ç±»å˜ä½“ç»Ÿæ²»ä¸‹çš„ç›®æ ‡æ£€æµ‹ç»¼è¿°ï¼šFaster R-CNNç³»åˆ—èƒœäº†å—ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/37056927" rel="nofollow"&gt;ç›®æ ‡æ£€æµ‹-20ç§æ¨¡å‹çš„åŸå‘³ä»£ç æ±‡æ€»&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40047760" rel="nofollow"&gt;ç›®æ ‡æ£€æµ‹ç®—æ³•ç»¼è¿°ä¸‰éƒ¨æ›²&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40047760" rel="nofollow"&gt;åŸºäºæ·±åº¦å­¦ä¹ çš„ç›®æ ‡æ£€æµ‹ç®—æ³•ç»¼è¿°ï¼ˆä¸€ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40020809" rel="nofollow"&gt;åŸºäºæ·±åº¦å­¦ä¹ çš„ç›®æ ‡æ£€æµ‹ç®—æ³•ç»¼è¿°ï¼ˆäºŒï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40102001" rel="nofollow"&gt;åŸºäºæ·±åº¦å­¦ä¹ çš„ç›®æ ‡æ£€æµ‹ç®—æ³•ç»¼è¿°ï¼ˆä¸‰ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35295839" rel="nofollow"&gt;å¦‚ä½•èµ°è¿‘æ·±åº¦å­¦ä¹ äººè„¸è¯†åˆ«ï¼Ÿä½ éœ€è¦è¿™ç¯‡è¶…é•¿ç»¼è¿° | é™„å¼€æºä»£ç &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;äººè„¸æ£€æµ‹å’Œè¯†åˆ«ç®—æ³•ç»¼è¿°&lt;/a&gt; Â  Â  Â 
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36621308" rel="nofollow"&gt;äººè„¸æ£€æµ‹ç®—æ³•ç»¼è¿° &lt;/a&gt; Â  Â  Â  Â  Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32702868" rel="nofollow"&gt;äººè„¸æ£€æµ‹èƒŒæ™¯ä»‹ç»å’Œå‘å±•ç°çŠ¶&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36416906" rel="nofollow"&gt;äººè„¸è¯†åˆ«ç®—æ³•æ¼”åŒ–å²&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/shuzfan/article/details/50358809" rel="nofollow"&gt;CascadeCNN&lt;/a&gt; Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_14845119/article/details/52680940" rel="nofollow"&gt;MTCNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ChanChiChoi/awesome-Face_Recognition"&gt;awesome-Face_Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/64191484" rel="nofollow"&gt;å¼‚è´¨äººè„¸è¯†åˆ«ç ”ç©¶ç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/26431250" rel="nofollow"&gt;è€æ¿æ¥äº†ï¼šäººè„¸è¯†åˆ«+æ‰‹æœºæ¨é€ï¼Œè€æ¿æ¥äº†ä½ ç«‹åˆ»çŸ¥é“ã€‚&lt;/a&gt;&amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/33456076" rel="nofollow"&gt;æ‰‹æŠŠæ‰‹æ•™ä½ ç”¨Pythonå®ç°äººè„¸è¯†åˆ«&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://www.jianshu.com/p/e57205edc364" rel="nofollow"&gt;äººè„¸è¯†åˆ«é¡¹ç›®ï¼Œç½‘ç»œæ¨¡å‹ï¼ŒæŸå¤±å‡½æ•°ï¼Œæ•°æ®é›†ç›¸å…³æ€»ç»“&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24816781" rel="nofollow"&gt;åŸºäºæ·±åº¦å­¦ä¹ çš„äººè„¸è¯†åˆ«æŠ€æœ¯ç»¼è¿°&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/35295839" rel="nofollow"&gt;å¦‚ä½•èµ°è¿‘æ·±åº¦å­¦ä¹ äººè„¸è¯†åˆ«ï¼Ÿä½ éœ€è¦è¿™ç¯‡è¶…é•¿ç»¼è¿°&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/51324547" rel="nofollow"&gt;äººè„¸è¯†åˆ«æŸå¤±å‡½æ•°ç»¼è¿°ï¼ˆé™„å¼€æºå®ç°ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/57564211" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ å›¾åƒè¶…åˆ†è¾¨ç‡ç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60590369" rel="nofollow"&gt;ç›®æ ‡æ£€æµ‹è¿›åŒ–å²&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61080508" rel="nofollow"&gt;ä¸€æ–‡çœ‹å°½21ç¯‡ç›®æ ‡æ£€æµ‹æœ€æ–°è®ºæ–‡ï¼ˆè…¾è®¯/Google/å•†æ±¤/æ—·è§†/æ¸…å/æµ™å¤§/CMU/åç§‘/ä¸­ç§‘é™¢ç­‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Anchor-Freeç›®æ ‡æ£€æµ‹ç®—æ³•&lt;/a&gt;: &lt;a href="https://zhuanlan.zhihu.com/p/40221183" rel="nofollow"&gt;ç¬¬ä¸€ç¯‡ï¼šarxiv2015_baidu_DenseBox&lt;/a&gt;ï¼Œ &lt;a href="https://www.zhihu.com/question/319605567/answer/647844997" rel="nofollow"&gt;å¦‚ä½•è¯„ä»·æœ€æ–°çš„anchor-freeç›®æ ‡æ£€æµ‹æ¨¡å‹FoveaBoxï¼Ÿ&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/61644900" rel="nofollow"&gt;FCOS: æœ€æ–°çš„one-stageé€åƒç´ ç›®æ ‡æ£€æµ‹ç®—æ³•&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/62198865" rel="nofollow"&gt;æœ€æ–°çš„Anchor-Freeç›®æ ‡æ£€æµ‹æ¨¡å‹FCOSï¼Œç°å·²å¼€æºï¼&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/62789701" rel="nofollow"&gt;ä¸­ç§‘é™¢ç‰›æ´¥åä¸ºè¯ºäºšæå‡ºCenterNetï¼Œone-stage detectorå¯è¾¾47APï¼Œå·²å¼€æºï¼&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/VCBE123/AnchorFreeDetection"&gt;AnchorFreeDetection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62975854" rel="nofollow"&gt;ç›®æ ‡æ£€æµ‹ç®—æ³•ç»¼è¿°ä¹‹FPNä¼˜åŒ–ç¯‡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/63273342" rel="nofollow"&gt;èŠèŠAnchorçš„"å‰ä¸–ä»Šç”Ÿ"ï¼ˆä¸Šï¼‰&lt;/a&gt;&amp;amp;&amp;amp;&lt;a href="https://zhuanlan.zhihu.com/p/68291859" rel="nofollow"&gt;èŠèŠAnchorçš„"å‰ä¸–ä»Šç”Ÿ"ï¼ˆä¸‹ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62843442" rel="nofollow"&gt;ã€CVPR2019æ­£å¼å…¬å¸ƒã€‘è¡Œäººé‡è¯†åˆ«è®ºæ–‡&lt;/a&gt;ï¼Œ&lt;a href="https://zhuanlan.zhihu.com/p/64004977" rel="nofollow"&gt;2019 è¡Œäººå†è¯†åˆ«å¹´åº¦è¿›å±•å›é¡¾&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/67319122" rel="nofollow"&gt;2019CVPRæ–‡æœ¬æ£€æµ‹ç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/31664818" rel="nofollow"&gt;ä»SRCNNåˆ°EDSRï¼Œæ€»ç»“æ·±åº¦å­¦ä¹ ç«¯åˆ°ç«¯è¶…åˆ†è¾¨ç‡æ–¹æ³•å‘å±•å†ç¨‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62843442" rel="nofollow"&gt;ã€CVPR2019æ­£å¼å…¬å¸ƒã€‘è¡Œäººé‡è¯†åˆ«è®ºæ–‡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&amp;amp;mid=2247485142&amp;amp;idx=1&amp;amp;sn=c0e01da30eb5e750be453eabe4be2bf4&amp;amp;chksm=fdb69b41cac11257ae22c7dac395e9651dab628fc35dd6d3c02d9566a8c7f5f2b56353d58a64&amp;amp;token=1065243837&amp;amp;lang=zh_CN#rd" rel="nofollow"&gt;è‡ªç„¶åœºæ™¯æ–‡æœ¬æ£€æµ‹è¯†åˆ«æŠ€æœ¯ç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MarkMoHR/Awesome-Image-Colorization"&gt;Awesome-Image-Colorization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MarkMoHR/Awesome-Edge-Detection-Papers"&gt;Awesome-Edge-Detection-Papers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/65707543" rel="nofollow"&gt;OCRæ–‡å­—å¤„ç†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/65690433" rel="nofollow"&gt;awesome-point-cloud-analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/65539782" rel="nofollow"&gt;Graph Neural Networkï¼ˆGNNï¼‰ç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61215293" rel="nofollow"&gt;å°æ ·æœ¬å­¦ä¹ ï¼ˆFew-shot Learningï¼‰ç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/73542103" rel="nofollow"&gt;è¶…å…¨æ·±åº¦å­¦ä¹ ç»†ç²’åº¦å›¾åƒåˆ†æï¼šé¡¹ç›®ã€ç»¼è¿°ã€æ•™ç¨‹ä¸€ç½‘æ‰“å°½&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;å›¾åƒæ£€ç´¢çš„åå¹´&lt;a href="https://mp.weixin.qq.com/s/sM78DCOK3fuG2JrP2QaSZA" rel="nofollow"&gt;ä¸Š&lt;/a&gt;ã€&lt;a href="https://mp.weixin.qq.com/s/yzVMDEpwbXVS0y-CwWSBEA" rel="nofollow"&gt;ä¸‹&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-æ•™ç¨‹" class="anchor" aria-hidden="true" href="#æ•™ç¨‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ•™ç¨‹&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/39022858" rel="nofollow"&gt;å·ç§¯ç¥ç»ç½‘ç»œå·¥ä½œåŸç†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/28863709" rel="nofollow"&gt;ã€Œä¸ƒå¤•çš„ç¤¼ç‰©ã€: ä¸€æ—¥ææ‡‚å·ç§¯ç¥ç»ç½‘ç»œ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215" rel="nofollow"&gt;A Comprehensive Introduction to Different Types of Convolutions in Deep Learning&lt;/a&gt; &amp;amp;&amp;amp; ç¿»è¯‘ï¼š&lt;a href="https://www.leiphone.com/news/201902/biIqSBpehsaXFwpN.html?uniqueCode=OTEsp9649VqJfUcO" rel="nofollow"&gt;ä¸Š&lt;/a&gt;ã€&lt;a href="https://www.leiphone.com/news/201902/D2Mkv61w9IPq9qGh.html" rel="nofollow"&gt;ä¸‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/28749411" rel="nofollow"&gt;å˜å½¢å·ç§¯æ ¸ã€å¯åˆ†ç¦»å·ç§¯&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/chaolei3/article/details/79374563" rel="nofollow"&gt;å¯¹æ·±åº¦å¯åˆ†ç¦»å·ç§¯ã€åˆ†ç»„å·ç§¯ã€æ‰©å¼ å·ç§¯ã€è½¬ç½®å·ç§¯ï¼ˆåå·ç§¯ï¼‰çš„ç†è§£&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cnblogs.com/cvtoEyes/p/8848815.html" rel="nofollow"&gt;å„ç§å·ç§¯&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/57575810" rel="nofollow"&gt;å·ç§¯æœ‰å¤šå°‘ç§ï¼Ÿä¸€æ–‡è¯»æ‡‚æ·±åº¦å­¦ä¹ ä¸­çš„å„ç§å·ç§¯&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://buptldy.github.io/2016/10/29/2016-10-29-deconv/" rel="nofollow"&gt;åå·ç§¯&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cnblogs.com/yangperasd/p/7071657.html" rel="nofollow"&gt;Convolution NetworkåŠå…¶å˜ç§ï¼ˆåå·ç§¯ã€æ‰©å±•å·ç§¯ã€å› æœå·ç§¯ã€å›¾å·ç§¯ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/320462422" rel="nofollow"&gt;å¦‚ä½•è¯„ä»·æœ€æ–°çš„Octave Convolutionï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59839551" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ åŸºç¡€--å·ç§¯ç±»å‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/silence2015/article/details/79748729" rel="nofollow"&gt;Dilated/Atrous conv ç©ºæ´å·ç§¯/å¤šå­”å·ç§¯&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32304419" rel="nofollow"&gt;CNNæ¨¡å‹ä¹‹ShuffleNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35985680" rel="nofollow"&gt;ä¸€æ–‡ç®€è¿°ResNetåŠå…¶å¤šç§å˜ä½“&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/lanran2/article/details/79057994" rel="nofollow"&gt;ResNetè§£æ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/23006190" rel="nofollow"&gt;å°†CNNå¼•å…¥ç›®æ ‡æ£€æµ‹çš„å¼€å±±ä¹‹ä½œï¼šR-CNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/hjimce/article/details/50187029" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ ï¼ˆåå…«ï¼‰åŸºäºR-CNNçš„ç‰©ä½“æ£€æµ‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u014696921/article/details/52824097" rel="nofollow"&gt;R-CNNè®ºæ–‡è¯¦è§£&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/hjimce/article/details/73382553" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ ï¼ˆå…­åå››ï¼‰Faster R-CNNç‰©ä½“æ£€æµ‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34816076" rel="nofollow"&gt;å…ˆç†è§£Mask R-CNNçš„å·¥ä½œåŸç†ï¼Œç„¶åæ„å»ºé¢œè‰²å¡«å……å™¨åº”ç”¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.codetd.com/article/2554465" rel="nofollow"&gt;å®ä¾‹åˆ†å‰²--Mask RCNNè¯¦è§£(ROI Align / Loss Function)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_20084101/article/details/80455877" rel="nofollow"&gt;è¯­ä¹‰åˆ†å‰²å·ç§¯ç¥ç»ç½‘ç»œå¿«é€Ÿå…¥é—¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/38033032" rel="nofollow"&gt;å›¾åƒè¯­ä¹‰åˆ†å‰²çš„å·¥ä½œåŸç†å’ŒCNNæ¶æ„å˜è¿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;amp;mid=2247484099&amp;amp;idx=1&amp;amp;sn=97e209f1a9860c8d8c51e81d98fc8a0a&amp;amp;chksm=eb4ee600dc396f16624a33cdfc0ead905e62ae9447b49b20146020e6cbd7d71f089101512a40&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;CapsNetå…¥é—¨ç³»åˆ—&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;amp;mid=2247484099&amp;amp;idx=1&amp;amp;sn=97e209f1a9860c8d8c51e81d98fc8a0a&amp;amp;chksm=eb4ee600dc396f16624a33cdfc0ead905e62ae9447b49b20146020e6cbd7d71f089101512a40&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;CapsNetå…¥é—¨ç³»åˆ—ä¹‹ä¸€ï¼šèƒ¶å›Šç½‘ç»œèƒŒåçš„ç›´è§‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;amp;mid=2247484165&amp;amp;idx=1&amp;amp;sn=0ca679e3a5f499f8d8addb405fe3df83&amp;amp;chksm=eb4ee7c6dc396ed0a330fcac12690110bcaf9a8a10794dbc5e1a326c69ecbb140140f55fd6ba&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;CapsNetå…¥é—¨ç³»åˆ—ä¹‹äºŒï¼šèƒ¶å›Šå¦‚ä½•å·¥ä½œ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;amp;mid=2247484433&amp;amp;idx=1&amp;amp;sn=3afe4605bc2501eebbc41c6dd1af9572&amp;amp;chksm=eb4ee0d2dc3969c4619d6c1097d5c949c76c6c854e60d36eba4388da2c3855747818d062c90a&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;CapsNetå…¥é—¨ç³»åˆ—ä¹‹ä¸‰ï¼šå›Šé—´åŠ¨æ€è·¯ç”±ç®—æ³•&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/6CRSen8P6zKaMGtX8IRfqw" rel="nofollow"&gt;CapsNetå…¥é—¨ç³»åˆ—ä¹‹å››ï¼šèƒ¶å›Šç½‘ç»œæ¶æ„&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.mamicode.com/info-detail-2314392.html" rel="nofollow"&gt;YOLO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35325884?group_id=966229905398362112" rel="nofollow"&gt;ç›®æ ‡æ£€æµ‹|YOLOv2åŸç†ä¸å®ç°(é™„YOLOv3)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34995629" rel="nofollow"&gt;ç›®æ ‡æ£€æµ‹æ¨¡å‹YOLO v3é—®ä¸–&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cnblogs.com/shouhuxianjian/p/7903097.html" rel="nofollow"&gt;Attention&lt;/a&gt;ï¼Œ &lt;a href="https://zhuanlan.zhihu.com/p/31547842" rel="nofollow"&gt;1&lt;/a&gt;ï¼Œ&lt;a href="https://blog.csdn.net/yideqianfenzhiyi/article/details/79422857" rel="nofollow"&gt;2&lt;/a&gt;ï¼Œ&lt;a href="https://blog.csdn.net/Wayne2019/article/details/78488142" rel="nofollow"&gt;3&lt;/a&gt;ï¼Œ&lt;a href="https://zhuanlan.zhihu.com/p/37601161" rel="nofollow"&gt;4&lt;/a&gt;ï¼Œ&lt;a href="https://blog.csdn.net/bvl10101111/article/details/78470716" rel="nofollow"&gt;5&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40050371" rel="nofollow"&gt;ä¸€æ–‡è¯»æ‡‚å·ç§¯ç¥ç»ç½‘ç»œä¸­çš„1x1å·ç§¯æ ¸&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1808.01244" rel="nofollow"&gt;ç›®æ ‡æ£€æµ‹ä¹‹CornerNet&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/41825737" rel="nofollow"&gt;1&lt;/a&gt;, &lt;a href="https://blog.csdn.net/Hibercraft/article/details/81637451" rel="nofollow"&gt;2&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/41759548" rel="nofollow"&gt;3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/70306015" rel="nofollow"&gt;ç›®æ ‡æ£€æµ‹çš„æ€§èƒ½è¯„ä»·æŒ‡æ ‡&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/75348108" rel="nofollow"&gt;NMSå’Œè®¡ç®—mAPæ—¶çš„ç½®ä¿¡åº¦é˜ˆå€¼å’ŒIoUé˜ˆå€¼ &lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/60834912" rel="nofollow"&gt;ç™½è¯mAP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://chuansong.me/n/443237851736" rel="nofollow"&gt;äººç¾¤è®¡æ•°&lt;/a&gt;, &lt;a href="https://www.cnblogs.com/wmr95/p/8134692.html" rel="nofollow"&gt;1&lt;/a&gt;, &lt;a href="https://blog.csdn.net/u011285477/article/details/51954989" rel="nofollow"&gt;2&lt;/a&gt;, &lt;a href="https://blog.csdn.net/qingqingdeaini/article/details/79922549" rel="nofollow"&gt;3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/60784169" rel="nofollow"&gt;RelationNetwork&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40980942" rel="nofollow"&gt;ShuffleNet V2å’Œå››ä¸ªç½‘ç»œæ¶æ„è®¾è®¡å‡†åˆ™&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/mao_xiao_feng/article/details/78003476" rel="nofollow"&gt;ã€Tensorflowã€‘tf.nn.depthwise_conv2då¦‚ä½•å®ç°æ·±åº¦å·ç§¯?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/mao_xiao_feng/article/details/78003730" rel="nofollow"&gt;Tensorflowã€‘tf.nn.atrous_conv2då¦‚ä½•å®ç°ç©ºæ´å·ç§¯ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/mao_xiao_feng/article/details/78002811" rel="nofollow"&gt;ã€Tensorflowã€‘tf.nn.separable_conv2då¦‚ä½•å®ç°æ·±åº¦å¯åˆ†å·ç§¯?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/mao_xiao_feng/article/details/71713358" rel="nofollow"&gt;ã€TensorFlowã€‘tf.nn.conv2d_transposeæ˜¯æ€æ ·å®ç°åå·ç§¯çš„ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32423092" rel="nofollow"&gt;ä½•æºæ˜å¤§ç¥çš„ã€ŒFocal Lossã€ï¼Œå¦‚ä½•æ›´å¥½åœ°ç†è§£ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/65305385" rel="nofollow"&gt;CNN æ¨¡å‹æ‰€éœ€çš„è®¡ç®—åŠ›ï¼ˆflopsï¼‰å’Œå‚æ•°ï¼ˆparametersï¼‰æ•°é‡æ˜¯æ€ä¹ˆè®¡ç®—çš„ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-action" class="anchor" aria-hidden="true" href="#action"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Action&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/30753326" rel="nofollow"&gt;å…ˆè¯»æ‡‚CapsNetæ¶æ„ç„¶åç”¨TensorFlowå®ç°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_36148847/article/details/79306762" rel="nofollow"&gt;TensorFlow Object Detection API æ•™ç¨‹&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_36148847/article/details/79306762" rel="nofollow"&gt;TensorFlow å¯¹è±¡æ£€æµ‹ API æ•™ç¨‹1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_36148847/article/details/79307598" rel="nofollow"&gt;TensorFlow å¯¹è±¡æ£€æµ‹ API æ•™ç¨‹2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_36148847/article/details/79307751" rel="nofollow"&gt;TensorFlow å¯¹è±¡æ£€æµ‹ API æ•™ç¨‹3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_36148847/article/details/79307931" rel="nofollow"&gt;TensorFlow å¯¹è±¡æ£€æµ‹ API æ•™ç¨‹ 4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_36148847/article/details/79307933" rel="nofollow"&gt;TensorFlow å¯¹è±¡æ£€æµ‹ API æ•™ç¨‹5&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/65327747" rel="nofollow"&gt;åœ¨TensorFlow+Kerasç¯å¢ƒä¸‹ä½¿ç”¨RoIæ± åŒ–ä¸€æ­¥æ­¥å®ç°æ³¨æ„åŠ›æœºåˆ¶&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://discuss.gluon.ai/t/topic/7216" rel="nofollow"&gt;mxnetå¦‚ä½•æŸ¥çœ‹å‚æ•°æ•°é‡&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/likelyzhao/CalFLOPS-Mxnet"&gt;mxnetæŸ¥çœ‹FLOPS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-gan" class="anchor" aria-hidden="true" href="#gan"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GAN&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://kexue.fm/category/Big-Data" rel="nofollow"&gt;è‹å‰‘æ—åšå®¢ï¼Œè®²è§£å¾—æ·‹æ¼“å°½è‡´&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-å‘å±•å²-1" class="anchor" aria-hidden="true" href="#å‘å±•å²-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å‘å±•å²&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/26491601" rel="nofollow"&gt;åƒå¥‡ç™¾æ€ªçš„GANå˜ä½“&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1807.04720.pdf" rel="nofollow"&gt;The GAN Landscapeï¼šLosses, Architectures, Regularization, and Normalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.leiphone.com/news/201701/Kq6FvnjgbKK8Lh8N.html" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ æ–°æ˜Ÿï¼šGANçš„åŸºæœ¬åŸç†ã€åº”ç”¨å’Œèµ°å‘&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62746494" rel="nofollow"&gt;GANç”Ÿæˆå›¾åƒç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-æ•™ç¨‹-1" class="anchor" aria-hidden="true" href="#æ•™ç¨‹-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ•™ç¨‹&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27295635" rel="nofollow"&gt;1. GANåŸç†å­¦ä¹ ç¬”è®°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35783437?group_id=969598777652420608" rel="nofollow"&gt;2. æç«¯å›¾åƒå‹ç¼©çš„å¯¹æŠ—ç”Ÿæˆç½‘ç»œ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=0CKeqXl5IY0&amp;amp;feature=youtu.be" rel="nofollow"&gt;3. å°æ¹¾å¤§å­¦æå®æ¯…GANæ•™ç¨‹&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/GAN-Basic%20Idea%20(2017.04.21).pdf"&gt;Basic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/GAN-Improving%20GAN%20(2017.05.05).pdf"&gt;Improving&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29882709" rel="nofollow"&gt;4. 2017å¹´GAN è®¡ç®—æœºè§†è§‰ç›¸å…³paperæ±‡æ€»&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35030377" rel="nofollow"&gt;5. åœ¨Kerasä¸Šå®ç°GANï¼šæ„å»ºæ¶ˆé™¤å›¾ç‰‡æ¨¡ç³Šçš„åº”ç”¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34711316" rel="nofollow"&gt;6. CycleGANï¼šå›¾ç‰‡é£æ ¼ï¼Œæƒ³æ¢å°±æ¢ | ICCV 2017è®ºæ–‡è§£è¯»&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25071913" rel="nofollow"&gt;7. Wasserstein GAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/40105143" rel="nofollow"&gt;ç”¨å˜åˆ†æ¨æ–­ç»Ÿä¸€ç†è§£ç”Ÿæˆæ¨¡å‹ï¼ˆVAEã€GANã€AAEã€ALIï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-action-1" class="anchor" aria-hidden="true" href="#action-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Action&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24767059" rel="nofollow"&gt;1. GANå­¦ä¹ æŒ‡å—ï¼šä»åŸç†å…¥é—¨åˆ°åˆ¶ä½œç”ŸæˆDemo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29837245" rel="nofollow"&gt;2. æœºå™¨ä¹‹å¿ƒGitHubé¡¹ç›®ï¼šGANå®Œæ•´ç†è®ºæ¨å¯¼ä¸å®ç°&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-rnn" class="anchor" aria-hidden="true" href="#rnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RNN&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-å‘å±•å²-2" class="anchor" aria-hidden="true" href="#å‘å±•å²-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å‘å±•å²&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32668465" rel="nofollow"&gt;ä»90å¹´ä»£çš„SRNNå¼€å§‹ï¼Œçºµè§ˆå¾ªç¯ç¥ç»ç½‘ç»œ27å¹´çš„ç ”ç©¶è¿›å±•&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-æ•™ç¨‹-2" class="anchor" aria-hidden="true" href="#æ•™ç¨‹-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ•™ç¨‹&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/28054589" rel="nofollow"&gt;å®Œå…¨å›¾è§£RNNã€RNNå˜ä½“ã€Seq2Seqã€Attentionæœºåˆ¶&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/heyongluoyao8/article/details/48636251" rel="nofollow"&gt;å¾ªç¯ç¥ç»ç½‘ç»œ(RNN, Recurrent Neural Networks)ä»‹ç»&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/Dark_Scope/article/details/47056361" rel="nofollow"&gt;RNNä»¥åŠLSTMçš„ä»‹ç»å’Œå…¬å¼æ¢³ç†&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24018768" rel="nofollow"&gt;ï¼ˆè¯‘ï¼‰ç†è§£é•¿çŸ­æœŸè®°å¿†(LSTM) ç¥ç»ç½‘ç»œ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35878575?group_id=970350175025385472" rel="nofollow"&gt; ä¸€æ–‡è¯»æ‡‚LSTMå’ŒRNN&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27345523" rel="nofollow"&gt;æ¢ç´¢LSTMï¼šåŸºæœ¬æ¦‚å¿µåˆ°å†…éƒ¨ç»“æ„&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/matrix_space/article/details/53374040" rel="nofollow"&gt; ç¿»è¯‘ï¼šæ·±å…¥ç†è§£LSTMç³»åˆ—&lt;/a&gt; Â            Â  Â  Â  Â  Â &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/matrix_space/article/details/53374040" rel="nofollow"&gt;æ·±å…¥ç†è§£ LSTM ç½‘ç»œ (ä¸€)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/matrix_space/article/details/53376870" rel="nofollow"&gt;æ·±å…¥ç†è§£ LSTM ç½‘ç»œ (äºŒ)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32085405" rel="nofollow"&gt;LSTM&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zybuluo.com/hanbingtao/note/541458" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ å…¶äº” å¾ªç¯ç¥ç»ç½‘ç»œ&lt;/a&gt; Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32582764" rel="nofollow"&gt;ç”¨å¾ªç¯ç¥ç»ç½‘ç»œè¿›è¡Œæ–‡ä»¶æ— æŸå‹ç¼©ï¼šæ–¯å¦ç¦å¤§å­¦æå‡ºDeepZip&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=""&gt;å´æ©è¾¾åºåˆ—å»ºæ¨¡è¯¾ç¨‹&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34309635" rel="nofollow"&gt;Courseraå´æ©è¾¾ã€Šåºåˆ—æ¨¡å‹ã€‹è¯¾ç¨‹ç¬”è®°ï¼ˆ1ï¼‰-- å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34975871" rel="nofollow"&gt;Courseraå´æ©è¾¾ã€Šåºåˆ—æ¨¡å‹ã€‹è¯¾ç¨‹ç¬”è®°ï¼ˆ2ï¼‰-- NLP &amp;amp; Word Embeddings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35532553" rel="nofollow"&gt;Courseraå´æ©è¾¾ã€Šåºåˆ—æ¨¡å‹ã€‹è¯¾ç¨‹ç¬”è®°ï¼ˆ3ï¼‰-- Sequence models &amp;amp; Attention mechanism&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;word2vec&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;åŸç†
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/26306795" rel="nofollow"&gt;NLP ç§’æ‡‚è¯å‘é‡Word2vecçš„æœ¬è´¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35500923" rel="nofollow"&gt;ä¸€ç¯‡é€šä¿—æ˜“æ‡‚çš„word2vec&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27830489" rel="nofollow"&gt;YJangoçš„Word Embedding--ä»‹ç»&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56382372" rel="nofollow"&gt;nlpä¸­çš„è¯å‘é‡å¯¹æ¯”ï¼šword2vec/glove/fastText/elmo/GPT/bert&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zh.diveintodeeplearning.org/chapter_natural-language-processing/word2vec.html" rel="nofollow"&gt;è¯åµŒå…¥ï¼ˆword2vecï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/wangyangzhizhou/article/details/77073023" rel="nofollow"&gt;è°ˆè°ˆè°·æ­Œword2vecçš„åŸç†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/67117737" rel="nofollow"&gt;Word2Vecä¸­ä¸ºä»€ä¹ˆä½¿ç”¨è´Ÿé‡‡æ ·ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;è®­ç»ƒè¯å‘é‡
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29200034" rel="nofollow"&gt;ç»ƒä¹ -word2vec&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/31886824" rel="nofollow"&gt;word2vecæ–¹æ³•çš„å®ç°å’Œåº”ç”¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/wzdjsgf/article/details/79541492" rel="nofollow"&gt;è‡ªç„¶è¯­è¨€å¤„ç†å…¥é—¨ word2vec ä½¿ç”¨tensorflowè‡ªå·±è®­ç»ƒè¯å‘é‡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/28979653" rel="nofollow"&gt;ä½¿ç”¨tensorflowå®ç°word2vecä¸­æ–‡è¯å‘é‡çš„è®­ç»ƒ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/wangyangzhizhou/article/details/77530479?locationNum=1&amp;amp;fps=1" rel="nofollow"&gt;å¦‚ä½•ç”¨TensorFlowè®­ç»ƒè¯å‘é‡&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/47812375" rel="nofollow"&gt;èŠèŠ Transformer&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35648927" rel="nofollow"&gt;åŸºäºword2vecè®­ç»ƒè¯å‘é‡(ä¸€)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35889385" rel="nofollow"&gt;åŸºäºword2vecè®­ç»ƒè¯å‘é‡(äºŒ)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35041012" rel="nofollow"&gt;è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attention Mechanismï¼‰&lt;/a&gt; Â  Â &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/54491016" rel="nofollow"&gt;è‡ªç„¶è¯­è¨€å¤„ç†ä¸­æ³¨æ„åŠ›æœºåˆ¶ç»¼è¿°&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27830489" rel="nofollow"&gt;YJangoçš„Word Embedding--ä»‹ç»&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-action-2" class="anchor" aria-hidden="true" href="#action-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Action&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/liuchonge/article/details/78405185?locationNum=8&amp;amp;fps=1" rel="nofollow"&gt;tensorflowä¸­RNNcellæºç åˆ†æä»¥åŠè‡ªå®šä¹‰RNNCellçš„æ–¹æ³•&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/28196873" rel="nofollow"&gt;TensorFlowä¸­RNNå®ç°çš„æ­£ç¡®æ‰“å¼€æ–¹å¼&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27906426" rel="nofollow"&gt;TensorFlow RNN ä»£ç &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/67031035" rel="nofollow"&gt;Tensorflowå®ç°çš„æ·±åº¦NLPæ¨¡å‹é›†é”¦&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/graykode/nlp-tutorial"&gt;nlp-tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/33186759" rel="nofollow"&gt;ç”¨tensorflow LSTMå¦‚ä½•é¢„æµ‹è‚¡ç¥¨ä»·æ ¼&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29797089" rel="nofollow"&gt;TensorFlowçš„å¤šå±‚LSTMå®è·µ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27087310" rel="nofollow"&gt;ã€Šå®‰å¨œå¡åˆ—å°¼å¨œã€‹æ–‡æœ¬ç”Ÿæˆâ€”â€”åˆ©ç”¨TensorFlowæ„å»ºLSTMæ¨¡å‹&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-gnn" class="anchor" aria-hidden="true" href="#gnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GNN&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-å‘å±•å²-3" class="anchor" aria-hidden="true" href="#å‘å±•å²-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å‘å±•å²&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/65539782" rel="nofollow"&gt;Graph Neural Networkï¼ˆGNNï¼‰ç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650754422&amp;amp;idx=4&amp;amp;sn=0dc881487f362322a875b4ce06e645f7&amp;amp;chksm=871a8908b06d001ef7386ccc752827c20711877a4a23d6a8318978095dd241d118257c607b22&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ æ—¶ä»£çš„å›¾æ¨¡å‹ï¼Œæ¸…åå‘æ–‡ç»¼è¿°å›¾ç½‘ç»œ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650754558&amp;amp;idx=2&amp;amp;sn=7d79191b9ed30679d5d40e22d9cabdf8&amp;amp;chksm=871a8980b06d00962e0dbe984e1d3469214db31cb402b4725a0dfe330249a830b45cb26932b5&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ¸…åå¤§å­¦å›¾ç¥ç»ç½‘ç»œç»¼è¿°ï¼šæ¨¡å‹ä¸åº”ç”¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/54241746" rel="nofollow"&gt;å›¾ç¥ç»ç½‘ç»œæ¦‚è¿°ç¬¬ä¸‰å¼¹ï¼šæ¥è‡ªIEEE Fellowçš„GNNç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DeepGraphLearning/LiteratureDL4Graph"&gt;GNNæœ€å…¨æ–‡çŒ®èµ„æ–™æ•´ç†&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://github.com/nnzhan/Awesome-Graph-Neural-Networks"&gt;Awesome-Graph-Neural-Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-æ•™ç¨‹-3" class="anchor" aria-hidden="true" href="#æ•™ç¨‹-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ•™ç¨‹&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/54504471/answer/611222866" rel="nofollow"&gt;å¦‚ä½•ç†è§£ Graph Convolutional Networkï¼ˆGCNï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/54505069" rel="nofollow"&gt;å›¾å·ç§¯ç½‘ç»œ(GCN)æ–°æ‰‹æ‘å®Œå…¨æŒ‡å—&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/71200936" rel="nofollow"&gt;ä½•æ—¶èƒ½æ‡‚ä½ çš„å¿ƒâ€”â€”å›¾å·ç§¯ç¥ç»ç½‘ç»œï¼ˆGCNï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/90470499" rel="nofollow"&gt;å›¾å·ç§¯ç½‘ç»œGCNçš„ç†è§£ä¸ä»‹ç»&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/89503068" rel="nofollow"&gt;ä¸€æ–‡è¯»æ‡‚å›¾å·ç§¯GCN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-action-3" class="anchor" aria-hidden="true" href="#action-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Action&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/57235377" rel="nofollow"&gt;å›¾å·ç§¯ç½‘ç»œåˆ°åº•æ€ä¹ˆåšï¼Œè¿™æ˜¯ä¸€ä»½æç®€çš„Numpyå®ç°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.dgl.ai/index.html" rel="nofollow"&gt;DGL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-ä¸‰-æ·±åº¦æ¨¡å‹çš„ä¼˜åŒ–--" class="anchor" aria-hidden="true" href="#ä¸‰-æ·±åº¦æ¨¡å‹çš„ä¼˜åŒ–--"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä¸‰. æ·±åº¦æ¨¡å‹çš„ä¼˜åŒ– Â  Â &lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://fa.bianp.net/teaching/2018/eecs227at/" rel="nofollow"&gt;1. ä¼˜åŒ–ç®—æ³•çºµè§ˆ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27449596" rel="nofollow"&gt;2. ä»æ¢¯åº¦ä¸‹é™åˆ°Adam&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25703402" rel="nofollow"&gt;3. ä»æ¢¯åº¦ä¸‹é™åˆ°æ‹Ÿç‰›é¡¿æ³•ï¼šç›˜ç‚¹è®­ç»ƒç¥ç»ç½‘ç»œçš„äº”å¤§å­¦ä¹ ç®—æ³•&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35429054?group_id=966442942538444800" rel="nofollow"&gt;4. æ­£åˆ™åŒ–æŠ€æœ¯æ€»ç»“&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35429054?group_id=966442942538444800" rel="nofollow"&gt;å²ä¸Šæœ€å…¨é¢çš„æ­£åˆ™åŒ–æŠ€æœ¯æ€»ç»“ä¸åˆ†æ--part1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35432128?group_id=966443101011738624" rel="nofollow"&gt;å²ä¸Šæœ€å…¨é¢çš„æ­£åˆ™åŒ–æŠ€æœ¯æ€»ç»“ä¸åˆ†æ--part2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/chunyun0716/article/category/6188191/2" rel="nofollow"&gt;5. æœ€ä¼˜åŒ–ç®—æ³•ç³»åˆ—ï¼ˆmathï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25631496" rel="nofollow"&gt;6. ç¥ç»ç½‘ç»œè®­ç»ƒä¸­çš„æ¢¯åº¦æ¶ˆå¤±ä¸æ¢¯åº¦çˆ†ç‚¸&lt;/a&gt; Â  Â  Â  Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36050743" rel="nofollow"&gt;7. ç¥ç»ç½‘ç»œçš„ä¼˜åŒ–åŠè®­ç»ƒ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35888543" rel="nofollow"&gt;8. é€šä¿—è®²è§£æŸ¥å…¨ç‡å’ŒæŸ¥å‡†ç‡&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/34079183" rel="nofollow"&gt;å…¨é¢æ¢³ç†ï¼šå‡†ç¡®ç‡,ç²¾ç¡®ç‡,å¬å›ç‡,æŸ¥å‡†ç‡,æŸ¥å…¨ç‡,å‡é˜³æ€§,çœŸé˜³æ€§,PRC,ROC,AUC,F1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/30567264" rel="nofollow"&gt;9. æ¿€æ´»å‡½æ•°ä¸€è§ˆ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/30922689" rel="nofollow"&gt;10. Courseraå´æ©è¾¾ã€Šä¼˜åŒ–æ·±åº¦ç¥ç»ç½‘ç»œã€‹è¯¾ç¨‹ç¬”è®°ï¼ˆ3ï¼‰-- è¶…å‚æ•°è°ƒè¯•ã€Batchæ­£åˆ™åŒ–å’Œç¼–ç¨‹æ¡†æ¶&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35423404" rel="nofollow"&gt;11. æœºå™¨å­¦ä¹ å„ç§ç†µ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27305237" rel="nofollow"&gt;12. è·ç¦»å’Œç›¸ä¼¼æ€§åº¦é‡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29974820" rel="nofollow"&gt;13. æœºå™¨å­¦ä¹ é‡Œçš„é»‘è‰²è‰ºæœ¯ï¼šnormalization, standardization, regularization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36101196" rel="nofollow"&gt;14. LSTMç³»åˆ—çš„æ¢¯åº¦é—®é¢˜&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35027284" rel="nofollow"&gt;15. æŸå¤±å‡½æ•°æ•´ç†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/28124810" rel="nofollow"&gt;16. è¯¦è§£æ®‹å·®å—ä¸ºä½•æœ‰åŠ©äºè§£å†³æ¢¯åº¦å¼¥æ•£é—®é¢˜&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34858971" rel="nofollow"&gt;17. FAIRä½•æºæ˜ç­‰äººæå‡ºç»„å½’ä¸€åŒ–ï¼šæ›¿ä»£æ‰¹å½’ä¸€åŒ–ï¼Œä¸å—æ‰¹é‡å¤§å°é™åˆ¶&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;18. Batch Normalizationï¼ˆBNï¼‰&lt;/a&gt;:&lt;a href="https://zhuanlan.zhihu.com/p/26702482" rel="nofollow"&gt;1 &lt;/a&gt;,&lt;a href="https://blog.csdn.net/hjimce/article/details/50866313" rel="nofollow"&gt;2 &lt;/a&gt;,&lt;a href="http://www.cvmart.net/community/article/detail/368" rel="nofollow"&gt;3 &lt;/a&gt;,&lt;a href="https://blog.csdn.net/edogawachia/article/details/80040456" rel="nofollow"&gt;4 &lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/38176412" rel="nofollow"&gt;5&lt;/a&gt;, &lt;a href="https://www.zhihu.com/question/38102762" rel="nofollow"&gt;6&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/52132614" rel="nofollow"&gt;7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/33173246" rel="nofollow"&gt;19. è¯¦è§£æ·±åº¦å­¦ä¹ ä¸­çš„Normalizationï¼Œä¸åªæ˜¯BN&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/69659844" rel="nofollow"&gt;å¦‚ä½•åŒºåˆ†å¹¶è®°ä½å¸¸è§çš„å‡ ç§ Normalization ç®—æ³•&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/philosophyatmath/article/details/70173128" rel="nofollow"&gt;20. BFGS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/33006526" rel="nofollow"&gt;21. è¯¦è§£æ·±åº¦å­¦ä¹ ä¸­çš„æ¢¯åº¦æ¶ˆå¤±ã€çˆ†ç‚¸åŸå› åŠå…¶è§£å†³æ–¹æ³•&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1207.0580.pdf" rel="nofollow"&gt;22. Dropout&lt;/a&gt;, &lt;a href="https://blog.csdn.net/stdcoutzyx/article/details/49022443" rel="nofollow"&gt;1&lt;/a&gt;, &lt;a href="https://blog.csdn.net/hjimce/article/details/50413257" rel="nofollow"&gt;2&lt;/a&gt;, &lt;a href="https://blog.csdn.net/shuzfan/article/details/50580915" rel="nofollow"&gt;3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/StreamRock/article/details/83590347" rel="nofollow"&gt;23.è°±å½’ä¸€åŒ–ï¼ˆSpectral Normalizationï¼‰çš„ç†è§£&lt;/a&gt;ï¼Œ&lt;a href="https://blog.csdn.net/left_la/article/details/9159949" rel="nofollow"&gt;å¸¸è§å‘é‡èŒƒæ•°å’ŒçŸ©é˜µèŒƒæ•°&lt;/a&gt;ï¼Œ&lt;a href="https://blog.csdn.net/StreamRock/article/details/83539937" rel="nofollow"&gt;è°±èŒƒæ•°æ­£åˆ™ï¼ˆSpectral Norm Regularizationï¼‰çš„ç†è§£&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35356992" rel="nofollow"&gt;24.L1æ­£åˆ™åŒ–ä¸L2æ­£åˆ™åŒ–&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61944055" rel="nofollow"&gt;25.ä¸ºä»€ä¹ˆé€‰ç”¨äº¤å‰ç†µè€Œä¸æ˜¯MSE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/xierhacker/article/details/53316138" rel="nofollow"&gt;æœºå™¨å­¦ä¹ ç¬”è®°å››ï¼šçº¿æ€§å›å½’å›é¡¾ä¸logisticå›å½’&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u014313009/article/details/51039334" rel="nofollow"&gt;åå‘ä¼ æ’­ç®—æ³•ï¼ˆè¿‡ç¨‹åŠå…¬å¼æ¨å¯¼ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u014313009/article/details/51043064" rel="nofollow"&gt;äº¤å‰ç†µä»£ä»·å‡½æ•°ï¼ˆä½œç”¨åŠå…¬å¼æ¨å¯¼ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Softmax&lt;/strong&gt;ï¼š&lt;a href="https://zhuanlan.zhihu.com/p/25723112" rel="nofollow"&gt;è¯¦è§£softmaxå‡½æ•°ä»¥åŠç›¸å…³æ±‚å¯¼è¿‡ç¨‹&lt;/a&gt;  &amp;amp;&amp;amp;  &lt;a href="https://blog.csdn.net/u014313009/article/details/51045303" rel="nofollow"&gt;softmaxçš„logä¼¼ç„¶ä»£ä»·å‡½æ•°ï¼ˆå…¬å¼æ±‚å¯¼ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æƒé‡åˆå§‹åŒ–&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62850258" rel="nofollow"&gt;ç¥ç»ç½‘ç»œä¸­çš„æƒé‡åˆå§‹åŒ–ä¸€è§ˆï¼šä»åŸºç¡€åˆ°Kaiming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61641174" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ å…¥é—¨--æƒé‡åˆå§‹å€¼çš„ä¼˜åŒ–&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/75879624" rel="nofollow"&gt;è°ˆè°ˆç¥ç»ç½‘ç»œæƒé‡ä¸ºä»€ä¹ˆä¸èƒ½åˆå§‹åŒ–ä¸º0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/305340182" rel="nofollow"&gt;ç¥ç»ç½‘ç»œä¸­çš„åç½®ï¼ˆbiasï¼‰ç©¶ç«Ÿæœ‰è¿™ä¹ˆç”¨ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/66894061" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ é‡Œé¢çš„åç½®ä¸ºä»€ä¹ˆä¸åŠ æ­£åˆ™ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-å››-ç‚¼ä¸¹æœ¯å£«é‚£äº›äº‹" class="anchor" aria-hidden="true" href="#å››-ç‚¼ä¸¹æœ¯å£«é‚£äº›äº‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å››. ç‚¼ä¸¹æœ¯å£«é‚£äº›äº‹&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-è°ƒå‚ç»éªŒ" class="anchor" aria-hidden="true" href="#è°ƒå‚ç»éªŒ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è°ƒå‚ç»éªŒ&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/jiandanjinxin/article/details/77190687" rel="nofollow"&gt;è®­ç»ƒçš„ç¥ç»ç½‘ç»œä¸å·¥ä½œï¼Ÿä¸€æ–‡å¸¦ä½ è·¨è¿‡è¿™37ä¸ªå‘&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59918821" rel="nofollow"&gt;ç¥ç»ç½‘ç»œè®­ç»ƒtrick&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/han_xiaoyang/article/details/50521064" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ ä¸è®¡ç®—æœºè§†è§‰ç³»åˆ—(8)_ç¥ç»ç½‘ç»œè®­ç»ƒä¸æ³¨æ„ç‚¹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/liuweiyuxiang/article/details/80856991" rel="nofollow"&gt;ç¥ç»ç½‘ç»œè®­ç»ƒlossä¸ä¸‹é™åŸå› é›†åˆ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/ningyanggege/article/details/82183666" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ ï¼šæ¬ æ‹Ÿåˆé—®é¢˜çš„å‡ ç§è§£å†³æ–¹æ¡ˆ&lt;/a&gt; &amp;amp;&amp;amp;&lt;a href="https://blog.csdn.net/mzpmzk/article/details/79741682" rel="nofollow"&gt;è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆé—®é¢˜&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/whut_ldz/article/details/78882871" rel="nofollow"&gt;æœºå™¨å­¦ä¹ ï¼šå¦‚ä½•æ‰¾åˆ°æœ€ä¼˜å­¦ä¹ ç‡&lt;/a&gt;åŠ&lt;a href="https://github.com/L1aoXingyu/torchlib"&gt;å®ç°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;ä¸å¹³è¡¡æ•°æ®é›†å¤„ç†æ–¹æ³•&lt;/a&gt;: &lt;a href="https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/" rel="nofollow"&gt;å…¶ä¸€&lt;/a&gt;, &lt;a href="https://www.zhihu.com/question/285824343" rel="nofollow"&gt;å…¶äºŒ&lt;/a&gt;, &lt;a href="https://blog.csdn.net/songhk0209/article/details/71484469" rel="nofollow"&gt;å…¶ä¸‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/41841299" rel="nofollow"&gt;åŒä¸€ä¸ªç¥ç»ç½‘ç»œä½¿ç”¨ä¸åŒæ¿€æ´»å‡½æ•°çš„è¡¨è¾¾èƒ½åŠ›æ˜¯å¦ä¸€è‡´&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ruder.io/optimizing-gradient-descent/" rel="nofollow"&gt;æ¢¯åº¦ä¸‹é™ä¼˜åŒ–ç®—æ³•çºµè§ˆ&lt;/a&gt;, &lt;a href="https://blog.csdn.net/qq_23269761/article/details/80901411" rel="nofollow"&gt;1&lt;/a&gt;, &lt;a href="https://www.cnblogs.com/guoyaohua/p/8542554.html" rel="nofollow"&gt;2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/ly244855983/article/details/78938667#%E8%AE%A8%E8%AE%BA" rel="nofollow"&gt;è®ºæ–‡ç¬”è®°ä¹‹æ•°æ®å¢å¹¿ï¼šmixup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/44331706" rel="nofollow"&gt;é¿å‘æŒ‡å—ï¼šæ•°æ®ç§‘å­¦å®¶æ–°æ‰‹å¸¸çŠ¯çš„13ä¸ªé”™è¯¯&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bindog.github.io/blog/2018/02/10/model-explanation/" rel="nofollow"&gt;å‡­ä»€ä¹ˆç›¸ä¿¡CNNçš„ç»“æœ?--å¯è§†åŒ–&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://bindog.github.io/blog/2018/02/10/model-explanation/" rel="nofollow"&gt;å‡­ä»€ä¹ˆç›¸ä¿¡ä½ ï¼Œæˆ‘çš„CNNæ¨¡å‹ï¼Ÿï¼ˆç¯‡ä¸€ï¼šCAMå’ŒGrad-CAM)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://bindog.github.io/blog/2018/02/11/model-explanation-2/" rel="nofollow"&gt;å‡­ä»€ä¹ˆç›¸ä¿¡ä½ ï¼Œæˆ‘çš„CNNæ¨¡å‹ï¼Ÿï¼ˆç¯‡äºŒï¼šä¸‡é‡‘æ²¹LIME)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jianshu.com/p/294ad9ae2e50" rel="nofollow"&gt;è®ºæ–‡ç¬”è®°:Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_41185868/article/details/80323646" rel="nofollow"&gt;CVï¼šåŸºäºKerasåˆ©ç”¨è®­ç»ƒå¥½çš„hdf5æ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹å®ç°è¾“å‡ºæ¨¡å‹ä¸­çš„è¡¨æƒ…æˆ–æ€§åˆ«çš„gradcam(å¯è§†åŒ–)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;å¤§å·ç§¯æ ¸è¿˜æ˜¯å°å·ç§¯æ ¸?&lt;/a&gt; &lt;a href="https://www.jianshu.com/p/d75375dd7ebd" rel="nofollow"&gt;1&lt;/a&gt;, &lt;a href="https://blog.csdn.net/kuangtun9713/article/details/79475457" rel="nofollow"&gt;2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://baijiahao.baidu.com/s?id=1608193373391996908" rel="nofollow"&gt;æ¨¡å‹å¯è§£é‡Šæ€§å·®ï¼Ÿä½ è€ƒè™‘äº†å„ç§ä¸ç¡®å®šæ€§äº†å—ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;ç‚¼ä¸¹ç¬”è®°ç³»åˆ—&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56882616" rel="nofollow"&gt;ç‚¼ä¸¹ç¬”è®°ä¸€ï¼šæ ·æœ¬ä¸å¹³è¡¡é—®é¢˜&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56022212" rel="nofollow"&gt;ç‚¼ä¸¹ç¬”è®°äºŒï¼šæ•°æ®æ¸…æ´—&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56139575" rel="nofollow"&gt;ç‚¼ä¸¹ç¬”è®°ä¸‰ï¼šæ•°æ®å¢å¼º&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56365469" rel="nofollow"&gt;ç‚¼ä¸¹ç¬”è®°å››ï¼šå°æ ·æœ¬é—®é¢˜&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56443169" rel="nofollow"&gt;ç‚¼ä¸¹ç¬”è®°äº”ï¼šæ•°æ®æ ‡æ³¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56745640" rel="nofollow"&gt;ç‚¼ä¸¹ç¬”è®°å…­ : è°ƒå‚æŠ€å·§&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/57738934" rel="nofollow"&gt;ç‚¼ä¸¹ç¬”è®°ä¸ƒï¼šå·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹è®¾è®¡&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-åˆ·æ’è¡Œæ¦œçš„å¥‡æŠ€æ·«å·§" class="anchor" aria-hidden="true" href="#åˆ·æ’è¡Œæ¦œçš„å¥‡æŠ€æ·«å·§"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;åˆ·æ’è¡Œæ¦œçš„å¥‡æŠ€æ·«å·§&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.leiphone.com/news/201803/XBjvQriKTyTMPLcz.html" rel="nofollow"&gt;Kaggle å…­å¤§æ¯”èµ›æœ€å…¨é¢è§£æï¼ˆä¸Šï¼‰&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.leiphone.com/news/201803/chz1DNHqgVWNEm5t.html" rel="nofollow"&gt;Kaggle å…­å¤§æ¯”èµ›æœ€å…¨é¢è§£æï¼ˆä¸‹ï¼‰&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-å›¾åƒåˆ†ç±»" class="anchor" aria-hidden="true" href="#å›¾åƒåˆ†ç±»"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å›¾åƒåˆ†ç±»&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56139575" rel="nofollow"&gt;ç‚¼ä¸¹ç¬”è®°ä¸‰ï¼šæ•°æ®å¢å¼º&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/41679153" rel="nofollow"&gt;æ•°æ®å¢å¼º(Data Augmentation)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/38345420" rel="nofollow"&gt;ã€æŠ€æœ¯ç»¼è¿°ã€‘ æ·±åº¦å­¦ä¹ ä¸­çš„æ•°æ®å¢å¼ºï¼ˆä¸Šï¼‰&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/38437739" rel="nofollow"&gt;ã€æŠ€æœ¯ç»¼è¿°ã€‘æ·±åº¦å­¦ä¹ ä¸­çš„æ•°æ®å¢å¼ºï¼ˆä¸‹ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/53324148" rel="nofollow"&gt;ã€ŠBag of Tricks for Image Classification with CNNã€‹&lt;/a&gt;&amp;amp;&amp;amp; &lt;a href="https://arxiv.org/pdf/1812.01187.pdf" rel="nofollow"&gt;pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59918821" rel="nofollow"&gt;ç¥ç»ç½‘ç»œè®­ç»ƒtrick&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;Kaggleè§£å†³æ–¹æ¡ˆåˆ†äº«&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.itcodemonkey.com/article/4898.html" rel="nofollow"&gt;ä»0ä¸Šæ‰‹Kaggleå›¾åƒåˆ†ç±»æŒ‘æˆ˜ï¼šå† å†›è§£å†³æ–¹æ¡ˆè¯¦è§£&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.leiphone.com/news/201803/u40cjEZWArBfFaBm.html" rel="nofollow"&gt;Kaggle å†°å±±å›¾åƒåˆ†ç±»å¤§èµ›è¿‘æ—¥è½å¹•ï¼Œçœ‹å† å†›å›¢é˜Ÿæ–¹æ¡ˆæœ‰ä½•äº®ç‚¹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/_S8EBBJ-u9g_fHp7I3ChMQ?" rel="nofollow"&gt;ã€Kaggleå† å†›åˆ†äº«ã€‘å›¾åƒè¯†åˆ«å’Œåˆ†ç±»ç«èµ›ï¼Œæ•°æ®å¢å¼ºåŠä¼˜åŒ–ç®—æ³•&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58496385" rel="nofollow"&gt;è¯†åˆ«åº§å¤´é²¸ï¼ŒKaggleç«èµ›ç¬¬ä¸€åè§£å†³æ–¹æ¡ˆè§£è¯»&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60953933" rel="nofollow"&gt;kaggle é¦–æˆ˜æ‹¿é‡‘ç‰Œæ€»ç»“&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/37522227" rel="nofollow"&gt;16å²é«˜ä¸­ç”Ÿå¤ºå† Kaggleåœ°æ ‡æ£€ç´¢æŒ‘æˆ˜èµ›ï¼è€Œä¸”ç«Ÿç„¶æ˜¯Kaggleè€å…µ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/37663895" rel="nofollow"&gt;6æ¬¡Kaggleè®¡ç®—æœºè§†è§‰ç±»æ¯”èµ›èµ›åæ„Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/63275166" rel="nofollow"&gt;Kaggleé¦–æˆ˜æ–©è·ç¬¬ä¸‰-å«æ˜Ÿå›¾åƒè¯†åˆ«&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-ç›®æ ‡æ£€æµ‹" class="anchor" aria-hidden="true" href="#ç›®æ ‡æ£€æµ‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ç›®æ ‡æ£€æµ‹&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;ensemble&lt;/li&gt;
&lt;li&gt;deformable&lt;/li&gt;
&lt;li&gt;sync bn&lt;/li&gt;
&lt;li&gt;ms train/test&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56792817" rel="nofollow"&gt;ç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„ä¼˜åŒ–ç­–ç•¥tricks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60612064" rel="nofollow"&gt;ç›®æ ‡æ£€æµ‹å°tricks--æ ·æœ¬ä¸å‡è¡¡å¤„ç†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/39262769" rel="nofollow"&gt;ç›®æ ‡æ£€æµ‹ç®—æ³•ä¸­çš„å¸¸è§trick&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jianshu.com/p/50158f8daf0d" rel="nofollow"&gt;Kaggleï¼šè‚ºç™Œè‡ªåŠ¨è¯Šæ–­ç³»ç»Ÿ3D Deep Leaky Noisy-or Network è®ºæ–‡é˜…è¯»&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://yq.aliyun.com/articles/89312" rel="nofollow"&gt;å¹²è´§|å¤§ç¥æ•™ä½ å¦‚ä½•å‚åŠ kaggleæ¯”èµ›â€”â€”æ ¹æ®CTæ‰«æå›¾é¢„æµ‹è‚ºç™Œ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-äº”-å¹´åº¦æ€»ç»“" class="anchor" aria-hidden="true" href="#äº”-å¹´åº¦æ€»ç»“"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;äº”. å¹´åº¦æ€»ç»“&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/53717510" rel="nofollow"&gt;æ–°å¹´å¤§ç¤¼åŒ…ï¼šæœºå™¨ä¹‹å¿ƒ2018é«˜åˆ†æ•™ç¨‹åˆé›†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59376548" rel="nofollow"&gt;CVPR2019ç›®æ ‡æ£€æµ‹æ–¹æ³•è¿›å±•ç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-å…­-ç§‘ç ”ç›¸å…³" class="anchor" aria-hidden="true" href="#å…­-ç§‘ç ”ç›¸å…³"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å…­. ç§‘ç ”ç›¸å…³&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-æ·±åº¦å­¦ä¹ æ¡†æ¶" class="anchor" aria-hidden="true" href="#æ·±åº¦å­¦ä¹ æ¡†æ¶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ·±åº¦å­¦ä¹ æ¡†æ¶&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-python3xå…ˆä¿®" class="anchor" aria-hidden="true" href="#python3xå…ˆä¿®"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python3.x(å…ˆä¿®)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/tutorial/" rel="nofollow"&gt;The Python Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" rel="nofollow"&gt;å»–é›ªå³°Pythonæ•™ç¨‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.runoob.com/python3/python3-tutorial.html" rel="nofollow"&gt;èœé¸Ÿæ•™ç¨‹&lt;/a&gt; Â  Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24162430" rel="nofollow"&gt;ç»™æ·±åº¦å­¦ä¹ å…¥é—¨è€…çš„Pythonå¿«é€Ÿæ•™ç¨‹ - åŸºç¡€ç¯‡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jackfrued/Python-100-Days"&gt;Python - 100å¤©ä»æ–°æ‰‹åˆ°å¤§å¸ˆ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-numpyå…ˆä¿®" class="anchor" aria-hidden="true" href="#numpyå…ˆä¿®"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Numpy(å…ˆä¿®)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.numpy.org/devdocs/user/quickstart.html" rel="nofollow"&gt;Quickstart tutorial&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.jianshu.com/p/3e566f09a0cf" rel="nofollow"&gt;Numpyå¿«é€Ÿå…¥é—¨(Numpy 1.14 å®˜æ–¹æ–‡æ¡£ä¸­æ–‡ç¿»è¯‘)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.numpy.org.cn/index.html" rel="nofollow"&gt;Numpyä¸­æ–‡æ–‡æ¡£&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24309547" rel="nofollow"&gt;ç»™æ·±åº¦å­¦ä¹ å…¥é—¨è€…çš„Pythonå¿«é€Ÿæ•™ç¨‹ - numpyå’ŒMatplotlibç¯‡&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-opencv-python" class="anchor" aria-hidden="true" href="#opencv-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Opencv-python&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html" rel="nofollow"&gt;OpenCV-Python Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cnblogs.com/Undo-self-blog/p/8423851.html" rel="nofollow"&gt;OpenCVå®˜æ–¹æ•™ç¨‹ä¸­æ–‡ç‰ˆï¼ˆFor Pythonï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/feilong_csdn/article/category/8037591" rel="nofollow"&gt;æ•°å­—å›¾åƒå¤„ç†ç³»åˆ—&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_40962368/article/category/7688903" rel="nofollow"&gt;python+OpenCVå›¾åƒå¤„ç†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24425116" rel="nofollow"&gt;ç»™æ·±åº¦å­¦ä¹ å…¥é—¨è€…çš„Pythonå¿«é€Ÿæ•™ç¨‹ - ç•ªå¤–ç¯‡ä¹‹Python-OpenCV&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-pandas" class="anchor" aria-hidden="true" href="#pandas"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pandas&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.jianshu.com/p/d9774cf1fea5?utm_campaign=maleskine&amp;amp;utm_content=note&amp;amp;utm_medium=seo_notes&amp;amp;utm_source=recommendation" rel="nofollow"&gt;Python æ•°æ®ç§‘å­¦å…¥é—¨æ•™ç¨‹ï¼šPandas&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-tensorflow" class="anchor" aria-hidden="true" href="#tensorflow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tensorflow&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/41667903" rel="nofollow"&gt;å¦‚ä½•é«˜æ•ˆåœ°å­¦ä¹  TensorFlow ä»£ç &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.tensorfly.cn/tfdoc/tutorials/overview.html" rel="nofollow"&gt;ä¸­æ–‡æ•™ç¨‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.w3cschool.cn/tensorflow_python/" rel="nofollow"&gt;TensorFlowå®˜æ–¹æ–‡æ¡£&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://web.stanford.edu/class/cs20si/syllabus.html" rel="nofollow"&gt;CS20:Tensorflow for DeepLearning Research&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62981537" rel="nofollow"&gt;å´æ©è¾¾TensorFlowä¸“é¡¹è¯¾ç¨‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35515805?group_id=967136289941897216" rel="nofollow"&gt;ã€å¹²è´§ã€‘å²ä¸Šæœ€å…¨çš„Tensorflowå­¦ä¹ èµ„æºæ±‡æ€»&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/hzy46/Deep-Learning-21-Examples"&gt;ã€Š21ä¸ªé¡¹ç›®ç©è½¬æ·±åº¦å­¦ä¹ â€”â€”â€”åŸºäºTensorFlowçš„å®è·µè¯¦è§£ã€‹&lt;/a&gt; Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59507137" rel="nofollow"&gt;æœ€å…¨Tensorflow2.0 å…¥é—¨æ•™ç¨‹æŒç»­æ›´æ–°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/search?o=desc&amp;amp;q=tensorflow+tutorial&amp;amp;s=&amp;amp;type=Repositories"&gt;Githubä¼˜ç§€å¼€æºæ•™ç¨‹&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-mxnet" class="anchor" aria-hidden="true" href="#mxnet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MXNet&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://zh.gluon.ai/#" rel="nofollow"&gt;Gluon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gluon-cv.mxnet.io/index.html#" rel="nofollow"&gt;GluonCV&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://gluon-nlp.mxnet.io/" rel="nofollow"&gt;GluonNLP&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-pytorch" class="anchor" aria-hidden="true" href="#pytorch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyTorch&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/ShusenTang/Dive-into-DL-PyTorch"&gt;Pytorchç‰ˆåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://pytorch-cn.readthedocs.io/zh/latest/" rel="nofollow"&gt;PyTorchä¸­æ–‡æ–‡æ¡£&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://pytorch.org/tutorials/index.html" rel="nofollow"&gt;WELCOME TO PYTORCH TUTORIALS&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/64895011" rel="nofollow"&gt;å²ä¸Šæœ€å…¨çš„PyTorchå­¦ä¹ èµ„æºæ±‡æ€»&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/INTERMT/Awesome-PyTorch-Chinese"&gt;ã€å¹²è´§ã€‘å²ä¸Šæœ€å…¨çš„PyTorchå­¦ä¹ èµ„æºæ±‡æ€»&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://mlelarge.github.io/dataflowr-web/cea_edf_inria.html" rel="nofollow"&gt;Hands-on tour to deep learning with PyTorch&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pythonå¯è§†åŒ–" class="anchor" aria-hidden="true" href="#pythonå¯è§†åŒ–"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pythonå¯è§†åŒ–&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/" rel="nofollow"&gt;Top 50 matplotlib Visualizations â€“ The Master Plots (with full python code)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jianshu.com/p/92e1a4497505" rel="nofollow"&gt;Pythonä¹‹MatPlotLibä½¿ç”¨æ•™ç¨‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/UfvEdzr-ZGmyT08yKDOchA" rel="nofollow"&gt;ååˆ†é’Ÿä¸Šæ‰‹matplotlibï¼Œå¼€å¯ä½ çš„pythonå¯è§†åŒ–&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24309547" rel="nofollow"&gt;ç»™æ·±åº¦å­¦ä¹ å…¥é—¨è€…çš„Pythonå¿«é€Ÿæ•™ç¨‹ - numpyå’ŒMatplotlibç¯‡&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-æ ‡æ³¨å·¥å…·" class="anchor" aria-hidden="true" href="#æ ‡æ³¨å·¥å…·"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ ‡æ³¨å·¥å…·&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ç›®æ ‡æ£€æµ‹æ ‡æ³¨å·¥å…·
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/tzutalin/labelImg"&gt;labelImg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;è¯­ä¹‰åˆ†å‰²æ ‡æ³¨å·¥å…·
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/wkentaro/labelme"&gt;labelme&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-æ•°æ®é›†" class="anchor" aria-hidden="true" href="#æ•°æ®é›†"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ•°æ®é›†&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35449783" rel="nofollow"&gt;1. 25ä¸ªæ·±åº¦å­¦ä¹ ç›¸å…³å…¬å¼€æ•°æ®é›†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35423943" rel="nofollow"&gt;2. è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ•°æ®é›†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pan.baidu.com/s/1o7QlUhO" rel="nofollow"&gt;3.å…¨å”è¯—(43030é¦–)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://people.eecs.berkeley.edu/~taesung_park/" rel="nofollow"&gt;4. ä¼¯å…‹åˆ©å¤§å­¦å…¬å¼€æ•°æ®é›†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36835964" rel="nofollow"&gt;5. ACL 2018èµ„æºï¼š100+ é¢„è®­ç»ƒçš„ä¸­æ–‡è¯å‘é‡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Embedding/Chinese-Word-Vectors"&gt;6. é¢„è®­ç»ƒä¸­æ–‡è¯å‘é‡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://academictorrents.com" rel="nofollow"&gt;7. å…¬å¼€æ•°æ®é›†ç§å­åº“&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/c20081052/article/details/79814082" rel="nofollow"&gt;8. è®¡ç®—æœºè§†è§‰ï¼Œæ·±åº¦å­¦ä¹ ï¼Œæ•°æ®æŒ–æ˜æ•°æ®é›†æ•´ç†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/accepthjp/article/details/51831026" rel="nofollow"&gt;9. è®¡ç®—æœºè§†è§‰è‘—åæ•°æ®é›†CV Datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/NNNNNNNNNNNNY/article/details/68485160" rel="nofollow"&gt;10. è®¡ç®—æœºè§†è§‰ç›¸å…³æ•°æ®é›†å’Œæ¯”èµ›&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/43846002" rel="nofollow"&gt;11. è¿™æ˜¯ä¸€ä»½éå¸¸å…¨é¢çš„å¼€æºæ•°æ®é›†ï¼Œä½ ï¼ŒçœŸçš„ä¸æƒ³è¦å—ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/weixin_40516558/article/details/81564464" rel="nofollow"&gt;12. äººç¾¤å¯†åº¦ä¼°è®¡ç°æœ‰ä¸»è¦æ•°æ®é›†ç‰¹ç‚¹åŠå…¶æ¯”è¾ƒ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.gwern.net/Danbooru2017" rel="nofollow"&gt;13. DANBOORU2017: A LARGE-SCALE CROWDSOURCED AND TAGGED ANIME ILLUSTRATION DATASET&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://robustsystems.coe.neu.edu/sites/robustsystems.coe.neu.edu/files/systems/projectpages/reiddataset.html" rel="nofollow"&gt;14. è¡Œäººé‡è¯†åˆ«æ•°æ®é›†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/56144877" rel="nofollow"&gt;15. è‡ªç„¶è¯­è¨€å¤„ç†å¸¸è§æ•°æ®é›†ã€è®ºæ–‡æœ€å…¨æ•´ç†åˆ†äº«&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://paperswithcode.com/" rel="nofollow"&gt;16. paper, code, sota&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/55627416" rel="nofollow"&gt;17. æ—·è§†RPCå¤§å‹å•†å“æ•°æ®é›†å‘å¸ƒï¼&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/60617001" rel="nofollow"&gt;18. CVPR 2019ã€Œå‡†æ»¡åˆ†ã€è®ºæ–‡ï¼šè‹±ä¼Ÿè¾¾æ¨å‡ºé¦–ä¸ªè·¨æ‘„åƒå¤´æ±½è½¦è·Ÿè¸ªæ•°æ®é›†(æ±½è½¦Re-ID)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/59052013" rel="nofollow"&gt;19.ã€OCRæŠ€æœ¯ã€‘å¤§æ‰¹é‡ç”Ÿæˆæ–‡å­—è®­ç»ƒé›†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/msra-nlc/MSParS"&gt;20. è¯­ä¹‰åˆ†ææ•°æ®é›†-MSRA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-ä¼šè®®åˆ—è¡¨" class="anchor" aria-hidden="true" href="#ä¼šè®®åˆ—è¡¨"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä¼šè®®åˆ—è¡¨&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/JackieTseng/conference_call_for_paper"&gt;å›½é™…ä¼šè®®æ—¥æœŸè¡¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/abhshkdz/ai-deadlines/"&gt;ai-deadlines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://handong1587.github.io/deep_learning/2017/12/18/keep-up-with-new-trends.html" rel="nofollow"&gt;Keep Up With New Trends&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/cserchen/article/details/40508181" rel="nofollow"&gt;è®¡ç®—æœºä¼šè®®æ’åç­‰çº§&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ccf.org.cn/xspj/rgzn/" rel="nofollow"&gt;ä¸­å›½è®¡ç®—æœºå­¦ä¼š(CCF)æ¨èå›½é™…å­¦æœ¯åˆŠç‰©å’Œä¼šè®®&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-è®ºæ–‡å†™ä½œå·¥å…·" class="anchor" aria-hidden="true" href="#è®ºæ–‡å†™ä½œå·¥å…·"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è®ºæ–‡å†™ä½œå·¥å…·&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://jingyan.baidu.com/article/b2c186c83c9b40c46ff6ff4f.html" rel="nofollow"&gt;Windows: Texlive+Texstudio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jingyan.baidu.com/article/7c6fb4280b024180642c90e4.html" rel="nofollow"&gt;Ubuntu: Texlive+Texmaker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-è®ºæ–‡ç”»å›¾å·¥å…·" class="anchor" aria-hidden="true" href="#è®ºæ–‡ç”»å›¾å·¥å…·"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è®ºæ–‡ç”»å›¾å·¥å…·&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Visio2016&lt;/li&gt;
&lt;li&gt;&lt;a href="#Python%E5%8F%AF%E8%A7%86%E5%8C%96"&gt;Matplotlib&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-è®ºæ–‡å†™ä½œæ•™ç¨‹" class="anchor" aria-hidden="true" href="#è®ºæ–‡å†™ä½œæ•™ç¨‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è®ºæ–‡å†™ä½œæ•™ç¨‹&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58752815" rel="nofollow"&gt;åˆ˜çŸ¥è¿œ_å¦‚ä½•å†™ä¸€ç¯‡åˆæ ¼çš„NLPè®ºæ–‡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nlp.csai.tsinghua.edu.cn/~ly/talks/cwmt14_tut.pdf" rel="nofollow"&gt;åˆ˜æ´‹_å¦‚ä½•å†™è®ºæ–‡_V7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://xpqiu.github.io/slides/20181019-PaperWriting.pdf" rel="nofollow"&gt;å¦‚ä½•ç«¯åˆ°ç«¯åœ°å†™ç§‘ç ”è®ºæ–‡-é‚±é”¡é¹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/33876355" rel="nofollow"&gt;è®ºæ–‡Introductionå†™ä½œå…¶ä¸€&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/52494933" rel="nofollow"&gt;è®ºæ–‡Introductionå†™ä½œå…¶äºŒ&lt;/a&gt;, &lt;a href="https://zhuanlan.zhihu.com/p/52494879" rel="nofollow"&gt;è®ºæ–‡Introductionå†™ä½œå…¶ä¸‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/c_179195484" rel="nofollow"&gt;æ¯•ä¸šè®ºæ–‡æ€ä¹ˆå†™&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-researchgo" class="anchor" aria-hidden="true" href="#researchgo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ResearchGo&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22323250?refer=wjdml" rel="nofollow"&gt;ResearchGo:ç ”ç©¶ç”Ÿæ´»ç¬¬ä¸€å¸–â€”â€”æ–‡çŒ®æ£€ç´¢ä¸ç®¡ç†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22402393?refer=wjdml" rel="nofollow"&gt;ResearchGo:ç ”ç©¶ç”Ÿæ´»ç¬¬äºŒè´´â€”â€”æ–‡çŒ®é˜…è¯»&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22622502?refer=wjdml" rel="nofollow"&gt;ResearchGo:ç ”ç©¶ç”Ÿæ´»ç¬¬ä¸‰å¸–â€”â€”é˜…è¯»è¾…åŠ©&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/23178836?refer=wjdml" rel="nofollow"&gt;ResearchGo:ç ”ç©¶ç”Ÿæ´»ç¬¬å››å¸–â€”â€”æ–‡çŒ®è°ƒç ”&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/23356843?refer=wjdml" rel="nofollow"&gt;ResearchGo:ç ”ç©¶ç”Ÿæ´»ç¬¬äº”å¸–â€”â€”æ–‡çŒ®ç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/23872063?refer=wjdml" rel="nofollow"&gt;ResearchGo:ç ”ç©¶ç”Ÿæ´»ç¬¬å…­å¸–â€”â€”å¦‚ä½•è®²è®ºæ–‡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25191025" rel="nofollow"&gt;ResearchGo:ç ”ç©¶ç”Ÿæ´»ç¬¬ä¸ƒå¸–â€”â€”ä¸“åˆ©æ£€ç´¢ä¸ç”³è¯·&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62100815" rel="nofollow"&gt;ResearchGo:ç ”ç©¶ç”Ÿæ´»ç¬¬å…«å¸–â€”â€”å†™è®ºæ–‡ã€åšPPTã€å†™æ–‡æ¡£å¿…å¤‡å·¥å…·é›†é”¦&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-æ¯•ä¸šè®ºæ–‡æ’ç‰ˆ" class="anchor" aria-hidden="true" href="#æ¯•ä¸šè®ºæ–‡æ’ç‰ˆ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ¯•ä¸šè®ºæ–‡æ’ç‰ˆ&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/52495345" rel="nofollow"&gt;åè¡€æ¨èæ”¶è—çš„å­¦ä½è®ºæ–‡æ’ç‰ˆæ•™ç¨‹ï¼ˆå®Œæ•´ç‰ˆï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35951260" rel="nofollow"&gt;è®ºæ–‡æ€ä¹ˆå†™â€”â€”å¦‚ä½•ä¿®æ”¹æ¯•ä¸šè®ºæ–‡æ ¼å¼&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-æœºå™¨å­¦ä¹ ç†è®ºä¸å®æˆ˜" class="anchor" aria-hidden="true" href="#æœºå™¨å­¦ä¹ ç†è®ºä¸å®æˆ˜"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æœºå™¨å­¦ä¹ ç†è®ºä¸å®æˆ˜&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/shunliz/Machine-Learning"&gt;æœºå™¨å­¦ä¹ åŸç†&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="star" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png"&gt;â­ï¸&lt;/g-emoji&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34534004" rel="nofollow"&gt;ID3ã€C4.5ã€CARTã€éšæœºæ£®æ—ã€baggingã€boostingã€Adaboostã€GBDTã€xgboostç®—æ³•æ€»ç»“&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.cnblogs.com/en-heng/p/5013995.html" rel="nofollow"&gt;æ•°æ®æŒ–æ˜åå¤§ç®—æ³•ç®€è¦è¯´æ˜&lt;/a&gt;ï¼Œ&lt;a href="https://blog.csdn.net/qq_42379006/article/details/80741808" rel="nofollow"&gt;æœºå™¨å­¦ä¹ åå¤§ç»å…¸ç®—æ³•å…¥é—¨&lt;/a&gt;ï¼Œ &lt;a href="https://www.cnblogs.com/ljt1412451704/p/9678248.html" rel="nofollow"&gt;ã€ç®—æ³•æ¨¡å‹ã€‘è½»æ¾çœ‹æ‡‚æœºå™¨å­¦ä¹ åå¤§å¸¸ç”¨ç®—æ³•&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=""&gt;AdaBooståˆ°GBDTç³»åˆ—&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25096501?refer=data-miner" rel="nofollow"&gt;å½“æˆ‘ä»¬åœ¨è°ˆè®ºGBDTï¼šä» AdaBoost åˆ° Gradient Boosting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25257856?refer=data-miner" rel="nofollow"&gt;å½“æˆ‘ä»¬åœ¨è°ˆè®ºGBDTï¼šGradient Boosting ç”¨äºåˆ†ç±»ä¸å›å½’&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25443980" rel="nofollow"&gt;å½“æˆ‘ä»¬åœ¨è°ˆè®ºGBDTï¼šå…¶ä»– Ensemble Learning ç®—æ³•&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/41809927" rel="nofollow"&gt;é›†æˆå­¦ä¹ ä¹‹bagging,stacking,boostingæ¦‚å¿µç†è§£&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ç•ªå¤–ç¯‡ä¹‹å‚…é‡Œå¶å˜æ¢&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/19763358" rel="nofollow"&gt;å‚…é‡Œå¶åˆ†æä¹‹ææ­»æ•™ç¨‹ï¼ˆå®Œæ•´ç‰ˆï¼‰æ›´æ–°äº2014.06.06&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/34899574/answer/612923473" rel="nofollow"&gt;å¦‚ä½•ç®€æ˜çš„æ€»ç»“å‚…é‡Œå¶å˜æ¢ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/clover13/article/details/79469851" rel="nofollow"&gt;ä»è¿ç»­æ—¶é—´å‚…é‡Œå¶çº§æ•°åˆ°å¿«é€Ÿå‚…é‡Œå¶å˜æ¢&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/enjoy_pascal/article/details/81478582" rel="nofollow"&gt;ååˆ†ç®€æ˜æ˜“æ‡‚çš„FFTï¼ˆå¿«é€Ÿå‚…é‡Œå¶å˜æ¢ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/hanxiaohu88/article/details/8245687" rel="nofollow"&gt;å‚…é‡Œå¶çº§æ•°æ¨å¯¼è¿‡ç¨‹&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-æœºå™¨å­¦ä¹ ç†è®ºç¯‡ä¹‹ç»å…¸ç®—æ³•" class="anchor" aria-hidden="true" href="#æœºå™¨å­¦ä¹ ç†è®ºç¯‡ä¹‹ç»å…¸ç®—æ³•"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æœºå™¨å­¦ä¹ ç†è®ºç¯‡ä¹‹ç»å…¸ç®—æ³•&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-ä¿¡æ¯è®º" class="anchor" aria-hidden="true" href="#ä¿¡æ¯è®º"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä¿¡æ¯è®º&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35423404" rel="nofollow"&gt;1. æœºå™¨å­¦ä¹ ä¸­çš„å„ç§ç†µ&lt;/a&gt; Â  Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32985487" rel="nofollow"&gt;2. ä»é¦™å†œç†µåˆ°æ‰‹æ¨KLæ•£åº¦ï¼šçºµè§ˆæœºå™¨å­¦ä¹ ä¸­çš„ä¿¡æ¯è®º&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-å¤šå±‚æ„ŸçŸ¥æœºmlp" class="anchor" aria-hidden="true" href="#å¤šå±‚æ„ŸçŸ¥æœºmlp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å¤šå±‚æ„ŸçŸ¥æœº(MLP)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/baidu_33718858/article/details/84972537" rel="nofollow"&gt;å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰å­¦ä¹ ä¸æ€»ç»“åšå®¢&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-kè¿‘é‚»knn" class="anchor" aria-hidden="true" href="#kè¿‘é‚»knn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;kè¿‘é‚»(KNN)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/sinat_30353259/article/details/80901746" rel="nofollow"&gt;æœºå™¨å­¦ä¹ ä¹‹KNNï¼ˆkè¿‘é‚»ï¼‰ç®—æ³•è¯¦è§£&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-kå‡å€¼k-means" class="anchor" aria-hidden="true" href="#kå‡å€¼k-means"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;kå‡å€¼(K-means)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_32892383/article/details/80107795" rel="nofollow"&gt;Kmeansèšç±»ç®—æ³•è¯¦è§£&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-æœ´ç´ è´å¶æ–¯naive-bayesian" class="anchor" aria-hidden="true" href="#æœ´ç´ è´å¶æ–¯naive-bayesian"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æœ´ç´ è´å¶æ–¯(Naive Bayesian)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/qq_32690999/article/details/78737393" rel="nofollow"&gt;æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼ˆNaive Bayesian Classifierï¼‰&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/qq_17073497/article/details/81076250" rel="nofollow"&gt;æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ è¯¦ç»†è§£æ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-å†³ç­–æ ‘decision-tree" class="anchor" aria-hidden="true" href="#å†³ç­–æ ‘decision-tree"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å†³ç­–æ ‘(Decision Tree)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/c406495762/article/details/75663451" rel="nofollow"&gt;Python3ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹å­¦ä¹ ç¬”è®°ï¼ˆäºŒï¼‰ï¼šå†³ç­–æ ‘åŸºç¡€ç¯‡ä¹‹è®©æˆ‘ä»¬ä»ç›¸äº²è¯´èµ·&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/c406495762/article/details/76262487" rel="nofollow"&gt;Python3ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹å­¦ä¹ ç¬”è®°ï¼ˆä¸‰ï¼‰ï¼šå†³ç­–æ ‘å®æˆ˜ç¯‡ä¹‹ä¸ºè‡ªå·±é…ä¸ªéšå½¢çœ¼é•œ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cuijiahua.com/blog/2017/12/ml_13_regtree_1.html" rel="nofollow"&gt;æœºå™¨å­¦ä¹ å®æˆ˜æ•™ç¨‹ï¼ˆåä¸‰ï¼‰ï¼šæ ‘å›å½’åŸºç¡€ç¯‡ä¹‹CARTç®—æ³•ä¸æ ‘å‰ªæ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/gamer_gyt/article/details/51242815" rel="nofollow"&gt;ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹åŸºäºä¿¡æ¯è®ºçš„ä¸‰ç§å†³ç­–æ ‘ç®—æ³•(ID3,C4.5,CART)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/31404571" rel="nofollow"&gt;è¯´è¯´å†³ç­–æ ‘å‰ªæç®—æ³•&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/namelessml/article/details/52595066" rel="nofollow"&gt;æœºå™¨å­¦ä¹ å®æˆ˜ ç¬¬ä¹ç«  æ ‘å›å½’&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u014688145/article/details/53212112" rel="nofollow"&gt;å†³ç­–æ ‘å€¼ID3ã€C4.5å®ç°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u014688145/article/details/53326910" rel="nofollow"&gt;å†³ç­–æ ‘å€¼CARTå®ç°&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-éšæœºæ£®æ—random-forest" class="anchor" aria-hidden="true" href="#éšæœºæ£®æ—random-forest"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;éšæœºæ£®æ—(Random Forest)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/sb19931201/article/details/52601058" rel="nofollow"&gt;éšæœºæ£®æ—ï¼ˆRandom Forestï¼‰å…¥é—¨ä¸å®æˆ˜&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-é€»è¾‘å›å½’logistic-regression" class="anchor" aria-hidden="true" href="#é€»è¾‘å›å½’logistic-regression"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;é€»è¾‘å›å½’(Logistic Regression)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62653034" rel="nofollow"&gt;ã€æœºå™¨å­¦ä¹ é¢è¯•é¢˜ã€‘é€»è¾‘å›å½’ç¯‡&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-æ”¯æŒå‘é‡æœºsvm" class="anchor" aria-hidden="true" href="#æ”¯æŒå‘é‡æœºsvm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ”¯æŒå‘é‡æœº(SVM)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E9%80%9A%E4%BF%97%E5%AF%BC%E8%AE%BA%EF%BC%88%E7%90%86%E8%A7%A3SVM%E7%9A%84%E4%B8%89%E5%B1%82%E5%A2%83%E7%95%8C%EF%BC%89LaTeX%E6%9C%80%E6%96%B0%E7%89%88_2015.1.9.pdf"&gt;SVMé€šä¿—å¯¼è®º July&lt;/a&gt; Â  Â  Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/c406495762/article/details/78072313" rel="nofollow"&gt;Python3ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹å­¦ä¹ ç¬”è®°ï¼ˆå…«ï¼‰ï¼šæ”¯æŒå‘é‡æœºåŸç†ç¯‡ä¹‹æ‰‹æ’•çº¿æ€§SVM ï¼ˆSMOè®­ç»ƒè¿‡ç¨‹æ€»ç»“å¾—æ¸…æ™°æ˜“æ‡‚ï¼‰&lt;/a&gt; Â  Â  Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/leonis_v/article/details/50688766" rel="nofollow"&gt;svmæ ¸å‡½æ•°çš„ç†è§£å’Œé€‰æ‹©&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/huang1024rui/article/details/51510611" rel="nofollow"&gt;æ ¸å‡½æ•°å’Œå¾„å‘åŸºæ ¸å‡½æ•° (Radial Basis Function)--RBF&lt;/a&gt; Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/xiaowei_cqu/article/details/35993729" rel="nofollow"&gt;SVMæ ¸å‡½æ•°&lt;/a&gt; Â  Â  Â &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-æå‡æ–¹æ³•adaboost" class="anchor" aria-hidden="true" href="#æå‡æ–¹æ³•adaboost"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æå‡æ–¹æ³•(Adaboost)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25096501" rel="nofollow"&gt;å½“æˆ‘ä»¬åœ¨è°ˆè®ºGBDTï¼šä» AdaBoost åˆ° Gradient Boosting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-æ¢¯åº¦æå‡å†³ç­–æ ‘gbdt" class="anchor" aria-hidden="true" href="#æ¢¯åº¦æå‡å†³ç­–æ ‘gbdt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ¢¯åº¦æå‡å†³ç­–æ ‘(GBDT)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35645973" rel="nofollow"&gt;LightGBMå¤§æˆ˜XGBoost&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34698733" rel="nofollow"&gt;æ¦‚è¿°XGBoostã€Light GBMå’ŒCatBoostçš„åŒä¸ä¸åŒ&lt;/a&gt; Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36339161" rel="nofollow"&gt;æ¢¯åº¦æå‡å†³ç­–æ ‘&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/30339807" rel="nofollow"&gt;GBDTåŸç†åŠåº”ç”¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/31654000" rel="nofollow"&gt;XGBOOSTåŸç†ç¯‡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/sb19931201/article/details/52557382" rel="nofollow"&gt;xgboostå…¥é—¨ä¸å®æˆ˜ï¼ˆåŸç†ç¯‡ï¼‰&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://blog.csdn.net/sb19931201/article/details/52577592" rel="nofollow"&gt;xgboostå…¥é—¨ä¸å®æˆ˜ï¼ˆå®æˆ˜è°ƒå‚ç¯‡ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/41417638" rel="nofollow"&gt;ã€å¹²è´§åˆé›†ã€‘é€šä¿—ç†è§£kaggleæ¯”èµ›å¤§æ€å™¨xgboost&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/bf02jgtrs00xktcx/article/details/82719765" rel="nofollow"&gt;GBDTåˆ†ç±»çš„åŸç†åŠPythonå®ç°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/shine19930820/article/details/71713680" rel="nofollow"&gt;GBDTåŸç†åŠåˆ©ç”¨GBDTæ„é€ æ–°çš„ç‰¹å¾-Pythonå®ç°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jianshu.com/p/47e73a985ba1" rel="nofollow"&gt;Python+GBDTç®—æ³•å®æˆ˜â€”â€”é¢„æµ‹å®ç°100%å‡†ç¡®ç‡&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-emæœŸæœ›æœ€å¤§åŒ–" class="anchor" aria-hidden="true" href="#emæœŸæœ›æœ€å¤§åŒ–"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;EM(æœŸæœ›æœ€å¤§åŒ–)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/36331115" rel="nofollow"&gt;äººäººéƒ½æ‡‚çš„EMç®—æ³• &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61768577" rel="nofollow"&gt;EMç®—æ³•å…¥é—¨æ–‡ç« &lt;/a&gt; Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-é«˜æ–¯æ··åˆæ¨¡å‹gmm" class="anchor" aria-hidden="true" href="#é«˜æ–¯æ··åˆæ¨¡å‹gmm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;é«˜æ–¯æ··åˆæ¨¡å‹(GMM)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/67107370" rel="nofollow"&gt;é«˜æ–¯æ··åˆæ¨¡å‹ä¸EMç®—æ³•çš„æ•°å­¦åŸç†åŠåº”ç”¨å®ä¾‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/30483076" rel="nofollow"&gt;é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹mdp" class="anchor" aria-hidden="true" href="#é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹mdp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹(MDP)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35124726" rel="nofollow"&gt;é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹ä¹‹Markov Processesï¼ˆé©¬å°”ç§‘å¤«è¿‡ç¨‹ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35231424" rel="nofollow"&gt;é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹ä¹‹Markov Reward Processï¼ˆé©¬å°”ç§‘å¤«å¥–åŠ±è¿‡ç¨‹ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35261164" rel="nofollow"&gt;é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹ä¹‹Bellman Equationï¼ˆè´å°”æ›¼æ–¹ç¨‹ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35354956" rel="nofollow"&gt;é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹ä¹‹Markov Decision Process(é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35373905" rel="nofollow"&gt;é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹ä¹‹æœ€ä¼˜ä»·å€¼å‡½æ•°ä¸æœ€ä¼˜ç­–ç•¥&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-æ¡ä»¶éšæœºåœºcrf-åˆ¤åˆ«å¼æ¨¡å‹" class="anchor" aria-hidden="true" href="#æ¡ä»¶éšæœºåœºcrf-åˆ¤åˆ«å¼æ¨¡å‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ¡ä»¶éšæœºåœº(CRF, åˆ¤åˆ«å¼æ¨¡å‹)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.jianshu.com/p/55755fc649b1" rel="nofollow"&gt;å¦‚ä½•è½»æ¾æ„‰å¿«åœ°ç†è§£æ¡ä»¶éšæœºåœº&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/35866596" rel="nofollow"&gt;å¦‚ä½•ç”¨ç®€å•æ˜“æ‡‚çš„ä¾‹å­è§£é‡Šæ¡ä»¶éšæœºåœºï¼ˆCRFï¼‰æ¨¡å‹ï¼Ÿå®ƒå’ŒHMMæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u013378306/article/details/55213029" rel="nofollow"&gt;HMM ,MHMM,CRF ä¼˜ç¼ºç‚¹ä¸åŒºåˆ«&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-é™ç»´ç®—æ³•" class="anchor" aria-hidden="true" href="#é™ç»´ç®—æ³•"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;é™ç»´ç®—æ³•&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/62470700" rel="nofollow"&gt;æ•°æ®é™ç»´ç®—æ³•-ä»PCAåˆ°LargeVis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-ä¸»æˆåˆ†åˆ†æpca" class="anchor" aria-hidden="true" href="#ä¸»æˆåˆ†åˆ†æpca"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä¸»æˆåˆ†åˆ†æ(PCA)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/program_developer/article/details/80632779" rel="nofollow"&gt;ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰åŸç†è¯¦è§£&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/hustqb/article/details/78394058" rel="nofollow"&gt;å›¾æ–‡å¹¶èŒ‚çš„PCAæ•™ç¨‹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.360doc.com/content/13/1124/02/9482_331688889.shtml" rel="nofollow"&gt;PCAæ•°å­¦åŸç†&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-å¥‡å¼‚å€¼åˆ†è§£svd" class="anchor" aria-hidden="true" href="#å¥‡å¼‚å€¼åˆ†è§£svd"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å¥‡å¼‚å€¼åˆ†è§£(SVD)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html" rel="nofollow"&gt;å¼ºå¤§çš„çŸ©é˜µå¥‡å¼‚å€¼åˆ†è§£(SVD)åŠå…¶åº”ç”¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29846048" rel="nofollow"&gt;å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/zhongkejingwang/article/details/43053513" rel="nofollow"&gt;å¥‡å¼‚å€¼åˆ†è§£(SVD)åŸç†è¯¦è§£åŠæ¨å¯¼&lt;/a&gt; Â  Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/zhongkejingwang/article/details/43083603" rel="nofollow"&gt;SVDåœ¨æ¨èç³»ç»Ÿä¸­çš„åº”ç”¨è¯¦è§£ä»¥åŠç®—æ³•æ¨å¯¼&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-çº¿æ€§åˆ¤åˆ«åˆ†ælda" class="anchor" aria-hidden="true" href="#çº¿æ€§åˆ¤åˆ«åˆ†ælda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;çº¿æ€§åˆ¤åˆ«åˆ†æ(LDA)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/42238953" rel="nofollow"&gt;æ•™ç§‘ä¹¦ä¸Šçš„LDAä¸ºä»€ä¹ˆé•¿è¿™ä¸ªæ ·å­ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-æ ‡ç­¾ä¼ æ’­ç®—æ³•label-propagation-algorithm--" class="anchor" aria-hidden="true" href="#æ ‡ç­¾ä¼ æ’­ç®—æ³•label-propagation-algorithm--"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ ‡ç­¾ä¼ æ’­ç®—æ³•(Label Propagation Algorithm) Â  Â &lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/zouxy09/article/details/49105265" rel="nofollow"&gt;æ ‡ç­¾ä¼ æ’­ç®—æ³•ï¼ˆLabel Propagationï¼‰åŠPythonå®ç°&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/books/Semi-Supervised%20Learning%20with%20Graphs.pdf"&gt;å‚è€ƒèµ„æ–™&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-è’™å¡”å¡ç½—æ ‘æœç´¢mcts" class="anchor" aria-hidden="true" href="#è’™å¡”å¡ç½—æ ‘æœç´¢mcts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è’™å¡”å¡ç½—æ ‘æœç´¢(MCTS)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34950988" rel="nofollow"&gt;è’™ç‰¹å¡æ´›æ ‘æœç´¢å…¥é—¨æŒ‡å—&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-é›†æˆensemble" class="anchor" aria-hidden="true" href="#é›†æˆensemble"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;é›†æˆ(Ensemble)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_30189255/article/details/51532442" rel="nofollow"&gt;é›†æˆå­¦ä¹ æ³•ä¹‹baggingæ–¹æ³•å’Œboostingæ–¹æ³•&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/Mr_tyting/article/details/72957853" rel="nofollow"&gt;Bagging,Boosting,Stacking&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/65888174" rel="nofollow"&gt;å¸¸ç”¨çš„æ¨¡å‹é›†æˆæ–¹æ³•ä»‹ç»ï¼šbaggingã€boosting ã€stacking&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-tåˆ†å¸ƒéšæœºé‚»å±…åµŒå…¥tsne" class="anchor" aria-hidden="true" href="#tåˆ†å¸ƒéšæœºé‚»å±…åµŒå…¥tsne"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;tåˆ†å¸ƒéšæœºé‚»å±…åµŒå…¥(TSNE)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/u012162613/article/details/45920827" rel="nofollow"&gt;æµå½¢å­¦ä¹ -é«˜ç»´æ•°æ®çš„é™ç»´ä¸å¯è§†åŒ–&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/flyingzhan/article/details/79521765" rel="nofollow"&gt;tSNE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-è°±èšç±»spectral-clustering" class="anchor" aria-hidden="true" href="#è°±èšç±»spectral-clustering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è°±èšç±»(Spectral Clustering)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_24519677/article/details/82291867" rel="nofollow"&gt;è°±èšç±»ï¼ˆSpectral Clusteringï¼‰ç®—æ³•ä»‹ç»&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/xueyingxue001/article/details/51966980" rel="nofollow"&gt;èšç±»5--è°±å’Œè°±èšç±»&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-å¼‚å¸¸ç‚¹æ£€æµ‹" class="anchor" aria-hidden="true" href="#å¼‚å¸¸ç‚¹æ£€æµ‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å¼‚å¸¸ç‚¹æ£€æµ‹&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/280696035/answer/417091151" rel="nofollow"&gt;æ•°æ®æŒ–æ˜ä¸­å¸¸è§çš„ã€Œå¼‚å¸¸æ£€æµ‹ã€ç®—æ³•æœ‰å“ªäº›ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/30169110" rel="nofollow"&gt;å¼‚å¸¸ç‚¹æ£€æµ‹ç®—æ³•ç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-æœºå™¨å­¦ä¹ å®æˆ˜ç¯‡" class="anchor" aria-hidden="true" href="#æœºå™¨å­¦ä¹ å®æˆ˜ç¯‡"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æœºå™¨å­¦ä¹ å®æˆ˜ç¯‡&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247484110&amp;amp;idx=1&amp;amp;sn=b016e270d7b7707e6ad41a81ca45fc28&amp;amp;chksm=c0791fd7f70e96c103a8a2aebee166ce14f5648b3b889dd85dd9786f48b6b8269f11e5e27e1c&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;15åˆ†é’Ÿå¸¦ä½ å…¥é—¨sklearnä¸æœºå™¨å­¦ä¹ â€”â€”åˆ†ç±»ç®—æ³•ç¯‡&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="https://zhuanlan.zhihu.com/p/62034592" rel="nofollow"&gt;å¦‚ä½•ä¸ºä½ çš„å›å½’é—®é¢˜é€‰æ‹©æœ€åˆé€‚çš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blackblog.tech/2018/02/05/%E5%8D%81%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8Bsklearn-1/" rel="nofollow"&gt;ååˆ†é’Ÿä¸Šæ‰‹sklearnï¼šå®‰è£…ï¼Œè·å–æ•°æ®ï¼Œæ•°æ®é¢„å¤„ç†&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href="http://blackblog.tech/2018/02/05/%E5%8D%81%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8Bsklearn-2/" rel="nofollow"&gt;ååˆ†é’Ÿä¸Šæ‰‹sklearnï¼šç‰¹å¾æå–ï¼Œå¸¸ç”¨æ¨¡å‹ï¼Œäº¤å‰éªŒè¯&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/machinelearningmindset/machine-learning-course"&gt;Machine Learning Course with Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/c406495762/column/info/16415" rel="nofollow"&gt;Python3æœºå™¨å­¦ä¹ &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-æœºå™¨å­¦ä¹ æ·±åº¦å­¦ä¹ çš„ä¸€äº›ç ”ç©¶æ–¹å‘" class="anchor" aria-hidden="true" href="#æœºå™¨å­¦ä¹ æ·±åº¦å­¦ä¹ çš„ä¸€äº›ç ”ç©¶æ–¹å‘"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ çš„ä¸€äº›ç ”ç©¶æ–¹å‘&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-å¤šä»»åŠ¡å­¦ä¹ " class="anchor" aria-hidden="true" href="#å¤šä»»åŠ¡å­¦ä¹ "&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å¤šä»»åŠ¡å­¦ä¹ &lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27421983" rel="nofollow"&gt;æ¨¡å‹æ±‡æ€»-14 å¤šä»»åŠ¡å­¦ä¹ -Multitask Learningæ¦‚è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cnblogs.com/shuzirank/p/7141017.html" rel="nofollow"&gt;(è¯‘)æ·±åº¦ç¥ç»ç½‘ç»œçš„å¤šä»»åŠ¡å­¦ä¹ æ¦‚è§ˆ(An Overview of Multi-task Learning in Deep Neural Networks)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-é›¶æ¬¡å­¦ä¹ zero-shot-learning" class="anchor" aria-hidden="true" href="#é›¶æ¬¡å­¦ä¹ zero-shot-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;é›¶æ¬¡å­¦ä¹ (Zero Shot Learning)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34656727" rel="nofollow"&gt;é›¶æ¬¡å­¦ä¹ ï¼ˆZero-Shot Learningï¼‰å…¥é—¨&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-å°æ ·æœ¬å­¦ä¹ few-shot-learning" class="anchor" aria-hidden="true" href="#å°æ ·æœ¬å­¦ä¹ few-shot-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å°æ ·æœ¬å­¦ä¹ (Few-Shot Learning)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/xhw205/article/details/79491649" rel="nofollow"&gt;few-shot learningæ˜¯ä»€ä¹ˆ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34656727" rel="nofollow"&gt;é›¶æ¬¡å­¦ä¹ ï¼ˆZero-Shot Learningï¼‰å…¥é—¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/61215293" rel="nofollow"&gt;å°æ ·æœ¬å­¦ä¹ ï¼ˆFew-shot Learningï¼‰ç»¼è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/few-shot-learning-in-cvpr19-6c6892fc8c5" rel="nofollow"&gt;Few-Shot Learning in CVPR 2019&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/mao_feng/article/details/78939864" rel="nofollow"&gt;å½“å°æ ·æœ¬é‡ä¸Šæœºå™¨å­¦ä¹  fewshot learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-å¤šè§†è§‰å­¦ä¹ multi-view-learning" class="anchor" aria-hidden="true" href="#å¤šè§†è§‰å­¦ä¹ multi-view-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å¤šè§†è§‰å­¦ä¹ (Multi-View Learning)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/danliwoo/article/details/79278574" rel="nofollow"&gt;Multi-view Learning å¤šè§†è§’å­¦ä¹ å…¥é—¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/shine19930820/article/details/77426599" rel="nofollow"&gt;å¤šè§†è§’å­¦ä¹  (Multi-View Learning)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-embedding" class="anchor" aria-hidden="true" href="#embedding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Embedding&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/53194407" rel="nofollow"&gt;ä¸‡ç‰©çš†Embeddingï¼Œä»ç»å…¸çš„word2vecåˆ°æ·±åº¦å­¦ä¹ åŸºæœ¬æ“ä½œitem2vec&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27830489" rel="nofollow"&gt;YJangoçš„Word Embedding--ä»‹ç»&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-è¿ç§»å­¦ä¹ " class="anchor" aria-hidden="true" href="#è¿ç§»å­¦ä¹ "&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è¿ç§»å­¦ä¹ &lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/linolzhang/article/details/73358219" rel="nofollow"&gt;1. è¿ç§»å­¦ä¹ ï¼šç»å…¸ç®—æ³•è§£æ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zhihu.com/question/41979241" rel="nofollow"&gt;2. ä»€ä¹ˆæ˜¯è¿ç§»å­¦ä¹  (Transfer Learning)ï¼Ÿè¿™ä¸ªé¢†åŸŸå†å²å‘å±•å‰æ™¯å¦‚ä½•ï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Mikoto10032/DeepLearning/blob/master/notes/%E6%97%A5%E5%B8%B8%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/2018_4_12_%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0.pdf"&gt;3. è¿ç§»å­¦ä¹ ä¸ªäººç¬”è®°&lt;/a&gt; Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/XJTU_NOC_Wei/article/details/77850221" rel="nofollow"&gt;è¿ç§»å­¦ä¹ æ€»ç»“(One Shot Learning, Zero Shot Learning)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-åŸŸè‡ªé€‚åº”" class="anchor" aria-hidden="true" href="#åŸŸè‡ªé€‚åº”"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;åŸŸè‡ªé€‚åº”&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27519182" rel="nofollow"&gt;Domain Adaptationè§†é¢‘æ•™ç¨‹ï¼ˆé™„PPTï¼‰åŠç»å…¸è®ºæ–‡åˆ†äº«&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/27449079" rel="nofollow"&gt;æ¨¡å‹æ±‡æ€»15 é¢†åŸŸé€‚åº”æ€§Domain Adaptationã€One-shot/zero-shot Learningæ¦‚è¿°&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/mao_xiao_feng/article/details/54426101" rel="nofollow"&gt;ã€æ·±åº¦å­¦ä¹ ã€‘è®ºæ–‡å¯¼è¯»ï¼šæ— ç›‘ç£åŸŸé€‚åº”ï¼ˆDeep Transfer Network: Unsupervised Domain Adaptationï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/37298073" rel="nofollow"&gt;ã€è®ºæ–‡é˜…è¯»ç¬”è®°ã€‘åŸºäºåå‘ä¼ æ’­çš„æ— ç›‘ç£åŸŸè‡ªé€‚åº”ç ”ç©¶&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21441807" rel="nofollow"&gt;ã€Valseå¤§ä¼šé¦–å‘ã€‘é¢†åŸŸè‡ªé€‚åº”åŠå…¶åœ¨äººè„¸è¯†åˆ«ä¸­çš„åº”ç”¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/41126114" rel="nofollow"&gt;CVPR 2018ï¼šåŸºäºåŸŸé€‚åº”å¼±ç›‘ç£å­¦ä¹ çš„ç›®æ ‡æ£€æµ‹&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-å…ƒå­¦ä¹ " class="anchor" aria-hidden="true" href="#å…ƒå­¦ä¹ "&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å…ƒå­¦ä¹ &lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35869158?group_id=970310501209645056" rel="nofollow"&gt;OpenAIæå‡ºæ–°å‹å…ƒå­¦ä¹ æ–¹æ³•EPGï¼Œè°ƒæ•´æŸå¤±å‡½æ•°å®ç°æ–°ä»»åŠ¡ä¸Šçš„å¿«é€Ÿè®­ç»ƒ&lt;/a&gt; Â  Â  Â &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-å¼ºåŒ–å­¦ä¹ " class="anchor" aria-hidden="true" href="#å¼ºåŒ–å­¦ä¹ "&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å¼ºåŒ–å­¦ä¹ &lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25498081" rel="nofollow"&gt;å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰çŸ¥è¯†æ•´ç†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/34918639" rel="nofollow"&gt;å¼ºåŒ–å­¦ä¹ ä»å…¥é—¨åˆ°æ”¾å¼ƒçš„èµ„æ–™&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25498081" rel="nofollow"&gt;å¼ºåŒ–å­¦ä¹ å…¥é—¨&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/25498081" rel="nofollow"&gt;å¼ºåŒ–å­¦ä¹ å…¥é—¨ ç¬¬ä¸€è®² MDP&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35882937" rel="nofollow"&gt;å¼ºåŒ–å­¦ä¹ â€”â€”ä»Q-Learningåˆ°DQNåˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35688924" rel="nofollow"&gt;ä»å¼ºåŒ–å­¦ä¹ åˆ°æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆä¸Šï¼‰&lt;/a&gt; Â  Â  Â  Â  Â  Â  Â  Â  Â &lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/35965070" rel="nofollow"&gt;ä»å¼ºåŒ–å­¦ä¹ åˆ°æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆä¸‹ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/37048004" rel="nofollow"&gt;ä¸€æ–‡å¸¦ä½ ç†è§£Q-Learningçš„æœç´¢ç­–ç•¥&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-æ¨èç³»ç»Ÿ" class="anchor" aria-hidden="true" href="#æ¨èç³»ç»Ÿ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ¨èç³»ç»Ÿ&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/29969721" rel="nofollow"&gt;æ¨èç®—æ³•ç›¸å…³çš„æ–‡æ¡£æ•´ç†&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58805184" rel="nofollow"&gt;Embeddingä»å…¥é—¨åˆ°ä¸“å®¶å¿…è¯»çš„åç¯‡è®ºæ–‡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;æ¨èç³»ç»Ÿä¹‹è·¯
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650760136&amp;amp;idx=2&amp;amp;sn=afc75d6bf614bc7929b6ea9cb1abb260&amp;amp;chksm=871aa7b6b06d2ea0129ec7b06bf7b2448c3a55d485d6b80a066d622709066242fe7c925160c3&amp;amp;scene=21#wechat_redirect" rel="nofollow"&gt;æ¨èç³»ç»Ÿä¹‹è·¯ (1)ï¼šèµ°ä¸Šæ¨èç³»ç»Ÿè¿™æ¡è·¯&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/64722876" rel="nofollow"&gt;æ¨èç³»ç»Ÿä¹‹è·¯ (2)ï¼šäº§å“èšç±»&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-è¯­ä¹‰åˆ†å‰²ç›¸å…³ç®—æ³•" class="anchor" aria-hidden="true" href="#è¯­ä¹‰åˆ†å‰²ç›¸å…³ç®—æ³•"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è¯­ä¹‰åˆ†å‰²ç›¸å…³ç®—æ³•&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/qq_20084101/article/details/80432960" rel="nofollow"&gt;å¹²è´§ | ä¸€æ–‡æ¦‚è§ˆä¸»è¦è¯­ä¹‰åˆ†å‰²ç½‘ç»œ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/iamoldpan/article/details/78799857" rel="nofollow"&gt;æ·±åº¦å­¦ä¹ ä¸­IUã€IoU(Intersection over Union)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/" rel="nofollow"&gt;Selective Search for Object Detection &lt;/a&gt;&lt;a href="https://blog.csdn.net/guoyunfei20/article/details/78723646" rel="nofollow"&gt;ï¼ˆè¯‘æ–‡ï¼‰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/shuzfan/article/details/52711706" rel="nofollow"&gt;NMSâ€”â€”éæå¤§å€¼æŠ‘åˆ¶&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/zijin0802034/article/details/77685438" rel="nofollow"&gt;è¾¹æ¡†å›å½’(Bounding Box Regression)è¯¦è§£&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-ä¸€äº›è®¡åˆ’" class="anchor" aria-hidden="true" href="#ä¸€äº›è®¡åˆ’"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä¸€äº›è®¡åˆ’&lt;/h2&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; æœ‰ç©ºå†æ•´ç†ä¸‹æ•´ä¸ªåˆ—è¡¨çš„ç»“æ„, å†æ”¶é›†ä¸‹æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ å…¥é—¨çš„ç³»åˆ—æ•™ç¨‹, å¹¶é™„ä»¥ä»£ç å®ç°, äº‰å–å…¨é¢è€Œç®€å•ä¸Šæ‰‹&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; æœ¬å­¦æœŸå­¦å®Œã€Šdocker_practiceã€‹&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Mikoto10032</author><guid isPermaLink="false">https://github.com/Mikoto10032/DeepLearning</guid><pubDate>Sun, 09 Feb 2020 00:15:00 GMT</pubDate></item><item><title>jeffmli/TinderAutomation #16 in Jupyter Notebook, Today</title><link>https://github.com/jeffmli/TinderAutomation</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tinderautomation" class="anchor" aria-hidden="true" href="#tinderautomation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TinderAutomation&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/tinder.png?raw=true"&gt;&lt;img src="/img/tinder.png?raw=true" alt="Alt text" title="Optional Title" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-1-introduction" class="anchor" aria-hidden="true" href="#1-introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;The other day, while I sat on the toilet to take a &lt;em&gt;poop&lt;/em&gt;, I whipped out my phone, opened up the king of all toilet apps: Tinder. I clicked open the application and started the mindless swiping. &lt;em&gt;Left&lt;/em&gt; &lt;em&gt;Right&lt;/em&gt; &lt;em&gt;Left&lt;/em&gt; &lt;em&gt;Right&lt;/em&gt; &lt;em&gt;Left&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Now that we have dating apps, everyone suddenly has access to exponentially more people to date compared to the pre-app era. The Bay Area tends to lean more men than women. The Bay Area also attracts uber-successful, smart men from all around the world. As a big-foreheaded, 5 foot 9 asian man who doesn't take many pictures, there's fierce competition within the San Francisco dating sphere.&lt;/p&gt;
&lt;p&gt;From talking to female friends using dating apps, females in San Francisco can get a match almost every other swipe. Assuming females get 20 matches in an hour, they do not have the time to go out with every man that messages them. Obviously, they'll pick the man they like most based off their profile + initial message.&lt;/p&gt;
&lt;p&gt;I'm an above-average looking guy. However, in a sea of asian men, based purely on looks, my face wouldn't pop out the page. In a stock exchange, we have buyers and sellers. The top investors earn a profit through informational advantages. At the poker table, you become profitable if you have a skill advantage over the other people on your table. If we think of dating as a "competitive marketplace", how do you give yourself the edge over the competition? A competitive advantage could be: amazing looks, career success, social-charm, adventurous, proximity, great social circle etc.&lt;/p&gt;
&lt;p&gt;On dating apps, men &amp;amp; women who have a competitive advantage in photos &amp;amp; texting skills will reap the highest ROI from the app. As a result, I've broken down the reward system from dating apps down to a formula, assuming we normalize message quality from a 0 to 1 scale:&lt;/p&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/formula.gif"&gt;&lt;img src="/img/formula.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The better photos/good looking you are you have, the less you need to write a quality message. If you have bad photos, it doesn't matter how good your message is, nobody will respond. If you have great photos, a witty message will significantly boost your ROI. If you don't do any swiping, you'll have zero ROI.&lt;/p&gt;
&lt;p&gt;While I don't have the BEST pictures, my main bottleneck is that I just don't have a high-enough swipe volume. I just think that the mindless swiping is a waste of my time and prefer to meet people in person. However, the problem with this, is that this strategy severely limits the range of people that I could date. To solve this swipe volume problem, I decided to build an AI that automates tinder called: THE DATE-A MINER.&lt;/p&gt;
&lt;p&gt;The DATE-A MINER is an artificial intelligence that learns the dating profiles I like. Once it finished learning what I like, the DATE-A MINER will automatically swipe left or right on each profile on my Tinder application. As a result, this will significantly increase swipe volume, therefore, increasing my projected Tinder ROI. Once I attain a match, the AI will automatically send a message to the matchee.&lt;/p&gt;
&lt;p&gt;While this doesn't give me a competitive advantage in photos, this does give me an advantage in swipe volume &amp;amp; initial message. Let's dive into my methodology:&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-2-data-collection" class="anchor" aria-hidden="true" href="#2-data-collection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Data Collection&lt;/h2&gt;
&lt;p&gt;To build the DATE-A MINER, I needed to feed her A LOT of images. As a result, I accessed the Tinder API using pynder. What this API allows me to do, is use Tinder through my terminal interface rather than the app:&lt;/p&gt;
&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/sample_bot.png"&gt;&lt;img src="/img/sample_bot.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I wrote a script where I could swipe through each profile, and save each image to a "likes" folder or a "dislikes" folder. I spent hours and hours swiping and collected about 10,000 images.&lt;/p&gt;
&lt;p&gt;One problem I noticed, was I swiped left for about 80% of the profiles. As a result, I had about 8000 in dislikes and 2000 in the likes folder. This is a severely imbalanced dataset. Because I have such few images for the likes folder, the date-ta miner won't be well-trained to know what I like. It'll only know what I dislike.&lt;/p&gt;
&lt;p&gt;To fix this problem, I found images on google of people I found attractive. Then I scraped these images and used them within my dataset.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-3-data-pre-processing" class="anchor" aria-hidden="true" href="#3-data-pre-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. Data Pre-Processing&lt;/h2&gt;
&lt;p&gt;Now that I have the images, there are a number of problems. There is a wide range of images on Tinder. Some profiles have images with multiple friends. Some images are zoomed out. Some images are low quality. It would difficult to extract information from such a high variation of images.&lt;/p&gt;
&lt;p&gt;To solve this problem, I used a &lt;a href="https://docs.opencv.org/3.4.1/d7/d8b/tutorial_py_face_detection.html" rel="nofollow"&gt;Haars Cascade Classifier Algorithm&lt;/a&gt; to extract the faces from images and then saved it.&lt;/p&gt;
&lt;p&gt;The Algorithm failed to detect the faces for about 70% of the data. As a result, my dataset was sliced into a dataset of 3,000 images.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-4-modeling" class="anchor" aria-hidden="true" href="#4-modeling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4. Modeling&lt;/h2&gt;
&lt;p&gt;To model this data, I used a Convolutional Neural Network. Because my classification problem was extremely detailed &amp;amp; subjective, I needed an algorithm that could extract a large enough amount of features to detect a difference between the profiles I liked and disliked. A cNN was also built for image classification problems.&lt;/p&gt;
&lt;p&gt;To model this data, I used two approaches:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3-Layer Model&lt;/strong&gt;: I didn't expect the three layer model to perform very well. Whenever I build any model, my goal is to get a dumb model working first. This was my dumb model. I used a very basic architecture:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;model &lt;span class="pl-k"&gt;=&lt;/span&gt; Sequential()
model.add(Convolution2D(&lt;span class="pl-c1"&gt;32&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;relu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;input_shape&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(img_size, img_size, &lt;span class="pl-c1"&gt;3&lt;/span&gt;)))
model.add(MaxPooling2D(&lt;span class="pl-v"&gt;pool_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;,&lt;span class="pl-c1"&gt;2&lt;/span&gt;)))

model.add(Convolution2D(&lt;span class="pl-c1"&gt;32&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;relu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;))
model.add(MaxPooling2D(&lt;span class="pl-v"&gt;pool_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;,&lt;span class="pl-c1"&gt;2&lt;/span&gt;)))

model.add(Convolution2D(&lt;span class="pl-c1"&gt;64&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;relu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;))
model.add(MaxPooling2D(&lt;span class="pl-v"&gt;pool_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;,&lt;span class="pl-c1"&gt;2&lt;/span&gt;)))
          
model.add(Flatten())
model.add(Dense(&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;relu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;))
model.add(Dropout(&lt;span class="pl-c1"&gt;0.5&lt;/span&gt;))
model.add(Dense(&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;softmax&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;))

adam &lt;span class="pl-k"&gt;=&lt;/span&gt; optimizers.SGD(&lt;span class="pl-v"&gt;lr&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1e-4&lt;/span&gt;, &lt;span class="pl-v"&gt;decay&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1e-6&lt;/span&gt;, &lt;span class="pl-v"&gt;momentum&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0.9&lt;/span&gt;, &lt;span class="pl-v"&gt;nesterov&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
model.compile(&lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;categorical_crossentropy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
              &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt; adam,
              &lt;span class="pl-v"&gt;metrics&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;accuracy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The resulting accuracy was about 67%.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transfer Learning using VGG19&lt;/strong&gt;: The problem with the 3-Layer model, is that I'm training the cNN on a SUPER small dataset: 3000 images. The best performing cNN's train on millions of images.&lt;/p&gt;
&lt;p&gt;As a result, I used a technique called "Transfer Learning." Transfer learning, is basically taking a model someone else built and using it on your own data. This is usually the way to go when you have an extremely small dataset.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accuracy&lt;/strong&gt;:73% accuracy&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Precision&lt;/strong&gt; 59%&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recall:&lt;/strong&gt; 44.61%&lt;/p&gt;
&lt;p&gt;Accuracy is just predicting whether I liked or disliked the image correctly.&lt;/p&gt;
&lt;p&gt;Precision, tells us "out of all the profiles that my algorithm predicted were true, how many did I actually like?" A low precision score would mean my algorithm wouldn't be useful since most of the matches I get are profiles I don't like.&lt;/p&gt;
&lt;p&gt;Recall, tells us "out of all the profiles that I actually like, how many did the algorithm predict correctly?" If this score is low, it means the algorithm is being overly picky.&lt;/p&gt;
&lt;p&gt;You can see here the algorithm predicting on Scarlet Johansson:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/scarlet_v2.png?raw=true"&gt;&lt;img src="/img/scarlet_v2.png?raw=true" alt="Alt text" title="Optional Title" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-5-running-the-bot" class="anchor" aria-hidden="true" href="#5-running-the-bot"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;5. Running the Bot&lt;/h2&gt;
&lt;p&gt;Now that I have the algorithm built, I needed to connect it to the bot. Builting the bot wasn't too difficult. Here, you can see the bot in action:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/baetamining_bot.gif?raw=true"&gt;&lt;img src="/img/baetamining_bot.gif?raw=true" alt="Alt text" title="Optional Title" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I intentionally added a 3 to 15 second delay on each swipe so Tinder wouldn't find out that it was a bot running on my profile. Unfortunately, I did not have time to add a GUI to this program.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-6-future-work" class="anchor" aria-hidden="true" href="#6-future-work"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;6. Future Work&lt;/h2&gt;
&lt;p&gt;I gave myself only a month of part-time work to complete this project. In reality, there's an infinite number of additional things I could do:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Natural Language Processing on Profile text/interest&lt;/strong&gt;: I could extract the profile description and facebook interests and incorporate this into a scoring metric to develop more accurate swipes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Create a "total profile score"&lt;/strong&gt;: Rather than make a swipe decision off the first valid picture, I could have the algorithm look at every picture and compile the cumulative swipe decisions into one scoring metric to decide if she should swipe right or left.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;More Data&lt;/strong&gt;: I only trained on 3,000 images. If I could train on 150,000 Tinder images, I'm confident I'd have an 80-90% performing algorithm. In addition, I could also improve the facial extraction program, so I'm not losing 70% of my data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Adapt to Hinge, Coffee Meets Bagel, Bumble:&lt;/strong&gt; To widen my quantity, adapt the algorithm to hit multiple channels:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A/B Testing&lt;/strong&gt;: Having a framework to AB test different messages, profile pictures and have analytics supporting these different decisions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Google's Inception, VGG16&lt;/strong&gt;: These are different pre-trained cNN's. I wanted to try these but I ran out of time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Add GUI/Turn into a user-friendly app&lt;/strong&gt;: This would allow non-technical people to use this.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-7-installation" class="anchor" aria-hidden="true" href="#7-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;7. Installation&lt;/h2&gt;
&lt;p&gt;To install everything, follow these instructions:&lt;/p&gt;
&lt;p&gt;You must have the correct packages installed. To install the packages run the following command on the commandline:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Once you have the requirements installed, you'll need to get your FB authentication token &amp;amp; ID and store it in the &lt;code&gt;auth.json&lt;/code&gt; file. I have a script in here to extract the token called helpers.py so run that script.&lt;/p&gt;
&lt;p&gt;If you're running into issues. Read &lt;a href="https://github.com/charliewolf/pynder/issues/136"&gt;this&lt;/a&gt; to get your ID. Read &lt;a href="https://github.com/charliewolf/pynder/issues/171"&gt;this&lt;/a&gt; to get your Token. If you really have trouble, you can message me.&lt;/p&gt;
&lt;p&gt;If you want to use the model trained on my female preferences, you can now just run &lt;code&gt;bot.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you want to train your own model, there are additional steps you'll need to follow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Use img_scrape.py to access Tinder through your terminal. When running the program, press 1 to dislike or 2 to like. Do this for thousands of images.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once you have your dataset, run &lt;code&gt;prepare_data.ipynb&lt;/code&gt; to extract the faces from the images. Save as a numpy file. Aim for 3000 use-able images for decent performance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I wouldn't recommend training the cNN on your PC. You'll need to start a deep learning server using AWS or Google Cloud. On AWS, I used the Deep Learning AMI t2.medium.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once you're done training, you need to export your model as an h5 file. Transport this h5 file into the bot. Within &lt;code&gt;bot.py&lt;/code&gt;, find the &lt;code&gt;load_model()&lt;/code&gt; function and plug the name of your file into that functino.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Voila, you should be good to go!&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jeffmli</author><guid isPermaLink="false">https://github.com/jeffmli/TinderAutomation</guid><pubDate>Sun, 09 Feb 2020 00:16:00 GMT</pubDate></item><item><title>maplezzz/NTU_ML2017_Hung-yi-Lee_HW #17 in Jupyter Notebook, Today</title><link>https://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HW</link><description>&lt;p&gt;&lt;i&gt;NTU ML2017 Spring and Fall Homework Hung-yi_Li æå®æ¯…è€å¸ˆ æœºå™¨å­¦ä¹ è¯¾ç¨‹ä½œä¸š&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-ml2017sf_hung-yi-lee_hw" class="anchor" aria-hidden="true" href="#ml2017sf_hung-yi-lee_hw"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ML2017S+F_Hung-yi-Lee_HW&lt;/h1&gt;
&lt;p&gt;NTU ML2017 Spring and Fall Homework Hung-yi_Li æå®æ¯…è€å¸ˆ&lt;/p&gt;
&lt;p&gt;&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17.html" title="NTU ML17S" rel="nofollow"&gt;&lt;strong&gt;2017SCourse Website&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17_2.html" title="NTU ML17F" rel="nofollow"&gt;&lt;strong&gt;2017FCourse Website&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NTU Mechine Learning 2017 Spring and Fall total Homework&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/maplezzz/ML2017S_Hung-yi-Lee_HW/tree/master/HW0"&gt;HW0 Prerequisite&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;çŸ©é˜µä¹˜æ³•&lt;/li&gt;
&lt;li&gt;å›¾åƒæå–&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/maplezzz/ML2017S_Hung-yi-Lee_HW/tree/master/HW1"&gt;HW1 PM2.5 Prediction&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;linear regression&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/maplezzz/ML2017S_Hung-yi-Lee_HW/tree/master/HW2"&gt;HW2 Income Prediction&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;logestic regression&lt;/li&gt;
&lt;li&gt;probabilistic generative model&lt;/li&gt;
&lt;li&gt;keras&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/maplezzz/ML2017S_Hung-yi-Lee_HW/tree/master/HW3"&gt;HW3 Image Sentiment Classification&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Convolution Neural Network&lt;/li&gt;
&lt;li&gt;Deep Neural Network&lt;/li&gt;
&lt;li&gt;Confusion Matrix&lt;/li&gt;
&lt;li&gt;Saliency Map&lt;/li&gt;
&lt;li&gt;Visualizing Filters&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/maplezzz/ML2017S_Hung-yi-Lee_HW/tree/master/HW4"&gt;HW4 Text Sentiment Classification&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Processing the Sentence&lt;/li&gt;
&lt;li&gt;Word Embedding&lt;/li&gt;
&lt;li&gt;Semi-Supervised learning&lt;/li&gt;
&lt;li&gt;RNN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>maplezzz</author><guid isPermaLink="false">https://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HW</guid><pubDate>Sun, 09 Feb 2020 00:17:00 GMT</pubDate></item><item><title>jakevdp/PythonDataScienceHandbook #18 in Jupyter Notebook, Today</title><link>https://github.com/jakevdp/PythonDataScienceHandbook</link><description>&lt;p&gt;&lt;i&gt;Python Data Science Handbook: full text in Jupyter Notebooks&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-python-data-science-handbook" class="anchor" aria-hidden="true" href="#python-data-science-handbook"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python Data Science Handbook&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://mybinder.org/v2/gh/jakevdp/PythonDataScienceHandbook/master?filepath=notebooks%2FIndex.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repository contains the entire &lt;a href="http://shop.oreilly.com/product/0636920034919.do" rel="nofollow"&gt;Python Data Science Handbook&lt;/a&gt;, in the form of (free!) Jupyter notebooks.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="notebooks/figures/PDSH-cover.png"&gt;&lt;img src="notebooks/figures/PDSH-cover.png" alt="cover image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-use-this-book" class="anchor" aria-hidden="true" href="#how-to-use-this-book"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to Use this Book&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Read the book in its entirety online at &lt;a href="https://jakevdp.github.io/PythonDataScienceHandbook/" rel="nofollow"&gt;https://jakevdp.github.io/PythonDataScienceHandbook/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the code using the Jupyter notebooks available in this repository's &lt;a href="notebooks"&gt;notebooks&lt;/a&gt; directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Launch executable versions of these notebooks using &lt;a href="http://colab.research.google.com" rel="nofollow"&gt;Google Colab&lt;/a&gt;: &lt;a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Launch a live notebook server with these notebooks using &lt;a href="https://beta.mybinder.org/" rel="nofollow"&gt;binder&lt;/a&gt;: &lt;a href="https://mybinder.org/v2/gh/jakevdp/PythonDataScienceHandbook/master?filepath=notebooks%2FIndex.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Buy the printed book through &lt;a href="http://shop.oreilly.com/product/0636920034919.do" rel="nofollow"&gt;O'Reilly Media&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-about" class="anchor" aria-hidden="true" href="#about"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About&lt;/h2&gt;
&lt;p&gt;The book was written and tested with Python 3.5, though other Python versions (including Python 2.7) should work in nearly all cases.&lt;/p&gt;
&lt;p&gt;The book introduces the core libraries essential for working with data in Python: particularly &lt;a href="http://ipython.org" rel="nofollow"&gt;IPython&lt;/a&gt;, &lt;a href="http://numpy.org" rel="nofollow"&gt;NumPy&lt;/a&gt;, &lt;a href="http://pandas.pydata.org" rel="nofollow"&gt;Pandas&lt;/a&gt;, &lt;a href="http://matplotlib.org" rel="nofollow"&gt;Matplotlib&lt;/a&gt;, &lt;a href="http://scikit-learn.org" rel="nofollow"&gt;Scikit-Learn&lt;/a&gt;, and related packages.
Familiarity with Python as a language is assumed; if you need a quick introduction to the language itself, see the free companion project,
&lt;a href="https://github.com/jakevdp/WhirlwindTourOfPython"&gt;A Whirlwind Tour of Python&lt;/a&gt;: it's a fast-paced introduction to the Python language aimed at researchers and scientists.&lt;/p&gt;
&lt;p&gt;See &lt;a href="http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb" rel="nofollow"&gt;Index.ipynb&lt;/a&gt; for an index of the notebooks available to accompany the text.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-software" class="anchor" aria-hidden="true" href="#software"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Software&lt;/h2&gt;
&lt;p&gt;The code in the book was tested with Python 3.5, though most (but not all) will also work correctly with Python 2.7 and other older Python versions.&lt;/p&gt;
&lt;p&gt;The packages I used to run the code in the book are listed in &lt;a href="requirements.txt"&gt;requirements.txt&lt;/a&gt; (Note that some of these exact version numbers may not be available on your platform: you may have to tweak them for your own use).
To install the requirements using &lt;a href="http://conda.pydata.org" rel="nofollow"&gt;conda&lt;/a&gt;, run the following at the command-line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda install --file requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To create a stand-alone environment named &lt;code&gt;PDSH&lt;/code&gt; with Python 3.5 and all the required package versions, run the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda create -n PDSH python=3.5 --file requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can read more about using conda environments in the &lt;a href="http://conda.pydata.org/docs/using/envs.html" rel="nofollow"&gt;Managing Environments&lt;/a&gt; section of the conda documentation.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-code" class="anchor" aria-hidden="true" href="#code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code&lt;/h3&gt;
&lt;p&gt;The code in this repository, including all code samples in the notebooks listed above, is released under the &lt;a href="LICENSE-CODE"&gt;MIT license&lt;/a&gt;. Read more at the &lt;a href="https://opensource.org/licenses/MIT" rel="nofollow"&gt;Open Source Initiative&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-text" class="anchor" aria-hidden="true" href="#text"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Text&lt;/h3&gt;
&lt;p&gt;The text content of the book is released under the &lt;a href="LICENSE-TEXT"&gt;CC-BY-NC-ND license&lt;/a&gt;. Read more at &lt;a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode" rel="nofollow"&gt;Creative Commons&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jakevdp</author><guid isPermaLink="false">https://github.com/jakevdp/PythonDataScienceHandbook</guid><pubDate>Sun, 09 Feb 2020 00:18:00 GMT</pubDate></item><item><title>jessevig/bertviz #19 in Jupyter Notebook, Today</title><link>https://github.com/jessevig/bertviz</link><description>&lt;p&gt;&lt;i&gt;Tool for visualizing attention in the Transformer model (BERT, GPT-2, Albert, XLNet, RoBERTa, CTRL, etc.)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-bertviz" class="anchor" aria-hidden="true" href="#bertviz"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;BertViz&lt;/h1&gt;
&lt;p&gt;BertViz is a tool for visualizing attention in the Transformer model, supporting all models from the &lt;a href="https://github.com/huggingface/transformers"&gt;transformers&lt;/a&gt; library (BERT, GPT-2, XLNet, RoBERTa, XLM, CTRL, etc.). It extends the &lt;a href="https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/visualization"&gt;Tensor2Tensor visualization tool&lt;/a&gt; by &lt;a href="https://medium.com/@llionj" rel="nofollow"&gt;Llion Jones&lt;/a&gt; and the &lt;a href="https://github.com/huggingface/transformers"&gt;transformers&lt;/a&gt; library from &lt;a href="https://github.com/huggingface"&gt;HuggingFace&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Blog posts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1" rel="nofollow"&gt;Deconstructing BERT, Part 2: Visualizing the Inner Workings of Attention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/openai-gpt-2-understanding-language-generation-through-visualization-8252f683b2f8" rel="nofollow"&gt;OpenAI GPT-2: Understanding Language Generation through Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/deconstructing-bert-distilling-6-patterns-from-100-million-parameters-b49113672f77" rel="nofollow"&gt;Deconstructing BERT: Distilling 6 Patterns from 100 Million Parameters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Paper:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1906.05714.pdf" rel="nofollow"&gt;A Multiscale Visualization of Attention in the Transformer Model&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-attention-head-view" class="anchor" aria-hidden="true" href="#attention-head-view"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Attention-head view&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;attention-head view&lt;/em&gt; visualizes the attention patterns produced by one or more attention heads in a given transformer layer.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_left.png"&gt;&lt;img src="https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_left.png" alt="Attention-head view" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_right.gif"&gt;&lt;img src="https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_right.gif" alt="Attention-head view animated" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The attention view supports all models from the Transformers library, including:&lt;br&gt;
BERT:
&lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_bert.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1PEHWRHrvxQvYr9NFRC-E_fr3xDq1htCj" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
GPT-2:
&lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_gpt2.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1c9kBsbvSqpKkmd62u7nfqVhvWr0W8_Lx" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
XLNet: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_xlnet.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
RoBERTa: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_roberta.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
XLM: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_xlm.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
Albert: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_albert.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
DistilBert: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_distilbert.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
(and others)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-model-view" class="anchor" aria-hidden="true" href="#model-view"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model view&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;model view&lt;/em&gt; provides a birds-eye view of attention across all of the modelâ€™s layers  and heads.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jessevig/bertviz/master/images/model_thumbnail.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jessevig/bertviz/master/images/model_thumbnail.jpg" alt="Model view" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The model view supports all models from the Transformers library, including:&lt;br&gt;
BERT: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_bert.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1c73DtKNdl66B0_HF7QXuPenraDp0jHRS" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
GPT2: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_gpt2.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1y-wfC95Z0aASawYqA34LQeV0_qC9mOto" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
XLNet: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_xlnet.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
RoBERTa: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_roberta.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
XLM: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_xlm.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
Albert: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_albert.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
DistilBert: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_distilbert.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
(and others)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-neuron-view" class="anchor" aria-hidden="true" href="#neuron-view"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Neuron view&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;neuron view&lt;/em&gt; visualizes the individual neurons in the query and key vectors and shows how they are used to compute attention.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jessevig/bertviz/master/images/neuron_thumbnail.png"&gt;&lt;img src="https://raw.githubusercontent.com/jessevig/bertviz/master/images/neuron_thumbnail.png" alt="Neuron view" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The neuron view supports the following three models:&lt;br&gt;
BERT: &lt;a href="https://github.com/jessevig/bertviz/blob/master/neuron_view_bert.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1m37iotFeubMrp9qIf9yscXEL1zhxTN2b" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
GPT-2
&lt;a href="https://github.com/jessevig/bertviz/blob/master/neuron_view_gpt2.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1s8XCCyxsKvNRWNzjWi5Nl8ZAYZ5YkLm_" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
RoBERTa
&lt;a href="https://github.com/jessevig/bertviz/blob/master/neuron_view_roberta.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/transformers/" rel="nofollow"&gt;Transformers&lt;/a&gt; (version required depends on models used)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pytorch.org/" rel="nofollow"&gt;PyTorch&lt;/a&gt; &amp;gt;=1.0.0&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jupyter.org/install" rel="nofollow"&gt;Jupyter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/tqdm/" rel="nofollow"&gt;tqdm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/boto3/" rel="nofollow"&gt;boto3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/ipython/" rel="nofollow"&gt;IPython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/requests/" rel="nofollow"&gt;requests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/regex/" rel="nofollow"&gt;regex&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/sentencepiece/" rel="nofollow"&gt;sentencepiece&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(See &lt;a href="https://github.com/jessevig/bertviz/blob/master/requirements.txt"&gt;requirements.txt&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-execution" class="anchor" aria-hidden="true" href="#execution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Execution&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/jessevig/bertviz.git
cd bertviz
jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;NOTE: If you wish to run BertViz using Colab, please see the example Colab scripts above, as they differ slightly from the Jupyter notebook versions.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authors&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://twitter.com/jesse_vig" rel="nofollow"&gt;Jesse Vig&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;When referencing BertViz, please cite &lt;a href="https://arxiv.org/abs/1906.05714" rel="nofollow"&gt;this paper&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{vig2019transformervis,
  author    = {Jesse Vig},
  title     = {A Multiscale Visualization of Attention in the Transformer Model},
  journal   = {arXiv preprint arXiv:1906.05714},
  year      = {2019},
  url       = {https://arxiv.org/abs/1906.05714}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href="LICENSE"&gt;LICENSE&lt;/a&gt; file for details&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;This project incorporates code from the following repos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tensor2tensor"&gt;https://github.com/tensorflow/tensor2tensor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT"&gt;https://github.com/huggingface/pytorch-pretrained-BERT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jessevig</author><guid isPermaLink="false">https://github.com/jessevig/bertviz</guid><pubDate>Sun, 09 Feb 2020 00:19:00 GMT</pubDate></item><item><title>blue-yonder/tsfresh #20 in Jupyter Notebook, Today</title><link>https://github.com/blue-yonder/tsfresh</link><description>&lt;p&gt;&lt;i&gt;Automatic extraction of relevant features from time series:&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://tsfresh.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/36acd223668ed9b8757d4b53b31463c5052e705f/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f747366726573682f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/tsfresh/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.org/blue-yonder/tsfresh" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9d7ac3b7a4be38dda0e1acb1e2df0a452e132ab8/68747470733a2f2f7472617669732d63692e6f72672f626c75652d796f6e6465722f747366726573682e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/blue-yonder/tsfresh.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://coveralls.io/github/blue-yonder/tsfresh?branch=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d600de5532fa69596b8e6c08d848381f3d1fae78/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f626c75652d796f6e6465722f747366726573682f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/blue-yonder/tsfresh/badge.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/blue-yonder/tsfresh/blob/master/LICENSE.txt"&gt;&lt;img src="https://camo.githubusercontent.com/b0224997019dec4e51d692c722ea9bee2818c837/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6173686170652f6170697374617475732e737667" alt="license" data-canonical-src="https://img.shields.io/github/license/mashape/apistatus.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/tsfresh/Lobby?utm_source=share-link&amp;amp;utm_medium=link&amp;amp;utm_campaign=share-link" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e3f3756ed14ab89e92954154ae3210ee867e5bf3/68747470733a2f2f6261646765732e6769747465722e696d2f747366726573682f4c6f6262792e737667" alt="Gitter chat" data-canonical-src="https://badges.gitter.im/tsfresh/Lobby.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/blue-yonder/tsfresh/issues/8"&gt;&lt;img src="https://camo.githubusercontent.com/848b334aabca64e10f1535e7b6a8dd952a025db0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e332e352e322d737570706f727465642d677265656e2e737667" alt="py352 status" data-canonical-src="https://img.shields.io/badge/python3.5.2-supported-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://mybinder.org/v2/gh/blue-yonder/tsfresh/master?filepath=notebooks" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24c94be25a8a8b5703a34466825bbfdd6147d9d0/68747470733a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pepy.tech/project/tsfresh" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5e21bea1727201bd2b3270bd63d7d29796444bb9/68747470733a2f2f706570792e746563682f62616467652f74736672657368" alt="Downloads" data-canonical-src="https://pepy.tech/badge/tsfresh" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-tsfresh" class="anchor" aria-hidden="true" href="#tsfresh"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;tsfresh&lt;/h1&gt;
&lt;p&gt;This repository contains the &lt;em&gt;TSFRESH&lt;/em&gt; python package. The abbreviation stands for&lt;/p&gt;
&lt;p&gt;&lt;em&gt;"Time Series Feature extraction based on scalable hypothesis tests"&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The package contains many feature extraction methods and a robust feature selection algorithm.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-spend-less-time-on-feature-engineering" class="anchor" aria-hidden="true" href="#spend-less-time-on-feature-engineering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spend less time on feature engineering&lt;/h2&gt;
&lt;p&gt;Data Scientists often spend most of their time either cleaning data or building features.
While we cannot change the first thing, the second can be automated.
&lt;em&gt;TSFRESH&lt;/em&gt; frees your time spent on building features by extracting them automatically.
Hence, you have more time to study the newest deep learning paper, read hacker news or build better models.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-automatic-extraction-of-100s-of-features" class="anchor" aria-hidden="true" href="#automatic-extraction-of-100s-of-features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Automatic extraction of 100s of features&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;TSFRESH&lt;/em&gt; automatically extracts 100s of features from time series.
Those features describe basic characteristics of the time series such as the number of peaks, the average or maximal value or more complex features such as the time reversal symmetry statistic.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="docs/images/introduction_ts_exa_features.png"&gt;&lt;img src="docs/images/introduction_ts_exa_features.png" alt="The features extracted from a exemplary time series" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The set of features can then be used to construct statistical or machine learning models on the time series to be used for example in regression or
classification tasks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-forget-irrelevant-features" class="anchor" aria-hidden="true" href="#forget-irrelevant-features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Forget irrelevant features&lt;/h2&gt;
&lt;p&gt;Time series often contain noise, redundancies or irrelevant information.
As a result most of the extracted features will not be useful for the machine learning task at hand.&lt;/p&gt;
&lt;p&gt;To avoid extracting irrelevant features, the &lt;em&gt;TSFRESH&lt;/em&gt; package has a built-in filtering procedure.
This filtering procedure evaluates the explaining power and importance of each characteristic for the regression or classification tasks at hand.&lt;/p&gt;
&lt;p&gt;It is based on the well developed theory of hypothesis testing and uses a multiple test procedure.
As a result the filtering process mathematically controls the percentage of irrelevant extracted features.&lt;/p&gt;
&lt;p&gt;The  &lt;em&gt;TSFRESH&lt;/em&gt; package is described in the following open access paper&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Christ, M., Braun, N., Neuffer, J. and Kempa-Liehr A.W. (2018).
&lt;em&gt;Time Series FeatuRe Extraction on basis of Scalable Hypothesis tests (tsfresh -- A Python package).&lt;/em&gt;
Neurocomputing 307 (2018) 72-77, &lt;a href="https://doi.org/10.1016/j.neucom.2018.03.067" rel="nofollow"&gt;doi:10.1016/j.neucom.2018.03.067&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The FRESH algorithm is described in the following whitepaper&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Christ, M., Kempa-Liehr, A.W. and Feindt, M. (2017).&lt;br&gt;
&lt;em&gt;Distributed and parallel time series feature extraction for industrial big data applications.&lt;/em&gt;&lt;br&gt;
ArXiv e-print 1610.07717,  &lt;a href="https://arxiv.org/abs/1610.07717" rel="nofollow"&gt;https://arxiv.org/abs/1610.07717&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-advantages-of-tsfresh" class="anchor" aria-hidden="true" href="#advantages-of-tsfresh"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Advantages of tsfresh&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;TSFRESH&lt;/em&gt; has several selling points, for example&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;it is field tested&lt;/li&gt;
&lt;li&gt;it is unit tested&lt;/li&gt;
&lt;li&gt;the filtering process is statistically/mathematically correct&lt;/li&gt;
&lt;li&gt;it has a comprehensive documentation&lt;/li&gt;
&lt;li&gt;it is compatible with sklearn, pandas and numpy&lt;/li&gt;
&lt;li&gt;it allows anyone to easily add their favorite features&lt;/li&gt;
&lt;li&gt;it both runs on your local machine or even on a cluster&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-next-steps" class="anchor" aria-hidden="true" href="#next-steps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Next steps&lt;/h2&gt;
&lt;p&gt;If you are interested in the technical workings, go to see our comprehensive Read-The-Docs documentation at &lt;a href="http://tsfresh.readthedocs.io" rel="nofollow"&gt;http://tsfresh.readthedocs.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The algorithm, especially the filtering part are also described in the paper mentioned above.&lt;/p&gt;
&lt;p&gt;If you have some questions or feedback you can find the developers in the &lt;a href="https://gitter.im/tsfresh/Lobby?utm_source=share-link&amp;amp;utm_medium=link&amp;amp;utm_campaign=share-link" rel="nofollow"&gt;gitter chatroom.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We appreciate any contributions, if you are interested in helping us to make &lt;em&gt;TSFRESH&lt;/em&gt; the biggest archive of feature extraction methods in python, just head over to our &lt;a href="http://tsfresh.readthedocs.io/en/latest/text/how_to_contribute.html" rel="nofollow"&gt;How-To-Contribute&lt;/a&gt; instructions.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;The research and development of &lt;em&gt;TSFRESH&lt;/em&gt; was funded in part by the German Federal Ministry of Education and Research under grant number 01IS14004 (project iPRODICT).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>blue-yonder</author><guid isPermaLink="false">https://github.com/blue-yonder/tsfresh</guid><pubDate>Sun, 09 Feb 2020 00:20:00 GMT</pubDate></item><item><title>AllenDowney/ThinkDSP #21 in Jupyter Notebook, Today</title><link>https://github.com/AllenDowney/ThinkDSP</link><description>&lt;p&gt;&lt;i&gt;Think DSP: Digital Signal Processing in Python, by Allen B. Downey.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-thinkdsp" class="anchor" aria-hidden="true" href="#thinkdsp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ThinkDSP&lt;/h1&gt;
&lt;p&gt;LaTeX source and Python code for &lt;em&gt;Think DSP: Digital Signal Processing in Python&lt;/em&gt;, by Allen B. Downey.&lt;/p&gt;
&lt;p&gt;The premise of this book (and the other books in the &lt;em&gt;Think X&lt;/em&gt; series) is that if you know how to program,
you can use that skill to learn other things.  I am writing this book because I think the conventional
approach to digital signal processing is backward: most books (and the classes that use them) present
the material bottom-up, starting with mathematical abstractions like phasors.&lt;/p&gt;
&lt;p&gt;With a programming-based approach, I can go top-down, which means I can present the most important
ideas right away.  By the end of the first chapter, you can break down a sound into its harmonics, modify the harmonics, and generate new sounds.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-running-the-code" class="anchor" aria-hidden="true" href="#running-the-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running the code&lt;/h2&gt;
&lt;p&gt;Most of the code for this book is in Jupyter notebooks.
If you are not familiar with Jupyter, you can run a tutorial by &lt;a href="https://jupyter.org/try" rel="nofollow"&gt;clicking here&lt;/a&gt;.  Then select "Try Classic Notebook".  It will open a notebook with instructions for getting started.&lt;/p&gt;
&lt;p&gt;To run the ThinkDSP code, you have two options:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The simplest option is to run the code on Binder.  The drawback is that the notebooks run in a temporary environment; if you leave a notebook idle for a while, the temporary environment goes away and you lose any changes you made.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The other option is to install Python, Jupyter, and the other packages you need on your computer, and download my code from GitHub.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following two sections explain these options in detail.&lt;/p&gt;
&lt;p&gt;Note: I have heard from a few people who tried to run the code in Spyder.  Apparently there were problems, so I don't recommend it.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-option-1-run-on-binder" class="anchor" aria-hidden="true" href="#option-1-run-on-binder"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 1: Run on Binder&lt;/h3&gt;
&lt;p&gt;To run the code for this book on Binder, press this button:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://mybinder.org/repo/AllenDowney/ThinkDSP" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/70c5b4d050d4019f4f20b170d75679a9316ac5e5/687474703a2f2f6d7962696e6465722e6f72672f62616467652e737667" alt="Binder" data-canonical-src="http://mybinder.org/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It takes a minute or so to start up, but then you should see the Jupyter home page with a list of files.  Click on &lt;code&gt;code&lt;/code&gt; to open the folder with the notebooks, then click on one of the notebooks (with the .ipynb extension).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-option-2-install-pythonjupyter" class="anchor" aria-hidden="true" href="#option-2-install-pythonjupyter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Option 2: Install Python+Jupyter&lt;/h3&gt;
&lt;p&gt;First, download the files from this repository.  If you are a Git user, you can run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone --depth 1 https://github.com/AllenDowney/ThinkDSP.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Otherwise you can &lt;a href="https://github.com/AllenDowney/ThinkDSP/archive/master.zip"&gt;download this Zip file&lt;/a&gt; and unzip it.
Either way, you should end up with a directory called &lt;code&gt;ThinkDSP&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now, if you don't already have Jupyter, I highly recommend installing Anaconda, which is a Python distribution that contains everything you need to run the ThinkDSP code.  It is easy to install on Windows, Mac, and Linux, and because it does a
user-level install, it will not interfere with other Python installations.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.anaconda.com/distribution/" rel="nofollow"&gt;Information about installing Anaconda is here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have the choice of Python 2 or 3, choose 3.&lt;/p&gt;
&lt;p&gt;There are two ways to get the packages you need for ThinkDSP.  You can install them by hand or create a Conda environment.&lt;/p&gt;
&lt;p&gt;To install them by hand run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install jupyter numpy scipy pandas matplotlib seaborn
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or, to create a conda environment, run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd ThinkDSP
conda env create -f environment.yml
conda activate ThinkDSP
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To start Jupyter, run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Jupyter should launch your default browser or open a tab in an existing browser window.
If not, the Jupyter server should print a URL you can use.  For example, when I launch Jupyter, I get&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~/ThinkComplexity2$ jupyter notebook
[I 10:03:20.115 NotebookApp] Serving notebooks from local directory: /home/downey/ThinkDSP
[I 10:03:20.115 NotebookApp] 0 active kernels
[I 10:03:20.115 NotebookApp] The Jupyter Notebook is running at: http://localhost:8888/
[I 10:03:20.115 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case, the URL is &lt;a href="http://localhost:8888" rel="nofollow"&gt;http://localhost:8888&lt;/a&gt;.&lt;br&gt;
When you start your server, you might get a different URL.
Whatever it is, if you paste it into a browser, you should should see a home page with a list of directories.&lt;/p&gt;
&lt;p&gt;Click on &lt;code&gt;code&lt;/code&gt; to open the folder with the notebooks, then click on one of the notebooks (with the .ipynb extension).&lt;/p&gt;
&lt;p&gt;Select the cell with the import statements and press "Shift-Enter" to run the code in the cell.
If it works and you get no error messages, &lt;strong&gt;you are all set&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If you get error messages about missing packages, you can install the packages you need using your
package manager, or install Anaconda.&lt;/p&gt;
&lt;p&gt;If you run into problems with these instructions, let me know and I will make corrections.  Good luck!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-freesound" class="anchor" aria-hidden="true" href="#freesound"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Freesound&lt;/h2&gt;
&lt;p&gt;Special thanks to Freesound (&lt;a href="http://freesound.org" rel="nofollow"&gt;http://freesound.org&lt;/a&gt;), which is the source of many of the
sound samples I use in this book, and to the Freesound users who
uploaded those sounds.  I include some of their wave files in
the GitHub repository for this book, using the original file
names, so it should be easy to find their sources.&lt;/p&gt;
&lt;p&gt;Unfortunately, most Freesound users don't make their real names
available, so I can only thank them using their user names.  Samples
used in this book were contributed by Freesound users: iluppai,
wcfl10, thirsk, docquesting, kleeb, landup, zippi1, themusicalnomad,
bcjordan, rockwehrmann, marchascon7, jcveliz.  Thank you all!&lt;/p&gt;
&lt;p&gt;Here are links to the sources:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/iluppai/sounds/100475/" rel="nofollow"&gt;http://www.freesound.org/people/iluppai/sounds/100475/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/wcfl10/sounds/105977/" rel="nofollow"&gt;http://www.freesound.org/people/wcfl10/sounds/105977/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/Thirsk/sounds/120994/" rel="nofollow"&gt;http://www.freesound.org/people/Thirsk/sounds/120994/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/ciccarelli/sounds/132736/" rel="nofollow"&gt;http://www.freesound.org/people/ciccarelli/sounds/132736/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/Kleeb/sounds/180960/" rel="nofollow"&gt;http://www.freesound.org/people/Kleeb/sounds/180960/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/zippi1/sounds/18871/" rel="nofollow"&gt;http://www.freesound.org/people/zippi1/sounds/18871/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/themusicalnomad/sounds/253887/" rel="nofollow"&gt;http://www.freesound.org/people/themusicalnomad/sounds/253887/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/bcjordan/sounds/28042/" rel="nofollow"&gt;http://www.freesound.org/people/bcjordan/sounds/28042/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/rockwehrmann/sounds/72475/" rel="nofollow"&gt;http://www.freesound.org/people/rockwehrmann/sounds/72475/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/marcgascon7/sounds/87778/" rel="nofollow"&gt;http://www.freesound.org/people/marcgascon7/sounds/87778/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.freesound.org/people/jcveliz/sounds/92002/" rel="nofollow"&gt;http://www.freesound.org/people/jcveliz/sounds/92002/&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>AllenDowney</author><guid isPermaLink="false">https://github.com/AllenDowney/ThinkDSP</guid><pubDate>Sun, 09 Feb 2020 00:21:00 GMT</pubDate></item><item><title>kavgan/nlp-in-practice #22 in Jupyter Notebook, Today</title><link>https://github.com/kavgan/nlp-in-practice</link><description>&lt;p&gt;&lt;i&gt;NLP, Text Mining and Machine Learning starter code to solve real world text data problems. Includes: Gensim Word2Vec, phrase embeddings, keyword extraction with TFIDF,  Text Classification with Logistic Regression, word count with pyspark, simple text preprocessing, pre-trained embeddings and more.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-nlp-in-practice" class="anchor" aria-hidden="true" href="#nlp-in-practice"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NLP-IN-PRACTICE&lt;/h1&gt;
&lt;p&gt;Use these NLP, Text Mining and Machine Learning code samples and tools to solve real world text data problems.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-notebooks--source" class="anchor" aria-hidden="true" href="#notebooks--source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notebooks / Source&lt;/h2&gt;
&lt;p&gt;Links in the first column take you to the subfolder/repository with the source code.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Task&lt;/th&gt;
&lt;th&gt;Related Article&lt;/th&gt;
&lt;th&gt;Source Type&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/kavgan/phrase-at-scale"&gt;Large Scale Phrase Extraction&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/how-to-generate-phrase-embeddings-using-word2vec-in-3-easy-steps/" rel="nofollow"&gt;phrase2vec article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;python script&lt;/td&gt;
&lt;td&gt;Extract phrases for large amounts of data using PySpark. Annotate text using these phrases or use the phrases for other downstream tasks.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/kavgan/word_cloud"&gt;Word Cloud for Jupyter Notebook and Python Web Apps &lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/word-cloud-for-data-scientists/#.W867cBNKj65" rel="nofollow"&gt;word_cloud article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;python script + notebook&lt;/td&gt;
&lt;td&gt;Visualize top keywords using word counts or tfidf&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="word2vec/"&gt;Gensim Word2Vec (with dataset)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/" rel="nofollow"&gt;word2vec article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;How to work correctly with Word2Vec to get desired results&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="spark_wordcount/"&gt;Reading files and word count with Spark&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/reading-csv-and-json-files-in-spark/" rel="nofollow"&gt;spark article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;python script&lt;/td&gt;
&lt;td&gt;How to read files of different formats using PySpark with a word count example&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="tf-idf"&gt;Extracting Keywords with TF-IDF and SKLearn (with dataset)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/extracting-keywords-from-text-with-tf-idf-and-pythons-scikit-learn/#.W2TlD9hKhhE" rel="nofollow"&gt;tfidf article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;How to extract interesting keywords from text using TF-IDF and Python's SKLEARN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="text-pre-processing"&gt;Text Preprocessing&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/getting-started-with-text-preprocessing/#.XHa4-ZNKhuU" rel="nofollow"&gt;text preprocessing article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;A few code snippets on how to perform text preprocessing. Includes stemming, noise removal, lemmatization and stop word removal.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="tfidftransformer/"&gt;TFIDFTransformer vs. TFIDFVectorizer&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/how-to-use-tfidftransformer-tfidfvectorizer-and-whats-the-difference/" rel="nofollow"&gt;tfidftransformer and tfidfvectorizer usage article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;How to use TFIDFTransformer and TFIDFVectorizer correctly and the difference between the two and what to use when.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="pre-trained-embeddings/"&gt;Accessing Pre-trained Word Embeddings with Gensim&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://kavita-ganesan.com/easily-access-pre-trained-word-embeddings-with-gensim/#.XQCYP9NKhhE" rel="nofollow"&gt;Pre-trained word embeddings article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;How to access pre-trained GloVe and Word2Vec Embeddings using Gensim and an example of how these embeddings can be leveraged for text similarity&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="text-classification/"&gt;Text Classification in Python (with news dataset)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://kavita-ganesan.com/news-classifier-with-logistic-regression-in-python/#.XT95_5NKhgc" rel="nofollow"&gt;Text classification with Logistic Regression article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;Get started with text classification. Learn how to build and evaluate a text classifier for news classification using Logistic Regression.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="CountVectorizer/"&gt;CountVectorizer Usage Examples&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://kavita-ganesan.com/how-to-use-countvectorizer/#.XeqMhpNKhhE" rel="nofollow"&gt;How to Correctly Use CountVectorizer? An In-Depth Look article&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;notebook&lt;/td&gt;
&lt;td&gt;Learn how to maximize the use of CountVectorizer such that you are not just computing counts of words, but also preprocessing your text data appropriately as well as extracting additional features from your text dataset.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-notes" class="anchor" aria-hidden="true" href="#notes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notes&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;For more articles, please &lt;a href="http://kavita-ganesan.com/kavitas-tutorials/#.WvIizNMvyog" rel="nofollow"&gt;see this list&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If you would like to receive articles via email &lt;a href="https://kavita-ganesan.com/subscribe/#.XTThjZNKhgc" rel="nofollow"&gt;subscribe to my mailing list&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h1&gt;
&lt;p&gt;This repository is maintained by &lt;a href="https://kavita-ganesan.com/about-me/#.XTTh6ZNKhgc" rel="nofollow"&gt;Kavita Ganesan&lt;/a&gt;. Connect with me on &lt;a href="https://www.linkedin.com/in/kavita-ganesan/" rel="nofollow"&gt;LinkedIn&lt;/a&gt; or &lt;a href="https://twitter.com/kav_gan" rel="nofollow"&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>kavgan</author><guid isPermaLink="false">https://github.com/kavgan/nlp-in-practice</guid><pubDate>Sun, 09 Feb 2020 00:22:00 GMT</pubDate></item><item><title>NLP-LOVE/ML-NLP #23 in Jupyter Notebook, Today</title><link>https://github.com/NLP-LOVE/ML-NLP</link><description>&lt;p&gt;&lt;i&gt;æ­¤é¡¹ç›®æ˜¯æœºå™¨å­¦ä¹ (Machine Learning)ã€æ·±åº¦å­¦ä¹ (Deep Learning)ã€NLPé¢è¯•ä¸­å¸¸è€ƒåˆ°çš„çŸ¥è¯†ç‚¹å’Œä»£ç å®ç°ï¼Œä¹Ÿæ˜¯ä½œä¸ºä¸€ä¸ªç®—æ³•å·¥ç¨‹å¸ˆå¿…ä¼šçš„ç†è®ºåŸºç¡€çŸ¥è¯†ã€‚&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-é¡¹ç›®ä»‹ç»" class="anchor" aria-hidden="true" href="#é¡¹ç›®ä»‹ç»"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;é¡¹ç›®ä»‹ç»&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;æ­¤é¡¹ç›®æ˜¯&lt;strong&gt;æœºå™¨å­¦ä¹ ã€NLPé¢è¯•&lt;/strong&gt;ä¸­å¸¸è€ƒåˆ°çš„&lt;strong&gt;çŸ¥è¯†ç‚¹å’Œä»£ç å®ç°&lt;/strong&gt;ï¼Œä¹Ÿæ˜¯ä½œä¸ºä¸€ä¸ªç®—æ³•å·¥ç¨‹å¸ˆå¿…ä¼šçš„ç†è®ºåŸºç¡€çŸ¥è¯†ã€‚&lt;/li&gt;
&lt;li&gt;æ—¢ç„¶æ˜¯ä»¥é¢è¯•ä¸ºä¸»è¦ç›®çš„ï¼Œäº¦ä¸å¯ä»¥ç¯‡æ¦‚å…¨ï¼Œè¯·è°…è§£ï¼Œæœ‰é—®é¢˜å¯æå‡ºã€‚&lt;/li&gt;
&lt;li&gt;æ­¤é¡¹ç›®ä»¥å„ä¸ªæ¨¡å—ä¸ºåˆ‡å…¥ç‚¹ï¼Œè®©å¤§å®¶æœ‰ä¸€ä¸ªæ¸…æ™°çš„çŸ¥è¯†ä½“ç³»ã€‚&lt;/li&gt;
&lt;li&gt;æ­¤é¡¹ç›®äº¦å¯æ‹¿æ¥å¸¸è¯»ã€å¸¸è®°ä»¥åŠé¢è¯•æ—¶å¤ä¹ ä¹‹ç”¨ã€‚&lt;/li&gt;
&lt;li&gt;æ¯ä¸€ç« é‡Œçš„é—®é¢˜éƒ½æ˜¯é¢è¯•æ—¶æœ‰å¯èƒ½é—®åˆ°çš„çŸ¥è¯†ç‚¹ï¼Œå¦‚æœ‰é—æ¼å¯è”ç³»æˆ‘è¿›è¡Œè¡¥å……ï¼Œç»“å°¾å¤„éƒ½æœ‰ç®—æ³•çš„&lt;strong&gt;å®æˆ˜ä»£ç æ¡ˆä¾‹&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;li&gt;æ€ç»´å¯¼å›¾ï¼Œ&lt;strong&gt;è¯·å…³æ³¨ AIArea å…¬ä¼—å·å¹¶å›å¤ï¼šNLPæ€ç»´å¯¼å›¾&lt;/strong&gt; ï¼Œå³èƒ½ä¸‹è½½é«˜æ¸…å¤§å›¾ã€‚&lt;/li&gt;
&lt;li&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/NLP-LOVE/Introduction-NLP/raw/master/img/2020-2-3_16-0-25.png?raw=true"&gt;&lt;img src="https://github.com/NLP-LOVE/Introduction-NLP/raw/master/img/2020-2-3_16-0-25.png?raw=true" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-ç›®å½•" class="anchor" aria-hidden="true" href="#ç›®å½•"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ç›®å½•&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;é¡¹ç›®æŒç»­æ›´æ–°ä¸­......&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;æ¨¡å—&lt;/th&gt;
&lt;th&gt;ç« èŠ‚&lt;/th&gt;
&lt;th&gt;è´Ÿè´£äºº(GitHub)&lt;/th&gt;
&lt;th&gt;è”ç³»QQ&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/Liner%20Regression/1.Liner%20Regression.md"&gt;1. çº¿æ€§å›å½’(Liner Regression)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/2.Logistics%20Regression/2.Logistics%20Regression.md"&gt;2. é€»è¾‘å›å½’(Logistics Regression)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.Desition%20Tree/Desition%20Tree.md"&gt;3. å†³ç­–æ ‘(Desision Tree)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.1%20Random%20Forest/3.1%20Random%20Forest.md"&gt;3.1 éšæœºæ£®æ—(Random Forest)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.2%20GBDT/3.2%20GBDT.md"&gt;3.2 æ¢¯åº¦æå‡å†³ç­–æ ‘(GBDT)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.3%20XGBoost/3.3%20XGBoost.md"&gt;3.3 XGBoost&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.4%20LightGBM/3.4%20LightGBM.md"&gt;3.4 LightGBM&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/4.%20SVM/4.%20SVM.md"&gt;4. æ”¯æŒå‘é‡æœº(SVM)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;5. æ¦‚ç‡å›¾æ¨¡å‹(Probabilistic Graphical Model)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/5.1%20Bayes%20Network/5.1%20Bayes%20Network.md"&gt;5.1 è´å¶æ–¯ç½‘ç»œ(Bayesian Network)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/5.2%20Markov/5.2%20Markov.md"&gt;5.2 é©¬å°”ç§‘å¤«(Markov)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/5.3%20Topic%20Model"&gt;5.3 ä¸»é¢˜æ¨¡å‹(Topic Model)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/6.%20EM"&gt;6.æœ€å¤§æœŸæœ›ç®—æ³•(EM)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/7.%20Clustering"&gt;7.èšç±»(Clustering)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/8.%20ML%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"&gt;8.MLç‰¹å¾å·¥ç¨‹å’Œä¼˜åŒ–æ–¹æ³•&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æœºå™¨å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/9.%20KNN"&gt;9.Kè¿‘é‚»ç®—æ³•(KNN)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æ·±åº¦å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/10.%20Neural%20Network"&gt;10.ç¥ç»ç½‘ç»œ(Neural Network)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æ·±åº¦å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/11.%20CNN"&gt;11. å·ç§¯ç¥ç»ç½‘ç»œ(CNN)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æ·±åº¦å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/12.%20RNN"&gt;12. å¾ªç¯ç¥ç»ç½‘ç»œ(RNN)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æ·±åº¦å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/12.1%20GRU"&gt;12.1 é—¨æ§å¾ªç¯å•å…ƒ(GRU)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æ·±åº¦å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/12.2%20LSTM"&gt;12.2 é•¿çŸ­æœŸè®°å¿†(LSTM)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æ·±åº¦å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/13.%20Transfer%20Learning"&gt;13.è¿ç§»å­¦ä¹ (Transfer)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æ·±åº¦å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/14.%20Reinforcement%20Learning"&gt;14.å¼ºåŒ–å­¦ä¹ (Reinforcement) &amp;amp; å¤šä»»åŠ¡&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æ·±åº¦å­¦ä¹ &lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/15.%20DL%20Optimizer"&gt;15. æ·±åº¦å­¦ä¹ çš„ä¼˜åŒ–æ–¹æ³•&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.%20NLP"&gt;16. è‡ªç„¶è¯­è¨€å¤„ç†(NLP)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.1%20Word%20Embedding"&gt;16.1 è¯åµŒå…¥(Word2Vec)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.2%20fastText"&gt;16.2 å­è¯åµŒå…¥(fastText)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.3%20GloVe"&gt;16.3 å…¨å±€å‘é‡è¯åµŒå…¥(GloVe)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.4%20textRNN%20%26%20textCNN"&gt;16.4 textRNN &amp;amp; textCNN&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.5%20seq2seq"&gt;16.5 åºåˆ—åˆ°åºåˆ—æ¨¡å‹(seq2seq)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.6%20Attention"&gt;16.6 æ³¨æ„åŠ›æœºåˆ¶(Attention Mechanism)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.7%20Transformer"&gt;16.7 Transformeræ¨¡å‹&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.8%20BERT"&gt;16.8 BERTæ¨¡å‹&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.9%20XLNet"&gt;16.9 XLNetæ¨¡å‹&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;é¡¹ç›®&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System"&gt;17. æ¨èç³»ç»Ÿ(Recommendation System)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;é¡¹ç›®&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/18.%20Intelligent%20Customer%20Service"&gt;18. æ™ºèƒ½å®¢æœ(Intelligent Customer Service)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;é¡¹ç›®&lt;/td&gt;
&lt;td&gt;19. çŸ¥è¯†å›¾è°±(Knowledge Graph)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;é¡¹ç›®&lt;/td&gt;
&lt;td&gt;20. è¯„è®ºåˆ†æ&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;æ¬¢è¿å¤§å®¶åŠ å…¥ï¼å…±åŒå®Œå–„æ­¤é¡¹ç›®ï¼NLPå­¦ä¹ QQ2ç¾¤ã€207576902ã€‘&lt;a href="http://shang.qq.com/wpa/qunwpa?idkey=1defd70810d9e67ca6ab3a30e1425a8a358139315a186dd2192d82a4c0ca1ce9" rel="nofollow"&gt;&lt;img border="0" src="https://camo.githubusercontent.com/615c9901677f501582b6057efc9396b3ed27dc29/687474703a2f2f7075622e69647171696d672e636f6d2f7770612f696d616765732f67726f75702e706e67" alt="NLPå­¦ä¹ ç¾¤â‘¡" title="NLPå­¦ä¹ ç¾¤â‘¡" data-canonical-src="http://pub.idqqimg.com/wpa/images/group.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>NLP-LOVE</author><guid isPermaLink="false">https://github.com/NLP-LOVE/ML-NLP</guid><pubDate>Sun, 09 Feb 2020 00:23:00 GMT</pubDate></item><item><title>empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks #24 in Jupyter Notebook, Today</title><link>https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks</link><description>&lt;p&gt;&lt;i&gt;A series of Python Jupyter notebooks that help you better understand "The Elements of Statistical Learning" book&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-the-elements-of-statistical-learning-notebooks" class="anchor" aria-hidden="true" href="#the-elements-of-statistical-learning-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;"The Elements of Statistical Learning" Notebooks&lt;/h1&gt;
&lt;p&gt;Reproducing examples from the "The Elements of Statistical Learning" by Trevor Hastie, Robert Tibshirani and Jerome Friedman with Python and its popular libraries:
&lt;strong&gt;numpy&lt;/strong&gt;, &lt;strong&gt;math&lt;/strong&gt;, &lt;strong&gt;scipy&lt;/strong&gt;, &lt;strong&gt;sklearn&lt;/strong&gt;, &lt;strong&gt;pandas&lt;/strong&gt;, &lt;strong&gt;tensorflow&lt;/strong&gt;, &lt;strong&gt;statsmodels&lt;/strong&gt;, &lt;strong&gt;sympy&lt;/strong&gt;, &lt;strong&gt;catboost&lt;/strong&gt;, &lt;strong&gt;pyearth&lt;/strong&gt;, &lt;strong&gt;mlxtend&lt;/strong&gt;, &lt;strong&gt;cvxpy&lt;/strong&gt;. Almost all plotting is done using &lt;strong&gt;matplotlib&lt;/strong&gt;, sometimes using &lt;strong&gt;seaborn&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;p&gt;The documented Jupyter Notebooks are in the &lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/tree/master/examples"&gt;examples&lt;/a&gt; folder:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesmixtureipynb" class="anchor" aria-hidden="true" href="#examplesmixtureipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Mixture.ipynb"&gt;examples/Mixture.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Classifying the points from a mixture of "gaussians" using linear regression, nearest-neighbor, logistic regression with natural cubic splines basis expansion, neural networks, support vector machines, flexible discriminant analysis over MARS regression, mixture discriminant analysis, k-Means clustering, Gaussian mixture model and random forests.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/mixture.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/mixture.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesprostate-canceripynb" class="anchor" aria-hidden="true" href="#examplesprostate-canceripynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Prostate%20Cancer.ipynb"&gt;examples/Prostate Cancer.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Predicting prostate specific antigen using ordinary least squares, ridge/lasso regularized linear regression, principal components regression, partial least squares and best subset regression. Model parameters are selected by K-folds cross-validation.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/cancer.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/cancer.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplessouth-african-heart-diseaseipynb" class="anchor" aria-hidden="true" href="#examplessouth-african-heart-diseaseipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/South%20African%20Heart%20Disease.ipynb"&gt;examples/South African Heart Disease.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Understanding the risk factors using logistic regression, L1 regularized logistic regression, natural cubic splines basis expansion for nonlinearities, thin-plate spline for mutual dependency, local logistic regression, kernel density estimation and gaussian mixture models.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/chd.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/chd.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesvowelipynb" class="anchor" aria-hidden="true" href="#examplesvowelipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Vowel.ipynb"&gt;examples/Vowel.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Vowel speech recognition using regression of an indicator matrix, linear/quadratic/regularized/reduced-rank discriminant analysis and logistic regression.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/vowel.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/vowel.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesbone-mineral-densityipynb" class="anchor" aria-hidden="true" href="#examplesbone-mineral-densityipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Bone%20Mineral%20Density.ipynb"&gt;examples/Bone Mineral Density.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Comparing patterns of bone mineral density relative change for men and women using smoothing splines.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/bone.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/bone.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesair-pollution-dataipynb" class="anchor" aria-hidden="true" href="#examplesair-pollution-dataipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Air%20Pollution.ipynb"&gt;examples/Air Pollution Data.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing Los Angeles pollution data using smoothing splines.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/ozone_vs_pressure_gradient.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/ozone_vs_pressure_gradient.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesphoneme-recognitionipynb" class="anchor" aria-hidden="true" href="#examplesphoneme-recognitionipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Phoneme%20Recognition.ipynb"&gt;examples/Phoneme Recognition.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Phonemes speech recognition using reduced flexibility logistic regression.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/phoneme.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/phoneme.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesgalaxyipynb" class="anchor" aria-hidden="true" href="#examplesgalaxyipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Galaxy.ipynb"&gt;examples/Galaxy.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing radial velocity of galaxy NGC7531 using local regression in multidimentional space.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/galaxy.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/galaxy.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesozoneipynb" class="anchor" aria-hidden="true" href="#examplesozoneipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Ozone.ipynb"&gt;examples/Ozone.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing the factors influencing ozone concentration using local regression and trellis plot.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/ozone.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/ozone.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesspamipynb" class="anchor" aria-hidden="true" href="#examplesspamipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Spam.ipynb"&gt;examples/Spam.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Detecting email spam using logistic regression, generalized additive logistic model, decision tree, multivariate adaptive regression splines, boosting and random forest.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/spam.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/spam.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplescalifornia-housingipynb" class="anchor" aria-hidden="true" href="#examplescalifornia-housingipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/California%20Housing.ipynb"&gt;examples/California Housing.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing the factors influencing California houses prices using boosting over decision trees and partial dependance plots.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/california.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/california.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesdemographicsipynb" class="anchor" aria-hidden="true" href="#examplesdemographicsipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Demographics.ipynb"&gt;examples/Demographics.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Predicting shopping mall customers occupation, and hence identifying demographic variables that discriminate between different occupational categories using boosting and market basket analysis.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/demographics.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/demographics.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-exampleszip-codeipynb" class="anchor" aria-hidden="true" href="#exampleszip-codeipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/ZIP%20Code.ipynb"&gt;examples/ZIP Code.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Recognizing small hand-drawn digits using LeCun's Net-1 - Net-5 neural networks.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/zip1.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/zip1.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Analysing of the number three variation in ZIP codes using principal component and archetypal analysis.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/zip2.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/zip2.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-exampleshuman-tumor-microarray-dataipynb" class="anchor" aria-hidden="true" href="#exampleshuman-tumor-microarray-dataipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Human%20Tumor%20Microarray%20Data.ipynb"&gt;examples/Human Tumor Microarray Data.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing microarray data using K-means clustring and hierarchical clustering.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/tumor.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/tumor.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplescountry-dissimilaritiesipynb" class="anchor" aria-hidden="true" href="#examplescountry-dissimilaritiesipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Country%20Dissimilarities.ipynb"&gt;examples/Country Dissimilarities.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing country dissimilarities using K-medoids clustering and multidimensional scaling.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/country.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/country.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplessignatureipynb" class="anchor" aria-hidden="true" href="#examplessignatureipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Signature.ipynb"&gt;examples/Signature.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing signature shapes using Procrustes transformation.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/signature.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/signature.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-exampleswaveformipynb" class="anchor" aria-hidden="true" href="#exampleswaveformipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Waveform.ipynb"&gt;examples/Waveform.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Recognizing wave classes using linear, quadratic, flexible (over MARS regression), mixture discriminant analysis and decision trees.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/waveform.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/waveform.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesprotein-flow-cytometryipynb" class="anchor" aria-hidden="true" href="#examplesprotein-flow-cytometryipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Protein%20Flow%20Cytometry.ipynb"&gt;examples/Protein Flow-Cytometry.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing protein flow-cytometry data using graphical-lasso undirected graphical model for continuous variables.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/cytometry.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/cytometry.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplessrbct-microarrayipynb" class="anchor" aria-hidden="true" href="#examplessrbct-microarrayipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/SRBCT%20Microarray.ipynb"&gt;examples/SRBCT Microarray.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing microarray data of 2308 genes and selecting the most significant genes for cancer classification using nearest shrunken centroids.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/srbct.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/srbct.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examples14-cancer-microarrayipynb" class="anchor" aria-hidden="true" href="#examples14-cancer-microarrayipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/14%20Cancer.ipynb"&gt;examples/14 Cancer Microarray.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Analysing microarray data of 16,063 genes gathered by Ramaswamy et al. (2001) and selecting the most significant genes for cancer classification using nearest shrunken centroids, L2-penalized discriminant analysis, support vector classifier, k-nearest neighbors, L2-penalized multinominal, L1-penalized multinominal and elastic-net penalized multinominal. It is a difficult classification problem with p&amp;gt;&amp;gt;N (only 144 training observations).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesskin-of-the-orangeipynb" class="anchor" aria-hidden="true" href="#examplesskin-of-the-orangeipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Skin%20of%20the%20Orange.ipynb"&gt;examples/Skin of the Orange.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Solving a synthetic classification problem using Support Vector Machines and multivariate adaptive regression splines to show the influence of additional noise features.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-examplesradiation-sensitivityipynb" class="anchor" aria-hidden="true" href="#examplesradiation-sensitivityipynb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Radiation%20Sensitivity.ipynb"&gt;examples/Radiation Sensitivity.ipynb&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Assessing the significance of 12,625 genes from microarray study of radiation sensitivity using Benjamini-Hochberg method and the significane analysis of microarrays (SAM) approach.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/images/radiation.png"&gt;&lt;img src="https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/raw/master/images/radiation.png" alt="alt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>empathy87</author><guid isPermaLink="false">https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks</guid><pubDate>Sun, 09 Feb 2020 00:24:00 GMT</pubDate></item><item><title>ypwhs/captcha_break #25 in Jupyter Notebook, Today</title><link>https://github.com/ypwhs/captcha_break</link><description>&lt;p&gt;&lt;i&gt;éªŒè¯ç è¯†åˆ«&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¥ç ´è§£-captcha-éªŒè¯ç " class="anchor" aria-hidden="true" href="#ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¥ç ´è§£-captcha-éªŒè¯ç "&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¥ç ´è§£ captcha éªŒè¯ç &lt;/h1&gt;
&lt;p&gt;æœ¬é¡¹ç›®ä¼šé€šè¿‡ Keras æ­å»ºä¸€ä¸ªæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œæ¥è¯†åˆ« captcha éªŒè¯ç ï¼Œå»ºè®®ä½¿ç”¨æ˜¾å¡æ¥è¿è¡Œè¯¥é¡¹ç›®ã€‚&lt;/p&gt;
&lt;p&gt;ä¸‹é¢çš„å¯è§†åŒ–ä»£ç éƒ½æ˜¯åœ¨ &lt;code&gt;jupyter notebook&lt;/code&gt; ä¸­å®Œæˆçš„ï¼Œå¦‚æœä½ å¸Œæœ›å†™æˆ python è„šæœ¬ï¼Œç¨åŠ ä¿®æ”¹å³å¯æ­£å¸¸è¿è¡Œï¼Œå½“ç„¶ä¹Ÿå¯ä»¥å»æ‰è¿™äº›å¯è§†åŒ–ä»£ç ã€‚&lt;/p&gt;
&lt;p&gt;2019 å¹´æ›´æ–°äº†ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;é€‚é…äº†æ–°ç‰ˆ API&lt;/li&gt;
&lt;li&gt;æé«˜äº†æ•°æ®ç”Ÿæˆå™¨çš„æ•ˆç‡&lt;/li&gt;
&lt;li&gt;ä½¿ç”¨äº† CuDNNGRU æé«˜äº†è®­ç»ƒå’Œé¢„æµ‹æ•ˆç‡&lt;/li&gt;
&lt;li&gt;æ›´æ–°äº†æ–‡æ¡£&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-ç¯å¢ƒ" class="anchor" aria-hidden="true" href="#ç¯å¢ƒ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ç¯å¢ƒ&lt;/h1&gt;
&lt;p&gt;æœ¬é¡¹ç›®ä½¿ç”¨çš„ç¯å¢ƒå¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;captcha 0.3&lt;/li&gt;
&lt;li&gt;tensorflow-gpu 1.13.1&lt;/li&gt;
&lt;li&gt;numpy 1.16.4&lt;/li&gt;
&lt;li&gt;tqdm 4.28.1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä¸‹é¢å‡ ä¸ªåŒ…æ˜¯ç”¨äºå¯è§†åŒ–çš„ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;matplotlib 2.2.2&lt;/li&gt;
&lt;li&gt;pandas 0.23.0&lt;/li&gt;
&lt;li&gt;pydot 1.4.1&lt;/li&gt;
&lt;li&gt;graphviz 2.38.0-12ubuntu2.1&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-captcha" class="anchor" aria-hidden="true" href="#captcha"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;captcha&lt;/h1&gt;
&lt;p&gt;captcha æ˜¯ç”¨ python å†™çš„ç”ŸæˆéªŒè¯ç çš„åº“ï¼Œå®ƒæ”¯æŒå›¾ç‰‡éªŒè¯ç å’Œè¯­éŸ³éªŒè¯ç ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯å®ƒç”Ÿæˆå›¾ç‰‡éªŒè¯ç çš„åŠŸèƒ½ã€‚&lt;/p&gt;
&lt;p&gt;é¦–å…ˆæˆ‘ä»¬è®¾ç½®æˆ‘ä»¬çš„éªŒè¯ç æ ¼å¼ä¸ºæ•°å­—åŠ å¤§å†™å­—æ¯ï¼Œç”Ÿæˆä¸€ä¸²éªŒè¯ç è¯•è¯•çœ‹ï¼š&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; captcha.image &lt;span class="pl-k"&gt;import&lt;/span&gt; ImageCaptcha
&lt;span class="pl-k"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class="pl-k"&gt;as&lt;/span&gt; plt
&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np
&lt;span class="pl-k"&gt;import&lt;/span&gt; random

&lt;span class="pl-k"&gt;%&lt;/span&gt;matplotlib inline
&lt;span class="pl-k"&gt;%&lt;/span&gt;config InlineBackend.figure_format &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;retina&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;

&lt;span class="pl-k"&gt;import&lt;/span&gt; string
characters &lt;span class="pl-k"&gt;=&lt;/span&gt; string.digits &lt;span class="pl-k"&gt;+&lt;/span&gt; string.ascii_uppercase
&lt;span class="pl-c1"&gt;print&lt;/span&gt;(characters)

width, height, n_len, n_class &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;170&lt;/span&gt;, &lt;span class="pl-c1"&gt;80&lt;/span&gt;, &lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-c1"&gt;len&lt;/span&gt;(characters)

generator &lt;span class="pl-k"&gt;=&lt;/span&gt; ImageCaptcha(&lt;span class="pl-v"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;width, &lt;span class="pl-v"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;height)
random_str &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([random.choice(characters) &lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;4&lt;/span&gt;)])
img &lt;span class="pl-k"&gt;=&lt;/span&gt; generator.generate_image(random_str)

plt.imshow(img)
plt.title(random_str)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/captcha.png"&gt;&lt;img src="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/captcha.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-é˜²æ­¢-tensorflow-å ç”¨æ‰€æœ‰æ˜¾å­˜" class="anchor" aria-hidden="true" href="#é˜²æ­¢-tensorflow-å ç”¨æ‰€æœ‰æ˜¾å­˜"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;é˜²æ­¢ tensorflow å ç”¨æ‰€æœ‰æ˜¾å­˜&lt;/h1&gt;
&lt;p&gt;ä¼—æ‰€å‘¨çŸ¥ tensorflow é»˜è®¤å ç”¨æ‰€æœ‰æ˜¾å­˜ï¼Œè¿™æ ·ä¸åˆ©äºæˆ‘ä»¬åŒæ—¶è¿›è¡Œå¤šé¡¹å®éªŒï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç å½“ tensorflow ä½¿ç”¨å®ƒéœ€è¦çš„æ˜¾å­˜ï¼Œè€Œä¸æ˜¯ç›´æ¥å ç”¨æ‰€æœ‰æ˜¾å­˜ã€‚&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow &lt;span class="pl-k"&gt;as&lt;/span&gt; tf
&lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow.keras.backend &lt;span class="pl-k"&gt;as&lt;/span&gt; K

config &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.ConfigProto()
config.gpu_options.allow_growth&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;
sess &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.Session(&lt;span class="pl-v"&gt;config&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;config)
K.set_session(sess)&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-æ•°æ®ç”Ÿæˆå™¨" class="anchor" aria-hidden="true" href="#æ•°æ®ç”Ÿæˆå™¨"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ•°æ®ç”Ÿæˆå™¨&lt;/h1&gt;
&lt;p&gt;è®­ç»ƒæ¨¡å‹çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¸¤ç§æ–¹å¼æ¥ç”Ÿæˆæˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ï¼Œä¸€ç§æ˜¯ä¸€æ¬¡æ€§ç”Ÿæˆå‡ ä¸‡å¼ å›¾ï¼Œç„¶åå¼€å§‹è®­ç»ƒï¼Œä¸€ç§æ˜¯å®šä¹‰ä¸€ä¸ªæ•°æ®ç”Ÿæˆå™¨ï¼Œç„¶ååˆ©ç”¨ &lt;code&gt;fit_generator&lt;/code&gt; å‡½æ•°æ¥è®­ç»ƒã€‚&lt;/p&gt;
&lt;p&gt;ç¬¬ä¸€ç§æ–¹å¼çš„å¥½å¤„æ˜¯è®­ç»ƒçš„æ—¶å€™æ˜¾å¡åˆ©ç”¨ç‡é«˜ï¼Œå¦‚æœä½ éœ€è¦ç»å¸¸è°ƒå‚ï¼Œå¯ä»¥ä¸€æ¬¡ç”Ÿæˆï¼Œå¤šæ¬¡ä½¿ç”¨ï¼›ç¬¬äºŒç§æ–¹å¼çš„å¥½å¤„æ˜¯ä½ ä¸éœ€è¦ç”Ÿæˆå¤§é‡æ•°æ®ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥åˆ©ç”¨ CPU ç”Ÿæˆæ•°æ®ï¼Œè€Œä¸”è¿˜æœ‰ä¸€ä¸ªå¥½å¤„æ˜¯ä½ å¯ä»¥æ— é™ç”Ÿæˆæ•°æ®ã€‚&lt;/p&gt;
&lt;p&gt;æˆ‘ä»¬çš„æ•°æ®æ ¼å¼å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-x" class="anchor" aria-hidden="true" href="#x"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;X&lt;/h2&gt;
&lt;p&gt;X çš„å½¢çŠ¶æ˜¯ &lt;code&gt;(batch_size, height, width, 3)&lt;/code&gt;ï¼Œæ¯”å¦‚ä¸€æ‰¹ç”Ÿæˆ 128 ä¸ªæ ·æœ¬ï¼Œå›¾ç‰‡å®½åº¦ä¸º170ï¼Œé«˜åº¦ä¸º80ï¼Œé‚£ä¹ˆ X çš„å½¢çŠ¶å°±æ˜¯ &lt;code&gt;(128, 64, 128, 3)&lt;/code&gt;ï¼Œå¦‚æœä½ æƒ³å–ç¬¬ä¸€å¼ å›¾ï¼Œä»£ç å¯ä»¥è¿™æ ·å†™ &lt;code&gt;X[0]&lt;/code&gt;ã€‚&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-y" class="anchor" aria-hidden="true" href="#y"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;y&lt;/h2&gt;
&lt;p&gt;y çš„å½¢çŠ¶æ˜¯å››ä¸ª &lt;code&gt;(batch_size, n_class)&lt;/code&gt;ï¼Œå¦‚æœè½¬æ¢æˆ numpy çš„æ ¼å¼ï¼Œåˆ™æ˜¯ &lt;code&gt;(n_len, batch_size, n_class)&lt;/code&gt;ï¼Œæ¯”å¦‚ä¸€æ‰¹ç”Ÿæˆ 128 ä¸ªæ ·æœ¬ï¼ŒéªŒè¯ç çš„å­—ç¬¦æœ‰ 36 ç§ï¼Œé•¿åº¦æ˜¯ 4 ä½ï¼Œé‚£ä¹ˆå®ƒçš„å½¢çŠ¶å°±æ˜¯ 4 ä¸ª &lt;code&gt;(128, 36)&lt;/code&gt; çš„çŸ©é˜µï¼Œä¹Ÿå¯ä»¥è¯´æ˜¯ &lt;code&gt;(4, 32, 36)&lt;/code&gt;ã€‚&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-æ•°æ®ç”Ÿæˆå™¨-1" class="anchor" aria-hidden="true" href="#æ•°æ®ç”Ÿæˆå™¨-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ•°æ®ç”Ÿæˆå™¨&lt;/h2&gt;
&lt;p&gt;ä¸ºäº†è®© Keras èƒ½å¤Ÿä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œç”Ÿæˆæ•°æ®ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ Keras çš„ Sequence ç±»å®ç°ä¸€ä¸ªæˆ‘ä»¬è‡ªå·±çš„æ•°æ®ç±»ã€‚&lt;/p&gt;
&lt;p&gt;åœ¨ &lt;code&gt;__init__&lt;/code&gt; åˆå§‹åŒ–å‡½æ•°é‡Œï¼Œæˆ‘ä»¬å®šä¹‰æ•°æ®æ‰€éœ€çš„å‚æ•°ï¼Œç„¶åè¿™ä¸ªæ•°æ®çš„é•¿åº¦å°±æ˜¯ steps æ•°ã€‚åœ¨ &lt;code&gt;__getitem__&lt;/code&gt; é‡Œï¼Œæˆ‘ä»¬ä¸ç”¨ç†ä¼šç´¢å¼•å·ï¼Œç›´æ¥éšæœºç”Ÿæˆä¸€æ‰¹æ ·æœ¬é€å»è®­ç»ƒå³å¯ã€‚&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.utils &lt;span class="pl-k"&gt;import&lt;/span&gt; Sequence

&lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;CaptchaSequence&lt;/span&gt;(&lt;span class="pl-e"&gt;Sequence&lt;/span&gt;):
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__init__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;characters&lt;/span&gt;, &lt;span class="pl-smi"&gt;batch_size&lt;/span&gt;, &lt;span class="pl-smi"&gt;steps&lt;/span&gt;, &lt;span class="pl-smi"&gt;n_len&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-smi"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-smi"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;64&lt;/span&gt;):
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.characters &lt;span class="pl-k"&gt;=&lt;/span&gt; characters
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size &lt;span class="pl-k"&gt;=&lt;/span&gt; batch_size
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.steps &lt;span class="pl-k"&gt;=&lt;/span&gt; steps
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_len &lt;span class="pl-k"&gt;=&lt;/span&gt; n_len
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.width &lt;span class="pl-k"&gt;=&lt;/span&gt; width
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.height &lt;span class="pl-k"&gt;=&lt;/span&gt; height
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_class &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;len&lt;/span&gt;(characters)
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.generator &lt;span class="pl-k"&gt;=&lt;/span&gt; ImageCaptcha(&lt;span class="pl-v"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;width, &lt;span class="pl-v"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;height)
    
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__len__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;):
        &lt;span class="pl-k"&gt;return&lt;/span&gt; &lt;span class="pl-c1"&gt;self&lt;/span&gt;.steps

    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__getitem__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;idx&lt;/span&gt;):
        X &lt;span class="pl-k"&gt;=&lt;/span&gt; np.zeros((&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.height, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.width, &lt;span class="pl-c1"&gt;3&lt;/span&gt;), &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.float32)
        y &lt;span class="pl-k"&gt;=&lt;/span&gt; [np.zeros((&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_class), &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.uint8) &lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_len)]
        &lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size):
            random_str &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([random.choice(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.characters) &lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_len)])
            X[i] &lt;span class="pl-k"&gt;=&lt;/span&gt; np.array(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.generator.generate_image(random_str)) &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255.0&lt;/span&gt;
            &lt;span class="pl-k"&gt;for&lt;/span&gt; j, ch &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;enumerate&lt;/span&gt;(random_str):
                y[j][i, :] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;
                y[j][i, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.characters.find(ch)] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1&lt;/span&gt;
        &lt;span class="pl-k"&gt;return&lt;/span&gt; X, y&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-ä½¿ç”¨ç”Ÿæˆå™¨" class="anchor" aria-hidden="true" href="#ä½¿ç”¨ç”Ÿæˆå™¨"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä½¿ç”¨ç”Ÿæˆå™¨&lt;/h1&gt;
&lt;p&gt;ç”Ÿæˆå™¨çš„ä½¿ç”¨æ–¹æ³•å¾ˆç®€å•ï¼Œåªéœ€è¦ç”¨å¯¹å®ƒå–ç¬¬ä¸€ä¸ª batch å³å¯ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªä¾‹å­ï¼Œåˆå§‹åŒ–ä¸€ä¸ªæ•°æ®é›†ï¼Œè®¾ç½® batch_size å’Œ steps éƒ½ä¸º 1ï¼Œç„¶åå–å‡ºæ¥ç¬¬ä¸€ä¸ªæ•°æ®ï¼Œå¯¹å®ƒå¯è§†åŒ–ã€‚&lt;/p&gt;
&lt;p&gt;åœ¨è¿™é‡Œæˆ‘ä»¬å¯¹ç”Ÿæˆçš„  One-Hot ç¼–ç åçš„æ ‡ç­¾è¿›è¡Œäº†è§£ç ï¼Œé¦–å…ˆå°†å®ƒè½¬ä¸º numpy æ•°ç»„ï¼Œç„¶åå–36ä¸ªå­—ç¬¦ä¸­æœ€å¤§çš„æ•°å­—çš„ä½ç½®ï¼ˆaxis=2ä»£è¡¨å­—ç¬¦çš„è½´ï¼‰ï¼Œå®é™…ä¸Šç¥ç»ç½‘ç»œä¼šè¾“å‡º36ä¸ªå­—ç¬¦çš„æ¦‚ç‡ï¼Œæˆ‘ä»¬éœ€è¦å°†æ¦‚ç‡æœ€å¤§çš„å››ä¸ªå­—ç¬¦çš„ç¼–å·å–å‡ºæ¥ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;decode&lt;/span&gt;(&lt;span class="pl-smi"&gt;y&lt;/span&gt;):
    y &lt;span class="pl-k"&gt;=&lt;/span&gt; np.argmax(np.array(y), &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;)[:,&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
    &lt;span class="pl-k"&gt;return&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([characters[x] &lt;span class="pl-k"&gt;for&lt;/span&gt; x &lt;span class="pl-k"&gt;in&lt;/span&gt; y])

data &lt;span class="pl-k"&gt;=&lt;/span&gt; CaptchaSequence(characters, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-v"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;)
X, y &lt;span class="pl-k"&gt;=&lt;/span&gt; data[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
plt.imshow(X[&lt;span class="pl-c1"&gt;0&lt;/span&gt;])
plt.title(decode(y))&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-æ„å»ºæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œ" class="anchor" aria-hidden="true" href="#æ„å»ºæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ„å»ºæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œ&lt;/h1&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.models &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;
&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.layers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

input_tensor &lt;span class="pl-k"&gt;=&lt;/span&gt; Input((height, width, &lt;span class="pl-c1"&gt;3&lt;/span&gt;))
x &lt;span class="pl-k"&gt;=&lt;/span&gt; input_tensor
&lt;span class="pl-k"&gt;for&lt;/span&gt; i, n_cnn &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;enumerate&lt;/span&gt;([&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;]):
    &lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(n_cnn):
        x &lt;span class="pl-k"&gt;=&lt;/span&gt; Conv2D(&lt;span class="pl-c1"&gt;32&lt;/span&gt;&lt;span class="pl-k"&gt;*&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;&lt;span class="pl-k"&gt;**&lt;/span&gt;&lt;span class="pl-c1"&gt;min&lt;/span&gt;(i, &lt;span class="pl-c1"&gt;3&lt;/span&gt;), &lt;span class="pl-v"&gt;kernel_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-v"&gt;padding&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;same&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;kernel_initializer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;he_uniform&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)(x)
        x &lt;span class="pl-k"&gt;=&lt;/span&gt; BatchNormalization()(x)
        x &lt;span class="pl-k"&gt;=&lt;/span&gt; Activation(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;relu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)(x)
    x &lt;span class="pl-k"&gt;=&lt;/span&gt; MaxPooling2D(&lt;span class="pl-c1"&gt;2&lt;/span&gt;)(x)

x &lt;span class="pl-k"&gt;=&lt;/span&gt; Flatten()(x)
x &lt;span class="pl-k"&gt;=&lt;/span&gt; [Dense(n_class, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;softmax&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;c&lt;span class="pl-c1"&gt;%d&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-k"&gt;%&lt;/span&gt;(i&lt;span class="pl-k"&gt;+&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;))(x) &lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(n_len)]
model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(&lt;span class="pl-v"&gt;inputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;input_tensor, &lt;span class="pl-v"&gt;outputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;x)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;æ¨¡å‹ç»“æ„å¾ˆç®€å•ï¼Œç‰¹å¾æå–éƒ¨åˆ†ä½¿ç”¨çš„æ˜¯ä¸¤ä¸ªå·ç§¯ï¼Œä¸€ä¸ªæ± åŒ–çš„ç»“æ„ï¼Œè¿™ä¸ªç»“æ„æ˜¯å­¦çš„ VGG16 çš„ç»“æ„ã€‚æˆ‘ä»¬é‡å¤äº”ä¸ª blockï¼Œç„¶åæˆ‘ä»¬å°†å®ƒ Flattenï¼Œè¿æ¥å››ä¸ªåˆ†ç±»å™¨ï¼Œæ¯ä¸ªåˆ†ç±»å™¨æ˜¯36ä¸ªç¥ç»å…ƒï¼Œè¾“å‡º36ä¸ªå­—ç¬¦çš„æ¦‚ç‡ã€‚&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-æ¨¡å‹å¯è§†åŒ–" class="anchor" aria-hidden="true" href="#æ¨¡å‹å¯è§†åŒ–"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ¨¡å‹å¯è§†åŒ–&lt;/h1&gt;
&lt;p&gt;å¾—ç›Šäº Keras è‡ªå¸¦çš„å¯è§†åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å‡ å¥ä»£ç æ¥å¯è§†åŒ–æ¨¡å‹çš„ç»“æ„ï¼š&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.utils &lt;span class="pl-k"&gt;import&lt;/span&gt; plot_model
&lt;span class="pl-k"&gt;from&lt;/span&gt; IPython.display &lt;span class="pl-k"&gt;import&lt;/span&gt; Image

plot_model(model, &lt;span class="pl-v"&gt;to_file&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn.png&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;show_shapes&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
Image(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn.png&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;è¿™é‡Œéœ€è¦ä½¿ç”¨ pydot è¿™ä¸ªåº“ï¼Œä»¥åŠ graphviz è¿™ä¸ªåº“ï¼Œåœ¨ macOS ç³»ç»Ÿä¸Šå®‰è£…æ–¹æ³•å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;brew install graphviz
pip install pydot-ng&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="imgs/cnn.png"&gt;&lt;img src="imgs/cnn.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æœ€åä¸€å±‚å·ç§¯å±‚è¾“å‡ºçš„å½¢çŠ¶æ˜¯ &lt;code&gt;(1, 6, 256)&lt;/code&gt;ï¼Œå·²ç»ä¸èƒ½å†åŠ å·ç§¯å±‚äº†ã€‚&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-è®­ç»ƒæ¨¡å‹" class="anchor" aria-hidden="true" href="#è®­ç»ƒæ¨¡å‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è®­ç»ƒæ¨¡å‹&lt;/h1&gt;
&lt;p&gt;è®­ç»ƒæ¨¡å‹åè€Œæ˜¯æ‰€æœ‰æ­¥éª¤é‡Œé¢æœ€ç®€å•çš„ä¸€ä¸ªï¼Œç›´æ¥ä½¿ç”¨ &lt;code&gt;model.fit_generator&lt;/code&gt; å³å¯ï¼Œè¿™é‡Œçš„éªŒè¯é›†ä½¿ç”¨äº†åŒæ ·çš„ç”Ÿæˆå™¨ï¼Œç”±äºæ•°æ®æ˜¯é€šè¿‡ç”Ÿæˆå™¨éšæœºç”Ÿæˆçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸ç”¨è€ƒè™‘æ•°æ®æ˜¯å¦ä¼šé‡å¤ã€‚&lt;/p&gt;
&lt;p&gt;ä¸ºäº†é¿å…æ‰‹åŠ¨è°ƒå‚ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† Adam ä¼˜åŒ–å™¨ï¼Œå®ƒçš„å­¦ä¹ ç‡æ˜¯è‡ªåŠ¨è®¾ç½®çš„ï¼Œæˆ‘ä»¬åªéœ€è¦ç»™ä¸€ä¸ªè¾ƒå¥½çš„åˆå§‹å­¦ä¹ ç‡å³å¯ã€‚&lt;/p&gt;
&lt;p&gt;EarlyStopping æ˜¯ä¸€ä¸ª Keras çš„ Callbackï¼Œå®ƒå¯ä»¥åœ¨ loss è¶…è¿‡å¤šå°‘ä¸ª epoch æ²¡æœ‰ä¸‹é™ä»¥åï¼Œå°±è‡ªåŠ¨ç»ˆæ­¢è®­ç»ƒï¼Œé¿å…æµªè´¹æ—¶é—´ã€‚&lt;/p&gt;
&lt;p&gt;ModelCheckpoint æ˜¯å¦ä¸€ä¸ªå¥½ç”¨çš„ Callbackï¼Œå®ƒå¯ä»¥ä¿å­˜è®­ç»ƒè¿‡ç¨‹ä¸­æœ€å¥½çš„æ¨¡å‹ã€‚&lt;/p&gt;
&lt;p&gt;CSVLogger å¯ä»¥è®°å½• loss ä¸º CSV æ–‡ä»¶ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥åœ¨è®­ç»ƒå®Œæˆä»¥åç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„ loss æ›²çº¿ã€‚&lt;/p&gt;
&lt;p&gt;æ³¨æ„ï¼Œè¿™æ®µä»£ç åœ¨ç¬”è®°æœ¬ç”µè„‘ä¸Šå¯èƒ½è¦è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®ä½¿ç”¨å¸¦æœ‰ NVIDIA æ˜¾å¡çš„æœºå™¨è¿è¡Œã€‚æ³¨æ„æˆ‘ä»¬è¿™é‡Œä½¿ç”¨äº†ä¸€ä¸ªå°æŠ€å·§ï¼Œæ·»åŠ  &lt;code&gt;workers=4&lt;/code&gt; å‚æ•°è®© Keras è‡ªåŠ¨å®ç°å¤šè¿›ç¨‹ç”Ÿæˆæ•°æ®ï¼Œæ‘†è„± python å•çº¿ç¨‹æ•ˆç‡ä½çš„ç¼ºç‚¹ã€‚&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.callbacks &lt;span class="pl-k"&gt;import&lt;/span&gt; EarlyStopping, CSVLogger, ModelCheckpoint
&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.optimizers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

train_data &lt;span class="pl-k"&gt;=&lt;/span&gt; CaptchaSequence(characters, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1000&lt;/span&gt;)
valid_data &lt;span class="pl-k"&gt;=&lt;/span&gt; CaptchaSequence(characters, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;)
callbacks &lt;span class="pl-k"&gt;=&lt;/span&gt; [EarlyStopping(&lt;span class="pl-v"&gt;patience&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;3&lt;/span&gt;), CSVLogger(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn.csv&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;), ModelCheckpoint(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn_best.h5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;save_best_only&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)]

model.compile(&lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;categorical_crossentropy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
              &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;Adam(&lt;span class="pl-c1"&gt;1e-3&lt;/span&gt;, &lt;span class="pl-v"&gt;amsgrad&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;), 
              &lt;span class="pl-v"&gt;metrics&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;accuracy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])
model.fit_generator(train_data, &lt;span class="pl-v"&gt;epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;validation_data&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;valid_data, &lt;span class="pl-v"&gt;workers&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-v"&gt;use_multiprocessing&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;,
                    &lt;span class="pl-v"&gt;callbacks&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;callbacks)&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-è½½å…¥æœ€å¥½çš„æ¨¡å‹ç»§ç»­è®­ç»ƒä¸€ä¼š" class="anchor" aria-hidden="true" href="#è½½å…¥æœ€å¥½çš„æ¨¡å‹ç»§ç»­è®­ç»ƒä¸€ä¼š"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è½½å…¥æœ€å¥½çš„æ¨¡å‹ç»§ç»­è®­ç»ƒä¸€ä¼š&lt;/h3&gt;
&lt;p&gt;ä¸ºäº†è®©æ¨¡å‹å……åˆ†è®­ç»ƒï¼Œæˆ‘ä»¬å¯ä»¥è½½å…¥ä¹‹å‰æœ€å¥½çš„æ¨¡å‹æƒå€¼ï¼Œç„¶åé™ä½å­¦ä¹ ç‡ä¸ºåŸæ¥çš„ååˆ†ä¹‹ä¸€ï¼Œç»§ç»­è®­ç»ƒï¼Œè¿™æ ·å¯ä»¥è®©æ¨¡å‹æ”¶æ•›å¾—æ›´å¥½ã€‚&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;model.load_weights(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn_best.h5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

callbacks &lt;span class="pl-k"&gt;=&lt;/span&gt; [EarlyStopping(&lt;span class="pl-v"&gt;patience&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;3&lt;/span&gt;), CSVLogger(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn.csv&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;append&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;), 
             ModelCheckpoint(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cnn_best.h5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;save_best_only&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)]

model.compile(&lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;categorical_crossentropy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
              &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;Adam(&lt;span class="pl-c1"&gt;1e-4&lt;/span&gt;, &lt;span class="pl-v"&gt;amsgrad&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;), 
              &lt;span class="pl-v"&gt;metrics&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;accuracy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])
model.fit_generator(train_data, &lt;span class="pl-v"&gt;epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;validation_data&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;valid_data, &lt;span class="pl-v"&gt;workers&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-v"&gt;use_multiprocessing&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;,
                    &lt;span class="pl-v"&gt;callbacks&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;callbacks)&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-æµ‹è¯•æ¨¡å‹" class="anchor" aria-hidden="true" href="#æµ‹è¯•æ¨¡å‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æµ‹è¯•æ¨¡å‹&lt;/h1&gt;
&lt;p&gt;å½“æˆ‘ä»¬è®­ç»ƒå®Œæˆä»¥åï¼Œå¯ä»¥è¯†åˆ«ä¸€ä¸ªéªŒè¯ç è¯•è¯•çœ‹ï¼š&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;X, y &lt;span class="pl-k"&gt;=&lt;/span&gt; data[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
y_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict(X)
plt.title(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;real: &lt;span class="pl-c1"&gt;%s&lt;/span&gt;&lt;span class="pl-cce"&gt;\n&lt;/span&gt;pred:&lt;span class="pl-c1"&gt;%s&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-k"&gt;%&lt;/span&gt;(decode(y), decode(y_pred)))
plt.imshow(X[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], &lt;span class="pl-v"&gt;cmap&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;gray&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
plt.axis(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;off&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/test_model.png"&gt;&lt;img src="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/test_model.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-è®¡ç®—æ¨¡å‹æ€»ä½“å‡†ç¡®ç‡" class="anchor" aria-hidden="true" href="#è®¡ç®—æ¨¡å‹æ€»ä½“å‡†ç¡®ç‡"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è®¡ç®—æ¨¡å‹æ€»ä½“å‡†ç¡®ç‡&lt;/h1&gt;
&lt;p&gt;æ¨¡å‹åœ¨è®­ç»ƒçš„æ—¶å€™åªä¼šæ˜¾ç¤ºæ¯ä¸€ä¸ªå­—ç¬¦çš„å‡†ç¡®ç‡ï¼Œä¸ºäº†ç»Ÿè®¡æ¨¡å‹çš„æ€»ä½“å‡†ç¡®ç‡ï¼Œæˆ‘ä»¬å¯ä»¥å†™ä¸‹é¢çš„å‡½æ•°ï¼š&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tqdm &lt;span class="pl-k"&gt;import&lt;/span&gt; tqdm
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;evaluate&lt;/span&gt;(&lt;span class="pl-smi"&gt;model&lt;/span&gt;, &lt;span class="pl-smi"&gt;batch_num&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;):
    batch_acc &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;
    &lt;span class="pl-k"&gt;with&lt;/span&gt; tqdm(CaptchaSequence(characters, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;)) &lt;span class="pl-k"&gt;as&lt;/span&gt; pbar:
        &lt;span class="pl-k"&gt;for&lt;/span&gt; X, y &lt;span class="pl-k"&gt;in&lt;/span&gt; pbar:
            y_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict(X)
            y_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; np.argmax(y_pred, &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;).T
            y_true &lt;span class="pl-k"&gt;=&lt;/span&gt; np.argmax(y, &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;).T

            batch_acc &lt;span class="pl-k"&gt;+=&lt;/span&gt; (y_true &lt;span class="pl-k"&gt;==&lt;/span&gt; y_pred).all(&lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;).mean()
    &lt;span class="pl-k"&gt;return&lt;/span&gt; batch_acc &lt;span class="pl-k"&gt;/&lt;/span&gt; batch_num

evaluate(model)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;è¿™é‡Œç”¨åˆ°äº†ä¸€ä¸ªåº“å«åš tqdmï¼Œå®ƒæ˜¯ä¸€ä¸ªè¿›åº¦æ¡çš„åº“ï¼Œä¸ºçš„æ˜¯èƒ½å¤Ÿå®æ—¶åé¦ˆè¿›åº¦ã€‚ç„¶åæˆ‘ä»¬é€šè¿‡ä¸€äº› numpy è®¡ç®—å»ç»Ÿè®¡æˆ‘ä»¬çš„å‡†ç¡®ç‡ï¼Œè¿™é‡Œè®¡ç®—è§„åˆ™æ˜¯åªè¦æœ‰ä¸€ä¸ªé”™ï¼Œé‚£ä¹ˆå°±ä¸ç®—å®ƒå¯¹ã€‚ç»è¿‡è®¡ç®—ï¼Œæˆ‘ä»¬çš„æ¨¡å‹çš„æ€»ä½“å‡†ç¡®ç‡åœ¨ç»è¿‡å……åˆ†è®­ç»ƒä»¥åï¼Œå¯ä»¥è¾¾åˆ° 98.26% çš„æ€»ä½“å‡†ç¡®ç‡ã€‚&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-æ¨¡å‹æ€»ç»“" class="anchor" aria-hidden="true" href="#æ¨¡å‹æ€»ç»“"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ¨¡å‹æ€»ç»“&lt;/h1&gt;
&lt;p&gt;æ¨¡å‹çš„å¤§å°æ˜¯10.7MBï¼Œæ€»ä½“å‡†ç¡®ç‡æ˜¯ 98.26%ï¼ŒåŸºæœ¬ä¸Šå¯ä»¥ç¡®å®šç ´è§£äº†æ­¤ç±»éªŒè¯ç ã€‚&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-æ”¹è¿›" class="anchor" aria-hidden="true" href="#æ”¹è¿›"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ”¹è¿›&lt;/h1&gt;
&lt;p&gt;å¯¹äºè¿™ç§æŒ‰é¡ºåºä¹¦å†™çš„æ–‡å­—ï¼Œæˆ‘ä»¬è¿˜æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥ä½¿ç”¨ï¼Œé‚£å°±æ˜¯å¾ªç¯ç¥ç»ç½‘ç»œæ¥è¯†åˆ«åºåˆ—ã€‚ä¸‹é¢æˆ‘ä»¬æ¥äº†è§£ä¸€ä¸‹å¦‚ä½•ä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œæ¥è¯†åˆ«è¿™ç±»éªŒè¯ç ã€‚&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-ctc-loss" class="anchor" aria-hidden="true" href="#ctc-loss"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CTC Loss&lt;/h1&gt;
&lt;p&gt;è¿™ä¸ª loss æ˜¯ä¸€ä¸ªç‰¹åˆ«ç¥å¥‡çš„ lossï¼Œå®ƒå¯ä»¥åœ¨åªçŸ¥é“åºåˆ—çš„é¡ºåºï¼Œä¸çŸ¥é“å…·ä½“ä½ç½®çš„æƒ…å†µä¸‹ï¼Œè®©æ¨¡å‹æ”¶æ•›ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªéå¸¸å¥½çš„æ–‡ç« ä»‹ç»äº† CTC Loss: &lt;a href="https://distill.pub/2017/ctc/" rel="nofollow"&gt;Sequence Modeling
With CTC&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/deep-speech-ctc-small.png"&gt;&lt;img src="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/deep-speech-ctc-small.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;åœ¨ Keras é‡Œé¢å·²ç»å†…ç½®äº† CTC Loss ï¼Œæˆ‘ä»¬å®ç°ä¸‹é¢çš„ä»£ç å³å¯åœ¨æ¨¡å‹é‡Œä½¿ç”¨ CTC Lossã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;y_pred&lt;/code&gt; æ˜¯æ¨¡å‹çš„è¾“å‡ºï¼Œæ˜¯æŒ‰é¡ºåºè¾“å‡ºçš„37ä¸ªå­—ç¬¦çš„æ¦‚ç‡ï¼Œå› ä¸ºæˆ‘ä»¬è¿™é‡Œç”¨åˆ°äº†å¾ªç¯ç¥ç»ç½‘ç»œï¼Œæ‰€ä»¥éœ€è¦ä¸€ä¸ªç©ºç™½å­—ç¬¦çš„æ¦‚å¿µï¼›&lt;/li&gt;
&lt;li&gt;&lt;code&gt;labels&lt;/code&gt; æ˜¯éªŒè¯ç ï¼Œæ˜¯å››ä¸ªæ•°å­—ï¼Œæ¯ä¸ªæ•°å­—ä»£è¡¨å­—ç¬¦åœ¨å­—ç¬¦é›†é‡Œçš„ä½ç½®&lt;/li&gt;
&lt;li&gt;&lt;code&gt;input_length&lt;/code&gt; è¡¨ç¤º &lt;code&gt;y_pred&lt;/code&gt; çš„é•¿åº¦ï¼Œæˆ‘ä»¬è¿™é‡Œæ˜¯16&lt;/li&gt;
&lt;li&gt;&lt;code&gt;label_length&lt;/code&gt; è¡¨ç¤º &lt;code&gt;labels&lt;/code&gt; çš„é•¿åº¦ï¼Œæˆ‘ä»¬è¿™é‡Œæ˜¯4&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow.keras.backend &lt;span class="pl-k"&gt;as&lt;/span&gt; K

&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;ctc_lambda_func&lt;/span&gt;(&lt;span class="pl-smi"&gt;args&lt;/span&gt;):
    y_pred, labels, input_length, label_length &lt;span class="pl-k"&gt;=&lt;/span&gt; args
    &lt;span class="pl-k"&gt;return&lt;/span&gt; K.ctc_batch_cost(labels, y_pred, input_length, label_length)&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-æ¨¡å‹ç»“æ„" class="anchor" aria-hidden="true" href="#æ¨¡å‹ç»“æ„"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ¨¡å‹ç»“æ„&lt;/h1&gt;
&lt;p&gt;æˆ‘ä»¬çš„æ¨¡å‹ç»“æ„æ˜¯è¿™æ ·è®¾è®¡çš„ï¼Œé¦–å…ˆé€šè¿‡å·ç§¯ç¥ç»ç½‘ç»œå»è¯†åˆ«ç‰¹å¾ï¼Œç„¶åæŒ‰æ°´å¹³é¡ºåºè¾“å…¥åˆ° GRU è¿›è¡Œåºåˆ—å»ºæ¨¡ï¼Œæœ€åä½¿ç”¨ä¸€ä¸ªåˆ†ç±»å™¨å¯¹æ¯ä¸ªæ—¶åˆ»è¾“å‡ºçš„ç‰¹å¾è¿›è¡Œåˆ†ç±»ã€‚&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.models &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;
&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.layers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

input_tensor &lt;span class="pl-k"&gt;=&lt;/span&gt; Input((height, width, &lt;span class="pl-c1"&gt;3&lt;/span&gt;))
x &lt;span class="pl-k"&gt;=&lt;/span&gt; input_tensor
&lt;span class="pl-k"&gt;for&lt;/span&gt; i, n_cnn &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;enumerate&lt;/span&gt;([&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;]):
    &lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(n_cnn):
        x &lt;span class="pl-k"&gt;=&lt;/span&gt; Conv2D(&lt;span class="pl-c1"&gt;32&lt;/span&gt;&lt;span class="pl-k"&gt;*&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;&lt;span class="pl-k"&gt;**&lt;/span&gt;&lt;span class="pl-c1"&gt;min&lt;/span&gt;(i, &lt;span class="pl-c1"&gt;3&lt;/span&gt;), &lt;span class="pl-v"&gt;kernel_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-v"&gt;padding&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;same&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;kernel_initializer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;he_uniform&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)(x)
        x &lt;span class="pl-k"&gt;=&lt;/span&gt; BatchNormalization()(x)
        x &lt;span class="pl-k"&gt;=&lt;/span&gt; Activation(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;relu&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)(x)
    x &lt;span class="pl-k"&gt;=&lt;/span&gt; MaxPooling2D(&lt;span class="pl-c1"&gt;2&lt;/span&gt; &lt;span class="pl-k"&gt;if&lt;/span&gt; i &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;3&lt;/span&gt; &lt;span class="pl-k"&gt;else&lt;/span&gt; (&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;1&lt;/span&gt;))(x)

x &lt;span class="pl-k"&gt;=&lt;/span&gt; Permute((&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;))(x)
x &lt;span class="pl-k"&gt;=&lt;/span&gt; TimeDistributed(Flatten())(x)

rnn_size &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;128&lt;/span&gt;
x &lt;span class="pl-k"&gt;=&lt;/span&gt; Bidirectional(CuDNNGRU(rnn_size, &lt;span class="pl-v"&gt;return_sequences&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;))(x)
x &lt;span class="pl-k"&gt;=&lt;/span&gt; Bidirectional(CuDNNGRU(rnn_size, &lt;span class="pl-v"&gt;return_sequences&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;))(x)
x &lt;span class="pl-k"&gt;=&lt;/span&gt; Dense(n_class, &lt;span class="pl-v"&gt;activation&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;softmax&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)(x)

base_model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(&lt;span class="pl-v"&gt;inputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;input_tensor, &lt;span class="pl-v"&gt;outputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;x)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;ä¸ºäº†è®­ç»ƒè¿™ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬è¿˜éœ€è¦æ­å»ºä¸€ä¸ª loss è®¡ç®—ç½‘ç»œï¼Œä»£ç å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;labels &lt;span class="pl-k"&gt;=&lt;/span&gt; Input(&lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;the_labels&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;shape&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[n_len], &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;float32&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
input_length &lt;span class="pl-k"&gt;=&lt;/span&gt; Input(&lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;input_length&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;shape&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-c1"&gt;1&lt;/span&gt;], &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;int64&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
label_length &lt;span class="pl-k"&gt;=&lt;/span&gt; Input(&lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;label_length&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;shape&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-c1"&gt;1&lt;/span&gt;], &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;int64&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
loss_out &lt;span class="pl-k"&gt;=&lt;/span&gt; Lambda(ctc_lambda_func, &lt;span class="pl-v"&gt;output_shape&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;,), &lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)([x, labels, input_length, label_length])

model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(&lt;span class="pl-v"&gt;inputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[input_tensor, labels, input_length, label_length], &lt;span class="pl-v"&gt;outputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;loss_out)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;çœŸæ­£è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹æ˜¯ &lt;code&gt;base_model&lt;/code&gt;ï¼Œç”±äº Keras çš„é™åˆ¶ï¼Œæˆ‘ä»¬æ²¡åŠæ³•ç›´æ¥ä½¿ç”¨ &lt;code&gt;base_model&lt;/code&gt; æ­å»º CTCLossï¼Œæ‰€ä»¥æˆ‘ä»¬åªèƒ½æŒ‰ç…§ä¸Šé¢çš„æ–¹æ³•ï¼Œè®©æ¨¡å‹ç›´æ¥è¾“å‡º lossã€‚&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-æ¨¡å‹å¯è§†åŒ–-1" class="anchor" aria-hidden="true" href="#æ¨¡å‹å¯è§†åŒ–-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ¨¡å‹å¯è§†åŒ–&lt;/h1&gt;
&lt;p&gt;å¯è§†åŒ–çš„ä»£ç åŒä¸Šï¼Œè¿™é‡Œåªè´´å›¾ã€‚&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="imgs/ctc.png"&gt;&lt;img src="imgs/ctc.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;å¯ä»¥çœ‹åˆ°æ¨¡å‹æ¯”ä¸Šä¸€ä¸ªæ¨¡å‹å¤æ‚äº†è®¸å¤šï¼Œä½†å®é™…ä¸Šåªæ˜¯å› ä¸ºè¾“å…¥æ¯”è¾ƒå¤šï¼Œæ‰€ä»¥å®ƒæ˜¾å¾—å¾ˆå¤§ã€‚&lt;/p&gt;
&lt;p&gt;é¦–å…ˆæ¨¡å‹è¾“å…¥ä¸€ä¸ª &lt;code&gt;(height, width, 3)&lt;/code&gt; ç»´åº¦çš„å›¾ç‰‡ï¼Œç„¶åç»è¿‡ä¸€ç³»åˆ—çš„å±‚é™ç»´åˆ°äº† &lt;code&gt;(2, 16, 256)&lt;/code&gt;ï¼Œä¹‹åæˆ‘ä»¬ä½¿ç”¨ Permute æŠŠ width è½´è°ƒæ•´åˆ°ç¬¬ä¸€ä¸ªç»´åº¦ä»¥é€‚é… RNN çš„è¾“å…¥æ ¼å¼ã€‚è°ƒæ•´ä»¥åçš„ç»´åº¦æ˜¯ &lt;code&gt;(16, 2, 256)&lt;/code&gt;ï¼Œç„¶åä½¿ç”¨ &lt;code&gt;TimeDistributed(Flatten())&lt;/code&gt; æŠŠåä¸¤ä¸ªç»´åº¦å‹æˆä¸€ç»´ï¼Œä¹Ÿå°±æ˜¯ &lt;code&gt;(16, 512)&lt;/code&gt;ï¼Œä¹‹åç»è¿‡ 2 å±‚åŒå‘çš„ GRU å¯¹åºåˆ—æ¨ªå‘å»ºæ¨¡ï¼Œæœ€åç»è¿‡ Dense åˆ†ç±»å™¨è¾“å‡ºæ°´å¹³æ–¹å‘ä¸Šæ¯ä¸ªå­—ç¬¦çš„æ¦‚ç‡åˆ†å¸ƒã€‚&lt;/p&gt;
&lt;p&gt;ä½¿ç”¨ CuDNNGRU æ˜¯å› ä¸ºå®ƒåœ¨ NVIDIA æ˜¾å¡ä¸Šå¯ä»¥åŠ é€Ÿéå¸¸å¤šå€ï¼Œå¦‚æœä½ ä½¿ç”¨çš„æ˜¯ CPUï¼Œæ”¹ä¸º GRU å³å¯ã€‚&lt;/p&gt;
&lt;p&gt;ä½¿ç”¨ RNN çš„åŸå› æ˜¯ï¼Œå¦‚æœä½ çœ‹åˆ°ä¸€å¥è¯æ˜¯ &lt;code&gt;ä»Šå¤©æˆ‘*äº†ä¸€ä¸ªéå¸¸å¥½åƒçš„è‹¹æœ&lt;/code&gt;ï¼Œæœ‰ä¸€ä¸ªå­—çœ‹ä¸æ¸…ï¼Œä½ å¾ˆå®¹æ˜“çŒœåˆ°è¿™ä¸ªå­—æ˜¯â€œåƒâ€ï¼Œä½†æ˜¯ä½¿ç”¨ CNNï¼Œä½ å°±å¾ˆéš¾æœ‰è¿™ä¹ˆå¤§çš„æ„Ÿå—é‡ï¼Œä»è‹¹æœæ¨æµ‹å‡ºå‰é¢çš„å­—æ˜¯åƒã€‚&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-æ•°æ®ç”Ÿæˆå™¨-2" class="anchor" aria-hidden="true" href="#æ•°æ®ç”Ÿæˆå™¨-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ•°æ®ç”Ÿæˆå™¨&lt;/h1&gt;
&lt;p&gt;æ•°æ®ç”Ÿæˆå™¨å’Œ CNN çš„å·®ä¸å¤šï¼Œè¿™é‡Œéœ€è¦å¤šå‡ ä¸ªçŸ©é˜µï¼Œä¸€ä¸ªæ˜¯ input_lengthï¼Œä»£è¡¨åºåˆ—é•¿åº¦ï¼Œä¸€ä¸ªæ˜¯ label_lengthï¼Œä»£è¡¨éªŒè¯ç é•¿åº¦ï¼Œè¿˜æœ‰ä¸€ä¸ª np.onesï¼Œæ²¡æœ‰æ„ä¹‰ï¼Œåªæ˜¯ä¸ºäº†é€‚é… Keras è®­ç»ƒéœ€è¦çš„çŸ©é˜µè¾“å…¥ã€‚&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.utils &lt;span class="pl-k"&gt;import&lt;/span&gt; Sequence

&lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;CaptchaSequence&lt;/span&gt;(&lt;span class="pl-e"&gt;Sequence&lt;/span&gt;):
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__init__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;characters&lt;/span&gt;, &lt;span class="pl-smi"&gt;batch_size&lt;/span&gt;, &lt;span class="pl-smi"&gt;steps&lt;/span&gt;, &lt;span class="pl-smi"&gt;n_len&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-smi"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-smi"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;64&lt;/span&gt;, 
                 &lt;span class="pl-smi"&gt;input_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;16&lt;/span&gt;, &lt;span class="pl-smi"&gt;label_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;):
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.characters &lt;span class="pl-k"&gt;=&lt;/span&gt; characters
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size &lt;span class="pl-k"&gt;=&lt;/span&gt; batch_size
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.steps &lt;span class="pl-k"&gt;=&lt;/span&gt; steps
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_len &lt;span class="pl-k"&gt;=&lt;/span&gt; n_len
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.width &lt;span class="pl-k"&gt;=&lt;/span&gt; width
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.height &lt;span class="pl-k"&gt;=&lt;/span&gt; height
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.input_length &lt;span class="pl-k"&gt;=&lt;/span&gt; input_length
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.label_length &lt;span class="pl-k"&gt;=&lt;/span&gt; label_length
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_class &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;len&lt;/span&gt;(characters)
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.generator &lt;span class="pl-k"&gt;=&lt;/span&gt; ImageCaptcha(&lt;span class="pl-v"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;width, &lt;span class="pl-v"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;height)
    
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__len__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;):
        &lt;span class="pl-k"&gt;return&lt;/span&gt; &lt;span class="pl-c1"&gt;self&lt;/span&gt;.steps

    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__getitem__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;idx&lt;/span&gt;):
        X &lt;span class="pl-k"&gt;=&lt;/span&gt; np.zeros((&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.height, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.width, &lt;span class="pl-c1"&gt;3&lt;/span&gt;), &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.float32)
        y &lt;span class="pl-k"&gt;=&lt;/span&gt; np.zeros((&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size, &lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_len), &lt;span class="pl-v"&gt;dtype&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.uint8)
        input_length &lt;span class="pl-k"&gt;=&lt;/span&gt; np.ones(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size)&lt;span class="pl-k"&gt;*&lt;/span&gt;&lt;span class="pl-c1"&gt;self&lt;/span&gt;.input_length
        label_length &lt;span class="pl-k"&gt;=&lt;/span&gt; np.ones(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size)&lt;span class="pl-k"&gt;*&lt;/span&gt;&lt;span class="pl-c1"&gt;self&lt;/span&gt;.label_length
        &lt;span class="pl-k"&gt;for&lt;/span&gt; i &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size):
            random_str &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([random.choice(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.characters) &lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.n_len)])
            X[i] &lt;span class="pl-k"&gt;=&lt;/span&gt; np.array(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.generator.generate_image(random_str)) &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255.0&lt;/span&gt;
            y[i] &lt;span class="pl-k"&gt;=&lt;/span&gt; [&lt;span class="pl-c1"&gt;self&lt;/span&gt;.characters.find(x) &lt;span class="pl-k"&gt;for&lt;/span&gt; x &lt;span class="pl-k"&gt;in&lt;/span&gt; random_str]
        &lt;span class="pl-k"&gt;return&lt;/span&gt; [X, y, input_length, label_length], np.ones(&lt;span class="pl-c1"&gt;self&lt;/span&gt;.batch_size)&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-è¯„ä¼°æ¨¡å‹" class="anchor" aria-hidden="true" href="#è¯„ä¼°æ¨¡å‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è¯„ä¼°æ¨¡å‹&lt;/h1&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tqdm &lt;span class="pl-k"&gt;import&lt;/span&gt; tqdm

&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;evaluate&lt;/span&gt;(&lt;span class="pl-smi"&gt;model&lt;/span&gt;, &lt;span class="pl-smi"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-smi"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;20&lt;/span&gt;):
    batch_acc &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;
    valid_data &lt;span class="pl-k"&gt;=&lt;/span&gt; CaptchaSequence(characters, batch_size, steps)
    &lt;span class="pl-k"&gt;for&lt;/span&gt; [X_test, y_test, _, _], _ &lt;span class="pl-k"&gt;in&lt;/span&gt; valid_data:
        y_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; base_model.predict(X_test)
        shape &lt;span class="pl-k"&gt;=&lt;/span&gt; y_pred.shape
        out &lt;span class="pl-k"&gt;=&lt;/span&gt; K.get_value(K.ctc_decode(y_pred, &lt;span class="pl-v"&gt;input_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.ones(shape[&lt;span class="pl-c1"&gt;0&lt;/span&gt;])&lt;span class="pl-k"&gt;*&lt;/span&gt;shape[&lt;span class="pl-c1"&gt;1&lt;/span&gt;])[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;0&lt;/span&gt;])[:, :&lt;span class="pl-c1"&gt;4&lt;/span&gt;]
        &lt;span class="pl-k"&gt;if&lt;/span&gt; out.shape[&lt;span class="pl-c1"&gt;1&lt;/span&gt;] &lt;span class="pl-k"&gt;==&lt;/span&gt; &lt;span class="pl-c1"&gt;4&lt;/span&gt;:
            batch_acc &lt;span class="pl-k"&gt;+=&lt;/span&gt; (y_test &lt;span class="pl-k"&gt;==&lt;/span&gt; out).all(&lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;).mean()
    &lt;span class="pl-k"&gt;return&lt;/span&gt; batch_acc &lt;span class="pl-k"&gt;/&lt;/span&gt; steps&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;æˆ‘ä»¬ä¼šé€šè¿‡è¿™ä¸ªå‡½æ•°æ¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå’Œä¸Šé¢çš„è¯„ä¼°æ ‡å‡†ä¸€æ ·ï¼Œåªæœ‰å…¨éƒ¨æ­£ç¡®ï¼Œæˆ‘ä»¬æ‰ç®—é¢„æµ‹æ­£ç¡®ï¼Œä¸­é—´æœ‰ä¸ªå‘ï¼Œå°±æ˜¯æ¨¡å‹æœ€å¼€å§‹è®­ç»ƒçš„æ—¶å€™ï¼Œå¹¶ä¸ä¸€å®šä¼šè¾“å‡ºå››ä¸ªå­—ç¬¦ï¼Œæ‰€ä»¥æˆ‘ä»¬å¦‚æœé‡åˆ°æ‰€æœ‰çš„å­—ç¬¦éƒ½ä¸åˆ°å››ä¸ªçš„æ—¶å€™ï¼Œå°±ä¸è®¡ç®—äº†ï¼Œç›¸å½“äºåŠ 0ï¼Œé‡åˆ°å¤šäº4ä¸ªå­—ç¬¦çš„æ—¶å€™ï¼Œåªå–å‰å››ä¸ªã€‚&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-è¯„ä¼°å›è°ƒ" class="anchor" aria-hidden="true" href="#è¯„ä¼°å›è°ƒ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è¯„ä¼°å›è°ƒ&lt;/h1&gt;
&lt;p&gt;å› ä¸º Keras æ²¡æœ‰é’ˆå¯¹è¿™ç§è¾“å‡ºè®¡ç®—å‡†ç¡®ç‡çš„é€‰é¡¹ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦è‡ªå®šä¹‰ä¸€ä¸ªå›è°ƒå‡½æ•°ï¼Œå®ƒä¼šåœ¨æ¯ä¸€ä»£è®­ç»ƒå®Œæˆçš„æ—¶å€™è®¡ç®—æ¨¡å‹çš„å‡†ç¡®ç‡ã€‚&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.callbacks &lt;span class="pl-k"&gt;import&lt;/span&gt; Callback

&lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;Evaluate&lt;/span&gt;(&lt;span class="pl-e"&gt;Callback&lt;/span&gt;):
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__init__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;):
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.accs &lt;span class="pl-k"&gt;=&lt;/span&gt; []
    
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;on_epoch_end&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;epoch&lt;/span&gt;, &lt;span class="pl-smi"&gt;logs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;None&lt;/span&gt;):
        logs &lt;span class="pl-k"&gt;=&lt;/span&gt; logs &lt;span class="pl-k"&gt;or&lt;/span&gt; {}
        acc &lt;span class="pl-k"&gt;=&lt;/span&gt; evaluate(base_model)
        logs[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;val_acc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; acc
        &lt;span class="pl-c1"&gt;self&lt;/span&gt;.accs.append(acc)
        &lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;f&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-cce"&gt;\n&lt;/span&gt;&lt;span class="pl-s"&gt;acc: &lt;/span&gt;&lt;span class="pl-c1"&gt;{&lt;/span&gt;acc&lt;span class="pl-k"&gt;*&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;&lt;span class="pl-k"&gt;:.4f&lt;/span&gt;&lt;span class="pl-c1"&gt;}&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-è®­ç»ƒæ¨¡å‹-1" class="anchor" aria-hidden="true" href="#è®­ç»ƒæ¨¡å‹-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è®­ç»ƒæ¨¡å‹&lt;/h1&gt;
&lt;p&gt;æˆ‘ä»¬è¿˜æ˜¯æŒ‰ç…§ä¹‹å‰çš„è®­ç»ƒç­–ç•¥ï¼Œå…ˆè®­ç»ƒ 100 ä»£ï¼Œç­‰ loss ä¸é™ä½ä»¥åï¼Œé™ä½å­¦ä¹ ç‡ï¼Œå†è®­ç»ƒ 100 ä»£ï¼Œä»£ç å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.callbacks &lt;span class="pl-k"&gt;import&lt;/span&gt; EarlyStopping, CSVLogger, ModelCheckpoint
&lt;span class="pl-k"&gt;from&lt;/span&gt; tensorflow.keras.optimizers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

train_data &lt;span class="pl-k"&gt;=&lt;/span&gt; CaptchaSequence(characters, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1000&lt;/span&gt;)
valid_data &lt;span class="pl-k"&gt;=&lt;/span&gt; CaptchaSequence(characters, &lt;span class="pl-v"&gt;batch_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;)
callbacks &lt;span class="pl-k"&gt;=&lt;/span&gt; [EarlyStopping(&lt;span class="pl-v"&gt;patience&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;5&lt;/span&gt;), Evaluate(), 
             CSVLogger(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc.csv&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;), ModelCheckpoint(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc_best.h5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;save_best_only&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)]

model.compile(&lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-k"&gt;lambda&lt;/span&gt; &lt;span class="pl-smi"&gt;y_true&lt;/span&gt;, &lt;span class="pl-smi"&gt;y_pred&lt;/span&gt;: y_pred}, &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;Adam(&lt;span class="pl-c1"&gt;1e-3&lt;/span&gt;, &lt;span class="pl-v"&gt;amsgrad&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;))
model.fit_generator(train_data, &lt;span class="pl-v"&gt;epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;validation_data&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;valid_data, &lt;span class="pl-v"&gt;workers&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-v"&gt;use_multiprocessing&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;,
                    &lt;span class="pl-v"&gt;callbacks&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;callbacks)&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;model.load_weights(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc_best.h5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

callbacks &lt;span class="pl-k"&gt;=&lt;/span&gt; [EarlyStopping(&lt;span class="pl-v"&gt;patience&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;5&lt;/span&gt;), Evaluate(), 
             CSVLogger(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc.csv&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;append&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;), ModelCheckpoint(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc_best.h5&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;save_best_only&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)]

model.compile(&lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-k"&gt;lambda&lt;/span&gt; &lt;span class="pl-smi"&gt;y_true&lt;/span&gt;, &lt;span class="pl-smi"&gt;y_pred&lt;/span&gt;: y_pred}, &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;Adam(&lt;span class="pl-c1"&gt;1e-4&lt;/span&gt;, &lt;span class="pl-v"&gt;amsgrad&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;))
model.fit_generator(train_data, &lt;span class="pl-v"&gt;epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;validation_data&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;valid_data, &lt;span class="pl-v"&gt;workers&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-v"&gt;use_multiprocessing&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;,
                    &lt;span class="pl-v"&gt;callbacks&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;callbacks)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="imgs/vis.png"&gt;&lt;img src="imgs/vis.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;å¯ä»¥çœ‹åˆ° loss ä¸€å¼€å§‹ä¸‹é™å¾ˆå¿«ï¼Œåé¢å°±å¾ˆå¹³äº†ï¼Œä½†æ˜¯æˆ‘ä»¬æŠŠåœ¨å¯¹æ•°å°ºåº¦ä¸‹ç»˜åˆ¶ loss å›¾çš„è¯ï¼Œè¿˜æ˜¯èƒ½çœ‹åˆ° loss ä¸€ç›´åœ¨ä¸‹é™çš„ã€‚acc ä¸Šå‡å¾—ä¹Ÿå¾ˆå¿«ï¼Œè™½ç„¶å‰æœŸè®­ç»ƒçš„æ—¶å€™ acc å¾ˆæŠ–åŠ¨ï¼Œä½†æ˜¯åæœŸå­¦ä¹ ç‡é™ä¸‹æ¥ä»¥åå°±ä¸ä¼šå†è·Œä¸‹æ¥äº†ã€‚&lt;/p&gt;
&lt;p&gt;æœ€ç»ˆæ¨¡å‹çš„å‡†ç¡®ç‡è¾¾åˆ°äº† 99.21%ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­çš„å‡†ç¡®ç‡æœ€é«˜è¾¾åˆ°äº† 99.49%ã€‚&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-æµ‹è¯•æ¨¡å‹-1" class="anchor" aria-hidden="true" href="#æµ‹è¯•æ¨¡å‹-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æµ‹è¯•æ¨¡å‹&lt;/h1&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;characters2 &lt;span class="pl-k"&gt;=&lt;/span&gt; characters &lt;span class="pl-k"&gt;+&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt; &lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
[X_test, y_test, _, _], _  &lt;span class="pl-k"&gt;=&lt;/span&gt; data[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
y_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; base_model.predict(X_test)
out &lt;span class="pl-k"&gt;=&lt;/span&gt; K.get_value(K.ctc_decode(y_pred, &lt;span class="pl-v"&gt;input_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.ones(y_pred.shape[&lt;span class="pl-c1"&gt;0&lt;/span&gt;])&lt;span class="pl-k"&gt;*&lt;/span&gt;y_pred.shape[&lt;span class="pl-c1"&gt;1&lt;/span&gt;], )[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;0&lt;/span&gt;])[:, :&lt;span class="pl-c1"&gt;4&lt;/span&gt;]
out &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([characters[x] &lt;span class="pl-k"&gt;for&lt;/span&gt; x &lt;span class="pl-k"&gt;in&lt;/span&gt; out[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]])
y_true &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([characters[x] &lt;span class="pl-k"&gt;for&lt;/span&gt; x &lt;span class="pl-k"&gt;in&lt;/span&gt; y_test[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]])

plt.imshow(X_test[&lt;span class="pl-c1"&gt;0&lt;/span&gt;])
plt.title(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pred:&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;+&lt;/span&gt; &lt;span class="pl-c1"&gt;str&lt;/span&gt;(out) &lt;span class="pl-k"&gt;+&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-cce"&gt;\n&lt;/span&gt;true: &lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;+&lt;/span&gt; &lt;span class="pl-c1"&gt;str&lt;/span&gt;(y_true))

argmax &lt;span class="pl-k"&gt;=&lt;/span&gt; np.argmax(y_pred, &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;)[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
&lt;span class="pl-c1"&gt;list&lt;/span&gt;(&lt;span class="pl-c1"&gt;zip&lt;/span&gt;(argmax, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([characters2[x] &lt;span class="pl-k"&gt;for&lt;/span&gt; x &lt;span class="pl-k"&gt;in&lt;/span&gt; argmax])))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;è¿™é‡Œéšæœºå‡ºæ¥çš„éªŒè¯ç å¾ˆå‰å®³ï¼Œæ˜¯&lt;code&gt;O0OP&lt;/code&gt;ï¼Œä¸è¿‡æ›´å‰å®³çš„æ˜¯æ¨¡å‹è®¤å‡ºæ¥äº†ã€‚&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/O0OP.png"&gt;&lt;img src="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/O0OP.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-æœ‰è¶£çš„é—®é¢˜" class="anchor" aria-hidden="true" href="#æœ‰è¶£çš„é—®é¢˜"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æœ‰è¶£çš„é—®é¢˜&lt;/h1&gt;
&lt;p&gt;æˆ‘åˆç”¨ä¹‹å‰çš„æ¨¡å‹åšäº†ä¸ªæµ‹è¯•ï¼Œå¯¹äº &lt;code&gt;O0O0&lt;/code&gt; è¿™æ ·ä¸§å¿ƒç—…ç‹‚çš„éªŒè¯ç ï¼Œæ¨¡å‹å¶å°”ä¹Ÿèƒ½æ­£ç¡®è¯†åˆ«ï¼Œè¿™è®©æˆ‘éå¸¸æƒŠè®¶ï¼Œå®ƒæ˜¯çœŸçš„èƒ½è¯†åˆ« O ä¸ 0 çš„å·®åˆ«å‘¢ï¼Œè¿˜æ˜¯çŒœå‡ºæ¥çš„å‘¢ï¼Ÿè¿™å¾ˆéš¾è¯´ã€‚&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;generator &lt;span class="pl-k"&gt;=&lt;/span&gt; ImageCaptcha(&lt;span class="pl-v"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;width, &lt;span class="pl-v"&gt;height&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;height)
random_str &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;O0O0&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
X &lt;span class="pl-k"&gt;=&lt;/span&gt; generator.generate_image(random_str)
X &lt;span class="pl-k"&gt;=&lt;/span&gt; np.expand_dims(X, &lt;span class="pl-c1"&gt;0&lt;/span&gt;) &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255.0&lt;/span&gt;

y_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; base_model.predict(X)
out &lt;span class="pl-k"&gt;=&lt;/span&gt; K.get_value(K.ctc_decode(y_pred, &lt;span class="pl-v"&gt;input_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;np.ones(y_pred.shape[&lt;span class="pl-c1"&gt;0&lt;/span&gt;])&lt;span class="pl-k"&gt;*&lt;/span&gt;y_pred.shape[&lt;span class="pl-c1"&gt;1&lt;/span&gt;], )[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;0&lt;/span&gt;])[:, :&lt;span class="pl-c1"&gt;4&lt;/span&gt;]
out &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;.join([characters[x] &lt;span class="pl-k"&gt;for&lt;/span&gt; x &lt;span class="pl-k"&gt;in&lt;/span&gt; out[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]])

plt.title(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;real: &lt;span class="pl-c1"&gt;%s&lt;/span&gt;&lt;span class="pl-cce"&gt;\n&lt;/span&gt;pred:&lt;span class="pl-c1"&gt;%s&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;span class="pl-k"&gt;%&lt;/span&gt;(random_str, out))
plt.imshow(X[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], &lt;span class="pl-v"&gt;cmap&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;gray&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/O0O0.png"&gt;&lt;img src="https://raw.githubusercontent.com/ypwhs/resources/master/captcha/O0O0.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-æ€»ç»“" class="anchor" aria-hidden="true" href="#æ€»ç»“"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ€»ç»“&lt;/h1&gt;
&lt;p&gt;æ¨¡å‹çš„å¤§å°æ˜¯12.8MBï¼Œå‡†ç¡®ç‡è¾¾åˆ°äº†æƒŠäººçš„ 99.21%ï¼Œå³ä½¿è¿ 0 å’Œ O éƒ½èƒ½ç²¾å‡†åŒºåˆ†ï¼Œéå¸¸æˆåŠŸã€‚&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-æ‰©å±•" class="anchor" aria-hidden="true" href="#æ‰©å±•"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ‰©å±•&lt;/h1&gt;
&lt;p&gt;å¦‚æœä½ æ¯”è¾ƒå–œæ¬¢ PyTorchï¼Œå¯ä»¥çœ‹ &lt;a href="ctc_pytorch.ipynb"&gt;ctc_pytorch.ipynb&lt;/a&gt;ï¼Œç²¾åº¦æ›´é«˜ï¼Œè¾¾åˆ°äº† 99.57%ã€‚&lt;/p&gt;
&lt;p&gt;å¦‚æœä½ æƒ³æŸ¥çœ‹æ›´å¤šç»éªŒï¼Œå¯ä»¥çœ‹çœ‹æˆ‘åœ¨ç™¾åº¦äº‘é­…æ—æ·±åº¦å­¦ä¹ åº”ç”¨å¤§èµ›çš„ä»£ç å’Œæ€è·¯ï¼š&lt;a href="https://github.com/ypwhs/baiduyun_deeplearning_competition"&gt;https://github.com/ypwhs/baiduyun_deeplearning_competition&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-å‚è€ƒé“¾æ¥" class="anchor" aria-hidden="true" href="#å‚è€ƒé“¾æ¥"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å‚è€ƒé“¾æ¥&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://keras.io/getting-started/functional-api-guide/" rel="nofollow"&gt;https://keras.io/getting-started/functional-api-guide/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss" rel="nofollow"&gt;https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/keras-team/keras/blob/master/examples/image_ocr.py"&gt;https://github.com/keras-team/keras/blob/master/examples/image_ocr.py&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cs231n.github.io/convolutional-networks/" rel="nofollow"&gt;https://cs231n.github.io/convolutional-networks/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://distill.pub/2017/ctc/" rel="nofollow"&gt;https://distill.pub/2017/ctc/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ypwhs</author><guid isPermaLink="false">https://github.com/ypwhs/captcha_break</guid><pubDate>Sun, 09 Feb 2020 00:25:00 GMT</pubDate></item></channel></rss>