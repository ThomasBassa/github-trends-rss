<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Jupyter Notebook, Today</title><link>https://github.com/trending/jupyter-notebook?since=daily</link><description>The top repositories on GitHub for jupyter-notebook, measured daily</description><pubDate>Sat, 30 Nov 2019 01:04:07 GMT</pubDate><lastBuildDate>Sat, 30 Nov 2019 01:04:07 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>pytorch/vision #1 in Jupyter Notebook, Today</title><link>https://github.com/pytorch/vision</link><description>&lt;p&gt;&lt;i&gt;Datasets, Transforms and Models specific to Computer Vision&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body rst" data-path="README.rst"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;a name="user-content-torchvision"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-torchvision" class="anchor" aria-hidden="true" href="#torchvision"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;torchvision&lt;/h2&gt;
&lt;a href="https://travis-ci.org/pytorch/vision" rel="nofollow"&gt;&lt;img alt="https://travis-ci.org/pytorch/vision.svg?branch=master" src="https://camo.githubusercontent.com/066c54ca32f191cb2a7dff8eb895dae99fa62364/68747470733a2f2f7472617669732d63692e6f72672f7079746f7263682f766973696f6e2e7376673f6272616e63683d6d6173746572" data-canonical-src="https://travis-ci.org/pytorch/vision.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/pytorch/vision" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d206df8ce39b22dbcfcbc8044d7058b8c47bc1b3/68747470733a2f2f636f6465636f762e696f2f67682f7079746f7263682f766973696f6e2f6272616e63682f6d61737465722f67726170682f62616467652e737667" data-canonical-src="https://codecov.io/gh/pytorch/vision/branch/master/graph/badge.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://pepy.tech/project/torchvision" rel="nofollow"&gt;&lt;img alt="https://pepy.tech/badge/torchvision" src="https://camo.githubusercontent.com/a080a02ba27e8ab65f937476759d12f72b9a1c28/68747470733a2f2f706570792e746563682f62616467652f746f726368766973696f6e" data-canonical-src="https://pepy.tech/badge/torchvision" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pytorch.org/docs/stable/torchvision/index.html" rel="nofollow"&gt;&lt;img alt="https://img.shields.io/badge/dynamic/json.svg?label=docs&amp;amp;url=https%3A%2F%2Fpypi.org%2Fpypi%2Ftorchvision%2Fjson&amp;amp;query=%24.info.version&amp;amp;colorB=brightgreen&amp;amp;prefix=v" src="https://camo.githubusercontent.com/891cde72d6784500640b8c547eee3201b233dc8a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e2e7376673f6c6162656c3d646f63732675726c3d6874747073253341253246253246707970692e6f726725324670797069253246746f726368766973696f6e2532466a736f6e2671756572793d2532342e696e666f2e76657273696f6e26636f6c6f72423d627269676874677265656e267072656669783d76" data-canonical-src="https://img.shields.io/badge/dynamic/json.svg?label=docs&amp;amp;url=https%3A%2F%2Fpypi.org%2Fpypi%2Ftorchvision%2Fjson&amp;amp;query=%24.info.version&amp;amp;colorB=brightgreen&amp;amp;prefix=v" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;p&gt;The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.&lt;/p&gt;
&lt;a name="user-content-installation"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;TorchVision requires PyTorch 1.2 or newer.&lt;/p&gt;
&lt;p&gt;Anaconda:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;conda install torchvision -c pytorch&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;pip:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install torchvision&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From source:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python setup.py install
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; or, for OSX&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py install&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By default, GPU support is built if CUDA is found and &lt;code&gt;torch.cuda.is_available()&lt;/code&gt; is true.
It's possible to force building GPU support by setting &lt;code&gt;FORCE_CUDA=1&lt;/code&gt; environment variable,
which is useful when building a docker image.&lt;/p&gt;
&lt;a name="user-content-image-backend"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-image-backend" class="anchor" aria-hidden="true" href="#image-backend"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image Backend&lt;/h2&gt;
&lt;p&gt;Torchvision currently supports the following image backends:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://python-pillow.org/" rel="nofollow"&gt;Pillow&lt;/a&gt; (default)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/uploadcare/pillow-simd"&gt;Pillow-SIMD&lt;/a&gt; - a &lt;strong&gt;much faster&lt;/strong&gt; drop-in replacement for Pillow with SIMD. If installed will be used as the default.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pytorch/accimage"&gt;accimage&lt;/a&gt; - if installed can be activated by calling &lt;code&gt;torchvision.set_image_backend('accimage')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-c-api"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-c-api" class="anchor" aria-hidden="true" href="#c-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;C++ API&lt;/h2&gt;
&lt;p&gt;TorchVision also offers a C++ API that contains C++ equivalent of python models.&lt;/p&gt;
&lt;p&gt;Installation From source:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;mkdir build
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; build
cmake ..
make
make install&lt;/pre&gt;&lt;/div&gt;
&lt;a name="user-content-documentation"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;You can find the API documentation on the pytorch website: &lt;a href="http://pytorch.org/docs/master/torchvision/" rel="nofollow"&gt;http://pytorch.org/docs/master/torchvision/&lt;/a&gt;&lt;/p&gt;
&lt;a name="user-content-contributing"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;We appreciate all contributions. If you are planning to contribute back bug-fixes, please do so without any further discussion. If you plan to contribute new features, utility functions or extensions, please first open an issue and discuss the feature with us.&lt;/p&gt;
&lt;a name="user-content-disclaimer-on-datasets"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-disclaimer-on-datasets" class="anchor" aria-hidden="true" href="#disclaimer-on-datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disclaimer on Datasets&lt;/h2&gt;
&lt;p&gt;This is a utility library that downloads and prepares public datasets. We do not host or distribute these datasets, vouch for their quality or fairness, or claim that you have license to use the dataset. It is your responsibility to determine whether you have permission to use the dataset under the dataset's license.&lt;/p&gt;
&lt;p&gt;If you're a dataset owner and wish to update any part of it (description, citation, etc.), or do not want your dataset to be included in this library, please get in touch through a GitHub issue. Thanks for your contribution to the ML community!&lt;/p&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>pytorch</author><guid isPermaLink="false">https://github.com/pytorch/vision</guid><pubDate>Sat, 30 Nov 2019 00:01:00 GMT</pubDate></item><item><title>neolee/pilot #2 in Jupyter Notebook, Today</title><link>https://github.com/neolee/pilot</link><description>&lt;p&gt;&lt;i&gt;进入编程世界的第一课&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-进入编程世界的第一课" class="anchor" aria-hidden="true" href="#进入编程世界的第一课"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;进入编程世界的第一课&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-更新" class="anchor" aria-hidden="true" href="#更新"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;更新&lt;/h2&gt;
&lt;p&gt;第二阶段课程（S2）已发布， 请阅读 &lt;a href="README-S2.md"&gt;对 S2 课程的说明&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-前言" class="anchor" aria-hidden="true" href="#前言"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;前言&lt;/h2&gt;
&lt;p&gt;这个仓库（&lt;em&gt;repo&lt;/em&gt;）里保存的是&lt;strong&gt;教材&lt;/strong&gt;，也就是需要你阅读和学习的内容。我们另外还有个 &lt;em&gt;repo&lt;/em&gt; 是你的&lt;strong&gt;学习用书&lt;/strong&gt;，我们会在下面告诉你如何使用这两个仓库。&lt;/p&gt;
&lt;p&gt;编程（&lt;em&gt;programming&lt;/em&gt;）并不算是一门&lt;strong&gt;科学&lt;/strong&gt;，更像是一种&lt;strong&gt;手艺&lt;/strong&gt;，里面有科学，有理论有思想，也有经验和体会。学习编程最有效的方法是——赶紧动手开始写程序，如果不自己动手，听再多、再牛的课程讲解也没用。&lt;/p&gt;
&lt;p&gt;在动手写程序的前提下，优秀的课程才能发挥作用——那就是缩短你走弯路的时间，就好像学踢足球或者打高尔夫球，一开始就掌握&lt;strong&gt;正确的姿势&lt;/strong&gt;很重要，之后就能够&lt;strong&gt;事半功倍&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;这门课程就能够发挥这样的作用——但必须你亲手开始编程。&lt;/p&gt;
&lt;p&gt;为了帮助你做到这一点，我们设计了一个学习方案，你的每个学习单元都由 &lt;strong&gt;听课&lt;/strong&gt;、&lt;strong&gt;自学&lt;/strong&gt; 和 &lt;strong&gt;提问&lt;/strong&gt; 三个环节组成。&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-听课" class="anchor" aria-hidden="true" href="#听课"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;听课&lt;/h4&gt;
&lt;p&gt;这部分以讲解原理和思维方法为主，重点在“学会学习的方法（&lt;em&gt;learning to learn&lt;/em&gt;）”和“问题解决的方法（&lt;em&gt;problem solving&lt;/em&gt;）”。&lt;/p&gt;
&lt;p&gt;课程的讲解大致上每周一次，在课程讲解的最后会给大家布置自学任务，就是下面这个环节。&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-自学" class="anchor" aria-hidden="true" href="#自学"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;自学&lt;/h4&gt;
&lt;p&gt;你要通过我们提供的教材和学习用书完成 &lt;strong&gt;自学任务&lt;/strong&gt;。方法很简单：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用下面的课程大纲打开指定章节进行阅读；&lt;/li&gt;
&lt;li&gt;一边读一边在 &lt;strong&gt;学习用书&lt;/strong&gt; 中完成代码的编写和运行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们的教材和学习用书都是用一种叫做 &lt;strong&gt;Jupyter Notebook&lt;/strong&gt; 的格式编写的，这种格式编写的 &lt;em&gt;notebook&lt;/em&gt; 中除了文字，还有&lt;strong&gt;可运行的程序代码&lt;/strong&gt;（！）。&lt;/p&gt;
&lt;p&gt;学习用书和教材的区别只有一个：在学习用书中，所有写着程序代码的格子（&lt;em&gt;cell&lt;/em&gt;）都被清空了，等着你自己动手填进去。&lt;/p&gt;
&lt;p&gt;所以学习用书就好像我们小时候学写字时用的“描红本”，你可以对着教材“描”和“抄”。不要小看了这个“描”和“抄”的过程，无数实践证明，自己输入一遍和光看就是不一样；而且，程序和描字不同，很多时候你可以自己修改一些地方，改的越多你就掌握的越多。&lt;/p&gt;
&lt;p&gt;为了使用 &lt;strong&gt;学习用书&lt;/strong&gt;，你首先需要配置好一个（你可以用一辈子的）编程环境，然后从我们的共享代码仓库获取学习用书并运行，具体来说按照下面的两个指引操作即可：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="x1-setup.md"&gt;编程环境配置指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="x2-students-book.md"&gt;如何使用配套学习用书&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;自学过程中遇到问题是正常的，所以下面这个环节很重要。&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-提问" class="anchor" aria-hidden="true" href="#提问"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;提问&lt;/h4&gt;
&lt;p&gt;我们鼓励大家提问，在学习过程中遇到问题就及时提出来，及时解决。&lt;/p&gt;
&lt;p&gt;万事开头难，一开始快速清障前进，后面就会越来越顺。&lt;/p&gt;
&lt;p&gt;可以使用 GitHub 提供的 Issues 功能来提问，只要访问 &lt;a href="https://github.com/neolee/pilot/issues"&gt;这个页面&lt;/a&gt;，点击右上的 &lt;code&gt;New issue&lt;/code&gt; 绿色按钮即可提出问题，记得选择 &lt;code&gt;question&lt;/code&gt; 这个 &lt;em&gt;label&lt;/em&gt;（如果提的是关于课程教材中的错误或者改进建议可以选择 &lt;code&gt;bug&lt;/code&gt; 或者 &lt;code&gt;enhancement&lt;/code&gt; 这样的 &lt;em&gt;label&lt;/em&gt;）。&lt;/p&gt;
&lt;p&gt;提问是有一些技巧的，经过思考的问题更容易得到靠谱答案。&lt;/p&gt;
&lt;p&gt;关于这个问题，有个近乎标准的答案在网上已经存在很久了，那就是大牛 Eric S. Raymond 2001 年发表在 BBS 上的 &lt;a href="http://www.catb.org/~esr/faqs/smart-questions.html" rel="nofollow"&gt;How To Ask Questions The Smart Way&lt;/a&gt;，这篇文章从发表之后一直在不断更新修订，内容清晰详实，附有丰富的“好问题”和“蠢问题”样例，一看就明白；另有质量很不错的 &lt;a href="https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way/blob/master/README-zh_CN.md"&gt;中文译文&lt;/a&gt;（也是开源的）。请务必仔细阅读，尽量按照里面的建议来思考和组织你的问题。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-课程大纲" class="anchor" aria-hidden="true" href="#课程大纲"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;课程大纲&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-第一部分-基础篇" class="anchor" aria-hidden="true" href="#第一部分-基础篇"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第一部分 基础篇&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="p1-1-understanding-programming-languages.ipynb"&gt;第一章 理解编程语言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p1-2-structure-1.ipynb"&gt;第二章 程序的基本结构（一）：值与变量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p1-3-structure-2.ipynb"&gt;第三章 程序的基本结构（二）：操作符与函数&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p1-4-structure-3.ipynb"&gt;第四章 程序的基本结构（三）：逻辑判断与分支&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p1-5-structure-4.ipynb"&gt;第五章 程序的基本结构（四）：循环&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p1-6-structure-5.ipynb"&gt;第六章 程序的基本结构（五）：异常处理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p1-7-oo-1.ipynb"&gt;第七章 理解对象与类：起源篇&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p1-8-oo-2.ipynb"&gt;第八章 理解对象与类：概念篇&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p1-9-oo-3.ipynb"&gt;第九章 理解对象与类：Python 篇&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p1-a-string.ipynb"&gt;第十章 字符与字符串&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p1-b-final.ipynb"&gt;最十一章 课程练习&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-第二部分-进阶篇" class="anchor" aria-hidden="true" href="#第二部分-进阶篇"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第二部分 进阶篇&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="p2-1-function-def.ipynb"&gt;第一章 函数定义再探&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p2-2-docstrings.ipynb"&gt;第二章 程序中的文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p2-3-modules.ipynb"&gt;第三章 模块&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p2-4-recursion.ipynb"&gt;第四章 递归&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p2-5-functional-1.ipynb"&gt;第五章 函数也是数据：初级篇&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p2-6-string-data.ipynb"&gt;第六章 字符串数据&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p2-7-iterable-iterator.ipynb"&gt;第七章 Iterable 与 Iterator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p2-8-list.ipynb"&gt;第八章 列表&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p2-9-tuple-set-dict.ipynb"&gt;第九章 元组，集合，字典&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p2-a-tree.ipynb"&gt;第十章 树&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p2-b-fsm.ipynb"&gt;第十一章 有限状态机&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p2-c-database.ipynb"&gt;第十二章 数据和数据库&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="p2-d-functional-2.ipynb"&gt;第十三章 函数也是数据：进阶篇&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-附录" class="anchor" aria-hidden="true" href="#附录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;附录&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="x1-setup.md"&gt;编程环境配置指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="x2-students-book.md"&gt;如何使用配套学习用书&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="x3-git-github.ipynb"&gt;Git 与 GitHub 入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="x4-regex.ipynb"&gt;正则表达式入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="x5-mysql-setup.ipynb"&gt;MySQL 配置指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="x6-redis-setup.ipynb"&gt;Redis 配置指南&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-重要的附注" class="anchor" aria-hidden="true" href="#重要的附注"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;重要的附注&lt;/h4&gt;
&lt;p&gt;由于 GitHub 的某些 bug，点击上面的这些链接打开 &lt;em&gt;notebook&lt;/em&gt; 时可能会出现 &lt;code&gt;Sorry, something went wrong. Reload?&lt;/code&gt; 的错误，这时可打开下面的链接，改用 Jupyter Notebook 官方提供的阅读器：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://nbviewer.jupyter.org/github/neolee/pilot/tree/master/" rel="nofollow"&gt;https://nbviewer.jupyter.org/github/neolee/pilot/tree/master/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;ipynb&lt;/code&gt; 后缀的文件就是 &lt;em&gt;notebook&lt;/em&gt; 文件，文件名最开始的数字对应第几章（&lt;code&gt;a&lt;/code&gt; 对应第十章，&lt;code&gt;b&lt;/code&gt; 对应最终章，&lt;code&gt;x&lt;/code&gt; 开头的则是附录）。&lt;/p&gt;
&lt;p&gt;比较推荐的学习方式是，用一个浏览器窗口打开上面列出的课程内容，同时在你自己机器的学生用书目录下运行 &lt;code&gt;jupyter lab&lt;/code&gt;，并在学生用书的对应 &lt;em&gt;notebook&lt;/em&gt; 下自己输入代码尝试。&lt;/p&gt;
&lt;p&gt;具体可参考这个 &lt;a href="https://www.bilibili.com/video/av71399509/" rel="nofollow"&gt;视频指引&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-问题与反馈" class="anchor" aria-hidden="true" href="#问题与反馈"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;问题与反馈&lt;/h2&gt;
&lt;p&gt;如果在学习过程中遇到问题或者发现教材中的错误，可以通过 GitHub 的 Issues 系统提出，这个系统基本上就像一个问答论坛，但它集成了一些功能，让它目的性更强、更容易跟踪问题解决的进度状态。&lt;/p&gt;
&lt;p&gt;访问我们课程教材的 Issues 页面：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://github.com/neolee/pilot/issues"&gt;https://github.com/neolee/pilot/issues&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;点击右上的 &lt;code&gt;New issue&lt;/code&gt; 绿色按钮来提出问题或者反馈，如果是问题请选择 &lt;code&gt;question&lt;/code&gt; 这个 &lt;em&gt;label&lt;/em&gt;，如果是关于教材中的错误或者改进建议可以选择 &lt;code&gt;bug&lt;/code&gt; 或者 &lt;code&gt;enhancement&lt;/code&gt; 这样的 &lt;em&gt;label&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;遇到问题的时候其实也可以到这个 Issues 页面去搜索一下，看看是不是有人提过，得到了怎样的答案；如果没人提过，那就正好可以由你来提出，所有人都会从中获益。&lt;/p&gt;
&lt;p&gt;有些常见或者特别有价值的问题我们会整理出来放到课程项目的 &lt;a href="https://github.com/neolee/pilot/wiki"&gt;Wiki&lt;/a&gt; 中，方便大家查阅。&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>neolee</author><guid isPermaLink="false">https://github.com/neolee/pilot</guid><pubDate>Sat, 30 Nov 2019 00:02:00 GMT</pubDate></item><item><title>ultralytics/yolov3 #3 in Jupyter Notebook, Today</title><link>https://github.com/ultralytics/yolov3</link><description>&lt;p&gt;&lt;i&gt;YOLOv3 in PyTorch &gt; ONNX &gt; CoreML &gt; iOS&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;table&gt;
  &lt;tbody&gt;&lt;tr&gt;
    &lt;td&gt;
      &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/26833433/61591130-f7beea00-abc2-11e9-9dc0-d6abcf41d713.jpg"&gt;&lt;img src="https://user-images.githubusercontent.com/26833433/61591130-f7beea00-abc2-11e9-9dc0-d6abcf41d713.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;/td&gt;
    &lt;td align="center"&gt;
    &lt;a href="https://www.ultralytics.com" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/c7f01c9051691f7f4c6239349b6b55cb5a0871c9/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f756c7472616c79746963732f6c6f676f2f6c6f676f6e616d65313030302e706e67" width="160" data-canonical-src="https://storage.googleapis.com/ultralytics/logo/logoname1000.png" style="max-width:100%;"&gt;&lt;/a&gt;
      &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/26833433/61591093-2b4d4480-abc2-11e9-8b46-d88eb1dabba1.jpg"&gt;&lt;img src="https://user-images.githubusercontent.com/26833433/61591093-2b4d4480-abc2-11e9-8b46-d88eb1dabba1.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
          &lt;a href="https://itunes.apple.com/app/id1452689527" rel="nofollow"&gt;
    &lt;img src="https://user-images.githubusercontent.com/26833433/50044365-9b22ac00-0082-11e9-862f-e77aee7aa7b0.png" width="180" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/26833433/61591100-55066b80-abc2-11e9-9647-52c0e045b288.jpg"&gt;&lt;img src="https://user-images.githubusercontent.com/26833433/61591100-55066b80-abc2-11e9-9647-52c0e045b288.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h1&gt;
&lt;p&gt;This directory contains PyTorch YOLOv3 software developed by Ultralytics LLC, and &lt;strong&gt;is freely available for redistribution under the GPL-3.0 license&lt;/strong&gt;. For more information please visit &lt;a href="https://www.ultralytics.com" rel="nofollow"&gt;https://www.ultralytics.com&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-description" class="anchor" aria-hidden="true" href="#description"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Description&lt;/h1&gt;
&lt;p&gt;The &lt;a href="https://github.com/ultralytics/yolov3"&gt;https://github.com/ultralytics/yolov3&lt;/a&gt; repo contains inference and training code for YOLOv3 in PyTorch. The code works on Linux, MacOS and Windows. Training is done on the COCO dataset by default: &lt;a href="https://cocodataset.org/#home" rel="nofollow"&gt;https://cocodataset.org/#home&lt;/a&gt;. &lt;strong&gt;Credit to Joseph Redmon for YOLO:&lt;/strong&gt; &lt;a href="https://pjreddie.com/darknet/yolo/" rel="nofollow"&gt;https://pjreddie.com/darknet/yolo/&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h1&gt;
&lt;p&gt;Python 3.7 or later with the following &lt;code&gt;pip3 install -U -r requirements.txt&lt;/code&gt; packages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;numpy&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;torch &amp;gt;= 1.1.0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;opencv-python&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tqdm&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-tutorials" class="anchor" aria-hidden="true" href="#tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorials&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ultralytics/yolov3/wiki/GCP-Quickstart"&gt;GCP Quickstart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ultralytics/yolov3/wiki/Example:-Transfer-Learning"&gt;Transfer Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ultralytics/yolov3/wiki/Example:-Train-Single-Image"&gt;Train Single Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ultralytics/yolov3/wiki/Example:-Train-Single-Class"&gt;Train Single Class&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data"&gt;Train Custom Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-jupyter-notebook" class="anchor" aria-hidden="true" href="#jupyter-notebook"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Jupyter Notebook&lt;/h1&gt;
&lt;p&gt;Our Jupyter &lt;a href="https://colab.research.google.com/github/ultralytics/yolov3/blob/master/examples.ipynb" rel="nofollow"&gt;notebook&lt;/a&gt; provides quick training, inference and testing examples.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-training" class="anchor" aria-hidden="true" href="#training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Start Training:&lt;/strong&gt; &lt;code&gt;python3 train.py&lt;/code&gt; to begin training after downloading COCO data with &lt;code&gt;data/get_coco_dataset.sh&lt;/code&gt;. Each epoch trains on 117,263 images from the train and validate COCO sets, and tests on 5000 images from the COCO validate set.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Resume Training:&lt;/strong&gt; &lt;code&gt;python3 train.py --resume&lt;/code&gt; to resume training from &lt;code&gt;weights/last.pt&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Plot Training:&lt;/strong&gt; &lt;code&gt;from utils import utils; utils.plot_results()&lt;/code&gt; plots training results from &lt;code&gt;coco_16img.data&lt;/code&gt;, &lt;code&gt;coco_64img.data&lt;/code&gt;, 2 example datasets available in the &lt;code&gt;data/&lt;/code&gt; folder, which train and test on the first 16 and 64 images of the COCO2014-trainval dataset.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/26833433/63258271-fe9d5300-c27b-11e9-9a15-95038daf4438.png"&gt;&lt;img src="https://user-images.githubusercontent.com/26833433/63258271-fe9d5300-c27b-11e9-9a15-95038daf4438.png" width="900" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-image-augmentation" class="anchor" aria-hidden="true" href="#image-augmentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image Augmentation&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;datasets.py&lt;/code&gt; applies random OpenCV-powered (&lt;a href="https://opencv.org/" rel="nofollow"&gt;https://opencv.org/&lt;/a&gt;) augmentation to the input images in accordance with the following specifications. Augmentation is applied &lt;strong&gt;only&lt;/strong&gt; during training, not during inference. Bounding boxes are automatically tracked and updated with the images. 416 x 416 examples pictured below.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Augmentation&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Translation&lt;/td&gt;
&lt;td&gt;+/- 10% (vertical and horizontal)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Rotation&lt;/td&gt;
&lt;td&gt;+/- 5 degrees&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Shear&lt;/td&gt;
&lt;td&gt;+/- 2 degrees (vertical and horizontal)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Scale&lt;/td&gt;
&lt;td&gt;+/- 10%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Reflection&lt;/td&gt;
&lt;td&gt;50% probability (horizontal-only)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;H&lt;strong&gt;S&lt;/strong&gt;V Saturation&lt;/td&gt;
&lt;td&gt;+/- 50%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HS&lt;strong&gt;V&lt;/strong&gt; Intensity&lt;/td&gt;
&lt;td&gt;+/- 50%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/26833433/66699231-27beea80-ece5-11e9-9cad-bdf9d82c500a.jpg"&gt;&lt;img src="https://user-images.githubusercontent.com/26833433/66699231-27beea80-ece5-11e9-9cad-bdf9d82c500a.jpg" width="900" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-speed" class="anchor" aria-hidden="true" href="#speed"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speed&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://cloud.google.com/deep-learning-vm/" rel="nofollow"&gt;https://cloud.google.com/deep-learning-vm/&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Machine type:&lt;/strong&gt; n1-standard-8 (8 vCPUs, 30 GB memory)&lt;br&gt;
&lt;strong&gt;CPU platform:&lt;/strong&gt; Intel Skylake&lt;br&gt;
&lt;strong&gt;GPUs:&lt;/strong&gt; K80 ($0.20/hr), T4 ($0.35/hr), V100 ($0.83/hr) CUDA with &lt;a href="https://github.com/NVIDIA/apex"&gt;Nvidia Apex&lt;/a&gt; FP16/32&lt;br&gt;
&lt;strong&gt;HDD:&lt;/strong&gt; 100 GB SSD&lt;br&gt;
&lt;strong&gt;Dataset:&lt;/strong&gt; COCO train 2014 (117,263 images)&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;GPUs&lt;/th&gt;
&lt;th&gt;&lt;code&gt;batch_size&lt;/code&gt;&lt;/th&gt;
&lt;th&gt;images/sec&lt;/th&gt;
&lt;th&gt;epoch time&lt;/th&gt;
&lt;th&gt;epoch cost&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;K80&lt;/td&gt;
&lt;td&gt;64 (32x2)&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;175 min&lt;/td&gt;
&lt;td&gt;$0.58&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;T4&lt;/td&gt;
&lt;td&gt;64 (32x2)&lt;/td&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;49 min&lt;/td&gt;
&lt;td&gt;$0.29&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;T4 x2&lt;/td&gt;
&lt;td&gt;64 (64x1)&lt;/td&gt;
&lt;td&gt;61&lt;/td&gt;
&lt;td&gt;32 min&lt;/td&gt;
&lt;td&gt;$0.36&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;V100&lt;/td&gt;
&lt;td&gt;64 (32x2)&lt;/td&gt;
&lt;td&gt;115&lt;/td&gt;
&lt;td&gt;17 min&lt;/td&gt;
&lt;td&gt;$0.24&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;V100 x2&lt;/td&gt;
&lt;td&gt;64 (64x1)&lt;/td&gt;
&lt;td&gt;150&lt;/td&gt;
&lt;td&gt;13 min&lt;/td&gt;
&lt;td&gt;$0.36&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2080Ti&lt;/td&gt;
&lt;td&gt;64 (32x2)&lt;/td&gt;
&lt;td&gt;81&lt;/td&gt;
&lt;td&gt;24 min&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2080Ti x2&lt;/td&gt;
&lt;td&gt;64 (64x1)&lt;/td&gt;
&lt;td&gt;140&lt;/td&gt;
&lt;td&gt;14 min&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-inference" class="anchor" aria-hidden="true" href="#inference"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Inference&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;detect.py&lt;/code&gt; runs inference on any sources:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python3 detect.py --source ...&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Image:  &lt;code&gt;--source file.jpg&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Video:  &lt;code&gt;--source file.mp4&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Directory:  &lt;code&gt;--source dir/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Webcam:  &lt;code&gt;--source 0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;RTSP stream:  &lt;code&gt;--source rtsp://170.93.143.139/rtplive/470011e600ef003a004ee33696235daa&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;HTTP stream:  &lt;code&gt;--source http://wmccpinetop.axiscam.net/mjpg/video.mjpg&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To run a specific models:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;YOLOv3:&lt;/strong&gt; &lt;code&gt;python3 detect.py --cfg cfg/yolov3.cfg --weights weights/yolov3.weights&lt;/code&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/26833433/64067835-51d5b500-cc2f-11e9-982e-843f7f9a6ea2.jpg"&gt;&lt;img src="https://user-images.githubusercontent.com/26833433/64067835-51d5b500-cc2f-11e9-982e-843f7f9a6ea2.jpg" width="500" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;YOLOv3-tiny:&lt;/strong&gt; &lt;code&gt;python3 detect.py --cfg cfg/yolov3-tiny.cfg --weights weights/yolov3-tiny.weights&lt;/code&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/26833433/64067834-51d5b500-cc2f-11e9-9357-c485b159a20b.jpg"&gt;&lt;img src="https://user-images.githubusercontent.com/26833433/64067834-51d5b500-cc2f-11e9-9357-c485b159a20b.jpg" width="500" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;YOLOv3-SPP:&lt;/strong&gt; &lt;code&gt;python3 detect.py --cfg cfg/yolov3-spp.cfg --weights weights/yolov3-spp.weights&lt;/code&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/26833433/64067833-51d5b500-cc2f-11e9-8208-6fe197809131.jpg"&gt;&lt;img src="https://user-images.githubusercontent.com/26833433/64067833-51d5b500-cc2f-11e9-8208-6fe197809131.jpg" width="500" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-pretrained-weights" class="anchor" aria-hidden="true" href="#pretrained-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pretrained Weights&lt;/h1&gt;
&lt;p&gt;Download from: &lt;a href="https://drive.google.com/open?id=1LezFG5g3BCW6iYaV89B2i64cqEUZD7e0" rel="nofollow"&gt;https://drive.google.com/open?id=1LezFG5g3BCW6iYaV89B2i64cqEUZD7e0&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-darknet-conversion" class="anchor" aria-hidden="true" href="#darknet-conversion"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Darknet Conversion&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ git clone https://github.com/ultralytics/yolov3 &lt;span class="pl-k"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="pl-c1"&gt;cd&lt;/span&gt; yolov3

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; convert darknet cfg/weights to pytorch model&lt;/span&gt;
$ python3  -c &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;from models import *; convert('cfg/yolov3-spp.cfg', 'weights/yolov3-spp.weights')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
Success: converted &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;weights/yolov3-spp.weights&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; to &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;converted.pt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; convert cfg/pytorch model to darknet weights&lt;/span&gt;
$ python3  -c &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;from models import *; convert('cfg/yolov3-spp.cfg', 'weights/yolov3-spp.pt')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
Success: converted &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;weights/yolov3-spp.pt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; to &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;converted.weights&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-map" class="anchor" aria-hidden="true" href="#map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;mAP&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;test.py --weights weights/yolov3.weights&lt;/code&gt; tests official YOLOv3 weights.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;test.py --weights weights/last.pt&lt;/code&gt; tests latest checkpoint.&lt;/li&gt;
&lt;li&gt;mAPs on COCO2014 using pycocotools.&lt;/li&gt;
&lt;li&gt;mAP@0.5 run at &lt;code&gt;--nms-thres 0.5&lt;/code&gt;, mAP@0.5...0.95 run at &lt;code&gt;--nms-thres 0.7&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;YOLOv3-SPP ultralytics is &lt;code&gt;ultralytics68.pt&lt;/code&gt; with &lt;code&gt;yolov3-spp.cfg&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Darknet results published in &lt;a href="https://arxiv.org/abs/1804.02767" rel="nofollow"&gt;https://arxiv.org/abs/1804.02767&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;i&gt;&lt;/i&gt;&lt;/th&gt;
&lt;th&gt;img-size&lt;/th&gt;
&lt;th&gt;COCO mAP&lt;br&gt;@0.5...0.95&lt;/th&gt;
&lt;th&gt;COCO mAP&lt;br&gt;@0.5&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;YOLOv3-tiny&lt;br&gt;YOLOv3&lt;br&gt;YOLOv3-SPP&lt;br&gt;&lt;strong&gt;YOLOv3-SPP ultralytics&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;320&lt;/td&gt;
&lt;td&gt;14.0&lt;br&gt;28.7&lt;br&gt;30.5&lt;br&gt;&lt;strong&gt;35.4&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;29.0&lt;br&gt;51.5&lt;br&gt;52.3&lt;br&gt;&lt;strong&gt;54.3&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;YOLOv3-tiny&lt;br&gt;YOLOv3&lt;br&gt;YOLOv3-SPP&lt;br&gt;&lt;strong&gt;YOLOv3-SPP ultralytics&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;416&lt;/td&gt;
&lt;td&gt;16.0&lt;br&gt;31.1&lt;br&gt;33.9&lt;br&gt;&lt;strong&gt;39.0&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;32.9&lt;br&gt;55.3&lt;br&gt;56.8&lt;br&gt;&lt;strong&gt;59.2&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;YOLOv3-tiny&lt;br&gt;YOLOv3&lt;br&gt;YOLOv3-SPP&lt;br&gt;&lt;strong&gt;YOLOv3-SPP ultralytics&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;608&lt;/td&gt;
&lt;td&gt;16.6&lt;br&gt;33.0&lt;br&gt;37.0&lt;br&gt;&lt;strong&gt;40.7&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;35.5&lt;br&gt;57.9&lt;br&gt;60.6&lt;br&gt;&lt;strong&gt;60.7&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ python3 test.py --save-json --img-size 608 --nms-thres 0.65 --weights ultralytics68.pt
Namespace(batch_size=16, cfg=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;cfg/yolov3-spp.cfg&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, conf_thres=0.001, data=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;data/coco.data&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, device=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, img_size=608, iou_thres=0.5, nms_thres=0.65, save_json=True, weights=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ultralytics68.pt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
Using CUDA device0 _CudaDeviceProperties(name=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Tesla T4&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, total_memory=15079MB)

               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 313/313 [06:&lt;span class="pl-k"&gt;52&amp;lt;&lt;/span&gt;00:00,  1.24it/s]
                 all     5e+03  3.58e+04     0.107     0.779      0.59     0.182
 Average Precision  (AP) @[ IoU&lt;span class="pl-k"&gt;=&lt;/span&gt;0.50:0.95 &lt;span class="pl-k"&gt;|&lt;/span&gt; area&lt;span class="pl-k"&gt;=&lt;/span&gt;   all &lt;span class="pl-k"&gt;|&lt;/span&gt; maxDets&lt;span class="pl-k"&gt;=&lt;/span&gt;100 ] = 0.404 &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;---
 Average Precision  (AP) @[ IoU&lt;span class="pl-k"&gt;=&lt;/span&gt;0.50      &lt;span class="pl-k"&gt;|&lt;/span&gt; area&lt;span class="pl-k"&gt;=&lt;/span&gt;   all &lt;span class="pl-k"&gt;|&lt;/span&gt; maxDets&lt;span class="pl-k"&gt;=&lt;/span&gt;100 ] = 0.597 &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt;---
 Average Precision  (AP) @[ IoU&lt;span class="pl-k"&gt;=&lt;/span&gt;0.75      &lt;span class="pl-k"&gt;|&lt;/span&gt; area&lt;span class="pl-k"&gt;=&lt;/span&gt;   all &lt;span class="pl-k"&gt;|&lt;/span&gt; maxDets&lt;span class="pl-k"&gt;=&lt;/span&gt;100 ] = 0.438
 Average Precision  (AP) @[ IoU&lt;span class="pl-k"&gt;=&lt;/span&gt;0.50:0.95 &lt;span class="pl-k"&gt;|&lt;/span&gt; area&lt;span class="pl-k"&gt;=&lt;/span&gt; small &lt;span class="pl-k"&gt;|&lt;/span&gt; maxDets&lt;span class="pl-k"&gt;=&lt;/span&gt;100 ] = 0.241
 Average Precision  (AP) @[ IoU&lt;span class="pl-k"&gt;=&lt;/span&gt;0.50:0.95 &lt;span class="pl-k"&gt;|&lt;/span&gt; area&lt;span class="pl-k"&gt;=&lt;/span&gt;medium &lt;span class="pl-k"&gt;|&lt;/span&gt; maxDets&lt;span class="pl-k"&gt;=&lt;/span&gt;100 ] = 0.444
 Average Precision  (AP) @[ IoU&lt;span class="pl-k"&gt;=&lt;/span&gt;0.50:0.95 &lt;span class="pl-k"&gt;|&lt;/span&gt; area&lt;span class="pl-k"&gt;=&lt;/span&gt; large &lt;span class="pl-k"&gt;|&lt;/span&gt; maxDets&lt;span class="pl-k"&gt;=&lt;/span&gt;100 ] = 0.511
 Average Recall     (AR) @[ IoU&lt;span class="pl-k"&gt;=&lt;/span&gt;0.50:0.95 &lt;span class="pl-k"&gt;|&lt;/span&gt; area&lt;span class="pl-k"&gt;=&lt;/span&gt;   all &lt;span class="pl-k"&gt;|&lt;/span&gt; maxDets&lt;span class="pl-k"&gt;=&lt;/span&gt;  1 ] = 0.326
 Average Recall     (AR) @[ IoU&lt;span class="pl-k"&gt;=&lt;/span&gt;0.50:0.95 &lt;span class="pl-k"&gt;|&lt;/span&gt; area&lt;span class="pl-k"&gt;=&lt;/span&gt;   all &lt;span class="pl-k"&gt;|&lt;/span&gt; maxDets&lt;span class="pl-k"&gt;=&lt;/span&gt; 10 ] = 0.533
 Average Recall     (AR) @[ IoU&lt;span class="pl-k"&gt;=&lt;/span&gt;0.50:0.95 &lt;span class="pl-k"&gt;|&lt;/span&gt; area&lt;span class="pl-k"&gt;=&lt;/span&gt;   all &lt;span class="pl-k"&gt;|&lt;/span&gt; maxDets&lt;span class="pl-k"&gt;=&lt;/span&gt;100 ] = 0.570
 Average Recall     (AR) @[ IoU&lt;span class="pl-k"&gt;=&lt;/span&gt;0.50:0.95 &lt;span class="pl-k"&gt;|&lt;/span&gt; area&lt;span class="pl-k"&gt;=&lt;/span&gt; small &lt;span class="pl-k"&gt;|&lt;/span&gt; maxDets&lt;span class="pl-k"&gt;=&lt;/span&gt;100 ] = 0.393
 Average Recall     (AR) @[ IoU&lt;span class="pl-k"&gt;=&lt;/span&gt;0.50:0.95 &lt;span class="pl-k"&gt;|&lt;/span&gt; area&lt;span class="pl-k"&gt;=&lt;/span&gt;medium &lt;span class="pl-k"&gt;|&lt;/span&gt; maxDets&lt;span class="pl-k"&gt;=&lt;/span&gt;100 ] = 0.614
 Average Recall     (AR) @[ IoU&lt;span class="pl-k"&gt;=&lt;/span&gt;0.50:0.95 &lt;span class="pl-k"&gt;|&lt;/span&gt; area&lt;span class="pl-k"&gt;=&lt;/span&gt; large &lt;span class="pl-k"&gt;|&lt;/span&gt; maxDets&lt;span class="pl-k"&gt;=&lt;/span&gt;100 ] = 0.691&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://zenodo.org/badge/latestdoi/146165888" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/cd760a8900fd4be0105229509d566b7c9499ef8d/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3134363136353838382e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/146165888.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h1&gt;
&lt;p&gt;Issues should be raised directly in the repository. For additional questions or comments please email Glenn Jocher at &lt;a href="mailto:glenn.jocher@ultralytics.com"&gt;glenn.jocher@ultralytics.com&lt;/a&gt; or visit us at &lt;a href="https://contact.ultralytics.com" rel="nofollow"&gt;https://contact.ultralytics.com&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ultralytics</author><guid isPermaLink="false">https://github.com/ultralytics/yolov3</guid><pubDate>Sat, 30 Nov 2019 00:03:00 GMT</pubDate></item><item><title>trekhleb/homemade-machine-learning #4 in Jupyter Notebook, Today</title><link>https://github.com/trekhleb/homemade-machine-learning</link><description>&lt;p&gt;&lt;i&gt;🤖 Python examples of popular machine learning algorithms with interactive Jupyter demos and math being explained&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-homemade-machine-learning" class="anchor" aria-hidden="true" href="#homemade-machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Homemade Machine Learning&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://mybinder.org/v2/gh/trekhleb/homemade-machine-learning/master?filepath=notebooks" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/483bae47a175c24dfbfc57390edd8b6982ac5fb3/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge_logo.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.org/trekhleb/homemade-machine-learning" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ec56d7f6b55050cd6e8ee599c29b1436223ebebc/68747470733a2f2f7472617669732d63692e6f72672f7472656b686c65622f686f6d656d6164652d6d616368696e652d6c6561726e696e672e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/trekhleb/homemade-machine-learning.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;For Octave/MatLab version of this repository please check &lt;a href="https://github.com/trekhleb/machine-learning-octave"&gt;machine-learning-octave&lt;/a&gt; project.&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This repository contains examples of popular machine learning algorithms implemented in &lt;strong&gt;Python&lt;/strong&gt; with mathematics behind them being explained. Each algorithm has interactive &lt;strong&gt;Jupyter Notebook&lt;/strong&gt; demo that allows you to play with training data, algorithms configurations and immediately see the results, charts and predictions &lt;strong&gt;right in your browser&lt;/strong&gt;. In most cases the explanations are based on &lt;a href="https://www.coursera.org/learn/machine-learning" rel="nofollow"&gt;this great machine learning course&lt;/a&gt; by Andrew Ng.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The purpose of this repository is &lt;em&gt;not&lt;/em&gt; to implement machine learning algorithms by using 3&lt;sup&gt;rd&lt;/sup&gt; party library one-liners &lt;em&gt;but&lt;/em&gt; rather to practice implementing these algorithms from scratch and get better understanding of the mathematics behind each algorithm. That's why all algorithms implementations are called "homemade" and not intended to be used for production.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-supervised-learning" class="anchor" aria-hidden="true" href="#supervised-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Supervised Learning&lt;/h2&gt;
&lt;p&gt;In supervised learning we have a set of training data as an input and a set of labels or "correct answers" for each training set as an output. Then we're training our model (machine learning algorithm parameters) to map the input to the output correctly (to do correct prediction). The ultimate purpose is to find such model parameters that will successfully continue correct &lt;em&gt;input→output&lt;/em&gt; mapping (predictions) even for new input examples.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-regression" class="anchor" aria-hidden="true" href="#regression"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Regression&lt;/h3&gt;
&lt;p&gt;In regression problems we do real value predictions. Basically we try to draw a line/plane/n-dimensional plane along the training examples.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Usage examples: stock price forecast, sales analysis, dependency of any number, etc.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content--linear-regression" class="anchor" aria-hidden="true" href="#-linear-regression"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="robot" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f916.png"&gt;🤖&lt;/g-emoji&gt; Linear Regression&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="green_book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d7.png"&gt;📗&lt;/g-emoji&gt; &lt;a href="homemade/linear_regression"&gt;Math | Linear Regression&lt;/a&gt; - theory and links for further readings&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="gear" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2699.png"&gt;⚙️&lt;/g-emoji&gt; &lt;a href="homemade/linear_regression/linear_regression.py"&gt;Code | Linear Regression&lt;/a&gt; - implementation example&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="arrow_forward" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/25b6.png"&gt;▶️&lt;/g-emoji&gt; &lt;a href="https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/univariate_linear_regression_demo.ipynb" rel="nofollow"&gt;Demo | Univariate Linear Regression&lt;/a&gt; - predict &lt;code&gt;country happiness&lt;/code&gt; score by &lt;code&gt;economy GDP&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="arrow_forward" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/25b6.png"&gt;▶️&lt;/g-emoji&gt; &lt;a href="https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/multivariate_linear_regression_demo.ipynb" rel="nofollow"&gt;Demo | Multivariate Linear Regression&lt;/a&gt; - predict &lt;code&gt;country happiness&lt;/code&gt; score by &lt;code&gt;economy GDP&lt;/code&gt; and &lt;code&gt;freedom index&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="arrow_forward" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/25b6.png"&gt;▶️&lt;/g-emoji&gt; &lt;a href="https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/non_linear_regression_demo.ipynb" rel="nofollow"&gt;Demo | Non-linear Regression&lt;/a&gt; - use linear regression with &lt;em&gt;polynomial&lt;/em&gt; and &lt;em&gt;sinusoid&lt;/em&gt; features to predict non-linear dependencies&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-classification" class="anchor" aria-hidden="true" href="#classification"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Classification&lt;/h3&gt;
&lt;p&gt;In classification problems we split input examples by certain characteristic.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Usage examples: spam-filters, language detection, finding similar documents, handwritten letters recognition, etc.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content--logistic-regression" class="anchor" aria-hidden="true" href="#-logistic-regression"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="robot" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f916.png"&gt;🤖&lt;/g-emoji&gt; Logistic Regression&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="green_book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d7.png"&gt;📗&lt;/g-emoji&gt; &lt;a href="homemade/logistic_regression"&gt;Math | Logistic Regression&lt;/a&gt; - theory and links for further readings&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="gear" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2699.png"&gt;⚙️&lt;/g-emoji&gt; &lt;a href="homemade/logistic_regression/logistic_regression.py"&gt;Code | Logistic Regression&lt;/a&gt; - implementation example&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="arrow_forward" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/25b6.png"&gt;▶️&lt;/g-emoji&gt; &lt;a href="https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_linear_boundary_demo.ipynb" rel="nofollow"&gt;Demo | Logistic Regression (Linear Boundary)&lt;/a&gt; - predict Iris flower &lt;code&gt;class&lt;/code&gt; based on &lt;code&gt;petal_length&lt;/code&gt; and &lt;code&gt;petal_width&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="arrow_forward" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/25b6.png"&gt;▶️&lt;/g-emoji&gt; &lt;a href="https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_non_linear_boundary_demo.ipynb" rel="nofollow"&gt;Demo | Logistic Regression (Non-Linear Boundary)&lt;/a&gt; - predict microchip &lt;code&gt;validity&lt;/code&gt; based on &lt;code&gt;param_1&lt;/code&gt; and &lt;code&gt;param_2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="arrow_forward" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/25b6.png"&gt;▶️&lt;/g-emoji&gt; &lt;a href="https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/multivariate_logistic_regression_demo.ipynb" rel="nofollow"&gt;Demo | Multivariate Logistic Regression | MNIST&lt;/a&gt; - recognize handwritten digits from &lt;code&gt;28x28&lt;/code&gt; pixel images&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="arrow_forward" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/25b6.png"&gt;▶️&lt;/g-emoji&gt; &lt;a href="https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/multivariate_logistic_regression_fashion_demo.ipynb" rel="nofollow"&gt;Demo | Multivariate Logistic Regression | Fashion MNIST&lt;/a&gt; - recognize clothes types from &lt;code&gt;28x28&lt;/code&gt; pixel images&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-unsupervised-learning" class="anchor" aria-hidden="true" href="#unsupervised-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Unsupervised Learning&lt;/h2&gt;
&lt;p&gt;Unsupervised learning is a branch of machine learning that learns from test data that has not been labeled, classified or categorized. Instead of responding to feedback, unsupervised learning identifies commonalities in the data and reacts based on the presence or absence of such commonalities in each new piece of data.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-clustering" class="anchor" aria-hidden="true" href="#clustering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Clustering&lt;/h3&gt;
&lt;p&gt;In clustering problems we split the training examples by unknown characteristics. The algorithm itself decides what characteristic to use for splitting.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Usage examples: market segmentation, social networks analysis, organize computing clusters, astronomical data analysis, image compression, etc.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content--k-means-algorithm" class="anchor" aria-hidden="true" href="#-k-means-algorithm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="robot" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f916.png"&gt;🤖&lt;/g-emoji&gt; K-means Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="green_book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d7.png"&gt;📗&lt;/g-emoji&gt; &lt;a href="homemade/k_means"&gt;Math | K-means Algorithm&lt;/a&gt; - theory and links for further readings&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="gear" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2699.png"&gt;⚙️&lt;/g-emoji&gt; &lt;a href="homemade/k_means/k_means.py"&gt;Code | K-means Algorithm&lt;/a&gt; - implementation example&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="arrow_forward" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/25b6.png"&gt;▶️&lt;/g-emoji&gt; &lt;a href="https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/k_means/k_means_demo.ipynb" rel="nofollow"&gt;Demo | K-means Algorithm&lt;/a&gt; - split Iris flowers into clusters based on &lt;code&gt;petal_length&lt;/code&gt; and &lt;code&gt;petal_width&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-anomaly-detection" class="anchor" aria-hidden="true" href="#anomaly-detection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Anomaly Detection&lt;/h3&gt;
&lt;p&gt;Anomaly detection (also outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Usage examples: intrusion detection, fraud detection, system health monitoring, removing anomalous data from the dataset etc.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content--anomaly-detection-using-gaussian-distribution" class="anchor" aria-hidden="true" href="#-anomaly-detection-using-gaussian-distribution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="robot" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f916.png"&gt;🤖&lt;/g-emoji&gt; Anomaly Detection using Gaussian Distribution&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="green_book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d7.png"&gt;📗&lt;/g-emoji&gt; &lt;a href="homemade/anomaly_detection"&gt;Math | Anomaly Detection using Gaussian Distribution&lt;/a&gt; - theory and links for further readings&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="gear" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2699.png"&gt;⚙️&lt;/g-emoji&gt; &lt;a href="homemade/anomaly_detection/gaussian_anomaly_detection.py"&gt;Code | Anomaly Detection using Gaussian Distribution&lt;/a&gt; - implementation example&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="arrow_forward" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/25b6.png"&gt;▶️&lt;/g-emoji&gt; &lt;a href="https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/anomaly_detection/anomaly_detection_gaussian_demo.ipynb" rel="nofollow"&gt;Demo | Anomaly Detection&lt;/a&gt; - find anomalies in server operational parameters like &lt;code&gt;latency&lt;/code&gt; and &lt;code&gt;threshold&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-neural-network-nn" class="anchor" aria-hidden="true" href="#neural-network-nn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Neural Network (NN)&lt;/h2&gt;
&lt;p&gt;The neural network itself isn't an algorithm, but rather a framework for many different machine learning algorithms to work together and process complex data inputs.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Usage examples: as a substitute of all other algorithms in general, image recognition, voice recognition, image processing (applying specific style), language translation, etc.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content--multilayer-perceptron-mlp" class="anchor" aria-hidden="true" href="#-multilayer-perceptron-mlp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="robot" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f916.png"&gt;🤖&lt;/g-emoji&gt; Multilayer Perceptron (MLP)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="green_book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d7.png"&gt;📗&lt;/g-emoji&gt; &lt;a href="homemade/neural_network"&gt;Math | Multilayer Perceptron&lt;/a&gt; - theory and links for further readings&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="gear" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2699.png"&gt;⚙️&lt;/g-emoji&gt; &lt;a href="homemade/neural_network/multilayer_perceptron.py"&gt;Code | Multilayer Perceptron&lt;/a&gt; - implementation example&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="arrow_forward" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/25b6.png"&gt;▶️&lt;/g-emoji&gt; &lt;a href="https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/neural_network/multilayer_perceptron_demo.ipynb" rel="nofollow"&gt;Demo | Multilayer Perceptron | MNIST&lt;/a&gt; - recognize handwritten digits from &lt;code&gt;28x28&lt;/code&gt; pixel images&lt;/li&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="arrow_forward" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/25b6.png"&gt;▶️&lt;/g-emoji&gt; &lt;a href="https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/neural_network/multilayer_perceptron_fashion_demo.ipynb" rel="nofollow"&gt;Demo | Multilayer Perceptron | Fashion MNIST&lt;/a&gt; - recognize the type of clothes from &lt;code&gt;28x28&lt;/code&gt; pixel images&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-machine-learning-map" class="anchor" aria-hidden="true" href="#machine-learning-map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning Map&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/machine-learning-map.png"&gt;&lt;img src="images/machine-learning-map.png" alt="Machine Learning Map" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The source of the following machine learning topics map is &lt;a href="https://vas3k.ru/blog/machine_learning/" rel="nofollow"&gt;this wonderful blog post&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prerequisites&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-installing-python" class="anchor" aria-hidden="true" href="#installing-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing Python&lt;/h4&gt;
&lt;p&gt;Make sure that you have &lt;a href="https://realpython.com/installing-python/" rel="nofollow"&gt;Python installed&lt;/a&gt; on your machine.&lt;/p&gt;
&lt;p&gt;You might want to use &lt;a href="https://docs.python.org/3/library/venv.html" rel="nofollow"&gt;venv&lt;/a&gt; standard Python library
to create virtual environments and have Python, &lt;code&gt;pip&lt;/code&gt; and all dependent packages to be installed and
served from the local project directory to avoid messing with system wide packages and their
versions.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-installing-dependencies" class="anchor" aria-hidden="true" href="#installing-dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing Dependencies&lt;/h4&gt;
&lt;p&gt;Install all dependencies that are required for the project by running:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install -r requirements.txt&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-launching-jupyter-locally" class="anchor" aria-hidden="true" href="#launching-jupyter-locally"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Launching Jupyter Locally&lt;/h4&gt;
&lt;p&gt;All demos in the project may be run directly in your browser without installing Jupyter locally. But if you want to launch &lt;a href="http://jupyter.org/" rel="nofollow"&gt;Jupyter Notebook&lt;/a&gt; locally you may do it by running the following command from the root folder of the project:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;jupyter notebook&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After this Jupyter Notebook will be accessible by &lt;code&gt;http://localhost:8888&lt;/code&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-launching-jupyter-remotely" class="anchor" aria-hidden="true" href="#launching-jupyter-remotely"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Launching Jupyter Remotely&lt;/h4&gt;
&lt;p&gt;Each algorithm section contains demo links to &lt;a href="http://nbviewer.jupyter.org/" rel="nofollow"&gt;Jupyter NBViewer&lt;/a&gt;. This is fast online previewer for Jupyter notebooks where you may see demo code, charts and data right in your browser without installing anything locally. In case if you want to &lt;em&gt;change&lt;/em&gt; the code and &lt;em&gt;experiment&lt;/em&gt; with demo notebook you need to launch the notebook in &lt;a href="https://mybinder.org/" rel="nofollow"&gt;Binder&lt;/a&gt;. You may do it by simply clicking the &lt;em&gt;"Execute on Binder"&lt;/em&gt; link in top right corner of the NBViewer.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./images/binder-button-place.png"&gt;&lt;img src="./images/binder-button-place.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-datasets" class="anchor" aria-hidden="true" href="#datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Datasets&lt;/h2&gt;
&lt;p&gt;The list of datasets that is being used for Jupyter Notebook demos may be found in &lt;a href="data"&gt;data folder&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>trekhleb</author><guid isPermaLink="false">https://github.com/trekhleb/homemade-machine-learning</guid><pubDate>Sat, 30 Nov 2019 00:04:00 GMT</pubDate></item><item><title>Pierian-Data/Complete-Python-3-Bootcamp #5 in Jupyter Notebook, Today</title><link>https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</link><description>&lt;p&gt;&lt;i&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-complete-python-3-bootcamp" class="anchor" aria-hidden="true" href="#complete-python-3-bootcamp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Complete-Python-3-Bootcamp&lt;/h1&gt;
&lt;p&gt;Course Files for Complete Python 3 Bootcamp Course on Udemy&lt;/p&gt;
&lt;p&gt;Get it now for 95% off with the link:
&lt;a href="https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB" rel="nofollow"&gt;https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Pierian-Data</author><guid isPermaLink="false">https://github.com/Pierian-Data/Complete-Python-3-Bootcamp</guid><pubDate>Sat, 30 Nov 2019 00:05:00 GMT</pubDate></item><item><title>spmallick/learnopencv #6 in Jupyter Notebook, Today</title><link>https://github.com/spmallick/learnopencv</link><description>&lt;p&gt;&lt;i&gt;Learn OpenCV  : C++ and Python Examples&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-learnopencv" class="anchor" aria-hidden="true" href="#learnopencv"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;learnopencv&lt;/h1&gt;
&lt;p&gt;Learn OpenCV  : C++ and Python Examples. You can find the details at &lt;a href="https://www.LearnOpenCV.com" rel="nofollow"&gt;LearnOpenCV.com&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-list-of-blog-posts" class="anchor" aria-hidden="true" href="#list-of-blog-posts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;List of Blog Posts&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Blog Post&lt;/th&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/applications-of-foreground-background-separation-with-semantic-segmentation/" rel="nofollow"&gt;Applications of Foreground-Background separation with Semantic Segmentation&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/app-seperation-semseg"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/efficientnet-theory-code" rel="nofollow"&gt;EfficientNet: Theory + Code&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/EfficientNet"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/mask-r-cnn-instance-segmentation-with-pytorch/" rel="nofollow"&gt;PyTorch for Beginners: Mask R-CNN Instance Segmentation with PyTorch&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="./PyTorch-Mask-RCNN"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/faster-r-cnn-object-detection-with-pytorch" rel="nofollow"&gt;PyTorch for Beginners: Faster R-CNN Object Detection with PyTorch&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/PyTorch-faster-RCNN"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/pytorch-for-beginners-semantic-segmentation-using-torchvision/" rel="nofollow"&gt;PyTorch for Beginners: Semantic Segmentation using torchvision&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/PyTorch-Segmentation-torchvision"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/image-classification-using-pre-trained-models-using-pytorch/" rel="nofollow"&gt;PyTorch for Beginners: Comparison of pre-trained models for Image Classification&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Image-classification-pre-trained-models/Image_Classification_using_pre_trained_models.ipynb"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/pytorch-for-beginners-basics/" rel="nofollow"&gt;PyTorch for Beginners: Basics&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/PyTorch-for-Beginners/PyTorch_for_Beginners.ipynb"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/pytorch-model-inference-using-onnx-and-caffe2/" rel="nofollow"&gt;PyTorch Model Inference using ONNX and Caffe2&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Inference-for-PyTorch-Models/ONNX-Caffe2"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/image-classification-using-transfer-learning-in-pytorch/" rel="nofollow"&gt;Image Classification Using Transfer Learning in PyTorch&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Image-Classification-in-PyTorch"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/hangman-creating-games-in-opencv/" rel="nofollow"&gt;Hangman: Creating games in OpenCV&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Hangman"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/image-inpainting-with-opencv-c-python/" rel="nofollow"&gt;Image Inpainting with OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Image-Inpainting"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/hough-transform-with-opencv-c-python/" rel="nofollow"&gt;Hough Transform with OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Hough-Transform"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/xeus-cling-run-c-code-in-jupyter-notebook/" rel="nofollow"&gt;Xeus-Cling: Run C++ code in Jupyter Notebook&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/XeusCling"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/age-gender-classification-using-opencv-deep-learning-c-python/" rel="nofollow"&gt;Gender &amp;amp; Age Classification using OpenCV Deep Learning ( C++/Python )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/AgeGender"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/invisibility-cloak-using-color-detection-and-segmentation-with-opencv/" rel="nofollow"&gt;Invisibility Cloak using Color Detection and Segmentation with OpenCV&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/InvisibilityCloak"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/fast-image-downloader-for-open-images-v4/" rel="nofollow"&gt;Fast Image Downloader for Open Images V4 (Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/downloadOpenImages"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/deep-learning-based-text-detection-using-opencv-c-python/" rel="nofollow"&gt;Deep Learning based Text Detection Using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/TextDetectionEAST"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/video-stabilization-using-point-feature-matching-in-opencv/" rel="nofollow"&gt;Video Stabilization Using Point Feature Matching in OpenCV&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/VideoStabilization"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/training-yolov3-deep-learning-based-custom-object-detector/" rel="nofollow"&gt;Training YOLOv3 : Deep Learning based Custom Object Detector&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/YOLOv3-Training-Snowman-Detector"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/using-openvino-with-opencv/" rel="nofollow"&gt;Using OpenVINO with OpenCV&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/OpenVINO-OpenCV"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/duplicate-search-on-quora-dataset/" rel="nofollow"&gt;Duplicate Search on Quora Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Quora-Dataset-Duplicate-Search"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/shape-matching-using-hu-moments-c-python/" rel="nofollow"&gt;Shape Matching using Hu Moments (C++/Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/HuMoments"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-4-on-centos-7/" rel="nofollow"&gt;Install OpenCV 4 on CentOS (C++ and Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-centos.sh"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-3-4-4-on-centos-7/" rel="nofollow"&gt;Install OpenCV 3.4.4 on CentOS (C++ and Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-centos.sh"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-3-4-4-on-red-hat/" rel="nofollow"&gt;Install OpenCV 3.4.4 on Red Hat (C++ and Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-red-hat.sh"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-4-on-red-hat/" rel="nofollow"&gt;Install OpenCV 4 on Red Hat (C++ and Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-4-on-red-hat.sh"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-4-on-macos/" rel="nofollow"&gt;Install OpenCV 4 on macOS (C++ and Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/InstallScripts/installOpenCV-4-macos.sh"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-3-4-4-on-raspberry-pi/" rel="nofollow"&gt;Install OpenCV 3.4.4 on Raspberry Pi&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-raspberry-pi.sh"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-3-4-4-on-macos/" rel="nofollow"&gt;Install OpenCV 3.4.4 on macOS (C++ and Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-macos.sh"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/opencv-qr-code-scanner-c-and-python/" rel="nofollow"&gt;OpenCV QR Code Scanner (C++ and Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/QRCode-OpenCV"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-3-4-4-on-windows/" rel="nofollow"&gt;Install OpenCV 3.4.4 on Windows (C++ and Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/InstallScripts/Windows-3"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-3-4-4-on-ubuntu-16-04/" rel="nofollow"&gt;Install OpenCV 3.4.4 on Ubuntu 16.04 (C++ and Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-Ubuntu-16-04.sh"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-3-4-4-on-ubuntu-18-04/" rel="nofollow"&gt;Install OpenCV 3.4.4 on Ubuntu 18.04 (C++ and Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-Ubuntu-18-04.sh"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/universal-sentence-encoder" rel="nofollow"&gt;Universal Sentence Encoder&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/blob/master/Universal-Sentence-Encoder"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-4-on-raspberry-pi/" rel="nofollow"&gt;Install OpenCV 4 on Raspberry Pi&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-4-raspberry-pi.sh"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-4-on-windows/" rel="nofollow"&gt;Install OpenCV 4 on Windows (C++ and Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/InstallScripts/Windows-4"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/hand-keypoint-detection-using-deep-learning-and-opencv/" rel="nofollow"&gt;Hand Keypoint Detection using Deep Learning and OpenCV&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/HandPose"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/deep-learning-based-object-detection-and-instance-segmentation-using-mask-r-cnn-in-opencv-python-c/" rel="nofollow"&gt;Deep learning based Object Detection and Instance Segmentation using Mask R-CNN in OpenCV (Python / C++)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Mask-RCNN"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-4-on-ubuntu-18-04/" rel="nofollow"&gt;Install OpenCV 4 on Ubuntu 18.04 (C++ and Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-4-on-Ubuntu-18-04.sh"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-4-on-ubuntu-16-04/" rel="nofollow"&gt;Install OpenCV 4 on Ubuntu 16.04 (C++ and Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-4-on-Ubuntu-16-04.sh"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/multi-person-pose-estimation-in-opencv-using-openpose/" rel="nofollow"&gt;Multi-Person Pose Estimation in OpenCV using OpenPose&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/OpenPose-Multi-Person"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/heatmap-for-logo-detection-using-opencv-python/" rel="nofollow"&gt;Heatmap for Logo Detection using OpenCV (Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/heatmap"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/deep-learning-based-object-detection-using-yolov3-with-opencv-python-c/" rel="nofollow"&gt;Deep Learning based Object Detection using YOLOv3 with OpenCV ( Python / C++ )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/ObjectDetection-YOLO"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/convex-hull-using-opencv-in-python-and-c/" rel="nofollow"&gt;Convex Hull using OpenCV in Python and C++&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/ConvexHull"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/multitracker-multiple-object-tracking-using-opencv-c-python/" rel="nofollow"&gt;MultiTracker : Multiple Object Tracking using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/MultiObjectTracker"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/convolutional-neural-network-based-image-colorization-using-opencv/" rel="nofollow"&gt;Convolutional Neural Network based Image Colorization using OpenCV&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Colorization"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/svm-using-scikit-learn-in-python/" rel="nofollow"&gt;SVM using scikit-learn&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/SVM-using-Python"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/goturn-deep-learning-based-object-tracking/" rel="nofollow"&gt;GOTURN: Deep Learning based Object Tracking&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/GOTURN"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/find-center-of-blob-centroid-using-opencv-cpp-python/" rel="nofollow"&gt;Find the Center of a Blob (Centroid) using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/CenterofBlob"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/support-vector-machines-svm/" rel="nofollow"&gt;Support Vector Machines (SVM)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/SVM-using-Python"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/batch-normalization-in-deep-networks/" rel="nofollow"&gt;Batch Normalization in Deep Networks&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/BatchNormalization"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/deep-learning-character-classification-using-synthetic-dataset/" rel="nofollow"&gt;Deep Learning based Character Classification using Synthetic Dataset&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/CharClassification"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/image-quality-assessment-brisque/" rel="nofollow"&gt;Image Quality Assessment : BRISQUE&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/ImageMetrics"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/understanding-alexnet/" rel="nofollow"&gt;Understanding AlexNet&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/deep-learning-based-text-recognition-ocr-using-tesseract-and-opencv/" rel="nofollow"&gt;Deep Learning based Text Recognition (OCR) using Tesseract and OpenCV&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/OCR"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/" rel="nofollow"&gt;Deep Learning based Human Pose Estimation using OpenCV ( C++ / Python )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/OpenPose"&gt; Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/" rel="nofollow"&gt;Number of Parameters and Tensor Sizes in a Convolutional Neural Network (CNN)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/how-to-convert-your-opencv-c-code-into-a-python-module/" rel="nofollow"&gt;How to convert your OpenCV C++ code into a Python module&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/pymodule"&gt; Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/cv4faces-best-project-award-2018/" rel="nofollow"&gt;CV4Faces : Best Project Award 2018&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/facemark-facial-landmark-detection-using-opencv/" rel="nofollow"&gt;Facemark : Facial Landmark Detection using OpenCV&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/FacialLandmarkDetection"&gt; Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/image-alignment-feature-based-using-opencv-c-python/" rel="nofollow"&gt;Image Alignment (Feature Based) using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/ImageAlignment-FeatureBased"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/barcode-and-qr-code-scanner-using-zbar-and-opencv/" rel="nofollow"&gt;Barcode and QR code Scanner using ZBar and OpenCV&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/barcode-QRcodeScanner"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/" rel="nofollow"&gt;Keras Tutorial : Fine-tuning using pre-trained models&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Keras-Fine-Tuning"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/opencv-transparent-api/" rel="nofollow"&gt;OpenCV Transparent API&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/face-reconstruction-using-eigenfaces-cpp-python/" rel="nofollow"&gt;Face Reconstruction using EigenFaces (C++/Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/ReconstructFaceUsingEigenFaces"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/eigenface-using-opencv-c-python/" rel="nofollow"&gt;Eigenface using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/EigenFace"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/principal-component-analysis/" rel="nofollow"&gt;Principal Component Analysis&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/keras-tutorial-transfer-learning-using-pre-trained-models/" rel="nofollow"&gt;Keras Tutorial : Transfer Learning using pre-trained models&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Keras-Transfer-Learning"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/keras-tutorial-using-pre-trained-imagenet-models/" rel="nofollow"&gt;Keras Tutorial : Using pre-trained Imagenet models&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Keras-ImageNet-Models"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/technical-aspects-of-a-digital-slr/" rel="nofollow"&gt;Technical Aspects of a Digital SLR&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/using-harry-potter-interactive-wand-with-opencv-to-create-magic/" rel="nofollow"&gt;Using Harry Potter interactive wand with OpenCV to create magic&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/install-opencv-3-and-dlib-on-windows-python-only/" rel="nofollow"&gt;Install OpenCV 3 and Dlib on Windows ( Python only )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras" rel="nofollow"&gt;Image Classification using Convolutional Neural Networks in Keras&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/KerasCNN-CIFAR"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/understanding-autoencoders-using-tensorflow-python/" rel="nofollow"&gt;Understanding Autoencoders using Tensorflow (Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/DenoisingAutoencoder"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/best-project-award-computer-vision-for-faces/" rel="nofollow"&gt;Best Project Award : Computer Vision for Faces&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/understanding-activation-functions-in-deep-learning/" rel="nofollow"&gt;Understanding Activation Functions in Deep Learning&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/image-classification-using-feedforward-neural-network-in-keras/" rel="nofollow"&gt;Image Classification using Feedforward Neural Network in Keras&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/KerasMLP-MNIST"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/exposure-fusion-using-opencv-cpp-python/" rel="nofollow"&gt;Exposure Fusion using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/ExposureFusion"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://www.learnopencv.com/understanding-feedforward-neural-networks/" rel="nofollow"&gt;Understanding Feedforward Neural Networks&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/high-dynamic-range-hdr-imaging-using-opencv-cpp-python" rel="nofollow"&gt;High Dynamic Range (HDR) Imaging using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/hdr"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/deep-learning-using-keras-the-basics" rel="nofollow"&gt;Deep learning using Keras – The Basics&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/keras-linear-regression"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/selective-search-for-object-detection-cpp-python/" rel="nofollow"&gt;Selective Search for Object Detection (C++ / Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/SelectiveSearch"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/installing-deep-learning-frameworks-on-ubuntu-with-cuda-support/" rel="nofollow"&gt;Installing Deep Learning Frameworks on Ubuntu with CUDA support&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/parallel-pixel-access-in-opencv-using-foreach/" rel="nofollow"&gt;Parallel Pixel Access in OpenCV using forEach&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/forEach"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/cvui-gui-lib-built-on-top-of-opencv-drawing-primitives/" rel="nofollow"&gt;cvui: A GUI lib built on top of OpenCV drawing primitives&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/UI-cvui"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/install-dlib-on-windows/" rel="nofollow"&gt;Install Dlib on Windows&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/install-dlib-on-ubuntu/" rel="nofollow"&gt;Install Dlib on Ubuntu&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/install-opencv3-on-ubuntu/" rel="nofollow"&gt;Install OpenCV3 on Ubuntu&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/" rel="nofollow"&gt;Read, Write and Display a video using OpenCV ( C++/ Python )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/VideoReadWriteDisplay"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/install-dlib-on-macos/" rel="nofollow"&gt;Install Dlib on MacOS&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/install-opencv3-on-macos/" rel="nofollow"&gt;Install OpenCV 3 on MacOS&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/install-opencv3-on-windows/" rel="nofollow"&gt;Install OpenCV 3 on Windows&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/get-opencv-build-information-getbuildinformation/" rel="nofollow"&gt;Get OpenCV Build Information ( getBuildInformation )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/color-spaces-in-opencv-cpp-python/" rel="nofollow"&gt;Color spaces in OpenCV (C++ / Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/ColorSpaces"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/neural-networks-a-30000-feet-view-for-beginners/" rel="nofollow"&gt;Neural Networks : A 30,000 Feet View for Beginners&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/alpha-blending-using-opencv-cpp-python/" rel="nofollow"&gt;Alpha Blending using OpenCV (C++ / Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/AlphaBlending"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/user-stories-how-readers-of-this-blog-are-applying-their-knowledge-to-build-applications/" rel="nofollow"&gt;User stories : How readers of this blog are applying their knowledge to build applications&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/how-to-select-a-bounding-box-roi-in-opencv-cpp-python/" rel="nofollow"&gt;How to select a bounding box ( ROI ) in OpenCV (C++/Python) ?&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/automatic-red-eye-remover-using-opencv-cpp-python/" rel="nofollow"&gt;Automatic Red Eye Remover using OpenCV (C++ / Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/RedEyeRemover"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/bias-variance-tradeoff-in-machine-learning/" rel="nofollow"&gt;Bias-Variance Tradeoff in Machine Learning&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/embedded-computer-vision-which-device-should-you-choose/" rel="nofollow"&gt;Embedded Computer Vision: Which device should you choose?&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/object-tracking-using-opencv-cpp-python/" rel="nofollow"&gt;Object Tracking using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/tracking"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/handwritten-digits-classification-an-opencv-c-python-tutorial/" rel="nofollow"&gt;Handwritten Digits Classification : An OpenCV ( C++ / Python ) Tutorial&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/digits-classification"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/training-better-haar-lbp-cascade-eye-detector-opencv/" rel="nofollow"&gt;Training a better Haar and LBP cascade based Eye Detector using OpenCV&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/deep-learning-book-gift-recipients/" rel="nofollow"&gt;Deep Learning Book Gift Recipients&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/minified-opencv-haar-and-lbp-cascades/" rel="nofollow"&gt;Minified OpenCV Haar and LBP Cascades&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/ninjaEyeDetector"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/deep-learning-book-gift/" rel="nofollow"&gt;Deep Learning Book Gift&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/histogram-of-oriented-gradients/" rel="nofollow"&gt;Histogram of Oriented Gradients&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/image-recognition-and-object-detection-part1/" rel="nofollow"&gt;Image Recognition and Object Detection : Part 1&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/head-pose-estimation-using-opencv-and-dlib/" rel="nofollow"&gt;Head Pose Estimation using OpenCV and Dlib&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/HeadPose"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/live-cv/" rel="nofollow"&gt;Live CV : A Computer Vision Coding Application&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/approximate-focal-length-for-webcams-and-cell-phone-cameras/" rel="nofollow"&gt;Approximate Focal Length for Webcams and Cell Phone Cameras&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/configuring-qt-for-opencv-on-osx/" rel="nofollow"&gt;Configuring Qt for OpenCV on OSX&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/qt-test"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/rotation-matrix-to-euler-angles/" rel="nofollow"&gt;Rotation Matrix To Euler Angles&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/RotationMatrixToEulerAngles"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/speeding-up-dlib-facial-landmark-detector/" rel="nofollow"&gt;Speeding up Dlib’s Facial Landmark Detector&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/warp-one-triangle-to-another-using-opencv-c-python/" rel="nofollow"&gt;Warp one triangle to another using OpenCV ( C++ / Python )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/WarpTriangle"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/average-face-opencv-c-python-tutorial/" rel="nofollow"&gt;Average Face : OpenCV ( C++ / Python ) Tutorial&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/FaceAverage"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/face-swap-using-opencv-c-python/" rel="nofollow"&gt;Face Swap using OpenCV ( C++ / Python )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/FaceSwap"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/face-morph-using-opencv-cpp-python/" rel="nofollow"&gt;Face Morph Using OpenCV — C++ / Python&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/FaceMorph"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/deep-learning-example-using-nvidia-digits-3-on-ec2/" rel="nofollow"&gt;Deep Learning Example using NVIDIA DIGITS 3 on EC2&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/nvidia-digits-3-on-ec2/" rel="nofollow"&gt;NVIDIA DIGITS 3 on EC2&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/homography-examples-using-opencv-python-c/" rel="nofollow"&gt;Homography Examples using OpenCV ( Python / C ++ )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Homography"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/filling-holes-in-an-image-using-opencv-python-c/" rel="nofollow"&gt;Filling holes in an image using OpenCV ( Python / C++ )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Holes"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/how-to-find-frame-rate-or-frames-per-second-fps-in-opencv-python-cpp/" rel="nofollow"&gt;How to find frame rate or frames per second (fps) in OpenCV ( Python / C++ ) ?&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/FPS"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/" rel="nofollow"&gt;Delaunay Triangulation and Voronoi Diagram using OpenCV ( C++ / Python) &lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Delaunay"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/opencv-c-vs-python-vs-matlab-for-computer-vision/" rel="nofollow"&gt;OpenCV (C++ vs Python) vs MATLAB for Computer Vision&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/facial-landmark-detection/" rel="nofollow"&gt;Facial Landmark Detection&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/why-does-opencv-use-bgr-color-format/" rel="nofollow"&gt;Why does OpenCV use BGR color format ?&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/computer-vision-for-predicting-facial-attractiveness/" rel="nofollow"&gt;Computer Vision for Predicting Facial Attractiveness&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/FacialAttractiveness"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/applycolormap-for-pseudocoloring-in-opencv-c-python/" rel="nofollow"&gt;applyColorMap for pseudocoloring in OpenCV ( C++ / Python )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Colormap"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/image-alignment-ecc-in-opencv-c-python/" rel="nofollow"&gt;Image Alignment (ECC) in OpenCV ( C++ / Python )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/ImageAlignment"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/how-to-find-opencv-version-python-cpp/" rel="nofollow"&gt;How to find OpenCV version in Python and C++ ?&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/baidu-banned-from-ilsvrc-2015/" rel="nofollow"&gt;Baidu banned from ILSVRC 2015&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/opencv-transparent-api/" rel="nofollow"&gt;OpenCV Transparent API&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/how-computer-vision-solved-the-greatest-soccer-mystery-of-all-times/" rel="nofollow"&gt;How Computer Vision Solved the Greatest Soccer Mystery of All Time&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/embedded-vision-summit-2015/" rel="nofollow"&gt;Embedded Vision Summit 2015&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/read-an-image-in-opencv-python-cpp/" rel="nofollow"&gt;Read an Image in OpenCV ( Python, C++ )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/imread"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/non-photorealistic-rendering-using-opencv-python-c/" rel="nofollow"&gt;Non-Photorealistic Rendering using OpenCV ( Python, C++ )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/NonPhotorealisticRendering"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/seamless-cloning-using-opencv-python-cpp/" rel="nofollow"&gt;Seamless Cloning using OpenCV ( Python , C++ )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/SeamlessCloning"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/opencv-threshold-python-cpp/" rel="nofollow"&gt;OpenCV Threshold ( Python , C++ )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/Threshold"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/blob-detection-using-opencv-python-c/" rel="nofollow"&gt;Blob Detection Using OpenCV ( Python, C++ )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/spmallick/learnopencv/tree/master/BlobDetector"&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/turn-your-opencv-Code-into-a-web-api-in-under-10-minutes-part-1/" rel="nofollow"&gt;Turn your OpenCV Code into a Web API in under 10 minutes — Part 1&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/how-to-compile-opencv-sample-Code/" rel="nofollow"&gt;How to compile OpenCV sample Code ?&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://www.learnopencv.com/install-opencv-3-on-yosemite-osx-10-10-x/" rel="nofollow"&gt;Install OpenCV 3 on Yosemite ( OSX 10.10.x )&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>spmallick</author><guid isPermaLink="false">https://github.com/spmallick/learnopencv</guid><pubDate>Sat, 30 Nov 2019 00:06:00 GMT</pubDate></item><item><title>jessevig/bertviz #7 in Jupyter Notebook, Today</title><link>https://github.com/jessevig/bertviz</link><description>&lt;p&gt;&lt;i&gt;Tool for visualizing attention in the Transformer model (BERT, GPT-2, Albert, XLNet, RoBERTa, CTRL, etc.)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-bertviz" class="anchor" aria-hidden="true" href="#bertviz"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;BertViz&lt;/h1&gt;
&lt;p&gt;BertViz is a tool for visualizing attention in the Transformer model, supporting all models from the &lt;a href="https://github.com/huggingface/transformers"&gt;transformers&lt;/a&gt; library (BERT, GPT-2, XLNet, RoBERTa, XLM, CTRL, etc.). It extends the &lt;a href="https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/visualization"&gt;Tensor2Tensor visualization tool&lt;/a&gt; by &lt;a href="https://medium.com/@llionj" rel="nofollow"&gt;Llion Jones&lt;/a&gt; and the &lt;a href="https://github.com/huggingface/transformers"&gt;transformers&lt;/a&gt; library from &lt;a href="https://github.com/huggingface"&gt;HuggingFace&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Blog posts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1" rel="nofollow"&gt;Deconstructing BERT, Part 2: Visualizing the Inner Workings of Attention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/openai-gpt-2-understanding-language-generation-through-visualization-8252f683b2f8" rel="nofollow"&gt;OpenAI GPT-2: Understanding Language Generation through Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/deconstructing-bert-distilling-6-patterns-from-100-million-parameters-b49113672f77" rel="nofollow"&gt;Deconstructing BERT: Distilling 6 Patterns from 100 Million Parameters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Paper:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1906.05714.pdf" rel="nofollow"&gt;A Multiscale Visualization of Attention in the Transformer Model&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-attention-head-view" class="anchor" aria-hidden="true" href="#attention-head-view"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Attention-head view&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;attention-head view&lt;/em&gt; visualizes the attention patterns produced by one or more attention heads in a given transformer layer.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_left.png"&gt;&lt;img src="https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_left.png" alt="Attention-head view" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_right.gif"&gt;&lt;img src="https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_right.gif" alt="Attention-head view animated" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The attention view supports all models from the Transformers library, including:&lt;br&gt;
BERT:
&lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_bert.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1PEHWRHrvxQvYr9NFRC-E_fr3xDq1htCj" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
GPT-2:
&lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_gpt2.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1c9kBsbvSqpKkmd62u7nfqVhvWr0W8_Lx" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
XLNet: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_xlnet.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
RoBERTa: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_roberta.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
XLM: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_xlm.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
Albert: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_albert.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
DistilBert: &lt;a href="https://github.com/jessevig/bertviz/blob/master/head_view_distilbert.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
(and others)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-model-view" class="anchor" aria-hidden="true" href="#model-view"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model view&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;model view&lt;/em&gt; provides a birds-eye view of attention across all of the model’s layers  and heads.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jessevig/bertviz/master/images/model_thumbnail.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jessevig/bertviz/master/images/model_thumbnail.jpg" alt="Model view" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The model view supports all models from the Transformers library, including:&lt;br&gt;
BERT: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_bert.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1c73DtKNdl66B0_HF7QXuPenraDp0jHRS" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
GPT2: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_gpt2.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1y-wfC95Z0aASawYqA34LQeV0_qC9mOto" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
XLNet: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_xlnet.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
RoBERTa: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_roberta.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
XLM: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_xlm.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
Albert: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_albert.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
DistilBert: &lt;a href="https://github.com/jessevig/bertviz/blob/master/model_view_distilbert.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;br&gt;
(and others)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-neuron-view" class="anchor" aria-hidden="true" href="#neuron-view"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Neuron view&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;neuron view&lt;/em&gt; visualizes the individual neurons in the query and key vectors and shows how they are used to compute attention.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jessevig/bertviz/master/images/neuron_thumbnail.png"&gt;&lt;img src="https://raw.githubusercontent.com/jessevig/bertviz/master/images/neuron_thumbnail.png" alt="Neuron view" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The neuron view supports the following three models:&lt;br&gt;
BERT: &lt;a href="https://github.com/jessevig/bertviz/blob/master/neuron_view_bert.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1m37iotFeubMrp9qIf9yscXEL1zhxTN2b" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
GPT-2
&lt;a href="https://github.com/jessevig/bertviz/blob/master/neuron_view_gpt2.ipynb"&gt;[Notebook]&lt;/a&gt;
&lt;a href="https://colab.research.google.com/drive/1s8XCCyxsKvNRWNzjWi5Nl8ZAYZ5YkLm_" rel="nofollow"&gt;[Colab]&lt;/a&gt;&lt;br&gt;
RoBERTa
&lt;a href="https://github.com/jessevig/bertviz/blob/master/neuron_view_roberta.ipynb"&gt;[Notebook]&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/transformers/" rel="nofollow"&gt;Transformers&lt;/a&gt; (version required depends on models used)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pytorch.org/" rel="nofollow"&gt;PyTorch&lt;/a&gt; &amp;gt;=1.0.0&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jupyter.org/install" rel="nofollow"&gt;Jupyter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/tqdm/" rel="nofollow"&gt;tqdm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/boto3/" rel="nofollow"&gt;boto3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/ipython/" rel="nofollow"&gt;IPython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/requests/" rel="nofollow"&gt;requests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/regex/" rel="nofollow"&gt;regex&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.org/project/sentencepiece/" rel="nofollow"&gt;sentencepiece&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(See &lt;a href="https://github.com/jessevig/bertviz/blob/master/requirements.txt"&gt;requirements.txt&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-execution" class="anchor" aria-hidden="true" href="#execution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Execution&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/jessevig/bertviz.git
cd bertviz
jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;NOTE: If you wish to run BertViz using Colab, please see the example Colab scripts above, as they differ slightly from the Jupyter notebook versions.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jessevig"&gt;Jesse Vig&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;When referencing BertViz, please cite &lt;a href="https://arxiv.org/abs/1906.05714" rel="nofollow"&gt;this paper&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{vig2019transformervis,
  author    = {Jesse Vig},
  title     = {A Multiscale Visualization of Attention in the Transformer Model},
  journal   = {arXiv preprint arXiv:1906.05714},
  year      = {2019},
  url       = {https://arxiv.org/abs/1906.05714}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href="LICENSE"&gt;LICENSE&lt;/a&gt; file for details&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;This project incorporates code from the following repos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tensor2tensor"&gt;https://github.com/tensorflow/tensor2tensor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT"&gt;https://github.com/huggingface/pytorch-pretrained-BERT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jessevig</author><guid isPermaLink="false">https://github.com/jessevig/bertviz</guid><pubDate>Sat, 30 Nov 2019 00:07:00 GMT</pubDate></item><item><title>jackfrued/Python-100-Days #8 in Jupyter Notebook, Today</title><link>https://github.com/jackfrued/Python-100-Days</link><description>&lt;p&gt;&lt;i&gt;Python - 100天从新手到大师&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-python---100天从新手到大师" class="anchor" aria-hidden="true" href="#python---100天从新手到大师"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python - 100天从新手到大师&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;作者：骆昊&lt;/p&gt;
&lt;p&gt;最近有很多想学习Python的小伙伴陆陆续续加入我们的交流群，目前我们的交流群人数已经超过一万人。我们的目标是打造一个优质的Python交流社区，一方面为想学习Python的初学者扫平入门过程中的重重障碍；另一方为新入行的开发者提供问道的途径，帮助他们迅速成长为优秀的职业人；此外，有经验的开发者可以利用这个平台把自己的工作经验无偿分享或有偿提供出来，让大家都能够得到职业技能以及综合素质的全面提升。之前的公开课和线下技术交流活动因为工作的关系荒废了一段时间了，但是各位小伙伴仍然活跃在交流群并一如既往的支持我们，在此向大家表示感谢。近期开始持续更新前15天和最后10天的内容，前15天是写给初学者的，我希望把上手的难度进一步降低，例子程序更加简单清晰；最后10天是Python项目实战和面试相关的东西，我希望内容更详实和完整，尤其是第100天的面试题部分；创作不易，感谢大家的打赏支持，这些钱不会用于购买咖啡而是通过腾讯公益平台捐赠给需要帮助的人（&lt;a href="./%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97.md"&gt;点击&lt;/a&gt;了解捐赠情况）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-qq-group.png"&gt;&lt;img src="./res/python-qq-group.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-python应用领域和就业形势分析" class="anchor" aria-hidden="true" href="#python应用领域和就业形势分析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python应用领域和就业形势分析&lt;/h3&gt;
&lt;p&gt;简单的说，Python是一个“优雅”、“明确”、“简单”的编程语言。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;学习曲线低，非专业人士也能上手&lt;/li&gt;
&lt;li&gt;开源系统，拥有强大的生态圈&lt;/li&gt;
&lt;li&gt;解释型语言，完美的平台可移植性&lt;/li&gt;
&lt;li&gt;支持面向对象和函数式编程&lt;/li&gt;
&lt;li&gt;能够通过调用C/C++代码扩展功能&lt;/li&gt;
&lt;li&gt;代码规范程度高，可读性强&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目前几个比较流行的领域，Python都有用武之地。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;云基础设施 - Python / Java / Go&lt;/li&gt;
&lt;li&gt;DevOps - Python / Shell / Ruby / Go&lt;/li&gt;
&lt;li&gt;网络爬虫 - Python / PHP / C++&lt;/li&gt;
&lt;li&gt;数据分析挖掘 - Python / R / Scala / Matlab&lt;/li&gt;
&lt;li&gt;机器学习 - Python / R / Java / Lisp&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作为一名Python开发者，主要的就业领域包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python服务器后台开发 / 游戏服务器开发 / 数据接口开发工程师&lt;/li&gt;
&lt;li&gt;Python自动化运维工程师&lt;/li&gt;
&lt;li&gt;Python数据分析 / 数据可视化 / 大数据工程师&lt;/li&gt;
&lt;li&gt;Python爬虫工程师&lt;/li&gt;
&lt;li&gt;Python聊天机器人开发 / 图像识别和视觉算法 / 深度学习工程师&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图显示了主要城市Python招聘需求量及薪资待遇排行榜（截止到2018年5月）。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-top-10.png"&gt;&lt;img src="./res/python-top-10.png" alt="Python招聘需求及薪资待遇Top 10" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-bj-salary.png"&gt;&lt;img src="./res/python-bj-salary.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/python-salary-chengdu.png"&gt;&lt;img src="./res/python-salary-chengdu.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;给初学者的几个建议：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make English as your working language.&lt;/li&gt;
&lt;li&gt;Practice makes perfect.&lt;/li&gt;
&lt;li&gt;All experience comes from mistakes.&lt;/li&gt;
&lt;li&gt;Don't be one of the leeches.&lt;/li&gt;
&lt;li&gt;Either stand out or kicked out.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day0115---python语言基础" class="anchor" aria-hidden="true" href="#day0115---python语言基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day01~15 - &lt;a href="./Day01-15"&gt;Python语言基础&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day01---初识python" class="anchor" aria-hidden="true" href="#day01---初识python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day01 - &lt;a href="./Day01-15/01.%E5%88%9D%E8%AF%86Python.md"&gt;初识Python&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Python简介 - Python的历史 / Python的优缺点 / Python的应用领域&lt;/li&gt;
&lt;li&gt;搭建编程环境 - Windows环境 / Linux环境 / MacOS环境&lt;/li&gt;
&lt;li&gt;从终端运行Python程序 - Hello, world / print函数 / 运行程序&lt;/li&gt;
&lt;li&gt;使用IDLE - 交互式环境(REPL) / 编写多行代码 / 运行程序 / 退出IDLE&lt;/li&gt;
&lt;li&gt;注释 - 注释的作用 / 单行注释 / 多行注释&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day02---语言元素" class="anchor" aria-hidden="true" href="#day02---语言元素"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day02 - &lt;a href="./Day01-15/02.%E8%AF%AD%E8%A8%80%E5%85%83%E7%B4%A0.md"&gt;语言元素&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;程序和进制 - 指令和程序 / 冯诺依曼机 / 二进制和十进制 / 八进制和十六进制&lt;/li&gt;
&lt;li&gt;变量和类型 - 变量的命名 / 变量的使用 / input函数 / 检查变量类型 / 类型转换&lt;/li&gt;
&lt;li&gt;数字和字符串 - 整数 / 浮点数 / 复数 / 字符串 / 字符串基本操作 / 字符编码&lt;/li&gt;
&lt;li&gt;运算符 - 数学运算符 / 赋值运算符 / 比较运算符 / 逻辑运算符 / 身份运算符 / 运算符的优先级&lt;/li&gt;
&lt;li&gt;应用案例 - 华氏温度转换成摄氏温度 / 输入圆的半径计算周长和面积 / 输入年份判断是否是闰年&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day03---分支结构" class="anchor" aria-hidden="true" href="#day03---分支结构"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day03 - &lt;a href="./Day01-15/03.%E5%88%86%E6%94%AF%E7%BB%93%E6%9E%84.md"&gt;分支结构&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;分支结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图&lt;/li&gt;
&lt;li&gt;if语句 - 简单的if / if-else结构 / if-elif-else结构 / 嵌套的if&lt;/li&gt;
&lt;li&gt;应用案例 - 用户身份验证 / 英制单位与公制单位互换 / 掷骰子决定做什么 / 百分制成绩转等级制 / 分段函数求值 / 输入三条边的长度如果能构成三角形就计算周长和面积&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day04---循环结构" class="anchor" aria-hidden="true" href="#day04---循环结构"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day04 - &lt;a href="./Day01-15/04.%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84.md"&gt;循环结构&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;循环结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图&lt;/li&gt;
&lt;li&gt;while循环 - 基本结构 / break语句 / continue语句&lt;/li&gt;
&lt;li&gt;for循环 - 基本结构 / range类型 / 循环中的分支结构 / 嵌套的循环 / 提前结束程序&lt;/li&gt;
&lt;li&gt;应用案例 - 1~100求和 / 判断素数 / 猜数字游戏 / 打印九九表 / 打印三角形图案 / 猴子吃桃 / 百钱百鸡&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day05---构造程序逻辑" class="anchor" aria-hidden="true" href="#day05---构造程序逻辑"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day05 - &lt;a href="./Day01-15/05.%E6%9E%84%E9%80%A0%E7%A8%8B%E5%BA%8F%E9%80%BB%E8%BE%91.md"&gt;构造程序逻辑&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;经典案例：水仙花数 / 百钱百鸡 / Craps赌博游戏&lt;/li&gt;
&lt;li&gt;练习题目：斐波那契数列 / 完美数 / 素数&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day06---函数和模块的使用" class="anchor" aria-hidden="true" href="#day06---函数和模块的使用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day06 - &lt;a href="./Day01-15/06.%E5%87%BD%E6%95%B0%E5%92%8C%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8.md"&gt;函数和模块的使用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;函数的作用 - 代码的坏味道 / 用函数封装功能模块&lt;/li&gt;
&lt;li&gt;定义函数 - def语句 / 函数名 / 参数列表 / return语句 / 调用自定义函数&lt;/li&gt;
&lt;li&gt;调用函数 - Python内置函数 /  导入模块和函数&lt;/li&gt;
&lt;li&gt;函数的参数 - 默认参数 / 可变参数 / 关键字参数 / 命名关键字参数&lt;/li&gt;
&lt;li&gt;函数的返回值 - 没有返回值  / 返回单个值 / 返回多个值&lt;/li&gt;
&lt;li&gt;作用域问题 - 局部作用域 / 嵌套作用域 / 全局作用域 / 内置作用域 / 和作用域相关的关键字&lt;/li&gt;
&lt;li&gt;用模块管理函数 - 模块的概念 / 用自定义模块管理函数 / 命名冲突的时候会怎样（同一个模块和不同的模块）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day07---字符串和常用数据结构" class="anchor" aria-hidden="true" href="#day07---字符串和常用数据结构"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day07 - &lt;a href="./Day01-15/07.%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.md"&gt;字符串和常用数据结构&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;字符串的使用 - 计算长度 / 下标运算 / 切片 / 常用方法&lt;/li&gt;
&lt;li&gt;列表基本用法 - 定义列表 / 用下表访问元素 / 下标越界 / 添加元素 / 删除元素 / 修改元素 / 切片 / 循环遍历&lt;/li&gt;
&lt;li&gt;列表常用操作 - 连接 / 复制(复制元素和复制数组) / 长度 / 排序 / 倒转 / 查找&lt;/li&gt;
&lt;li&gt;生成列表 - 使用range创建数字列表 / 生成表达式 / 生成器&lt;/li&gt;
&lt;li&gt;元组的使用 - 定义元组 / 使用元组中的值 / 修改元组变量 / 元组和列表转换&lt;/li&gt;
&lt;li&gt;集合基本用法 - 集合和列表的区别 /  创建集合 / 添加元素 / 删除元素 /  清空&lt;/li&gt;
&lt;li&gt;集合常用操作 - 交集 / 并集 / 差集 / 对称差 / 子集 / 超集&lt;/li&gt;
&lt;li&gt;字典的基本用法 - 字典的特点 / 创建字典 / 添加元素 / 删除元素 / 取值 / 清空&lt;/li&gt;
&lt;li&gt;字典常用操作 - keys()方法 / values()方法 / items()方法 / setdefault()方法&lt;/li&gt;
&lt;li&gt;基础练习 - 跑马灯效果 / 列表找最大元素 / 统计考试成绩的平均分 / Fibonacci数列 / 杨辉三角&lt;/li&gt;
&lt;li&gt;综合案例 - 双色球选号 / 井字棋&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day08---面向对象编程基础" class="anchor" aria-hidden="true" href="#day08---面向对象编程基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day08 - &lt;a href="./Day01-15/08.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80.md"&gt;面向对象编程基础&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;类和对象 - 什么是类 / 什么是对象 / 面向对象其他相关概念&lt;/li&gt;
&lt;li&gt;定义类 - 基本结构 / 属性和方法 / 构造器 / 析构器 / __str__方法&lt;/li&gt;
&lt;li&gt;使用对象 - 创建对象 / 给对象发消息&lt;/li&gt;
&lt;li&gt;面向对象的四大支柱 - 抽象 / 封装 / 继承 / 多态&lt;/li&gt;
&lt;li&gt;基础练习 - 定义学生类 / 定义时钟类 / 定义图形类 / 定义汽车类&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day09---面向对象进阶" class="anchor" aria-hidden="true" href="#day09---面向对象进阶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day09 - &lt;a href="./Day01-15/09.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%BF%9B%E9%98%B6.md"&gt;面向对象进阶&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;属性 - 类属性 / 实例属性 / 属性访问器 / 属性修改器 / 属性删除器 / 使用__slots__&lt;/li&gt;
&lt;li&gt;类中的方法 - 实例方法 / 类方法 / 静态方法&lt;/li&gt;
&lt;li&gt;运算符重载 - __add__ / __sub__ / __or__ /__getitem__ / __setitem__ / __len__ / __repr__ / __gt__ / __lt__ / __le__ / __ge__ / __eq__ / __ne__ / __contains__&lt;/li&gt;
&lt;li&gt;类(的对象)之间的关系 - 关联 / 继承 / 依赖&lt;/li&gt;
&lt;li&gt;继承和多态 - 什么是继承 / 继承的语法 / 调用父类方法 / 方法重写 / 类型判定 / 多重继承 / 菱形继承(钻石继承)和C3算法&lt;/li&gt;
&lt;li&gt;综合案例 - 工资结算系统 / 图书自动折扣系统 / 自定义分数类&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day10---图形用户界面和游戏开发" class="anchor" aria-hidden="true" href="#day10---图形用户界面和游戏开发"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day10 - &lt;a href="./Day01-15/10.%E5%9B%BE%E5%BD%A2%E7%94%A8%E6%88%B7%E7%95%8C%E9%9D%A2%E5%92%8C%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91.md"&gt;图形用户界面和游戏开发&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;使用tkinter开发GUI程序&lt;/li&gt;
&lt;li&gt;使用pygame三方库开发游戏应用&lt;/li&gt;
&lt;li&gt;“大球吃小球”游戏&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day11---文件和异常" class="anchor" aria-hidden="true" href="#day11---文件和异常"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day11 - &lt;a href="./Day01-15/11.%E6%96%87%E4%BB%B6%E5%92%8C%E5%BC%82%E5%B8%B8.md"&gt;文件和异常&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;读文件 - 读取整个文件 / 逐行读取 / 文件路径&lt;/li&gt;
&lt;li&gt;写文件 - 覆盖写入 / 追加写入 / 文本文件 / 二进制文件&lt;/li&gt;
&lt;li&gt;异常处理 - 异常机制的重要性 / try-except代码块 / else代码块 / finally代码块 / 内置异常类型 / 异常栈 / raise语句&lt;/li&gt;
&lt;li&gt;数据持久化 - CSV文件概述 / csv模块的应用 / JSON数据格式 / json模块的应用&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day12---字符串和正则表达式" class="anchor" aria-hidden="true" href="#day12---字符串和正则表达式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day12 - &lt;a href="./Day01-15/12.%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F.md"&gt;字符串和正则表达式&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;字符串高级操作 - 转义字符 / 原始字符串 / 多行字符串 / in和 not in运算符 / is开头的方法 / join和split方法 / strip相关方法 / pyperclip模块 / 不变字符串和可变字符串 / StringIO的使用&lt;/li&gt;
&lt;li&gt;正则表达式入门 - 正则表达式的作用 / 元字符 / 转义 / 量词 / 分组 / 零宽断言 /贪婪匹配与惰性匹配懒惰 / 使用re模块实现正则表达式操作（匹配、搜索、替换、捕获）&lt;/li&gt;
&lt;li&gt;使用正则表达式 - re模块 / compile函数 / group和groups方法 / match方法 / search方法 / findall和finditer方法 / sub和subn方法 / split方法&lt;/li&gt;
&lt;li&gt;应用案例 - 使用正则表达式验证输入的字符串&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day13---进程和线程" class="anchor" aria-hidden="true" href="#day13---进程和线程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day13 - &lt;a href="./Day01-15/13.%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B.md"&gt;进程和线程&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;进程和线程的概念 - 什么是进程 / 什么是线程 / 多线程的应用场景&lt;/li&gt;
&lt;li&gt;使用进程 - fork函数 / multiprocessing模块 / 进程池 / 进程间通信&lt;/li&gt;
&lt;li&gt;使用线程 - thread模块 / threading模块 / Thread类 / Lock类 / Condition类 / 线程池&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day14---网络编程入门和网络应用开发" class="anchor" aria-hidden="true" href="#day14---网络编程入门和网络应用开发"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day14 - &lt;a href="./Day01-15/14.%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91.md"&gt;网络编程入门和网络应用开发&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;计算机网络基础 - 计算机网络发展史 / “TCP-IP”模型 / IP地址 / 端口 / 协议 / 其他相关概念&lt;/li&gt;
&lt;li&gt;网络应用模式 - “客户端-服务器”模式 / “浏览器-服务器”模式&lt;/li&gt;
&lt;li&gt;基于HTTP协议访问网络资源 - 网络API概述 / 访问URL / requests模块 / 解析JSON格式数据&lt;/li&gt;
&lt;li&gt;Python网络编程 - 套接字的概念 / socket模块 /  socket函数 / 创建TCP服务器 / 创建TCP客户端 / 创建UDP服务器 / 创建UDP客户端 / SocketServer模块&lt;/li&gt;
&lt;li&gt;电子邮件 - SMTP协议 / POP3协议 / IMAP协议 / smtplib模块 / poplib模块 / imaplib模块&lt;/li&gt;
&lt;li&gt;短信服务 - 调用短信服务网关&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day15---图像和文档处理" class="anchor" aria-hidden="true" href="#day15---图像和文档处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day15 - &lt;a href="./Day01-15/15.%E5%9B%BE%E5%83%8F%E5%92%8C%E5%8A%9E%E5%85%AC%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86.md"&gt;图像和文档处理&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;用Pillow处理图片 - 图片读写 / 图片合成 / 几何变换 / 色彩转换 / 滤镜效果&lt;/li&gt;
&lt;li&gt;读写Word文档 - 文本内容的处理 / 段落 / 页眉和页脚 / 样式的处理&lt;/li&gt;
&lt;li&gt;读写Excel文件 - xlrd模块 / xlwt模块&lt;/li&gt;
&lt;li&gt;生成PDF文件 - pypdf2模块 / reportlab模块&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day16day20---python语言进阶-" class="anchor" aria-hidden="true" href="#day16day20---python语言进阶-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day16~Day20 - &lt;a href="./Day16-20/16-20.Python%E8%AF%AD%E8%A8%80%E8%BF%9B%E9%98%B6.md"&gt;Python语言进阶 &lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;常用数据结构&lt;/li&gt;
&lt;li&gt;函数的高级用法 - “一等公民” / 高阶函数 / Lambda函数 / 作用域和闭包 / 装饰器&lt;/li&gt;
&lt;li&gt;面向对象高级知识 - “三大支柱” / 类与类之间的关系 / 垃圾回收 / 魔术属性和方法 / 混入 / 元类 / 面向对象设计原则 / GoF设计模式&lt;/li&gt;
&lt;li&gt;迭代器和生成器 - 相关魔术方法 / 创建生成器的两种方式 /&lt;/li&gt;
&lt;li&gt;并发和异步编程 - 多线程 / 多进程 / 异步IO / async和await&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day2130---web前端入门" class="anchor" aria-hidden="true" href="#day2130---web前端入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day21~30 - &lt;a href="./Day21-30/21-30.Web%E5%89%8D%E7%AB%AF%E6%A6%82%E8%BF%B0.md"&gt;Web前端入门&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用HTML标签承载页面内容&lt;/li&gt;
&lt;li&gt;用CSS渲染页面&lt;/li&gt;
&lt;li&gt;用JavaScript处理交互式行为&lt;/li&gt;
&lt;li&gt;jQuery入门和提高&lt;/li&gt;
&lt;li&gt;Vue.js入门&lt;/li&gt;
&lt;li&gt;Element的使用&lt;/li&gt;
&lt;li&gt;Bootstrap的使用&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day3135---玩转linux操作系统" class="anchor" aria-hidden="true" href="#day3135---玩转linux操作系统"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day31~35 - &lt;a href="./Day31-35/31-35.%E7%8E%A9%E8%BD%ACLinux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.md"&gt;玩转Linux操作系统&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;操作系统发展史和Linux概述&lt;/li&gt;
&lt;li&gt;Linux基础命令&lt;/li&gt;
&lt;li&gt;Linux中的实用程序&lt;/li&gt;
&lt;li&gt;Linux的文件系统&lt;/li&gt;
&lt;li&gt;Vim编辑器的应用&lt;/li&gt;
&lt;li&gt;环境变量和Shell编程&lt;/li&gt;
&lt;li&gt;软件的安装和服务的配置&lt;/li&gt;
&lt;li&gt;网络访问和管理&lt;/li&gt;
&lt;li&gt;其他相关内容&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day3640---数据库基础和进阶" class="anchor" aria-hidden="true" href="#day3640---数据库基础和进阶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day36~40 - &lt;a href="./Day36-40"&gt;数据库基础和进阶&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="./Day36-40/36-38.%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93MySQL.md"&gt;关系型数据库MySQL&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;关系型数据库概述&lt;/li&gt;
&lt;li&gt;MySQL的安装和使用&lt;/li&gt;
&lt;li&gt;SQL的使用
&lt;ul&gt;
&lt;li&gt;DDL - 数据定义语言 - create / drop / alter&lt;/li&gt;
&lt;li&gt;DML - 数据操作语言 - insert / delete / update / select&lt;/li&gt;
&lt;li&gt;DCL - 数据控制语言 - grant / revoke&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;相关知识
&lt;ul&gt;
&lt;li&gt;范式理论 - 设计二维表的指导思想&lt;/li&gt;
&lt;li&gt;数据完整性&lt;/li&gt;
&lt;li&gt;数据一致性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在Python中操作MySQL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="./Day36-40/39-40.NoSQL%E5%85%A5%E9%97%A8.md"&gt;NoSQL入门&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;NoSQL概述&lt;/li&gt;
&lt;li&gt;Redis概述&lt;/li&gt;
&lt;li&gt;Mongo概述&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day4155---实战django" class="anchor" aria-hidden="true" href="#day4155---实战django"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day41~55 - &lt;a href="./Day41-55"&gt;实战Django&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day41---快速上手" class="anchor" aria-hidden="true" href="#day41---快速上手"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day41 - &lt;a href="./Day41-55/41.%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B.md"&gt;快速上手&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Web应用工作原理和HTTP协议&lt;/li&gt;
&lt;li&gt;Django框架概述&lt;/li&gt;
&lt;li&gt;5分钟快速上手&lt;/li&gt;
&lt;li&gt;使用视图模板&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day42---深入模型" class="anchor" aria-hidden="true" href="#day42---深入模型"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day42 - &lt;a href="./Day41-55/42.%E6%B7%B1%E5%85%A5%E6%A8%A1%E5%9E%8B.md"&gt;深入模型&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;关系型数据库配置&lt;/li&gt;
&lt;li&gt;管理后台的使用&lt;/li&gt;
&lt;li&gt;使用ORM完成对模型的CRUD操作&lt;/li&gt;
&lt;li&gt;Django模型最佳实践&lt;/li&gt;
&lt;li&gt;模型定义参考&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day43---静态资源和ajax请求" class="anchor" aria-hidden="true" href="#day43---静态资源和ajax请求"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day43 - &lt;a href="./Day41-55/43.%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E5%92%8CAjax%E8%AF%B7%E6%B1%82.md"&gt;静态资源和Ajax请求&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;加载静态资源&lt;/li&gt;
&lt;li&gt;用Ajax请求获取数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day44---表单的应用" class="anchor" aria-hidden="true" href="#day44---表单的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day44 - &lt;a href="./Day41-55/44.%E8%A1%A8%E5%8D%95%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;表单的应用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;表单和表单控件&lt;/li&gt;
&lt;li&gt;跨站请求伪造和CSRF令牌&lt;/li&gt;
&lt;li&gt;Form和ModelForm&lt;/li&gt;
&lt;li&gt;表单验证&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day45---cookie和session" class="anchor" aria-hidden="true" href="#day45---cookie和session"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day45 - &lt;a href="./Day41-55/45.Cookie%E5%92%8CSession.md"&gt;Cookie和Session&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;实现用户跟踪&lt;/li&gt;
&lt;li&gt;cookie和session的关系&lt;/li&gt;
&lt;li&gt;Django框架对session的支持&lt;/li&gt;
&lt;li&gt;视图函数中的cookie读写操作&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day46---报表和日志" class="anchor" aria-hidden="true" href="#day46---报表和日志"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day46 - &lt;a href="./Day41-55/46.%E6%8A%A5%E8%A1%A8%E5%92%8C%E6%97%A5%E5%BF%97.md"&gt;报表和日志&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;通过HttpResponse修改响应头&lt;/li&gt;
&lt;li&gt;使用StreamingHttpResponse处理大文件&lt;/li&gt;
&lt;li&gt;使用xlwt生成Excel报表&lt;/li&gt;
&lt;li&gt;使用reportlab生成PDF报表&lt;/li&gt;
&lt;li&gt;使用ECharts生成前端图表&lt;/li&gt;
&lt;li&gt;配置日志和Django-Debug-Toolbar&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day47---中间件的应用" class="anchor" aria-hidden="true" href="#day47---中间件的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day47 - &lt;a href="./Day41-55/47.%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;中间件的应用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;什么是中间件&lt;/li&gt;
&lt;li&gt;Django框架内置的中间件&lt;/li&gt;
&lt;li&gt;自定义中间件及其应用场景&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day48---前后端分离开发入门" class="anchor" aria-hidden="true" href="#day48---前后端分离开发入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day48 - &lt;a href="./Day41-55/48.%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%BC%80%E5%8F%91%E5%85%A5%E9%97%A8.md"&gt;前后端分离开发入门&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;返回JSON格式的数据&lt;/li&gt;
&lt;li&gt;用Vue.js渲染页面&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day49---restful架构和drf入门" class="anchor" aria-hidden="true" href="#day49---restful架构和drf入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day49 - &lt;a href="./Day41-55/49.RESTful%E6%9E%B6%E6%9E%84%E5%92%8CDRF%E5%85%A5%E9%97%A8.md"&gt;RESTful架构和DRF入门&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day50---restful架构和drf进阶" class="anchor" aria-hidden="true" href="#day50---restful架构和drf进阶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day50 - &lt;a href="./Day41-55/50.RESTful%E6%9E%B6%E6%9E%84%E5%92%8CDRF%E8%BF%9B%E9%98%B6.md"&gt;RESTful架构和DRF进阶&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day51---使用缓存" class="anchor" aria-hidden="true" href="#day51---使用缓存"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day51 - &lt;a href="./Day41-55/51.%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98.md"&gt;使用缓存&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;网站优化第一定律&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在Django项目中使用Redis提供缓存服务&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在视图函数中读写缓存&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用装饰器实现页面缓存&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为数据接口提供缓存服务&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day52---文件上传和富文本编辑" class="anchor" aria-hidden="true" href="#day52---文件上传和富文本编辑"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day52 - &lt;a href="./Day41-55/52.%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%92%8C%E5%AF%8C%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8.md"&gt;文件上传和富文本编辑&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;文件上传表单控件和图片文件预览&lt;/li&gt;
&lt;li&gt;服务器端如何处理上传的文件&lt;/li&gt;
&lt;li&gt;富文本编辑器概述&lt;/li&gt;
&lt;li&gt;wangEditor的使用&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day53---短信和邮件" class="anchor" aria-hidden="true" href="#day53---短信和邮件"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day53 - &lt;a href="./Day41-55/53.%E7%9F%AD%E4%BF%A1%E5%92%8C%E9%82%AE%E4%BB%B6.md"&gt;短信和邮件&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;常用短信网关平台介绍&lt;/li&gt;
&lt;li&gt;使用螺丝帽发送短信&lt;/li&gt;
&lt;li&gt;Django框架对邮件服务的支持&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day54---异步任务和定时任务" class="anchor" aria-hidden="true" href="#day54---异步任务和定时任务"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day54 - &lt;a href="./Day41-55/54.%E5%BC%82%E6%AD%A5%E4%BB%BB%E5%8A%A1%E5%92%8C%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1.md"&gt;异步任务和定时任务&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;网站优化第二定律&lt;/li&gt;
&lt;li&gt;配置消息队列服务&lt;/li&gt;
&lt;li&gt;在项目中使用celery实现任务异步化&lt;/li&gt;
&lt;li&gt;在项目中使用celery实现定时任务&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day55---单元测试和项目上线" class="anchor" aria-hidden="true" href="#day55---单元测试和项目上线"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day55 - &lt;a href="./Day41-55/55.%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E5%92%8C%E9%A1%B9%E7%9B%AE%E4%B8%8A%E7%BA%BF.md"&gt;单元测试和项目上线&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Python中的单元测试&lt;/li&gt;
&lt;li&gt;Django框架对单元测试的支持&lt;/li&gt;
&lt;li&gt;使用版本控制系统&lt;/li&gt;
&lt;li&gt;配置和使用uWSGI&lt;/li&gt;
&lt;li&gt;动静分离和Nginx配置&lt;/li&gt;
&lt;li&gt;配置HTTPS&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day5660---实战flask" class="anchor" aria-hidden="true" href="#day5660---实战flask"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day56~60 - &lt;a href="./Day56-65"&gt;实战Flask&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day56---flask入门" class="anchor" aria-hidden="true" href="#day56---flask入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day56 - &lt;a href="./Day56-60/56.Flask%E5%85%A5%E9%97%A8.md"&gt;Flask入门&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day57---模板的使用" class="anchor" aria-hidden="true" href="#day57---模板的使用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day57 - &lt;a href="./Day56-60/57.%E6%A8%A1%E6%9D%BF%E7%9A%84%E4%BD%BF%E7%94%A8.md"&gt;模板的使用&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day58---表单的处理" class="anchor" aria-hidden="true" href="#day58---表单的处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day58 - &lt;a href="./Day56-60/58.%E8%A1%A8%E5%8D%95%E7%9A%84%E5%A4%84%E7%90%86.md"&gt;表单的处理&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day59---数据库操作" class="anchor" aria-hidden="true" href="#day59---数据库操作"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day59 - &lt;a href="./Day56-60/59.%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C.md"&gt;数据库操作&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day60---项目实战" class="anchor" aria-hidden="true" href="#day60---项目实战"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day60 - &lt;a href="./Day56-60/60.%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.md"&gt;项目实战&lt;/a&gt;&lt;/h4&gt;
&lt;h3&gt;&lt;a id="user-content-day6165---实战tornado" class="anchor" aria-hidden="true" href="#day6165---实战tornado"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day61~65 - &lt;a href="./Day61-65"&gt;实战Tornado&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day61---预备知识" class="anchor" aria-hidden="true" href="#day61---预备知识"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day61 - &lt;a href="./Day61-65/61.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86.md"&gt;预备知识&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;并发编程&lt;/li&gt;
&lt;li&gt;I/O模式和事件驱动&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day62---tornado入门" class="anchor" aria-hidden="true" href="#day62---tornado入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day62 - &lt;a href="./Day61-65/62.Tornado%E5%85%A5%E9%97%A8.md"&gt;Tornado入门&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Tornado概述&lt;/li&gt;
&lt;li&gt;5分钟上手Tornado&lt;/li&gt;
&lt;li&gt;路由解析&lt;/li&gt;
&lt;li&gt;请求处理器&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day63---异步化" class="anchor" aria-hidden="true" href="#day63---异步化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day63 - &lt;a href="./Day61-65/63.%E5%BC%82%E6%AD%A5%E5%8C%96.md"&gt;异步化&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;aiomysql和aioredis的使用&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day64---websocket的应用" class="anchor" aria-hidden="true" href="#day64---websocket的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day64 - &lt;a href="./Day61-65/64.WebSocket%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;WebSocket的应用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;WebSocket简介&lt;/li&gt;
&lt;li&gt;WebSocket服务器端编程&lt;/li&gt;
&lt;li&gt;WebSocket客户端编程&lt;/li&gt;
&lt;li&gt;项目：Web聊天室&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day65---项目实战" class="anchor" aria-hidden="true" href="#day65---项目实战"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day65 - &lt;a href="./Day61-65/65.%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.md"&gt;项目实战&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;前后端分离开发和接口文档的撰写&lt;/li&gt;
&lt;li&gt;使用Vue.js实现前端渲染&lt;/li&gt;
&lt;li&gt;使用ECharts实现报表功能&lt;/li&gt;
&lt;li&gt;使用WebSocket实现推送服务&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day6675---爬虫开发" class="anchor" aria-hidden="true" href="#day6675---爬虫开发"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day66~75 - &lt;a href="./Day66-75"&gt;爬虫开发&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day66---网络爬虫和相关工具" class="anchor" aria-hidden="true" href="#day66---网络爬虫和相关工具"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day66 - &lt;a href="./Day66-75/66.%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%92%8C%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7.md"&gt;网络爬虫和相关工具&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;网络爬虫的概念及其应用领域&lt;/li&gt;
&lt;li&gt;网络爬虫的合法性探讨&lt;/li&gt;
&lt;li&gt;开发网络爬虫的相关工具&lt;/li&gt;
&lt;li&gt;一个爬虫程序的构成&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day67---数据采集和解析" class="anchor" aria-hidden="true" href="#day67---数据采集和解析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day67 - &lt;a href="./Day66-75/67.%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%92%8C%E8%A7%A3%E6%9E%90.md"&gt;数据采集和解析&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;数据采集的标准和三方库&lt;/li&gt;
&lt;li&gt;页面解析的三种方式：正则表达式解析 / XPath解析 / CSS选择器解析&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day68---存储数据" class="anchor" aria-hidden="true" href="#day68---存储数据"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day68 - &lt;a href="./Day66-75/68.%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE.md"&gt;存储数据&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;如何存储海量数据&lt;/li&gt;
&lt;li&gt;实现数据的缓存&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day69---并发下载" class="anchor" aria-hidden="true" href="#day69---并发下载"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day69 - &lt;a href="./Day66-75/69.%E5%B9%B6%E5%8F%91%E4%B8%8B%E8%BD%BD.md"&gt;并发下载&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;多线程和多进程&lt;/li&gt;
&lt;li&gt;异步I/O和协程&lt;/li&gt;
&lt;li&gt;async和await关键字的使用&lt;/li&gt;
&lt;li&gt;三方库aiohttp的应用&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day70---解析动态内容" class="anchor" aria-hidden="true" href="#day70---解析动态内容"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day70 - &lt;a href="./Day66-75/70.%E8%A7%A3%E6%9E%90%E5%8A%A8%E6%80%81%E5%86%85%E5%AE%B9.md"&gt;解析动态内容&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;JavaScript逆向工程&lt;/li&gt;
&lt;li&gt;使用Selenium获取动态内容&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day71---表单交互和验证码处理" class="anchor" aria-hidden="true" href="#day71---表单交互和验证码处理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day71 - &lt;a href="./Day66-75/71.%E8%A1%A8%E5%8D%95%E4%BA%A4%E4%BA%92%E5%92%8C%E9%AA%8C%E8%AF%81%E7%A0%81%E5%A4%84%E7%90%86.md"&gt;表单交互和验证码处理&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;自动提交表单&lt;/li&gt;
&lt;li&gt;Cookie池的应用&lt;/li&gt;
&lt;li&gt;验证码处理&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day72---scrapy入门" class="anchor" aria-hidden="true" href="#day72---scrapy入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day72 - &lt;a href="./Day66-75/72.Scrapy%E5%85%A5%E9%97%A8.md"&gt;Scrapy入门&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Scrapy爬虫框架概述&lt;/li&gt;
&lt;li&gt;安装和使用Scrapy&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day73---scrapy高级应用" class="anchor" aria-hidden="true" href="#day73---scrapy高级应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day73 - &lt;a href="./Day66-75/73.Scrapy%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8.md"&gt;Scrapy高级应用&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Spider的用法&lt;/li&gt;
&lt;li&gt;中间件的应用：下载中间件 / 蜘蛛中间件&lt;/li&gt;
&lt;li&gt;Scrapy对接Selenium抓取动态内容&lt;/li&gt;
&lt;li&gt;Scrapy部署到Docker&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day74---scrapy分布式实现" class="anchor" aria-hidden="true" href="#day74---scrapy分布式实现"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day74 - &lt;a href="./Day66-75/74.Scrapy%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E7%8E%B0.md"&gt;Scrapy分布式实现&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;分布式爬虫的原理&lt;/li&gt;
&lt;li&gt;Scrapy分布式实现&lt;/li&gt;
&lt;li&gt;使用Scrapyd实现分布式部署&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-day75---爬虫项目实战" class="anchor" aria-hidden="true" href="#day75---爬虫项目实战"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day75 - &lt;a href="./Day66-75/75.%E7%88%AC%E8%99%AB%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.md"&gt;爬虫项目实战&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;爬取招聘网站数据&lt;/li&gt;
&lt;li&gt;爬取房地产行业数据&lt;/li&gt;
&lt;li&gt;爬取二手车交易平台数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-day7690---数据处理和机器学习" class="anchor" aria-hidden="true" href="#day7690---数据处理和机器学习"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day76~90 - &lt;a href="./Day76-90"&gt;数据处理和机器学习&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-day76---机器学习基础" class="anchor" aria-hidden="true" href="#day76---机器学习基础"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day76 - &lt;a href="./Day76-90/76.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md"&gt;机器学习基础&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day77---pandas的应用" class="anchor" aria-hidden="true" href="#day77---pandas的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day77 - &lt;a href="./Day76-90/77.Pandas%E7%9A%84%E5%BA%94%E7%94%A8.md"&gt;Pandas的应用&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day78---numpy和scipy的应用" class="anchor" aria-hidden="true" href="#day78---numpy和scipy的应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day78 - &lt;a href="./Day76-90/78.NumPy%E5%92%8CSciPy%E7%9A%84%E5%BA%94%E7%94%A8"&gt;NumPy和SciPy的应用&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day79---matplotlib和数据可视化" class="anchor" aria-hidden="true" href="#day79---matplotlib和数据可视化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day79 - &lt;a href="./Day76-90/79.Matplotlib%E5%92%8C%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96"&gt;Matplotlib和数据可视化&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day80---k最近邻knn分类" class="anchor" aria-hidden="true" href="#day80---k最近邻knn分类"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day80 - &lt;a href="./Day76-90/80.k%E6%9C%80%E8%BF%91%E9%82%BB%E5%88%86%E7%B1%BB.md"&gt;k最近邻(KNN)分类&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day81---决策树" class="anchor" aria-hidden="true" href="#day81---决策树"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day81 - &lt;a href="./Day76-90/81.%E5%86%B3%E7%AD%96%E6%A0%91.md"&gt;决策树&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day82---贝叶斯分类" class="anchor" aria-hidden="true" href="#day82---贝叶斯分类"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day82 - &lt;a href="./Day76-90/82.%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB.md"&gt;贝叶斯分类&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day83---支持向量机svm" class="anchor" aria-hidden="true" href="#day83---支持向量机svm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day83 - &lt;a href="./Day76-90/83.%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.md"&gt;支持向量机(SVM)&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day84---k-均值聚类" class="anchor" aria-hidden="true" href="#day84---k-均值聚类"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day84 - &lt;a href="./Day76-90/84.K-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB.md"&gt;K-均值聚类&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day85---回归分析" class="anchor" aria-hidden="true" href="#day85---回归分析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day85 - &lt;a href="./Day76-90/85.%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90.md"&gt;回归分析&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day86---大数据分析入门" class="anchor" aria-hidden="true" href="#day86---大数据分析入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day86 - &lt;a href="./Day76-90/86.%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%85%A5%E9%97%A8.md"&gt;大数据分析入门&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day87---大数据分析进阶" class="anchor" aria-hidden="true" href="#day87---大数据分析进阶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day87 - &lt;a href="./Day76-90/87.%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%BF%9B%E9%98%B6.md"&gt;大数据分析进阶&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day88---tensorflow入门" class="anchor" aria-hidden="true" href="#day88---tensorflow入门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day88 - &lt;a href="./Day76-90/88.Tensorflow%E5%85%A5%E9%97%A8.md"&gt;Tensorflow入门&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day89---tensorflow实战" class="anchor" aria-hidden="true" href="#day89---tensorflow实战"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day89 - &lt;a href="./Day76-90/89.Tensorflow%E5%AE%9E%E6%88%98.md"&gt;Tensorflow实战&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-day90---推荐系统" class="anchor" aria-hidden="true" href="#day90---推荐系统"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day90 - &lt;a href="./Day76-90/90.%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.md"&gt;推荐系统&lt;/a&gt;&lt;/h4&gt;
&lt;h3&gt;&lt;a id="user-content-day91100---团队项目开发" class="anchor" aria-hidden="true" href="#day91100---团队项目开发"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Day91~100 - &lt;a href="./Day91-100"&gt;团队项目开发&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-第91天团队项目开发的问题和解决方案" class="anchor" aria-hidden="true" href="#第91天团队项目开发的问题和解决方案"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第91天：&lt;a href="./Day91-100/91.%E5%9B%A2%E9%98%9F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md"&gt;团队项目开发的问题和解决方案&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;软件过程模型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;经典过程模型（瀑布模型）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可行性分析（研究做还是不做），输出《可行性分析报告》。&lt;/li&gt;
&lt;li&gt;需求分析（研究做什么），输出《需求规格说明书》和产品界面原型图。&lt;/li&gt;
&lt;li&gt;概要设计和详细设计，输出概念模型图、物理模型图、类图、时序图等。&lt;/li&gt;
&lt;li&gt;编码 / 测试。&lt;/li&gt;
&lt;li&gt;上线 / 维护。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;敏捷开发（Scrum）- 产品所有者、Scrum Master、研发人员 - Sprint&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;产品的Backlog（用户故事、产品原型）。&lt;/li&gt;
&lt;li&gt;计划会议（评估和预算）。&lt;/li&gt;
&lt;li&gt;日常开发（站立会议、番茄工作法、结对编程、测试先行、代码重构……）。&lt;/li&gt;
&lt;li&gt;修复bug（问题描述、重现步骤、测试人员、被指派人）。&lt;/li&gt;
&lt;li&gt;评审会议（Showcase）。&lt;/li&gt;
&lt;li&gt;回顾会议（当前周期做得好和不好的地方）。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;补充：敏捷软件开发宣言&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;个体和互动&lt;/strong&gt; 高于 流程和工具&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;工作的软件&lt;/strong&gt; 高于 详尽的文档&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;客户合作&lt;/strong&gt; 高于 合同谈判&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;响应变化&lt;/strong&gt; 高于 遵循计划&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/agile-scrum-sprint-cycle.png"&gt;&lt;img src="./res/agile-scrum-sprint-cycle.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;角色：产品所有者（决定做什么，能对需求拍板的人）、团队负责人（解决各种问题，专注如何更好的工作，屏蔽外部对开发团队的影响）、开发团队（项目执行人员，具体指开发人员和测试人员）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;准备工作：商业案例和资金、合同、憧憬、初始产品需求、初始发布计划、入股、组建团队。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;敏捷团队通常人数为8-10人。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;工作量估算：将开发任务量化，包括原型、Logo设计、UI设计、前端开发等，尽量把每个工作分解到最小任务量，最小任务量标准为工作时间不能超过两天，然后估算总体项目时间。把每个任务都贴在白板上面，白板上分三部分：to do（待完成）、in progress（进行中）和done（已完成）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;项目团队组建&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;团队的构成和角色&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;说明：谢谢付祥英女士绘制了下面这张精美的公司组织架构图。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/company_architecture.png"&gt;&lt;img src="./res/company_architecture.png" alt="company_architecture" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;编程规范和代码审查（flake8、pylint）&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/pylint.png"&gt;&lt;img src="./res/pylint.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Python中的一些“惯例”（请参考&lt;a href="Python%E6%83%AF%E4%BE%8B.md"&gt;《Python惯例-如何编写Pythonic的代码》&lt;/a&gt;）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;影响代码可读性的原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;代码注释太少或者没有注释&lt;/li&gt;
&lt;li&gt;代码破坏了语言的最佳实践&lt;/li&gt;
&lt;li&gt;反模式编程（意大利面代码、复制-黏贴编程、自负编程、……）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;团队开发工具介绍&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;版本控制：Git、Mercury&lt;/li&gt;
&lt;li&gt;缺陷管理：&lt;a href="https://about.gitlab.com/" rel="nofollow"&gt;Gitlab&lt;/a&gt;、&lt;a href="http://www.redmine.org.cn/" rel="nofollow"&gt;Redmine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;敏捷闭环工具：&lt;a href="https://www.zentao.net/" rel="nofollow"&gt;禅道&lt;/a&gt;、&lt;a href="https://www.atlassian.com/software/jira/features" rel="nofollow"&gt;JIRA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;持续集成：&lt;a href="https://jenkins.io/" rel="nofollow"&gt;Jenkins&lt;/a&gt;、&lt;a href="https://travis-ci.org/" rel="nofollow"&gt;Travis-CI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;请参考&lt;a href="Day91-100/%E5%9B%A2%E9%98%9F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91.md"&gt;《团队项目开发》&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-项目选题和理解业务" class="anchor" aria-hidden="true" href="#项目选题和理解业务"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目选题和理解业务&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;选题范围设定&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CMS（用户端）：新闻聚合网站、问答/分享社区、影评/书评网站等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MIS（用户端+管理端）：KMS、KPI考核系统、HRS、CRM系统、供应链系统、仓储管理系统等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;App后台（管理端+数据接口）：二手交易类、报刊杂志类、小众电商类、新闻资讯类、旅游类、社交类、阅读类等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;其他类型：自身行业背景和工作经验、业务容易理解和把控。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;需求理解、模块划分和任务分配&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需求理解：头脑风暴和竞品分析。&lt;/li&gt;
&lt;li&gt;模块划分：画思维导图（XMind），每个模块是一个枝节点，每个具体的功能是一个叶节点（用动词表述），需要确保每个叶节点无法再生出新节点，确定每个叶子节点的重要性、优先级和工作量。&lt;/li&gt;
&lt;li&gt;任务分配：由项目负责人根据上面的指标为每个团队成员分配任务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/requirements_by_xmind.png"&gt;&lt;img src="./res/requirements_by_xmind.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;制定项目进度表（每日更新）&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;th&gt;人员&lt;/th&gt;
&lt;th&gt;状态&lt;/th&gt;
&lt;th&gt;完成&lt;/th&gt;
&lt;th&gt;工时&lt;/th&gt;
&lt;th&gt;计划开始&lt;/th&gt;
&lt;th&gt;实际开始&lt;/th&gt;
&lt;th&gt;计划结束&lt;/th&gt;
&lt;th&gt;实际结束&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;评论&lt;/td&gt;
&lt;td&gt;添加评论&lt;/td&gt;
&lt;td&gt;王大锤&lt;/td&gt;
&lt;td&gt;正在进行&lt;/td&gt;
&lt;td&gt;50%&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;删除评论&lt;/td&gt;
&lt;td&gt;王大锤&lt;/td&gt;
&lt;td&gt;等待&lt;/td&gt;
&lt;td&gt;0%&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;查看评论&lt;/td&gt;
&lt;td&gt;白元芳&lt;/td&gt;
&lt;td&gt;正在进行&lt;/td&gt;
&lt;td&gt;20%&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;需要进行代码审查&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;评论投票&lt;/td&gt;
&lt;td&gt;白元芳&lt;/td&gt;
&lt;td&gt;等待&lt;/td&gt;
&lt;td&gt;0%&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2018/8/8&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2018/8/8&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OOAD和数据库设计&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;UML（统一建模语言）的类图&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/uml-class-diagram.png"&gt;&lt;img src="./res/uml-class-diagram.png" alt="uml" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过模型创建表（正向工程）&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python manage.py makemigrations app
python manage.py migrate&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用PowerDesigner绘制物理模型图。&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./res/power-designer-pdm.png"&gt;&lt;img src="./res/power-designer-pdm.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过数据表创建模型（反向工程）&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python manage.py inspectdb &lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; app/models.py&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-第92天使用docker部署应用" class="anchor" aria-hidden="true" href="#第92天使用docker部署应用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第92天：&lt;a href="./Day91-100/92.%E4%BD%BF%E7%94%A8Docker%E9%83%A8%E7%BD%B2%E5%BA%94%E7%94%A8.md"&gt;使用Docker部署应用&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Docker简介&lt;/li&gt;
&lt;li&gt;安装Docker&lt;/li&gt;
&lt;li&gt;使用Docker创建容器（Nginx、MySQL、Redis、Gitlab、Jenkins）&lt;/li&gt;
&lt;li&gt;构建Docker镜像（Dockerfile的编写和相关指令）&lt;/li&gt;
&lt;li&gt;容器编排（Docker-compose）&lt;/li&gt;
&lt;li&gt;集群管理&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-第93天mysql性能优化" class="anchor" aria-hidden="true" href="#第93天mysql性能优化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第93天：&lt;a href="./Day91-100/93.MySQL%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.md"&gt;MySQL性能优化&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第94天网络api接口设计" class="anchor" aria-hidden="true" href="#第94天网络api接口设计"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第94天：&lt;a href="./Day91-100/94.%E7%BD%91%E7%BB%9CAPI%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1.md"&gt;网络API接口设计&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第95天使用django开发商业项目day91-10095使用django开发商业项目md" class="anchor" aria-hidden="true" href="#第95天使用django开发商业项目day91-10095使用django开发商业项目md"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第95天：[使用Django开发商业项目](./Day91-100/95.使用Django开发商业项	目.md)&lt;/h4&gt;
&lt;h5&gt;&lt;a id="user-content-项目开发中的公共问题" class="anchor" aria-hidden="true" href="#项目开发中的公共问题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目开发中的公共问题&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;数据库的配置（多数据库、主从复制、数据库路由）&lt;/li&gt;
&lt;li&gt;缓存的配置（分区缓存、键设置、超时设置、主从复制、故障恢复（哨兵））&lt;/li&gt;
&lt;li&gt;日志的配置&lt;/li&gt;
&lt;li&gt;分析和调试（Django-Debug-ToolBar）&lt;/li&gt;
&lt;li&gt;好用的Python模块（日期计算、图像处理、数据加密、三方API）&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-rest-api设计" class="anchor" aria-hidden="true" href="#rest-api设计"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;REST API设计&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;RESTful架构
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.ruanyifeng.com/blog/2011/09/restful.html" rel="nofollow"&gt;理解RESTful架构&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ruanyifeng.com/blog/2014/05/restful_api.html" rel="nofollow"&gt;RESTful API设计指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html" rel="nofollow"&gt;RESTful API最佳实践&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;API接口文档的撰写
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://rap2.taobao.org/" rel="nofollow"&gt;RAP2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://yapi.demo.qunar.com/" rel="nofollow"&gt;YAPI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.django-rest-framework.org/" rel="nofollow"&gt;django-REST-framework&lt;/a&gt;的应用&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-项目中的重点难点剖析" class="anchor" aria-hidden="true" href="#项目中的重点难点剖析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目中的重点难点剖析&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;使用缓存缓解数据库压力 - Redis&lt;/li&gt;
&lt;li&gt;使用消息队列做解耦合和削峰 - Celery + RabbitMQ&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-第96天软件测试和自动化测试" class="anchor" aria-hidden="true" href="#第96天软件测试和自动化测试"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第96天：&lt;a href="Day91-100/96.%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E5%92%8C%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95.md"&gt;软件测试和自动化测试&lt;/a&gt;&lt;/h4&gt;
&lt;h5&gt;&lt;a id="user-content-单元测试" class="anchor" aria-hidden="true" href="#单元测试"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;单元测试&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;测试的种类&lt;/li&gt;
&lt;li&gt;编写单元测试（unittest、pytest、nose2、tox、ddt、……）&lt;/li&gt;
&lt;li&gt;测试覆盖率（coverage）&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-项目部署" class="anchor" aria-hidden="true" href="#项目部署"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目部署&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;部署前的准备工作
&lt;ul&gt;
&lt;li&gt;关键设置（SECRET_KEY / DEBUG / ALLOWED_HOSTS / 缓存 / 数据库）&lt;/li&gt;
&lt;li&gt;HTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECURE&lt;/li&gt;
&lt;li&gt;日志相关配置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Linux常用命令回顾&lt;/li&gt;
&lt;li&gt;Linux常用服务的安装和配置&lt;/li&gt;
&lt;li&gt;uWSGI/Gunicorn和Nginx的使用
&lt;ul&gt;
&lt;li&gt;Gunicorn和uWSGI的比较
&lt;ul&gt;
&lt;li&gt;对于不需要大量定制化的简单应用程序，Gunicorn是一个不错的选择，uWSGI的学习曲线比Gunicorn要陡峭得多，Gunicorn的默认参数就已经能够适应大多数应用程序。&lt;/li&gt;
&lt;li&gt;uWSGI支持异构部署。&lt;/li&gt;
&lt;li&gt;由于Nginx本身支持uWSGI，在线上一般都将Nginx和uWSGI捆绑在一起部署，而且uWSGI属于功能齐全且高度定制的WSGI中间件。&lt;/li&gt;
&lt;li&gt;在性能上，Gunicorn和uWSGI其实表现相当。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;使用虚拟化技术（Docker）部署测试环境和生产环境&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-性能测试" class="anchor" aria-hidden="true" href="#性能测试"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;性能测试&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;AB的使用&lt;/li&gt;
&lt;li&gt;SQLslap的使用&lt;/li&gt;
&lt;li&gt;sysbench的使用&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;a id="user-content-自动化测试" class="anchor" aria-hidden="true" href="#自动化测试"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;自动化测试&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;使用Shell和Python进行自动化测试&lt;/li&gt;
&lt;li&gt;使用Selenium实现自动化测试
&lt;ul&gt;
&lt;li&gt;Selenium IDE&lt;/li&gt;
&lt;li&gt;Selenium WebDriver&lt;/li&gt;
&lt;li&gt;Selenium Remote Control&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;测试工具Robot Framework介绍&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-第97天电商网站技术要点剖析" class="anchor" aria-hidden="true" href="#第97天电商网站技术要点剖析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第97天：&lt;a href="./Day91-100/97.%E7%94%B5%E5%95%86%E7%BD%91%E7%AB%99%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9%E5%89%96%E6%9E%90.md"&gt;电商网站技术要点剖析&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第98天项目部署上线和性能调优" class="anchor" aria-hidden="true" href="#第98天项目部署上线和性能调优"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第98天：&lt;a href="./Day91-100/98.%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E4%B8%8A%E7%BA%BF%E5%92%8C%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98.md"&gt;项目部署上线和性能调优&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;MySQL数据库调优&lt;/li&gt;
&lt;li&gt;Web服务器性能优化
&lt;ul&gt;
&lt;li&gt;Nginx负载均衡配置&lt;/li&gt;
&lt;li&gt;Keepalived实现高可用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;代码性能调优
&lt;ul&gt;
&lt;li&gt;多线程&lt;/li&gt;
&lt;li&gt;异步化&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;静态资源访问优化
&lt;ul&gt;
&lt;li&gt;云存储&lt;/li&gt;
&lt;li&gt;CDN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-第99天面试中的公共问题" class="anchor" aria-hidden="true" href="#第99天面试中的公共问题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第99天：&lt;a href="./Day91-100/99.%E9%9D%A2%E8%AF%95%E4%B8%AD%E7%9A%84%E5%85%AC%E5%85%B1%E9%97%AE%E9%A2%98.md"&gt;面试中的公共问题&lt;/a&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;a id="user-content-第100天python面试题集" class="anchor" aria-hidden="true" href="#第100天python面试题集"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;第100天：&lt;a href="./Day91-100/100.Python%E9%9D%A2%E8%AF%95%E9%A2%98%E9%9B%86.md"&gt;Python面试题集&lt;/a&gt;&lt;/h4&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jackfrued</author><guid isPermaLink="false">https://github.com/jackfrued/Python-100-Days</guid><pubDate>Sat, 30 Nov 2019 00:08:00 GMT</pubDate></item><item><title>ageron/handson-ml #9 in Jupyter Notebook, Today</title><link>https://github.com/ageron/handson-ml</link><description>&lt;p&gt;&lt;i&gt;A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-notebooks" class="anchor" aria-hidden="true" href="#machine-learning-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning Notebooks&lt;/h1&gt;
&lt;p&gt;This project aims at teaching you the fundamentals of Machine Learning in
python. It contains the example code and solutions to the exercises in my O'Reilly book &lt;a href="http://shop.oreilly.com/product/0636920052289.do" rel="nofollow"&gt;Hands-on Machine Learning with Scikit-Learn and TensorFlow&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://shop.oreilly.com/product/0636920052289.do" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/01556f925ba0ec59c669262141e65e39b92c5da0/687474703a2f2f616b616d6169636f766572732e6f7265696c6c792e636f6d2f696d616765732f303633363932303035323238392f6361742e676966" alt="book" data-canonical-src="http://akamaicovers.oreilly.com/images/0636920052289/cat.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Simply open the &lt;a href="http://jupyter.org/" rel="nofollow"&gt;Jupyter&lt;/a&gt; notebooks you are interested in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using &lt;a href="http://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/index.ipynb" rel="nofollow"&gt;jupyter.org's notebook viewer&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;note: &lt;a href="https://github.com/ageron/handson-ml/blob/master/index.ipynb"&gt;github.com's notebook viewer&lt;/a&gt; also works but it is slower and the math formulas are not displayed correctly,&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;by cloning this repository and running Jupyter locally. This option lets you play around with the code. In this case, follow the installation instructions below,&lt;/li&gt;
&lt;li&gt;or by running the notebooks in &lt;a href="https://beta.deepnote.com" rel="nofollow"&gt;Deepnote&lt;/a&gt;. This allows you to play around with the code online in your browser. For example, here's a link to the first chapter: &lt;a href="https://beta.deepnote.com/launch?template=data-science&amp;amp;url=https%3A//github.com/ageron/handson-ml/blob/master/02_end_to_end_machine_learning_project.ipynb" rel="nofollow"&gt;&lt;img height="22" src="https://camo.githubusercontent.com/c3b9bd12a99f8de3301018192105256209bcf800/68747470733a2f2f626574612e646565706e6f74652e636f6d2f627574746f6e732f6c61756e63682d696e2d646565706e6f74652e737667" data-canonical-src="https://beta.deepnote.com/buttons/launch-in-deepnote.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h1&gt;
&lt;p&gt;First, you will need to install &lt;a href="https://git-scm.com/" rel="nofollow"&gt;git&lt;/a&gt;, if you don't have it already.&lt;/p&gt;
&lt;p&gt;Next, clone this repository by opening a terminal and typing the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd $HOME  # or any other development directory you prefer
$ git clone https://github.com/ageron/handson-ml.git
$ cd handson-ml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you do not want to install git, you can instead download &lt;a href="https://github.com/ageron/handson-ml/archive/master.zip"&gt;master.zip&lt;/a&gt;, unzip it, rename the resulting directory to &lt;code&gt;handson-ml&lt;/code&gt; and move it to your development directory.&lt;/p&gt;
&lt;p&gt;If you want to go through chapter 16 on Reinforcement Learning, you will need to &lt;a href="https://gym.openai.com/docs" rel="nofollow"&gt;install OpenAI gym&lt;/a&gt; and its dependencies for Atari simulations.&lt;/p&gt;
&lt;p&gt;If you are familiar with Python and you know how to install Python libraries, go ahead and install the libraries listed in &lt;code&gt;requirements.txt&lt;/code&gt; and jump to the &lt;a href="#starting-jupyter"&gt;Starting Jupyter&lt;/a&gt; section. If you need detailed instructions, please read on.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-python--required-libraries" class="anchor" aria-hidden="true" href="#python--required-libraries"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python &amp;amp; Required Libraries&lt;/h2&gt;
&lt;p&gt;Of course, you obviously need Python. Python 3 is already preinstalled on many systems nowadays. You can check which version you have by typing the following command (you may need to replace &lt;code&gt;python3&lt;/code&gt; with &lt;code&gt;python&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 --version  # for Python 3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Any Python 3 version should be fine, preferably 3.5 or above. If you don't have Python 3, I recommend installing it. To do so, you have several options: on Windows or MacOSX, you can just download it from &lt;a href="https://www.python.org/downloads/" rel="nofollow"&gt;python.org&lt;/a&gt;. On MacOSX, you can alternatively use &lt;a href="https://www.macports.org/" rel="nofollow"&gt;MacPorts&lt;/a&gt; or &lt;a href="https://brew.sh/" rel="nofollow"&gt;Homebrew&lt;/a&gt;. If you are using Python 3.6 on MacOSX, you need to run the following command to install the &lt;code&gt;certifi&lt;/code&gt; package of certificates because Python 3.6 on MacOSX has no certificates to validate SSL connections (see this &lt;a href="https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error" rel="nofollow"&gt;StackOverflow question&lt;/a&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ /Applications/Python\ 3.6/Install\ Certificates.command
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On Linux, unless you know what you are doing, you should use your system's packaging system. For example, on Debian or Ubuntu, type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt-get update
$ sudo apt-get install python3 python3-pip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another option is to download and install &lt;a href="https://www.continuum.io/downloads" rel="nofollow"&gt;Anaconda&lt;/a&gt;. This is a package that includes both Python and many scientific libraries. You should prefer the Python 3 version.&lt;/p&gt;
&lt;p&gt;If you choose to use Anaconda, read the next section, or else jump to the &lt;a href="#using-pip"&gt;Using pip&lt;/a&gt; section.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-anaconda" class="anchor" aria-hidden="true" href="#using-anaconda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using Anaconda&lt;/h2&gt;
&lt;p&gt;Once you have &lt;a href="https://docs.anaconda.com/anaconda/install/" rel="nofollow"&gt;installed Anaconda&lt;/a&gt; (or Miniconda), you can run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda env create -f environment.yml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will give you a conda environment named &lt;code&gt;mlbook&lt;/code&gt;, ready to use! Just activate it and you will have everything setup
for you:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda activate mlbook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You are all set! Next, jump to the &lt;a href="#starting-jupyter"&gt;Starting Jupyter&lt;/a&gt; section.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-pip" class="anchor" aria-hidden="true" href="#using-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using pip&lt;/h2&gt;
&lt;p&gt;If you are not using Anaconda, you need to install several scientific Python libraries that are necessary for this project, in particular NumPy, Matplotlib, Pandas, Jupyter and TensorFlow (and a few others). For this, you can either use Python's integrated packaging system, pip, or you may prefer to use your system's own packaging system (if available, e.g. on Linux, or on MacOSX when using MacPorts or Homebrew). The advantage of using pip is that it is easy to create multiple isolated Python environments with different libraries and different library versions (e.g. one environment for each project). The advantage of using your system's packaging system is that there is less risk of having conflicts between your Python libraries and your system's other packages. Since I have many projects with different library requirements, I prefer to use pip with isolated environments. Moreover, the pip packages are usually the most recent ones available, while Anaconda and system packages often lag behind a bit.&lt;/p&gt;
&lt;p&gt;These are the commands you need to type in a terminal if you want to use pip to install the required libraries. Note: in all the following commands, if you chose to use Python 2 rather than Python 3, you must replace &lt;code&gt;pip3&lt;/code&gt; with &lt;code&gt;pip&lt;/code&gt;, and &lt;code&gt;python3&lt;/code&gt; with &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First you need to make sure you have the latest version of pip installed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --user --upgrade pip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;--user&lt;/code&gt; option will install the latest version of pip only for the current user. If you prefer to install it system wide (i.e. for all users), you must have administrator rights (e.g. use &lt;code&gt;sudo python3&lt;/code&gt; instead of &lt;code&gt;python3&lt;/code&gt; on Linux), and you should remove the &lt;code&gt;--user&lt;/code&gt; option. The same is true of the command below that uses the &lt;code&gt;--user&lt;/code&gt; option.&lt;/p&gt;
&lt;p&gt;Next, you can optionally create an isolated environment. This is recommended as it makes it possible to have a different environment for each project (e.g. one for this project), with potentially very different libraries, and different versions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --user --upgrade virtualenv
$ python3 -m virtualenv -p `which python3` env
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates a new directory called &lt;code&gt;env&lt;/code&gt; in the current directory, containing an isolated Python environment based on Python 3. If you installed multiple versions of Python 3 on your system, you can replace &lt;code&gt;`which python3`&lt;/code&gt; with the path to the Python executable you prefer to use.&lt;/p&gt;
&lt;p&gt;Now you must activate this environment. You will need to run this command every time you want to use this environment.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ source ./env/bin/activate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On Windows, the command is slightly different:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ .\env\Scripts\activate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, use pip to install the required python packages. If you are not using virtualenv, you should add the &lt;code&gt;--user&lt;/code&gt; option (alternatively you could install the libraries system-wide, but this will probably require administrator rights, e.g. using &lt;code&gt;sudo pip3&lt;/code&gt; instead of &lt;code&gt;pip3&lt;/code&gt; on Linux).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --upgrade -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great! You're all set, you just need to start Jupyter now.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-starting-jupyter" class="anchor" aria-hidden="true" href="#starting-jupyter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Starting Jupyter&lt;/h2&gt;
&lt;p&gt;Okay! You can now start Jupyter, simply type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This should open up your browser, and you should see Jupyter's tree view, with the contents of the current directory. If your browser does not open automatically, visit &lt;a href="http://127.0.0.1:8888/tree" rel="nofollow"&gt;127.0.0.1:8888&lt;/a&gt;. Click on &lt;code&gt;index.ipynb&lt;/code&gt; to get started!&lt;/p&gt;
&lt;p&gt;Congrats! You are ready to learn Machine Learning, hands on!&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributors&lt;/h1&gt;
&lt;p&gt;I would like to thank everyone who contributed to this project, either by providing useful feedback, filing issues or submitting Pull Requests. Special thanks go to Steven Bunkley and Ziembla who created the &lt;code&gt;docker&lt;/code&gt; directory.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ageron</author><guid isPermaLink="false">https://github.com/ageron/handson-ml</guid><pubDate>Sat, 30 Nov 2019 00:09:00 GMT</pubDate></item><item><title>SophonPlus/ChineseNlpCorpus #10 in Jupyter Notebook, Today</title><link>https://github.com/SophonPlus/ChineseNlpCorpus</link><description>&lt;p&gt;&lt;i&gt;搜集、整理、发布 中文 自然语言处理 语料/数据集，与 有志之士 共同 促进 中文 自然语言处理 的 发展。&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-chinesenlpcorpus" class="anchor" aria-hidden="true" href="#chinesenlpcorpus"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ChineseNlpCorpus&lt;/h1&gt;
&lt;p&gt;搜集、整理、发布 中文 自然语言处理 语料/数据集，与 有志之士 共同 促进 中文 自然语言处理 的 发展。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-情感观点评论-倾向性分析" class="anchor" aria-hidden="true" href="#情感观点评论-倾向性分析"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;情感/观点/评论 倾向性分析&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;数据集&lt;/th&gt;
&lt;th&gt;数据概览&lt;/th&gt;
&lt;th&gt;下载地址&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ChnSentiCorp_htl_all&lt;/td&gt;
&lt;td&gt;7000 多条酒店评论数据，5000 多条正向评论，2000 多条负向评论&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/ChnSentiCorp_htl_all/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;waimai_10k&lt;/td&gt;
&lt;td&gt;某外卖平台收集的用户评价，正向 4000 条，负向 约 8000 条&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/waimai_10k/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;online_shopping_10_cats&lt;/td&gt;
&lt;td&gt;10 个类别，共 6 万多条评论数据，正、负向评论各约 3 万条，&lt;br&gt; 包括书籍、平板、手机、水果、洗发水、热水器、蒙牛、衣服、计算机、酒店&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/online_shopping_10_cats/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;weibo_senti_100k&lt;/td&gt;
&lt;td&gt;10 万多条，带情感标注 新浪微博，正负向评论约各 5 万条&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/weibo_senti_100k/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;simplifyweibo_4_moods&lt;/td&gt;
&lt;td&gt;36 万多条，带情感标注 新浪微博，包含 4 种情感，&lt;br&gt; 其中喜悦约 20 万条，愤怒、厌恶、低落各约 5 万条&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/simplifyweibo_4_moods/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;dmsc_v2&lt;/td&gt;
&lt;td&gt;28 部电影，超 70 万 用户，超 200 万条 评分/评论 数据&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/dmsc_v2/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;yf_dianping&lt;/td&gt;
&lt;td&gt;24 万家餐馆，54 万用户，440 万条评论/评分数据&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/yf_dianping/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;yf_amazon&lt;/td&gt;
&lt;td&gt;52 万件商品，1100 多个类目，142 万用户，720 万条评论/评分数据&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/yf_amazon/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-中文命名实体识别" class="anchor" aria-hidden="true" href="#中文命名实体识别"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;中文命名实体识别&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;数据集&lt;/th&gt;
&lt;th&gt;数据概览&lt;/th&gt;
&lt;th&gt;下载地址&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;dh_msra&lt;/td&gt;
&lt;td&gt;5 万多条中文命名实体识别标注数据（包括地点、机构、人物）&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/dh_msra/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-推荐系统" class="anchor" aria-hidden="true" href="#推荐系统"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;推荐系统&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;数据集&lt;/th&gt;
&lt;th&gt;数据概览&lt;/th&gt;
&lt;th&gt;下载地址&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ez_douban&lt;/td&gt;
&lt;td&gt;5 万多部电影（3 万多有电影名称，2 万多没有电影名称），2.8 万 用户，280 万条评分数据&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/ez_douban/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;dmsc_v2&lt;/td&gt;
&lt;td&gt;28 部电影，超 70 万 用户，超 200 万条 评分/评论 数据&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/dmsc_v2/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;yf_dianping&lt;/td&gt;
&lt;td&gt;24 万家餐馆，54 万用户，440 万条评论/评分数据&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/yf_dianping/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;yf_amazon&lt;/td&gt;
&lt;td&gt;52 万件商品，1100 多个类目，142 万用户，720 万条评论/评分数据&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/yf_amazon/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-faq-问答系统" class="anchor" aria-hidden="true" href="#faq-问答系统"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FAQ 问答系统&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;数据集&lt;/th&gt;
&lt;th&gt;数据概览&lt;/th&gt;
&lt;th&gt;下载地址&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;保险知道&lt;/td&gt;
&lt;td&gt;8000 多条保险行业问答数据，包括用户提问、网友回答、最佳回答&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/baoxianzhidao/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;安徽电信知道&lt;/td&gt;
&lt;td&gt;15.6 万条电信问答数据，包括用户提问、网友回答、最佳回答&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/anhuidianxinzhidao/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;金融知道&lt;/td&gt;
&lt;td&gt;77 万条金融行业问答数据，包括用户提问、网友回答、最佳回答&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/financezhidao/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;法律知道&lt;/td&gt;
&lt;td&gt;3.6 万条法律问答数据，包括用户提问、网友回答、最佳回答&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/lawzhidao/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;联通知道&lt;/td&gt;
&lt;td&gt;20.3 万条联通问答数据，包括用户提问、网友回答、最佳回答&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/liantongzhidao/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;农行知道&lt;/td&gt;
&lt;td&gt;4 万条农业银行问答数据，包括用户提问、网友回答、最佳回答&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/nonghangzhidao/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;保险知道&lt;/td&gt;
&lt;td&gt;58.8 万条保险行业问答数据，包括用户提问、网友回答、最佳回答&lt;/td&gt;
&lt;td&gt;&lt;a href="./datasets/baoxianzhidao/intro.ipynb"&gt;点击查看&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-加入我们" class="anchor" aria-hidden="true" href="#加入我们"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;加入我们&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;愿景：以人工智能产品和技术服务 30 亿人&lt;/li&gt;
&lt;li&gt;团队：极客精神、技术驱动，做有温度的技术，让世界更美好&lt;/li&gt;
&lt;li&gt;产品：面向细分行业领域的自动营销机器人，客户需求旺盛，产品前景无限&lt;/li&gt;
&lt;li&gt;职位：&lt;a href="./docs/recruit/researcher.md"&gt;自然语言人机交互应用研究&lt;/a&gt;、&lt;a href="./docs/recruit/engineer.md"&gt;自然语言处理算法工程师&lt;/a&gt;、&lt;a href="./docs/recruit/architect.md"&gt;系统架构师（人工智能产品）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/images/recruit/recruit_banner.png"&gt;&lt;img src="./docs/images/recruit/recruit_banner.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>SophonPlus</author><guid isPermaLink="false">https://github.com/SophonPlus/ChineseNlpCorpus</guid><pubDate>Sat, 30 Nov 2019 00:10:00 GMT</pubDate></item><item><title>chenyuntc/pytorch-book #11 in Jupyter Notebook, Today</title><link>https://github.com/chenyuntc/pytorch-book</link><description>&lt;p&gt;&lt;i&gt;PyTorch tutorials and fun projects including neural talk, neural style, poem writing, anime generation &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;这是书籍《深度学习框架PyTorch：入门与实践》的对应代码，但是也可以作为一个独立的PyTorch入门指南和教程。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-更新说明" class="anchor" aria-hidden="true" href="#更新说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;更新说明&lt;/h2&gt;
&lt;p&gt;Working on migration to Pytorch 1.0, stay tuned!&lt;/p&gt;
&lt;p&gt;已更新到&lt;strong&gt;pytorch 0.4.1 (不是0.4.0)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;已更新到&lt;strong&gt;pytorch 0.4.1 (不是0.4.0)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;已更新到&lt;strong&gt;pytorch 0.4.1 (不是0.4.0)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当前版本的代码是基于pytorch 0.4.1， 如果想使用旧版的 请 &lt;code&gt;git checkout v0.2&lt;/code&gt; 或者 &lt;code&gt;git checkout v0.3&lt;/code&gt;。旧版代码有更好的python2/python3 兼容，CPU/GPU兼容测试。 新版的代码未经过完整测试，已在GPU和python3 下测试通过。但是理论上在python2和CPU上不应该有太多的问题。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-内容" class="anchor" aria-hidden="true" href="#内容"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;内容&lt;/h2&gt;
&lt;p&gt;该书（教程/仓库）的内容如图所示：
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e145e8ea41382f9d5400613da168b4051af115b7/687474703a2f2f377a683433722e636f6d322e7a302e676c622e636c6f7564646e2e636f6d2f64656c2f6d696e646d61702e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e145e8ea41382f9d5400613da168b4051af115b7/687474703a2f2f377a683433722e636f6d322e7a302e676c622e636c6f7564646e2e636f6d2f64656c2f6d696e646d61702e706e67" alt="思维导图" data-canonical-src="http://7zh43r.com2.z0.glb.clouddn.com/del/mindmap.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以看出本教程可以分为两部分：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基础部分&lt;/strong&gt;（前五章）讲解PyTorch内容，这部份介绍了PyTorch中主要的的模块，和深度学习中常用的一些工具。对于这部分内容，这里利用Jupyter Notebook作为教学工具，读者可以结合notebook修改运行，反复实验。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第二章介绍如何安装PyTorch和配置学习环境。同时提供了一个快速入门教程，基于官方的教程简化并更新内容，读者可以花费大约1到2小时的时间快速完成入门任务，而后根据需求再选择深入阅读后续相关章节的内容。&lt;/li&gt;
&lt;li&gt;第三章介绍了PyTorch中多维数组Tensor和动态图autograd/Variable的使用，并配以例子，让读者分别使用Tensor和autograd实现线性回归，比较二者的不同点。除了介绍这二者的基础使用之外，本章还对Tensor的底层设计，以及autograd的计算图原理进行比较深入分析，希望能使得读者能对这些底层知识有更全面的掌握。&lt;/li&gt;
&lt;li&gt;第四章介绍了PyTorch中神经网络模块nn的基础用法，同时讲解了神经网络中“层”，“损失函数”，“优化器”等，最后带领读者用不到50行的代码搭建出曾夺得ImageNet冠军的ResNet。&lt;/li&gt;
&lt;li&gt;第五章介绍了PyTorch中数据加载，GPU加速，持久化和可视化等相关工具。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;实战部分&lt;/strong&gt;（第六到十章）利用PyTorch实现了几个酷炫有趣的应用，对于这部分的内容，本仓库给出完整的实现代码，并提供预训练好的模型作为demo，供读者测试。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第六章是承上启下的一章，这一章的目标不是教会读者新函数，新知识，而是结合Kaggle中一个经典的比赛，实现一个深度学习中比较简单的图像二分类问题。在实现过程中，带领读者复习前五章的知识，并提出代码规范以合理的组织程序，代码，使得程序更加可读，可维护。第六章还介绍了在PyTorch中如何进行debug。&lt;/li&gt;
&lt;li&gt;第七章为读者讲解了当前最火爆的生成对抗网络（GAN），带领读者从头实现一个动漫头像生成器，能够利用GAN生成风格多变的动漫头像。&lt;/li&gt;
&lt;li&gt;第八章为读者讲解了风格迁移的相关知识，并带领读者实现风格迁移网络，将自己的照片变成高大上的名画。&lt;/li&gt;
&lt;li&gt;第九章为读者讲解了一些自然语言处理的基础知识，并讲解了CharRNN的原理。而后利用收集了几万首唐诗，训练出了一个可以自动写诗歌的小程序。这个小程序可以控制生成诗歌的&lt;strong&gt;格式&lt;/strong&gt;，&lt;strong&gt;意境&lt;/strong&gt;，还能生成&lt;strong&gt;藏头诗&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;第十章为读者介绍了图像描述任务，并以最新的AI Challenger比赛的数据为例，带领读者实现了一个可以进行简单图像描述的的小程序。&lt;/li&gt;
&lt;li&gt;第十一章（&lt;strong&gt;新增，实验性&lt;/strong&gt;） 由&lt;a href="https://github.com/Diamondfan"&gt;Diamondfan&lt;/a&gt; 编写的语音识别。完善了本项目（本项目已囊括图像，文本，语音三大领域的例子）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Notebook中的文字描述内容属于本书的初稿，有描述不通顺，错别字之处还请谅解&lt;/strong&gt;。本打算删除notebook中描述的内容，只留下代码，但为了方便读者阅读学习，最终还是决定留下。 我会抽空根据书中内容逐字校对这部分内容，但并不对此并不提供具体时间点。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-是否需要买书" class="anchor" aria-hidden="true" href="#是否需要买书"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;是否需要买书&lt;/h2&gt;
&lt;p&gt;书&lt;strong&gt;不是必要的&lt;/strong&gt;，这个仓库包含书中50%以上的文字内容，90%以上的代码，尤其是前几章入门内容，几乎是完全保留了书中的讲解内容。读者即使不买书也能正常使用本教程。&lt;/p&gt;
&lt;p&gt;&lt;del&gt;如果你觉得纸质书的优势吸引你，不妨小破费一笔，支持一下作者这大半年来的工作。同时为了尽可能的方便读者，笔者还专门开通腾讯云的服务，用以保存教程中用到的部分模型，预处理的数据和部分大文件。&lt;/del&gt;
书中的部分内容已经过时，以此仓库内容为准。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-代码说明" class="anchor" aria-hidden="true" href="#代码说明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;代码说明&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;代码主要在python3下测试得到最终结果，python2暂未测试。v0.2和v0.3 分支的代码同时经过严格测试支持python2/python3&lt;/li&gt;
&lt;li&gt;实战部分代码同时在GPU和CPU环境下测试通过&lt;/li&gt;
&lt;li&gt;代码已更新兼容到PyTorch &lt;code&gt;0.4.1&lt;/code&gt;, 后续会考虑兼容 &lt;code&gt;v1.0&lt;/code&gt;，但暂无确切时间点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你想在PyTorch 0.2.0或0.3下运行,请&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git checkout v0.2 # v0.3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果有任何不当，或者有待改进的地方，欢迎读者开issue讨论，或者提交pull request。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-环境配置" class="anchor" aria-hidden="true" href="#环境配置"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;环境配置&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;安装&lt;a href="http://pytorch.org" rel="nofollow"&gt;PyTorch&lt;/a&gt;，请从官网选择指定的版本安装即可，一键安装（即使你使用anaconda，也建议使用pip）。更多的安装方式请参阅书中说明。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;克隆仓库&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;git clone https:&lt;span class="pl-k"&gt;//&lt;/span&gt;github.com&lt;span class="pl-k"&gt;/&lt;/span&gt;chenyuntc&lt;span class="pl-k"&gt;/&lt;/span&gt;PyTorch&lt;span class="pl-k"&gt;-&lt;/span&gt;book.git&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装第三方依赖包&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;cd pytorch&lt;span class="pl-k"&gt;-&lt;/span&gt;book &lt;span class="pl-ii"&gt;&amp;amp;&amp;amp;&lt;/span&gt; pip install &lt;span class="pl-k"&gt;-&lt;/span&gt;r requirements.txt&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-visdom打不开及其解决方案" class="anchor" aria-hidden="true" href="#visdom打不开及其解决方案"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Visdom打不开及其解决方案&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;新版的visdom已经解决了这个问题,只需要升级即可&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install --upgrade visdom
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;之前的&lt;a href="https://github.com/chenyuntc/pytorch-book/blob/2c8366137b691aaa8fbeeea478cc1611c09e15f5/README.md#visdom%E6%89%93%E4%B8%8D%E5%BC%80%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"&gt;解决方案&lt;/a&gt; 不再需要，已删除。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-_" class="anchor" aria-hidden="true" href="#_"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;^_^&lt;/h2&gt;
&lt;p&gt;有任何bug，解释不清楚的地方或者是困惑，欢迎开issue&lt;/p&gt;
&lt;p&gt;欢迎pull requests&lt;/p&gt;
&lt;p&gt;Happy Coding!&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0376580818bbc47cd4b2f29ab6ca684122ba6e9f/687474703a2f2f696d6731342e333630627579696d672e636f6d2f6e312f6a66732f7431333333392f33322f323436333733303139382f3231373438332f65383134386336622f35613431323737644e62643134373063312e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/0376580818bbc47cd4b2f29ab6ca684122ba6e9f/687474703a2f2f696d6731342e333630627579696d672e636f6d2f6e312f6a66732f7431333333392f33322f323436333733303139382f3231373438332f65383134386336622f35613431323737644e62643134373063312e6a7067" alt="" data-canonical-src="http://img14.360buyimg.com/n1/jfs/t13339/32/2463730198/217483/e8148c6b/5a41277dNbd1470c1.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://search.jd.com/Search?keyword=pytorch%20%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AE%9E%E8%B7%B5&amp;amp;enc=utf-8&amp;amp;wq=pytorch%20%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AE%9E%E8%B7%B5&amp;amp;pvid=8b0d91d7108845ad8cbaf596326f3eb3" rel="nofollow"&gt;京东购买链接&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://search.dangdang.com/?key=pytorch%20%C8%EB%C3%C5%D3%EB%CA%B5%BC%F9&amp;amp;act=input" rel="nofollow"&gt;当当购买链接&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>chenyuntc</author><guid isPermaLink="false">https://github.com/chenyuntc/pytorch-book</guid><pubDate>Sat, 30 Nov 2019 00:11:00 GMT</pubDate></item><item><title>facebookresearch/InferSent #12 in Jupyter Notebook, Today</title><link>https://github.com/facebookresearch/InferSent</link><description>&lt;p&gt;&lt;i&gt;InferSent sentence embeddings&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-infersent" class="anchor" aria-hidden="true" href="#infersent"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;InferSent&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;InferSent&lt;/em&gt; is a &lt;em&gt;sentence embeddings&lt;/em&gt; method that provides semantic representations for English sentences. It is trained on natural language inference data and generalizes well to many different tasks.&lt;/p&gt;
&lt;p&gt;We provide our pre-trained English sentence encoder from &lt;a href="https://arxiv.org/abs/1705.02364" rel="nofollow"&gt;our paper&lt;/a&gt; and our &lt;a href="https://github.com/facebookresearch/SentEval"&gt;SentEval&lt;/a&gt; evaluation toolkit.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recent changes&lt;/strong&gt;: Removed train_nli.py and only kept pretrained models for simplicity. Reason is I do not have time anymore to maintain the repo beyond simple scripts to get sentence embeddings.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h2&gt;
&lt;p&gt;This code is written in python. Dependencies include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python 2/3&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pytorch.org/" rel="nofollow"&gt;Pytorch&lt;/a&gt; (recent version)&lt;/li&gt;
&lt;li&gt;NLTK &amp;gt;= 3&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-download-word-vectors" class="anchor" aria-hidden="true" href="#download-word-vectors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Download word vectors&lt;/h2&gt;
&lt;p&gt;Download &lt;a href="https://nlp.stanford.edu/projects/glove/" rel="nofollow"&gt;GloVe&lt;/a&gt; (V1) or &lt;a href="https://fasttext.cc/docs/en/english-vectors.html" rel="nofollow"&gt;fastText&lt;/a&gt; (V2) vectors:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;mkdir GloVe
curl -Lo GloVe/glove.840B.300d.zip http://nlp.stanford.edu/data/glove.840B.300d.zip
unzip GloVe/glove.840B.300d.zip -d GloVe/
mkdir fastText
curl -Lo fastText/crawl-300d-2M.vec.zip https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip
unzip fastText/crawl-300d-2M.vec.zip -d fastText/&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-use-our-sentence-encoder" class="anchor" aria-hidden="true" href="#use-our-sentence-encoder"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Use our sentence encoder&lt;/h2&gt;
&lt;p&gt;We provide a simple interface to encode English sentences. &lt;strong&gt;See &lt;a href="https://github.com/facebookresearch/InferSent/blob/master/demo.ipynb"&gt;&lt;strong&gt;demo.ipynb&lt;/strong&gt;&lt;/a&gt;
for a practical example.&lt;/strong&gt; Get started with the following steps:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;0.0) Download our InferSent models (V1 trained with GloVe, V2 trained with fastText)[147MB]:&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;mkdir encoder
curl -Lo encoder/infersent1.pkl https://dl.fbaipublicfiles.com/infersent/infersent1.pkl
curl -Lo encoder/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that infersent1 is trained with GloVe (which have been trained on text preprocessed with the PTB tokenizer) and infersent2 is trained with fastText (which have been trained on text preprocessed with the MOSES tokenizer). The latter also removes the padding of zeros with max-pooling which was inconvenient when embedding sentences outside of their batches.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;0.1) Make sure you have the NLTK tokenizer by running the following once:&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; nltk
nltk.download(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;punkt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;1) &lt;a href="https://github.com/facebookresearch/InferSent/blob/master/encoder/demo.ipynb"&gt;Load our pre-trained model&lt;/a&gt; (in encoder/):&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; models &lt;span class="pl-k"&gt;import&lt;/span&gt; InferSent
V &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;2&lt;/span&gt;
&lt;span class="pl-c1"&gt;MODEL_PATH&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;encoder/infersent&lt;span class="pl-c1"&gt;%s&lt;/span&gt;.pkl&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%&lt;/span&gt; V
params_model &lt;span class="pl-k"&gt;=&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bsize&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;64&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;word_emb_dim&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;300&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;enc_lstm_dim&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;2048&lt;/span&gt;,
                &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pool_type&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;max&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;dpout_model&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;0.0&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;version&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: V}
infersent &lt;span class="pl-k"&gt;=&lt;/span&gt; InferSent(params_model)
infersent.load_state_dict(torch.load(&lt;span class="pl-c1"&gt;MODEL_PATH&lt;/span&gt;))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;2) Set word vector path for the model:&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;W2V_PATH&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;fastText/crawl-300d-2M.vec&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
infersent.set_w2v_path(&lt;span class="pl-c1"&gt;W2V_PATH&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;3) Build the vocabulary of word vectors (i.e keep only those needed):&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;infersent.build_vocab(sentences, &lt;span class="pl-v"&gt;tokenize&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where &lt;em&gt;sentences&lt;/em&gt; is your list of &lt;strong&gt;n&lt;/strong&gt; sentences. You can update your vocabulary using &lt;em&gt;infersent.update_vocab(sentences)&lt;/em&gt;, or directly load the &lt;strong&gt;K&lt;/strong&gt; most common English words with &lt;em&gt;infersent.build_vocab_k_words(K=100000)&lt;/em&gt;.
If &lt;strong&gt;tokenize&lt;/strong&gt; is True (by default), sentences will be tokenized using NTLK.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;4) Encode your sentences (list of &lt;em&gt;n&lt;/em&gt; sentences):&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;embeddings &lt;span class="pl-k"&gt;=&lt;/span&gt; infersent.encode(sentences, &lt;span class="pl-v"&gt;tokenize&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This outputs a numpy array with &lt;em&gt;n&lt;/em&gt; vectors of dimension &lt;strong&gt;4096&lt;/strong&gt;. Speed is around &lt;em&gt;1000 sentences per second&lt;/em&gt; with batch size 128 on a single GPU.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;5) Visualize the importance that our model attributes to each word:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We provide a function to visualize the importance of each word in the encoding of a sentence:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;infersent.visualize(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;A man plays an instrument.&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;tokenize&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fdaffbdcdc7ea780e0b4d468b77d51f6baf24e9f/68747470733a2f2f646c2e666261697075626c696366696c65732e636f6d2f696e66657273656e742f76697375616c697a6174696f6e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/fdaffbdcdc7ea780e0b4d468b77d51f6baf24e9f/68747470733a2f2f646c2e666261697075626c696366696c65732e636f6d2f696e66657273656e742f76697375616c697a6174696f6e2e706e67" alt="Model" data-canonical-src="https://dl.fbaipublicfiles.com/infersent/visualization.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-evaluate-the-encoder-on-transfer-tasks" class="anchor" aria-hidden="true" href="#evaluate-the-encoder-on-transfer-tasks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Evaluate the encoder on transfer tasks&lt;/h2&gt;
&lt;p&gt;To evaluate the model on transfer tasks, see &lt;a href="https://github.com/facebookresearch/SentEval/tree/master/examples"&gt;SentEval&lt;/a&gt;. Be mindful to choose the same tokenization used for training the encoder. You should obtain the following test results for the baselines and the InferSent models:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Model&lt;/th&gt;
&lt;th align="center"&gt;MR&lt;/th&gt;
&lt;th align="center"&gt;CR&lt;/th&gt;
&lt;th align="center"&gt;SUBJ&lt;/th&gt;
&lt;th align="center"&gt;MPQA&lt;/th&gt;
&lt;th align="center"&gt;STS14&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark#Results" rel="nofollow"&gt;STS Benchmark&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;SICK Relatedness&lt;/th&gt;
&lt;th align="center"&gt;SICK Entailment&lt;/th&gt;
&lt;th align="center"&gt;SST&lt;/th&gt;
&lt;th align="center"&gt;TREC&lt;/th&gt;
&lt;th align="center"&gt;MRPC&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;code&gt;InferSent1&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;81.1&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;86.3&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;92.4&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;90.2&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;.68/.65&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;75.8/75.5&lt;/td&gt;
&lt;td align="center"&gt;0.884&lt;/td&gt;
&lt;td align="center"&gt;86.1&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;84.6&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;88.2&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;76.2&lt;/strong&gt;/83.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;code&gt;InferSent2&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;79.7&lt;/td&gt;
&lt;td align="center"&gt;84.2&lt;/td&gt;
&lt;td align="center"&gt;92.7&lt;/td&gt;
&lt;td align="center"&gt;89.4&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;.68/.66&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;78.4/78.4&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;0.888&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;86.3&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;84.3&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;90.8&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;76.0/&lt;strong&gt;83.8&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;code&gt;SkipThought&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;79.4&lt;/td&gt;
&lt;td align="center"&gt;83.1&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;93.7&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;89.3&lt;/td&gt;
&lt;td align="center"&gt;.44/.45&lt;/td&gt;
&lt;td align="center"&gt;72.1/70.2&lt;/td&gt;
&lt;td align="center"&gt;0.858&lt;/td&gt;
&lt;td align="center"&gt;79.5&lt;/td&gt;
&lt;td align="center"&gt;82.9&lt;/td&gt;
&lt;td align="center"&gt;88.4&lt;/td&gt;
&lt;td align="center"&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;code&gt;fastText-BoV&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;78.2&lt;/td&gt;
&lt;td align="center"&gt;80.2&lt;/td&gt;
&lt;td align="center"&gt;91.8&lt;/td&gt;
&lt;td align="center"&gt;88.0&lt;/td&gt;
&lt;td align="center"&gt;.65/.63&lt;/td&gt;
&lt;td align="center"&gt;70.2/68.3&lt;/td&gt;
&lt;td align="center"&gt;0.823&lt;/td&gt;
&lt;td align="center"&gt;78.9&lt;/td&gt;
&lt;td align="center"&gt;82.3&lt;/td&gt;
&lt;td align="center"&gt;83.4&lt;/td&gt;
&lt;td align="center"&gt;74.4/82.4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-reference" class="anchor" aria-hidden="true" href="#reference"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reference&lt;/h2&gt;
&lt;p&gt;Please consider citing &lt;a href="https://arxiv.org/abs/1705.02364" rel="nofollow"&gt;[1]&lt;/a&gt; if you found this code useful.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data-emnlp-2017" class="anchor" aria-hidden="true" href="#supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data-emnlp-2017"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Supervised Learning of Universal Sentence Representations from Natural Language Inference Data (EMNLP 2017)&lt;/h3&gt;
&lt;p&gt;[1] A. Conneau, D. Kiela, H. Schwenk, L. Barrault, A. Bordes, &lt;a href="https://arxiv.org/abs/1705.02364" rel="nofollow"&gt;&lt;em&gt;Supervised Learning of Universal Sentence Representations from Natural Language Inference Data&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@InProceedings{conneau-EtAl:2017:EMNLP2017,
  author    = {Conneau, Alexis  and  Kiela, Douwe  and  Schwenk, Holger  and  Barrault, Lo\"{i}c  and  Bordes, Antoine},
  title     = {Supervised Learning of Universal Sentence Representations from Natural Language Inference Data},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  pages     = {670--680},
  url       = {https://www.aclweb.org/anthology/D17-1070}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-related-work" class="anchor" aria-hidden="true" href="#related-work"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Related work&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1506.06726" rel="nofollow"&gt;J. R Kiros, Y. Zhu, R. Salakhutdinov, R. S. Zemel, A. Torralba, R. Urtasun, S. Fidler - SkipThought Vectors, NIPS 2015&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://openreview.net/pdf?id=SyK00v5xx" rel="nofollow"&gt;S. Arora, Y. Liang, T. Ma - A Simple but Tough-to-Beat Baseline for Sentence Embeddings, ICLR 2017&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1608.04207" rel="nofollow"&gt;Y. Adi, E. Kermany, Y. Belinkov, O. Lavi, Y. Goldberg - Fine-grained analysis of sentence embeddings using auxiliary prediction tasks, ICLR 2017&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1803.05449" rel="nofollow"&gt;A. Conneau, D. Kiela - SentEval: An Evaluation Toolkit for Universal Sentence Representations, LREC 2018&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1804.00079" rel="nofollow"&gt;S. Subramanian, A. Trischler, Y. Bengio, C. J Pal - Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning, ICLR 2018&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1710.04334" rel="nofollow"&gt;A. Nie, E. D. Bennett, N. D. Goodman - DisSent: Sentence Representation Learning from Explicit Discourse Relations, 2018&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1803.11175" rel="nofollow"&gt;D. Cer, Y. Yang, S. Kong, N. Hua, N. Limtiaco, R. St. John, N. Constant, M. Guajardo-Cespedes, S. Yuan, C. Tar, Y. Sung, B. Strope, R. Kurzweil - Universal Sentence Encoder, 2018&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1805.01070" rel="nofollow"&gt;A. Conneau, G. Kruszewski, G. Lample, L. Barrault, M. Baroni - What you can cram into a single vector: Probing sentence embeddings for linguistic properties, ACL 2018&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1804.07461" rel="nofollow"&gt;A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, S. Bowman - GLUE: A Multi-Task Benchmark and Analysis Platform
for Natural Language Understanding&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>facebookresearch</author><guid isPermaLink="false">https://github.com/facebookresearch/InferSent</guid><pubDate>Sat, 30 Nov 2019 00:12:00 GMT</pubDate></item><item><title>AtsushiSakai/PythonRobotics #13 in Jupyter Notebook, Today</title><link>https://github.com/AtsushiSakai/PythonRobotics</link><description>&lt;p&gt;&lt;i&gt;Python sample codes for robotics algorithms.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRobotics/raw/master/icon.png?raw=true"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRobotics/raw/master/icon.png?raw=true" align="right" width="300" alt="header pic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-pythonrobotics" class="anchor" aria-hidden="true" href="#pythonrobotics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PythonRobotics&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/AtsushiSakai/PythonRobotics" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/58f87d5d3604646322c28abd8c5a9b2faa05fa51/68747470733a2f2f7472617669732d63692e6f72672f4174737573686953616b61692f507974686f6e526f626f746963732e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/AtsushiSakai/PythonRobotics.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pythonrobotics.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a60f894ef011c8a7e648348c16aabfdfb603613a/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f707974686f6e726f626f746963732f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/pythonrobotics/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/AtsushiSakai/pythonrobotics" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2e66a00c9dcf7ecc1f24189c6055aa7e6da233dc/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f73623237396b787576316265333931673f7376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/sb279kxuv1be391g?svg=true" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://coveralls.io/github/AtsushiSakai/PythonRobotics?branch=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2c26144817eba34b4ee9f9a6aee913e6b466218b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4174737573686953616b61692f507974686f6e526f626f746963732f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/AtsushiSakai/PythonRobotics/badge.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/AtsushiSakai/PythonRobotics/context:python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/4c3af4cd47bb2ea2c71cac274f1f7dd392eea893/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f4174737573686953616b61692f507974686f6e526f626f746963732e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138" alt="Language grade: Python" data-canonical-src="https://img.shields.io/lgtm/grade/python/g/AtsushiSakai/PythonRobotics.svg?logo=lgtm&amp;amp;logoWidth=18" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.codefactor.io/repository/github/atsushisakai/pythonrobotics/overview/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c3cd55e61ef2e22ff00427b50b9e7f1c3547de91/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6174737573686973616b61692f707974686f6e726f626f746963732f62616467652f6d6173746572" alt="CodeFactor" data-canonical-src="https://www.codefactor.io/repository/github/atsushisakai/pythonrobotics/badge/master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/AtsushiSakai/PythonRobotics"&gt;&lt;img src="https://camo.githubusercontent.com/230f0a1eaa529fa727cad2c9d3c1ace4738bd25d/68747470733a2f2f746f6b65692e72732f62312f6769746875622f4174737573686953616b61692f507974686f6e526f626f74696373" alt="tokei" data-canonical-src="https://tokei.rs/b1/github/AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://saythanks.io/to/AtsushiSakai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0c9f6dc1c6a604b58d3c56bc5d7624e44f7eee2b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5361792532305468616e6b732d212d3145414544422e737667" alt="Say Thanks!" data-canonical-src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Python codes for robotics algorithm.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#what-is-this"&gt;What is this?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#requirements"&gt;Requirements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-use"&gt;How to use&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#localization"&gt;Localization&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#extended-kalman-filter-localization"&gt;Extended Kalman Filter localization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#particle-filter-localization"&gt;Particle filter localization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#histogram-filter-localization"&gt;Histogram filter localization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#mapping"&gt;Mapping&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#gaussian-grid-map"&gt;Gaussian grid map&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ray-casting-grid-map"&gt;Ray casting grid map&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lidar-to-grid-map"&gt;Lidar to grid map&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#k-means-object-clustering"&gt;k-means object clustering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rectangle-fitting"&gt;Rectangle fitting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#slam"&gt;SLAM&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#iterative-closest-point-icp-matching"&gt;Iterative Closest Point (ICP) Matching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fastslam-10"&gt;FastSLAM 1.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#path-planning"&gt;Path Planning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#dynamic-window-approach"&gt;Dynamic Window Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#grid-based-search"&gt;Grid based search&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#dijkstra-algorithm"&gt;Dijkstra algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#a-algorithm"&gt;A* algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#potential-field-algorithm"&gt;Potential Field algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#grid-based-coverage-path-planning"&gt;Grid based coverage path planning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#state-lattice-planning"&gt;State Lattice Planning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#biased-polar-sampling"&gt;Biased polar sampling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lane-sampling"&gt;Lane sampling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#probabilistic-road-map-prm-planning"&gt;Probabilistic Road-Map (PRM) planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rapidly-exploring-random-trees-rrt"&gt;Rapidly-Exploring Random Trees (RRT)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#rrt"&gt;RRT*&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rrt-with-reeds-shepp-path"&gt;RRT* with reeds-shepp path&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lqr-rrt"&gt;LQR-RRT*&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#quintic-polynomials-planning"&gt;Quintic polynomials planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#reeds-shepp-planning"&gt;Reeds Shepp planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lqr-based-path-planning"&gt;LQR based path planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#optimal-trajectory-in-a-frenet-frame"&gt;Optimal Trajectory in a Frenet Frame&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#path-tracking"&gt;Path Tracking&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#move-to-a-pose-control"&gt;move to a pose control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#stanley-control"&gt;Stanley control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rear-wheel-feedback-control"&gt;Rear wheel feedback control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#linearquadratic-regulator-lqr-speed-and-steering-control"&gt;Linear–quadratic regulator (LQR) speed and steering control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#model-predictive-speed-and-steering-control"&gt;Model predictive speed and steering control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#nonlinear-model-predictive-control-with-c-gmres"&gt;Nonlinear Model predictive control with C-GMRES&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#arm-navigation"&gt;Arm Navigation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#n-joint-arm-to-point-control"&gt;N joint arm to point control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#arm-navigation-with-obstacle-avoidance"&gt;Arm navigation with obstacle avoidance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#aerial-navigation"&gt;Aerial Navigation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#drone-3d-trajectory-following"&gt;drone 3d trajectory following&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rocket-powered-landing"&gt;rocket powered landing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#bipedal"&gt;Bipedal&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#bipedal-planner-with-inverted-pendulum"&gt;bipedal planner with inverted pendulum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#use-case"&gt;Use-case&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contribution"&gt;Contribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#citing"&gt;Citing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#support"&gt;Support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#authors"&gt;Authors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-what-is-this" class="anchor" aria-hidden="true" href="#what-is-this"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is this?&lt;/h1&gt;
&lt;p&gt;This is a Python code collection of robotics algorithms, especially for autonomous navigation.&lt;/p&gt;
&lt;p&gt;Features:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Easy to read for understanding each algorithm's basic idea.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Widely used and practical algorithms are selected.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Minimum dependency.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;See this paper for more details:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1808.10703" rel="nofollow"&gt;[1808.10703] PythonRobotics: a Python code collection of robotics algorithms&lt;/a&gt; (&lt;a href="https://github.com/AtsushiSakai/PythonRoboticsPaper/blob/master/python_robotics.bib"&gt;BibTeX&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Python 3.7.x (2.7 is not supported)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;numpy&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;scipy&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;matplotlib&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;pandas&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.cvxpy.org/index.html" rel="nofollow"&gt;cvxpy&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h1&gt;
&lt;p&gt;This README only shows some examples of this project.&lt;/p&gt;
&lt;p&gt;If you are interested in other examples or mathematical backgrounds of each algorithm,&lt;/p&gt;
&lt;p&gt;You can check the full documentation online: &lt;a href="https://pythonrobotics.readthedocs.io/" rel="nofollow"&gt;https://pythonrobotics.readthedocs.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All animation gifs are stored here: &lt;a href="https://github.com/AtsushiSakai/PythonRoboticsGifs"&gt;AtsushiSakai/PythonRoboticsGifs: Animation gifs of PythonRobotics&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-how-to-use" class="anchor" aria-hidden="true" href="#how-to-use"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to use&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Clone this repo.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;git clone &lt;a href="https://github.com/AtsushiSakai/PythonRobotics.git"&gt;https://github.com/AtsushiSakai/PythonRobotics.git&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;cd PythonRobotics/&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Install the required libraries. You can use environment.yml with conda command.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;conda env create -f environment.yml&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start="3"&gt;
&lt;li&gt;
&lt;p&gt;Execute python script in each directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add star to this repo if you like it &lt;g-emoji class="g-emoji" alias="smiley" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f603.png"&gt;😃&lt;/g-emoji&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;&lt;a id="user-content-localization" class="anchor" aria-hidden="true" href="#localization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Localization&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-extended-kalman-filter-localization" class="anchor" aria-hidden="true" href="#extended-kalman-filter-localization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Extended Kalman Filter localization&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/extended_kalman_filter/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/extended_kalman_filter/animation.gif" width="640" alt="EKF pic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Documentation: &lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/Localization/extended_kalman_filter/extended_kalman_filter_localization.ipynb"&gt;Notebook&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-particle-filter-localization" class="anchor" aria-hidden="true" href="#particle-filter-localization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Particle filter localization&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/particle_filter/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/particle_filter/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a sensor fusion localization with Particle Filter(PF).&lt;/p&gt;
&lt;p&gt;The blue line is true trajectory, the black line is dead reckoning trajectory,&lt;/p&gt;
&lt;p&gt;and the red line is estimated trajectory with PF.&lt;/p&gt;
&lt;p&gt;It is assumed that the robot can measure a distance from landmarks (RFID).&lt;/p&gt;
&lt;p&gt;This measurements are used for PF localization.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.probabilistic-robotics.org/" rel="nofollow"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-histogram-filter-localization" class="anchor" aria-hidden="true" href="#histogram-filter-localization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Histogram filter localization&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/histogram_filter/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/histogram_filter/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a 2D localization example with Histogram filter.&lt;/p&gt;
&lt;p&gt;The red cross is true position, black points are RFID positions.&lt;/p&gt;
&lt;p&gt;The blue grid shows a position probability of histogram filter.&lt;/p&gt;
&lt;p&gt;In this simulation, x,y are unknown, yaw is known.&lt;/p&gt;
&lt;p&gt;The filter integrates speed input and range observations from RFID for localization.&lt;/p&gt;
&lt;p&gt;Initial position is not needed.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.probabilistic-robotics.org/" rel="nofollow"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-mapping" class="anchor" aria-hidden="true" href="#mapping"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Mapping&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-gaussian-grid-map" class="anchor" aria-hidden="true" href="#gaussian-grid-map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gaussian grid map&lt;/h2&gt;
&lt;p&gt;This is a 2D Gaussian grid mapping example.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/gaussian_grid_map/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/gaussian_grid_map/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ray-casting-grid-map" class="anchor" aria-hidden="true" href="#ray-casting-grid-map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ray casting grid map&lt;/h2&gt;
&lt;p&gt;This is a 2D ray casting grid mapping example.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/raycasting_grid_map/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/raycasting_grid_map/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-lidar-to-grid-map" class="anchor" aria-hidden="true" href="#lidar-to-grid-map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lidar to grid map&lt;/h2&gt;
&lt;p&gt;This example shows how to convert a 2D range measurement to a grid map.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="Mapping/lidar_to_grid_map/animation.gif"&gt;&lt;img src="Mapping/lidar_to_grid_map/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-k-means-object-clustering" class="anchor" aria-hidden="true" href="#k-means-object-clustering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;k-means object clustering&lt;/h2&gt;
&lt;p&gt;This is a 2D object clustering with k-means algorithm.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/kmeans_clustering/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/kmeans_clustering/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-rectangle-fitting" class="anchor" aria-hidden="true" href="#rectangle-fitting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Rectangle fitting&lt;/h2&gt;
&lt;p&gt;This is a 2D rectangle fitting for vehicle detection.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/rectangle_fitting/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/rectangle_fitting/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-slam" class="anchor" aria-hidden="true" href="#slam"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SLAM&lt;/h1&gt;
&lt;p&gt;Simultaneous Localization and Mapping(SLAM) examples&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-iterative-closest-point-icp-matching" class="anchor" aria-hidden="true" href="#iterative-closest-point-icp-matching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Iterative Closest Point (ICP) Matching&lt;/h2&gt;
&lt;p&gt;This is a 2D ICP matching example with singular value decomposition.&lt;/p&gt;
&lt;p&gt;It can calculate a rotation matrix and a translation vector between points to points.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/iterative_closest_point/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/iterative_closest_point/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cs.gmu.edu/~kosecka/cs685/cs685-icp.pdf" rel="nofollow"&gt;Introduction to Mobile Robotics: Iterative Closest Point Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-fastslam-10" class="anchor" aria-hidden="true" href="#fastslam-10"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FastSLAM 1.0&lt;/h2&gt;
&lt;p&gt;This is a feature based SLAM example using FastSLAM 1.0.&lt;/p&gt;
&lt;p&gt;The blue line is ground truth, the black line is dead reckoning, the red line is the estimated trajectory with FastSLAM.&lt;/p&gt;
&lt;p&gt;The red points are particles of FastSLAM.&lt;/p&gt;
&lt;p&gt;Black points are landmarks, blue crosses are estimated landmark positions by FastSLAM.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/FastSLAM1/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/FastSLAM1/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.probabilistic-robotics.org/" rel="nofollow"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www-personal.acfr.usyd.edu.au/tbailey/software/slam_simulations.htm" rel="nofollow"&gt;SLAM simulations by Tim Bailey&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-path-planning" class="anchor" aria-hidden="true" href="#path-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Path Planning&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-dynamic-window-approach" class="anchor" aria-hidden="true" href="#dynamic-window-approach"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dynamic Window Approach&lt;/h2&gt;
&lt;p&gt;This is a 2D navigation sample code with Dynamic Window Approach.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.ri.cmu.edu/pub_files/pub1/fox_dieter_1997_1/fox_dieter_1997_1.pdf" rel="nofollow"&gt;The Dynamic Window Approach to Collision Avoidance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DynamicWindowApproach/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DynamicWindowApproach/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-grid-based-search" class="anchor" aria-hidden="true" href="#grid-based-search"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Grid based search&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-dijkstra-algorithm" class="anchor" aria-hidden="true" href="#dijkstra-algorithm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dijkstra algorithm&lt;/h3&gt;
&lt;p&gt;This is a 2D grid based shortest path planning with Dijkstra's algorithm.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/Dijkstra/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/Dijkstra/animation.gif" alt="PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the animation, cyan points are searched nodes.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-a-algorithm" class="anchor" aria-hidden="true" href="#a-algorithm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A* algorithm&lt;/h3&gt;
&lt;p&gt;This is a 2D grid based shortest path planning with A star algorithm.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/AStar/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/AStar/animation.gif" alt="PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the animation, cyan points are searched nodes.&lt;/p&gt;
&lt;p&gt;Its heuristic is 2D Euclid distance.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-potential-field-algorithm" class="anchor" aria-hidden="true" href="#potential-field-algorithm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Potential Field algorithm&lt;/h3&gt;
&lt;p&gt;This is a 2D grid based path planning with Potential Field algorithm.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/PotentialFieldPlanning/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/PotentialFieldPlanning/animation.gif" alt="PotentialField" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the animation, the blue heat map shows potential value on each grid.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.cs.cmu.edu/~motionplanning/lecture/Chap4-Potential-Field_howie.pdf" rel="nofollow"&gt;Robotic Motion Planning:Potential Functions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-grid-based-coverage-path-planning" class="anchor" aria-hidden="true" href="#grid-based-coverage-path-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Grid based coverage path planning&lt;/h3&gt;
&lt;p&gt;This is a 2D grid based coverage path planning simulation.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/GridBasedSweepCPP/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/GridBasedSweepCPP/animation.gif" alt="PotentialField" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-state-lattice-planning" class="anchor" aria-hidden="true" href="#state-lattice-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;State Lattice Planning&lt;/h2&gt;
&lt;p&gt;This script is a path planning code with state lattice planning.&lt;/p&gt;
&lt;p&gt;This code uses the model predictive trajectory generator to solve boundary problem.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://journals.sagepub.com/doi/pdf/10.1177/0278364906075328" rel="nofollow"&gt;Optimal rough terrain trajectory generation for wheeled mobile robots&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.frc.ri.cmu.edu/~alonzo/pubs/papers/JFR_08_SS_Sampling.pdf" rel="nofollow"&gt;State Space Sampling of Feasible Motions for High-Performance Mobile Robot Navigation in Complex Environments&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-biased-polar-sampling" class="anchor" aria-hidden="true" href="#biased-polar-sampling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Biased polar sampling&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/BiasedPolarSampling.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/BiasedPolarSampling.gif" alt="PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-lane-sampling" class="anchor" aria-hidden="true" href="#lane-sampling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lane sampling&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/LaneSampling.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/LaneSampling.gif" alt="PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-probabilistic-road-map-prm-planning" class="anchor" aria-hidden="true" href="#probabilistic-road-map-prm-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Probabilistic Road-Map (PRM) planning&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ProbabilisticRoadMap/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ProbabilisticRoadMap/animation.gif" alt="PRM" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This PRM planner uses Dijkstra method for graph search.&lt;/p&gt;
&lt;p&gt;In the animation, blue points are sampled points,&lt;/p&gt;
&lt;p&gt;Cyan crosses means searched points with Dijkstra method,&lt;/p&gt;
&lt;p&gt;The red line is the final path of PRM.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Probabilistic_roadmap" rel="nofollow"&gt;Probabilistic roadmap - Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;　　&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-rapidly-exploring-random-trees-rrt" class="anchor" aria-hidden="true" href="#rapidly-exploring-random-trees-rrt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Rapidly-Exploring Random Trees (RRT)&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-rrt" class="anchor" aria-hidden="true" href="#rrt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RRT*&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTstar/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTstar/animation.gif" alt="PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a path planning code with RRT*&lt;/p&gt;
&lt;p&gt;Black circles are obstacles, green line is a searched tree, red crosses are start and goal positions.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1005.0416" rel="nofollow"&gt;Incremental Sampling-based Algorithms for Optimal Motion Planning&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.419.5503&amp;amp;rep=rep1&amp;amp;type=pdf" rel="nofollow"&gt;Sampling-based Algorithms for Optimal Motion Planning&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-rrt-with-reeds-shepp-path" class="anchor" aria-hidden="true" href="#rrt-with-reeds-shepp-path"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RRT* with reeds-shepp path&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTStarReedsShepp/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTStarReedsShepp/animation.gif" alt="Robotics/animation.gif at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Path planning for a car robot with RRT* and reeds shepp path planner.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-lqr-rrt" class="anchor" aria-hidden="true" href="#lqr-rrt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LQR-RRT*&lt;/h3&gt;
&lt;p&gt;This is a path planning simulation with LQR-RRT*.&lt;/p&gt;
&lt;p&gt;A double integrator motion model is used for LQR local planner.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRRRTStar/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRRRTStar/animation.gif" alt="LQRRRT" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://lis.csail.mit.edu/pubs/perez-icra12.pdf" rel="nofollow"&gt;LQR-RRT*: Optimal Sampling-Based Motion Planning with Automatically Derived Extension Heuristics&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/MahanFathi/LQR-RRTstar"&gt;MahanFathi/LQR-RRTstar: LQR-RRT* method is used for random motion planning of a simple pendulum in its phase plot&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-quintic-polynomials-planning" class="anchor" aria-hidden="true" href="#quintic-polynomials-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quintic polynomials planning&lt;/h2&gt;
&lt;p&gt;Motion planning with quintic polynomials.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/QuinticPolynomialsPlanner/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/QuinticPolynomialsPlanner/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It can calculate 2D path, velocity, and acceleration profile based on quintic polynomials.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ieeexplore.ieee.org/document/637936/" rel="nofollow"&gt;Local Path Planning And Motion Control For Agv In Positioning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-reeds-shepp-planning" class="anchor" aria-hidden="true" href="#reeds-shepp-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reeds Shepp planning&lt;/h2&gt;
&lt;p&gt;A sample code with Reeds Shepp path planning.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ReedsSheppPath/animation.gif?raw=true"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ReedsSheppPath/animation.gif?raw=true" alt="RSPlanning" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://planning.cs.uiuc.edu/node822.html" rel="nofollow"&gt;15.3.2 Reeds-Shepp Curves&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://pdfs.semanticscholar.org/932e/c495b1d0018fd59dee12a0bf74434fac7af4.pdf" rel="nofollow"&gt;optimal paths for a car that goes both forwards and backwards&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/ghliu/pyReedsShepp"&gt;ghliu/pyReedsShepp: Implementation of Reeds Shepp curve.&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-lqr-based-path-planning" class="anchor" aria-hidden="true" href="#lqr-based-path-planning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LQR based path planning&lt;/h2&gt;
&lt;p&gt;A sample code using LQR based path planning for double integrator model.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRPlanner/animation.gif?raw=true"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRPlanner/animation.gif?raw=true" alt="RSPlanning" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-optimal-trajectory-in-a-frenet-frame" class="anchor" aria-hidden="true" href="#optimal-trajectory-in-a-frenet-frame"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Optimal Trajectory in a Frenet Frame&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/FrenetOptimalTrajectory/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/FrenetOptimalTrajectory/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is optimal trajectory generation in a Frenet Frame.&lt;/p&gt;
&lt;p&gt;The cyan line is the target course and black crosses are obstacles.&lt;/p&gt;
&lt;p&gt;The red line is predicted path.&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.researchgate.net/profile/Moritz_Werling/publication/224156269_Optimal_Trajectory_Generation_for_Dynamic_Street_Scenarios_in_a_Frenet_Frame/links/54f749df0cf210398e9277af.pdf" rel="nofollow"&gt;Optimal Trajectory Generation for Dynamic Street Scenarios in a Frenet Frame&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Cj6tAQe7UCY" rel="nofollow"&gt;Optimal trajectory generation for dynamic street scenarios in a Frenet Frame&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-path-tracking" class="anchor" aria-hidden="true" href="#path-tracking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Path Tracking&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-move-to-a-pose-control" class="anchor" aria-hidden="true" href="#move-to-a-pose-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;move to a pose control&lt;/h2&gt;
&lt;p&gt;This is a simulation of moving to a pose control&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/move_to_pose/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/move_to_pose/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://link.springer.com/book/10.1007/978-3-642-20144-8" rel="nofollow"&gt;P. I. Corke, "Robotics, Vision and Control" | SpringerLink p102&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-stanley-control" class="anchor" aria-hidden="true" href="#stanley-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stanley control&lt;/h2&gt;
&lt;p&gt;Path tracking simulation with Stanley steering control and PID speed control.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/stanley_controller/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/stanley_controller/animation.gif" alt="2" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://robots.stanford.edu/papers/thrun.stanley05.pdf" rel="nofollow"&gt;Stanley: The robot that won the DARPA grand challenge&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.ri.cmu.edu/pub_files/2009/2/Automatic_Steering_Methods_for_Autonomous_Automobile_Path_Tracking.pdf" rel="nofollow"&gt;Automatic Steering Methods for Autonomous Automobile Path Tracking&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-rear-wheel-feedback-control" class="anchor" aria-hidden="true" href="#rear-wheel-feedback-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Rear wheel feedback control&lt;/h2&gt;
&lt;p&gt;Path tracking simulation with rear wheel feedback steering control and PID speed control.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/rear_wheel_feedback/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/rear_wheel_feedback/animation.gif" alt="PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1604.07446" rel="nofollow"&gt;A Survey of Motion Planning and Control Techniques for Self-driving Urban Vehicles&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-linearquadratic-regulator-lqr-speed-and-steering-control" class="anchor" aria-hidden="true" href="#linearquadratic-regulator-lqr-speed-and-steering-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linear–quadratic regulator (LQR) speed and steering control&lt;/h2&gt;
&lt;p&gt;Path tracking simulation with LQR speed and steering control.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/lqr_speed_steer_control/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/lqr_speed_steer_control/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ieeexplore.ieee.org/document/5940562/" rel="nofollow"&gt;Towards fully autonomous driving: Systems and algorithms - IEEE Conference Publication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-model-predictive-speed-and-steering-control" class="anchor" aria-hidden="true" href="#model-predictive-speed-and-steering-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model predictive speed and steering control&lt;/h2&gt;
&lt;p&gt;Path tracking simulation with iterative linear model predictive speed and steering control.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/model_predictive_speed_and_steer_control/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/model_predictive_speed_and_steer_control/animation.gif" width="640" alt="MPC pic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/PathTracking/model_predictive_speed_and_steer_control/Model_predictive_speed_and_steering_control.ipynb"&gt;notebook&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://grauonline.de/wordpress/?page_id=3244" rel="nofollow"&gt;Real-time Model Predictive Control (MPC), ACADO, Python | Work-is-Playing&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-nonlinear-model-predictive-control-with-c-gmres" class="anchor" aria-hidden="true" href="#nonlinear-model-predictive-control-with-c-gmres"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Nonlinear Model predictive control with C-GMRES&lt;/h2&gt;
&lt;p&gt;A motion planning and path tracking simulation with NMPC of C-GMRES&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/cgmres_nmpc/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/cgmres_nmpc/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/PathTracking/cgmres_nmpc/cgmres_nmpc.ipynb"&gt;notebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-arm-navigation" class="anchor" aria-hidden="true" href="#arm-navigation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Arm Navigation&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-n-joint-arm-to-point-control" class="anchor" aria-hidden="true" href="#n-joint-arm-to-point-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;N joint arm to point control&lt;/h2&gt;
&lt;p&gt;N joint arm to a point control simulation.&lt;/p&gt;
&lt;p&gt;This is a interactive simulation.&lt;/p&gt;
&lt;p&gt;You can set the goal position of the end effector with left-click on the ploting area.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/n_joint_arm_to_point_control/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/n_joint_arm_to_point_control/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this simulation N = 10, however, you can change it.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-arm-navigation-with-obstacle-avoidance" class="anchor" aria-hidden="true" href="#arm-navigation-with-obstacle-avoidance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Arm navigation with obstacle avoidance&lt;/h2&gt;
&lt;p&gt;Arm navigation with obstacle avoidance simulation.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/arm_obstacle_navigation/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/arm_obstacle_navigation/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-aerial-navigation" class="anchor" aria-hidden="true" href="#aerial-navigation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Aerial Navigation&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-drone-3d-trajectory-following" class="anchor" aria-hidden="true" href="#drone-3d-trajectory-following"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;drone 3d trajectory following&lt;/h2&gt;
&lt;p&gt;This is a 3d trajectory following simulation for a quadrotor.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/drone_3d_trajectory_following/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/drone_3d_trajectory_following/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-rocket-powered-landing" class="anchor" aria-hidden="true" href="#rocket-powered-landing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;rocket powered landing&lt;/h2&gt;
&lt;p&gt;This is a 3d trajectory generation simulation for a rocket powered landing.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/rocket_powered_landing/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/rocket_powered_landing/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/AerialNavigation/rocket_powered_landing/rocket_powered_landing.ipynb"&gt;notebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-bipedal" class="anchor" aria-hidden="true" href="#bipedal"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bipedal&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-bipedal-planner-with-inverted-pendulum" class="anchor" aria-hidden="true" href="#bipedal-planner-with-inverted-pendulum"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;bipedal planner with inverted pendulum&lt;/h2&gt;
&lt;p&gt;This is a bipedal planner for modifying footsteps with inverted pendulum.&lt;/p&gt;
&lt;p&gt;You can set the footsteps and the planner will modify those automatically.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Bipedal/bipedal_planner/animation.gif"&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Bipedal/bipedal_planner/animation.gif" alt="3" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h1&gt;
&lt;p&gt;MIT&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-use-case" class="anchor" aria-hidden="true" href="#use-case"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Use-case&lt;/h1&gt;
&lt;p&gt;If this project helps your robotics project, please let me know with &lt;a href="https://saythanks.io/to/AtsushiSakai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0c9f6dc1c6a604b58d3c56bc5d7624e44f7eee2b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5361792532305468616e6b732d212d3145414544422e737667" alt="Say Thanks!" data-canonical-src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" style="max-width:100%;"&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Your robot's video, which is using PythonRobotics, is very welcome!!&lt;/p&gt;
&lt;p&gt;This is a list of other user's comment and references:&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/users_comments.md"&gt;users_comments&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-contribution" class="anchor" aria-hidden="true" href="#contribution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution&lt;/h1&gt;
&lt;p&gt;A small PR like bug fix is welcome.&lt;/p&gt;
&lt;p&gt;If your PR is merged multiple times, I will add your account to the author list.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-citing" class="anchor" aria-hidden="true" href="#citing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citing&lt;/h1&gt;
&lt;p&gt;If you use this project's code for your academic work, we encourage you to cite &lt;a href="https://arxiv.org/abs/1808.10703" rel="nofollow"&gt;our papers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you use this project's code in industry, we'd love to hear from you as well; feel free to reach out to the developers directly.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-support" class="anchor" aria-hidden="true" href="#support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support&lt;/h1&gt;
&lt;p&gt;If you or your company would like to support this project, please consider:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.patreon.com/myenigma" rel="nofollow"&gt;Become a backer or sponsor on Patreon&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.paypal.me/myenigmapay/" rel="nofollow"&gt;One-time donation via PayPal&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can add your name or your company logo in README if you are a patron.&lt;/p&gt;
&lt;p&gt;E-mail consultant is also available.&lt;/p&gt;
&lt;p&gt;　&lt;/p&gt;
&lt;p&gt;Your comment using &lt;a href="https://saythanks.io/to/AtsushiSakai" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0c9f6dc1c6a604b58d3c56bc5d7624e44f7eee2b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5361792532305468616e6b732d212d3145414544422e737667" alt="Say Thanks!" data-canonical-src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" style="max-width:100%;"&gt;&lt;/a&gt; is also welcome.&lt;/p&gt;
&lt;p&gt;This is a list: &lt;a href="https://github.com/AtsushiSakai/PythonRobotics/blob/master/users_comments.md"&gt;Users comments&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authors&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/AtsushiSakai/"&gt;Atsushi Sakai&lt;/a&gt; (&lt;a href="https://twitter.com/Atsushi_twi" rel="nofollow"&gt;@Atsushi_twi&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/daniel-s-ingram"&gt;Daniel Ingram&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/jwdinius"&gt;Joe Dinius&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/karanchawla"&gt;Karan Chawla&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/araffin"&gt;Antonin RAFFIN&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/AlexisTM"&gt;Alexis Paques&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/rsasaki0109"&gt;Ryohei Sasaki&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>AtsushiSakai</author><guid isPermaLink="false">https://github.com/AtsushiSakai/PythonRobotics</guid><pubDate>Sat, 30 Nov 2019 00:13:00 GMT</pubDate></item><item><title>TannerGilbert/Tutorials #14 in Jupyter Notebook, Today</title><link>https://github.com/TannerGilbert/Tutorials</link><description>&lt;p&gt;&lt;i&gt;Code for all my tutorials&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tutorials" class="anchor" aria-hidden="true" href="#tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorials&lt;/h1&gt;
&lt;p&gt;This repository contains the code for all my articles and video series.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;Clone the wanted part of the repository and run jupyter notebook&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prerequisites&lt;/h3&gt;
&lt;p&gt;You need to have &lt;a href="https://www.python.org/" rel="nofollow"&gt;Python&lt;/a&gt; install.&lt;br&gt;
As well as either &lt;a href="https://www.tensorflow.org/install/" rel="nofollow"&gt;Tensorflow&lt;/a&gt; or &lt;a href="http://deeplearning.net/software/theano/install.html" rel="nofollow"&gt;Theano&lt;/a&gt; as a backend for Keras.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-author" class="anchor" aria-hidden="true" href="#author"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Author&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Gilbert Tanner&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-support-me" class="anchor" aria-hidden="true" href="#support-me"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support me&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.buymeacoffee.com/gilberttanner" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/031fc5a134cdca5ae3460822aba371e63f794233/68747470733a2f2f7777772e6275796d6561636f666665652e636f6d2f6173736574732f696d672f637573746f6d5f696d616765732f6f72616e67655f696d672e706e67" alt="Buy Me A Coffee" data-canonical-src="https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="LICENSE"&gt;LICENSE.md&lt;/a&gt; file for details&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>TannerGilbert</author><guid isPermaLink="false">https://github.com/TannerGilbert/Tutorials</guid><pubDate>Sat, 30 Nov 2019 00:14:00 GMT</pubDate></item><item><title>jantic/DeOldify #15 in Jupyter Notebook, Today</title><link>https://github.com/jantic/DeOldify</link><description>&lt;p&gt;&lt;i&gt;A Deep Learning based project for colorizing and restoring old images (and video!)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deoldify" class="anchor" aria-hidden="true" href="#deoldify"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DeOldify&lt;/h1&gt;
&lt;p&gt;Image &lt;a href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColab.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" align="center" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt; |
Video &lt;a href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/VideoColorizerColab.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" align="center" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEW&lt;/strong&gt; Instructions on how to use the Colabs above have been kindly provided in video tutorial form by Old Ireland in Colour's John Breslin.  It's great! Click video image below to watch.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=VaEl0faDw38" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9d812131195cc524d5fe03696fdc284208bedbde/687474703a2f2f696d672e796f75747562652e636f6d2f76692f5661456c306661447733382f302e6a7067" alt="" data-canonical-src="http://img.youtube.com/vi/VaEl0faDw38/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Get more updates on &lt;a href="https://twitter.com/citnaj" rel="nofollow"&gt;Twitter &lt;img src="resource_images/Twitter_Social_Icon_Rounded_Square_Color.svg" width="16" style="max-width:100%;"&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#about-deoldify"&gt;About DeOldify&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#example-videos"&gt;Example Videos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#example-images"&gt;Example Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#stuff-that-should-probably-be-in-a-paper"&gt;Stuff That Should Probably Be In A Paper&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#how-to-achieve-stable-video"&gt;How to Achieve Stable Video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-is-nogan"&gt;What is NoGAN?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#why-three-models"&gt;Why Three Models?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-technical-details"&gt;Technical Details&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#this-project-going-forward"&gt;Going Forward&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#getting-started-yourself"&gt;Getting Started Yourself&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#easiest-approach"&gt;Easiest Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#your-own-machine-not-as-easy"&gt;Your Own Machine&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pretrained-weights"&gt;Pretrained Weights&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-about-deoldify" class="anchor" aria-hidden="true" href="#about-deoldify"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About DeOldify&lt;/h2&gt;
&lt;p&gt;Simply put, the mission of this project is to colorize and restore old images and film footage.
We'll get into the details in a bit, but first let's see some pretty pictures and videos!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-new-and-exciting-stuff-in-deoldify" class="anchor" aria-hidden="true" href="#new-and-exciting-stuff-in-deoldify"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;New and Exciting Stuff in DeOldify&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Glitches and artifacts are almost entirely eliminated&lt;/li&gt;
&lt;li&gt;Better skin (less zombies)&lt;/li&gt;
&lt;li&gt;More highly detailed and photorealistic renders&lt;/li&gt;
&lt;li&gt;Much less "blue bias"&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Video&lt;/strong&gt; - it actually looks good!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NoGAN&lt;/strong&gt; - a new and weird but highly effective way to do GAN training for image to image.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-example-videos" class="anchor" aria-hidden="true" href="#example-videos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Videos&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;  Click images to watch&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-facebook-f8-demo" class="anchor" aria-hidden="true" href="#facebook-f8-demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Facebook F8 Demo&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=l3UXXid04Ys" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/95e149f839667ddcd87e0a1970e3870f6a61c24a/687474703a2f2f696d672e796f75747562652e636f6d2f76692f6c335558586964303459732f302e6a7067" alt="" data-canonical-src="http://img.youtube.com/vi/l3UXXid04Ys/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-silent-movie-examples" class="anchor" aria-hidden="true" href="#silent-movie-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Silent Movie Examples&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=EXn-n2iqEjI" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24d210457f7e8b57ef701788f013f2f72d2eda1c/687474703a2f2f696d672e796f75747562652e636f6d2f76692f45586e2d6e326971456a492f302e6a7067" alt="" data-canonical-src="http://img.youtube.com/vi/EXn-n2iqEjI/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-example-images" class="anchor" aria-hidden="true" href="#example-images"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Images&lt;/h2&gt;
&lt;p&gt;"Migrant Mother" by Dorothea Lange (1936)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/cf0b5cd16cd934cba884172370a78b40b28db00a/68747470733a2f2f692e696d6775722e636f6d2f427430766e6b652e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/cf0b5cd16cd934cba884172370a78b40b28db00a/68747470733a2f2f692e696d6775722e636f6d2f427430766e6b652e6a7067" alt="Migrant Mother" data-canonical-src="https://i.imgur.com/Bt0vnke.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Woman relaxing in her livingroom in Sweden (1920)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/8ae04c8fc773e163705fd8ec24d3a9271806980c/68747470733a2f2f692e696d6775722e636f6d2f31353864306f552e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/8ae04c8fc773e163705fd8ec24d3a9271806980c/68747470733a2f2f692e696d6775722e636f6d2f31353864306f552e6a7067" alt="Sweden Living Room" data-canonical-src="https://i.imgur.com/158d0oU.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"Toffs and Toughs" by Jimmy Sime (1937)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0e3d002bbc787b75359789f8ade0c43b637cded3/68747470733a2f2f692e696d6775722e636f6d2f565975617634492e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/0e3d002bbc787b75359789f8ade0c43b637cded3/68747470733a2f2f692e696d6775722e636f6d2f565975617634492e6a7067" alt="Class Divide" data-canonical-src="https://i.imgur.com/VYuav4I.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanksgiving Maskers (1911)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ba7b6ae2cc2e908346ba56f06ea54061b9b1ee6e/68747470733a2f2f692e696d6775722e636f6d2f6e3871564a35632e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/ba7b6ae2cc2e908346ba56f06ea54061b9b1ee6e/68747470733a2f2f692e696d6775722e636f6d2f6e3871564a35632e6a7067" alt="Thanksgiving Maskers" data-canonical-src="https://i.imgur.com/n8qVJ5c.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Glen Echo Madame Careta Gypsy Camp in Maryland (1925)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/83d69aafb3b306643f99566d08d805099c741e98/68747470733a2f2f692e696d6775722e636f6d2f316f59724a52492e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/83d69aafb3b306643f99566d08d805099c741e98/68747470733a2f2f692e696d6775722e636f6d2f316f59724a52492e6a7067" alt="Gypsy Camp" data-canonical-src="https://i.imgur.com/1oYrJRI.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"Mr. and Mrs. Lemuel Smith and their younger children in their farm house, Carroll County, Georgia." (1941)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/f016893e9d37cab0175d218547699364d9c30f76/68747470733a2f2f692e696d6775722e636f6d2f49326a38796e6d2e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/f016893e9d37cab0175d218547699364d9c30f76/68747470733a2f2f692e696d6775722e636f6d2f49326a38796e6d2e6a7067" alt="Georgia Farmhouse" data-canonical-src="https://i.imgur.com/I2j8ynm.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;"Building the Golden Gate Bridge" (est 1937)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/3b1aca12e6009a5b8a47bcfbbc84cd533b22a1de/68747470733a2f2f692e696d6775722e636f6d2f365362466a66712e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/3b1aca12e6009a5b8a47bcfbbc84cd533b22a1de/68747470733a2f2f692e696d6775722e636f6d2f365362466a66712e6a7067" alt="Golden Gate Bridge" data-canonical-src="https://i.imgur.com/6SbFjfq.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;  What you might be wondering is while this render looks cool, are the colors accurate? The original photo certainly makes it look like the towers of the bridge could be white. We looked into this and it turns out the answer is no - the towers were already covered in red primer by this time. So that's something to keep in mind- historical accuracy remains a huge challenge!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;"Terrasse de café, Paris" (1925)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ae76951da1b7106193d81c44d7da2a0b74d60077/68747470733a2f2f692e696d6775722e636f6d2f577072517750352e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/ae76951da1b7106193d81c44d7da2a0b74d60077/68747470733a2f2f692e696d6775722e636f6d2f577072517750352e6a7067" alt="Cafe Paris" data-canonical-src="https://i.imgur.com/WprQwP5.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Norwegian Bride (est late 1890s)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/03ab876e5b758529725e98bceea87f0e610106df/68747470733a2f2f692e696d6775722e636f6d2f4d6d7476725a6d2e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/03ab876e5b758529725e98bceea87f0e610106df/68747470733a2f2f692e696d6775722e636f6d2f4d6d7476725a6d2e6a7067" alt="Norwegian Bride" data-canonical-src="https://i.imgur.com/MmtvrZm.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zitkála-Šá (Lakota: Red Bird), also known as Gertrude Simmons Bonnin (1898)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/60080246c37e01c042194b2d87f4360a25637a7b/68747470733a2f2f692e696d6775722e636f6d2f7a49474d3034332e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/60080246c37e01c042194b2d87f4360a25637a7b/68747470733a2f2f692e696d6775722e636f6d2f7a49474d3034332e6a7067" alt="Native Woman" data-canonical-src="https://i.imgur.com/zIGM043.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chinese Opium Smokers (1880)&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5a05086ca8215de683081c6fb29998045fee0ddf/68747470733a2f2f692e696d6775722e636f6d2f6c5647713856712e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/5a05086ca8215de683081c6fb29998045fee0ddf/68747470733a2f2f692e696d6775722e636f6d2f6c5647713856712e6a7067" alt="Opium Real" data-canonical-src="https://i.imgur.com/lVGq8Vq.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-stuff-that-should-probably-be-in-a-paper" class="anchor" aria-hidden="true" href="#stuff-that-should-probably-be-in-a-paper"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stuff That Should Probably Be In A Paper&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-how-to-achieve-stable-video" class="anchor" aria-hidden="true" href="#how-to-achieve-stable-video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to Achieve Stable Video&lt;/h3&gt;
&lt;p&gt;NoGAN training is crucial to getting the kind of stable and colorful images seen in this iteration of DeOldify. NoGAN training combines the benefits of GAN training (wonderful colorization) while eliminating the nasty side effects (like flickering objects in video). Believe it or not, video is rendered using isolated image generation without any sort of temporal modeling tacked on. The process performs 30-60 minutes of the GAN portion of "NoGAN" training, using 1% to 3% of imagenet data once.  Then, as with still image colorization, we "DeOldify" individual frames before rebuilding the video.&lt;/p&gt;
&lt;p&gt;In addition to improved video stability, there is an interesting thing going on here worth mentioning. It turns out the models I run, even different ones and with different training structures, keep arriving at more or less the same solution.  That's even the case for the colorization of things you may think would be arbitrary and unknowable, like the color of clothing, cars, and even special effects (as seen in "Metropolis").&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ea1738479cfd9811faa49b7dc78bb59606e74cfb/68747470733a2f2f7468756d62732e6766796361742e636f6d2f48656176794c6f6e65426c6f77666973682d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/ea1738479cfd9811faa49b7dc78bb59606e74cfb/68747470733a2f2f7468756d62732e6766796361742e636f6d2f48656176794c6f6e65426c6f77666973682d73697a655f726573747269637465642e676966" alt="Metropolis Special FX" data-canonical-src="https://thumbs.gfycat.com/HeavyLoneBlowfish-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My best guess is that the models are learning some interesting rules about how to colorize based on subtle cues present in the black and white images that I certainly wouldn't expect to exist.  This result leads to nicely deterministic and consistent results, and that means you don't have track model colorization decisions because they're not arbitrary.  Additionally, they seem remarkably robust so that even in moving scenes the renders are very consistent.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/007128e9e871429b96bca83aae7f2dfa9f3d9ecc/68747470733a2f2f7468756d62732e6766796361742e636f6d2f46616d696c6961724a7562696c616e744173702d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/007128e9e871429b96bca83aae7f2dfa9f3d9ecc/68747470733a2f2f7468756d62732e6766796361742e636f6d2f46616d696c6961724a7562696c616e744173702d73697a655f726573747269637465642e676966" alt="Moving Scene Example" data-canonical-src="https://thumbs.gfycat.com/FamiliarJubilantAsp-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Other ways to stabilize video add up as well. First, generally speaking rendering at a higher resolution (higher render_factor) will increase stability of colorization decisions.  This stands to reason because the model has higher fidelity image information to work with and will have a greater chance of making the "right" decision consistently.  Closely related to this is the use of resnet101 instead of resnet34 as the backbone of the generator- objects are detected more consistently and correctly with this. This is especially important for getting good, consistent skin rendering.  It can be particularly visually jarring if you wind up with "zombie hands", for example.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2b18ba56365c70078a0672e7aaa2b402e2a25eea/68747470733a2f2f7468756d62732e6766796361742e636f6d2f54687269667479496e666572696f7249736162656c6c696e6577686561746561722d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/2b18ba56365c70078a0672e7aaa2b402e2a25eea/68747470733a2f2f7468756d62732e6766796361742e636f6d2f54687269667479496e666572696f7249736162656c6c696e6577686561746561722d73697a655f726573747269637465642e676966" alt="Zombie Hand Example" data-canonical-src="https://thumbs.gfycat.com/ThriftyInferiorIsabellinewheatear-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Additionally, gaussian noise augmentation during training appears to help but at this point the conclusions as to just how much are bit more tenuous (I just haven't formally measured this yet).  This is loosely based on work done in style transfer video, described here:  &lt;a href="https://medium.com/element-ai-research-lab/stabilizing-neural-style-transfer-for-video-62675e203e42" rel="nofollow"&gt;https://medium.com/element-ai-research-lab/stabilizing-neural-style-transfer-for-video-62675e203e42&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Special thanks go to Rani Horev for his contributions in implementing this noise augmentation.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-what-is-nogan" class="anchor" aria-hidden="true" href="#what-is-nogan"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is NoGAN?&lt;/h3&gt;
&lt;p&gt;This is a new type of GAN training that I've developed to solve some key problems in the previous DeOldify model. It provides the benefits of GAN training while spending minimal time doing direct GAN training.  Instead, most of the training time is spent pretraining the generator and critic separately with more straight-forward, fast and reliable conventional methods.  A key insight here is that those more "conventional" methods generally get you most of the results you need, and that GANs can be used to close the gap on realism. During the very short amount of actual GAN training the generator not only gets the full realistic colorization capabilities that used to take days of progressively resized GAN training, but it also doesn't accrue nearly as much of the artifacts and other ugly baggage of GANs. In fact, you can pretty much eliminate glitches and artifacts almost entirely depending on your approach. As far as I know this is a new technique. And it's incredibly effective.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Original DeOldify Model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5f92319233179b2f204b8739173abf98a69ef39a/68747470733a2f2f7468756d62732e6766796361742e636f6d2f436f6f7264696e6174656456656e657261746564486f676765742d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/5f92319233179b2f204b8739173abf98a69ef39a/68747470733a2f2f7468756d62732e6766796361742e636f6d2f436f6f7264696e6174656456656e657261746564486f676765742d73697a655f726573747269637465642e676966" alt="Before Flicker" data-canonical-src="https://thumbs.gfycat.com/CoordinatedVeneratedHogget-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NoGAN-Based DeOldify Model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/410aabdcd548bde894635617caf09eaa678a7e80/68747470733a2f2f7468756d62732e6766796361742e636f6d2f4f696c79426c61636b417263746963686172652d73697a655f726573747269637465642e676966"&gt;&lt;img src="https://camo.githubusercontent.com/410aabdcd548bde894635617caf09eaa678a7e80/68747470733a2f2f7468756d62732e6766796361742e636f6d2f4f696c79426c61636b417263746963686172652d73697a655f726573747269637465642e676966" alt="After Flicker" data-canonical-src="https://thumbs.gfycat.com/OilyBlackArctichare-size_restricted.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The steps are as follows: First train the generator in a conventional way by itself with just the feature loss. Next, generate images from that, and train the critic on distinguishing between those outputs and real images as a basic binary classifier. Finally, train the generator and critic together in a GAN setting (starting right at the target size of 192px in this case).  Now for the weird part:  All the useful GAN training here only takes place within a very small window of time.  There's an inflection point where it appears the critic has transferred everything it can that is useful to the generator. Past this point, image quality oscillates between the best that you can get at the inflection point, or bad in a predictable way (orangish skin, overly red lips, etc).  There appears to be no productive training after the inflection point.  And this point lies within training on just 1% to 3% of the Imagenet Data!  That amounts to about 30-60 minutes of training at 192px.&lt;/p&gt;
&lt;p&gt;The hard part is finding this inflection point.  So far, I've accomplished this by making a whole bunch of model save checkpoints (every 0.1% of data iterated on) and then just looking for the point where images look great before they go totally bonkers with orange skin (always the first thing to go). Additionally, generator rendering starts immediately getting glitchy and inconsistent at this point, which is no good particularly for video. What I'd really like to figure out is what the tell-tale sign of the inflection point is that can be easily automated as an early stopping point.  Unfortunately, nothing definitive is jumping out at me yet.  For one, it's happening in the middle of training loss decreasing- not when it flattens out, which would seem more reasonable on the surface.&lt;/p&gt;
&lt;p&gt;Another key thing about NoGAN training is you can repeat pretraining the critic on generated images after the initial GAN training, then repeat the GAN training itself in the same fashion.  This is how I was able to get extra colorful results with the "artistic" model.  But this does come at a cost currently- the output of the generator becomes increasingly inconsistent and you have to experiment with render resolution (render_factor) to get the best result.  But the renders are still glitch free and way more consistent than I was ever able to achieve with the original DeOldify model. You can do about five of these repeat cycles, give or take, before you get diminishing returns, as far as I can tell.&lt;/p&gt;
&lt;p&gt;Keep in mind- I haven't been entirely rigorous in figuring out what all is going on in NoGAN- I'll save that for a paper. That means there's a good chance I'm wrong about something.  But I think it's definitely worth putting out there now because I'm finding it very useful- it's solving basically much of my remaining problems I had in DeOldify.&lt;/p&gt;
&lt;p&gt;This builds upon a technique developed in collaboration with Jeremy Howard and Sylvain Gugger for Fast.AI's Lesson 7 in version 3 of Practical Deep Learning for Coders Part I. The particular lesson notebook can be found here: &lt;a href="https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres-gan.ipynb"&gt;https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres-gan.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-why-three-models" class="anchor" aria-hidden="true" href="#why-three-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why Three Models?&lt;/h2&gt;
&lt;p&gt;There are now three models to choose from in DeOldify. Each of these has key strengths and weaknesses, and so have different use cases.  Video is for video of course.  But stable and artistic are both for images, and sometimes one will do images better than the other.&lt;/p&gt;
&lt;p&gt;More details:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Artistic&lt;/strong&gt; - This model achieves the highest quality results in image coloration, in terms of interesting details and vibrance. The most notable drawback however is that it's a bit of a pain to fiddle around with to get the best results (you have to adjust the rendering resolution or render_factor to achieve this).  Additionally, the model does not do as well as stable in a few key common scenarios- nature scenes and portraits.  The model uses a resnet34 backbone on a UNet with an emphasis on depth of layers on the decoder side.  This model was trained with 5 critic pretrain/GAN cycle repeats via NoGAN, in addition to the initial generator/critic pretrain/GAN NoGAN training, at 192px.  This adds up to a total of 32% of Imagenet data trained once (12.5 hours of direct GAN training).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stable&lt;/strong&gt; - This model achieves the best results with landscapes and portraits. Notably, it produces less "zombies"- where faces or limbs stay gray rather than being colored in properly.  It generally has less weird miscolorations than artistic, but it's also less colorful in general.  This model uses a resnet101 backbone on a UNet with an emphasis on width of layers on the decoder side.  This model was trained with 3 critic pretrain/GAN cycle repeats via NoGAN, in addition to the initial generator/critic pretrain/GAN NoGAN training, at 192px.  This adds up to a total of 7% of Imagenet data trained once (3 hours of direct GAN training).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Video&lt;/strong&gt; - This model is optimized for smooth, consistent and flicker-free video.  This would definitely be the least colorful of the three models, but it's honestly not too far off from "stable". The model is the same as "stable" in terms of architecture, but differs in training.  It's trained for a mere 2.2% of Imagenet data once at 192px, using only the initial generator/critic pretrain/GAN NoGAN training (1 hour of direct GAN training).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because the training of the artistic and stable models was done before the "inflection point" of NoGAN training described in "What is NoGAN???" was discovered,  I believe this amount of training on them can be knocked down considerably. As far as I can tell, the models were stopped at "good points" that were well beyond where productive training was taking place.  I'll be looking into this in the future.&lt;/p&gt;
&lt;p&gt;Ideally, eventually these three models will be consolidated into one that has all these good desirable unified.  I think there's a path there, but it's going to require more work!  So for now, the most practical solution appears to be to maintain multiple models.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-the-technical-details" class="anchor" aria-hidden="true" href="#the-technical-details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Technical Details&lt;/h2&gt;
&lt;p&gt;This is a deep learning based model.  More specifically, what I've done is combined the following approaches:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-self-attention-generative-adversarial-network" class="anchor" aria-hidden="true" href="#self-attention-generative-adversarial-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://arxiv.org/abs/1805.08318" rel="nofollow"&gt;Self-Attention Generative Adversarial Network&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Except the generator is a &lt;strong&gt;pretrained U-Net&lt;/strong&gt;, and I've just modified it to have the spectral normalization and self-attention.  It's a pretty straightforward translation.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-two-time-scale-update-rule" class="anchor" aria-hidden="true" href="#two-time-scale-update-rule"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://arxiv.org/abs/1706.08500" rel="nofollow"&gt;Two Time-Scale Update Rule&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This is also very straightforward – it's just one to one generator/critic iterations and higher critic learning rate.
This is modified to incorporate a "threshold" critic loss that makes sure that the critic is "caught up" before moving on to generator training.
This is particularly useful for the "NoGAN" method described below.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-nogan" class="anchor" aria-hidden="true" href="#nogan"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NoGAN&lt;/h3&gt;
&lt;p&gt;There's no paper here! This is a new type of GAN training that I've developed to solve some key problems in the previous DeOldify model.
The gist is that you get the benefits of GAN training while spending minimal time doing direct GAN training.
More details are in the &lt;a href="#what-is-nogan"&gt;What is NoGAN?&lt;/a&gt; section (it's a doozy).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-generator-loss" class="anchor" aria-hidden="true" href="#generator-loss"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generator Loss&lt;/h3&gt;
&lt;p&gt;Loss during NoGAN learning is two parts:  One is a basic Perceptual Loss (or Feature Loss) based on VGG16 – this just biases the generator model to replicate the input image.
The second is the loss score from the critic.  For the curious – Perceptual Loss isn't sufficient by itself to produce good results.
It tends to just encourage a bunch of brown/green/blue – you know, cheating to the test, basically, which neural networks are really good at doing!
Key thing to realize here is that GANs essentially are learning the loss function for you – which is really one big step closer to toward the ideal that we're shooting for in machine learning.
And of course you generally get much better results when you get the machine to learn something you were previously hand coding.
That's certainly the case here.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Of note:&lt;/strong&gt;  There's no longer any "Progressive Growing of GANs" type training going on here.  It's just not needed in lieu of the superior results obtained by the "NoGAN" technique described above.&lt;/p&gt;
&lt;p&gt;The beauty of this model is that it should be generally useful for all sorts of image modification, and it should do it quite well.
What you're seeing above are the results of the colorization model, but that's just one component in a pipeline that I'm developing with the exact same approach.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-this-project-going-forward" class="anchor" aria-hidden="true" href="#this-project-going-forward"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;This Project, Going Forward&lt;/h2&gt;
&lt;p&gt;So that's the gist of this project – I'm looking to make old photos and film look reeeeaaally good with GANs, and more importantly, make the project &lt;em&gt;useful&lt;/em&gt;.
In the meantime though this is going to be my baby and I'll be actively updating and improving the code over the foreseeable future.
I'll try to make this as user-friendly as possible, but I'm sure there's going to be hiccups along the way.&lt;/p&gt;
&lt;p&gt;Oh and I swear I'll document the code properly...eventually.  Admittedly I'm &lt;em&gt;one of those&lt;/em&gt; people who believes in "self documenting code" (LOL).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started-yourself" class="anchor" aria-hidden="true" href="#getting-started-yourself"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started Yourself&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-easiest-approach" class="anchor" aria-hidden="true" href="#easiest-approach"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Easiest Approach&lt;/h3&gt;
&lt;p&gt;The easiest way to get started is to go straight to the Colab notebooks:&lt;/p&gt;
&lt;p&gt;Image &lt;a href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColab.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" align="center" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
| Video &lt;a href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/VideoColorizerColab.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" align="center" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Special thanks to Matt Robinson and María Benavente for their image Colab notebook contributions, and Robert Bell for the video Colab notebook work!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-your-own-machine-not-as-easy" class="anchor" aria-hidden="true" href="#your-own-machine-not-as-easy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Your Own Machine (not as easy)&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-hardware-and-operating-system-requirements" class="anchor" aria-hidden="true" href="#hardware-and-operating-system-requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hardware and Operating System Requirements&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;(Training Only) BEEFY Graphics card&lt;/strong&gt;.  I'd really like to have more memory than the 11 GB in my GeForce 1080TI (11GB).  You'll have a tough time with less.  The Generators and Critic are ridiculously large.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(Colorization Alone) A decent graphics card&lt;/strong&gt;. Approximately 4GB+ memory video cards should be sufficient.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linux (or maybe Windows 10)&lt;/strong&gt;  I'm using Ubuntu 16.04, but nothing about this precludes Windows 10 support as far as I know.  I just haven't tested it and am not going to make it a priority for now.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-easy-install" class="anchor" aria-hidden="true" href="#easy-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Easy Install&lt;/h4&gt;
&lt;p&gt;You should now be able to do a simple install with Anaconda. Here are the steps:&lt;/p&gt;
&lt;p&gt;Open the command line and navigate to the root folder you wish to install.  Then type the following commands&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;git clone https://github.com/jantic/DeOldify.git DeOldify&lt;/span&gt;
&lt;span class="pl-c1"&gt;cd DeOldify&lt;/span&gt;
&lt;span class="pl-c1"&gt;conda env create -f environment.yml&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then start running with these commands:&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;source activate deoldify&lt;/span&gt;
&lt;span class="pl-c1"&gt;jupyter lab&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From there you can start running the notebooks in Jupyter Lab, via the url they provide you in the console.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can also now do "conda activate deoldify" if you have the latest version of conda and in fact that's now recommended. But a lot of people don't have that yet so I'm not going to make it the default instruction here yet.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-note-on-test_images-folder" class="anchor" aria-hidden="true" href="#note-on-test_images-folder"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Note on test_images Folder&lt;/h4&gt;
&lt;p&gt;The images in the &lt;code&gt;test_images&lt;/code&gt; folder have been removed because they were using Git LFS and that costs a lot of money when GitHub actually charges for bandwidth on a popular open source project (they had a billing bug for while that was recently fixed).  The notebooks that use them (the image test ones) still point to images in that directory that I (Jason) have personally and I'd like to keep it that way because, after all, I'm by far the primary and most active developer.  But they won't work for you.  Still, those notebooks are a convenient template for making your own tests if you're so inclined.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-docker-for-jupyter" class="anchor" aria-hidden="true" href="#docker-for-jupyter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker for Jupyter&lt;/h3&gt;
&lt;p&gt;You can build and run the docker using the following process:&lt;/p&gt;
&lt;p&gt;Cloning&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;git clone https://github.com/jantic/DeOldify.git DeOldify&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Building Docker&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;cd DeOldify &amp;amp;&amp;amp; docker build -t deoldify_jupyter -f Dockerfile .&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running Docker&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;echo "http://$(curl ifconfig.io):8888" &amp;amp;&amp;amp; nvidia-docker run --ipc=host --env NOTEBOOK_PASSWORD="pass123" -p 8888:8888 -it deoldify_jupyter&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-docker-for-api" class="anchor" aria-hidden="true" href="#docker-for-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker for API&lt;/h3&gt;
&lt;p&gt;You can build and run the docker using the following process:&lt;/p&gt;
&lt;p&gt;Cloning&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;git clone https://github.com/jantic/DeOldify.git DeOldify&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Building Docker&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;cd DeOldify &amp;amp;&amp;amp; docker build -t deoldify_api -f Dockerfile-api .&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running Docker&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;echo "http://$(curl ifconfig.io):5000" &amp;amp;&amp;amp; nvidia-docker run --ipc=host -p 5000:5000 -d deoldify_api&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Calling the API for image processing&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;curl -X POST "http://MY_SUPER_API_IP:5000/process" -H "accept: image/png" -H "Content-Type: application/json" -d "{\"source_url\":\"http://www.afrikanheritage.com/wp-content/uploads/2015/08/slave-family-P.jpeg\", \"render_factor\":35}" --output colorized_image.png&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Calling the API for video processing&lt;/p&gt;
&lt;div class="highlight highlight-text-shell-session"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;curl -X POST "http://MY_SUPER_API_IP:5000/process" -H "accept: application/octet-stream" -H "Content-Type: application/json" -d "{\"source_url\":\"https://v.redd.it/d1ku57kvuf421/HLSPlaylist.m3u8\", \"render_factor\":35}" --output colorized_video.mp4&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you don't have Nvidia Docker, &lt;a href="https://github.com/nvidia/nvidia-docker/wiki/Installation-(version-2.0)#installing-version-20"&gt;here&lt;/a&gt; is the installation guide.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-installation-details" class="anchor" aria-hidden="true" href="#installation-details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation Details&lt;/h3&gt;
&lt;p&gt;This project is built around the wonderful Fast.AI library.  Prereqs, in summary:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Fast.AI 1.0.51&lt;/strong&gt; (and its dependencies).  If you use any higher version you'll see grid artifacts in rendering and tensorboard will malfunction. So yeah...don't do that.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyTorch 1.0.1&lt;/strong&gt; Not the latest version of PyTorch- that will not play nicely with the version of FastAI above.  Note however that the conda install of FastAI 1.0.51 grabs the latest PyTorch, which doesn't work.  This is patched over by our own conda install but fyi.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jupyter Lab&lt;/strong&gt; &lt;code&gt;conda install -c conda-forge jupyterlab&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tensorboard&lt;/strong&gt; (i.e. install Tensorflow) and &lt;strong&gt;TensorboardX&lt;/strong&gt; (&lt;a href="https://github.com/lanpa/tensorboardX"&gt;https://github.com/lanpa/tensorboardX&lt;/a&gt;).  I guess you don't &lt;em&gt;have&lt;/em&gt; to but man, life is so much better with it.  FastAI now comes with built in support for this- you just  need to install the prereqs: &lt;code&gt;conda install -c anaconda tensorflow-gpu&lt;/code&gt; and &lt;code&gt;pip install tensorboardX&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ImageNet&lt;/strong&gt; – Only if you're training, of course. It has proven to be a great dataset for my purposes.  &lt;a href="http://www.image-net.org/download-images" rel="nofollow"&gt;http://www.image-net.org/download-images&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-pretrained-weights" class="anchor" aria-hidden="true" href="#pretrained-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pretrained Weights&lt;/h2&gt;
&lt;p&gt;To start right away on your own machine with your own images or videos without training the models yourself, you'll need to download the "Completed Generator Weights" listed below and drop them in the /models/ folder.&lt;/p&gt;
&lt;p&gt;The colorization inference notebooks should be able to guide you from here. The notebooks to use are named ImageColorizerArtistic.ipynb, ImageColorizerStable.ipynb, and VideoColorizer.ipynb.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-completed-generator-weights" class="anchor" aria-hidden="true" href="#completed-generator-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Completed Generator Weights&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/zkehq1uwahhbc2o/ColorizeArtistic_gen.pth?dl=0" rel="nofollow"&gt;Artistic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/mwjep3vyqk5mkjc/ColorizeStable_gen.pth?dl=0" rel="nofollow"&gt;Stable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/336vn9y4qwyg9yz/ColorizeVideo_gen.pth?dl=0" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-completed-critic-weights" class="anchor" aria-hidden="true" href="#completed-critic-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Completed Critic Weights&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/8g5txfzt2fw8mf5/ColorizeArtistic_crit.pth?dl=0" rel="nofollow"&gt;Artistic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/7a8u20e7xdu1dtd/ColorizeStable_crit.pth?dl=0" rel="nofollow"&gt;Stable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/0401djgo1dfxdzt/ColorizeVideo_crit.pth?dl=0" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pretrain-only-generator-weights" class="anchor" aria-hidden="true" href="#pretrain-only-generator-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pretrain Only Generator Weights&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/9zexurvrve141n9/ColorizeArtistic_PretrainOnly_gen.pth?dl=0" rel="nofollow"&gt;Artistic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/mdnuo1563bb8nh4/ColorizeStable_PretrainOnly_gen.pth?dl=0" rel="nofollow"&gt;Stable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/avzixh1ujf86e8x/ColorizeVideo_PretrainOnly_gen.pth?dl=0" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pretrain-only-critic-weights" class="anchor" aria-hidden="true" href="#pretrain-only-critic-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pretrain Only Critic Weights&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/lakxe8akzjgjnmh/ColorizeArtistic_PretrainOnly_crit.pth?dl=0" rel="nofollow"&gt;Artistic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/b3wka56iyv1fvdc/ColorizeStable_PretrainOnly_crit.pth?dl=0" rel="nofollow"&gt;Stable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.dropbox.com/s/j7og84cbhpa94gs/ColorizeVideo_PretrainOnly_crit.pth?dl=0" rel="nofollow"&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-want-the-old-deoldify" class="anchor" aria-hidden="true" href="#want-the-old-deoldify"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Want the Old DeOldify?&lt;/h2&gt;
&lt;p&gt;We suspect some of you are going to want access to the original DeOldify model for various reasons.  We have that archived here:  &lt;a href="https://github.com/dana-kelley/DeOldify"&gt;https://github.com/dana-kelley/DeOldify&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-want-more" class="anchor" aria-hidden="true" href="#want-more"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Want More?&lt;/h2&gt;
&lt;p&gt;Follow &lt;a href="https://twitter.com/search?q=%23Deoldify" rel="nofollow"&gt;#DeOldify&lt;/a&gt; or &lt;a href="https://twitter.com/citnaj" rel="nofollow"&gt;Jason Antic&lt;/a&gt; on Twitter.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;All code in this repository is under the MIT license as specified by the LICENSE file.&lt;/p&gt;
&lt;p&gt;The model weights listed in this readme under the "Pretrained Weights" section are trained by ourselves and are released under the MIT license.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jantic</author><guid isPermaLink="false">https://github.com/jantic/DeOldify</guid><pubDate>Sat, 30 Nov 2019 00:15:00 GMT</pubDate></item><item><title>NLP-LOVE/ML-NLP #16 in Jupyter Notebook, Today</title><link>https://github.com/NLP-LOVE/ML-NLP</link><description>&lt;p&gt;&lt;i&gt;此项目是机器学习(Machine Learning)、深度学习(Deep Learning)、NLP面试中常考到的知识点和代码实现，也是作为一个算法工程师必会的理论基础知识。&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-项目介绍" class="anchor" aria-hidden="true" href="#项目介绍"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目介绍&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;此项目是&lt;strong&gt;机器学习、NLP面试&lt;/strong&gt;中常考到的&lt;strong&gt;知识点和代码实现&lt;/strong&gt;，也是作为一个算法工程师必会的理论基础知识。&lt;/li&gt;
&lt;li&gt;既然是以面试为主要目的，亦不可以篇概全，请谅解，有问题可提出。&lt;/li&gt;
&lt;li&gt;此项目以各个模块为切入点，让大家有一个清晰的知识体系。&lt;/li&gt;
&lt;li&gt;此项目亦可拿来常读、常记以及面试时复习之用。&lt;/li&gt;
&lt;li&gt;每一章里的问题都是面试时有可能问到的知识点，如有遗漏可联系我进行补充，结尾处都有算法的&lt;strong&gt;实战代码案例&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;有意向一起完成此项目或者有问题、有补充的可以加入&lt;del&gt;NLP学习QQ群【541954936】&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1群已加满，请加2群，NLP学习QQ2群【207576902】&lt;/strong&gt;&lt;a href="http://shang.qq.com/wpa/qunwpa?idkey=1defd70810d9e67ca6ab3a30e1425a8a358139315a186dd2192d82a4c0ca1ce9" rel="nofollow"&gt;&lt;img border="0" src="https://camo.githubusercontent.com/615c9901677f501582b6057efc9396b3ed27dc29/687474703a2f2f7075622e69647171696d672e636f6d2f7770612f696d616765732f67726f75702e706e67" alt="NLP学习群②" title="NLP学习群②" data-canonical-src="http://pub.idqqimg.com/wpa/images/group.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-目录" class="anchor" aria-hidden="true" href="#目录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;项目持续更新中......&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;章节&lt;/th&gt;
&lt;th&gt;负责人(GitHub)&lt;/th&gt;
&lt;th&gt;联系QQ&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/Liner%20Regression/1.Liner%20Regression.md"&gt;1. 线性回归(Liner Regression)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/2.Logistics%20Regression/2.Logistics%20Regression.md"&gt;2. 逻辑回归(Logistics Regression)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.Desition%20Tree/Desition%20Tree.md"&gt;3. 决策树(Desision Tree)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.1%20Random%20Forest/3.1%20Random%20Forest.md"&gt;3.1 随机森林(Random Forest)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.2%20GBDT/3.2%20GBDT.md"&gt;3.2 梯度提升决策树(GBDT)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.3%20XGBoost/3.3%20XGBoost.md"&gt;3.3 XGBoost&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.4%20LightGBM/3.4%20LightGBM.md"&gt;3.4 LightGBM&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/4.%20SVM/4.%20SVM.md"&gt;4. 支持向量机(SVM)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;5. 概率图模型(Probabilistic Graphical Model)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/5.1%20Bayes%20Network/5.1%20Bayes%20Network.md"&gt;5.1 贝叶斯网络(Bayesian Network)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/5.2%20Markov/5.2%20Markov.md"&gt;5.2 马尔科夫(Markov)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/5.3%20Topic%20Model"&gt;5.3 主题模型(Topic Model)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/6.%20EM"&gt;6.最大期望算法(EM)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/7.%20Clustering"&gt;7.聚类(Clustering)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/8.%20ML%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"&gt;8.ML特征工程和优化方法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine%20Learning/9.%20KNN"&gt;9.K近邻算法(KNN)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/10.%20Neural%20Network"&gt;10.神经网络(Neural Network)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/11.%20CNN"&gt;11. 卷积神经网络(CNN)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/12.%20RNN"&gt;12. 循环神经网络(RNN)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/12.1%20GRU"&gt;12.1 门控循环单元(GRU)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/12.2%20LSTM"&gt;12.2 长短期记忆(LSTM)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/13.%20Transfer%20Learning"&gt;13.迁移学习(Transfer)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/14.%20Reinforcement%20Learning"&gt;14.强化学习(Reinforcement) &amp;amp; 多任务&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/15.%20DL%20Optimizer"&gt;15. 深度学习的优化方法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.%20NLP"&gt;16. 自然语言处理(NLP)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.1%20Word%20Embedding"&gt;16.1 词嵌入(Word2Vec)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.2%20fastText"&gt;16.2 子词嵌入(fastText)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.3%20GloVe"&gt;16.3 全局向量词嵌入(GloVe)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.4%20textRNN%20%26%20textCNN"&gt;16.4 textRNN &amp;amp; textCNN&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.5%20seq2seq"&gt;16.5 序列到序列模型(seq2seq)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.6%20Attention"&gt;16.6 注意力机制(Attention Mechanism)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.7%20Transformer"&gt;16.7 Transformer模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.8%20BERT"&gt;16.8 BERT模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NLP&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.9%20XLNet"&gt;16.9 XLNet模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;项目&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System"&gt;17. 推荐系统(Recommendation System)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;项目&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/18.%20Intelligent%20Customer%20Service"&gt;18. 智能客服(Intelligent Customer Service)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/NLP-LOVE"&gt;@mantchs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;448966528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;项目&lt;/td&gt;
&lt;td&gt;19. 知识图谱(Knowledge Graph)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;项目&lt;/td&gt;
&lt;td&gt;20. 评论分析&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;欢迎大家加入！共同完善此项目！NLP学习QQ2群【207576902】&lt;a href="http://shang.qq.com/wpa/qunwpa?idkey=1defd70810d9e67ca6ab3a30e1425a8a358139315a186dd2192d82a4c0ca1ce9" rel="nofollow"&gt;&lt;img border="0" src="https://camo.githubusercontent.com/615c9901677f501582b6057efc9396b3ed27dc29/687474703a2f2f7075622e69647171696d672e636f6d2f7770612f696d616765732f67726f75702e706e67" alt="NLP学习群②" title="NLP学习群②" data-canonical-src="http://pub.idqqimg.com/wpa/images/group.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>NLP-LOVE</author><guid isPermaLink="false">https://github.com/NLP-LOVE/ML-NLP</guid><pubDate>Sat, 30 Nov 2019 00:16:00 GMT</pubDate></item><item><title>AileenNielsen/TimeSeriesAnalysisWithPython #17 in Jupyter Notebook, Today</title><link>https://github.com/AileenNielsen/TimeSeriesAnalysisWithPython</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-timeseriesanalysiswithpython" class="anchor" aria-hidden="true" href="#timeseriesanalysiswithpython"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TimeSeriesAnalysisWithPython&lt;/h1&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>AileenNielsen</author><guid isPermaLink="false">https://github.com/AileenNielsen/TimeSeriesAnalysisWithPython</guid><pubDate>Sat, 30 Nov 2019 00:17:00 GMT</pubDate></item><item><title>GoogleCloudPlatform/training-data-analyst #18 in Jupyter Notebook, Today</title><link>https://github.com/GoogleCloudPlatform/training-data-analyst</link><description>&lt;p&gt;&lt;i&gt;Labs and demos for courses for GCP Training (http://cloud.google.com/training).&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-training-data-analyst" class="anchor" aria-hidden="true" href="#training-data-analyst"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;training-data-analyst&lt;/h1&gt;
&lt;p&gt;Labs and demos for Google Cloud Platform courses (&lt;a href="http://cloud.google.com/training" rel="nofollow"&gt;http://cloud.google.com/training&lt;/a&gt;).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing-to-this-repo" class="anchor" aria-hidden="true" href="#contributing-to-this-repo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing to this repo&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Small edits are welcome! Please submit a Pull-Request. See also &lt;a href="./CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;For larger edits, please submit an issue, and we will create a branch for you. Then, get the code reviewed (in the branch) before submitting.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-organization-of-this-repo" class="anchor" aria-hidden="true" href="#organization-of-this-repo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Organization of this repo&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-try-out-the-code-on-google-cloud-platform" class="anchor" aria-hidden="true" href="#try-out-the-code-on-google-cloud-platform"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Try out the code on Google Cloud Platform&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://console.cloud.google.com/cloudshell/open/?git_repo=https://github.com/GoogleCloudPlatform/training-data-analyst.git" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c6304dc5972cf1d3766a7697b6c74f49d72fbb61/687474703a2f2f677374617469632e636f6d2f636c6f75647373682f696d616765732f6f70656e2d62746e2e706e67" alt="Open in Cloud Shell" data-canonical-src="http://gstatic.com/cloudssh/images/open-btn.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-courses" class="anchor" aria-hidden="true" href="#courses"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Courses&lt;/h2&gt;
&lt;p&gt;Code for the following courses is included in this repo:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-google-cloud-platform-big-data-and-machine-learning-fundamentals" class="anchor" aria-hidden="true" href="#google-cloud-platform-big-data-and-machine-learning-fundamentals"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Google Cloud Platform Big Data and Machine Learning Fundamentals&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-course" class="anchor" aria-hidden="true" href="#course"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://cloud.google.com/training/courses/data-ml-fundamentals" rel="nofollow"&gt;https://cloud.google.com/training/courses/data-ml-fundamentals&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-code" class="anchor" aria-hidden="true" href="#code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="CPB100"&gt;GCP Big Data &amp;amp; Machine Learning Fundamentals&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-data-engineering-on-google-cloud-platform" class="anchor" aria-hidden="true" href="#data-engineering-on-google-cloud-platform"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Engineering on Google Cloud Platform&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-course-1" class="anchor" aria-hidden="true" href="#course-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://cloud.google.com/training/courses/data-engineering" rel="nofollow"&gt;https://cloud.google.com/training/courses/data-engineering&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-code-1" class="anchor" aria-hidden="true" href="#code-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="courses/unstructured"&gt;Leveraging unstructured data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="courses/data_analysis"&gt;Serverless Data Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="courses/machine_learning"&gt;Serverless Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="courses/streaming"&gt;Resilient streaming systems&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-machine-learning-on-google-cloud-platform--advanced-ml-on-gcp" class="anchor" aria-hidden="true" href="#machine-learning-on-google-cloud-platform--advanced-ml-on-gcp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning on Google Cloud Platform (&amp;amp; Advanced ML on GCP)&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-courses-1" class="anchor" aria-hidden="true" href="#courses-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Courses&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/learn/google-machine-learning" rel="nofollow"&gt;https://www.coursera.org/learn/google-machine-learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/specializations/advanced-machine-learning-tensorflow-gcp" rel="nofollow"&gt;https://www.coursera.org/specializations/advanced-machine-learning-tensorflow-gcp&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-codes" class="anchor" aria-hidden="true" href="#codes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Codes&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="courses/machine_learning/deepdive/01_googleml"&gt;How Google Does ML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="courses/machine_learning/deepdive/02_generalization"&gt;Launching into ML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="courses/machine_learning/deepdive/03_tensorflow"&gt;Introduction to TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="courses/machine_learning/deepdive/04_features"&gt;Feature Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="courses/machine_learning/deepdive/05_artandscience"&gt;Art and Science of ML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="courses/machine_learning/deepdive/06_structured"&gt;End-to-end machine learning on Structured Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Production ML models&lt;/li&gt;
&lt;li&gt;&lt;a href="courses/machine_learning/deepdive/08_image"&gt;Image Classification Models in TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="courses/machine_learning/deepdive/09_sequence"&gt;Sequence Models for Time-Series and Text problems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="courses/machine_learning/deepdive/10_recommend"&gt;Recommendation Engines using TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-blog-posts" class="anchor" aria-hidden="true" href="#blog-posts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Blog posts&lt;/h3&gt;
&lt;p&gt;blogs/&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>GoogleCloudPlatform</author><guid isPermaLink="false">https://github.com/GoogleCloudPlatform/training-data-analyst</guid><pubDate>Sat, 30 Nov 2019 00:18:00 GMT</pubDate></item><item><title>mahmoud/awesome-python-applications #19 in Jupyter Notebook, Today</title><link>https://github.com/mahmoud/awesome-python-applications</link><description>&lt;p&gt;&lt;i&gt;💿 Free software that works great, and also happens to be open-source Python. &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-awesome-python-applications" class="anchor" aria-hidden="true" href="#awesome-python-applications"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Awesome Python Applications&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Case studies in successfully shipping Python software&lt;/em&gt; &lt;a href="https://raw.githubusercontent.com/mahmoud/awesome-python-applications/master/atom.xml" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/mahmoud/awesome-python-applications/master/templates/rss.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/mahmoud/awesome-python-applications/master/templates/snake_cd.png"&gt;&lt;img src="https://raw.githubusercontent.com/mahmoud/awesome-python-applications/master/templates/snake_cd.png" width="30%" align="right" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As developers, we spend our days with code. The site you're reading
this on is mostly modules, packages, libraries, frameworks, and the
like. But users see applications.&lt;/p&gt;
&lt;p&gt;When building our own applications, open-source Python applications
are a gold mine of practical patterns that we know work together. A
production application is worth a thousand blog posts and Stack
Overflow answers.&lt;/p&gt;
&lt;p&gt;This document is an always-growing list of &lt;strong&gt;385&lt;/strong&gt;
open-source Python applications arranged by topic, with links to
repositories, docs, and more, generated from &lt;a href="https://github.com/mahmoud/awesome-python-applications/blob/master/projects.yaml"&gt;structured
data&lt;/a&gt;
using &lt;a href="https://github.com/mahmoud/apatite"&gt;apatite&lt;/a&gt;. If you have one
to add or find some information missing, &lt;a href="https://github.com/mahmoud/awesome-python-applications/issues"&gt;please let us
know&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Read &lt;a href="http://sedimental.org/awesome_python_applications.html" rel="nofollow"&gt;&lt;strong&gt;the announcement post&lt;/strong&gt;&lt;/a&gt; to learn more about this list.&lt;br&gt;
Subscribe to &lt;a href="https://raw.githubusercontent.com/mahmoud/awesome-python-applications/master/atom.xml" rel="nofollow"&gt;&lt;strong&gt;the RSS/Atom feed&lt;/strong&gt;&lt;/a&gt; to see new applications added.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#tag-internet"&gt;Internet&lt;/a&gt; &lt;em&gt;(32)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-audio"&gt;Audio&lt;/a&gt; &lt;em&gt;(17)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-video"&gt;Video&lt;/a&gt; &lt;em&gt;(7)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-graphics"&gt;Graphics&lt;/a&gt; &lt;em&gt;(20)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-games"&gt;Games&lt;/a&gt; &lt;em&gt;(10)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-productivity"&gt;Productivity&lt;/a&gt; &lt;em&gt;(24)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-organization"&gt;Organization&lt;/a&gt; &lt;em&gt;(38)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-communication"&gt;Communication&lt;/a&gt; &lt;em&gt;(33)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-education"&gt;Education&lt;/a&gt; &lt;em&gt;(8)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-science"&gt;Science&lt;/a&gt; &lt;em&gt;(22)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-cms"&gt;CMS&lt;/a&gt; &lt;em&gt;(11)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-erp"&gt;ERP&lt;/a&gt; &lt;em&gt;(5)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-static_site"&gt;Static Site&lt;/a&gt; &lt;em&gt;(9)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev"&gt;Dev&lt;/a&gt; &lt;em&gt;(166)&lt;/em&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#tag-dev.scm"&gt;SCM&lt;/a&gt; &lt;em&gt;(17)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.code_review"&gt;Code Review&lt;/a&gt; &lt;em&gt;(4)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.storage"&gt;Storage&lt;/a&gt; &lt;em&gt;(16)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.ops"&gt;Ops&lt;/a&gt; &lt;em&gt;(25)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.security"&gt;Security&lt;/a&gt; &lt;em&gt;(24)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.docs"&gt;Docs&lt;/a&gt; &lt;em&gt;(7)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.editor"&gt;Editor&lt;/a&gt; &lt;em&gt;(12)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.pkg_mgr"&gt;Package Managers&lt;/a&gt; &lt;em&gt;(10)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.pkg_repo"&gt;Package Repositories&lt;/a&gt; &lt;em&gt;(5)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.build"&gt;Build&lt;/a&gt; &lt;em&gt;(13)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev.shell"&gt;Shell&lt;/a&gt; &lt;em&gt;(3)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-dev-other"&gt;Other Dev projects&lt;/a&gt; &lt;em&gt;(31)&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#tag-misc"&gt;Misc&lt;/a&gt; &lt;em&gt;(12)&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;&lt;a id="user-content-internet" class="anchor" aria-hidden="true" href="#internet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-internet" href="#tag-internet"&gt;Internet&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ArchiveBox&lt;/strong&gt; - (&lt;a href="https://github.com/pirate/ArchiveBox"&gt;Repo&lt;/a&gt;, &lt;a href="https://archivebox.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/pirate/ArchiveBox/wiki"&gt;Docs&lt;/a&gt;) Self-hosted web archive, for creating local, browsable backups of content from the web. Imports HTML, JS, PDFs, video, subtitles, git repositories, and more, from Pocket, Pinboard, browser history, etc. &lt;code&gt;(organization, linux, windows, docker)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;archivematica&lt;/strong&gt; - (&lt;a href="https://github.com/artefactual/archivematica"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.archivematica.org/en" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.archivematica.org/en/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Digital preservation system designed to maintain standards-based, long-term access to collections of digital objects, targeted at archivists and librarians. &lt;code&gt;(organization, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Canto&lt;/strong&gt; - (&lt;a href="https://github.com/themoken/canto-next"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Canto_%28news_aggregator%29" rel="nofollow"&gt;WP&lt;/a&gt;) RSS daemon and &lt;a href="https://github.com/themoken/canto-curses"&gt;curses-based client&lt;/a&gt;. &lt;code&gt;(linux, tui)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deluge&lt;/strong&gt; - (&lt;a href="https://github.com/deluge-torrent/deluge"&gt;Repo&lt;/a&gt;, &lt;a href="https://deluge-torrent.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Deluge_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.patreon.com/deluge_cas" rel="nofollow"&gt;Fund&lt;/a&gt;) Popular, lightweight, cross-platform BitTorrent client. &lt;code&gt;(linux, windows, mac, server, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Elixire&lt;/strong&gt; - (&lt;a href="https://gitlab.com/elixire/elixire" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://elixi.re/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://gitlab.com/elixire/api-docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Featureful file host and link shortener with API and support for multiple vanity urls. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FlaskBB&lt;/strong&gt; - (&lt;a href="https://github.com/flaskbb/flaskbb"&gt;Repo&lt;/a&gt;, &lt;a href="https://flaskbb.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://forums.flaskbb.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://flaskbb.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) A classic web forum application (bulletin board) with a modern look. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gPodder&lt;/strong&gt; - (&lt;a href="https://github.com/gpodder/gpodder"&gt;Repo&lt;/a&gt;, &lt;a href="https://gpodder.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Simple, mature media aggregator and podcast client. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hosts&lt;/strong&gt; - (&lt;a href="https://github.com/StevenBlack/hosts"&gt;Repo&lt;/a&gt;) Command-line application which merges reputable &lt;a href="https://en.wikipedia.org/wiki/Hosts_(file)" rel="nofollow"&gt;hosts files&lt;/a&gt; with deduplication for the purpose of blocking undesirable websites via DNS blackhole. &lt;code&gt;(security, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;httpie&lt;/strong&gt; - (&lt;a href="https://github.com/jakubroztocil/httpie"&gt;Repo&lt;/a&gt;, &lt;a href="https://httpie.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/httpie" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line HTTP client with JSON support, syntax highlighting, wget-like downloads, extensions, and more. &lt;code&gt;(dev, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Isso&lt;/strong&gt; - (&lt;a href="https://github.com/posativ/isso"&gt;Repo&lt;/a&gt;, &lt;a href="https://posativ.org/isso" rel="nofollow"&gt;Home&lt;/a&gt;) Lightweight commenting server, designed as a drop-in replacement for Disqus. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;KindleEar&lt;/strong&gt; - (&lt;a href="https://github.com/cdhigh/KindleEar"&gt;Repo&lt;/a&gt;, &lt;a href="https://github.com/cdhigh/KindleEar/blob/master/readme_EN.md"&gt;Docs&lt;/a&gt;) Web application to automatically aggregate RSS into periodical mobi/epub files with images and send it to your kindle or your email. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mylar&lt;/strong&gt; - (&lt;a href="https://github.com/evilhero/mylar"&gt;Repo&lt;/a&gt;) A web-based automated comic book downloader (cbr/cbz) for use with SABnzbd, NZBGet, and torrents. &lt;code&gt;(graphics, linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Neubot&lt;/strong&gt; - (&lt;a href="https://github.com/neubot/neubot"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.neubot.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Lightweight agent which collects data for net-neutrality research. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NewsBlur&lt;/strong&gt; - (&lt;a href="https://github.com/samuelclay/NewsBlur"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.newsblur.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Web-based personal news reader. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Newspipe&lt;/strong&gt; - (&lt;a href="https://gitlab.com/newspipe/newspipe" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://newspipe.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.newspipe.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://github.com/newspipe/newspipe"&gt;gh&lt;/a&gt;, &lt;a href="https://newspipe.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based news aggregator and reader. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nsupdate.info&lt;/strong&gt; - (&lt;a href="https://github.com/nsupdate-info/nsupdate.info"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/nsupdate" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://nsupdateinfo.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Featureful dynamic DNS service, using the Dynamic DNS UPDATE protocol (&lt;a href="https://tools.ietf.org/html/rfc2136" rel="nofollow"&gt;RFC 2136&lt;/a&gt;) to update BIND and other major nameservers. &lt;code&gt;(ops, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nyaa&lt;/strong&gt; - (&lt;a href="https://github.com/nyaadevs/nyaa"&gt;Repo&lt;/a&gt;) Bittorrent tracker software built for anime site &lt;a href="https://nyaa.si/" rel="nofollow"&gt;nyaa.si&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pi-Hole&lt;/strong&gt; - (&lt;a href="https://github.com/pi-hole/pi-hole"&gt;Repo&lt;/a&gt;, &lt;a href="https://pi-hole.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Pi-hole" rel="nofollow"&gt;WP&lt;/a&gt;) Linux network-level advertisement and internet tracker blocking application which acts as a DNS sinkhole, and (optionally) a DHCP server, intended for use on a private network. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Planet&lt;/strong&gt; - (&lt;a href="https://github.com/python/planet"&gt;Repo&lt;/a&gt;, &lt;a href="https://web.archive.org/web/20051029095046/http%3A/www.planetplanet.org" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Planet_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) RSS and Atom feed aggregator, designed to collect posts from the weblogs of members of an Internet community and display them on a single page. Used to power &lt;a href="https://planetpython.org/" rel="nofollow"&gt;Planet Python&lt;/a&gt; and many more. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pol&lt;/strong&gt; - (&lt;a href="https://github.com/taroved/pol"&gt;Repo&lt;/a&gt;, &lt;a href="https://politepol.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Web application which allows users to subscribe to changes on a web site via an autogenerated RSS feed. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyLoad&lt;/strong&gt; - (&lt;a href="https://github.com/pyload/pyload"&gt;Repo&lt;/a&gt;, &lt;a href="https://pyload.net/" rel="nofollow"&gt;Home&lt;/a&gt;) Download manager with a web interface and API. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Qute Browser&lt;/strong&gt; - (&lt;a href="https://github.com/qutebrowser/qutebrowser"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.qutebrowser.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Keyboard-driven, minimal, &lt;code&gt;vim&lt;/code&gt;-like browser based on PyQt5. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reddit&lt;/strong&gt; - (&lt;a href="https://github.com/reddit-archive/reddit"&gt;Repo&lt;/a&gt;, &lt;a href="http://reddit.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Social news forum with voting, commenting, karma, and more. (Archival repo from 2017.) &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SABnzbd&lt;/strong&gt; - (&lt;a href="https://github.com/sabnzbd/sabnzbd"&gt;Repo&lt;/a&gt;, &lt;a href="https://sabnzbd.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://sabnzbd.org/wiki" rel="nofollow"&gt;Docs&lt;/a&gt;) Simple, cross-platform newsreader for downloading from Usenet. Supports many integrations and 16 languages. &lt;code&gt;(linux, windows, mac, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Searx&lt;/strong&gt; - (&lt;a href="https://github.com/asciimoo/searx"&gt;Repo&lt;/a&gt;, &lt;a href="https://asciimoo.github.io/searx" rel="nofollow"&gt;Docs&lt;/a&gt;) Self-hosted metasearch engine, aggregating results from more than 70 services while avoiding tracking and profiling. &lt;code&gt;(security, server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;speedtest-cli&lt;/strong&gt; - (&lt;a href="https://github.com/sivel/speedtest-cli"&gt;Repo&lt;/a&gt;) Command-line interface for testing Internet bandwidth using &lt;a href="https://speedtest.net" rel="nofollow"&gt;speedtest.net&lt;/a&gt;. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;streamlink&lt;/strong&gt; - (&lt;a href="https://github.com/streamlink/streamlink"&gt;Repo&lt;/a&gt;, &lt;a href="https://streamlink.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/streamlink" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line utility that extracts streams from various services and pipes them into a video player of choice. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;syncserver&lt;/strong&gt; - (&lt;a href="https://github.com/mozilla-services/syncserver"&gt;Repo&lt;/a&gt;, &lt;a href="https://mozilla-services.readthedocs.io/en/latest/howtos/run-sync-1.5.html" rel="nofollow"&gt;Docs&lt;/a&gt;) All-in-one package for running a self-hosted Mozilla Firefox Sync server. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tribler&lt;/strong&gt; - (&lt;a href="https://github.com/Tribler/tribler"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.tribler.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Tribler" rel="nofollow"&gt;WP&lt;/a&gt;) Privacy enhanced BitTorrent client with P2P content discovery. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;You-Get&lt;/strong&gt; - (&lt;a href="https://github.com/soimort/you-get"&gt;Repo&lt;/a&gt;, &lt;a href="https://you-get.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Command-line program to browserlessly scrape and stream video, audio, and images from web sites. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;youtube-dl&lt;/strong&gt; - (&lt;a href="https://github.com/rg3/youtube-dl"&gt;Repo&lt;/a&gt;, &lt;a href="http://rg3.github.io/youtube-dl" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/youtube_dl" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line program to browserlessly archive video and audio from YouTube and hundreds of other sites. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ZeroNet&lt;/strong&gt; - (&lt;a href="https://github.com/HelloZeroNet/ZeroNet"&gt;Repo&lt;/a&gt;, &lt;a href="https://zeronet.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/ZeroNet" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://zeronet.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Open, free, and uncensorable websites, using Bitcoin cryptography and BitTorrent network. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-audio" class="anchor" aria-hidden="true" href="#audio"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-audio" href="#tag-audio"&gt;Audio&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Beets&lt;/strong&gt; - (&lt;a href="https://github.com/beetbox/beets"&gt;Repo&lt;/a&gt;, &lt;a href="http://beets.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/beets" rel="nofollow"&gt;PyPI&lt;/a&gt;) Feature-rich command-line music library manager with web UI, duplicate detection, transcoding, and tagging support, integrating with MusicBrainz, Discogs, and more. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exaile&lt;/strong&gt; - (&lt;a href="https://github.com/exaile/exaile"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Exaile" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform audio player, tag editor, and library organizer. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Frescobaldi&lt;/strong&gt; - (&lt;a href="https://github.com/wbsoft/frescobaldi"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Frescobaldi_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) An editor for &lt;a href="https://en.wikipedia.org/wiki/LilyPond" rel="nofollow"&gt;LilyPond&lt;/a&gt; music files. &lt;code&gt;(linux, windows, mac, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Friture&lt;/strong&gt; - (&lt;a href="https://github.com/tlecomte/friture"&gt;Repo&lt;/a&gt;, &lt;a href="http://friture.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Visualizes and analyzes live audio data in real-time, including scope, spectrum analyzer, rolling 2D spectrogram, and more. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Funkwhale&lt;/strong&gt; - (&lt;a href="https://dev.funkwhale.audio/funkwhale/funkwhale" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://funkwhale.audio/en_US" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.funkwhale.audio/" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based, community-driven project that lets you listen and share music and audio within a decentralized, open network. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GNU Radio&lt;/strong&gt; - (&lt;a href="https://github.com/gnuradio/gnuradio"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.gnuradio.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GNU_Radio" rel="nofollow"&gt;WP&lt;/a&gt;) Software development toolkit that provides signal processing blocks to implement software-defined radios and signal-processing systems. &lt;code&gt;(linux, windows, mac, cpp, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GNU Solfege&lt;/strong&gt; - (&lt;a href="http://git.savannah.gnu.org/cgit/solfege.git" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GNU_Solfege" rel="nofollow"&gt;WP&lt;/a&gt;) An ear-training program intended to help musicians improve their skills. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mopidy&lt;/strong&gt; - (&lt;a href="https://github.com/mopidy/mopidy"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.mopidy.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Extensible music player server with plugin support for a wide range of services. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Music Player&lt;/strong&gt; - (&lt;a href="https://github.com/albertz/music-player"&gt;Repo&lt;/a&gt;, &lt;a href="http://albertz.github.io/music-player" rel="nofollow"&gt;Home&lt;/a&gt;) A simple music player designed around an infinite intelligent playlist, with support for headless playback. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MusicBrainz Picard&lt;/strong&gt; - (&lt;a href="https://github.com/metabrainz/picard"&gt;Repo&lt;/a&gt;, &lt;a href="https://picard.musicbrainz.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/MusicBrainz_Picard" rel="nofollow"&gt;WP&lt;/a&gt;) Automatically identify, tag, and organize music albums and other digital audio recordings. &lt;code&gt;(linux, windows, mac, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Musikernel&lt;/strong&gt; - (&lt;a href="https://github.com/j3ffhubb/musikernel"&gt;Repo&lt;/a&gt;) All-in-one Digital Audio Workstation (DAW) with a suite of instrument and effect plugins. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PuddleTag&lt;/strong&gt; - (&lt;a href="https://github.com/keithgg/puddletag"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Puddletag" rel="nofollow"&gt;WP&lt;/a&gt;) An audio tag (metadata) editor for audio file formats. &lt;code&gt;(linux, qt4)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quod Libet&lt;/strong&gt; - (&lt;a href="https://github.com/quodlibet/quodlibet"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Quod_Libet_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform audio player, tag editor, and library organizer. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SoundConverter&lt;/strong&gt; - (&lt;a href="https://github.com/kassoulet/soundconverter"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GNOME_SoundConverter" rel="nofollow"&gt;WP&lt;/a&gt;) A GNOME-based audio file transcoder. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SoundGrain&lt;/strong&gt; - (&lt;a href="https://github.com/belangeo/soundgrain"&gt;Repo&lt;/a&gt;, &lt;a href="http://ajaxsoundstudio.com/software/soundgrain" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=9CA99DH6ES3HA" rel="nofollow"&gt;Fund&lt;/a&gt;) Graphical interface designed for drawing and editing trajectories to control &lt;a href="https://en.wikipedia.org/wiki/Granular_synthesis" rel="nofollow"&gt;granular sound synthesis&lt;/a&gt;. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Supysonic&lt;/strong&gt; - (&lt;a href="https://github.com/spl0k/supysonic"&gt;Repo&lt;/a&gt;) Implementation of the &lt;a href="http://www.subsonic.org/" rel="nofollow"&gt;Subsonic server API&lt;/a&gt;, with support for browsing, streaming, transcoding, scrobbling, and more. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Whipper&lt;/strong&gt; - (&lt;a href="https://github.com/whipper-team/whipper"&gt;Repo&lt;/a&gt;) A CLI-based CD Audio ripper designed for accuracy over speed, with support for overriding hardware caches, accuracy verification, MusicBrainz metadata lookup, hidden tracks, FLAC, and much more. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-video" class="anchor" aria-hidden="true" href="#video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-video" href="#tag-video"&gt;Video&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Flowblade&lt;/strong&gt; - (&lt;a href="https://github.com/jliljebl/flowblade"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Flowblade" rel="nofollow"&gt;WP&lt;/a&gt;) Multitrack, non-linear video editing software for Linux. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Open Streaming Platform&lt;/strong&gt; - (&lt;a href="https://gitlab.com/Deamos/flask-nginx-rtmp-manager" rel="nofollow"&gt;Repo&lt;/a&gt;) Self-hosted video streaming and recording server, designed as an alternative to Twitch and YouTube. &lt;code&gt;(games, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenShot&lt;/strong&gt; - (&lt;a href="https://github.com/OpenShot/openshot-qt"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.openshot.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/OpenShot" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.patreon.com/openshot" rel="nofollow"&gt;Fund&lt;/a&gt;) A cross-platform video editor for FreeBSD, Linux, macOS, and Windows. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pitivi&lt;/strong&gt; - (&lt;a href="https://gitlab.gnome.org/GNOME/pitivi" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Pitivi" rel="nofollow"&gt;WP&lt;/a&gt;) Non-linear video editor for Linux, based on GStreamer. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plumi&lt;/strong&gt; - (&lt;a href="https://github.com/plumi/plumi.app"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Plumi" rel="nofollow"&gt;WP&lt;/a&gt;) Video sharing content management system based on &lt;a href="https://en.wikipedia.org/wiki/Plone_(software)" rel="nofollow"&gt;Plone&lt;/a&gt;. &lt;code&gt;(cms, server, plone)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyVideo&lt;/strong&gt; - (&lt;a href="https://github.com/pyvideo/pyvideo"&gt;Repo&lt;/a&gt;, &lt;a href="https://pyvideo.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Static media index custom-built for the Python community, and all the content our meetings and conferences produce. &lt;code&gt;(static_site, linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vidcutter&lt;/strong&gt; - (&lt;a href="https://github.com/ozmartian/vidcutter"&gt;Repo&lt;/a&gt;) GUI and CLI aiming to be the fastest and simplest way to cut and join video. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-graphics" class="anchor" aria-hidden="true" href="#graphics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-graphics" href="#tag-graphics"&gt;Graphics&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;cartoonify / Draw This.&lt;/strong&gt; - (&lt;a href="https://github.com/danmacnish/cartoonify"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.kapwing.com/cartoonify" rel="nofollow"&gt;Home&lt;/a&gt;) Turn a photograph into a toddler's drawing. Automatically! &lt;code&gt;(console, docker, hardware)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cura&lt;/strong&gt; - (&lt;a href="https://github.com/Ultimaker/Cura"&gt;Repo&lt;/a&gt;, &lt;a href="https://ultimaker.com/software/ultimaker-cura" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Cura_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://ultimaker.com/en/resources/manuals/software" rel="nofollow"&gt;Docs&lt;/a&gt;) Popular desktop software for preparation and control of 3D printing, integrated with CAD workflows. &lt;code&gt;(linux, windows, mac, corp, hardware)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DrawBot&lt;/strong&gt; - (&lt;a href="https://github.com/typemytype/drawbot"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.drawbot.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/DrawBot" rel="nofollow"&gt;WP&lt;/a&gt;) A powerful programmatic 2D drawing application for MacOS X which generates graphics from Python scripts. &lt;code&gt;(education, dev, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FreeCAD&lt;/strong&gt; - (&lt;a href="https://github.com/FreeCAD/FreeCAD"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/FreeCAD" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://salt.bountysource.com/teams/freecad" rel="nofollow"&gt;Fund&lt;/a&gt;) General-purpose parametric 3D CAD modeler and a building information modeling (BIM) software with finite-element-method (FEM) support. &lt;code&gt;(linux, windows, mac, cpp, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gaphor&lt;/strong&gt; - (&lt;a href="https://github.com/gaphor/gaphor"&gt;Repo&lt;/a&gt;, &lt;a href="https://gaphor.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Simple &lt;a href="https://en.wikipedia.org/wiki/Unified_Modeling_Language" rel="nofollow"&gt;UML&lt;/a&gt; modeling tool designed for beginners. &lt;code&gt;(docs, linux, windows, mac, flatpak, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lector&lt;/strong&gt; - (&lt;a href="https://github.com/BasioMeusPuga/Lector"&gt;Repo&lt;/a&gt;) Desktop ebook reader and browser, with support for many formats, including comic book archives. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MakeHuman&lt;/strong&gt; - (&lt;a href="https://bitbucket.org/MakeHuman/makehuman" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/MakeHuman" rel="nofollow"&gt;WP&lt;/a&gt;) 3D computer graphics software designed for the prototyping of photo realistic humanoids. &lt;code&gt;(linux, windows, mac, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Meshroom&lt;/strong&gt; - (&lt;a href="https://github.com/alicevision/meshroom"&gt;Repo&lt;/a&gt;, &lt;a href="http://alicevision.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Photogrammetry pipeline, for turning photographs into 3D models. &lt;code&gt;(linux, windows, mac, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mylar&lt;/strong&gt; - (&lt;a href="https://github.com/evilhero/mylar"&gt;Repo&lt;/a&gt;) A web-based automated comic book downloader (cbr/cbz) for use with SABnzbd, NZBGet, and torrents. &lt;code&gt;(internet, linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MyPaint&lt;/strong&gt; - (&lt;a href="https://github.com/mypaint/mypaint"&gt;Repo&lt;/a&gt;, &lt;a href="http://mypaint.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/MyPaint" rel="nofollow"&gt;WP&lt;/a&gt;) Raster graphics editor for digital painters with a focus on painting rather than image manipulation. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NFO Viewer&lt;/strong&gt; - (&lt;a href="https://github.com/otsaloma/nfoview"&gt;Repo&lt;/a&gt;, &lt;a href="https://otsaloma.io/nfoview" rel="nofollow"&gt;Home&lt;/a&gt;) A simple viewer for NFO files and the ASCII art therein, with preset fonts, encodings, automatic window sizing, and clickable hyperlinks. &lt;code&gt;(misc, linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OCRFeeder&lt;/strong&gt; - (&lt;a href="https://gitlab.gnome.org/GNOME/ocrfeeder" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/OCRFeeder" rel="nofollow"&gt;WP&lt;/a&gt;) An optical character recognition suite for GNOME, with support for command-line OCR engines like CuneiForm, GOCR, Ocrad and Tesseract. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OCRopus&lt;/strong&gt; - (&lt;a href="https://github.com/tmbdev/ocropy"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/OCRopus" rel="nofollow"&gt;WP&lt;/a&gt;) Document analysis and optical character recognition (OCR) system. &lt;code&gt;(linux, mac, console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Octoprint&lt;/strong&gt; - (&lt;a href="https://github.com/foosel/OctoPrint"&gt;Repo&lt;/a&gt;, &lt;a href="https://octoprint.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.patreon.com/foosel" rel="nofollow"&gt;Fund&lt;/a&gt;) Web-based controller for consumer 3D printers. &lt;code&gt;(server, flask, hardware)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PhotoCollage&lt;/strong&gt; - (&lt;a href="https://github.com/adrienverge/PhotoCollage"&gt;Repo&lt;/a&gt;) Automatically lays out a photo collage to fill out a given poster space. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Photonix&lt;/strong&gt; - (&lt;a href="https://github.com/damianmoore/photonix"&gt;Repo&lt;/a&gt;, &lt;a href="https://photonix.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://demo.photonix.org/" rel="nofollow"&gt;Demo&lt;/a&gt;) Web-based photo management, featuring smart filtering with object recognition, location awareness, color analysis, and more. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pynocchio&lt;/strong&gt; - (&lt;a href="https://github.com/mstuttgart/pynocchio"&gt;Repo&lt;/a&gt;, &lt;a href="https://mstuttgart.github.io/pynocchio" rel="nofollow"&gt;Home&lt;/a&gt;) Minimalist comic reader, supporting many common image and archive formats. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quru Image Server&lt;/strong&gt; - (&lt;a href="https://github.com/quru/qis"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.quruimageserver.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://images.quru.com/demo" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://github.com/quru/qis/blob/master/doc/overview.md"&gt;Docs&lt;/a&gt;) High-performance web server for creating and delivering dynamic images. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SK1&lt;/strong&gt; - (&lt;a href="https://github.com/sk1project/sk1-wx"&gt;Repo&lt;/a&gt;, &lt;a href="https://sk1project.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/SK1_%28program%29" rel="nofollow"&gt;WP&lt;/a&gt;) Feature-rich, cross-platform illustration program. &lt;code&gt;(linux, windows, mac, gtk, wx)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Thumbor&lt;/strong&gt; - (&lt;a href="https://github.com/thumbor/thumbor"&gt;Repo&lt;/a&gt;, &lt;a href="http://thumbor.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://thumbor.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Photo thumbnail service with resizing, flipping, and smart cropping of images. &lt;code&gt;(dev, server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-games" class="anchor" aria-hidden="true" href="#games"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-games" href="#tag-games"&gt;Games&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Cataclysm: Dark Days Ahead (Launcher)&lt;/strong&gt; - (&lt;a href="https://github.com/remyroy/CDDA-Game-Launcher"&gt;Repo&lt;/a&gt;, &lt;a href="https://cataclysmdda.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Launcher for popular FOSS game &lt;a href="https://cataclysmdda.org/" rel="nofollow"&gt;CDDA&lt;/a&gt;, which supports automatic updates and mod management. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Frets on Fire X&lt;/strong&gt; - (&lt;a href="https://github.com/fofix/fofix"&gt;Repo&lt;/a&gt;) Highly customizable rhythm game supporting many modes of guitar, bass, drum, and vocal gameplay for up to four players. &lt;code&gt;(linux, windows, pygame)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lucas Chess&lt;/strong&gt; - (&lt;a href="https://github.com/lukasmonk/lucaschess"&gt;Repo&lt;/a&gt;, &lt;a href="http://lucaschess.pythonanywhere.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Featureful chess client for Windows, with some Linux support. &lt;code&gt;(linux, windows, qt4)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lutris&lt;/strong&gt; - (&lt;a href="https://github.com/lutris/lutris"&gt;Repo&lt;/a&gt;, &lt;a href="https://lutris.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Lutris" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.patreon.com/lutris" rel="nofollow"&gt;Fund&lt;/a&gt;) Gaming platform for GNU/Linux, managing game installations with a unified interface. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Open Streaming Platform&lt;/strong&gt; - (&lt;a href="https://gitlab.com/Deamos/flask-nginx-rtmp-manager" rel="nofollow"&gt;Repo&lt;/a&gt;) Self-hosted video streaming and recording server, designed as an alternative to Twitch and YouTube. &lt;code&gt;(video, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyChess&lt;/strong&gt; - (&lt;a href="https://github.com/pychess/pychess"&gt;Repo&lt;/a&gt;, &lt;a href="http://pychess.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/PyChess" rel="nofollow"&gt;WP&lt;/a&gt;) Advanced chess client, suitable for new, casual, and competitive play. &lt;code&gt;(linux, windows, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pyfa&lt;/strong&gt; - (&lt;a href="https://github.com/pyfa-org/Pyfa"&gt;Repo&lt;/a&gt;) Python Fitting Assistant, cross-platform experimentation tool for &lt;a href="https://en.wikipedia.org/wiki/Eve_Online" rel="nofollow"&gt;EVE Online&lt;/a&gt; ship fittings. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PySolFC&lt;/strong&gt; - (&lt;a href="https://github.com/shlomif/PySolFC"&gt;Repo&lt;/a&gt;, &lt;a href="https://pysolfc.sourceforge.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://f-droid.org/en/packages/org.lufebe16.pysolfc" rel="nofollow"&gt;Android&lt;/a&gt;) Highly-portable collection of solitaire card games. &lt;code&gt;(linux, windows, android, kivy, tk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;term2048&lt;/strong&gt; - (&lt;a href="https://github.com/bfontaine/term2048"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.python.org/pypi/term2048" rel="nofollow"&gt;PyPI&lt;/a&gt;) TUI version of &lt;a href="http://gabrielecirulli.github.io/2048/" rel="nofollow"&gt;2048&lt;/a&gt;. &lt;code&gt;(linux, mac, tui)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unknown Horizons&lt;/strong&gt; - (&lt;a href="https://github.com/unknown-horizons/unknown-horizons"&gt;Repo&lt;/a&gt;, &lt;a href="http://unknown-horizons.org/" rel="nofollow"&gt;Home&lt;/a&gt;) 2D real-time strategy simulation with an emphasis on economy and city building. (Not unlike Age of Empires) &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-productivity" class="anchor" aria-hidden="true" href="#productivity"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-productivity" href="#tag-productivity"&gt;Productivity&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Autokey&lt;/strong&gt; - (&lt;a href="https://github.com/autokey/autokey"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/AutoKey" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://pypi.org/project/autokey" rel="nofollow"&gt;PyPI&lt;/a&gt;) Desktop automation utility for Linux and X11. &lt;code&gt;(linux, gtk, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bleachbit&lt;/strong&gt; - (&lt;a href="https://github.com/bleachbit/bleachbit"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.bleachbit.org/" rel="nofollow"&gt;Home&lt;/a&gt;) System cleaner designed to free disk space and maintain privacy. &lt;code&gt;(linux, windows, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BorgBackup&lt;/strong&gt; - (&lt;a href="https://github.com/borgbackup/borg"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.borgbackup.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Deduplicating backup system with optional encryption and other features. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bup&lt;/strong&gt; - (&lt;a href="https://github.com/Bup/Bup"&gt;Repo&lt;/a&gt;, &lt;a href="https://bup.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Efficient backup system based on the git packfile format, providing fast incremental saves and global deduplication. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Excalibur&lt;/strong&gt; - (&lt;a href="https://github.com/camelot-dev/excalibur"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.tryexcalibur.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Web interface to extract tabular data from PDFs. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Glances&lt;/strong&gt; - (&lt;a href="https://github.com/nicolargo/glances"&gt;Repo&lt;/a&gt;, &lt;a href="https://nicolargo.github.io/glances" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://glances.readthedocs.io/en/stable" rel="nofollow"&gt;Docs&lt;/a&gt;) A cross-platform top/htop alternative, providing an overview of system resources. &lt;code&gt;(ops, linux, windows, mac, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gmvault&lt;/strong&gt; - (&lt;a href="https://github.com/gaubert/gmvault"&gt;Repo&lt;/a&gt;, &lt;a href="http://gmvault.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Tool for backing up gmail accounts. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gridsync&lt;/strong&gt; - (&lt;a href="https://github.com/gridsync/gridsync"&gt;Repo&lt;/a&gt;) Cross-platform GUI built to synchronize local directories with Tahoe-LAFS storage grids. &lt;code&gt;(storage, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GTimeLog&lt;/strong&gt; - (&lt;a href="https://github.com/gtimelog/gtimelog"&gt;Repo&lt;/a&gt;, &lt;a href="https://gtimelog.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://ko-fi.com/mgedmin" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://gtimelog.org/docs.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Desktop-based time tracker with support for logging billable/non-billable work. &lt;code&gt;(organization, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kibitzr&lt;/strong&gt; - (&lt;a href="https://github.com/kibitzr/kibitzr"&gt;Repo&lt;/a&gt;, &lt;a href="https://kibitzr.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/kibitzr" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://kibitzr.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Self-hosted personal assistant server for automating routine tasks. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mackup&lt;/strong&gt; - (&lt;a href="https://github.com/lra/mackup"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/mackup" rel="nofollow"&gt;PyPI&lt;/a&gt;) Utility to back up and synchronize application settings, with support for several storage backends (e.g., Dropbox, Git), and dozens of applications. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Metamorphose&lt;/strong&gt; - (&lt;a href="https://github.com/metamorphose/metamorphose2"&gt;Repo&lt;/a&gt;, &lt;a href="http://file-folder-ren.sourceforge.net/" rel="nofollow"&gt;Home&lt;/a&gt;) Graphical mass renaming program for files and folders. &lt;code&gt;(linux, windows, mac, wx)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nuxeo Drive&lt;/strong&gt; - (&lt;a href="https://github.com/nuxeo/nuxeo-drive"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.nuxeo.com/products/drive-desktop-sync" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://doc.nuxeo.com/client-apps/nuxeo-drive" rel="nofollow"&gt;Docs&lt;/a&gt;) Cross-platform desktop synchronization client for the Nuxeo platform. &lt;code&gt;(storage, linux, windows, mac, console, appimage, lgpl, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nvda&lt;/strong&gt; - (&lt;a href="https://github.com/nvaccess/nvda"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.nvaccess.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Non-Visual Desktop Access, a powerful screen reader for Windows. &lt;code&gt;(windows, wx)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plover&lt;/strong&gt; - (&lt;a href="https://github.com/openstenoproject/plover"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.openstenoproject.org/plover" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.openstenoproject.org/donate" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://github.com/openstenoproject/plover/wiki"&gt;Docs&lt;/a&gt;) Background service for automatic translation of stenography movements to keystrokes, enabling typing speeds in excess of 200WPM in any application. &lt;code&gt;(linux, windows, mac, hardware, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Psono&lt;/strong&gt; - (&lt;a href="https://gitlab.com/psono/psono-server" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://psono.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.psono.pw/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://doc.psono.com/" rel="nofollow"&gt;Docs&lt;/a&gt;) Server-based password manager, built for teams. &lt;code&gt;(security, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ranger&lt;/strong&gt; - (&lt;a href="https://github.com/ranger/ranger"&gt;Repo&lt;/a&gt;, &lt;a href="https://ranger.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;) TUI (&lt;a href="https://en.wikipedia.org/wiki/Text-based_user_interface" rel="nofollow"&gt;Text User Interface&lt;/a&gt;) file manager, inspired by vim. &lt;code&gt;(linux, tui)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Redash&lt;/strong&gt; - (&lt;a href="https://github.com/getredash/redash"&gt;Repo&lt;/a&gt;, &lt;a href="https://redash.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Data visualization and dashboard construction geared toward business intelligence, used by Mozilla, SoundCloud, Sentry, and others. &lt;code&gt;(server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ReproZip&lt;/strong&gt; - (&lt;a href="https://github.com/VIDA-NYU/reprozip"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.reprozip.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://examples.reprozip.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://docs.reprozip.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Command-line tool which automatically builds reproducible experiments archives from console commands, designed for use in computational science. &lt;code&gt;(science, linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sunflower&lt;/strong&gt; - (&lt;a href="https://github.com/MeanEYE/Sunflower"&gt;Repo&lt;/a&gt;, &lt;a href="http://sunflower-fm.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Small and highly-customizable twin-panel file manager for Linux with plugin support. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Superset&lt;/strong&gt; - (&lt;a href="https://github.com/apache/incubator-superset"&gt;Repo&lt;/a&gt;, &lt;a href="http://superset.apache.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Data exploration, visualization, and business intelligence web application. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VisiData&lt;/strong&gt; - (&lt;a href="https://github.com/saulpw/visidata"&gt;Repo&lt;/a&gt;, &lt;a href="https://visidata.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://patreon.com/saulpw" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://pypi.org/project/visidata" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://visidata.org/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Interactive multitool for exploring, analyzing, and converting datasets in the terminal. &lt;code&gt;(linux, mac, tui)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vorta&lt;/strong&gt; - (&lt;a href="https://github.com/borgbase/vorta"&gt;Repo&lt;/a&gt;, &lt;a href="https://vorta.borgbase.com/" rel="nofollow"&gt;Home&lt;/a&gt;) GUI backup client built on top of &lt;a href="https://borgbackup.readthedocs.io/" rel="nofollow"&gt;BorgBackup&lt;/a&gt;. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;wttr.in&lt;/strong&gt; - (&lt;a href="https://github.com/chubin/wttr.in"&gt;Repo&lt;/a&gt;, &lt;a href="http://wttr.in/" rel="nofollow"&gt;Home&lt;/a&gt;) Weather forecast service that supports various representations, suitable for the terminal or web browser. &lt;code&gt;(server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-organization" class="anchor" aria-hidden="true" href="#organization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-organization" href="#tag-organization"&gt;Organization&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Ambar&lt;/strong&gt; - (&lt;a href="https://github.com/RD17/ambar"&gt;Repo&lt;/a&gt;, &lt;a href="https://ambar.cloud/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://app.ambar.cloud/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://ambar.cloud/docs/system-requirements" rel="nofollow"&gt;Docs&lt;/a&gt;) Document search engine with automated crawling, OCR, tagging, and instant full-text search. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ArchiveBox&lt;/strong&gt; - (&lt;a href="https://github.com/pirate/ArchiveBox"&gt;Repo&lt;/a&gt;, &lt;a href="https://archivebox.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/pirate/ArchiveBox/wiki"&gt;Docs&lt;/a&gt;) Self-hosted web archive, for creating local, browsable backups of content from the web. Imports HTML, JS, PDFs, video, subtitles, git repositories, and more, from Pocket, Pinboard, browser history, etc. &lt;code&gt;(internet, linux, windows, docker)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;archivematica&lt;/strong&gt; - (&lt;a href="https://github.com/artefactual/archivematica"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.archivematica.org/en" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.archivematica.org/en/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Digital preservation system designed to maintain standards-based, long-term access to collections of digital objects, targeted at archivists and librarians. &lt;code&gt;(internet, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Baby Buddy&lt;/strong&gt; - (&lt;a href="https://github.com/cdubz/babybuddy"&gt;Repo&lt;/a&gt;, &lt;a href="http://demo.baby-buddy.net/" rel="nofollow"&gt;Demo&lt;/a&gt;) Mobile-friendly web application which helps caregivers track sleep, feedings, diaper changes, and tummy time to learn about and predict baby's needs without (as much) guesswork. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;beancount&lt;/strong&gt; - (&lt;a href="https://bitbucket.org/blais/beancount" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://furius.ca/beancount" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/beancount/beancount"&gt;gh&lt;/a&gt;, &lt;a href="https://pypi.org/project/beancount" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://docs.google.com/document/d/1RaondTJCS_IUPBHFNdT8oqFKJjVJDsfsn6JEjBG04eA/edit" rel="nofollow"&gt;Docs&lt;/a&gt;) A double-entry bookkeeping language to define financial transaction records in plain text, then generate a variety of reports, via CLI and web interface. (See also, &lt;a href="https://plaintextaccounting.org/" rel="nofollow"&gt;Plain Text Accounting&lt;/a&gt;). &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Byro&lt;/strong&gt; - (&lt;a href="https://github.com/byro/byro"&gt;Repo&lt;/a&gt;, &lt;a href="https://byro.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based membership administration tool for small and medium sized clubs/NGOs/associations of all kinds, with a focus on the DACH region. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Calibre&lt;/strong&gt; - (&lt;a href="https://github.com/kovidgoyal/calibre"&gt;Repo&lt;/a&gt;, &lt;a href="https://calibre-ebook.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Calibre_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.patreon.com/kovidgoyal" rel="nofollow"&gt;Fund&lt;/a&gt;) E-book manager designed for viewing, converting, editing, and cataloging e-books in all major formats. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Calibre-Web&lt;/strong&gt; - (&lt;a href="https://github.com/janeczku/calibre-web"&gt;Repo&lt;/a&gt;) Web application providing a clean interface for browsing, reading, and downloading ebooks using an existing &lt;a href="https://calibre-ebook.com/" rel="nofollow"&gt;Calibre&lt;/a&gt; database. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CherryTree&lt;/strong&gt; - (&lt;a href="https://github.com/giuspen/cherrytree"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.giuspen.com/cherrytree" rel="nofollow"&gt;Home&lt;/a&gt;) Hierarchical wiki-like personal notepad, featuring rich text and syntax highlighting. &lt;code&gt;(linux, windows, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Collaborate&lt;/strong&gt; - (&lt;a href="https://github.com/propublica/django-collaborative"&gt;Repo&lt;/a&gt;, &lt;a href="https://propublica.gitbook.io/collaborate-user-manual" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based collaboration tool designed by &lt;a href="https://www.propublica.org/nerds/making-collaborative-data-projects-easier-our-new-tool-collaborate-is-here" rel="nofollow"&gt;Propublica&lt;/a&gt; for newsrooms to share datasets, with a workflow built around assigning tips and maintaining contacts. &lt;code&gt;(communication, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CouchPotato&lt;/strong&gt; - (&lt;a href="https://github.com/CouchPotato/CouchPotatoServer"&gt;Repo&lt;/a&gt;, &lt;a href="http://couchpota.to/" rel="nofollow"&gt;Home&lt;/a&gt;) Personal video recorder focused on movies, with support for usenet and torrents. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dupeGuru&lt;/strong&gt; - (&lt;a href="https://github.com/arsenetar/dupeguru"&gt;Repo&lt;/a&gt;, &lt;a href="https://dupeguru.voltaicideas.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://dupeguru.voltaicideas.net/help/en" rel="nofollow"&gt;Docs&lt;/a&gt;) Cross-platform GUI tool to find duplicate files. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dvc (Data Version Control)&lt;/strong&gt; - (&lt;a href="https://github.com/iterative/dvc"&gt;Repo&lt;/a&gt;, &lt;a href="https://dvc.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://dvc.org/doc" rel="nofollow"&gt;Docs&lt;/a&gt;) Command-line tool for version control over data used in machine learning projects. Aims to replace Excel and other tools used to track and deploy model versions. &lt;code&gt;(scm, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fava&lt;/strong&gt; - (&lt;a href="https://github.com/beancount/fava"&gt;Repo&lt;/a&gt;, &lt;a href="https://fava.pythonanywhere.com/huge-example-file/income_statement" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://beancount.github.io/fava" rel="nofollow"&gt;Docs&lt;/a&gt;) Web interface for the double-entry bookkeeping software &lt;a href="http://furius.ca/beancount/" rel="nofollow"&gt;Beancount&lt;/a&gt; with a focus on features and usability. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gramps&lt;/strong&gt; - (&lt;a href="https://github.com/gramps-project/gramps"&gt;Repo&lt;/a&gt;, &lt;a href="https://gramps-project.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Genealogy software that is both intuitive for hobbyists and feature-complete for professional genealogists. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GTimeLog&lt;/strong&gt; - (&lt;a href="https://github.com/gtimelog/gtimelog"&gt;Repo&lt;/a&gt;, &lt;a href="https://gtimelog.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://ko-fi.com/mgedmin" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://gtimelog.org/docs.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Desktop-based time tracker with support for logging billable/non-billable work. &lt;code&gt;(productivity, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Headphones&lt;/strong&gt; - (&lt;a href="https://github.com/rembo10/headphones"&gt;Repo&lt;/a&gt;, &lt;a href="https://github.com/rembo10/headphones/wiki"&gt;Docs&lt;/a&gt;) Web-based digital music library for automating music downloads through Usenet and torrents. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ihatemoney&lt;/strong&gt; - (&lt;a href="https://github.com/spiral-project/ihatemoney"&gt;Repo&lt;/a&gt;, &lt;a href="https://ihatemoney.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://ihatemoney.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application made to ease shared budget management by keeping track of who bought what, when, and for whom. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Indico&lt;/strong&gt; - (&lt;a href="https://github.com/indico/indico"&gt;Repo&lt;/a&gt;, &lt;a href="https://getindico.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://sandbox.getindico.io/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://docs.getindico.io/en/stable/installation" rel="nofollow"&gt;Docs&lt;/a&gt;) Feature-rich web application designed at &lt;a href="https://en.wikipedia.org/wiki/CERN" rel="nofollow"&gt;CERN&lt;/a&gt; for managing events, with support for conference organization workflow, from content management to receiving and reviewing abstracts/papers, event registration, payment integration, room booking, and more. &lt;code&gt;(communication, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Invenio&lt;/strong&gt; - (&lt;a href="https://github.com/inveniosoftware/invenio"&gt;Repo&lt;/a&gt;, &lt;a href="https://invenio.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Customizable platform for running a trusted digital repository. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;jrnl&lt;/strong&gt; - (&lt;a href="https://github.com/maebert/jrnl"&gt;Repo&lt;/a&gt;, &lt;a href="http://jrnl.sh/" rel="nofollow"&gt;Home&lt;/a&gt;) Simple, ecncrypted journal application for your command line. &lt;code&gt;(linux, windows, mac, homebrew)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LazyLibrarian&lt;/strong&gt; - (&lt;a href="https://gitlab.com/LazyLibrarian/LazyLibrarian" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.reddit.com/r/LazyLibrarian" rel="nofollow"&gt;Forum&lt;/a&gt;, &lt;a href="https://lazylibrarian.gitlab.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based digital library organizer with support for following authors and automatic metadata retrieval. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mayan&lt;/strong&gt; - (&lt;a href="https://gitlab.com/mayan-edms/mayan-edms" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.mayan-edms.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.paypal.me/MayanEDMS" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://pypi.org/project/mayan-edms/3.2.7" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://docs.mayan-edms.com/" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based document management system, designed to store, introspect, and categorize files, with OCR, preview, label, signing, and sending capabilities. Also featuring workflow system, role-based access control, and REST API. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MLflow&lt;/strong&gt; - (&lt;a href="https://github.com/mlflow/mlflow"&gt;Repo&lt;/a&gt;, &lt;a href="https://mlflow.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://mlflow.org/docs/latest/index.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Integrated command-line application and web service, supporting an end-to-end machine-learning workflow around tracking, packaging, and deploying. Developed by &lt;a href="https://docs.databricks.com/applications/mlflow/index.html" rel="nofollow"&gt;Databricks&lt;/a&gt;. &lt;code&gt;(dev, linux, mac, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenLibrary&lt;/strong&gt; - (&lt;a href="https://github.com/internetarchive/openlibrary"&gt;Repo&lt;/a&gt;, &lt;a href="https://openlibrary.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Open_Library" rel="nofollow"&gt;WP&lt;/a&gt;) Web application for an open, editable library catalog, used by &lt;a href="https://archive.org/" rel="nofollow"&gt;The Internet Archive&lt;/a&gt; towards building a web page for every book ever published. &lt;code&gt;(linux, windows, mac, docker)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Paperwork&lt;/strong&gt; - (&lt;a href="https://gitlab.gnome.org/World/OpenPaperwork/paperwork" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://openpaper.work/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.patreon.com/openpaper" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://gitlab.gnome.org/World/OpenPaperwork/paperwork/wikis/home" rel="nofollow"&gt;Docs&lt;/a&gt;) Personal document manager for organizing scanned documents and PDFs, with support for OCR, automatic tagging, and search. &lt;code&gt;(linux, windows, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pinry&lt;/strong&gt; - (&lt;a href="https://github.com/pinry/pinry"&gt;Repo&lt;/a&gt;, &lt;a href="https://getpinry.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Tiling image board system for saving, tagging, and sharing images, videos, and websites, like a self-hosted Pinterest. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pretalx&lt;/strong&gt; - (&lt;a href="https://github.com/pretalx/pretalx"&gt;Repo&lt;/a&gt;, &lt;a href="https://pretalx.com/p/about" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.patreon.com/rixx" rel="nofollow"&gt;Fund&lt;/a&gt;) Web-based conference planning tool, with support for Calls for Papers (CFP), scheduling, and speaker management. &lt;code&gt;(communication, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyMedusa&lt;/strong&gt; - (&lt;a href="https://github.com/pymedusa/Medusa"&gt;Repo&lt;/a&gt;, &lt;a href="https://pymedusa.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Video library manager for TV shows, with automatic download support. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Radicale&lt;/strong&gt; - (&lt;a href="https://github.com/Kozea/Radicale"&gt;Repo&lt;/a&gt;, &lt;a href="https://radicale.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://radicale.org/documentation" rel="nofollow"&gt;Docs&lt;/a&gt;) Simple CalDAV (calendar) and CardDAV (contact) server. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RedNotebook&lt;/strong&gt; - (&lt;a href="https://github.com/jendrikseipp/rednotebook"&gt;Repo&lt;/a&gt;, &lt;a href="https://rednotebook.sourceforge.io/downloads.html" rel="nofollow"&gt;Home&lt;/a&gt;) Desktop journal designed for rich text, media, and template-based entries, which can be tagged and searched, as well as exported to plain text, HTML, Latex, or PDF. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scholia&lt;/strong&gt; - (&lt;a href="https://github.com/fnielsen/scholia"&gt;Repo&lt;/a&gt;, &lt;a href="https://tools.wmflabs.org/scholia" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.wikidata.org/wiki/Wikidata%3AScholia" rel="nofollow"&gt;Docs&lt;/a&gt;) Python package and web application for interacting with scholarly information on &lt;a href="https://www.wikidata.org/" rel="nofollow"&gt;Wikidata&lt;/a&gt;. &lt;code&gt;(science, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Senaite&lt;/strong&gt; - (&lt;a href="https://github.com/senaite/senaite.lims"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.senaite.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Web-based, mobile-first laboratory information management system (LIMS). &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SiCKRAGE&lt;/strong&gt; - (&lt;a href="https://git.sickrage.ca/SiCKRAGE/sickrage" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://github.com/SiCKRAGE/SiCKRAGE"&gt;gh&lt;/a&gt;, &lt;a href="https://git.sickrage.ca/SiCKRAGE/sickrage/wikis/FAQ%27s-and-Fixes" rel="nofollow"&gt;Docs&lt;/a&gt;) Video library manager with support for automatic TV show archival. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Taiga&lt;/strong&gt; - (&lt;a href="https://github.com/taigaio/taiga-back"&gt;Repo&lt;/a&gt;, &lt;a href="https://taiga.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="http://taigaio.github.io/taiga-doc/dist" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application built for managing projects with agile development processes. &lt;code&gt;(dev, server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wikid Pad&lt;/strong&gt; - (&lt;a href="https://github.com/WikidPad/WikidPad"&gt;Repo&lt;/a&gt;, &lt;a href="http://wikidpad.sourceforge.net/" rel="nofollow"&gt;Home&lt;/a&gt;) Desktop wiki notebook for storing your thoughts and ideas. &lt;code&gt;(linux, windows, mac, wx)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Xandikos&lt;/strong&gt; - (&lt;a href="https://github.com/jelmer/xandikos"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.xandikos.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Lightweight but relatively complete CardDAV/CalDAV server which backs up changes in a Git repository. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Zim Wiki&lt;/strong&gt; - (&lt;a href="https://github.com/jaap-karssenberg/zim-desktop-wiki"&gt;Repo&lt;/a&gt;, &lt;a href="http://zim-wiki.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Desktop wiki designed for note-taking, list-making, and drafting. &lt;code&gt;(linux, windows, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-communication" class="anchor" aria-hidden="true" href="#communication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-communication" href="#tag-communication"&gt;Communication&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Abilian SBE&lt;/strong&gt; - (&lt;a href="https://github.com/abilian/abilian-sbe"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.abilian.com/" rel="nofollow"&gt;Home&lt;/a&gt;) A "Social Business Engine" with features including lightweight document management, discussions, wikis, timelines, and more. &lt;code&gt;(cms, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Askbot&lt;/strong&gt; - (&lt;a href="https://github.com/ASKBOT/askbot-devel"&gt;Repo&lt;/a&gt;, &lt;a href="https://askbot.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Q&amp;amp;A web platform similar to StackOverflow, complete with tagging, reputation, badges, and more. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bitmessage&lt;/strong&gt; - (&lt;a href="https://github.com/Bitmessage/PyBitmessage"&gt;Repo&lt;/a&gt;, &lt;a href="https://bitmessage.org/wiki/Main_Page" rel="nofollow"&gt;Docs&lt;/a&gt;) Reference client for Bitmessage, a peer-to-peer encrypted decentralised communication protocol. &lt;code&gt;(linux, windows, mac, kivy, qt4, tui)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Collaborate&lt;/strong&gt; - (&lt;a href="https://github.com/propublica/django-collaborative"&gt;Repo&lt;/a&gt;, &lt;a href="https://propublica.gitbook.io/collaborate-user-manual" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based collaboration tool designed by &lt;a href="https://www.propublica.org/nerds/making-collaborative-data-projects-easier-our-new-tool-collaborate-is-here" rel="nofollow"&gt;Propublica&lt;/a&gt; for newsrooms to share datasets, with a workflow built around assigning tips and maintaining contacts. &lt;code&gt;(organization, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dak&lt;/strong&gt; - (&lt;a href="https://salsa.debian.org/ftp-team/dak" rel="nofollow"&gt;Repo&lt;/a&gt;) Collection of programs used to maintain the Debian project's email archives. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Django Wiki&lt;/strong&gt; - (&lt;a href="https://github.com/django-wiki/django-wiki"&gt;Repo&lt;/a&gt;, &lt;a href="https://demo.django-wiki.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://django-wiki.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) A simple and mature web-based wiki. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Docassemble&lt;/strong&gt; - (&lt;a href="https://github.com/jhpyle/docassemble"&gt;Repo&lt;/a&gt;, &lt;a href="https://docassemble.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docassemble.org/docs.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Platform for creating mobile-friendly web-based interviews, collecting responses, and much more. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Formspree&lt;/strong&gt; - (&lt;a href="https://github.com/formspree/formspree"&gt;Repo&lt;/a&gt;, &lt;a href="https://formspree.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Web server which turns an HTML form submission into an email, without registration, JavaScript, or custom Python. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gajim&lt;/strong&gt; - (&lt;a href="https://dev.gajim.org/gajim/gajim" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Gajim" rel="nofollow"&gt;WP&lt;/a&gt;) Lightweight, cross-platform instant messaging client for the XMPP protocol. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GlobaLeaks&lt;/strong&gt; - (&lt;a href="https://github.com/globaleaks/GlobaLeaks"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.globaleaks.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Web application to enable secure and anonymous whistleblowing initiatives. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hangups&lt;/strong&gt; - (&lt;a href="https://github.com/tdryer/hangups"&gt;Repo&lt;/a&gt;, &lt;a href="https://snapcraft.io/hangups" rel="nofollow"&gt;Snap&lt;/a&gt;, &lt;a href="https://hangups.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Third-party instant messenger for &lt;a href="https://en.wikipedia.org/wiki/Google_Hangouts" rel="nofollow"&gt;Google Hangouts&lt;/a&gt;, with support for group messaging and other proprietary features. &lt;code&gt;(linux, mac, docker, snap)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hawkpost&lt;/strong&gt; - (&lt;a href="https://github.com/whitesmith/hawkpost"&gt;Repo&lt;/a&gt;, &lt;a href="https://hawkpost.co/" rel="nofollow"&gt;Home&lt;/a&gt;) Web application which enables receiving encrypted messages from less technical senders. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Helios Voting&lt;/strong&gt; - (&lt;a href="https://github.com/benadida/helios-server"&gt;Repo&lt;/a&gt;, &lt;a href="http://heliosvoting.org/" rel="nofollow"&gt;Home&lt;/a&gt;) End-to-end verifiable voting system. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inboxen&lt;/strong&gt; - (&lt;a href="https://github.com/Inboxen/Inboxen"&gt;Repo&lt;/a&gt;, &lt;a href="https://inboxen.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://inboxen.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application which provides an infinite number of unique email inboxes, for segmenting services and maintaining privacy. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Indico&lt;/strong&gt; - (&lt;a href="https://github.com/indico/indico"&gt;Repo&lt;/a&gt;, &lt;a href="https://getindico.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://sandbox.getindico.io/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://docs.getindico.io/en/stable/installation" rel="nofollow"&gt;Docs&lt;/a&gt;) Feature-rich web application designed at &lt;a href="https://en.wikipedia.org/wiki/CERN" rel="nofollow"&gt;CERN&lt;/a&gt; for managing events, with support for conference organization workflow, from content management to receiving and reviewing abstracts/papers, event registration, payment integration, room booking, and more. &lt;code&gt;(organization, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Magic Wormhole&lt;/strong&gt; - (&lt;a href="https://github.com/warner/magic-wormhole"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/magic-wormhole" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://magic-wormhole.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Security- and speed-focused file transfer tool with support for files, text, and directories. &lt;code&gt;(linux, mac, console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mailman&lt;/strong&gt; - (&lt;a href="https://gitlab.com/mailman/mailman" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.list.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GNU_Mailman" rel="nofollow"&gt;WP&lt;/a&gt;) The original listserv, a web application and email server for managing subscriptions and discussion archives. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mailpile&lt;/strong&gt; - (&lt;a href="https://github.com/mailpile/Mailpile"&gt;Repo&lt;/a&gt;, &lt;a href="https://mailpile.is/" rel="nofollow"&gt;Home&lt;/a&gt;) Fast email client with user-friendly encryption and privacy features. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mailu&lt;/strong&gt; - (&lt;a href="https://github.com/Mailu/Mailu"&gt;Repo&lt;/a&gt;, &lt;a href="https://mailu.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Full-featured mail server designed for easy setup and maintenance, supporting IMAP, IMAP+, SMTP, and Submission, as well as a slew of advanced features. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modoboa&lt;/strong&gt; - (&lt;a href="https://github.com/modoboa/modoboa"&gt;Repo&lt;/a&gt;, &lt;a href="https://modoboa.org/en" rel="nofollow"&gt;Home&lt;/a&gt;) Mail hosting and management platform including web UI based on Django. Provides useful components such as an admin panel and webmail. Integrates with Postfix or Dovecot. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MoinMoin&lt;/strong&gt; - (&lt;a href="https://bitbucket.org/thomaswaldmann/moin-2.0" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://moinmo.in/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/MoinMoin" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://moin-20.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Python's own web-based wiki software, used for &lt;a href="https://wiki.python.org/moin/" rel="nofollow"&gt;the official Python wiki&lt;/a&gt; and many others. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OfflineIMAP&lt;/strong&gt; - (&lt;a href="https://github.com/OfflineIMAP/offlineimap"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.offlineimap.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/OfflineIMAP" rel="nofollow"&gt;WP&lt;/a&gt;) IMAP reader and synchronizer. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OnionShare&lt;/strong&gt; - (&lt;a href="https://github.com/micahflee/onionshare"&gt;Repo&lt;/a&gt;, &lt;a href="https://onionshare.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/micahflee/onionshare/wiki"&gt;Docs&lt;/a&gt;) Secure and anonymous file sharing over &lt;a href="https://en.wikipedia.org/wiki/Tor_(anonymity_network)" rel="nofollow"&gt;Tor&lt;/a&gt; services. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pootle&lt;/strong&gt; - (&lt;a href="https://github.com/translate/pootle"&gt;Repo&lt;/a&gt;, &lt;a href="http://pootle.translatehouse.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Pootle" rel="nofollow"&gt;WP&lt;/a&gt;) Web application for collaborative translation. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pretalx&lt;/strong&gt; - (&lt;a href="https://github.com/pretalx/pretalx"&gt;Repo&lt;/a&gt;, &lt;a href="https://pretalx.com/p/about" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.patreon.com/rixx" rel="nofollow"&gt;Fund&lt;/a&gt;) Web-based conference planning tool, with support for Calls for Papers (CFP), scheduling, and speaker management. &lt;code&gt;(organization, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pycsw&lt;/strong&gt; - (&lt;a href="https://github.com/geopython/pycsw"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Pycsw" rel="nofollow"&gt;WP&lt;/a&gt;) Full implementation of the OpenGIS Catalogue Service Implementation Specification. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RapidSMS&lt;/strong&gt; - (&lt;a href="https://github.com/rapidsms/rapidsms"&gt;Repo&lt;/a&gt;, &lt;a href="http://rapidsms.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="http://readthedocs.org/docs/rapidsms" rel="nofollow"&gt;Docs&lt;/a&gt;) Interactive SMS text messaging platform. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SecureDrop&lt;/strong&gt; - (&lt;a href="https://github.com/freedomofpress/securedrop"&gt;Repo&lt;/a&gt;, &lt;a href="https://securedrop.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.securedrop.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Whistleblower submission system for media organizations to securely accept documents from anonymous sources. Originally created by &lt;a href="https://en.wikipedia.org/wiki/Aaron_Swartz" rel="nofollow"&gt;Aaron Swartz&lt;/a&gt; and currently managed by the &lt;a href="https://en.wikipedia.org/wiki/Freedom_of_the_Press_Foundation" rel="nofollow"&gt;Freedom of the Press Foundation&lt;/a&gt;. &lt;code&gt;(server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Socialhome&lt;/strong&gt; - (&lt;a href="https://git.feneas.org/socialhome/socialhome" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://socialhome.network/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/jaywink/socialhome"&gt;gh&lt;/a&gt;, &lt;a href="https://socialhome.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application enabling users to build a federated personal profile with social networking functionality. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Synapse&lt;/strong&gt; - (&lt;a href="https://github.com/matrix-org/synapse"&gt;Repo&lt;/a&gt;, &lt;a href="https://riot.im/app#/home" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.patreon.com/matrixdotorg/overview" rel="nofollow"&gt;Fund&lt;/a&gt;) Reference server for the &lt;a href="https://matrix.org" rel="nofollow"&gt;matrix.org&lt;/a&gt; distributed chat protocol. Used daily by tens of thousands at &lt;a href="https://riot.im/app/" rel="nofollow"&gt;riot.im&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Virtaal&lt;/strong&gt; - (&lt;a href="https://github.com/translate/virtaal"&gt;Repo&lt;/a&gt;, &lt;a href="http://virtaal.translatehouse.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Cross-platform GUI for performing translation, with support for a variety of formats. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Weblate&lt;/strong&gt; - (&lt;a href="https://github.com/WeblateOrg/weblate"&gt;Repo&lt;/a&gt;, &lt;a href="https://weblate.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/Weblate" rel="nofollow"&gt;PyPI&lt;/a&gt;) Web based localization tool with tight version control integration. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Zulip&lt;/strong&gt; - (&lt;a href="https://github.com/zulip/zulip"&gt;Repo&lt;/a&gt;, &lt;a href="https://zulip.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Zulip" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://zulip.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Powerful chat server and web client with support for threaded conversations. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-education" class="anchor" aria-hidden="true" href="#education"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-education" href="#tag-education"&gt;Education&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Anki&lt;/strong&gt; - (&lt;a href="https://github.com/dae/anki"&gt;Repo&lt;/a&gt;, &lt;a href="https://apps.ankiweb.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://apps.ankiweb.net/docs/manual.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Powerful desktop application for flash cards and memorization. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DrawBot&lt;/strong&gt; - (&lt;a href="https://github.com/typemytype/drawbot"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.drawbot.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/DrawBot" rel="nofollow"&gt;WP&lt;/a&gt;) A powerful programmatic 2D drawing application for MacOS X which generates graphics from Python scripts. &lt;code&gt;(graphics, dev, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kolibri&lt;/strong&gt; - (&lt;a href="https://github.com/learningequality/kolibri"&gt;Repo&lt;/a&gt;, &lt;a href="https://learningequality.org/kolibri" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://kolibridemo.learningequality.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://pypi.org/project/kolibri" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://kolibri.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Self-hostable learning web application targeted at making high quality education technology available in low-resource communities (e.g., rural schools, refugee camps, orphanages, non-formal school systems, and prison systems). &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mnemosyne&lt;/strong&gt; - (&lt;a href="https://github.com/mnemosyne-proj/mnemosyne"&gt;Repo&lt;/a&gt;, &lt;a href="https://mnemosyne-proj.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Spaced-repetition flashcard program for efficient memorization. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NBGrader&lt;/strong&gt; - (&lt;a href="https://github.com/jupyter/nbgrader"&gt;Repo&lt;/a&gt;, &lt;a href="https://nbgrader.readthedocs.io/en/stable" rel="nofollow"&gt;Docs&lt;/a&gt;) Jupyter-based application which enables educators to create, assign, and grade assignments in notebook form. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Open edX Platform&lt;/strong&gt; - (&lt;a href="https://github.com/edx/edx-platform"&gt;Repo&lt;/a&gt;, &lt;a href="http://open.edx.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/EdX#Open_edX" rel="nofollow"&gt;WP&lt;/a&gt;) Platform for online education providers, powering &lt;a href="https://en.wikipedia.org/wiki/EdX" rel="nofollow"&gt;edX&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RELATE&lt;/strong&gt; - (&lt;a href="https://github.com/inducer/relate"&gt;Repo&lt;/a&gt;, &lt;a href="https://documen.tician.de/relate" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based courseware with support for course planning and versioning, scheduling, testing, and grading. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tutor&lt;/strong&gt; - (&lt;a href="https://github.com/overhangio/tutor"&gt;Repo&lt;/a&gt;, &lt;a href="https://docs.tutor.overhang.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Docker-based Open edX distribution, both for production and local development, with a goal of easing deployment, customization, upgrading, and scaling. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-science" class="anchor" aria-hidden="true" href="#science"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-science" href="#tag-science"&gt;Science&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;AnuGA&lt;/strong&gt; - (&lt;a href="https://github.com/GeoscienceAustralia/anuga_core"&gt;Repo&lt;/a&gt;, &lt;a href="https://anuga.anu.edu.au/" rel="nofollow"&gt;Home&lt;/a&gt;) Advanced simulation of the shallow water equation, for modeling tsunamis, dam breaks, and floods. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Artisan&lt;/strong&gt; - (&lt;a href="https://github.com/artisan-roaster-scope/artisan"&gt;Repo&lt;/a&gt;, &lt;a href="https://artisan-scope.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://artisan-scope.org/docs/quick-start-guide" rel="nofollow"&gt;Docs&lt;/a&gt;) Desktop visual scope for coffee roasters, which helps coffee roasters record, analyze, and control roast profiles. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ASCEND&lt;/strong&gt; - (&lt;a href="http://code.ascend4.org/ascend/trunk" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://ascend4.org/Main_Page" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/ASCEND" rel="nofollow"&gt;WP&lt;/a&gt;) Mathematical chemical process modelling system developed at Carnegie Mellon University since late 1978. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CellProfiler&lt;/strong&gt; - (&lt;a href="https://github.com/CellProfiler/CellProfiler"&gt;Repo&lt;/a&gt;, &lt;a href="http://cellprofiler.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://cellprofiler.org/cpa" rel="nofollow"&gt;Manual&lt;/a&gt;, &lt;a href="https://github.com/CellProfiler/CellProfiler/wiki"&gt;Docs&lt;/a&gt;) Interactive data exploration, analysis, and classification of biological image sets. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cellxgene&lt;/strong&gt; - (&lt;a href="https://github.com/chanzuckerberg/cellxgene"&gt;Repo&lt;/a&gt;, &lt;a href="https://chanzuckerberg.github.io/cellxgene" rel="nofollow"&gt;Home&lt;/a&gt;) Web-based interactive explorer for single-cell transcriptomics data. &lt;code&gt;(linux, windows, mac, fnd)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CKAN&lt;/strong&gt; - (&lt;a href="https://github.com/ckan/ckan"&gt;Repo&lt;/a&gt;, &lt;a href="https://ckan.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Data management system (DMS) which makes it easy to publish, share, and use data. Data hubs powered by CKAN include &lt;a href="https://datahub.io" rel="nofollow"&gt;datahub.io&lt;/a&gt;, &lt;a href="https://catalog.data.gov" rel="nofollow"&gt;catalog.data.gov&lt;/a&gt;, and &lt;a href="https://europeandataportal.eu/data/en/dataset" rel="nofollow"&gt;europeandataportal.eu&lt;/a&gt;, among many other sites. &lt;code&gt;(server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CoCalc&lt;/strong&gt; - (&lt;a href="https://github.com/sagemathinc/cocalc"&gt;Repo&lt;/a&gt;, &lt;a href="https://cocalc.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/CoCalc" rel="nofollow"&gt;WP&lt;/a&gt;) Collaborative calculation in the cloud, with support for the scientific Python stack, SageMath, R, LaTeX, Markdown, and more. Also features chat, course management, and other supporting functionality. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dissem.in&lt;/strong&gt; - (&lt;a href="https://github.com/dissemin/dissemin"&gt;Repo&lt;/a&gt;, &lt;a href="https://dissem.in/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://dev.dissem.in/" rel="nofollow"&gt;Docs&lt;/a&gt;) Web platform to help researchers upload their papers to open-access repositories. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;InVesalius&lt;/strong&gt; - (&lt;a href="https://github.com/invesalius/invesalius3"&gt;Repo&lt;/a&gt;, &lt;a href="https://invesalius.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/InVesalius" rel="nofollow"&gt;WP&lt;/a&gt;) Generates virtual reconstructions of structures in the human body for medical purposes, including CT and MRI scans. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Manim&lt;/strong&gt; - (&lt;a href="https://github.com/3b1b/manim"&gt;Repo&lt;/a&gt;, &lt;a href="https://manim.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Animation engine for explanatory math videos, primarily designed for &lt;a href="https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw" rel="nofollow"&gt;works by 3blue1brown&lt;/a&gt;. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mayavi&lt;/strong&gt; - (&lt;a href="https://github.com/enthought/mayavi"&gt;Repo&lt;/a&gt;, &lt;a href="http://docs.enthought.com/mayavi/mayavi" rel="nofollow"&gt;Home&lt;/a&gt;) General purpose, cross-platform tool for 2-D and 3-D scientific data visualization. &lt;code&gt;(linux, windows, mac, qt4)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mosaic&lt;/strong&gt; - (&lt;a href="https://github.com/usnistgov/mosaic"&gt;Repo&lt;/a&gt;, &lt;a href="https://pages.nist.gov/mosaic" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pages.nist.gov/mosaic/html/index.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Desktop-based single molecule analysis toolbox that automatically decodes multi-state nanopore data. &lt;code&gt;(linux, windows, mac, gov)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;odemis&lt;/strong&gt; - (&lt;a href="https://github.com/delmic/odemis"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.delmic.com/microscopy-software-odemis" rel="nofollow"&gt;Home&lt;/a&gt;) Desktop imaging workflow software for Delmic microscopes, supporting autofocus, coordinate history, and OME-TIFF and HDF5 export. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OPEM&lt;/strong&gt; - (&lt;a href="https://github.com/ECSIM/opem"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.ecsim.ir/opem/doc" rel="nofollow"&gt;Docs&lt;/a&gt;) A modeling tool for evaluating the performance of &lt;a href="https://en.wikipedia.org/wiki/Proton-exchange_membrane_fuel_cell" rel="nofollow"&gt;proton exchange membrane (PEM) fuel cells&lt;/a&gt;. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Orange&lt;/strong&gt; - (&lt;a href="https://github.com/biolab/orange3"&gt;Repo&lt;/a&gt;, &lt;a href="https://orange.biolab.si/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Orange_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Component-based data mining software for graphical interactive data analysis and visualization. &lt;code&gt;(linux, windows, mac, qt4, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pybliographer&lt;/strong&gt; - (&lt;a href="https://github.com/GNOME/pybliographer"&gt;Repo&lt;/a&gt;, &lt;a href="https://pybliographer.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Bibliographic database manager with a user-friendly desktop UI. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ReproZip&lt;/strong&gt; - (&lt;a href="https://github.com/VIDA-NYU/reprozip"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.reprozip.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://examples.reprozip.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://docs.reprozip.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Command-line tool which automatically builds reproducible experiments archives from console commands, designed for use in computational science. &lt;code&gt;(productivity, linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sage Math&lt;/strong&gt; - (&lt;a href="https://git.sagemath.org/sage.git" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.sagemath.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/SageMath" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform computer algebra system with features covering many aspects of mathematics, including algebra, combinatorics, graph theory, numerical analysis, number theory, calculus, and statistics. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scholia&lt;/strong&gt; - (&lt;a href="https://github.com/fnielsen/scholia"&gt;Repo&lt;/a&gt;, &lt;a href="https://tools.wmflabs.org/scholia" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.wikidata.org/wiki/Wikidata%3AScholia" rel="nofollow"&gt;Docs&lt;/a&gt;) Python package and web application for interacting with scholarly information on &lt;a href="https://www.wikidata.org/" rel="nofollow"&gt;Wikidata&lt;/a&gt;. &lt;code&gt;(organization, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SOFA Statistics&lt;/strong&gt; - (&lt;a href="https://code.launchpad.net/sofastatistics" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.sofastatistics.com/" rel="nofollow"&gt;Home&lt;/a&gt;) User-friendly statistics and analysis with a learn-as-you-go approach. &lt;code&gt;(linux, windows, mac, wx)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Taguette&lt;/strong&gt; - (&lt;a href="https://gitlab.com/remram44/taguette" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.taguette.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/remram44/taguette"&gt;gh&lt;/a&gt;, &lt;a href="https://pypi.org/project/taguette" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://www.taguette.org/getting-started.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based qualitative research tool supporting importing, tagging, highlighting, and exporting many document formats. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Veusz&lt;/strong&gt; - (&lt;a href="https://github.com/veusz/veusz"&gt;Repo&lt;/a&gt;, &lt;a href="https://veusz.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;) 2D and 3D scientific plotting, designed to produce publication-ready PDF or SVG graphs. &lt;code&gt;(linux, windows, mac, qt)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-cms" class="anchor" aria-hidden="true" href="#cms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-cms" href="#tag-cms"&gt;CMS&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Abilian SBE&lt;/strong&gt; - (&lt;a href="https://github.com/abilian/abilian-sbe"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.abilian.com/" rel="nofollow"&gt;Home&lt;/a&gt;) A "Social Business Engine" with features including lightweight document management, discussions, wikis, timelines, and more. &lt;code&gt;(communication, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Django-CMS&lt;/strong&gt; - (&lt;a href="https://github.com/divio/django-cms"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.django-cms.org/en" rel="nofollow"&gt;Home&lt;/a&gt;) Enterprise content management system based on the Django framework with version control, multi-site support, and more. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ella&lt;/strong&gt; - (&lt;a href="https://github.com/ella/ella"&gt;Repo&lt;/a&gt;, &lt;a href="https://ella.readthedocs.io/en/latest/index.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Django-based content management system with a focus on high-traffic news sites and Internet magazines. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mezzanine&lt;/strong&gt; - (&lt;a href="https://github.com/stephenmcd/mezzanine"&gt;Repo&lt;/a&gt;, &lt;a href="http://mezzanine.jupo.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Consistent and flexible content management platform built on the Django framework. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plone&lt;/strong&gt; - (&lt;a href="https://github.com/plone/Plone"&gt;Repo&lt;/a&gt;, &lt;a href="https://plone.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Plone_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Extensible enterprise content management system built on Zope. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plumi&lt;/strong&gt; - (&lt;a href="https://github.com/plumi/plumi.app"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Plumi" rel="nofollow"&gt;WP&lt;/a&gt;) Video sharing content management system based on &lt;a href="https://en.wikipedia.org/wiki/Plone_(software)" rel="nofollow"&gt;Plone&lt;/a&gt;. &lt;code&gt;(video, server, plone)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pretix&lt;/strong&gt; - (&lt;a href="https://github.com/pretix/pretix"&gt;Repo&lt;/a&gt;, &lt;a href="https://pretix.eu/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pretix.eu/about/en/blog" rel="nofollow"&gt;Blog&lt;/a&gt;, &lt;a href="https://pypi.org/project/pretix" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://docs.pretix.eu/en/latest/development/index.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based ticketing software, with support for customizable storefronts, direct payments, box office, and reporting. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyCon&lt;/strong&gt; - (&lt;a href="https://github.com/PyCon/pycon"&gt;Repo&lt;/a&gt;, &lt;a href="https://us.pycon.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pycon.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Content management and conference organization web application, based on Django and &lt;a href="https://github.com/pinax/symposion"&gt;Symposion&lt;/a&gt;. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Saleor&lt;/strong&gt; - (&lt;a href="https://github.com/mirumee/saleor"&gt;Repo&lt;/a&gt;, &lt;a href="https://getsaleor.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Modular, high-performance e-commerce storefront built with Django, GraphQL, and ReactJS. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shuup&lt;/strong&gt; - (&lt;a href="https://github.com/shuup/shuup"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.shuup.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://shuup.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Storefront web application, with support for single- and multi-marketplace models. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wagtail&lt;/strong&gt; - (&lt;a href="https://github.com/wagtail/wagtail"&gt;Repo&lt;/a&gt;, &lt;a href="https://wagtail.io/" rel="nofollow"&gt;Home&lt;/a&gt;) A Django content management system focused on flexibility and user experience. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-erp" class="anchor" aria-hidden="true" href="#erp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-erp" href="#tag-erp"&gt;ERP&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ERP5&lt;/strong&gt; - (&lt;a href="https://lab.nexedi.com/nexedi/erp5" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://erp5.nexedi.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/ERP5" rel="nofollow"&gt;WP&lt;/a&gt;) Web-based ERP, CRM, DMS, and Big Data system with hundreds of built-in modules, designed for corporate scalability. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ERPNext&lt;/strong&gt; - (&lt;a href="https://github.com/frappe/erpnext"&gt;Repo&lt;/a&gt;, &lt;a href="https://erpnext.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/ERPNext" rel="nofollow"&gt;WP&lt;/a&gt;) Web-based ERP system with accounting, inventory, CRM, sales, procurement, project management, and HR. Built on &lt;a href="https://github.com/frappe/frappe"&gt;Frappe&lt;/a&gt; and MariaDB. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Frepple&lt;/strong&gt; - (&lt;a href="https://github.com/frePPLe/frepple"&gt;Repo&lt;/a&gt;, &lt;a href="https://frepple.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://frepple.com/docs/current/user-guide/index.php" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based supply chain planning for production planning and scheduling. &lt;code&gt;(linux, windows, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Odoo&lt;/strong&gt; - (&lt;a href="https://github.com/odoo/odoo"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.odoo.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Odoo" rel="nofollow"&gt;WP&lt;/a&gt;) Web-based ERP and CRM with many built-in modules, plus thousands of apps to suit any business. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tryton&lt;/strong&gt; - (&lt;a href="https://hg.tryton.org/trytond" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.tryton.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Tryton" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://docs.tryton.org/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Modular web-based ERP, designed for companies of all sizes. &lt;code&gt;(server, fdn)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-static-site" class="anchor" aria-hidden="true" href="#static-site"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-static_site" href="#tag-static_site"&gt;Static Site&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Cactus&lt;/strong&gt; - (&lt;a href="https://github.com/eudicots/Cactus"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/cactus" rel="nofollow"&gt;PyPI&lt;/a&gt;) Static website generator using Django templates. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chert&lt;/strong&gt; - (&lt;a href="https://github.com/mahmoud/chert"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/chert" rel="nofollow"&gt;PyPI&lt;/a&gt;) Static site generator with built-in support for listicles, created by this humble author, used to power &lt;a href="https://calver.org" rel="nofollow"&gt;calver.org&lt;/a&gt;, &lt;a href="https://zerover.org" rel="nofollow"&gt;zerover.org&lt;/a&gt;, and &lt;a href="https://sedimental.org/" rel="nofollow"&gt;sedimental.org&lt;/a&gt;, the author's blog. Mostly here as an easter egg :) &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Grow&lt;/strong&gt; - (&lt;a href="https://github.com/grow/grow"&gt;Repo&lt;/a&gt;, &lt;a href="https://grow.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/grow" rel="nofollow"&gt;PyPI&lt;/a&gt;) Static site generator optimized for building interactive, localized microsites, with a focus on workflow and maintainability. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hyde&lt;/strong&gt; - (&lt;a href="https://github.com/hyde/hyde"&gt;Repo&lt;/a&gt;, &lt;a href="http://hyde.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/hyde" rel="nofollow"&gt;PyPI&lt;/a&gt;) Static site generator which began as the Python counterpart to &lt;a href="https://github.com/jekyll/jekyll"&gt;Jekyll&lt;/a&gt;. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lektor&lt;/strong&gt; - (&lt;a href="https://github.com/lektor/lektor"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.getlektor.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Static site generator with built-in admin console and minimal desktop application. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nikola&lt;/strong&gt; - (&lt;a href="https://github.com/getnikola/nikola"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.getnikola.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/nikola" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line static site generator with incremental rebuilds and support for Markdown, reST, Jupyter notebooks, and HTML. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pelican&lt;/strong&gt; - (&lt;a href="https://github.com/getpelican/pelican"&gt;Repo&lt;/a&gt;, &lt;a href="https://blog.getpelican.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/pelican" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line static site generator that supports Markdown and reST syntax. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prosopopee&lt;/strong&gt; - (&lt;a href="https://github.com/Psycojoker/prosopopee"&gt;Repo&lt;/a&gt;, &lt;a href="https://surleschemins.fr/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://pypi.org/project/prosopopee" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://prosopopee.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) A static site generator designed for photographers and others who tell stories with pictures. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyVideo&lt;/strong&gt; - (&lt;a href="https://github.com/pyvideo/pyvideo"&gt;Repo&lt;/a&gt;, &lt;a href="https://pyvideo.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Static media index custom-built for the Python community, and all the content our meetings and conferences produce. &lt;code&gt;(video, linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-dev" class="anchor" aria-hidden="true" href="#dev"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev" href="#tag-dev"&gt;Dev&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Projects related to software development and adjacent technical areas.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-scm" class="anchor" aria-hidden="true" href="#scm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.scm" href="#tag-dev.scm"&gt;SCM&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Allura&lt;/strong&gt; - (&lt;a href="https://github.com/apache/allura"&gt;Repo&lt;/a&gt;, &lt;a href="https://allura.apache.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Apache_Allura" rel="nofollow"&gt;WP&lt;/a&gt;) Software &lt;a href="https://en.wikipedia.org/wiki/Forge_(software)" rel="nofollow"&gt;forge&lt;/a&gt;, with support for git, hg, and svn. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dvc (Data Version Control)&lt;/strong&gt; - (&lt;a href="https://github.com/iterative/dvc"&gt;Repo&lt;/a&gt;, &lt;a href="https://dvc.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://dvc.org/doc" rel="nofollow"&gt;Docs&lt;/a&gt;) Command-line tool for version control over data used in machine learning projects. Aims to replace Excel and other tools used to track and deploy model versions. &lt;code&gt;(organization, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Git Cola&lt;/strong&gt; - (&lt;a href="https://github.com/git-cola/git-cola"&gt;Repo&lt;/a&gt;, &lt;a href="https://git-cola.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Featureful cross-platform GUI wrapper for &lt;code&gt;git&lt;/code&gt;. &lt;code&gt;(linux, windows, mac, qt4, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gitless&lt;/strong&gt; - (&lt;a href="https://github.com/sdg-mit/gitless"&gt;Repo&lt;/a&gt;, &lt;a href="https://gitless.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/gitless" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://gitless.com/#documentation" rel="nofollow"&gt;Docs&lt;/a&gt;) Simple version control system built on top of Git. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GNU Bazaar&lt;/strong&gt; - (&lt;a href="https://code.launchpad.net/bzr" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://bazaar.canonical.com/en" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GNU_Bazaar" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="http://doc.bazaar.canonical.com/en" rel="nofollow"&gt;Docs&lt;/a&gt;) Distributed and client-server revision control system. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kallithea&lt;/strong&gt; - (&lt;a href="https://kallithea-scm.org/repos/kallithea" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Kallithea_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Software &lt;a href="https://en.wikipedia.org/wiki/Forge_(software)" rel="nofollow"&gt;forge&lt;/a&gt; for Mercurial and Git with a built-in push/pull server, full text search, and code-review. Forked from RhodeCode in 2014. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Klaus&lt;/strong&gt; - (&lt;a href="https://github.com/jonashaag/klaus"&gt;Repo&lt;/a&gt;, &lt;a href="http://klausdemo.lophus.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://pypi.org/project/klaus" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://github.com/jonashaag/klaus/wiki"&gt;Docs&lt;/a&gt;) pip-installable web-based viewer for git repositories that "just works". &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Launchpad&lt;/strong&gt; - (&lt;a href="https://launchpad.net/launchpad" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://launchpad.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Launchpad_%28website%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://dev.launchpad.net/" rel="nofollow"&gt;Docs&lt;/a&gt;) Software forge designed and run by Canonical, with support for Git and &lt;a href="https://en.wikipedia.org/wiki/GNU_Bazaar" rel="nofollow"&gt;Bazaar&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mercurial&lt;/strong&gt; - (&lt;a href="https://www.mercurial-scm.org/repo/hg-stable" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.mercurial-scm.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Mercurial" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform distributed revision-control system designed for high performance and advanced branching/merging capabilities. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pagure&lt;/strong&gt; - (&lt;a href="https://pagure.io/pagure" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://pagure.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Software &lt;a href="https://en.wikipedia.org/wiki/Forge_(software)" rel="nofollow"&gt;forge&lt;/a&gt; focused on git and developed by the Fedora engineering team. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Patchwork&lt;/strong&gt; - (&lt;a href="https://github.com/getpatchwork/patchwork"&gt;Repo&lt;/a&gt;, &lt;a href="http://jk.ozlabs.org/projects/patchwork" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://patchwork.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based patch tracking system designed to facilitate code contribution to an open-source project. Designed and used for Linux kernel subsystem development. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RabbitVCS&lt;/strong&gt; - (&lt;a href="https://github.com/rabbitvcs/rabbitvcs"&gt;Repo&lt;/a&gt;, &lt;a href="http://rabbitvcs.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="http://wiki.rabbitvcs.org/wiki" rel="nofollow"&gt;Docs&lt;/a&gt;) Tools providing straightforward graphical access to Subversion or Git within a variety of clients, including as Nautilus, Thunar, Nemo, Caja, and the command line. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RhodeCode&lt;/strong&gt; - (&lt;a href="https://code.rhodecode.com/rhodecode-enterprise-ce" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://rhodecode.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/RhodeCode" rel="nofollow"&gt;WP&lt;/a&gt;) Self-hosted platform for behind-the-firewall source code management, providing centralized control over Git, Mercurial, and Subversion. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Roundup&lt;/strong&gt; - (&lt;a href="http://hg.code.sf.net/p/roundup/code" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Roundup_%28issue_tracker%29" rel="nofollow"&gt;WP&lt;/a&gt;) Highly-customizable issue tracking system featuring command-line, web, and email interfaces, used by the official Python bug tracker at &lt;a href="https://bugs.python.org" rel="nofollow"&gt;bugs.python.org&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TortoiseHg&lt;/strong&gt; - (&lt;a href="https://bitbucket.org/tortoisehg/thg/src" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://tortoisehg.bitbucket.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://bitbucket.org/tortoisehg/thg/wiki/developers/Home" rel="nofollow"&gt;Docs&lt;/a&gt;) Windows shell extension and a series of applications for the Mercurial distributed revision control system. Also includes GNOME and CLI support. &lt;code&gt;(linux, windows, qt4, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Trac&lt;/strong&gt; - (&lt;a href="https://github.com/edgewall/trac"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Trac" rel="nofollow"&gt;WP&lt;/a&gt;) Enhanced web-based wiki and issue tracking system for software development projects. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ViewVC&lt;/strong&gt; - (&lt;a href="https://github.com/viewvc/viewvc"&gt;Repo&lt;/a&gt;, &lt;a href="http://viewvc.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Browser interface for CVS and Subversion version control repositories. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-code-review" class="anchor" aria-hidden="true" href="#code-review"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.code_review" href="#tag-dev.code_review"&gt;Code Review&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Diffoscope&lt;/strong&gt; - (&lt;a href="https://salsa.debian.org/reproducible-builds/diffoscope" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://diffoscope.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://try.diffoscope.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://pypi.org/project/diffoscope" rel="nofollow"&gt;PyPI&lt;/a&gt;) Web-based deep comparison of files, archives, and directories, including support for diffing tarballs, ISO images, and PDFs. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Meld&lt;/strong&gt; - (&lt;a href="https://github.com/GNOME/meld"&gt;Repo&lt;/a&gt;, &lt;a href="http://meldmerge.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Visual diff and merge tool targeted at developers, providing two- and three-way comparison of both files and directories, and supports many version control systems including Git, Mercurial, Bazaar, and Subversion. &lt;code&gt;(linux, windows, mac, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Review Board&lt;/strong&gt; - (&lt;a href="https://github.com/reviewboard/reviewboard"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.reviewboard.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Extensible code review tool for projects and companies of all sizes. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rietveld&lt;/strong&gt; - (&lt;a href="https://github.com/rietveld-codereview/rietveld"&gt;Repo&lt;/a&gt;, &lt;a href="https://codereview.appspot.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Rietveld_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Django-based collaborative code review tool for Subversion written by &lt;a href="https://en.wikipedia.org/wiki/Guido_van_Rossum" rel="nofollow"&gt;Guido van Rossum&lt;/a&gt; to run on &lt;a href="https://en.wikipedia.org/wiki/Google_App_Engine" rel="nofollow"&gt;Google AppEngine&lt;/a&gt;. The basis for &lt;a href="https://en.wikipedia.org/wiki/Gerrit_(software)" rel="nofollow"&gt;Gerrit&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-storage" class="anchor" aria-hidden="true" href="#storage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.storage" href="#tag-dev.storage"&gt;Storage&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;B2&lt;/strong&gt; - (&lt;a href="https://github.com/Backblaze/B2_Command_Line_Tool"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.python.org/pypi/b2" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line tool that gives easy access to all of the capabilities of Backblaze's &lt;a href="https://www.backblaze.com/b2/cloud-storage.html" rel="nofollow"&gt;B2 Cloud Storage&lt;/a&gt;. &lt;code&gt;(linux, windows, mac, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Barman&lt;/strong&gt; - (&lt;a href="https://github.com/2ndquadrant-it/barman"&gt;Repo&lt;/a&gt;) Remote backup and disaster recovery for PostgreSQL. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Datasette&lt;/strong&gt; - (&lt;a href="https://github.com/simonw/datasette"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/datasette" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://datasette.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) A tool for exploring and publishing data, backed by SQLite. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EdgeDB&lt;/strong&gt; - (&lt;a href="https://github.com/edgedb/edgedb"&gt;Repo&lt;/a&gt;, &lt;a href="https://edgedb.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://edgedb.com/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) High-performance object-relational database built on top of PostgreSQL, featuring strict, strong typing, built-in migrations, and GraphQL support. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FreeNAS&lt;/strong&gt; - (&lt;a href="https://github.com/freenas/freenas"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.freenas.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.ixsystems.com/documentation/freenas" rel="nofollow"&gt;Docs&lt;/a&gt;) Operating system designed to be installed virtually any hardware platform, for sharing &lt;a href="https://en.wikipedia.org/wiki/ZFS" rel="nofollow"&gt;ZFS&lt;/a&gt;-based storage over a network, using SMB, NFS, AFP, FTP, and more. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gridsync&lt;/strong&gt; - (&lt;a href="https://github.com/gridsync/gridsync"&gt;Repo&lt;/a&gt;) Cross-platform GUI built to synchronize local directories with Tahoe-LAFS storage grids. &lt;code&gt;(productivity, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;kinto&lt;/strong&gt; - (&lt;a href="https://github.com/Kinto/kinto"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.kinto-storage.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="http://docs.kinto-storage.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) A generic JSON document store with sharing and synchronisation capabilities, supporting in-memory and PostgreSQL backends. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nuxeo Drive&lt;/strong&gt; - (&lt;a href="https://github.com/nuxeo/nuxeo-drive"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.nuxeo.com/products/drive-desktop-sync" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://doc.nuxeo.com/client-apps/nuxeo-drive" rel="nofollow"&gt;Docs&lt;/a&gt;) Cross-platform desktop synchronization client for the Nuxeo platform. &lt;code&gt;(productivity, linux, windows, mac, console, appimage, lgpl, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pgcli&lt;/strong&gt; - (&lt;a href="https://github.com/dbcli/pgcli"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.pgcli.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.python.org/pypi/pgcli" rel="nofollow"&gt;PyPI&lt;/a&gt;) Interactive PostgreSQL client that does auto-completion and syntax highlighting. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;s3ql&lt;/strong&gt; - (&lt;a href="https://github.com/s3ql/s3ql"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.rath.org/s3ql-docs/index.html" rel="nofollow"&gt;Docs&lt;/a&gt;) A standards-conforming, full-featured UNIX filesystem for cloud-based storage services (S3, Google Storage, OpenStack), supporting compression, encryption, deduplication, snapshotting, and more. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Seafile&lt;/strong&gt; - (&lt;a href="https://github.com/haiwen/seahub"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Seafile" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform file hosting and synchronization system. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sqlmap&lt;/strong&gt; - (&lt;a href="https://github.com/sqlmapproject/sqlmap"&gt;Repo&lt;/a&gt;, &lt;a href="http://sqlmap.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/sqlmapproject/sqlmap/wiki"&gt;Docs&lt;/a&gt;) Automatic SQL injection and database takeover. &lt;code&gt;(security, console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TahoeLAFS&lt;/strong&gt; - (&lt;a href="https://github.com/tahoe-lafs/tahoe-lafs"&gt;Repo&lt;/a&gt;, &lt;a href="https://tahoe-lafs.org/trac/tahoe-lafs" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Tahoe-LAFS" rel="nofollow"&gt;WP&lt;/a&gt;) Decentralized cloud storage system for robust distributed data storage. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WAL-E&lt;/strong&gt; - (&lt;a href="https://github.com/wal-e/wal-e"&gt;Repo&lt;/a&gt;) Continuous archiving of PostgreSQL WAL files and base backups. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ZEO&lt;/strong&gt; - (&lt;a href="https://github.com/zopefoundation/ZEO"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/ZEO" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://zope.readthedocs.io/en/latest/zopebook/ZEO.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Server and client providing &lt;a href="http://www.zodb.org/" rel="nofollow"&gt;ZODB&lt;/a&gt;-based storage over the network. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ZFSp&lt;/strong&gt; - (&lt;a href="https://github.com/alcarithemad/zfsp"&gt;Repo&lt;/a&gt;) A reverse-engineered &lt;a href="https://en.wikipedia.org/wiki/ZFS" rel="nofollow"&gt;ZFS&lt;/a&gt; implementation, written in Python, without reading the original C. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-ops" class="anchor" aria-hidden="true" href="#ops"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.ops" href="#tag-dev.ops"&gt;Ops&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Airflow&lt;/strong&gt; - (&lt;a href="https://github.com/apache/airflow"&gt;Repo&lt;/a&gt;, &lt;a href="https://airflow.apache.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) A platform to programmatically author, schedule and monitor workflows. &lt;code&gt;(linux, server, corp, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ansible&lt;/strong&gt; - (&lt;a href="https://github.com/ansible/ansible"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.ansible.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.ansible.com/ansible" rel="nofollow"&gt;Docs&lt;/a&gt;) Agentless, playbook-based automation. &lt;code&gt;(linux, mac, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;aws-cli&lt;/strong&gt; - (&lt;a href="https://github.com/aws/aws-cli"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/awscli" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://docs.aws.amazon.com/cli/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Official command-line interface for Amazon Web Services. &lt;code&gt;(console, py26)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beaker&lt;/strong&gt; - (&lt;a href="https://git.beaker-project.org/cgit/beaker" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://beaker-project.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://beaker-project.org/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Hardware integration testing system, used by RedHat to test compatiblity for RHEL and Fedora. &lt;code&gt;(server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cobbler&lt;/strong&gt; - (&lt;a href="https://github.com/Cobbler/Cobbler"&gt;Repo&lt;/a&gt;, &lt;a href="https://cobbler.github.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Cobbler_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Linux installation server that allows for rapid setup of network installation environments. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DCOS&lt;/strong&gt; - (&lt;a href="https://github.com/dcos/dcos"&gt;Repo&lt;/a&gt;, &lt;a href="https://dcos.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Mesosphere%2C_Inc.#Mesosphere_DC/OS" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://dcos.io/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Management platform for hardware and software resources in datacenters, built on &lt;a href="https://en.wikipedia.org/wiki/Apache_Mesos" rel="nofollow"&gt;Apache Mesos&lt;/a&gt;. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fail2ban&lt;/strong&gt; - (&lt;a href="https://github.com/fail2ban/fail2ban"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.fail2ban.org/wiki/index.php/Main_Page" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Fail2ban" rel="nofollow"&gt;WP&lt;/a&gt;) Daemon to ban hosts that cause multiple authentication errors on Linux servers. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ganeti&lt;/strong&gt; - (&lt;a href="https://github.com/ganeti/ganeti"&gt;Repo&lt;/a&gt;) Virtual machine cluster management tool built on existing virtualization technologies such as &lt;a href="https://en.wikipedia.org/wiki/Xen" rel="nofollow"&gt;Xen&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Kernel-based_Virtual_Machine" rel="nofollow"&gt;KVM&lt;/a&gt;. &lt;code&gt;(linux, server, haskell)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Glances&lt;/strong&gt; - (&lt;a href="https://github.com/nicolargo/glances"&gt;Repo&lt;/a&gt;, &lt;a href="https://nicolargo.github.io/glances" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://glances.readthedocs.io/en/stable" rel="nofollow"&gt;Docs&lt;/a&gt;) A cross-platform top/htop alternative, providing an overview of system resources. &lt;code&gt;(productivity, linux, windows, mac, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gunicorn&lt;/strong&gt; - (&lt;a href="https://github.com/benoitc/gunicorn"&gt;Repo&lt;/a&gt;, &lt;a href="https://gunicorn.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.python.org/pypi/gunicorn" rel="nofollow"&gt;PyPI&lt;/a&gt;) Pluggable, pre-fork WSGI server, started as the counterpart to &lt;a href="https://en.wikipedia.org/wiki/Unicorn_(web_server)" rel="nofollow"&gt;Unicorn&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Healthchecks&lt;/strong&gt; - (&lt;a href="https://github.com/healthchecks/healthchecks"&gt;Repo&lt;/a&gt;, &lt;a href="https://healthchecks.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://healthchecks.io/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Web-based monitor for scheduled jobs (e.g., cron). &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Iris&lt;/strong&gt; - (&lt;a href="https://github.com/linkedin/iris"&gt;Repo&lt;/a&gt;, &lt;a href="https://iris.claims/" rel="nofollow"&gt;Home&lt;/a&gt;) Flexible automated incident paging system, developed by and used at LinkedIn. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nagstamon&lt;/strong&gt; - (&lt;a href="https://github.com/HenriWahl/Nagstamon"&gt;Repo&lt;/a&gt;, &lt;a href="https://nagstamon.ifw-dresden.de/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://nagstamon.ifw-dresden.de/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Status monitor for the desktop, with support for Nagios, Icinga, Opsview, and more. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NColony&lt;/strong&gt; - (&lt;a href="https://github.com/ncolony/ncolony"&gt;Repo&lt;/a&gt;, &lt;a href="http://ncolony.org/en/latest" rel="nofollow"&gt;Home&lt;/a&gt;) Process manager and monitor. &lt;code&gt;(linux, mac, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;netbox&lt;/strong&gt; - (&lt;a href="https://github.com/netbox-community/netbox"&gt;Repo&lt;/a&gt;, &lt;a href="https://netbox.readthedocs.io/en/stable" rel="nofollow"&gt;Docs&lt;/a&gt;) IP address management (IPAM) and data center infrastructure management (DCIM) tool, conceived at Digital Ocean. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nsupdate.info&lt;/strong&gt; - (&lt;a href="https://github.com/nsupdate-info/nsupdate.info"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/nsupdate" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://nsupdateinfo.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Featureful dynamic DNS service, using the Dynamic DNS UPDATE protocol (&lt;a href="https://tools.ietf.org/html/rfc2136" rel="nofollow"&gt;RFC 2136&lt;/a&gt;) to update BIND and other major nameservers. &lt;code&gt;(internet, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Oncall&lt;/strong&gt; - (&lt;a href="https://github.com/linkedin/oncall"&gt;Repo&lt;/a&gt;, &lt;a href="https://oncall.tools/" rel="nofollow"&gt;Home&lt;/a&gt;) Calendar tool designed for on-call management and scheduling, developed by and used at LinkedIn. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenStack&lt;/strong&gt; - (&lt;a href="https://github.com/openstack/openstack"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.openstack.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.openstack.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Cloud operating system that controls large pools of compute, storage, and networking resources throughout a datacenter, manageable through a web-based dashboard. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pulp&lt;/strong&gt; - (&lt;a href="https://github.com/pulp/pulp"&gt;Repo&lt;/a&gt;, &lt;a href="https://pulpproject.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.pulpproject.org/en/3.0/nightly" rel="nofollow"&gt;Docs&lt;/a&gt;) Platform for managing repositories of software packages and making it available to a large numbers of consumers. Developed and used by Red Hat. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ralph&lt;/strong&gt; - (&lt;a href="https://github.com/allegro/ralph"&gt;Repo&lt;/a&gt;, &lt;a href="https://ralph.allegro.tech/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://ralph-ng.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Simple and powerful Asset Management, DCIM, and CMDB system for the data center and back office. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Salt Stack&lt;/strong&gt; - (&lt;a href="https://github.com/saltstack/salt"&gt;Repo&lt;/a&gt;, &lt;a href="https://repo.saltstack.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Automation for the management and configuration of any infrastructure or application at scale. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shinken&lt;/strong&gt; - (&lt;a href="https://github.com/naparuba/shinken"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.shinken-monitoring.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Shinken is a modern, Nagios-compatible monitoring framework, designed to scale for large environments. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spinnaker&lt;/strong&gt; - (&lt;a href="https://github.com/spinnaker/spinnaker"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.spinnaker.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Spinnaker_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.spinnaker.io/concepts" rel="nofollow"&gt;Docs&lt;/a&gt;) Continuous delivery platform developed for Netflix's deployment and management of applications in cloud environments. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;StackStorm&lt;/strong&gt; - (&lt;a href="https://github.com/StackStorm/st2"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.stackstorm.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Rules- and event-driven operational automation for auto-remediation, security responses, troubleshooting, deployments, and more. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Supervisor&lt;/strong&gt; - (&lt;a href="https://github.com/Supervisor/supervisor"&gt;Repo&lt;/a&gt;, &lt;a href="http://supervisord.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Process manager and monitor. &lt;code&gt;(linux, mac, server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-security" class="anchor" aria-hidden="true" href="#security"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.security" href="#tag-dev.security"&gt;Security&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;BYOB (Build Your Own Botnet)&lt;/strong&gt; - (&lt;a href="https://github.com/malwaredllc/byob"&gt;Repo&lt;/a&gt;) Client-server framework (RAT and C2 server) for security researchers to build and operate basic botnets. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CAPE&lt;/strong&gt; - (&lt;a href="https://github.com/ctxis/CAPE"&gt;Repo&lt;/a&gt;, &lt;a href="https://cape.contextis.com/submit" rel="nofollow"&gt;Demo&lt;/a&gt;) Web application designed to automate malware analysis, with a goal of extracting payloads and configuration from uploaded artifacts. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cowrie&lt;/strong&gt; - (&lt;a href="https://github.com/cowrie/cowrie"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.cowrie.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Medium interaction SSH and Telnet honeypot designed to log brute force attacks and the shell interaction performed by the attacker. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GRR Rapid Response&lt;/strong&gt; - (&lt;a href="https://github.com/google/grr"&gt;Repo&lt;/a&gt;, &lt;a href="https://grr-doc.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Server-agent system focused on remote live forensics for quick, browser-based triage and analysis of attacks on fleets of machines, with agent support for Linux, Windows, and OS X. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hosts&lt;/strong&gt; - (&lt;a href="https://github.com/StevenBlack/hosts"&gt;Repo&lt;/a&gt;) Command-line application which merges reputable &lt;a href="https://en.wikipedia.org/wiki/Hosts_(file)" rel="nofollow"&gt;hosts files&lt;/a&gt; with deduplication for the purpose of blocking undesirable websites via DNS blackhole. &lt;code&gt;(internet, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hubble&lt;/strong&gt; - (&lt;a href="https://github.com/hubblestack/hubble"&gt;Repo&lt;/a&gt;, &lt;a href="https://hubblestack.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Modular security compliance client, providing on-demand profile-based auditing, alerting, and reporting. Originally designed for Adobe. &lt;code&gt;(linux, windows, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Infection Monkey&lt;/strong&gt; - (&lt;a href="https://github.com/guardicore/monkey"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.guardicore.com/infectionmonkey" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/guardicore/monkey/wiki"&gt;Docs&lt;/a&gt;) Web-based tool for testing a datacenter's resiliency to perimeter breaches and internal server infection. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;King Phisher&lt;/strong&gt; - (&lt;a href="https://github.com/securestate/king-phisher"&gt;Repo&lt;/a&gt;, &lt;a href="https://king-phisher.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Server-based &lt;a href="https://en.wikipedia.org/wiki/Phishing" rel="nofollow"&gt;phishing&lt;/a&gt; campaign toolkit, used to simulate real-world phishing attacks, with GTK-powered client application. &lt;code&gt;(linux, windows, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LinOTP&lt;/strong&gt; - (&lt;a href="https://github.com/LinOTP/LinOTP"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.linotp.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/LinOTP" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.linotp.org/documentation.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Server supporting two-factor authentication with one-time passwords from several sources, from Yubikeys to SMS. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Maltrail&lt;/strong&gt; - (&lt;a href="https://github.com/stamparm/maltrail"&gt;Repo&lt;/a&gt;) Malicious traffic detection system with web-based monitoring. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MITMproxy&lt;/strong&gt; - (&lt;a href="https://github.com/mitmproxy/mitmproxy"&gt;Repo&lt;/a&gt;, &lt;a href="https://mitmproxy.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Interactive TLS-capable intercepting HTTP proxy for penetration testers and software developers. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MozDef&lt;/strong&gt; - (&lt;a href="https://github.com/mozilla/MozDef"&gt;Repo&lt;/a&gt;, &lt;a href="https://mozdef.readthedocs.io/en/latest?badge=latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Security incident automation with metrics and collaboration tools for defenders. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenSnitch&lt;/strong&gt; - (&lt;a href="https://github.com/evilsocket/opensnitch"&gt;Repo&lt;/a&gt;, &lt;a href="https://opensnitch.io/" rel="nofollow"&gt;Home&lt;/a&gt;) GNU/Linux port of the &lt;a href="https://en.wikipedia.org/wiki/Little_Snitch" rel="nofollow"&gt;Little Snitch&lt;/a&gt; application firewall. &lt;code&gt;(linux, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Passit&lt;/strong&gt; - (&lt;a href="https://gitlab.com/passit/passit-backend" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://passit.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://passit.io/documentation" rel="nofollow"&gt;Docs&lt;/a&gt;) Password management server, providing storage services and group access control list features. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;privacyIDEA&lt;/strong&gt; - (&lt;a href="https://github.com/privacyidea/privacyidea"&gt;Repo&lt;/a&gt;, &lt;a href="https://privacyidea.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/PrivacyIDEA" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://privacyidea.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) A multi factor authentication server running on premises, supporting many different token types and allowing authentication via REST API, RADIUS, PAM, Windows Credential Provider, SAML, OpenID Connect. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Psono&lt;/strong&gt; - (&lt;a href="https://gitlab.com/psono/psono-server" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://psono.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.psono.pw/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://doc.psono.com/" rel="nofollow"&gt;Docs&lt;/a&gt;) Server-based password manager, built for teams. &lt;code&gt;(productivity, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pupy&lt;/strong&gt; - (&lt;a href="https://github.com/n1nj4sec/pupy"&gt;Repo&lt;/a&gt;, &lt;a href="https://github.com/n1nj4sec/pupy/wiki/Installation"&gt;Docs&lt;/a&gt;) Remote administration tool and post-exploitation framework, supporting Windows, Linux, Mac OS X, and Android targets. &lt;code&gt;(linux, docker, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyEW&lt;/strong&gt; - (&lt;a href="https://github.com/joxeankoret/pyew"&gt;Repo&lt;/a&gt;, &lt;a href="https://github.com/joxeankoret/pyew/wiki"&gt;Docs&lt;/a&gt;) Malware analysis tool, with support for hexadecimal viewing, disassembly, PE and ELF formats, plugins, and more. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Searx&lt;/strong&gt; - (&lt;a href="https://github.com/asciimoo/searx"&gt;Repo&lt;/a&gt;, &lt;a href="https://asciimoo.github.io/searx" rel="nofollow"&gt;Docs&lt;/a&gt;) Self-hosted metasearch engine, aggregating results from more than 70 services while avoiding tracking and profiling. &lt;code&gt;(internet, server, flask)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spiderfoot&lt;/strong&gt; - (&lt;a href="https://github.com/smicallef/spiderfoot"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.spiderfoot.net/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://www.spiderfoot.net/documentation" rel="nofollow"&gt;Docs&lt;/a&gt;) Reconnaissance tool that automatically queries over 100 public data sources to gather intelligence on IP addresses, domain names, e-mail addresses, names, and more. &lt;code&gt;(linux, windows, mac, docker, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sqlmap&lt;/strong&gt; - (&lt;a href="https://github.com/sqlmapproject/sqlmap"&gt;Repo&lt;/a&gt;, &lt;a href="http://sqlmap.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/sqlmapproject/sqlmap/wiki"&gt;Docs&lt;/a&gt;) Automatic SQL injection and database takeover. &lt;code&gt;(storage, console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sshuttle&lt;/strong&gt; - (&lt;a href="https://github.com/sshuttle/sshuttle"&gt;Repo&lt;/a&gt;, &lt;a href="https://sshuttle.readthedocs.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Transparent network proxy server that uses SSH to achieve VPN-like results, without requiring root access. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Universal Radio Hacker (URH)&lt;/strong&gt; - (&lt;a href="https://github.com/jopohl/urh"&gt;Repo&lt;/a&gt;) Wireless protocol investigator, with a focus on analyzing proprietary IoT communication. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;XSStrike&lt;/strong&gt; - (&lt;a href="https://github.com/s0md3v/XSStrike"&gt;Repo&lt;/a&gt;, &lt;a href="https://somdev.me/XSStrike" rel="nofollow"&gt;Home&lt;/a&gt;) &lt;a href="https://en.wikipedia.org/wiki/Cross-site_scripting" rel="nofollow"&gt;Cross Site Scripting&lt;/a&gt; (XSS) detection suite equipped with multiple hand-written parsers, a payload generator, a fuzzing engine, and a performance-focused crawler. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-docs" class="anchor" aria-hidden="true" href="#docs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.docs" href="#tag-dev.docs"&gt;Docs&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;asciidoc&lt;/strong&gt; - (&lt;a href="https://github.com/asciidoc/asciidoc"&gt;Repo&lt;/a&gt;) Text document format for writing notes, documentation, articles, books, slideshows, man pages &amp;amp; blogs. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;doc2dash&lt;/strong&gt; - (&lt;a href="https://github.com/hynek/doc2dash"&gt;Repo&lt;/a&gt;, &lt;a href="https://doc2dash.readthedocs.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/doc2dash" rel="nofollow"&gt;PyPI&lt;/a&gt;) Extensible CLI-based &lt;a href="https://developer.apple.com/library/archive/documentation/DeveloperTools/Conceptual/Documentation_Sets/010-Overview_of_Documentation_Sets/docset_overview.html#//apple_ref/doc/uid/TP40005266-CH13-SW6" rel="nofollow"&gt;Documentation Set&lt;/a&gt; generator intended for use with &lt;a href="https://kapeli.com/dash/" rel="nofollow"&gt;Dash.app&lt;/a&gt; and &lt;a href="https://velocity.silverlakesoftware.com/" rel="nofollow"&gt;other&lt;/a&gt; &lt;a href="https://github.com/dash-docs-el/helm-dash"&gt;compatible&lt;/a&gt; &lt;a href="https://zealdocs.org/" rel="nofollow"&gt;API browsers&lt;/a&gt;. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gaphor&lt;/strong&gt; - (&lt;a href="https://github.com/gaphor/gaphor"&gt;Repo&lt;/a&gt;, &lt;a href="https://gaphor.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Simple &lt;a href="https://en.wikipedia.org/wiki/Unified_Modeling_Language" rel="nofollow"&gt;UML&lt;/a&gt; modeling tool designed for beginners. &lt;code&gt;(graphics, linux, windows, mac, flatpak, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kuma&lt;/strong&gt; - (&lt;a href="https://github.com/mozilla/kuma"&gt;Repo&lt;/a&gt;, &lt;a href="https://developer.mozilla.org/en-US" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://kuma.readthedocs.io/en/latest/installation.html" rel="nofollow"&gt;Docs&lt;/a&gt;) The platform powering the Mozilla Developer Network (MDN) &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mkdocs&lt;/strong&gt; - (&lt;a href="https://github.com/mkdocs/mkdocs"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.mkdocs.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Simple, customizable project documentation, with built-in dev server. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;readthedocs.org&lt;/strong&gt; - (&lt;a href="https://github.com/readthedocs/readthedocs.org"&gt;Repo&lt;/a&gt;, &lt;a href="https://readthedocs.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.readthedocs.io/en/stable" rel="nofollow"&gt;Docs&lt;/a&gt;) Continuous integration platform for building and hosting documentation. &lt;code&gt;(server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sphinx&lt;/strong&gt; - (&lt;a href="https://github.com/sphinx-doc/sphinx"&gt;Repo&lt;/a&gt;, &lt;a href="http://sphinx-doc.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Documentation tool for interconnected bodies of authorship, from code documentation to books. Used by &lt;a href="https://docs.python.org" rel="nofollow"&gt;the official Python docs&lt;/a&gt;, and many other projects (&lt;a href="https://varnish-cache.org/docs/" rel="nofollow"&gt;not all of them Python&lt;/a&gt;). &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-editor" class="anchor" aria-hidden="true" href="#editor"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.editor" href="#tag-dev.editor"&gt;Editor&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Black&lt;/strong&gt; - (&lt;a href="https://github.com/ambv/black"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/black" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://black.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Uncompromising automatic formatter for Python code. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eric IDE&lt;/strong&gt; - (&lt;a href="http://die-offenbachs.homelinux.org:48888/hg/eric" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://eric-ide.python-projects.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Python editor and IDE, based on Qt, integrating Scintilla editor control. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gedit&lt;/strong&gt; - (&lt;a href="https://gitlab.gnome.org/GNOME/gedit" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Gedit" rel="nofollow"&gt;WP&lt;/a&gt;) The default GNOME text editor makes extensive use of Python, in addition to C. &lt;code&gt;(linux, c, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jupyter Notebook&lt;/strong&gt; - (&lt;a href="https://github.com/jupyter/notebook"&gt;Repo&lt;/a&gt;, &lt;a href="https://jupyter.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Project_Jupyter#Jupyter_Notebook" rel="nofollow"&gt;WP&lt;/a&gt;) Web-based, extensible notebook environment for interactive computing. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Komodo Edit&lt;/strong&gt; - (&lt;a href="https://github.com/Komodo/KomodoEdit"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.activestate.com/products/komodo-edit" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Komodo_Edit" rel="nofollow"&gt;WP&lt;/a&gt;) Multi-language code editor, written in JS, Python, and C++, based on the Mozilla platform. &lt;code&gt;(linux, windows, mac, cpp, js)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Leo Editor&lt;/strong&gt; - (&lt;a href="https://github.com/leo-editor/leo-editor"&gt;Repo&lt;/a&gt;, &lt;a href="http://leoeditor.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Leo_%28text_editor%29" rel="nofollow"&gt;WP&lt;/a&gt;) Personal Information Manager (PIM), IDE, and outliner with a holistic approach to programming and writing. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mu&lt;/strong&gt; - (&lt;a href="https://github.com/mu-editor/mu"&gt;Repo&lt;/a&gt;, &lt;a href="https://codewith.mu/en" rel="nofollow"&gt;Home&lt;/a&gt;) A small, simple editor designed for beginner Python programmers. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ninja IDE&lt;/strong&gt; - (&lt;a href="https://github.com/ninja-ide/ninja-ide"&gt;Repo&lt;/a&gt;, &lt;a href="http://ninja-ide.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Ninja-IDE" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform Python IDE with project management, linting, extensions, and more. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pluma&lt;/strong&gt; - (&lt;a href="https://github.com/mate-desktop/pluma"&gt;Repo&lt;/a&gt;) Small and lightweight UTF-8 text editor for &lt;a href="http://mate-desktop.org/" rel="nofollow"&gt;the MATE environment&lt;/a&gt;. Based on gedit. &lt;code&gt;(linux, c, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ReText&lt;/strong&gt; - (&lt;a href="https://github.com/retext-project/retext"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/ReText" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://github.com/retext-project/retext/wiki"&gt;Docs&lt;/a&gt;) Simple but powerful editor for Markdown and reStructuredText markup languages. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spyder IDE&lt;/strong&gt; - (&lt;a href="https://github.com/spyder-ide/spyder"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.spyder-ide.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Spyder_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Scientific editing and execution environment designed by and for scientists, engineers, and data analysts using Python. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Thonny&lt;/strong&gt; - (&lt;a href="https://github.com/thonny/thonny"&gt;Repo&lt;/a&gt;, &lt;a href="https://thonny.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Thonny" rel="nofollow"&gt;WP&lt;/a&gt;) Cross-platform Python IDE for beginners, designed for learning to code. &lt;code&gt;(linux, windows, mac, tk)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-package-managers" class="anchor" aria-hidden="true" href="#package-managers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.pkg_mgr" href="#tag-dev.pkg_mgr"&gt;Package Managers&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Conan&lt;/strong&gt; - (&lt;a href="https://github.com/conan-io/conan"&gt;Repo&lt;/a&gt;, &lt;a href="https://conan.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.conan.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Decentralized package manager for binary package management, targeted at C/C++ developers. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conda&lt;/strong&gt; - (&lt;a href="https://github.com/conda/conda"&gt;Repo&lt;/a&gt;, &lt;a href="https://conda.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Conda_%28package_manager%29" rel="nofollow"&gt;WP&lt;/a&gt;) OS-agnostic, system-level binary package manager and ecosystem, with a focus on Python and high-performance scientific computing. &lt;code&gt;(linux, windows, mac, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dnf&lt;/strong&gt; - (&lt;a href="https://github.com/rpm-software-management/dnf"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/DNF_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://dnf.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Dandified YUM (DNF) is the successor to &lt;code&gt;yum&lt;/code&gt; and works everywhere yum worked. &lt;code&gt;(linux, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pip&lt;/strong&gt; - (&lt;a href="https://github.com/pypa/pip"&gt;Repo&lt;/a&gt;, &lt;a href="https://pip.pypa.io/en/stable" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Pip_%28package_manager%29" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://pypi.org/project/pip" rel="nofollow"&gt;PyPI&lt;/a&gt;) Python's go-to package manager, with a wide range of features and platform support. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pip-tools&lt;/strong&gt; - (&lt;a href="https://github.com/jazzband/pip-tools"&gt;Repo&lt;/a&gt;) A set of command line tools to help you keep your pip-based packages fresh, even when you've pinned them. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pipenv&lt;/strong&gt; - (&lt;a href="https://github.com/pypa/pipenv"&gt;Repo&lt;/a&gt;, &lt;a href="https://pipenv.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Wrapper around &lt;code&gt;pip&lt;/code&gt;, &lt;a href="https://github.com/pypa/virtualenv"&gt;&lt;code&gt;virtualenv&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://github.com/jazzband/pip-tools"&gt;&lt;code&gt;pip-tools&lt;/code&gt;&lt;/a&gt; for a more holistic package management workflow. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Poetry&lt;/strong&gt; - (&lt;a href="https://github.com/sdispater/poetry"&gt;Repo&lt;/a&gt;, &lt;a href="https://poetry.eustace.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://poetry.eustace.io/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) An independent approach to Python dependency management and packaging. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Portage&lt;/strong&gt; - (&lt;a href="https://gitweb.gentoo.org/proj/portage.git" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Portage_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Platform-agnostic Package management system created for and used by Gentoo Linux and also by Chrome OS, Sabayon, and Funtoo Linux. Inspired by FreeBSD ports. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Solaris IPS&lt;/strong&gt; - (&lt;a href="https://github.com/oracle/solaris-ips"&gt;Repo&lt;/a&gt;) Software delivery system backed by network repository, featuring safe execution for zones, use of ZFS for efficiency and rollback, preventing the introduction of invalid packages, and efficient use of bandwidth. &lt;code&gt;(linux, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;yum&lt;/strong&gt; - (&lt;a href="https://github.com/rpm-software-management/yum"&gt;Repo&lt;/a&gt;, &lt;a href="http://yum.baseurl.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Yum_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) Automatic updater and package installer/remover for RPM-based systems (Fedora, RHEL, etc.). &lt;code&gt;(linux, corp)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-package-repositories" class="anchor" aria-hidden="true" href="#package-repositories"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.pkg_repo" href="#tag-dev.pkg_repo"&gt;Package Repositories&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Bandersnatch&lt;/strong&gt; - (&lt;a href="https://github.com/pypa/bandersnatch"&gt;Repo&lt;/a&gt;) PyPI mirror client complying with &lt;a href="http://www.python.org/dev/peps/pep-0381/" rel="nofollow"&gt;PEP 381&lt;/a&gt;. &lt;code&gt;(server, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;devpi&lt;/strong&gt; - (&lt;a href="https://github.com/devpi/devpi"&gt;Repo&lt;/a&gt;, &lt;a href="http://doc.devpi.net/" rel="nofollow"&gt;Docs&lt;/a&gt;) PyPI staging server, as well as a packaging, testing, release tool, complete with web and search interface. Like a local PyPI. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;distro-tracker&lt;/strong&gt; - (&lt;a href="https://salsa.debian.org/qa/distro-tracker" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://tracker.debian.org/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://qa.pages.debian.net/distro-tracker" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application designed to follow the evolution of a Debian-based distribution with email updates and a comprehensive web interface. Powers the &lt;a href="https://tracker.debian.org/" rel="nofollow"&gt;Debian Package Tracker&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SweetTooth Web&lt;/strong&gt; - (&lt;a href="https://gitlab.gnome.org/Infrastructure/extensions-web" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://extensions.gnome.org/" rel="nofollow"&gt;Home&lt;/a&gt;) The web store for extensions to the &lt;a href="https://en.wikipedia.org/wiki/GNOME" rel="nofollow"&gt;GNOME&lt;/a&gt; desktop environment, supporting adding and updating extensions directly from the browser. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Warehouse&lt;/strong&gt; - (&lt;a href="https://github.com/pypa/warehouse"&gt;Repo&lt;/a&gt;, &lt;a href="https://psfmember.org/civicrm/contribute/transact?reset=1&amp;amp;id=13" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://warehouse.pypa.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Server software that powers &lt;a href="https://pypi.org/" rel="nofollow"&gt;PyPI&lt;/a&gt;, where most Python libraries are downloaded from. &lt;code&gt;(server, fnd)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-build" class="anchor" aria-hidden="true" href="#build"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.build" href="#tag-dev.build"&gt;Build&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;bitbake&lt;/strong&gt; - (&lt;a href="https://github.com/openembedded/bitbake"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/BitBake" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.yoctoproject.org/docs/current/bitbake-user-manual/bitbake-user-manual.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Generic task execution engine that allows shell and Python tasks to be run efficiently and in parallel while working within complex inter-task dependency constraints. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;buildbot&lt;/strong&gt; - (&lt;a href="https://github.com/buildbot/buildbot"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Buildbot" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://www.buildbot.net/" rel="nofollow"&gt;Docs&lt;/a&gt;) Job scheduling system tailored to the needs of continuous integration and software packaging. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Buildout&lt;/strong&gt; - (&lt;a href="https://github.com/buildout/buildout"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Buildout" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="http://docs.buildout.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Extensible deployment automation tool designed for application-centric assembly and deployment, as well as repeatable Python software builds. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;doit&lt;/strong&gt; - (&lt;a href="https://github.com/pydoit/doit"&gt;Repo&lt;/a&gt;, &lt;a href="https://pydoit.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://opencollective.com/doit" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://pydoit.org/contents.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Command-line task management and automation tool, with directives written in Python. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GYP&lt;/strong&gt; - (&lt;a href="https://chromium.googlesource.com/external/gyp" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://gyp.gsrc.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GYP_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) AKA 'Generate Your Projects', a build system that generates other build systems. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JHBuild&lt;/strong&gt; - (&lt;a href="https://gitlab.gnome.org/GNOME/jhbuild" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://wiki.gnome.org/Projects/Jhbuild" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://github.com/GNOME/jhbuild"&gt;gh&lt;/a&gt;, &lt;a href="https://developer.gnome.org/jhbuild/stable/getting-started.html.en" rel="nofollow"&gt;Docs&lt;/a&gt;) Tool designed to ease building collections of packages, originally written to build the GNOME desktop from sources. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Meson&lt;/strong&gt; - (&lt;a href="https://github.com/mesonbuild/meson"&gt;Repo&lt;/a&gt;, &lt;a href="http://mesonbuild.com/" rel="nofollow"&gt;Home&lt;/a&gt;) Build system designed for speed and user-friendliness. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pants&lt;/strong&gt; - (&lt;a href="https://github.com/pantsbuild/pants"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.pantsbuild.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Build system designed for monolithic repositories. &lt;code&gt;(linux, mac, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PlatformIO Core&lt;/strong&gt; - (&lt;a href="https://github.com/platformio/platformio-core"&gt;Repo&lt;/a&gt;, &lt;a href="https://platformio.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://platformio.org/donate?utm_source=github&amp;amp;utm_medium=core" rel="nofollow"&gt;Fund&lt;/a&gt;, &lt;a href="https://pypi.org/project/platformio" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://docs.platformio.org/en/latest?utm_source=github&amp;amp;utm_medium=core" rel="nofollow"&gt;Docs&lt;/a&gt;) Multiplatform CLI build system and library manager for IoT development. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;redo&lt;/strong&gt; - (&lt;a href="https://github.com/apenwarr/redo"&gt;Repo&lt;/a&gt;, &lt;a href="https://redo.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) A recursive, general-purpose build sytem, replacing &lt;code&gt;make&lt;/code&gt; with original design by &lt;a href="https://en.wikipedia.org/wiki/Daniel_J._Bernstein" rel="nofollow"&gt;DJB&lt;/a&gt;. &lt;code&gt;(linux, windows, mac, console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SCons&lt;/strong&gt; - (&lt;a href="https://github.com/SCons/scons"&gt;Repo&lt;/a&gt;, &lt;a href="http://scons.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/SCons" rel="nofollow"&gt;WP&lt;/a&gt;) Domain-specific language and build tool, designed to replace Make, autoconf, and ccache. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Snapcraft&lt;/strong&gt; - (&lt;a href="https://github.com/snapcore/snapcraft"&gt;Repo&lt;/a&gt;, &lt;a href="https://snapcraft.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://snapcraft.io/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) A command-line tool to package, distribute, and update apps for Linux and IoT using containerization, developed by Canonical. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Waf&lt;/strong&gt; - (&lt;a href="https://gitlab.com/ita1024/waf" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://waf.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Waf" rel="nofollow"&gt;WP&lt;/a&gt;, &lt;a href="https://waf.io/book" rel="nofollow"&gt;Docs&lt;/a&gt;) Cross-platform build system designed to improve on SCons. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-shell" class="anchor" aria-hidden="true" href="#shell"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev.shell" href="#tag-dev.shell"&gt;Shell&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Ergonomica&lt;/strong&gt; - (&lt;a href="https://github.com/ergonomica/ergonomica"&gt;Repo&lt;/a&gt;, &lt;a href="http://ergonomica.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Cross-platform shell language based on &lt;a href="https://en.wikipedia.org/wiki/S-expression" rel="nofollow"&gt;S-expressions&lt;/a&gt; combined with traditional shell features. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Oil&lt;/strong&gt; - (&lt;a href="https://github.com/oilshell/oil"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.oilshell.org/" rel="nofollow"&gt;Home&lt;/a&gt;) A new &lt;a href="https://en.wikipedia.org/wiki/Bash_(Unix_shell)" rel="nofollow"&gt;bash&lt;/a&gt;- and &lt;a href="https://en.wikipedia.org/wiki/Almquist_shell#dash:_Ubuntu,_Debian_and_POSIX_compliance_of_Linux_distributions" rel="nofollow"&gt;dash&lt;/a&gt; backwards-compatible shell, with an improved language of its own. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Xonsh&lt;/strong&gt; - (&lt;a href="https://github.com/xonsh/xonsh"&gt;Repo&lt;/a&gt;, &lt;a href="https://xon.sh/" rel="nofollow"&gt;Home&lt;/a&gt;) Cross-platform shell language and command prompt. The language is a superset of Python 3.4+ with additional shell primitives. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-other-dev-projects" class="anchor" aria-hidden="true" href="#other-dev-projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-dev-other" href="#tag-dev-other"&gt;Other Dev projects&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;asciinema&lt;/strong&gt; - (&lt;a href="https://github.com/asciinema/asciinema"&gt;Repo&lt;/a&gt;, &lt;a href="https://asciinema.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Terminal session recorder and replayer. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;autojump&lt;/strong&gt; - (&lt;a href="https://github.com/wting/autojump"&gt;Repo&lt;/a&gt;) A &lt;code&gt;cd&lt;/code&gt; with many heuristics to speed up console filesystem navigation. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;coala&lt;/strong&gt; - (&lt;a href="https://github.com/coala/coala"&gt;Repo&lt;/a&gt;, &lt;a href="https://coala.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Unified command-line interface for linting and fixing code, regardless of programming language. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cookiecutter&lt;/strong&gt; - (&lt;a href="https://github.com/audreyr/cookiecutter"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/cookiecutter" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://cookiecutter.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Utility for creating new projects from shareable templates. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cython&lt;/strong&gt; - (&lt;a href="https://github.com/cython/cython"&gt;Repo&lt;/a&gt;, &lt;a href="https://cython.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/cython" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="http://docs.cython.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Language and compiler designed for high-performance Python and C interoperability. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;doitlive&lt;/strong&gt; - (&lt;a href="https://github.com/sloria/doitlive"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/doitlive" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://doitlive.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Tool for live presentations in the terminal. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DrawBot&lt;/strong&gt; - (&lt;a href="https://github.com/typemytype/drawbot"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.drawbot.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/DrawBot" rel="nofollow"&gt;WP&lt;/a&gt;) A powerful programmatic 2D drawing application for MacOS X which generates graphics from Python scripts. &lt;code&gt;(graphics, education, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gdbgui&lt;/strong&gt; - (&lt;a href="https://github.com/cs01/gdbgui"&gt;Repo&lt;/a&gt;, &lt;a href="https://gdbgui.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/gdbgui" rel="nofollow"&gt;PyPI&lt;/a&gt;) Browser-based frontend for &lt;a href="https://en.wikipedia.org/wiki/GNU_Debugger" rel="nofollow"&gt;gdb&lt;/a&gt;. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GNS3 GUI&lt;/strong&gt; - (&lt;a href="https://github.com/GNS3/gns3-gui"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.gns3.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/gns3-gui" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://docs.gns3.com/" rel="nofollow"&gt;Docs&lt;/a&gt;) Graphical Network Simulator used to emulate, configure, test and troubleshoot virtual and real networks. (Backed by server component &lt;a href="https://github.com/GNS3/gns3-server"&gt;here&lt;/a&gt;.) &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;howdoi&lt;/strong&gt; - (&lt;a href="https://github.com/gleitz/howdoi"&gt;Repo&lt;/a&gt;, &lt;a href="https://pypi.org/project/howdoi" rel="nofollow"&gt;PyPI&lt;/a&gt;) Instant coding answers from StackOverflow on your command line. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;httpie&lt;/strong&gt; - (&lt;a href="https://github.com/jakubroztocil/httpie"&gt;Repo&lt;/a&gt;, &lt;a href="https://httpie.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/httpie" rel="nofollow"&gt;PyPI&lt;/a&gt;) Command-line HTTP client with JSON support, syntax highlighting, wget-like downloads, extensions, and more. &lt;code&gt;(internet, linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IPython&lt;/strong&gt; - (&lt;a href="https://github.com/ipython/ipython"&gt;Repo&lt;/a&gt;, &lt;a href="https://ipython.readthedocs.org/" rel="nofollow"&gt;Docs&lt;/a&gt;) Set of enhancements to Python, wrapping it for richer interactivity. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LocalStack&lt;/strong&gt; - (&lt;a href="https://github.com/localstack/localstack"&gt;Repo&lt;/a&gt;, &lt;a href="https://localstack.cloud/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://pypi.org/project/localstack" rel="nofollow"&gt;PyPI&lt;/a&gt;) Self-hostable version of many AWS services, including S3, Route53, Lambda, Redshift, and much more, designed for testing cloud-centric code. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Locust&lt;/strong&gt; - (&lt;a href="https://github.com/locustio/locust"&gt;Repo&lt;/a&gt;, &lt;a href="https://locust.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.locust.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Scalable user load testing tool for web sites, featuring an interactive web interface. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MLflow&lt;/strong&gt; - (&lt;a href="https://github.com/mlflow/mlflow"&gt;Repo&lt;/a&gt;, &lt;a href="https://mlflow.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://mlflow.org/docs/latest/index.html" rel="nofollow"&gt;Docs&lt;/a&gt;) Integrated command-line application and web service, supporting an end-to-end machine-learning workflow around tracking, packaging, and deploying. Developed by &lt;a href="https://docs.databricks.com/applications/mlflow/index.html" rel="nofollow"&gt;Databricks&lt;/a&gt;. &lt;code&gt;(organization, linux, mac, corp)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PathPicker&lt;/strong&gt; - (&lt;a href="https://github.com/facebook/PathPicker"&gt;Repo&lt;/a&gt;, &lt;a href="http://facebook.github.io/PathPicker" rel="nofollow"&gt;Home&lt;/a&gt;) Shell utility to interactively select paths from the output of other commands. &lt;code&gt;(linux, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PeachPy&lt;/strong&gt; - (&lt;a href="https://github.com/Maratyszcza/PeachPy"&gt;Repo&lt;/a&gt;) Highly portable assembler with unified syntax, sporting an extensive user list, including many cryptography libraries for Go. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PINCE&lt;/strong&gt; - (&lt;a href="https://github.com/korcankaraokcu/PINCE"&gt;Repo&lt;/a&gt;) Debugging frontend for GDB focused on reverse engineering video games. &lt;code&gt;(linux, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plinth&lt;/strong&gt; - (&lt;a href="https://salsa.debian.org/freedombox-team/plinth" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://freedombox.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://wiki.debian.org/FreedomBox/Plinth" rel="nofollow"&gt;Docs&lt;/a&gt;) The core functionality and web front-end of &lt;a href="https://freedombox.org/" rel="nofollow"&gt;FreedomBox&lt;/a&gt;, an easy-to-manage, privacy-oriented home server. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Polyaxon&lt;/strong&gt; - (&lt;a href="https://github.com/polyaxon/polyaxon"&gt;Repo&lt;/a&gt;, &lt;a href="https://polyaxon.com/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://docs.polyaxon.com/" rel="nofollow"&gt;Docs&lt;/a&gt;) A web-based platform for reproducible and scalable machine learning experiment management and metrics-tracking, based on kubernetes, with support for TensorFlow, PyTorch, Keras, and many more. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PPCI&lt;/strong&gt; - (&lt;a href="https://bitbucket.org/windel/ppci" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://godbolt.org/g/eooaPP" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://github.com/windelbouwman/ppci-mirror"&gt;gh&lt;/a&gt;, &lt;a href="https://pypi.org/project/ppci" rel="nofollow"&gt;PyPI&lt;/a&gt;, &lt;a href="https://ppci.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) The Pure Python Compiler Infrastructure is a compiler written entirely in Python, containing front-ends for various programming languages (C, c3, WebAssembly, and others) as well as machine code generation backends for various CPUs (6500, arm, avr, x86_64, openrisc, among others). &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RedHat Anaconda&lt;/strong&gt; - (&lt;a href="https://github.com/rhinstaller/anaconda"&gt;Repo&lt;/a&gt;, &lt;a href="https://anaconda-installer.readthedocs.io/en/latest" rel="nofollow"&gt;Docs&lt;/a&gt;) Installation program used by Fedora, Red Hat Enterprise Linux, and other Linux distributions. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Robot Framework&lt;/strong&gt; - (&lt;a href="https://github.com/robotframework/robotframework"&gt;Repo&lt;/a&gt;, &lt;a href="http://robotframework.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Generic, cross-platform, and language-independent automation framework for acceptance testing, acceptance test driven development (ATDD), and robotic process automation (RPA). Extensible in Python and Java. &lt;code&gt;(console)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ScratchABit&lt;/strong&gt; - (&lt;a href="https://github.com/pfalcon/ScratchABit"&gt;Repo&lt;/a&gt;) Easily retargetable and hackable interactive disassembler with IDAPython-compatible plugin API. &lt;code&gt;(linux, tui)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sentry&lt;/strong&gt; - (&lt;a href="https://github.com/getsentry/sentry"&gt;Repo&lt;/a&gt;, &lt;a href="https://sentry.io/" rel="nofollow"&gt;Home&lt;/a&gt;) Web service and frontend for cross-platform application monitoring, with a focus on error reporting. &lt;code&gt;(server, corp, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Socorro&lt;/strong&gt; - (&lt;a href="https://github.com/mozilla-services/socorro"&gt;Repo&lt;/a&gt;, &lt;a href="https://wiki.mozilla.org/Socorro" rel="nofollow"&gt;Docs&lt;/a&gt;) Web service for collecting crash statistics from Mozilla products, including Firefox, Thunderbird, and &lt;a href="https://crash-stats.mozilla.org/" rel="nofollow"&gt;others&lt;/a&gt;. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Taiga&lt;/strong&gt; - (&lt;a href="https://github.com/taigaio/taiga-back"&gt;Repo&lt;/a&gt;, &lt;a href="https://taiga.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="http://taigaio.github.io/taiga-doc/dist" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application built for managing projects with agile development processes. &lt;code&gt;(organization, server, django)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Thumbor&lt;/strong&gt; - (&lt;a href="https://github.com/thumbor/thumbor"&gt;Repo&lt;/a&gt;, &lt;a href="http://thumbor.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://thumbor.readthedocs.io/" rel="nofollow"&gt;Docs&lt;/a&gt;) Photo thumbnail service with resizing, flipping, and smart cropping of images. &lt;code&gt;(graphics, server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ubiquity&lt;/strong&gt; - (&lt;a href="https://code.launchpad.net/ubiquity" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Ubiquity_%28software%29" rel="nofollow"&gt;WP&lt;/a&gt;) The default installer for Ubuntu and its derivatives, designed to be run from Live CD or USB. &lt;code&gt;(linux, gtk, qt)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Voltron&lt;/strong&gt; - (&lt;a href="https://github.com/snare/voltron"&gt;Repo&lt;/a&gt;) Extensible debugger wrapper aiming to improve the user experience of various debuggers, such as &lt;a href="https://lldb.llvm.org/" rel="nofollow"&gt;LLDB&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/GNU_Debugger" rel="nofollow"&gt;GDB&lt;/a&gt;, and &lt;a href="https://en.wikipedia.org/wiki/WinDbg" rel="nofollow"&gt;WinDbg&lt;/a&gt;. &lt;code&gt;(linux, windows, mac)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;YunoHost&lt;/strong&gt; - (&lt;a href="https://github.com/YunoHost/yunohost"&gt;Repo&lt;/a&gt;, &lt;a href="https://yunohost.org/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://yunohost.org/#/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Server operating system based on Debian Linux aiming to make self-hosting accessible to as many people as possible, with support for several types of hardware. &lt;code&gt;(linux, server)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-misc" class="anchor" aria-hidden="true" href="#misc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a id="user-content-tag-misc" href="#tag-misc"&gt;Misc&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Guake&lt;/strong&gt; - (&lt;a href="https://github.com/Guake/guake"&gt;Repo&lt;/a&gt;, &lt;a href="http://guake-project.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Drop-down terminal for GNOME, reminiscent of first-person game command consoles. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Home Assistant&lt;/strong&gt; - (&lt;a href="https://github.com/home-assistant/home-assistant"&gt;Repo&lt;/a&gt;, &lt;a href="https://www.home-assistant.io/" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://demo.home-assistant.io/" rel="nofollow"&gt;Demo&lt;/a&gt;, &lt;a href="https://www.home-assistant.io/docs" rel="nofollow"&gt;Docs&lt;/a&gt;) Home automation platform that puts local control and privacy first. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JARVIS on Messenger&lt;/strong&gt; - (&lt;a href="https://github.com/swapagarwal/JARVIS-on-Messenger"&gt;Repo&lt;/a&gt;, &lt;a href="https://m.me/J.A.R.V.I.S.on.Messenger" rel="nofollow"&gt;Home&lt;/a&gt;) Facebook Messenger bot with a wide assortment of features. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NFO Viewer&lt;/strong&gt; - (&lt;a href="https://github.com/otsaloma/nfoview"&gt;Repo&lt;/a&gt;, &lt;a href="https://otsaloma.io/nfoview" rel="nofollow"&gt;Home&lt;/a&gt;) A simple viewer for NFO files and the ASCII art therein, with preset fonts, encodings, automatic window sizing, and clickable hyperlinks. &lt;code&gt;(graphics, linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nicotine+&lt;/strong&gt; - (&lt;a href="https://github.com/Nicotine-Plus/nicotine-plus"&gt;Repo&lt;/a&gt;) Graphical desktop client for the &lt;a href="https://en.wikipedia.org/wiki/Soulseek" rel="nofollow"&gt;Soulseek&lt;/a&gt; peer-to-peer system. &lt;code&gt;(linux, windows, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nimbus&lt;/strong&gt; - (&lt;a href="https://github.com/nimbusproject/nimbus"&gt;Repo&lt;/a&gt;, &lt;a href="http://www.nimbusproject.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Infrastructure-as-a-Service platform geared toward scientific cloud computing. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenLP&lt;/strong&gt; - (&lt;a href="https://code.launchpad.net/openlp" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="https://openlp.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Presentation software geared toward church usage. &lt;code&gt;(linux, windows, mac, qt5)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;qtile&lt;/strong&gt; - (&lt;a href="https://github.com/qtile/qtile"&gt;Repo&lt;/a&gt;, &lt;a href="http://qtile.org/" rel="nofollow"&gt;Home&lt;/a&gt;) A small, flexible, scriptable tiling window manager. &lt;code&gt;(linux)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;uMap&lt;/strong&gt; - (&lt;a href="https://github.com/umap-project/umap"&gt;Repo&lt;/a&gt;, &lt;a href="https://wiki.openstreetmap.org/wiki/UMap" rel="nofollow"&gt;Docs&lt;/a&gt;) Web application allowing users to create maps with OpenStreetMap layers and embed it on other sites. &lt;code&gt;(server)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wammu&lt;/strong&gt; - (&lt;a href="https://github.com/gammu/wammu"&gt;Repo&lt;/a&gt;, &lt;a href="https://wammu.eu/wammu" rel="nofollow"&gt;Home&lt;/a&gt;) GUI phone manager with read/write support for contacts, todo, calendar, SMS, and more, primarily designed for Nokia and AT-compatible phones. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wicd&lt;/strong&gt; - (&lt;a href="https://code.launchpad.net/wicd" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://wicd.sourceforge.net/download.php" rel="nofollow"&gt;Home&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Wicd" rel="nofollow"&gt;WP&lt;/a&gt;) Graphical utility for managing wired and wireless connections on Linux. &lt;code&gt;(linux, gtk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Xpra&lt;/strong&gt; - (&lt;a href="https://xpra.org/svn/Xpra/trunk" rel="nofollow"&gt;Repo&lt;/a&gt;, &lt;a href="http://xpra.org/" rel="nofollow"&gt;Home&lt;/a&gt;) Cross-platform remote display server and client for forwarding applications and desktop screens. &lt;code&gt;(linux, windows)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;&lt;a id="user-content-conclusion" class="anchor" aria-hidden="true" href="#conclusion"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;If you have a project to add, &lt;a href="https://github.com/mahmoud/awesome-python-applications/issues"&gt;please let us know&lt;/a&gt;!&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>mahmoud</author><guid isPermaLink="false">https://github.com/mahmoud/awesome-python-applications</guid><pubDate>Sat, 30 Nov 2019 00:19:00 GMT</pubDate></item><item><title>StevenLei2017/AI_projects #20 in Jupyter Notebook, Today</title><link>https://github.com/StevenLei2017/AI_projects</link><description>&lt;p&gt;&lt;i&gt;I am a full-stack engineer for AI projects, glad to share my experience. pratices make the top engineer.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-ai_projects" class="anchor" aria-hidden="true" href="#ai_projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;AI_Projects&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;本项目包含作者完成过的各种人工智能工程，包括：目标检测、图片分类、文本分类、机器学习、数据分析&lt;/li&gt;
&lt;li&gt;读者可以通过每个工程文件夹中的说明文件&lt;code&gt;readme.md&lt;/code&gt;清楚地知道工程的实现流程。&lt;/li&gt;
&lt;li&gt;如果读者复现工程遇到困难，欢迎提交issues，本人联系QQ：474933858。&lt;/li&gt;
&lt;li&gt;作者白天上班工作，晚上8点以后能够上线帮助网友解答问题。&lt;/li&gt;
&lt;li&gt;建议按照下面的规范提交issues，否则得到回答的可能性低。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;我的硬件环境（如果你觉得有必要的话），我的软件环境（操作系统型号、python版本、各种库版本等）&lt;/li&gt;
&lt;li&gt;我在复现第xxx篇文章第xxx节的第xxx步时遇到了问题&lt;/li&gt;
&lt;li&gt;我遇到的问题：...&lt;/li&gt;
&lt;li&gt;我为了解决问题作出过哪些努力：...&lt;/li&gt;
&lt;li&gt;我希望得到的结果：...&lt;/li&gt;
&lt;/ol&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>StevenLei2017</author><guid isPermaLink="false">https://github.com/StevenLei2017/AI_projects</guid><pubDate>Sat, 30 Nov 2019 00:20:00 GMT</pubDate></item><item><title>santosjorge/cufflinks #21 in Jupyter Notebook, Today</title><link>https://github.com/santosjorge/cufflinks</link><description>&lt;p&gt;&lt;i&gt;Productivity Tools for Plotly + Pandas&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-cufflinks" class="anchor" aria-hidden="true" href="#cufflinks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cufflinks&lt;/h2&gt;
&lt;p&gt;This library binds the power of &lt;a href="http://www.plot.ly" rel="nofollow"&gt;plotly&lt;/a&gt; with the flexibility of &lt;a href="http://pandas.pydata.org/" rel="nofollow"&gt;pandas&lt;/a&gt; for easy plotting.&lt;/p&gt;
&lt;p&gt;This library is available on &lt;a href="https://github.com/santosjorge/cufflinks"&gt;https://github.com/santosjorge/cufflinks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tutorial assumes that the plotly user credentials have already been configured as stated on the &lt;a href="https://plot.ly/python/getting-started/" rel="nofollow"&gt;getting started&lt;/a&gt; guide.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-tutorials" class="anchor" aria-hidden="true" href="#tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tutorials:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/gist/santosjorge/b278ce0ae2448f47c31d" rel="nofollow"&gt;Chart Gallery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/gist/santosjorge/aba934a0d20023a136c2" rel="nofollow"&gt;Pandas Like Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/gist/santosjorge/f3b07b2be8094deea8c6" rel="nofollow"&gt;The Basics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/gist/santosjorge/00ca17b121fa2463e18b" rel="nofollow"&gt;Color Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/gist/santosjorge/5fdbe947496faf7af5e6" rel="nofollow"&gt;Offline Mode&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/ukswaps.gif"&gt;&lt;img src="img/ukswaps.gif" alt="3D Charts" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-release-notes" class="anchor" aria-hidden="true" href="#release-notes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Release Notes&lt;/h3&gt;
&lt;h3&gt;&lt;a id="user-content-v0170" class="anchor" aria-hidden="true" href="#v0170"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.17.0&lt;/h3&gt;
&lt;p&gt;Support for Plotly 4.x&lt;br&gt;
Cufflinks is no longer compatible with Plotly 3.x&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-v0140" class="anchor" aria-hidden="true" href="#v0140"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.14.0&lt;/h3&gt;
&lt;p&gt;Support for Plotly 3.0&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-v0130" class="anchor" aria-hidden="true" href="#v0130"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.13.0&lt;/h3&gt;
&lt;p&gt;New &lt;code&gt;iplot&lt;/code&gt; helper.
To see a comprehensive list of parameters
&lt;strong&gt;cf.help()&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; For a list of supported figures&lt;/span&gt;
cf.help()
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Or to see the parameters supported that apply to a given figure try&lt;/span&gt;
cf.help(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;scatter&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
cf.help(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;candle&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;etc&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-v0120" class="anchor" aria-hidden="true" href="#v0120"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.12.0&lt;/h3&gt;
&lt;p&gt;Removed dependecies on ta-lib.
This library is no longer required.
All studies have be rewritten in Python.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-v0110" class="anchor" aria-hidden="true" href="#v0110"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.11.0&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;QuantFigure&lt;/code&gt; is a new class that will generate a graph object with persistence.
Parameters can be added/modified at any given point.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This can be as easy as:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;df&lt;span class="pl-k"&gt;=&lt;/span&gt;cf.datagen.ohlc()
qf&lt;span class="pl-k"&gt;=&lt;/span&gt;cf.QuantFig(df,&lt;span class="pl-v"&gt;title&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;First Quant Figure&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-v"&gt;legend&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;top&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;GS&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
qf.add_bollinger_bands()
qf.iplot()
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/qf1.png"&gt;&lt;img src="img/qf1.png" alt="QuantFigure" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Technical Analysis Studies&lt;/strong&gt; can be added on demand.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;qf.add_sma([&lt;span class="pl-c1"&gt;10&lt;/span&gt;,&lt;span class="pl-c1"&gt;20&lt;/span&gt;],&lt;span class="pl-v"&gt;width&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;,&lt;span class="pl-v"&gt;color&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;green&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;lightgreen&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;],&lt;span class="pl-v"&gt;legendgroup&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
qf.add_rsi(&lt;span class="pl-v"&gt;periods&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;20&lt;/span&gt;,&lt;span class="pl-v"&gt;color&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;java&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
qf.add_bollinger_bands(&lt;span class="pl-v"&gt;periods&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;20&lt;/span&gt;,&lt;span class="pl-v"&gt;boll_std&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;,&lt;span class="pl-v"&gt;colors&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;magenta&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;grey&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;],&lt;span class="pl-v"&gt;fill&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
qf.add_volume()
qf.add_macd()
qf.iplot()&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/qf2.png"&gt;&lt;img src="img/qf2.png" alt="Technical Analysis" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-v0100" class="anchor" aria-hidden="true" href="#v0100"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.10.0&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rangeslider&lt;/code&gt; to display a date range slider at the bottom
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.ohlc().iplot(kind='candle',rangeslider=True)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rangeselector&lt;/code&gt; to display buttons to change the date range displayed
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.ohlc(500).iplot(kind='candle', rangeselector={ 'steps':['1y','2 months','5 weeks','ytd','2mtd','reset'],     'bgcolor' : ('grey',.3), 'x': 0.3 , 'y' : 0.95})&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Customise annotions, with &lt;code&gt;fontsize&lt;/code&gt;,&lt;code&gt;fontcolor&lt;/code&gt;,&lt;code&gt;textangle&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Label mode
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.lines(1,mode='stocks').iplot(kind='line', annotations={'2015-02-02':'Market Crash', '2015-03-01':'Recovery'}, textangle=-70,fontsize=13,fontcolor='grey')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Explicit mode
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.lines(1,mode='stocks').iplot(kind='line', annotations=[{'text':'exactly here','x':'0.2', 'xref':'paper','arrowhead':2, 'textangle':-10,'ay':150,'arrowcolor':'red'}])&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-v090" class="anchor" aria-hidden="true" href="#v090"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.9.0&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Figure.iplot()&lt;/code&gt; to plot figures&lt;/li&gt;
&lt;li&gt;New high performing &lt;strong&gt;candle&lt;/strong&gt; and &lt;strong&gt;ohlc&lt;/strong&gt; plots
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.ohlc().iplot(kind='candle')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-v080" class="anchor" aria-hidden="true" href="#v080"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.8.0&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;'cf.datagen.choropleth()' to for sample choropleth data.&lt;/li&gt;
&lt;li&gt;'cf.datagen.scattergeo()' to for sample scattergeo data.&lt;/li&gt;
&lt;li&gt;Support for choropleth and scattergeo figures in &lt;code&gt;iplot&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;'cf.get_colorscale' for maps and plotly objects that support colorscales&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-v071" class="anchor" aria-hidden="true" href="#v071"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.7.1&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;xrange&lt;/code&gt;, &lt;code&gt;yrange&lt;/code&gt; and &lt;code&gt;zrange&lt;/code&gt; can be specified in &lt;code&gt;iplot&lt;/code&gt; and &lt;code&gt;getLayout&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.lines(1).iplot(yrange=[5,15])&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;layout_update&lt;/code&gt; can be set in &lt;code&gt;iplot&lt;/code&gt; and &lt;code&gt;getLayout&lt;/code&gt; to explicitly update any &lt;code&gt;Layout&lt;/code&gt; value&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-v07" class="anchor" aria-hidden="true" href="#v07"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.7&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Support for Python 3&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-v06" class="anchor" aria-hidden="true" href="#v06"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.6&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://nbviewer.ipython.org/gist/santosjorge/72665839a6f05a0567e0?flush_cache=true" rel="nofollow"&gt;See the IPython Notebook&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Support for &lt;strong&gt;pie&lt;/strong&gt; charts
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.pie().iplot(kind='pie',labels='labels',values='values')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Generate Open, High, Low, Close data
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;datagen.ohlc()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Candle Charts support
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ohlc=cf.datagen.ohlc()&lt;/code&gt;&lt;br&gt;
&lt;code&gt;ohlc.iplot(kind='candle',up_color='blue',down_color='red')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;OHLC (Bar) Charts support
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ohlc=cf.datagen.ohlc()&lt;/code&gt;&lt;br&gt;
&lt;code&gt;ohlc.iplot(kind='ohlc',up_color='blue',down_color='red')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for logarithmic charts ( logx | logy )
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;df=pd.DataFrame([x**2] for x in range(100))&lt;/code&gt;&lt;br&gt;
&lt;code&gt;df.iplot(kind='lines',logy=True)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for MulitIndex DataFrames&lt;/li&gt;
&lt;li&gt;Support for Error Bars ( error_x | error_y )
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.lines(1,5).iplot(kind='bar',error_y=[1,2,3.5,2,2])&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.lines(1,5).iplot(kind='bar',error_y=20, error_type='percent')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for continuous error bars
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.lines(1).iplot(kind='lines',error_y=20,error_type='continuous_percent')&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.lines(1).iplot(kind='lines',error_y=10,error_type='continuous',color='blue')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Technical Analysis Studies for Timeseries&lt;/strong&gt; &lt;em&gt;(beta)&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;Simple Moving Averages (SMA)
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.lines(1,500).ta_plot(study='sma',periods=[13,21,55])&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Relative Strength Indicator (RSI)
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.lines(1,200).ta_plot(study='boll',periods=14)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bollinger Bands (BOLL)
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.lines(1,200).ta_plot(study='rsi',periods=14)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Moving Average Convergence Divergence (MACD)
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.datagen.lines(1,200).ta_plot(study='macd',fast_period=12,slow_period=26, signal_period=9)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-v05" class="anchor" aria-hidden="true" href="#v05"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.5&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Support of offline charts
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cf.go_offline()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cf.go_online()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cf.iplot(figure,online=True)&lt;/code&gt; (To force online whilst on offline mode)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for secondary axis
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;fig=cf.datagen.lines(3,columns=['a','b','c']).figure()&lt;/code&gt;&lt;br&gt;
&lt;code&gt;fig=fig.set_axis('b',side='right')&lt;/code&gt;&lt;br&gt;
&lt;code&gt;cf.iplot(fig)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-v04" class="anchor" aria-hidden="true" href="#v04"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.4&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Support for global theme setting
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.set_config_file(theme='pearl')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;New theme &lt;em&gt;ggplot&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.lines(5).iplot(theme='ggplot')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for horizontal bar charts &lt;em&gt;barh&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.lines(2).iplot(kind='barh',barmode='stack',bargap=.1)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for histogram orientation and normalization
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.histogram().iplot(kind='histogram',orientation='h',norm='probability')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for &lt;em&gt;area&lt;/em&gt; plots
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.lines(4).iplot(kind='area',fill=True,opacity=1)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for &lt;em&gt;subplots&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.histogram(4).iplot(kind='histogram',subplots=True,bins=50)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.lines(4).iplot(subplots=True,shape=(4,1),shared_xaxes=True,vertical_spacing=.02,fill=True)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for &lt;em&gt;scatter matrix&lt;/em&gt; to display the distribution amongst every series in the DataFrame
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.lines(4,1000).scatter_matrix()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for &lt;em&gt;vline&lt;/em&gt; and &lt;em&gt;hline&lt;/em&gt; for horizontal and vertical lines
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.lines(3).iplot(hline=[2,3])&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.lines(3).iplot(hline=dict(y=2,color='blue',width=3))&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for &lt;em&gt;vspan&lt;/em&gt; and &lt;em&gt;hspan&lt;/em&gt; for horizontal and vertical areas
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.lines(3).iplot(hspan=(-1,2))&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.lines(3).iplot(hspan=dict(y0=-1,y1=2,color='orange',fill=True,opacity=.4))&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-v032" class="anchor" aria-hidden="true" href="#v032"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.3.2&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Global setting for public charts
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.set_config_file(world_readable=True)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-v03" class="anchor" aria-hidden="true" href="#v03"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v0.3&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Enhanced Spread charts
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.lines(2).iplot(kind='spread')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for Heatmap charts
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.heatmap().iplot(kind='heatmap')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for Bubble charts
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.bubble(4).iplot(kind='bubble',x='x',y='y',text='text',size='size',categories='categories')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for Bubble3d charts
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.bubble3d(4).iplot(kind='bubble3d',x='x',y='y',z='z',text='text',size='size',categories='categories')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for Box charts
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.box().iplot(kind='box')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for Surface charts
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.surface().iplot(kind='surface')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for Scatter3d charts
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.scatter3d().iplot(kind='scatter3d',x='x',y='y',z='z',text='text',categories='categories')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for Histograms
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen.histogram(2).iplot(kind='histogram')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data generation for most common plot types
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.datagen&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data extraction: Extract data from any Plotly chart. Data is delivered in DataFrame
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cufflinks.to_df(Figure)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Integration with &lt;a href="https://github.com/jackparmer/colorlover/"&gt;colorlover&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Support for scales &lt;code&gt;iplot(colorscale='accent')&lt;/code&gt; to plot a chart using an &lt;em&gt;accent&lt;/em&gt; color scale&lt;/li&gt;
&lt;li&gt;cufflinks.scales() to see all available scales&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for named colors
* &lt;code&gt;iplot(colors=['pink','red','yellow'])&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>santosjorge</author><guid isPermaLink="false">https://github.com/santosjorge/cufflinks</guid><pubDate>Sat, 30 Nov 2019 00:21:00 GMT</pubDate></item><item><title>slundberg/shap #22 in Jupyter Notebook, Today</title><link>https://github.com/slundberg/shap</link><description>&lt;p&gt;&lt;i&gt;A unified approach to explain the output of any machine learning model.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/shap_diagram.png"&gt;&lt;img src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/shap_diagram.png" width="400" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/slundberg/shap" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/19de279a6f67f8eea3f52ccecc779c3e1aff55e7/68747470733a2f2f7472617669732d63692e6f72672f736c756e64626572672f736861702e7376673f6272616e63683d6d6173746572" data-canonical-src="https://travis-ci.org/slundberg/shap.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://mybinder.org/v2/gh/slundberg/shap/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/483bae47a175c24dfbfc57390edd8b6982ac5fb3/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667" alt="Binder" data-canonical-src="https://mybinder.org/badge_logo.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SHAP (SHapley Additive exPlanations)&lt;/strong&gt; is a unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods [1-7] and representing the only possible consistent and locally accurate additive feature attribution method based on expectations (see our &lt;a href="#citations"&gt;papers&lt;/a&gt; for details and citations).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-install" class="anchor" aria-hidden="true" href="#install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install&lt;/h2&gt;
&lt;p&gt;SHAP can be installed from either &lt;a href="https://pypi.org/project/shap" rel="nofollow"&gt;PyPI&lt;/a&gt; or &lt;a href="https://anaconda.org/conda-forge/shap" rel="nofollow"&gt;conda-forge&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;pip install shap
&lt;i&gt;or&lt;/i&gt;
conda install -c conda-forge shap
&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-tree-ensemble-example-with-treeexplainer-xgboostlightgbmcatboostscikit-learnpyspark-models" class="anchor" aria-hidden="true" href="#tree-ensemble-example-with-treeexplainer-xgboostlightgbmcatboostscikit-learnpyspark-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tree ensemble example with TreeExplainer (XGBoost/LightGBM/CatBoost/scikit-learn/pyspark models)&lt;/h2&gt;
&lt;p&gt;While SHAP values can explain the output of any machine learning model, we have developed a high-speed exact algorithm for tree ensemble methods (&lt;a href="https://arxiv.org/abs/1802.03888" rel="nofollow"&gt;Tree SHAP arXiv paper&lt;/a&gt;). Fast C++ implementations are supported for &lt;em&gt;XGBoost&lt;/em&gt;, &lt;em&gt;LightGBM&lt;/em&gt;, &lt;em&gt;CatBoost&lt;/em&gt;, &lt;em&gt;scikit-learn&lt;/em&gt; and &lt;em&gt;pyspark&lt;/em&gt; tree models:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; xgboost
&lt;span class="pl-k"&gt;import&lt;/span&gt; shap

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; load JS visualization code to notebook&lt;/span&gt;
shap.initjs()

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; train XGBoost model&lt;/span&gt;
X,y &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.datasets.boston()
model &lt;span class="pl-k"&gt;=&lt;/span&gt; xgboost.train({&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;learning_rate&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;0.01&lt;/span&gt;}, xgboost.DMatrix(X, &lt;span class="pl-v"&gt;label&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;y), &lt;span class="pl-c1"&gt;100&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; explain the model's predictions using SHAP values&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)&lt;/span&gt;
explainer &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.TreeExplainer(model)
shap_values &lt;span class="pl-k"&gt;=&lt;/span&gt; explainer.shap_values(X)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)&lt;/span&gt;
shap.force_plot(explainer.expected_value, shap_values[&lt;span class="pl-c1"&gt;0&lt;/span&gt;,:], X.iloc[&lt;span class="pl-c1"&gt;0&lt;/span&gt;,:])&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_instance.png"&gt;&lt;img width="811" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_instance.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;The above explanation shows features each contributing to push the model output from the base value (the average model output over the training dataset we passed) to the model output. Features pushing the prediction higher are shown in red, those pushing the prediction lower are in blue (these force plots are introduced in our &lt;a href="https://www.nature.com/articles/s41551-018-0304-0" rel="nofollow"&gt;Nature BME paper&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;If we take many explanations such as the one shown above, rotate them 90 degrees, and then stack them horizontally, we can see explanations for an entire dataset (in the notebook this plot is interactive):&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; visualize the training set predictions&lt;/span&gt;
shap.force_plot(explainer.expected_value, shap_values, X)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_dataset.png"&gt;&lt;img width="811" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_dataset.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;To understand how a single feature effects the output of the model we can plot the SHAP value of that feature vs. the value of the feature for all the examples in a dataset. Since SHAP values represent a feature's responsibility for a change in the model output, the plot below represents the change in predicted house price as RM (the average number of rooms per house in an area) changes. Vertical dispersion at a single value of RM represents interaction effects with other features. To help reveal these interactions &lt;code&gt;dependence_plot&lt;/code&gt; automatically selects another feature for coloring. In this case coloring by RAD (index of accessibility to radial highways) highlights that the average number of rooms per house has less impact on home price for areas with a high RAD value.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; create a SHAP dependence plot to show the effect of a single feature across the whole dataset&lt;/span&gt;
shap.dependence_plot(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;RM&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, shap_values, X)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_dependence_plot.png"&gt;&lt;img width="544" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_dependence_plot.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;To get an overview of which features are most important for a model we can plot the SHAP values of every feature for every sample. The plot below sorts features by the sum of SHAP value magnitudes over all samples, and uses SHAP values to show the distribution of the impacts each feature has on the model output. The color represents the feature value (red high, blue low). This reveals for example that a high LSTAT (% lower status of the population) lowers the predicted home price.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; summarize the effects of all the features&lt;/span&gt;
shap.summary_plot(shap_values, X)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_summary_plot.png"&gt;&lt;img width="483" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_summary_plot.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;We can also just take the mean absolute value of the SHAP values for each feature to get a standard bar plot (produces stacked bars for multi-class outputs):&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;shap.summary_plot(shap_values, X, &lt;span class="pl-v"&gt;plot_type&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;bar&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_summary_plot_bar.png"&gt;&lt;img width="470" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_summary_plot_bar.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-deep-learning-example-with-deepexplainer-tensorflowkeras-models" class="anchor" aria-hidden="true" href="#deep-learning-example-with-deepexplainer-tensorflowkeras-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep learning example with DeepExplainer (TensorFlow/Keras models)&lt;/h2&gt;
&lt;p&gt;Deep SHAP is a high-speed approximation algorithm for SHAP values in deep learning models that builds on a connection with &lt;a href="https://arxiv.org/abs/1704.02685" rel="nofollow"&gt;DeepLIFT&lt;/a&gt; described in the SHAP NIPS paper. The implementation here differs from the original DeepLIFT by using a distribution of background samples instead of a single reference value, and using Shapley equations to linearize components such as max, softmax, products, divisions, etc. Note that some of these enhancements have also been since integrated into DeepLIFT. TensorFlow models and Keras models using the TensorFlow backend are supported (there is also preliminary support for PyTorch):&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; ...include code from https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py&lt;/span&gt;

&lt;span class="pl-k"&gt;import&lt;/span&gt; shap
&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; select a set of background examples to take an expectation over&lt;/span&gt;
background &lt;span class="pl-k"&gt;=&lt;/span&gt; x_train[np.random.choice(x_train.shape[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], &lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;replace&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;False&lt;/span&gt;)]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; explain predictions of the model on four images&lt;/span&gt;
e &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.DeepExplainer(model, background)
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; ...or pass tensors directly&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)&lt;/span&gt;
shap_values &lt;span class="pl-k"&gt;=&lt;/span&gt; e.shap_values(x_test[&lt;span class="pl-c1"&gt;1&lt;/span&gt;:&lt;span class="pl-c1"&gt;5&lt;/span&gt;])

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; plot the feature attributions&lt;/span&gt;
shap.image_plot(shap_values, &lt;span class="pl-k"&gt;-&lt;/span&gt;x_test[&lt;span class="pl-c1"&gt;1&lt;/span&gt;:&lt;span class="pl-c1"&gt;5&lt;/span&gt;])&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/mnist_image_plot.png"&gt;&lt;img width="820" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/mnist_image_plot.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;The plot above explains ten outputs (digits 0-9) for four different images. Red pixels increase the model's output while blue pixels decrease the output. The input images are shown on the left, and as nearly transparent grayscale backings behind each of the explanations. The sum of the SHAP values equals the difference between the expected model output (averaged over the background dataset) and the current model output. Note that for the 'zero' image the blank middle is important, while for the 'four' image the lack of a connection on top makes it a four instead of a nine.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-deep-learning-example-with-gradientexplainer-tensorflowkeraspytorch-models" class="anchor" aria-hidden="true" href="#deep-learning-example-with-gradientexplainer-tensorflowkeraspytorch-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep learning example with GradientExplainer (TensorFlow/Keras/PyTorch models)&lt;/h2&gt;
&lt;p&gt;Expected gradients combines ideas from &lt;a href="https://arxiv.org/abs/1703.01365" rel="nofollow"&gt;Integrated Gradients&lt;/a&gt;, SHAP, and &lt;a href="https://arxiv.org/abs/1706.03825" rel="nofollow"&gt;SmoothGrad&lt;/a&gt; into a single expected value equation. This allows an entire dataset to be used as the background distribution (as opposed to a single reference value) and allows local smoothing. If we approximate the model with a linear function between each background data sample and the current input to be explained, and we assume the input features are independent then expected gradients will compute approximate SHAP values. In the example below we have explained how the 7th intermediate layer of the VGG16 ImageNet model impacts the output probabilities.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; keras.applications.vgg16 &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-c1"&gt;VGG16&lt;/span&gt;
&lt;span class="pl-k"&gt;from&lt;/span&gt; keras.applications.vgg16 &lt;span class="pl-k"&gt;import&lt;/span&gt; preprocess_input
&lt;span class="pl-k"&gt;import&lt;/span&gt; keras.backend &lt;span class="pl-k"&gt;as&lt;/span&gt; K
&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np
&lt;span class="pl-k"&gt;import&lt;/span&gt; json
&lt;span class="pl-k"&gt;import&lt;/span&gt; shap

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; load pre-trained model and choose two images to explain&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; VGG16(&lt;span class="pl-v"&gt;weights&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;imagenet&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;include_top&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
X,y &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.datasets.imagenet50()
to_explain &lt;span class="pl-k"&gt;=&lt;/span&gt; X[[&lt;span class="pl-c1"&gt;39&lt;/span&gt;,&lt;span class="pl-c1"&gt;41&lt;/span&gt;]]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; load the ImageNet class names&lt;/span&gt;
url &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
fname &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.datasets.cache(url)
&lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-c1"&gt;open&lt;/span&gt;(fname) &lt;span class="pl-k"&gt;as&lt;/span&gt; f:
    class_names &lt;span class="pl-k"&gt;=&lt;/span&gt; json.load(f)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; explain how the input to the 7th layer of the model explains the top two classes&lt;/span&gt;
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;map2layer&lt;/span&gt;(&lt;span class="pl-smi"&gt;x&lt;/span&gt;, &lt;span class="pl-smi"&gt;layer&lt;/span&gt;):
    feed_dict &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;dict&lt;/span&gt;(&lt;span class="pl-c1"&gt;zip&lt;/span&gt;([model.layers[&lt;span class="pl-c1"&gt;0&lt;/span&gt;].input], [preprocess_input(x.copy())]))
    &lt;span class="pl-k"&gt;return&lt;/span&gt; K.get_session().run(model.layers[layer].input, feed_dict)
e &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.GradientExplainer(
    (model.layers[&lt;span class="pl-c1"&gt;7&lt;/span&gt;].input, model.layers[&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;].output),
    map2layer(X, &lt;span class="pl-c1"&gt;7&lt;/span&gt;),
    &lt;span class="pl-v"&gt;local_smoothing&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0&lt;/span&gt; &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; std dev of smoothing noise&lt;/span&gt;
)
shap_values,indexes &lt;span class="pl-k"&gt;=&lt;/span&gt; e.shap_values(map2layer(to_explain, &lt;span class="pl-c1"&gt;7&lt;/span&gt;), &lt;span class="pl-v"&gt;ranked_outputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; get the names for the classes&lt;/span&gt;
index_names &lt;span class="pl-k"&gt;=&lt;/span&gt; np.vectorize(&lt;span class="pl-k"&gt;lambda&lt;/span&gt; &lt;span class="pl-smi"&gt;x&lt;/span&gt;: class_names[&lt;span class="pl-c1"&gt;str&lt;/span&gt;(x)][&lt;span class="pl-c1"&gt;1&lt;/span&gt;])(indexes)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; plot the explanations&lt;/span&gt;
shap.image_plot(shap_values, to_explain, index_names)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/gradient_imagenet_plot.png"&gt;&lt;img width="500" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/gradient_imagenet_plot.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Predictions for two input images are explained in the plot above. Red pixels represent positive SHAP values that increase the probability of the class, while blue pixels represent negative SHAP values the reduce the probability of the class. By using &lt;code&gt;ranked_outputs=2&lt;/code&gt; we explain only the two most likely classes for each input (this spares us from explaining all 1,000 classes).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-model-agnostic-example-with-kernelexplainer-explains-any-function" class="anchor" aria-hidden="true" href="#model-agnostic-example-with-kernelexplainer-explains-any-function"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model agnostic example with KernelExplainer (explains any function)&lt;/h2&gt;
&lt;p&gt;Kernel SHAP uses a specially-weighted local linear regression to estimate SHAP values for any model. Below is a simple example for explaining a multi-class SVM on the classic iris dataset.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; sklearn
&lt;span class="pl-k"&gt;import&lt;/span&gt; shap
&lt;span class="pl-k"&gt;from&lt;/span&gt; sklearn.model_selection &lt;span class="pl-k"&gt;import&lt;/span&gt; train_test_split

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; print the JS visualization code to the notebook&lt;/span&gt;
shap.initjs()

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; train a SVM classifier&lt;/span&gt;
X_train,X_test,Y_train,Y_test &lt;span class="pl-k"&gt;=&lt;/span&gt; train_test_split(&lt;span class="pl-k"&gt;*&lt;/span&gt;shap.datasets.iris(), &lt;span class="pl-v"&gt;test_size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0.2&lt;/span&gt;, &lt;span class="pl-v"&gt;random_state&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
svm &lt;span class="pl-k"&gt;=&lt;/span&gt; sklearn.svm.SVC(&lt;span class="pl-v"&gt;kernel&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;rbf&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;probability&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
svm.fit(X_train, Y_train)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; use Kernel SHAP to explain test set predictions&lt;/span&gt;
explainer &lt;span class="pl-k"&gt;=&lt;/span&gt; shap.KernelExplainer(svm.predict_proba, X_train, &lt;span class="pl-v"&gt;link&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;logit&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
shap_values &lt;span class="pl-k"&gt;=&lt;/span&gt; explainer.shap_values(X_test, &lt;span class="pl-v"&gt;nsamples&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;100&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; plot the SHAP values for the Setosa output of the first instance&lt;/span&gt;
shap.force_plot(explainer.expected_value[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], shap_values[&lt;span class="pl-c1"&gt;0&lt;/span&gt;][&lt;span class="pl-c1"&gt;0&lt;/span&gt;,:], X_test.iloc[&lt;span class="pl-c1"&gt;0&lt;/span&gt;,:], &lt;span class="pl-v"&gt;link&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;logit&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/iris_instance.png"&gt;&lt;img width="810" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/iris_instance.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;The above explanation shows four features each contributing to push the model output from the base value (the average model output over the training dataset we passed) towards zero. If there were any features pushing the class label higher they would be shown in red.&lt;/p&gt;
&lt;p&gt;If we take many explanations such as the one shown above, rotate them 90 degrees, and then stack them horizontally, we can see explanations for an entire dataset. This is exactly what we do below for all the examples in the iris test set:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; plot the SHAP values for the Setosa output of all instances&lt;/span&gt;
shap.force_plot(explainer.expected_value[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], shap_values[&lt;span class="pl-c1"&gt;0&lt;/span&gt;], X_test, &lt;span class="pl-v"&gt;link&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;logit&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/iris_dataset.png"&gt;&lt;img width="813" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/iris_dataset.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-shap-interaction-values" class="anchor" aria-hidden="true" href="#shap-interaction-values"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SHAP Interaction Values&lt;/h2&gt;
&lt;p&gt;SHAP interaction values are a generalization of SHAP values to higher order interactions. Fast exact computation of pairwise interactions are implemented for tree models with &lt;code&gt;shap.TreeExplainer(model).shap_interaction_values(X)&lt;/code&gt;. This returns a matrix for every prediction, where the main effects are on the diagonal and the interaction effects are off-diagonal. These values often reveal interesting hidden relationships, such as how the increased risk of death peaks for men at age 60 (see the NHANES notebook for details):&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/nhanes_age_sex_interaction.png"&gt;&lt;img width="483" src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/nhanes_age_sex_interaction.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sample-notebooks" class="anchor" aria-hidden="true" href="#sample-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sample notebooks&lt;/h2&gt;
&lt;p&gt;The notebooks below demonstrate different use cases for SHAP. Look inside the notebooks directory of the repository if you want to try playing with the original notebooks yourself.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-treeexplainer" class="anchor" aria-hidden="true" href="#treeexplainer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TreeExplainer&lt;/h3&gt;
&lt;p&gt;An implementation of Tree SHAP, a fast and exact algorithm to compute SHAP values for trees and ensembles of trees.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/NHANES%20I%20Survival%20Model.html" rel="nofollow"&gt;&lt;strong&gt;NHANES survival model with XGBoost and SHAP interaction values&lt;/strong&gt;&lt;/a&gt; - Using mortality data from 20 years of followup this notebook demonstrates how to use XGBoost and &lt;code&gt;shap&lt;/code&gt; to uncover complex risk factor relationships.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/tree_explainer/Census%20income%20classification%20with%20LightGBM.html" rel="nofollow"&gt;&lt;strong&gt;Census income classification with LightGBM&lt;/strong&gt;&lt;/a&gt; - Using the standard adult census income dataset, this notebook trains a gradient boosting tree model with LightGBM and then explains predictions using &lt;code&gt;shap&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/League%20of%20Legends%20Win%20Prediction%20with%20XGBoost.html" rel="nofollow"&gt;&lt;strong&gt;League of Legends Win Prediction with XGBoost&lt;/strong&gt;&lt;/a&gt; - Using a Kaggle dataset of 180,000 ranked matches from League of Legends we train and explain a gradient boosting tree model with XGBoost to predict if a player will win their match.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-deepexplainer" class="anchor" aria-hidden="true" href="#deepexplainer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DeepExplainer&lt;/h3&gt;
&lt;p&gt;An implementation of Deep SHAP, a faster (but only approximate) algorithm to compute SHAP values for deep learning models that is based on connections between SHAP and the DeepLIFT algorithm.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/deep_explainer/Front%20Page%20DeepExplainer%20MNIST%20Example.html" rel="nofollow"&gt;&lt;strong&gt;MNIST Digit classification with Keras&lt;/strong&gt;&lt;/a&gt; - Using the MNIST handwriting recognition dataset, this notebook trains a neural network with Keras and then explains predictions using &lt;code&gt;shap&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/deep_explainer/Keras%20LSTM%20for%20IMDB%20Sentiment%20Classification.html" rel="nofollow"&gt;&lt;strong&gt;Keras LSTM for IMDB Sentiment Classification&lt;/strong&gt;&lt;/a&gt; - This notebook trains an LSTM with Keras on the IMDB text sentiment analysis dataset and then explains predictions using &lt;code&gt;shap&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-gradientexplainer" class="anchor" aria-hidden="true" href="#gradientexplainer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GradientExplainer&lt;/h3&gt;
&lt;p&gt;An implementation of expected gradients to approximate SHAP values for deep learning models. It is based on connections between SHAP and the Integrated Gradients algorithm. GradientExplainer is slower than DeepExplainer and makes different approximation assumptions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/gradient_explainer/Explain%20an%20Intermediate%20Layer%20of%20VGG16%20on%20ImageNet.html" rel="nofollow"&gt;&lt;strong&gt;Explain an Intermediate Layer of VGG16 on ImageNet&lt;/strong&gt;&lt;/a&gt; - This notebook demonstrates how to explain the output of a pre-trained VGG16 ImageNet model using an internal convolutional layer.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-linearexplainer" class="anchor" aria-hidden="true" href="#linearexplainer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LinearExplainer&lt;/h3&gt;
&lt;p&gt;For a linear model with independent features we can analytically compute the exact SHAP values. We can also account for feature correlation if we are willing to estimate the feature covaraince matrix. LinearExplainer supports both of these options.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/linear_explainer/Sentiment%20Analysis%20with%20Logistic%20Regression.html" rel="nofollow"&gt;&lt;strong&gt;Sentiment Analysis with Logistic Regression&lt;/strong&gt;&lt;/a&gt; - This notebook demonstrates how to explain a linear logistic regression sentiment analysis model.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-kernelexplainer" class="anchor" aria-hidden="true" href="#kernelexplainer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;KernelExplainer&lt;/h3&gt;
&lt;p&gt;An implementation of Kernel SHAP, a model agnostic method to estimate SHAP values for any model. Because it makes not assumptions about the model type, KernelExplainer is slower than the other model type specific algorithms.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/Census%20income%20classification%20with%20scikit-learn.html" rel="nofollow"&gt;&lt;strong&gt;Census income classification with scikit-learn&lt;/strong&gt;&lt;/a&gt; - Using the standard adult census income dataset, this notebook trains a k-nearest neighbors classifier using scikit-learn and then explains predictions using &lt;code&gt;shap&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/ImageNet%20VGG16%20Model%20with%20Keras.html" rel="nofollow"&gt;&lt;strong&gt;ImageNet VGG16 Model with Keras&lt;/strong&gt;&lt;/a&gt; - Explain the classic VGG16 convolutional nerual network's predictions for an image. This works by applying the model agnostic Kernel SHAP method to a super-pixel segmented image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/Iris%20classification%20with%20scikit-learn.html" rel="nofollow"&gt;&lt;strong&gt;Iris classification&lt;/strong&gt;&lt;/a&gt; - A basic demonstration using the popular iris species dataset. It explains predictions from six different models in scikit-learn using &lt;code&gt;shap&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-documentation-notebooks" class="anchor" aria-hidden="true" href="#documentation-notebooks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation notebooks&lt;/h2&gt;
&lt;p&gt;These notebooks comprehensively demonstrate how to use specific functions and objects.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/plots/decision_plot.html" rel="nofollow"&gt;&lt;code&gt;shap.decision_plot&lt;/code&gt; and &lt;code&gt;shap.multioutput_decision_plot&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://slundberg.github.io/shap/notebooks/plots/dependence_plot.html" rel="nofollow"&gt;&lt;code&gt;shap.dependence_plot&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-methods-unified-by-shap" class="anchor" aria-hidden="true" href="#methods-unified-by-shap"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Methods Unified by SHAP&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;LIME:&lt;/em&gt; Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. "Why should i trust you?: Explaining the predictions of any classifier." Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Shapley sampling values:&lt;/em&gt; Strumbelj, Erik, and Igor Kononenko. "Explaining prediction models and individual predictions with feature contributions." Knowledge and information systems 41.3 (2014): 647-665.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;DeepLIFT:&lt;/em&gt; Shrikumar, Avanti, Peyton Greenside, and Anshul Kundaje. "Learning important features through propagating activation differences." arXiv preprint arXiv:1704.02685 (2017).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;QII:&lt;/em&gt; Datta, Anupam, Shayak Sen, and Yair Zick. "Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems." Security and Privacy (SP), 2016 IEEE Symposium on. IEEE, 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Layer-wise relevance propagation:&lt;/em&gt; Bach, Sebastian, et al. "On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation." PloS one 10.7 (2015): e0130140.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Shapley regression values:&lt;/em&gt; Lipovetsky, Stan, and Michael Conklin. "Analysis of regression in game theory approach." Applied Stochastic Models in Business and Industry 17.4 (2001): 319-330.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Tree interpreter:&lt;/em&gt; Saabas, Ando. Interpreting random forests. &lt;a href="http://blog.datadive.net/interpreting-random-forests/" rel="nofollow"&gt;http://blog.datadive.net/interpreting-random-forests/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-citations" class="anchor" aria-hidden="true" href="#citations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citations&lt;/h2&gt;
&lt;p&gt;The algorithms and visualizations used in this package came primarily out of research in &lt;a href="https://suinlee.cs.washington.edu" rel="nofollow"&gt;Su-In Lee's lab&lt;/a&gt; at the University of Washington. If you use SHAP in your research we would appreciate a citation to the appropriate paper(s):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For general use of SHAP you can read/cite our &lt;a href="http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions" rel="nofollow"&gt;NeurIPS paper&lt;/a&gt; (&lt;a href="https://raw.githubusercontent.com/slundberg/shap/master/docs/references/shap_nips.bib" rel="nofollow"&gt;bibtex&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;For TreeExplainer you can (for now) read/cite our &lt;a href="https://arxiv.org/abs/1905.04610" rel="nofollow"&gt;arXiv paper&lt;/a&gt; (&lt;a href="https://raw.githubusercontent.com/slundberg/shap/master/docs/references/treeshap_arxiv.bib" rel="nofollow"&gt;bibtex&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;For &lt;code&gt;force_plot&lt;/code&gt; visualizations and medical applications you can read/cite our &lt;a href="https://www.nature.com/articles/s41551-018-0304-0" rel="nofollow"&gt;Nature Biomedical Engineering paper&lt;/a&gt; (&lt;a href="https://raw.githubusercontent.com/slundberg/shap/master/docs/references/nature_bme.bib" rel="nofollow"&gt;bibtex&lt;/a&gt;; &lt;a href="https://rdcu.be/baVbR" rel="nofollow"&gt;free access&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/db8c6ffa9af4cf6d17c411a9f7ad56cc1b508c35/68747470733a2f2f7777772e66616365626f6f6b2e636f6d2f74723f69643d3138393134373039313835353939312665763d5061676556696577266e6f7363726970743d31"&gt;&lt;img height="1" width="1" src="https://camo.githubusercontent.com/db8c6ffa9af4cf6d17c411a9f7ad56cc1b508c35/68747470733a2f2f7777772e66616365626f6f6b2e636f6d2f74723f69643d3138393134373039313835353939312665763d5061676556696577266e6f7363726970743d31" data-canonical-src="https://www.facebook.com/tr?id=189147091855991&amp;amp;ev=PageView&amp;amp;noscript=1" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>slundberg</author><guid isPermaLink="false">https://github.com/slundberg/shap</guid><pubDate>Sat, 30 Nov 2019 00:22:00 GMT</pubDate></item><item><title>Kulbear/deep-learning-coursera #23 in Jupyter Notebook, Today</title><link>https://github.com/Kulbear/deep-learning-coursera</link><description>&lt;p&gt;&lt;i&gt;Deep Learning Specialization by Andrew Ng on Coursera.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deep-learning-specialization-on-coursera" class="anchor" aria-hidden="true" href="#deep-learning-specialization-on-coursera"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning Specialization on Coursera&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Master Deep Learning, and Break into AI&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Instructor: &lt;a href="http://www.andrewng.org/" rel="nofollow"&gt;Andrew Ng&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This repo contains all my work for this specialization. All the code base, quiz questions, screenshot, and images, are taken from, unless specified, &lt;a href="https://www.coursera.org/specializations/deep-learning" rel="nofollow"&gt;Deep Learning Specialization on Coursera&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-what-i-want-to-say" class="anchor" aria-hidden="true" href="#what-i-want-to-say"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What I want to say&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;VERBOSE CONTENT WARNING: YOU CAN JUMP TO THE NEXT SECTION IF YOU WANT&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As a CS major student and a long-time self-taught learner, I have completed many CS related MOOCs on Coursera, Udacity, Udemy, and Edx. I do understand the hard time you spend on understanding new concepts and debugging your program. There are discussion forums on most MOOC platforms, however, even a question with detailed description may need some time to be answered. Here I released these solutions, which are &lt;strong&gt;only for your reference purpose&lt;/strong&gt;. It may help you to save some time. And I hope you don't copy any part of the code (the programming assignments are fairly easy if you read the instructions carefully), see the quiz solutions before you start your own adventure. This course is almost the simplest deep learning course I have ever taken, but the simplicity is based on the fabulous course content and structure. It's a treasure given by deeplearning.ai team.&lt;/p&gt;
&lt;p&gt;Currently, this repo has 3 major parts you may be interested in and I will give a list here.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-programming-assignments" class="anchor" aria-hidden="true" href="#programming-assignments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Programming Assignments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Course 1: Neural Networks and Deep Learning&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Logistic%20Regression%20with%20a%20Neural%20Network%20mindset.ipynb"&gt;Week 2 - PA 1 - Logistic Regression with a Neural Network mindset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Planar%20data%20classification%20with%20one%20hidden%20layer.ipynb"&gt;Week 3 - PA 2 - Planar data classification with one hidden layer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Building%20your%20Deep%20Neural%20Network%20-%20Step%20by%20Step.ipynb"&gt;Week 4 - PA 3 - Building your Deep Neural Network: Step by Step¶&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Deep%20Neural%20Network%20-%20Application.ipynb"&gt;Week 4 - PA 4 - Deep Neural Network for Image Classification: Application&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Initialization.ipynb"&gt;Week 1 - PA 1 - Initialization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Regularization.ipynb"&gt;Week 1 - PA 2 - Regularization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Gradient%20Checking.ipynb"&gt;Week 1 - PA 3 - Gradient Checking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Optimization%20methods.ipynb"&gt;Week 2 - PA 4 - Optimization Methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Tensorflow%20Tutorial.ipynb"&gt;Week 3 - PA 5 - TensorFlow Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Course 3: Structuring Machine Learning Projects&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is no PA for this course. But this course comes with very interesting case study quizzes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Course 4: Convolutional Neural Networks&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Convolutional%20Neural%20Networks/Convolution%20model%20-%20Step%20by%20Step%20-%20v1.ipynb"&gt;Week 1 - PA 1 - Convolutional Model: step by step&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Convolutional%20Neural%20Networks/Convolution%20model%20-%20Application%20-%20v1.ipynb"&gt;Week 1 - PA 2 - Convolutional Model: application&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Convolutional%20Neural%20Networks/Keras%20-%20Tutorial%20-%20Happy%20House%20v1.ipynb"&gt;Week 2 - PA 1 - Keras - Tutorial - Happy House&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Convolutional%20Neural%20Networks/Residual%20Networks%20-%20v1.ipynb"&gt;Week 2 - PA 2 - Residual Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Course 5: Sequence Models&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Sequence%20Models/Building%20a%20Recurrent%20Neural%20Network%20-%20Step%20by%20Step%20-%20v2.ipynb"&gt;Week 1 - PA 1 - Building a Recurrent Neural Network - Step by Step&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Sequence%20Models/Dinosaurus%20Island%20--%20Character%20level%20language%20model%20final%20-%20v3.ipynb"&gt;Week 1 - PA 2 - Character level language model - Dinosaurus land&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-quiz-solutions" class="anchor" aria-hidden="true" href="#quiz-solutions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quiz Solutions&lt;/h2&gt;
&lt;p&gt;There are concerns that some people may use the content here to quickly ace the course so I'll no longer update any quiz solution.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Course 1: Neural Networks and Deep Learning&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week%201%20Quiz%20-%20Introduction%20to%20deep%20learning.md"&gt;Week 1 Quiz - Introduction to deep learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week%202%20Quiz%20-%20Neural%20Network%20Basics.md"&gt;Week 2 Quiz - Neural Network Basics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week%203%20Quiz%20-%20%20Shallow%20Neural%20Networks.md"&gt;Week 3 Quiz - Shallow Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week%204%20Quiz%20-%20Key%20concepts%20on%20Deep%20Neural%20Networks.md"&gt;Week 4 Quiz - Key concepts on Deep Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week%201%20Quiz%20-%20Practical%20aspects%20of%20deep%20learning.md"&gt;Week 1 Quiz - Practical aspects of deep learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week%202%20Quiz%20-%20Optimization%20algorithms.md"&gt;Week 2 Quiz - Optimization algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week%203%20Quiz%20-%20Hyperparameter%20tuning%2C%20Batch%20Normalization%2C%20Programming%20Frameworks.md"&gt;Week 3 Quiz - Hyperparameter tuning, Batch Normalization, Programming Frameworks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Course 3: Structuring Machine Learning Projects&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Structuring%20Machine%20Learning%20Projects/Week%201%20Quiz%20-%20Bird%20recognition%20in%20the%20city%20of%20Peacetopia%20(case%20study).md"&gt;Week 1 Quiz - Bird recognition in the city of Peacetopia (case study)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Structuring%20Machine%20Learning%20Projects/Week%202%20Quiz%20-%20Autonomous%20driving%20(case%20study).md"&gt;Week 2 Quiz - Autonomous driving (case study)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;del&gt;- Course 4: Convolutional Neural Networks&lt;/del&gt;
&lt;del&gt;- Course 5: Sequence Models&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;&lt;del&gt;## Important Slide Notes&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;&lt;del&gt;I screenshotted some important slide page and store them into GitHub issues. It seems not very helpful for everyone since I only keep those I think may be useful to me.&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;&lt;del&gt;- &lt;a href="https://github.com/Kulbear/deep-learning-coursera/issues/1"&gt;Screenshots for Course 1: Neural Networks and Deep Learning&lt;/a&gt;&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;&lt;del&gt;- &lt;a href="https://github.com/Kulbear/deep-learning-coursera/issues/2"&gt;Screenshots for Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/a&gt;&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;&lt;del&gt;- &lt;a href="https://github.com/Kulbear/deep-learning-coursera/issues/3"&gt;Screenshots for Course 3: Structuring Machine Learning Projects&lt;/a&gt;&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;&lt;del&gt;- &lt;a href="https://github.com/Kulbear/deep-learning-coursera/issues/14"&gt;Screenshots for Course 4: Convolutional Neural Networks&lt;/a&gt;&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;&lt;del&gt;- Screenshots for Course 5: Sequence Models&lt;/del&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-milestones" class="anchor" aria-hidden="true" href="#milestones"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Milestones&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2017-08-17&lt;/strong&gt;: Finished the first-released 3 courses, YAY! &lt;g-emoji class="g-emoji" alias="smiling_imp" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f608.png"&gt;😈&lt;/g-emoji&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Kulbear</author><guid isPermaLink="false">https://github.com/Kulbear/deep-learning-coursera</guid><pubDate>Sat, 30 Nov 2019 00:23:00 GMT</pubDate></item><item><title>udacity/machine-learning #24 in Jupyter Notebook, Today</title><link>https://github.com/udacity/machine-learning</link><description>&lt;p&gt;&lt;i&gt;Content for Udacity's Machine Learning curriculum&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning" class="anchor" aria-hidden="true" href="#machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;machine-learning&lt;/h1&gt;
&lt;p&gt;Content for Udacity's Machine Learning curriculum, which includes projects and their descriptions.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://creativecommons.org/licenses/by-nc-nd/4.0/" rel="nofollow"&gt;&lt;img alt="Creative Commons License" src="https://camo.githubusercontent.com/777429797f9180579ed59a4f95d148a0c213dfa8/68747470733a2f2f692e6372656174697665636f6d6d6f6e732e6f72672f6c2f62792d6e632d6e642f342e302f38387833312e706e67" data-canonical-src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;br&gt;This work is licensed under a &lt;a href="http://creativecommons.org/licenses/by-nc-nd/4.0/" rel="nofollow"&gt;Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License&lt;/a&gt;. Please refer to &lt;a href="https://www.udacity.com/legal" rel="nofollow"&gt;Udacity Terms of Service&lt;/a&gt; for further information.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>udacity</author><guid isPermaLink="false">https://github.com/udacity/machine-learning</guid><pubDate>Sat, 30 Nov 2019 00:24:00 GMT</pubDate></item><item><title>aespresso/a_journey_into_math_of_ml #25 in Jupyter Notebook, Today</title><link>https://github.com/aespresso/a_journey_into_math_of_ml</link><description>&lt;p&gt;&lt;i&gt;汉语自然语言处理视频教程-开源学习资料&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-a_journey_into_math_of_ml" class="anchor" aria-hidden="true" href="#a_journey_into_math_of_ml"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;a_journey_into_math_of_ml&lt;/h1&gt;
&lt;h3&gt;&lt;a id="user-content-机器学习之数学之旅系列课程" class="anchor" aria-hidden="true" href="#机器学习之数学之旅系列课程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习之数学之旅系列课程:&lt;/h3&gt;
&lt;p&gt;作者邮箱: &lt;a href="mailto:espresso_ml@hotmail.com"&gt;espresso_ml@hotmail.com&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;视频讲解频道&lt;/strong&gt;:&lt;br&gt;
&lt;strong&gt;youtube&lt;/strong&gt;:&lt;br&gt;
&lt;a href="https://www.youtube.com/channel/UCZ4Rpk5ilk5w1uO3KRNaYBg" rel="nofollow"&gt;https://www.youtube.com/channel/UCZ4Rpk5ilk5w1uO3KRNaYBg&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Bilibili&lt;/strong&gt;:&lt;br&gt;
&lt;a href="https://space.bilibili.com/255296093" rel="nofollow"&gt;https://space.bilibili.com/255296093&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;知乎&lt;/strong&gt;专栏:
espresso数据萃取机&lt;br&gt;
&lt;a href="https://zhuanlan.zhihu.com/c_1018534554512035840" rel="nofollow"&gt;https://zhuanlan.zhihu.com/c_1018534554512035840&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-目前的课程请点击-指向对应repo目录和视频链接" class="anchor" aria-hidden="true" href="#目前的课程请点击-指向对应repo目录和视频链接"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目前的课程(请点击, 指向对应repo目录和视频链接):&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;书面教程: &lt;a href="https://github.com/aespresso/a_journey_into_math_of_ml/tree/master/00_maximum_likelihood_estimationa_and_3d_visualization"&gt;图解极大似然估计推导与3D可视化&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;视频讲解: &lt;a href="https://www.bilibili.com/video/av54346038/" rel="nofollow"&gt;B站讲解&lt;/a&gt; / &lt;a href="https://www.youtube.com/watch?v=C6a-SMY0H50" rel="nofollow"&gt;youtube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;书面教程: &lt;a href="https://github.com/aespresso/a_journey_into_math_of_ml/tree/master/01_logistic_regression"&gt;逻辑回归(一)-logit-odds-sigmoid函数-最大似然估计&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;视频讲解: &lt;a href="https://www.bilibili.com/video/av53400966/" rel="nofollow"&gt;B站讲解&lt;/a&gt; / &lt;a href="https://www.youtube.com/watch?v=i3zz7DQU3tc&amp;amp;t=535s" rel="nofollow"&gt;youtube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;书面教程: &lt;a href="https://github.com/aespresso/a_journey_into_math_of_ml/tree/master/01_logistic_regression"&gt;逻辑回归(二)-交叉熵与困惑度&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;视频讲解: &lt;a href="https://www.bilibili.com/video/av53704693/" rel="nofollow"&gt;B站讲解&lt;/a&gt; / &lt;a href="https://www.youtube.com/watch?v=bkC1Lna4lBY&amp;amp;t=16s" rel="nofollow"&gt;youtube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;书面教程: &lt;a href="https://github.com/aespresso/a_journey_into_math_of_ml/tree/master/01_logistic_regression"&gt;逻辑回归(三)-梯度下降-偏导数-求导最小化-分类边界可视化&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;视频讲解: &lt;a href="https://www.bilibili.com/video/av54780873/" rel="nofollow"&gt;B站讲解&lt;/a&gt; / &lt;a href="https://www.youtube.com/watch?v=up85PnWFBY8&amp;amp;t=9s" rel="nofollow"&gt;youtube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;书面教程: &lt;a href="https://github.com/aespresso/a_journey_into_math_of_ml/tree/master/02_adaboost"&gt;机器学习之数学之旅-从零推导adaboost与3D可视化-特征选择-集体智能-集成学习-boosting&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;视频讲解: &lt;a href="https://www.bilibili.com/video/av56033745/" rel="nofollow"&gt;B站讲解&lt;/a&gt; / &lt;a href="https://www.youtube.com/watch?v=-rqGPD06Ifs&amp;amp;t=5s" rel="nofollow"&gt;youtube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;书面教程: &lt;a href="https://github.com/aespresso/a_journey_into_math_of_ml/tree/master/03_transformer_tutorial_1st_part"&gt;汉语自然语言处理-从零解读碾压循环神经网络的transformer模型(一)&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;视频讲解: &lt;a href="https://www.bilibili.com/video/av58239477/" rel="nofollow"&gt;B站讲解&lt;/a&gt; / &lt;a href="https://www.youtube.com/watch?v=wLKsaZWeuCM" rel="nofollow"&gt;youtube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;书面教程: &lt;a href="https://github.com/aespresso/a_journey_into_math_of_ml/tree/master/04_transformer_tutorial_2nd_part"&gt;汉语自然语言处理-BERT的解读语言模型预训练与实践应用-transformer模型(二)&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;视频讲解: &lt;a href="https://www.bilibili.com/video/av60168891/" rel="nofollow"&gt;B站讲解&lt;/a&gt; / &lt;a href=""&gt;youtube&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;书面教程: &lt;a href="https://github.com/aespresso/a_journey_into_math_of_ml/tree/master/05_NER_hidden_markov_model"&gt;汉语自然语言处理-隐马尔可夫模型命名实体识别NER-HMM-从零解读-概率图模型-生成模型&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;视频讲解: &lt;a href="https://www.bilibili.com/video/av68032676/" rel="nofollow"&gt;B站讲解&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;书面教程: &lt;a href="https://github.com/aespresso/a_journey_into_math_of_ml/tree/master/05_NER_hidden_markov_model"&gt;汉语自然语言处理-维特比算法与NER&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;视频讲解: &lt;a href="https://www.bilibili.com/video/av68907334/" rel="nofollow"&gt;B站讲解&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>aespresso</author><guid isPermaLink="false">https://github.com/aespresso/a_journey_into_math_of_ml</guid><pubDate>Sat, 30 Nov 2019 00:25:00 GMT</pubDate></item></channel></rss>