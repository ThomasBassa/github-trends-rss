<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: C++, Today</title><link>https://github.com/trending/c++?since=daily</link><description>The top repositories on GitHub for c++, measured daily</description><pubDate>Sun, 05 Jan 2020 01:06:56 GMT</pubDate><lastBuildDate>Sun, 05 Jan 2020 01:06:56 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>oguzhaninan/Stacer #1 in C++, Today</title><link>https://github.com/oguzhaninan/Stacer</link><description>&lt;p&gt;&lt;i&gt;Linux System Optimizer and Monitoring - https://oguzhaninan.github.io/Stacer-Web&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/header.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/header.png" width="800" style="max-width:100%;"&gt;&lt;/a&gt;    
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;b&gt;Linux System Optimizer and Monitoring&lt;/b&gt;   &lt;br&gt;
  &lt;a href="https://www.patreon.com/oguzhaninan" rel="nofollow"&gt;
	&lt;img alt="Patreon" src="https://camo.githubusercontent.com/3d9b27bdf72d7e5407fbad6f9240f6cadc98a7a5/68747470733a2f2f63352e70617472656f6e2e636f6d2f65787465726e616c2f6c6f676f2f6265636f6d655f615f706174726f6e5f627574746f6e2e706e67" height="50" data-canonical-src="https://c5.patreon.com/external/logo/become_a_patron_button.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
	&lt;a href="https://sourceforge.net/projects/stacer/files/" rel="nofollow"&gt;
		&lt;img alt="Download Stacer" src="https://camo.githubusercontent.com/30c2e90a904039e14383773ffedb77a5629ef2fe/68747470733a2f2f696d672e736869656c64732e696f2f736f75726365666f7267652f64742f7374616365722e737667" data-canonical-src="https://img.shields.io/sourceforge/dt/stacer.svg" style="max-width:100%;"&gt;
	&lt;/a&gt;
	&lt;a href="http://www.kernel.org" rel="nofollow"&gt;
		&lt;img alt="Platform (GNU/Linux)" src="https://camo.githubusercontent.com/ac9372e1f206bf69154581fea80bd3340af5e4ae/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d474e552f4c696e75782d626c75652e737667" data-canonical-src="https://img.shields.io/badge/platform-GNU/Linux-blue.svg" style="max-width:100%;"&gt;
	&lt;/a&gt;
	&lt;a href="https://github.com/oguzhaninan/Stacer/releases"&gt;
		&lt;img alt="Github All Releases" src="https://camo.githubusercontent.com/30b14b52d84ad63c3bcd4bd9714eb80c3a4e1a69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f646f776e6c6f6164732f6f67757a68616e696e616e2f7374616365722f746f74616c2e737667" data-canonical-src="https://img.shields.io/github/downloads/oguzhaninan/stacer/total.svg" style="max-width:100%;"&gt;
	&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
	&lt;a href="https://sourceforge.net/projects/stacer/files/" rel="nofollow"&gt;
		&lt;img src="https://camo.githubusercontent.com/4cbcafd11cbbc6351d48cb968594ad457738c49c/68747470733a2f2f612e6673646e2e636f6d2f636f6e2f6170702f73662d646f776e6c6f61642d627574746f6e" data-canonical-src="https://a.fsdn.com/con/app/sf-download-button" style="max-width:100%;"&gt;
	&lt;/a&gt;
&lt;/p&gt;	
&lt;h2&gt;&lt;a id="user-content-reviews" class="anchor" aria-hidden="true" href="#reviews"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reviews&lt;/h2&gt;
&lt;p align="left"&gt;
    &lt;a href="http://www.omgubuntu.co.uk/2017/01/stacer-system-optimizer-for-ubuntu" rel="nofollow"&gt;
		&lt;img width="65px" src="https://camo.githubusercontent.com/15d5ba08be5697ef25cb73d3ff695440e5d8cc73/68747470733a2f2f6f67757a68616e696e616e2e6769746875622e696f2f5374616365722d5765622f696d616765732f73697465732f73697465302e706e67" data-canonical-src="https://oguzhaninan.github.io/Stacer-Web/images/sites/site0.png" style="max-width:100%;"&gt;
	&lt;/a&gt;        
    &lt;a href="http://www.diolinux.com.br/2017/02/stacer-um-programa-para-otimizar-o-ubuntu.html" rel="nofollow"&gt;
		&lt;img width="170px" src="https://camo.githubusercontent.com/3c6da63da825de0290cc3675890ece9f3a34e29d/687474703a2f2f636f6c657469766f2e73656d616e61646f6c696e75782e636f6d2e62722f696d616765732f736974652f64696f6c696e75782e706e67" data-canonical-src="http://coletivo.semanadolinux.com.br/images/site/diolinux.png" style="max-width:100%;"&gt;
	&lt;/a&gt;    
    &lt;a href="https://www.genbeta.com/linux/stacer-una-app-todo-en-uno-que-te-deja-monitorizar-y-optimizar-el-sistema-en-ubuntu" rel="nofollow"&gt;
		&lt;img width="155px" src="https://camo.githubusercontent.com/13adc91a1ed2eae46aa08d5f717123c8644b17bb/687474703a2f2f7365616e6665652e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031342f30342f4c6f676f5f67656e626574612e6a7067" data-canonical-src="http://seanfee.com/wp-content/uploads/2014/04/Logo_genbeta.jpg" style="max-width:100%;"&gt;
	&lt;/a&gt;
    &lt;a href="http://www.dobreprogramy.pl/Stacer-program-do-optymalizacji-Ubuntu-ktory-wyglada-jakby-uciekl-z-Windowsa,News,78941.html" rel="nofollow"&gt;
		&lt;img width="155px" src="https://camo.githubusercontent.com/967b3c4efa4c20e6e02a00204ee32741d9e68899/687474703a2f2f73746f726167652e646f62726570726f6772616d792e706c2f617274796b756c792f3975726f647a696e792f6c6f676f44502d6e617069732e706e67" data-canonical-src="http://storage.dobreprogramy.pl/artykuly/9urodziny/logoDP-napis.png" style="max-width:100%;"&gt;
	&lt;/a&gt;
    &lt;a href="http://blog.desdelinux.net/optimizar-debian-ubuntu-linux-mint-derivados-stacer/" rel="nofollow"&gt;
		&lt;img width="155px" src="https://camo.githubusercontent.com/f6370fbd2177c3d129ae4ffb2445f09f633b307e/687474703a2f2f692e696d6775722e636f6d2f6556315778595a2e706e67" data-canonical-src="http://i.imgur.com/eV1WxYZ.png" style="max-width:100%;"&gt;
	&lt;/a&gt;
	&lt;a href="http://www.techrepublic.com/article/how-to-install-stacer-for-quick-linux-system-optimization/" rel="nofollow"&gt;
		&lt;img width="150px" src="https://camo.githubusercontent.com/959c465cc828b8d8593db5679662e618e2702748/68747470733a2f2f737461746963312e73717561726573706163652e636f6d2f7374617469632f3535616664633131653462303030623232396139373834392f742f3535623133663164653462303434663535366130323532342f313433373637393430383931332f" data-canonical-src="https://static1.squarespace.com/static/55afdc11e4b000b229a97849/t/55b13f1de4b044f556a02524/1437679408913/" style="max-width:100%;"&gt;
	&lt;/a&gt;
	
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-required-packages" class="anchor" aria-hidden="true" href="#required-packages"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Required Packages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;curl, systemd&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-ppa-repository-for-ubuntu" class="anchor" aria-hidden="true" href="#ppa-repository-for-ubuntu"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PPA Repository (for ubuntu)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;sudo add-apt-repository ppa:oguzhaninan/stacer -y&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sudo apt-get update&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sudo apt-get install stacer -y&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-debian-x64" class="anchor" aria-hidden="true" href="#debian-x64"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Debian x64&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Download &lt;code&gt;stacer_1.1.0_amd64.deb&lt;/code&gt; from the &lt;a href="https://github.com/oguzhaninan/Stacer/releases"&gt;Stacer releases page&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;sudo dpkg -i stacer*.deb&lt;/code&gt; on the downloaded package.&lt;/li&gt;
&lt;li&gt;Launch Stacer using the installed &lt;code&gt;stacer&lt;/code&gt; command.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-fedora" class="anchor" aria-hidden="true" href="#fedora"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fedora&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Download &lt;code&gt;stacer_1.1.0_amd64.rpm&lt;/code&gt; from the &lt;a href="https://github.com/oguzhaninan/Stacer/releases"&gt;Stacer releases page&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;sudo rpm --install stacer*.rpm --nodeps --force&lt;/code&gt; on the downloaded package.&lt;/li&gt;
&lt;li&gt;Launch Stacer using the installed &lt;code&gt;stacer&lt;/code&gt; command.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-fedora-with-dnf" class="anchor" aria-hidden="true" href="#fedora-with-dnf"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fedora (with DNF)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Run: &lt;code&gt;sudo dnf install stacer&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Launch Stacer using the installed &lt;code&gt;stacer&lt;/code&gt; command.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-build-from-source-with-cmake-qt-version-qt-5x" class="anchor" aria-hidden="true" href="#build-from-source-with-cmake-qt-version-qt-5x"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Build from source with CMake (Qt Version Qt 5.x)&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;mkdir build &amp;amp;&amp;amp; cd build&lt;/li&gt;
&lt;li&gt;cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH=/qt/path/bin ..&lt;/li&gt;
&lt;li&gt;make -j $(nproc)&lt;/li&gt;
&lt;li&gt;output/bin/stacer&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-screenshots" class="anchor" aria-hidden="true" href="#screenshots"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Screenshots&lt;/h2&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-1.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-1.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-2.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-2.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-3.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-3.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-4.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-4.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-5.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-5.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-6.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-6.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-7.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-7.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-8.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-8.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-9.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-9.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-10.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-10.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-11.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-11.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-12.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-12.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-13.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-13.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-14.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-14.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-15.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-15.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-16.png"&gt;&lt;img src="https://raw.githubusercontent.com/oguzhaninan/Stacer/native/screenshots/Screenshot-1.0.9-16.png" width="700" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributors&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-code-contributors" class="anchor" aria-hidden="true" href="#code-contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code Contributors&lt;/h3&gt;
&lt;p&gt;This project exists thanks to all the people who contribute. [&lt;a href="CONTRIBUTING.md"&gt;Contribute&lt;/a&gt;].
&lt;a href="https://github.com/oguzhaninan/Stacer/graphs/contributors"&gt;&lt;img src="https://camo.githubusercontent.com/6f1c945491e1d9d34835e0a4f4ec41becf0c7894/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f5374616365722f636f6e7472696275746f72732e7376673f77696474683d38393026627574746f6e3d66616c7365" data-canonical-src="https://opencollective.com/Stacer/contributors.svg?width=890&amp;amp;button=false" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-financial-contributors" class="anchor" aria-hidden="true" href="#financial-contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Financial Contributors&lt;/h3&gt;
&lt;p&gt;Become a financial contributor and help us sustain our community. [&lt;a href="https://opencollective.com/Stacer/contribute" rel="nofollow"&gt;Contribute&lt;/a&gt;]&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-individuals" class="anchor" aria-hidden="true" href="#individuals"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Individuals&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://opencollective.com/Stacer" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6fc61930c081649bc0b4738d753f0d5b2e2c9192/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f5374616365722f696e646976696475616c732e7376673f77696474683d383930" data-canonical-src="https://opencollective.com/Stacer/individuals.svg?width=890" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-organizations" class="anchor" aria-hidden="true" href="#organizations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Organizations&lt;/h4&gt;
&lt;p&gt;Support this project with your organization. Your logo will show up here with a link to your website. [&lt;a href="https://opencollective.com/Stacer/contribute" rel="nofollow"&gt;Contribute&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;a href="https://opencollective.com/Stacer/organization/0/website" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0e705d1ed69b9145133204d01a265c3ebb256f96/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f5374616365722f6f7267616e697a6174696f6e2f302f6176617461722e737667" data-canonical-src="https://opencollective.com/Stacer/organization/0/avatar.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opencollective.com/Stacer/organization/1/website" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/203c5175ead14c1f6a02add4af84b574e95299cb/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f5374616365722f6f7267616e697a6174696f6e2f312f6176617461722e737667" data-canonical-src="https://opencollective.com/Stacer/organization/1/avatar.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opencollective.com/Stacer/organization/2/website" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1b0bfbdfcfe74c4e9a3e8819f9a8f0dd1323fa5b/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f5374616365722f6f7267616e697a6174696f6e2f322f6176617461722e737667" data-canonical-src="https://opencollective.com/Stacer/organization/2/avatar.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opencollective.com/Stacer/organization/3/website" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/77eaf8477b3d82b0307d499912fe5b65e7e91b0c/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f5374616365722f6f7267616e697a6174696f6e2f332f6176617461722e737667" data-canonical-src="https://opencollective.com/Stacer/organization/3/avatar.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opencollective.com/Stacer/organization/4/website" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/95e850c20ebbaef24e8203ee1ee25465463fb738/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f5374616365722f6f7267616e697a6174696f6e2f342f6176617461722e737667" data-canonical-src="https://opencollective.com/Stacer/organization/4/avatar.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opencollective.com/Stacer/organization/5/website" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a5cb55cdaf65d8e5fd67b8d8955057b8aaabf75b/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f5374616365722f6f7267616e697a6174696f6e2f352f6176617461722e737667" data-canonical-src="https://opencollective.com/Stacer/organization/5/avatar.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opencollective.com/Stacer/organization/6/website" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9562513dbd4e9f719f0e87047678d4ca02d5c0a0/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f5374616365722f6f7267616e697a6174696f6e2f362f6176617461722e737667" data-canonical-src="https://opencollective.com/Stacer/organization/6/avatar.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opencollective.com/Stacer/organization/7/website" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/cd4c78a7c167994544e1b0139570218df8c4e940/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f5374616365722f6f7267616e697a6174696f6e2f372f6176617461722e737667" data-canonical-src="https://opencollective.com/Stacer/organization/7/avatar.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opencollective.com/Stacer/organization/8/website" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/fec46f2a7605df677fa3ffd38979cb75f2573271/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f5374616365722f6f7267616e697a6174696f6e2f382f6176617461722e737667" data-canonical-src="https://opencollective.com/Stacer/organization/8/avatar.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opencollective.com/Stacer/organization/9/website" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/daec0f62b413df2d290c06d3fab51d22322a88c1/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f5374616365722f6f7267616e697a6174696f6e2f392f6176617461722e737667" data-canonical-src="https://opencollective.com/Stacer/organization/9/avatar.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>oguzhaninan</author><guid isPermaLink="false">https://github.com/oguzhaninan/Stacer</guid><pubDate>Sun, 05 Jan 2020 00:01:00 GMT</pubDate></item><item><title>uNetworking/uWebSockets.js #2 in C++, Today</title><link>https://github.com/uNetworking/uWebSockets.js</link><description>&lt;p&gt;&lt;i&gt;μWebSockets for TypeScript &amp; JavaScript backends&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="misc/logo.svg"&gt;&lt;img src="misc/logo.svg" height="180" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;p&gt;&lt;em&gt;µWebSockets.js™ (it's "&lt;a href="https://en.wikipedia.org/wiki/Micro-" rel="nofollow"&gt;micro&lt;/a&gt;") is simple, secure&lt;/em&gt;&lt;sup&gt;&lt;a href="https://github.com/uNetworking/uWebSockets/tree/master/fuzzing"&gt;[1]&lt;/a&gt;&lt;/sup&gt; &lt;em&gt;&amp;amp; standards compliant&lt;/em&gt;&lt;sup&gt;&lt;a href="https://unetworking.github.io/uWebSockets.js/report.pdf" rel="nofollow"&gt;[2]&lt;/a&gt;&lt;/sup&gt; &lt;em&gt;web I/O for the most demanding&lt;/em&gt;&lt;sup&gt;&lt;a href="https://github.com/uNetworking/uWebSockets/tree/master/benchmarks"&gt;[3]&lt;/a&gt;&lt;/sup&gt; &lt;em&gt;of applications.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;• &lt;a href="https://unetworking.github.io/uWebSockets.js/generated/" rel="nofollow"&gt;TypeScript docs&lt;/a&gt; • &lt;a href="https://github.com/uNetworking/uWebSockets/blob/master/misc/READMORE.md"&gt;Read more &amp;amp; user manual (C++ project)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2016-2019, &amp;gt;39,632,272 downloads&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-in-a-nutshell" class="anchor" aria-hidden="true" href="#in-a-nutshell"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;In a nutshell.&lt;/h4&gt;
&lt;p&gt;Think of it as a complete replacement to both Express.js and Socket.IO, written entirely in C/C++ for maximum performance and reliability. There are tons of &lt;a href="examples"&gt;examples&lt;/a&gt; but here's the gist of it all:&lt;/p&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;/*&lt;/span&gt; Non-SSL is simply App() &lt;span class="pl-c"&gt;*/&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c1"&gt;require&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;uWebSockets.js&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;).&lt;span class="pl-en"&gt;SSLApp&lt;/span&gt;({

  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;/*&lt;/span&gt; There are tons of SSL options &lt;span class="pl-c"&gt;*/&lt;/span&gt;&lt;/span&gt;
  key_file_name&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;misc/key.pem&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
  cert_file_name&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;misc/cert.pem&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
  
}).&lt;span class="pl-en"&gt;ws&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;/*&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, {

  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;/*&lt;/span&gt; For brevity we skip the other events &lt;span class="pl-c"&gt;*/&lt;/span&gt;&lt;/span&gt;
  &lt;span class="pl-en"&gt;message&lt;/span&gt;&lt;span class="pl-k"&gt;:&lt;/span&gt; (&lt;span class="pl-smi"&gt;ws&lt;/span&gt;, &lt;span class="pl-smi"&gt;message&lt;/span&gt;, &lt;span class="pl-smi"&gt;isBinary&lt;/span&gt;) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; {
    &lt;span class="pl-k"&gt;let&lt;/span&gt; ok &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-smi"&gt;ws&lt;/span&gt;.&lt;span class="pl-c1"&gt;send&lt;/span&gt;(message, isBinary);
  }
  
}).&lt;span class="pl-en"&gt;any&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;/*&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, (&lt;span class="pl-smi"&gt;res&lt;/span&gt;, &lt;span class="pl-smi"&gt;req&lt;/span&gt;) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; {

  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;/*&lt;/span&gt; Let's deny all Http &lt;span class="pl-c"&gt;*/&lt;/span&gt;&lt;/span&gt;
  &lt;span class="pl-smi"&gt;res&lt;/span&gt;.&lt;span class="pl-en"&gt;end&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Nothing to see here!&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);
  
}).&lt;span class="pl-en"&gt;listen&lt;/span&gt;(&lt;span class="pl-c1"&gt;9001&lt;/span&gt;, (&lt;span class="pl-smi"&gt;listenSocket&lt;/span&gt;) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; {

  &lt;span class="pl-k"&gt;if&lt;/span&gt; (listenSocket) {
    &lt;span class="pl-en"&gt;console&lt;/span&gt;.&lt;span class="pl-c1"&gt;log&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Listening to port 9001&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);
  }
  
});&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-ready-all-thrusters" class="anchor" aria-hidden="true" href="#ready-all-thrusters"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ready all thrusters.&lt;/h4&gt;
&lt;p&gt;Install with &lt;code&gt;npm install uNetworking/uWebSockets.js#v16.5.0&lt;/code&gt; or any such &lt;a href="https://github.com/uNetworking/uWebSockets.js/releases"&gt;release&lt;/a&gt;. No compiler needed.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="misc/features_strip.png"&gt;&lt;img src="misc/features_strip.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-pay-what-you-want" class="anchor" aria-hidden="true" href="#pay-what-you-want"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pay what you want.&lt;/h4&gt;
&lt;p&gt;Commercially developed on a sponsored/consulting basis; BitMEX, Bitfinex and Coinbase are current or previous sponsors. Contact &lt;a href="https://github.com/alexhultman"&gt;me, the author&lt;/a&gt; for support, feature development or consulting/contracting.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/uNetworking/uWebSockets/master/misc/2018.png"&gt;&lt;img src="https://raw.githubusercontent.com/uNetworking/uWebSockets/master/misc/2018.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-know-thy-legal-matters" class="anchor" aria-hidden="true" href="#know-thy-legal-matters"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Know thy legal matters.&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;µWebSockets.js is intellectual property licensed Apache 2.0 with limitations on trademark use. Forks must be clearly labelled as such and must not be confused with the original.&lt;/em&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>uNetworking</author><guid isPermaLink="false">https://github.com/uNetworking/uWebSockets.js</guid><pubDate>Sun, 05 Jan 2020 00:02:00 GMT</pubDate></item><item><title>facebookresearch/faiss #3 in C++, Today</title><link>https://github.com/facebookresearch/faiss</link><description>&lt;p&gt;&lt;i&gt;A library for efficient similarity search and clustering of dense vectors.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-faiss" class="anchor" aria-hidden="true" href="#faiss"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Faiss&lt;/h1&gt;
&lt;p&gt;Faiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. Faiss is written in C++ with complete wrappers for Python/numpy. Some of the most useful algorithms are implemented on the GPU. It is developed by &lt;a href="https://research.fb.com/category/facebook-ai-research-fair/" rel="nofollow"&gt;Facebook AI Research&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-news" class="anchor" aria-hidden="true" href="#news"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NEWS&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;NEW: version 1.6.0 (2019-10-15) code structure reorg, support for codec interface.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NEW: version 1.5.3 (2019-06-24) fix performance regression in IndexIVF.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NEW: version 1.5.2 (2019-05-27) the license was relaxed to MIT from BSD+Patents. Read LICENSE for details.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NEW: version 1.5.0 (2018-12-19) GPU binary flat index and binary HNSW index&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NEW: version 1.4.0 (2018-08-30) no more crashes in pure Python code&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NEW: version 1.3.0 (2018-07-12) support for binary indexes&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NEW: latest commit (2018-02-22) supports on-disk storage of inverted indexes, see demos/demo_ondisk_ivf.py&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NEW: latest commit (2018-01-09) includes an implementation of the HNSW indexing method, see benchs/bench_hnsw.py&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NEW: there is now a Facebook public discussion group for Faiss users at &lt;a href="https://www.facebook.com/groups/faissusers/" rel="nofollow"&gt;https://www.facebook.com/groups/faissusers/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NEW: on 2017-07-30, the license on Faiss was relaxed to BSD from CC-BY-NC. Read LICENSE for details.&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Faiss contains several methods for similarity search. It assumes that the instances are represented as vectors and are identified by an integer, and that the vectors can be compared with L2 (Euclidean) distances or dot products. Vectors that are similar to a query vector are those that have the lowest L2 distance or the highest dot product with the query vector. It also supports cosine similarity, since this is a dot product on normalized vectors.&lt;/p&gt;
&lt;p&gt;Most of the methods, like those based on binary vectors and compact quantization codes, solely use a compressed representation of the vectors and do not require to keep the original vectors. This generally comes at the cost of a less precise search but these methods can scale to billions of vectors in main memory on a single server.&lt;/p&gt;
&lt;p&gt;The GPU implementation can accept input from either CPU or GPU memory. On a server with GPUs, the GPU indexes can be used a drop-in replacement for the CPU indexes (e.g., replace &lt;code&gt;IndexFlatL2&lt;/code&gt; with &lt;code&gt;GpuIndexFlatL2&lt;/code&gt;) and copies to/from GPU memory are handled automatically. Results will be faster however if both input and output remain resident on the GPU. Both single and multi-GPU usage is supported.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-building" class="anchor" aria-hidden="true" href="#building"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building&lt;/h2&gt;
&lt;p&gt;The library is mostly implemented in C++, with optional GPU support provided via CUDA, and an optional Python interface. The CPU version requires a BLAS library. It compiles with a Makefile and can be packaged in a docker image. See &lt;a href="INSTALL.md"&gt;INSTALL.md&lt;/a&gt; for details.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-faiss-works" class="anchor" aria-hidden="true" href="#how-faiss-works"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How Faiss works&lt;/h2&gt;
&lt;p&gt;Faiss is built around an index type that stores a set of vectors, and provides a function to search in them with L2 and/or dot product vector comparison. Some index types are simple baselines, such as exact search. Most of the available indexing structures correspond to various trade-offs with respect to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;search time&lt;/li&gt;
&lt;li&gt;search quality&lt;/li&gt;
&lt;li&gt;memory used per index vector&lt;/li&gt;
&lt;li&gt;training time&lt;/li&gt;
&lt;li&gt;need for external data for unsupervised training&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The optional GPU implementation provides what is likely (as of March 2017) the fastest exact and approximate (compressed-domain) nearest neighbor search implementation for high-dimensional vectors, fastest Lloyd's k-means, and fastest small k-selection algorithm known. &lt;a href="https://arxiv.org/abs/1702.08734" rel="nofollow"&gt;The implementation is detailed here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-full-documentation-of-faiss" class="anchor" aria-hidden="true" href="#full-documentation-of-faiss"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Full documentation of Faiss&lt;/h2&gt;
&lt;p&gt;The following are entry points for documentation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the full documentation, including a &lt;a href="https://github.com/facebookresearch/faiss/wiki/Getting-started"&gt;tutorial&lt;/a&gt;, a &lt;a href="https://github.com/facebookresearch/faiss/wiki/FAQ"&gt;FAQ&lt;/a&gt; and a &lt;a href="https://github.com/facebookresearch/faiss/wiki/Troubleshooting"&gt;troubleshooting section&lt;/a&gt; can be found on the &lt;a href="http://github.com/facebookresearch/faiss/wiki"&gt;wiki page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;the &lt;a href="http://rawgithub.com/facebookresearch/faiss/master/docs/html/annotated.html" rel="nofollow"&gt;doxygen documentation&lt;/a&gt; gives per-class information&lt;/li&gt;
&lt;li&gt;to reproduce results from our research papers, &lt;a href="https://arxiv.org/abs/1609.01882" rel="nofollow"&gt;Polysemous codes&lt;/a&gt; and &lt;a href="https://arxiv.org/abs/1702.08734" rel="nofollow"&gt;Billion-scale similarity search with GPUs&lt;/a&gt;, refer to the &lt;a href="benchs/README.md"&gt;benchmarks README&lt;/a&gt;. For &lt;a href="https://arxiv.org/abs/1804.09996" rel="nofollow"&gt;
Link and code: Fast indexing with graphs and compact regression codes&lt;/a&gt;, see the &lt;a href="benchs/link_and_code"&gt;link_and_code README&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authors&lt;/h2&gt;
&lt;p&gt;The main authors of Faiss are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jegou"&gt;Hervé Jégou&lt;/a&gt; initiated the Faiss project and wrote its first implementation&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mdouze"&gt;Matthijs Douze&lt;/a&gt; implemented most of the CPU Faiss&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wickedfoo"&gt;Jeff Johnson&lt;/a&gt; implemented all of the GPU Faiss&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/beauby"&gt;Lucas Hosseini&lt;/a&gt; implemented the binary indexes&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-reference" class="anchor" aria-hidden="true" href="#reference"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reference&lt;/h2&gt;
&lt;p&gt;Reference to cite when you use Faiss in a research paper:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{JDH17,
  title={Billion-scale similarity search with GPUs},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:1702.08734},
  year={2017}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-join-the-faiss-community" class="anchor" aria-hidden="true" href="#join-the-faiss-community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Join the Faiss community&lt;/h2&gt;
&lt;p&gt;For public discussion of Faiss or for questions, there is a Facebook public discussion group at &lt;a href="https://www.facebook.com/groups/faissusers/" rel="nofollow"&gt;https://www.facebook.com/groups/faissusers/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We monitor the &lt;a href="http://github.com/facebookresearch/faiss/issues"&gt;issues page&lt;/a&gt; of the repository. You can report bugs, ask questions, etc.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Faiss is MIT-licensed.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>facebookresearch</author><guid isPermaLink="false">https://github.com/facebookresearch/faiss</guid><pubDate>Sun, 05 Jan 2020 00:03:00 GMT</pubDate></item><item><title>AGWA/git-crypt #4 in C++, Today</title><link>https://github.com/AGWA/git-crypt</link><description>&lt;p&gt;&lt;i&gt;Transparent file encryption in git&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-git-crypt---transparent-file-encryption-in-git" class="anchor" aria-hidden="true" href="#git-crypt---transparent-file-encryption-in-git"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;git-crypt - transparent file encryption in git&lt;/h1&gt;
&lt;p&gt;git-crypt enables transparent encryption and decryption of files in a
git repository.  Files which you choose to protect are encrypted when
committed, and decrypted when checked out.  git-crypt lets you freely
share a repository containing a mix of public and private content.
git-crypt gracefully degrades, so developers without the secret key can
still clone and commit to a repository with encrypted files.  This lets
you store your secret material (such as keys or passwords) in the same
repository as your code, without requiring you to lock down your entire
repository.&lt;/p&gt;
&lt;p&gt;git-crypt was written by &lt;a href="https://www.agwa.name" rel="nofollow"&gt;Andrew Ayer&lt;/a&gt; (&lt;a href="mailto:agwa@andrewayer.name"&gt;agwa@andrewayer.name&lt;/a&gt;).
For more information, see &lt;a href="https://www.agwa.name/projects/git-crypt" rel="nofollow"&gt;https://www.agwa.name/projects/git-crypt&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-building-git-crypt" class="anchor" aria-hidden="true" href="#building-git-crypt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building git-crypt&lt;/h2&gt;
&lt;p&gt;See the &lt;a href="INSTALL.md"&gt;INSTALL.md&lt;/a&gt; file.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-using-git-crypt" class="anchor" aria-hidden="true" href="#using-git-crypt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using git-crypt&lt;/h2&gt;
&lt;p&gt;Configure a repository to use git-crypt:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd repo
git-crypt init
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Specify files to encrypt by creating a .gitattributes file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;secretfile filter=git-crypt diff=git-crypt
*.key filter=git-crypt diff=git-crypt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Like a .gitignore file, it can match wildcards and should be checked into
the repository.  See below for more information about .gitattributes.
Make sure you don't accidentally encrypt the .gitattributes file itself
(or other git files like .gitignore or .gitmodules).  Make sure your
.gitattributes rules are in place &lt;em&gt;before&lt;/em&gt; you add sensitive files, or
those files won't be encrypted!&lt;/p&gt;
&lt;p&gt;Share the repository with others (or with yourself) using GPG:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git-crypt add-gpg-user USER_ID
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;USER_ID&lt;/code&gt; can be a key ID, a full fingerprint, an email address, or
anything else that uniquely identifies a public key to GPG (see "HOW TO
SPECIFY A USER ID" in the gpg man page).  Note: &lt;code&gt;git-crypt add-gpg-user&lt;/code&gt;
will add and commit a GPG-encrypted key file in the .git-crypt directory
of the root of your repository.&lt;/p&gt;
&lt;p&gt;Alternatively, you can export a symmetric secret key, which you must
securely convey to collaborators (GPG is not required, and no files
are added to your repository):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git-crypt export-key /path/to/key
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After cloning a repository with encrypted files, unlock with GPG:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git-crypt unlock
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or with a symmetric key:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git-crypt unlock /path/to/key
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That's all you need to do - after git-crypt is set up (either with
&lt;code&gt;git-crypt init&lt;/code&gt; or &lt;code&gt;git-crypt unlock&lt;/code&gt;), you can use git normally -
encryption and decryption happen transparently.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-current-status" class="anchor" aria-hidden="true" href="#current-status"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Current Status&lt;/h2&gt;
&lt;p&gt;The latest version of git-crypt is &lt;a href="NEWS.md"&gt;0.6.0&lt;/a&gt;, released on
2017-11-26.  git-crypt aims to be bug-free and reliable, meaning it
shouldn't crash, malfunction, or expose your confidential data.
However, it has not yet reached maturity, meaning it is not as
documented, featureful, or easy-to-use as it should be.  Additionally,
there may be backwards-incompatible changes introduced before version
1.0.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-security" class="anchor" aria-hidden="true" href="#security"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Security&lt;/h2&gt;
&lt;p&gt;git-crypt is more secure than other transparent git encryption systems.
git-crypt encrypts files using AES-256 in CTR mode with a synthetic IV
derived from the SHA-1 HMAC of the file.  This mode of operation is
provably semantically secure under deterministic chosen-plaintext attack.
That means that although the encryption is deterministic (which is
required so git can distinguish when a file has and hasn't changed),
it leaks no information beyond whether two files are identical or not.
Other proposals for transparent git encryption use ECB or CBC with a
fixed IV.  These systems are not semantically secure and leak information.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-limitations" class="anchor" aria-hidden="true" href="#limitations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Limitations&lt;/h2&gt;
&lt;p&gt;git-crypt relies on git filters, which were not designed with encryption
in mind.  As such, git-crypt is not the best tool for encrypting most or
all of the files in a repository. Where git-crypt really shines is where
most of your repository is public, but you have a few files (perhaps
private keys named *.key, or a file with API credentials) which you
need to encrypt.  For encrypting an entire repository, consider using a
system like &lt;a href="https://spwhitton.name/tech/code/git-remote-gcrypt/" rel="nofollow"&gt;git-remote-gcrypt&lt;/a&gt;
instead.  (Note: no endorsement is made of git-remote-gcrypt's security.)&lt;/p&gt;
&lt;p&gt;git-crypt does not encrypt file names, commit messages, symlink targets,
gitlinks, or other metadata.&lt;/p&gt;
&lt;p&gt;git-crypt does not hide when a file does or doesn't change, the length
of a file, or the fact that two files are identical (see "Security"
section above).&lt;/p&gt;
&lt;p&gt;git-crypt does not support revoking access to an encrypted repository
which was previously granted. This applies to both multi-user GPG
mode (there's no del-gpg-user command to complement add-gpg-user)
and also symmetric key mode (there's no support for rotating the key).
This is because it is an inherently complex problem in the context
of historical data. For example, even if a key was rotated at one
point in history, a user having the previous key can still access
previous repository history. This problem is discussed in more detail in
&lt;a href="https://github.com/AGWA/git-crypt/issues/47"&gt;https://github.com/AGWA/git-crypt/issues/47&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Files encrypted with git-crypt are not compressible.  Even the smallest
change to an encrypted file requires git to store the entire changed file,
instead of just a delta.&lt;/p&gt;
&lt;p&gt;Although git-crypt protects individual file contents with a SHA-1
HMAC, git-crypt cannot be used securely unless the entire repository is
protected against tampering (an attacker who can mutate your repository
can alter your .gitattributes file to disable encryption).  If necessary,
use git features such as signed tags instead of relying solely on
git-crypt for integrity.&lt;/p&gt;
&lt;p&gt;Files encrypted with git-crypt cannot be patched with git-apply, unless
the patch itself is encrypted.  To generate an encrypted patch, use &lt;code&gt;git diff --no-textconv --binary&lt;/code&gt;.  Alternatively, you can apply a plaintext
patch outside of git using the patch command.&lt;/p&gt;
&lt;p&gt;git-crypt does not work reliably with some third-party git GUIs, such
as &lt;a href="https://jira.atlassian.com/browse/SRCTREE-2511" rel="nofollow"&gt;Atlassian SourceTree&lt;/a&gt;
and GitHub for Mac.  Files might be left in an unencrypted state.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-gitattributes-file" class="anchor" aria-hidden="true" href="#gitattributes-file"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gitattributes File&lt;/h2&gt;
&lt;p&gt;The .gitattributes file is documented in the gitattributes(5) man page.
The file pattern format is the same as the one used by .gitignore,
as documented in the gitignore(5) man page, with the exception that
specifying merely a directory (e.g. &lt;code&gt;/dir/&lt;/code&gt;) is &lt;em&gt;not&lt;/em&gt; sufficient to
encrypt all files beneath it.&lt;/p&gt;
&lt;p&gt;Also note that the pattern &lt;code&gt;dir/*&lt;/code&gt; does not match files under
sub-directories of dir/.  To encrypt an entire sub-tree dir/, place the
following in dir/.gitattributes:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;* filter=git-crypt diff=git-crypt
.gitattributes !filter !diff
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second pattern is essential for ensuring that .gitattributes itself
is not encrypted.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-mailing-lists" class="anchor" aria-hidden="true" href="#mailing-lists"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Mailing Lists&lt;/h2&gt;
&lt;p&gt;To stay abreast of, and provide input to, git-crypt development,
consider subscribing to one or both of our mailing lists:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://lists.cloudmutt.com/mailman/listinfo/git-crypt-announce" rel="nofollow"&gt;Announcements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://lists.cloudmutt.com/mailman/listinfo/git-crypt-discuss" rel="nofollow"&gt;Discussion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>AGWA</author><guid isPermaLink="false">https://github.com/AGWA/git-crypt</guid><pubDate>Sun, 05 Jan 2020 00:04:00 GMT</pubDate></item><item><title>google/re2 #5 in C++, Today</title><link>https://github.com/google/re2</link><description>&lt;p&gt;&lt;i&gt;RE2 is a fast, safe, thread-friendly alternative to backtracking regular expression engines like those used in PCRE, Perl, and Python. It is a C++ library.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="" data-path="README"&gt;&lt;div class="plain"&gt;&lt;pre style="white-space: pre-wrap"&gt;This is the source code repository for RE2, a regular expression library.

For documentation about how to install and use RE2,
visit &lt;a href="https://github.com/google/re2/"&gt;https://github.com/google/re2/&lt;/a&gt;.

The short version is:

make
make test
make install
make testinstall

There is a fair amount of documentation (including code snippets) in
the re2.h header file.

More information can be found on the wiki:
&lt;a href="https://github.com/google/re2/wiki"&gt;https://github.com/google/re2/wiki&lt;/a&gt;

Issue tracker:
&lt;a href="https://github.com/google/re2/issues"&gt;https://github.com/google/re2/issues&lt;/a&gt;

Mailing list:
&lt;a href="https://groups.google.com/group/re2-dev" rel="nofollow"&gt;https://groups.google.com/group/re2-dev&lt;/a&gt;

Unless otherwise noted, the RE2 source files are distributed
under the BSD-style license found in the LICENSE file.

RE2's native language is C++.

A C wrapper is at &lt;a href="https://github.com/marcomaggi/cre2/"&gt;https://github.com/marcomaggi/cre2/&lt;/a&gt;.
An Erlang wrapper is at &lt;a href="https://github.com/dukesoferl/re2/"&gt;https://github.com/dukesoferl/re2/&lt;/a&gt; and on Hex (hex.pm).
An Inferno wrapper is at &lt;a href="https://github.com/powerman/inferno-re2/"&gt;https://github.com/powerman/inferno-re2/&lt;/a&gt;.
A Node.js wrapper is at &lt;a href="https://github.com/uhop/node-re2/"&gt;https://github.com/uhop/node-re2/&lt;/a&gt; and on NPM (npmjs.com).
An OCaml wrapper is at &lt;a href="https://github.com/janestreet/re2/"&gt;https://github.com/janestreet/re2/&lt;/a&gt; and on OPAM (opam.ocaml.org).
A Perl wrapper is at &lt;a href="https://github.com/dgl/re-engine-RE2/"&gt;https://github.com/dgl/re-engine-RE2/&lt;/a&gt; and on CPAN (cpan.org).
A Python wrapper is at &lt;a href="https://github.com/facebook/pyre2/"&gt;https://github.com/facebook/pyre2/&lt;/a&gt; and on PyPI (pypi.org).
An R wrapper is at &lt;a href="https://github.com/qinwf/re2r/"&gt;https://github.com/qinwf/re2r/&lt;/a&gt; and on CRAN (cran.r-project.org).
A Ruby wrapper is at &lt;a href="https://github.com/mudge/re2/"&gt;https://github.com/mudge/re2/&lt;/a&gt; and on RubyGems (rubygems.org).
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</description><author>google</author><guid isPermaLink="false">https://github.com/google/re2</guid><pubDate>Sun, 05 Jan 2020 00:05:00 GMT</pubDate></item><item><title>apache/thrift #6 in C++, Today</title><link>https://github.com/apache/thrift</link><description>&lt;p&gt;&lt;i&gt;Apache Thrift&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-apache-thrift" class="anchor" aria-hidden="true" href="#apache-thrift"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Apache Thrift&lt;/h1&gt;
&lt;h1&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Thrift is a lightweight, language-independent software stack for
point-to-point RPC implementation.
Thrift provides clean abstractions and implementations for data transport,
data serialization, and application level processing. The code generation
system takes a simple definition language as input and generates code
across programming languages that uses the abstracted stack to build
interoperable RPC clients and servers.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="doc/images/thrift-layers.png"&gt;&lt;img src="doc/images/thrift-layers.png" alt="Apache Thrift Layered Architecture" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thrift makes it easy for programs written in different programming
languages to share data and call remote procedures.  With support
for &lt;a href="LANGUAGES.md"&gt;28 programming languages&lt;/a&gt;, chances are Thrift
supports the languages that you currently use.&lt;/p&gt;
&lt;p&gt;Thrift is specifically designed to support non-atomic version changes
across client and server code.  This allows you to upgrade your
server while still being able service older clients; or have newer
clients issue requests to older servers.  An excellent community-provided
write-up about thrift and compatibility when versioning an API can be
found in the &lt;a href="https://diwakergupta.github.io/thrift-missing-guide/#_versioning_compatibility" rel="nofollow"&gt;Thrift Missing Guide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For more details on Thrift's design and implementation, see the Thrift
whitepaper included in this distribution, or at the README.md file
in your particular subdirectory of interest.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-status" class="anchor" aria-hidden="true" href="#status"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Status&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Branch&lt;/th&gt;
&lt;th align="left"&gt;Travis&lt;/th&gt;
&lt;th align="left"&gt;Appveyor&lt;/th&gt;
&lt;th align="left"&gt;Coverity Scan&lt;/th&gt;
&lt;th align="left"&gt;codecov.io&lt;/th&gt;
&lt;th align="left"&gt;Website&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/apache/thrift/tree/master"&gt;&lt;code&gt;master&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://travis-ci.org/apache/thrift/branches" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/db150a5e03c0f2d6330320151cf907a67c4f8dc4/68747470733a2f2f7472617669732d63692e6f72672f6170616368652f7468726966742e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/apache/thrift.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://ci.appveyor.com/project/ApacheSoftwareFoundation/thrift/history" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f8eb3e87e2f66840427395264b5ddc4898b40e40/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f6170616368652f7468726966743f6272616e63683d6d6173746572267376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/apache/thrift?branch=master&amp;amp;svg=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://scan.coverity.com/projects/thrift" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a33186ad79d67aab4f141d6386c8c73390b0aadf/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f313334352f62616467652e737667" alt="Coverity Scan Build Status" data-canonical-src="https://scan.coverity.com/projects/1345/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://thrift.apache.org/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/fbdd9c6d53af6fba0fa2865636f741163b527043/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f6666696369616c2d776562736974652d627269676874677265656e2e737667" alt="Website" data-canonical-src="https://img.shields.io/badge/official-website-brightgreen.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/apache/thrift/tree/0.12.0"&gt;&lt;code&gt;0.12.0&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://travis-ci.org/apache/thrift/branches" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a384d3a21941e018db9c1524d15eb7a09277ff05/68747470733a2f2f7472617669732d63692e6f72672f6170616368652f7468726966742e7376673f6272616e63683d302e31322e30" alt="Build Status" data-canonical-src="https://travis-ci.org/apache/thrift.svg?branch=0.12.0" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-releases" class="anchor" aria-hidden="true" href="#releases"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Releases&lt;/h1&gt;
&lt;p&gt;Thrift does not maintain a specific release calendar at this time.&lt;/p&gt;
&lt;p&gt;We strive to release twice yearly.  Download the &lt;a href="http://thrift.apache.org/download" rel="nofollow"&gt;current release&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h1&gt;
&lt;p&gt;Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements. See the NOTICE file
distributed with this work for additional information
regarding copyright ownership. The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License. You may obtain a copy of the License at&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied. See the License for the
specific language governing permissions and limitations
under the License.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-project-hierarchy" class="anchor" aria-hidden="true" href="#project-hierarchy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Project Hierarchy&lt;/h1&gt;
&lt;p&gt;thrift/&lt;/p&gt;
&lt;p&gt;compiler/&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Contains the Thrift compiler, implemented in C++.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;lib/&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Contains the Thrift software library implementation, subdivided by
language of implementation.

cpp/
go/
java/
php/
py/
rb/
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;test/&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Contains sample Thrift files and test code across the target programming
languages.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;tutorial/&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Contains a basic tutorial that will teach you how to develop software
using Thrift.
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;&lt;a id="user-content-development" class="anchor" aria-hidden="true" href="#development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development&lt;/h1&gt;
&lt;p&gt;To build the same way Travis CI builds the project you should use docker.
We have &lt;a href="build/docker/README.md"&gt;comprehensive building instructions for docker&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h1&gt;
&lt;p&gt;See &lt;a href="http://thrift.apache.org/docs/install" rel="nofollow"&gt;http://thrift.apache.org/docs/install&lt;/a&gt; for a list of build requirements (may be stale).  Alternatively see the docker build environments for a list of prerequisites.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h1&gt;
&lt;p&gt;More information about Thrift can be obtained on the Thrift webpage at:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; http://thrift.apache.org
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;&lt;a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgments&lt;/h1&gt;
&lt;p&gt;Thrift was inspired by pillar, a lightweight RPC tool written by Adam D'Angelo,
and also by Google's protocol buffers.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h1&gt;
&lt;p&gt;If you are building from the first time out of the source repository, you will
need to generate the configure scripts.  (This is not necessary if you
downloaded a tarball.)  From the top directory, do:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./bootstrap.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the configure scripts are generated, thrift can be configured.
From the top directory, do:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./configure
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may need to specify the location of the boost files explicitly.
If you installed boost in /usr/local, you would run configure as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./configure --with-boost=/usr/local
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that by default the thrift C++ library is typically built with debugging
symbols included. If you want to customize these options you should use the
CXXFLAGS option in configure, as such:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./configure CXXFLAGS='-g -O2'
./configure CFLAGS='-g -O2'
./configure CPPFLAGS='-DDEBUG_MY_FEATURE'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To enable gcov required options -fprofile-arcs -ftest-coverage enable them:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./configure  --enable-coverage
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Run ./configure --help to see other configuration options&lt;/p&gt;
&lt;p&gt;Please be aware that the Python library will ignore the --prefix option
and just install wherever Python's distutils puts it (usually along
the lines of /usr/lib/pythonX.Y/site-packages/).  If you need to control
where the Python modules are installed, set the PY_PREFIX variable.
(DESTDIR is respected for Python and C++.)&lt;/p&gt;
&lt;p&gt;Make thrift:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;make
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the top directory, become superuser and do:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;make install
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that some language packages must be installed manually using build tools
better suited to those languages (at the time of this writing, this applies
to Java, Ruby, PHP).&lt;/p&gt;
&lt;p&gt;Look for the README.md file in the lib// folder for more details on the
installation of each language library package.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-testing" class="anchor" aria-hidden="true" href="#testing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Testing&lt;/h1&gt;
&lt;p&gt;There are a large number of client library tests that can all be run
from the top-level directory.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;      make -k check
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will make all of the libraries (as necessary), and run through
the unit tests defined in each of the client libraries. If a single
language fails, the make check will continue on and provide a synopsis
at the end.&lt;/p&gt;
&lt;p&gt;To run the cross-language test suite, please run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;      make cross
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will run a set of tests that use different language clients and
servers.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>apache</author><guid isPermaLink="false">https://github.com/apache/thrift</guid><pubDate>Sun, 05 Jan 2020 00:06:00 GMT</pubDate></item><item><title>IntelRealSense/librealsense #7 in C++, Today</title><link>https://github.com/IntelRealSense/librealsense</link><description>&lt;p&gt;&lt;i&gt;Intel® RealSense™ SDK&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="readme.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="doc/img/realsense.png"&gt;&lt;img src="doc/img/realsense.png" width="70%" style="max-width:100%;"&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;CI State&lt;/strong&gt;: &lt;a href="https://travis-ci.org/IntelRealSense/librealsense" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d1ccb42a6f049dd10d75306398602785af45ad25/68747470733a2f2f7472617669732d63692e6f72672f496e74656c5265616c53656e73652f6c69627265616c73656e73652e7376673f6272616e63683d646576656c6f706d656e74" alt="Build Status" data-canonical-src="https://travis-ci.org/IntelRealSense/librealsense.svg?branch=development" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overview&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Intel® RealSense™ SDK 2.0&lt;/strong&gt; is a cross-platform library for Intel® RealSense™ depth cameras (D400 series and the SR300) and the &lt;a href="./doc/t265.md"&gt;T265 tracking camera&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="pushpin" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4cc.png"&gt;📌&lt;/g-emoji&gt; For other Intel® RealSense™ devices (F200, R200, LR200 and ZR300), please refer to the &lt;a href="https://github.com/IntelRealSense/librealsense/tree/v1.12.1"&gt;latest legacy release&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The SDK allows depth and color streaming, and provides intrinsic and extrinsic calibration information.
The library also offers synthetic streams (pointcloud, depth aligned to color and vise-versa), and a built-in support for &lt;a href="./src/media/readme.md"&gt;record and playback&lt;/a&gt; of streaming sessions.&lt;/p&gt;
&lt;p&gt;Developer kits containing the necessary hardware to use this library are available for purchase at &lt;a href="https://store.intelrealsense.com/products.html" rel="nofollow"&gt;store.intelrealsense.com&lt;/a&gt;.
Information about the Intel® RealSense™ technology at &lt;a href="https://www.intelrealsense.com/" rel="nofollow"&gt;www.intelrealsense.com&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="open_file_folder" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4c2.png"&gt;📂&lt;/g-emoji&gt; Don't have access to a RealSense camera? Check-out &lt;a href="./doc/sample-data.md"&gt;sample data&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-download-and-install" class="anchor" aria-hidden="true" href="#download-and-install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Download and Install&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Download&lt;/strong&gt; - The latest releases including the Intel RealSense SDK, Viewer and Depth Quality tools are available at: &lt;a href="https://github.com/IntelRealSense/librealsense/releases"&gt;&lt;strong&gt;latest releases&lt;/strong&gt;&lt;/a&gt;. Please check the &lt;a href="https://github.com/IntelRealSense/librealsense/wiki/Release-Notes"&gt;&lt;strong&gt;release notes&lt;/strong&gt;&lt;/a&gt; for the supported platforms, new features and capabilities, known issues, how to upgrade the Firmware and more.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Install&lt;/strong&gt; - You can also install or build from source the SDK (on &lt;a href="./doc/distribution_linux.md"&gt;Linux&lt;/a&gt; \ &lt;a href="./doc/distribution_windows.md"&gt;Windows&lt;/a&gt; \ &lt;a href="doc/installation_osx.md"&gt;Mac OS&lt;/a&gt; \ &lt;a href="./doc/android.md"&gt;Android&lt;/a&gt;), connect your D400 depth camera and you are ready to start writing your first application.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Support &amp;amp; Issues&lt;/strong&gt;: If you need product support (e.g. ask a question about / are having problems with the device), please check the &lt;a href="https://github.com/IntelRealSense/librealsense/wiki/Troubleshooting-Q%26A"&gt;FAQ &amp;amp; Troubleshooting&lt;/a&gt; section.
If not covered there, please search our &lt;a href="https://github.com/IntelRealSense/librealsense/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aclosed"&gt;Closed GitHub Issues&lt;/a&gt; page,  &lt;a href="https://communities.intel.com/community/tech/realsense" rel="nofollow"&gt;Community&lt;/a&gt; and &lt;a href="https://www.intel.com/content/www/us/en/support/emerging-technologies/intel-realsense-technology.html" rel="nofollow"&gt;Support&lt;/a&gt; sites.
If you still cannot find an answer to your question, please &lt;a href="https://github.com/IntelRealSense/librealsense/issues/new"&gt;open a new issue&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-whats-included-in-the-sdk" class="anchor" aria-hidden="true" href="#whats-included-in-the-sdk"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What’s included in the SDK:&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;What&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Download link&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;&lt;a href="./tools/realsense-viewer"&gt;Intel® RealSense™ Viewer&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;With this application, you can quickly access your Intel® RealSense™ Depth Camera to view the depth stream, visualize point clouds, record and playback streams, configure your camera settings, modify advanced controls, enable depth visualization and post processing  and much more.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/IntelRealSense/librealsense/releases"&gt;&lt;strong&gt;Intel.RealSense.Viewer.exe&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;&lt;a href="./tools/depth-quality"&gt;Depth Quality Tool&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;This application allows you to test the camera’s depth quality, including: standard deviation from plane fit, normalized RMS – the subpixel accuracy, distance accuracy and fill rate. You should be able to easily get and interpret several of the depth quality metrics and record and save the data for offline analysis.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/IntelRealSense/librealsense/releases"&gt;&lt;strong&gt;Depth.Quality.Tool.exe&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;&lt;a href="./tools/"&gt;Debug Tools&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Device enumeration, FW logger, etc as can be seen at the tools directory&lt;/td&gt;
&lt;td&gt;Included in &lt;a href="https://github.com/IntelRealSense/librealsense/releases"&gt;&lt;strong&gt;Intel.RealSense.SDK.exe&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;&lt;a href="./examples"&gt;Code Samples&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;These simple examples demonstrate how to easily use the SDK to include code snippets that access the camera into your applications. Check some of the &lt;a href="./examples"&gt;&lt;strong&gt;C++ examples&lt;/strong&gt;&lt;/a&gt; including capture, pointcloud and more and basic &lt;a href="./examples/C"&gt;&lt;strong&gt;C examples&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Included in &lt;a href="https://github.com/IntelRealSense/librealsense/releases"&gt;&lt;strong&gt;Intel.RealSense.SDK.exe&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/IntelRealSense/librealsense/tree/development/wrappers"&gt;Wrappers&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="./wrappers/python"&gt;Python&lt;/a&gt;, &lt;a href="./wrappers/csharp"&gt;C#/.NET&lt;/a&gt;, &lt;a href="./wrappers/nodejs"&gt;Node.js&lt;/a&gt; API, as well as integration with the following 3rd-party technologies: &lt;a href="https://github.com/intel-ros/realsense/releases"&gt;ROS&lt;/a&gt;, &lt;a href="https://github.com/intel/ros2_intel_realsense"&gt;ROS2&lt;/a&gt;, &lt;a href="./wrappers/labview"&gt;LabVIEW&lt;/a&gt;, &lt;a href="./wrappers/opencv"&gt;OpenCV&lt;/a&gt;, &lt;a href="./wrappers/pcl"&gt;PCL&lt;/a&gt;, &lt;a href="./wrappers/unity"&gt;Unity&lt;/a&gt;, &lt;a href="./wrappers/matlab"&gt;Matlab&lt;/a&gt;, &lt;a href="./wrappers/openni2"&gt;OpenNI&lt;/a&gt;, &lt;a href="./wrappers/unrealengine4"&gt;UnrealEngine4&lt;/a&gt; and more to come.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-ready-to-hack" class="anchor" aria-hidden="true" href="#ready-to-hack"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ready to Hack!&lt;/h2&gt;
&lt;p&gt;Our library offers a high level API for using Intel RealSense depth cameras (in addition to lower level ones).
The following snippet shows how to start streaming frames and extracting the depth value of a pixel:&lt;/p&gt;
&lt;div class="highlight highlight-source-c++"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Create a Pipeline - this serves as a top-level API for streaming and processing frames&lt;/span&gt;
rs2::pipeline p;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Configure and start the pipeline&lt;/span&gt;
p.start();

&lt;span class="pl-k"&gt;while&lt;/span&gt; (&lt;span class="pl-c1"&gt;true&lt;/span&gt;)
{
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Block program until frames arrive&lt;/span&gt;
    rs2::frameset frames = p.&lt;span class="pl-c1"&gt;wait_for_frames&lt;/span&gt;();

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Try to get a frame of a depth image&lt;/span&gt;
    rs2::depth_frame depth = frames.&lt;span class="pl-c1"&gt;get_depth_frame&lt;/span&gt;();

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Get the depth frame's dimensions&lt;/span&gt;
    &lt;span class="pl-k"&gt;float&lt;/span&gt; width = depth.&lt;span class="pl-c1"&gt;get_width&lt;/span&gt;();
    &lt;span class="pl-k"&gt;float&lt;/span&gt; height = depth.&lt;span class="pl-c1"&gt;get_height&lt;/span&gt;();

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Query the distance from the camera to the object in the center of the image&lt;/span&gt;
    &lt;span class="pl-k"&gt;float&lt;/span&gt; dist_to_center = depth.&lt;span class="pl-c1"&gt;get_distance&lt;/span&gt;(width / &lt;span class="pl-c1"&gt;2&lt;/span&gt;, height / &lt;span class="pl-c1"&gt;2&lt;/span&gt;);

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Print the distance&lt;/span&gt;
    std::cout &amp;lt;&amp;lt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;The camera is facing an object &lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &amp;lt;&amp;lt; dist_to_center &amp;lt;&amp;lt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt; meters away &lt;span class="pl-cce"&gt;\r&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;;
}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For more information on the library, please follow our &lt;a href="./examples"&gt;examples&lt;/a&gt;, and read the &lt;a href="./doc"&gt;documentation&lt;/a&gt; to learn more.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;In order to contribute to Intel RealSense SDK, please follow our &lt;a href="CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is licensed under the &lt;a href="LICENSE"&gt;Apache License, Version 2.0&lt;/a&gt;.
Copyright 2018 Intel Corporation&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>IntelRealSense</author><guid isPermaLink="false">https://github.com/IntelRealSense/librealsense</guid><pubDate>Sun, 05 Jan 2020 00:07:00 GMT</pubDate></item><item><title>yuanming-hu/taichi #8 in C++, Today</title><link>https://github.com/yuanming-hu/taichi</link><description>&lt;p&gt;&lt;i&gt;The Taichi programming language&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;div align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/yuanming-hu/taichi/raw/master/misc/logo.png"&gt;&lt;img width="500px" src="https://github.com/yuanming-hu/taichi/raw/master/misc/logo.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;h3&gt;&lt;a id="user-content---docs----tutorial----difftaichi----examples----faq----forum--" class="anchor" aria-hidden="true" href="#--docs----tutorial----difftaichi----examples----faq----forum--"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt; &lt;a href="https://taichi.readthedocs.io/en/latest/" rel="nofollow"&gt; Docs &lt;/a&gt; | &lt;a href="https://taichi.readthedocs.io/en/latest/hello.html" rel="nofollow"&gt; Tutorial &lt;/a&gt; | &lt;a href="https://github.com/yuanming-hu/difftaichi"&gt; DiffTaichi &lt;/a&gt; | &lt;a href="https://github.com/yuanming-hu/taichi/tree/master/examples"&gt; Examples &lt;/a&gt; | &lt;a href="https://github.com/yuanming-hu/taichi/tree/master/misc#faq"&gt; FAQ &lt;/a&gt; | &lt;a href="https://forum.taichi.graphics/" rel="nofollow"&gt; Forum &lt;/a&gt; &lt;/h3&gt;
&lt;/div&gt;        
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;strong&gt;Documentations&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;Chat&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;taichi-nightly&lt;/th&gt;
&lt;th align="left"&gt;taichi-nightly-cuda-10-0&lt;/th&gt;
&lt;th align="left"&gt;taichi-nightly-cuda-10-1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="http://taichi.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/df8b6b65c1fac5dbe537988531d7c2f8f055fbdc/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f7461696368692f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/taichi/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://gitter.im/taichi-dev/Lobby?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ebaf0b73c71cbdf5e5d9fb026f5140e85b941bdc/68747470733a2f2f6261646765732e6769747465722e696d2f7461696368692d6465762f4c6f6262792e737667" alt="Join the chat at https://gitter.im/taichi-dev/Lobby" data-canonical-src="https://badges.gitter.im/taichi-dev/Lobby.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://pepy.tech/project/taichi-nightly/month" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/665623c50e338f6821fa478b2eb4d64960e0a718/68747470733a2f2f706570792e746563682f62616467652f7461696368692d6e696768746c792f6d6f6e7468" alt="Downloads" data-canonical-src="https://pepy.tech/badge/taichi-nightly/month" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://pepy.tech/project/taichi-nightly-cuda-10-0/month" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/462343470d8a13504bf964a36c21528d5c7e8ee3/68747470733a2f2f706570792e746563682f62616467652f7461696368692d6e696768746c792d637564612d31302d302f6d6f6e7468" alt="Downloads" data-canonical-src="https://pepy.tech/badge/taichi-nightly-cuda-10-0/month" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://pepy.tech/project/taichi-nightly-cuda-10-1/month" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/462343470d8a13504bf964a36c21528d5c7e8ee3/68747470733a2f2f706570792e746563682f62616467652f7461696368692d6e696768746c792d637564612d31302d302f6d6f6e7468" alt="Downloads" data-canonical-src="https://pepy.tech/badge/taichi-nightly-cuda-10-0/month" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Python 3.6+ needed&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; CPU only. No GPU/CUDA needed. (Linux, OS X and Windows)&lt;/span&gt;
python3 -m pip install taichi-nightly

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; With GPU (CUDA 10.0) support (Linux only)&lt;/span&gt;
python3 -m pip install taichi-nightly-cuda-10-0

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; With GPU (CUDA 10.1) support (Linux only)&lt;/span&gt;
python3 -m pip install taichi-nightly-cuda-10-1&lt;/pre&gt;&lt;/div&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;Linux (CUDA)&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;OS X&lt;/strong&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;strong&gt;Build&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="http://f11.csail.mit.edu:8080/job/taichi/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a52458d8ded10f803df1fd93eba7ffbcbef75b1d/687474703a2f2f6631312e637361696c2e6d69742e6564753a383038302f6a6f622f7461696368692f62616467652f69636f6e" alt="Build Status" data-canonical-src="http://f11.csail.mit.edu:8080/job/taichi/badge/icon" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://travis-ci.com/yuanming-hu/taichi" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/cbcaa80b5e08a0ebd9cce0c4a1fba796e58a5769/68747470733a2f2f7472617669732d63692e636f6d2f7975616e6d696e672d68752f7461696368692e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/yuanming-hu/taichi.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://ci.appveyor.com/project/IteratorAdvance/taichi" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/aae7ba4e011b50e6b51474df5fe466b969276638/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f7975616e6d696e672d68752f7461696368693f6272616e63683d6d6173746572267376673d74727565" alt="Build Status" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/yuanming-hu/taichi?branch=master&amp;amp;svg=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;strong&gt;PyPI&lt;/strong&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://travis-ci.com/yuanming-hu/taichi-wheels-test" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2ea2cfde28ca0557d4b39e5317db8aff785d0be4/68747470733a2f2f7472617669732d63692e636f6d2f7975616e6d696e672d68752f7461696368692d776865656c732d746573742e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/yuanming-hu/taichi-wheels-test.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://travis-ci.com/yuanming-hu/taichi-wheels-test" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2ea2cfde28ca0557d4b39e5317db8aff785d0be4/68747470733a2f2f7472617669732d63692e636f6d2f7975616e6d696e672d68752f7461696368692d776865656c732d746573742e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/yuanming-hu/taichi-wheels-test.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;a href="https://ci.appveyor.com/project/IteratorAdvance/taichi-wheels-test" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e0a4cc9518f896bcdf5774ba6f1b3561e5fd7d90/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f3339617239776138796434396a65376f3f7376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/39ar9wa8yd49je7o?svg=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-related-papers" class="anchor" aria-hidden="true" href="#related-papers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Related papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://taichi.graphics/wp-content/uploads/2019/09/taichi_lang.pdf" rel="nofollow"&gt;&lt;strong&gt;(SIGGRAPH Asia 2019) High-Performance Computation on Sparse Data Structures&lt;/strong&gt;&lt;/a&gt; &lt;a href="https://youtu.be/wKw8LMF3Djo" rel="nofollow"&gt;[Video]&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yuanming-hu/taichi/master/misc/taichi_bibtex.txt" rel="nofollow"&gt;[BibTex]&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;by &lt;em&gt;Yuanming Hu, Tzu-Mao Li, Luke Anderson, Jonathan Ragan-Kelley, and Frédo Durand&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1910.00935" rel="nofollow"&gt;&lt;strong&gt;(ICLR 2020) Differentiable Programming for Physical Simulation&lt;/strong&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/watch?v=Z1xvAZve9aE" rel="nofollow"&gt;[Video]&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yuanming-hu/taichi/master/misc/difftaichi_bibtex.txt" rel="nofollow"&gt;[BibTex]&lt;/a&gt; &lt;a href="https://github.com/yuanming-hu/difftaichi"&gt;[Code]&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;by &lt;em&gt;Yuanming Hu, Luke Anderson, Tzu-Mao Li, Qi Sun, Nathan Carr, Jonathan Ragan-Kelley, and Frédo Durand&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-short-term-goals" class="anchor" aria-hidden="true" href="#short-term-goals"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Short-term goals&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Fully implement the LLVM backend to replace the legacy source-to-source C++/CUDA backends
&lt;ul&gt;
&lt;li&gt;Dense computation (done)&lt;/li&gt;
&lt;li&gt;Sparse data structures (done)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tune the performance of the LLVM backend to match that of the legacy source-to-source backends (WIP)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-updates" class="anchor" aria-hidden="true" href="#updates"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Updates&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;(Jan   3, 2020) v0.3.20 released.
&lt;ul&gt;
&lt;li&gt;Support for loops with &lt;code&gt;ti.static(ti.grouped(ti.ndrange(...)))&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Jan   2, 2020) v0.3.19 released.
&lt;ul&gt;
&lt;li&gt;Added &lt;code&gt;ti.atan2(y, x)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Improved error msg when using float point numbers as tensor indices&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Jan   1, 2020) v0.3.18 released.
&lt;ul&gt;
&lt;li&gt;Added &lt;code&gt;ti.GUI&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;Improved the performance of performance &lt;code&gt;ti.Matrix.fill&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  31, 2019) v0.3.17 released.
&lt;ul&gt;
&lt;li&gt;Fixed cuda context conflict with PyTorch  (thanks to @Xingzhe He for reporting)&lt;/li&gt;
&lt;li&gt;Support &lt;code&gt;ti.Matrix.T()&lt;/code&gt; for transposing a matrix&lt;/li&gt;
&lt;li&gt;Iteratable &lt;code&gt;ti.static(ti.ndrange)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fixed &lt;code&gt;ti.Matrix.identity()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Added &lt;code&gt;ti.Matrix.one()&lt;/code&gt; (create a matrix with 1 as all the entries)&lt;/li&gt;
&lt;li&gt;Improved &lt;code&gt;ir_printer&lt;/code&gt; on SNodes&lt;/li&gt;
&lt;li&gt;Better support for &lt;code&gt;dynamic&lt;/code&gt; SNodes.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Struct-for's&lt;/code&gt; on &lt;code&gt;dynamic&lt;/code&gt; nodes supported&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ti.length&lt;/code&gt; and &lt;code&gt;ti.append&lt;/code&gt; to query and manipulate dynamic nodes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  29, 2019) v0.3.16 released.
&lt;ul&gt;
&lt;li&gt;Fixed ndrange-fors with local variables (thanks to Xingzhe He for reporting this issue)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  28, 2019) v0.3.15 released.
&lt;ul&gt;
&lt;li&gt;Multi-dimensional parallel range-for using &lt;code&gt;ti.ndrange&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;  &lt;span class="pl-en"&gt;@ti.kernel&lt;/span&gt;
  &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;fill_3d&lt;/span&gt;():
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Parallelized for all 3 &amp;lt;= i &amp;lt; 8, 1 &amp;lt;= j &amp;lt; 6, 0 &amp;lt;= k &amp;lt; 9&lt;/span&gt;
    &lt;span class="pl-k"&gt;for&lt;/span&gt; i, j, k &lt;span class="pl-k"&gt;in&lt;/span&gt; ti.ndrange((&lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-c1"&gt;8&lt;/span&gt;), (&lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-c1"&gt;6&lt;/span&gt;), &lt;span class="pl-c1"&gt;9&lt;/span&gt;):
      x[i, j, k] &lt;span class="pl-k"&gt;=&lt;/span&gt; i &lt;span class="pl-k"&gt;+&lt;/span&gt; j &lt;span class="pl-k"&gt;+&lt;/span&gt; k&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;(Dec  28, 2019) v0.3.14 released.
&lt;ul&gt;
&lt;li&gt;GPU random number generator support for more than 1024x1024 threads&lt;/li&gt;
&lt;li&gt;Parallelized element list generation on GPUs. Struct-fors significantly sped up.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ti&lt;/code&gt; and &lt;code&gt;tid&lt;/code&gt; (debug mode) CLI commands&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  26, 2019) v0.3.13 released.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ti.append&lt;/code&gt; now returns the list length before appending&lt;/li&gt;
&lt;li&gt;Fixed for loops with 0 iterations&lt;/li&gt;
&lt;li&gt;Set &lt;code&gt;ti.get_runtime().set_verbose_kernel_launch(True)&lt;/code&gt; to log kernel launches&lt;/li&gt;
&lt;li&gt;Distinguish &lt;code&gt;/&lt;/code&gt; and &lt;code&gt;//&lt;/code&gt; following the Python convention&lt;/li&gt;
&lt;li&gt;Allow using local variables as kernel argument type annotations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  25, 2019) v0.3.11 released.
&lt;ul&gt;
&lt;li&gt;Support multiple kernels with the same name, especially in the OOP cases where multiple member kernels share the same name&lt;/li&gt;
&lt;li&gt;Basic &lt;code&gt;dynamic&lt;/code&gt; node support (&lt;code&gt;ti.append&lt;/code&gt;, &lt;code&gt;ti.length&lt;/code&gt;) in the new LLVM backend&lt;/li&gt;
&lt;li&gt;Fixed struct-for loops on 0-D tensors&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  24, 2019) v0.3.10 released.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;assert &amp;lt;condition&amp;gt;&lt;/code&gt; statement supported in Taichi kernels.&lt;/li&gt;
&lt;li&gt;Comparison operator chaining (e.g. &lt;code&gt;1 &amp;lt; x &amp;lt;3&lt;/code&gt;) supported in Taichi kernels.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  24, 2019) v0.3.9 released.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ti.classfunc&lt;/code&gt; decorator for functions within a &lt;code&gt;data_oriented&lt;/code&gt; class&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[Expr/Vector/Matrix].to_torch&lt;/code&gt; now has a extra argument &lt;code&gt;device&lt;/code&gt;, which specifies the device placement for returned torch tensor, and should have type &lt;code&gt;torch.device&lt;/code&gt;. Default=&lt;code&gt;None&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Cross-device (CPU/GPU) taichi/PyTorch interaction support, when using &lt;code&gt;to_torch/from_torch&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;#kernels compiled during external array IO significantly reduced (from &lt;code&gt;matrix size&lt;/code&gt; to &lt;code&gt;1&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  23, 2019) v0.3.8 released.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Breaking change&lt;/strong&gt;: &lt;code&gt;ti.data_oriented&lt;/code&gt; decorator introduced. Please decorate all your Taichi data-oriented objects using this decorator. To invoke the gradient versions of &lt;code&gt;classmethod&lt;/code&gt;, for example, &lt;code&gt;A.forward&lt;/code&gt;, simply use &lt;code&gt;A.forward.grad()&lt;/code&gt; instead of &lt;code&gt;A.forward(__gradient=True)&lt;/code&gt; (obsolete).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  22, 2019) v0.3.5 released.
&lt;ul&gt;
&lt;li&gt;Maximum tensor dimensionality is 8 now (used to be 4). I.e., you can now allocate up to 8-D tensors.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  22, 2019) v0.3.4 released.
&lt;ul&gt;
&lt;li&gt;2D and 3D polar decomposition (&lt;code&gt;R, S = ti.polar_decompose(A, ti.f32)&lt;/code&gt;) and svd (&lt;code&gt;U, sigma, V = ti.svd(A, ti.f32)&lt;/code&gt;) support. Note that &lt;code&gt;sigma&lt;/code&gt; is a &lt;code&gt;3x3&lt;/code&gt; diagonal matrix.&lt;/li&gt;
&lt;li&gt;Fixed documentation versioning&lt;/li&gt;
&lt;li&gt;Allow &lt;code&gt;expr_init&lt;/code&gt; with &lt;code&gt;ti.core.DataType&lt;/code&gt; as inputs, so that &lt;code&gt;ti.core.DataType&lt;/code&gt; can be used as &lt;code&gt;ti.func&lt;/code&gt; parameter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  20, 2019) v0.3.3 released.
&lt;ul&gt;
&lt;li&gt;Loud failure message when calling nested kernels. Closed #310&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DiffTaichi&lt;/code&gt; examples moved to &lt;a href="https://github.com/yuanming-hu/difftaichi"&gt;a standalone repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Fixed documentation versioning&lt;/li&gt;
&lt;li&gt;Correctly differentiating kernels with multiple offloaded statements&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  18, 2019) v0.3.2 released
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Vector.norm&lt;/code&gt; now comes with a parameter &lt;code&gt;eps&lt;/code&gt; (&lt;code&gt;=0&lt;/code&gt; by default), and returns &lt;code&gt;sqrt(\sum_i(x_i ^ 2) + eps)&lt;/code&gt;. A non-zero &lt;code&gt;eps&lt;/code&gt; safe guards the operator's gradient on zero vectors during differentiable programming.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  17, 2019) v0.3.1 released.
&lt;ul&gt;
&lt;li&gt;Removed dependency on &lt;code&gt;glibc 2.27&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  17, 2019) v0.3.0 released.
&lt;ul&gt;
&lt;li&gt;Documentation significantly improved&lt;/li&gt;
&lt;li&gt;&lt;code&gt;break&lt;/code&gt; statements supported in while loops&lt;/li&gt;
&lt;li&gt;CPU multithreading enabled by default&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  16, 2019) v0.2.6 released.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ti.GUI.set_image(np.ndarray/Taichi tensor)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Inplace adds are &lt;em&gt;atomic&lt;/em&gt; by default. E.g., &lt;code&gt;x[i] += j&lt;/code&gt; is equivalent to &lt;code&gt;ti.atomic_add(x[i], j)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ti.func&lt;/code&gt; arguments are forced to pass by value&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min/max&lt;/code&gt; can now take more than two arguments, e.g. &lt;code&gt;max(a, b, c, d)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Matrix operators &lt;code&gt;transposed&lt;/code&gt;, &lt;code&gt;trace&lt;/code&gt;, &lt;code&gt;polar_decompose&lt;/code&gt;, &lt;code&gt;determinant&lt;/code&gt; promoted to &lt;code&gt;ti&lt;/code&gt; scope. I.e., users can now use &lt;code&gt;ti.transposed(M)&lt;/code&gt; instead of &lt;code&gt;ti.Matrix.transposed(M)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ti.get_runtime().set_verbose(False)&lt;/code&gt; to eliminate verbose outputs&lt;/li&gt;
&lt;li&gt;LLVM backend now supports multithreading on CPUs&lt;/li&gt;
&lt;li&gt;LLVM backend now supports random number generators (&lt;code&gt;ti.random(ti.i32/i64/f32/f64&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  5, 2019) v0.2.3 released.
&lt;ul&gt;
&lt;li&gt;Simplified interaction between &lt;code&gt;Taichi&lt;/code&gt;, &lt;code&gt;numpy&lt;/code&gt; and &lt;code&gt;PyTorch&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;taichi_scalar_tensor.to_numpy()/from_numpy(numpy_array)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;taichi_scalar_tensor.to_torch()/from_torch(torch_array)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  4, 2019) v0.2.2 released.
&lt;ul&gt;
&lt;li&gt;Argument type &lt;code&gt;ti.ext_arr()&lt;/code&gt; now takes PyTorch tensors&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Dec  3, 2019) v0.2.1 released.
&lt;ul&gt;
&lt;li&gt;Improved type mismatch error message&lt;/li&gt;
&lt;li&gt;native &lt;code&gt;min&lt;/code&gt;/&lt;code&gt;max&lt;/code&gt; supprt&lt;/li&gt;
&lt;li&gt;Tensor access index dimensionality checking&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Matrix.to_numpy&lt;/code&gt;, &lt;code&gt;Matrix.zero&lt;/code&gt;, &lt;code&gt;Matrix.identity&lt;/code&gt;, &lt;code&gt;Matrix.fill&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Warning instead of error on lossy stores&lt;/li&gt;
&lt;li&gt;Added some initial support for cross-referencing local variables in different offloaded blocks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(Nov 28, 2019) v0.2.0 released.
&lt;ul&gt;
&lt;li&gt;More friendly syntax error when passing non-compile-time-constant values to &lt;code&gt;ti.static&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Systematically resolved the variable name resolution &lt;a href="https://github.com/yuanming-hu/taichi/issues/282"&gt;issue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Better interaction with numpy:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;numpy&lt;/code&gt; arrays passed as a &lt;code&gt;ti.ext_arr()&lt;/code&gt; &lt;a href="https://github.com/yuanming-hu/taichi/blob/master/tests/python/test_numpy.py"&gt;[examples]&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;i32/f32/i64/f64&lt;/code&gt; data type support for numpy&lt;/li&gt;
&lt;li&gt;Multidimensional numpy arrays now supported in Taichi kernels&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Tensor.to_numpy()&lt;/code&gt; and &lt;code&gt;Tensor.from_numpy(numpy.ndarray)&lt;/code&gt; supported &lt;a href="https://github.com/yuanming-hu/taichi/blob/master/tests/python/test_cvt_numpy.py"&gt;[examples]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Corresponding PyTorch tensor interaction will be supported very soon. Now only 1D f32 PyTorch tensors supproted when using &lt;code&gt;ti.ext_arr()&lt;/code&gt;. Please use numpy arrays as intermediate buffers for now&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Indexing arrays with an incorrect number of indices now results in a syntax error&lt;/li&gt;
&lt;li&gt;Tensor shape reflection: &lt;a href="https://github.com/yuanming-hu/taichi/blob/master/tests/python/test_tensor_reflection.py"&gt;[examples]&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Tensor.dim()&lt;/code&gt; to retrieve the dimensionality of a global tensor&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Tensor.shape()&lt;/code&gt; to retrieve the shape of a global tensor&lt;/li&gt;
&lt;li&gt;Note the above queries will cause data structures to be materialized&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;struct-for&lt;/code&gt; (e.g. &lt;code&gt;for i, j in x&lt;/code&gt;) now supports iterating over tensors with non power-of-two dimensions&lt;/li&gt;
&lt;li&gt;Handy tensor filling: &lt;a href="https://github.com/yuanming-hu/taichi/blob/master/tests/python/test_fill.py"&gt;[examples]&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Tensor.fill(x)&lt;/code&gt; to set all entries to &lt;code&gt;x&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Matrix.fill(x)&lt;/code&gt; to set all entries to &lt;code&gt;x&lt;/code&gt;, where &lt;code&gt;x&lt;/code&gt; can be a scalar or &lt;code&gt;ti.Matrix&lt;/code&gt; of the same size&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reduced python package size&lt;/li&gt;
&lt;li&gt;&lt;code&gt;struct-for&lt;/code&gt; with grouped indices for better metaprogramming, especially in writing dimensionality-independent code, in e.g. physical simulation: &lt;a href="https://github.com/yuanming-hu/taichi/blob/master/tests/python/test_grouped.py"&gt;[examples]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;for&lt;/span&gt; I &lt;span class="pl-k"&gt;in&lt;/span&gt; ti.grouped(x): &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; I is a vector of size x.dim() and data type i32&lt;/span&gt;
  x[I] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;
  
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; If tensor x is 2D &lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; I &lt;span class="pl-k"&gt;in&lt;/span&gt; ti.grouped(x): &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; I is a vector of size x.dim() and data type i32&lt;/span&gt;
  y[I &lt;span class="pl-k"&gt;+&lt;/span&gt; ti.Vector([&lt;span class="pl-c1"&gt;0&lt;/span&gt;, &lt;span class="pl-c1"&gt;1&lt;/span&gt;])] &lt;span class="pl-k"&gt;=&lt;/span&gt; I[&lt;span class="pl-c1"&gt;0&lt;/span&gt;] &lt;span class="pl-k"&gt;+&lt;/span&gt; I[&lt;span class="pl-c1"&gt;1&lt;/span&gt;]
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; is equivalent to&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; i, j &lt;span class="pl-k"&gt;in&lt;/span&gt; x:
  y[i, j &lt;span class="pl-k"&gt;+&lt;/span&gt; &lt;span class="pl-c1"&gt;1&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; i &lt;span class="pl-k"&gt;+&lt;/span&gt; j&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;(Nov 27, 2019) v0.1.5 released.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/yuanming-hu/taichi/issues/282"&gt;Better modular programming support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Disalow the use of &lt;code&gt;ti.static&lt;/code&gt; outside Taichi kernels&lt;/li&gt;
&lt;li&gt;Documentation improvements (WIP)&lt;/li&gt;
&lt;li&gt;Codegen bug fixes&lt;/li&gt;
&lt;li&gt;Special thanks to Andrew Spielberg and KLozes for bug report and feedback.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Nov 22, 2019) v0.1.3 released.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Object-oriented programming. &lt;a href="https://github.com/yuanming-hu/taichi/blob/master/tests/python/test_oop.py"&gt;[Example]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;native Python function translation in Taichi kernels:
&lt;ul&gt;
&lt;li&gt;Use &lt;code&gt;print&lt;/code&gt; instead of &lt;code&gt;ti.print&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;int()&lt;/code&gt; instead of &lt;code&gt;ti.cast(x, ti.i32)&lt;/code&gt; (or &lt;code&gt;ti.cast(x, ti.i64)&lt;/code&gt; if your default integer precision is 64 bit)&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;float()&lt;/code&gt; instead of &lt;code&gt;ti.cast(x, ti.f32)&lt;/code&gt; (or &lt;code&gt;ti.cast(x, ti.f64)&lt;/code&gt; if your default float-point precision is 64 bit)&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;abs&lt;/code&gt; instead of &lt;code&gt;ti.abs&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;ti.static_print&lt;/code&gt; for compile-time printing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Nov 16, 2019) v0.1.0 released. Fixed PyTorch interface.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Nov 12, 2019) v0.0.87 released.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Added experimental Windows support with a &lt;a href="https://github.com/yuanming-hu/taichi/issues/251"&gt;[known issue]&lt;/a&gt; regarding virtual memory allocation, which will potentially limit the scalability of Taichi programs (If you are a Windows expert, please let me know how to solve this. Thanks!). Most examples work on Windows now.&lt;/li&gt;
&lt;li&gt;CUDA march autodetection;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/yuanming-hu/taichi/blob/master/tests/python/test_complex_kernels.py"&gt;Complex kernel&lt;/a&gt; to override autodiff.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Nov 4, 2019) v0.0.85 released.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ti.stop_grad&lt;/code&gt; for stopping gradients during backpropagation. &lt;a href="https://github.com/yuanming-hu/taichi/blob/master/tests/python/test_stop_grad.py#L75"&gt;[Example]&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;Compatibility improvements on Linux and OS X;&lt;/li&gt;
&lt;li&gt;Minor bug fixes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Nov 1, 2019) v0.0.77 released.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Python wheels now support OS X 10.14+&lt;/strong&gt;;&lt;/li&gt;
&lt;li&gt;LLVM is now the default backend. No need to install &lt;code&gt;gcc-7&lt;/code&gt; or &lt;code&gt;clang-7&lt;/code&gt; anymore. To use legacy backends, &lt;code&gt;export TI_LLVM=0&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;LLVM compilation speed is improved by 2x;&lt;/li&gt;
&lt;li&gt;More friendly syntax error messages.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Oct 30, 2019) v0.0.72 released.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLVM GPU backend now as fast as the legacy (yet optimized) CUDA backend. To enable, &lt;code&gt;export TI_LLVM=1&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;Bug fixes: LLVM &lt;code&gt;struct for&lt;/code&gt; list generation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Oct 29, 2019) v0.0.71 released. LLVM GPU backend performance greatly improved. Frontend compiler now emits readable syntax error messages.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Oct 28, 2019) v0.0.70 released. This version comes with experimental LLVM backends for x86_64 and CUDA (via NVVM/PTX). GPU kernel compilation speed is improved by 10x. To enable, update the taichi package and &lt;code&gt;export TI_LLVM=1&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Oct 24, 2019) Python wheels (v0.0.61) released for Python 3.6/3.7 and CUDA 10.0/10.1 on Ubuntu 16.04+. Contributors of this release include &lt;em&gt;Yuanming Hu, robbertvc, Zhoutong Zhang, Tao Du, Srinivas Kaza, and Kenneth Lozes&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Oct 22, 2019) Added support for &lt;a href="https://github.com/yuanming-hu/taichi/blob/master/tests/python/test_kernel_templates.py"&gt;kernel templates&lt;/a&gt;. Kernel templates allow users to pass in taichi tensors and compile-time constants as kernel parameters.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Oct 9, 2019) Compatibility improvements. Added a basic PyTorch interface. &lt;a href="https://github.com/yuanming-hu/taichi/blob/master/examples/pytorch_tensor_ad.py"&gt;[Example]&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You still need to clone this repo for demo scripts under &lt;code&gt;examples&lt;/code&gt;. You &lt;em&gt;do not&lt;/em&gt; need to execute &lt;code&gt;install.py&lt;/code&gt; or &lt;code&gt;dev_setup.py&lt;/code&gt;.
After installation using &lt;code&gt;pip&lt;/code&gt; you can simply go to &lt;code&gt;examples&lt;/code&gt; and execute, e.g., &lt;code&gt;python3 mpm_fluid.py&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Make sure you clear your legacy Taichi installation (if applicable) by cleaning the environment variables (delete &lt;code&gt;TAICHI_REPO_DIR&lt;/code&gt;, and remove legacy taichi from &lt;code&gt;PYTHONPATH&lt;/code&gt;) in your &lt;code&gt;.bashrc&lt;/code&gt; or &lt;code&gt;.zshrc&lt;/code&gt;. Or you can simply do this in your shell to temporarily clear them:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;export PYTHONPATH=
export TAICHI_REPO_DIR=
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;&lt;a id="user-content-the-taichi-library-legacy-branch" class="anchor" aria-hidden="true" href="#the-taichi-library-legacy-branch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Taichi Library &lt;a href="https://github.com/yuanming-hu/taichi/tree/legacy"&gt;[Legacy branch]&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Taichi&lt;/strong&gt; is an open-source computer graphics library that aims to provide easy-to-use infrastructures for computer graphics R&amp;amp;D. It's written in C++14 and wrapped friendly with Python.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-news" class="anchor" aria-hidden="true" href="#news"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;News&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;May 17, 2019: &lt;a href="https://github.com/yuanming-hu/spgrid_topo_opt"&gt;Giga-Voxel SPGrid Topology Optimization Solver&lt;/a&gt; is released!&lt;/li&gt;
&lt;li&gt;March 4, 2019: &lt;a href="https://github.com/yuanming-hu/taichi_mpm"&gt;MLS-MPM/CPIC solver&lt;/a&gt; is now MIT-licensed!&lt;/li&gt;
&lt;li&gt;August 14, 2018: &lt;a href="https://github.com/yuanming-hu/taichi_mpm"&gt;MLS-MPM/CPIC solver&lt;/a&gt; reloaded! It delivers 4-14x performance boost over the previous state of the art on CPUs.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/yuanming-hu/public_files/raw/master/graphics/topopt/bird-beak.gif"&gt;&lt;img src="https://github.com/yuanming-hu/public_files/raw/master/graphics/topopt/bird-beak.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/water_wheel.gif"&gt;&lt;img src="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/water_wheel.gif" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/sand_paddles.gif"&gt;&lt;img src="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/sand_paddles.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/armodillo.gif"&gt;&lt;img src="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/armodillo.gif" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/debris_flow.gif"&gt;&lt;img src="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/debris_flow.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/sand-sweep.gif"&gt;&lt;img src="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/sand-sweep.gif" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/sand_stir.gif"&gt;&lt;img src="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/sand_stir.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/bunny.gif"&gt;&lt;img src="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/bunny.gif" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/robot_forward.gif"&gt;&lt;img src="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/robot_forward.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/banana.gif"&gt;&lt;img src="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/banana.gif" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/cheese.gif"&gt;&lt;img src="https://github.com/yuanming-hu/public_files/raw/master/graphics/mls-mpm-cpic/cheese.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started-legacy" class="anchor" aria-hidden="true" href="#getting-started-legacy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://taichi.readthedocs.io/en/latest/installation.html#" rel="nofollow"&gt;Getting Started (Legacy)&lt;/a&gt;&lt;/h2&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>yuanming-hu</author><guid isPermaLink="false">https://github.com/yuanming-hu/taichi</guid><pubDate>Sun, 05 Jan 2020 00:08:00 GMT</pubDate></item><item><title>godotengine/godot #9 in C++, Today</title><link>https://github.com/godotengine/godot</link><description>&lt;p&gt;&lt;i&gt;Godot Engine – Multi-platform 2D and 3D game engine&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://godotengine.org" rel="nofollow"&gt;&lt;img src="/logo.png" alt="Godot Engine logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-godot-engine" class="anchor" aria-hidden="true" href="#godot-engine"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Godot Engine&lt;/h2&gt;
&lt;p&gt;Homepage: &lt;a href="https://godotengine.org" rel="nofollow"&gt;https://godotengine.org&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-2d-and-3d-cross-platform-game-engine" class="anchor" aria-hidden="true" href="#2d-and-3d-cross-platform-game-engine"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2D and 3D cross-platform game engine&lt;/h4&gt;
&lt;p&gt;Godot Engine is a feature-packed, cross-platform game engine to create 2D and
3D games from a unified interface. It provides a comprehensive set of common
tools, so that users can focus on making games without having to reinvent the
wheel. Games can be exported in one click to a number of platforms, including
the major desktop platforms (Linux, Mac OSX, Windows) as well as mobile
(Android, iOS) and web-based (HTML5) platforms.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-free-open-source-and-community-driven" class="anchor" aria-hidden="true" href="#free-open-source-and-community-driven"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Free, open source and community-driven&lt;/h4&gt;
&lt;p&gt;Godot is completely free and open source under the very permissive MIT license.
No strings attached, no royalties, nothing. The users' games are theirs, down
to the last line of engine code. Godot's development is fully independent and
community-driven, empowering users to help shape their engine to match their
expectations. It is supported by the Software Freedom Conservancy
not-for-profit.&lt;/p&gt;
&lt;p&gt;Before being open sourced in February 2014, Godot had been developed by Juan
Linietsky and Ariel Manzur (both still maintaining the project) for several
years as an in-house engine, used to publish several work-for-hire titles.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/godotengine/godot-design/master/screenshots/editor_tps_demo_1920x1080.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/godotengine/godot-design/master/screenshots/editor_tps_demo_1920x1080.jpg" alt="Screenshot of a 3D scene in Godot Engine" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-getting-the-engine" class="anchor" aria-hidden="true" href="#getting-the-engine"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting the engine&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-binary-downloads" class="anchor" aria-hidden="true" href="#binary-downloads"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Binary downloads&lt;/h4&gt;
&lt;p&gt;Official binaries for the Godot editor and the export templates can be found
&lt;a href="https://godotengine.org/download" rel="nofollow"&gt;on the homepage&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-compiling-from-source" class="anchor" aria-hidden="true" href="#compiling-from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Compiling from source&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://docs.godotengine.org/en/latest/development/compiling/" rel="nofollow"&gt;See the official docs&lt;/a&gt;
for compilation instructions for every supported platform.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-community-and-contributing" class="anchor" aria-hidden="true" href="#community-and-contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community and contributing&lt;/h3&gt;
&lt;p&gt;Godot is not only an engine but an ever-growing community of users and engine
developers. The main community channels are listed &lt;a href="https://godotengine.org/community" rel="nofollow"&gt;on the homepage&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To get in touch with the developers, the best way is to join the
&lt;a href="https://webchat.freenode.net/?channels=godotengine" rel="nofollow"&gt;#godotengine IRC channel&lt;/a&gt;
on Freenode.&lt;/p&gt;
&lt;p&gt;To get started contributing to the project, see the &lt;a href="CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-documentation-and-demos" class="anchor" aria-hidden="true" href="#documentation-and-demos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation and demos&lt;/h3&gt;
&lt;p&gt;The official documentation is hosted on &lt;a href="https://docs.godotengine.org" rel="nofollow"&gt;ReadTheDocs&lt;/a&gt;.
It is maintained by the Godot community in its own &lt;a href="https://github.com/godotengine/godot-docs"&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://docs.godotengine.org/en/latest/classes/" rel="nofollow"&gt;class reference&lt;/a&gt;
is also accessible from within the engine.&lt;/p&gt;
&lt;p&gt;The official demos are maintained in their own &lt;a href="https://github.com/godotengine/godot-demo-projects"&gt;GitHub repository&lt;/a&gt;
as well.&lt;/p&gt;
&lt;p&gt;There are also a number of other learning resources provided by the community,
such as text and video tutorials, demos, etc. Consult the &lt;a href="https://godotengine.org/community" rel="nofollow"&gt;community channels&lt;/a&gt;
for more info.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/godotengine/godot" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1749bd189cb7e200d00f73c7aea7c12a81c51213/68747470733a2f2f7472617669732d63692e6f72672f676f646f74656e67696e652f676f646f742e7376673f6272616e63683d6d6173746572" alt="Travis Build Status" data-canonical-src="https://travis-ci.org/godotengine/godot.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/akien-mga/godot" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/26a2ec75e7db307fe6519108365c8b912d18753c/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6266696968717136627978736a7878682f6272616e63682f6d61737465723f7376673d74727565" alt="AppVeyor Build Status" data-canonical-src="https://ci.appveyor.com/api/projects/status/bfiihqq6byxsjxxh/branch/master?svg=true" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.codetriage.com/godotengine/godot" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6094dc9f409fe501c72fccae301f6cbc69f8746c/68747470733a2f2f7777772e636f64657472696167652e636f6d2f676f646f74656e67696e652f676f646f742f6261646765732f75736572732e737667" alt="Code Triagers Badge" data-canonical-src="https://www.codetriage.com/godotengine/godot/badges/users.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://hosted.weblate.org/engage/godot-engine/?utm_source=widget" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2124b3de8872ae25a95093b43a55c35dbbaee1d4/68747470733a2f2f686f737465642e7765626c6174652e6f72672f776964676574732f676f646f742d656e67696e652f2d2f676f646f742f7376672d62616467652e737667" alt="Translate on Weblate" data-canonical-src="https://hosted.weblate.org/widgets/godot-engine/-/godot/svg-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>godotengine</author><guid isPermaLink="false">https://github.com/godotengine/godot</guid><pubDate>Sun, 05 Jan 2020 00:09:00 GMT</pubDate></item><item><title>arangodb/arangodb #10 in C++, Today</title><link>https://github.com/arangodb/arangodb</link><description>&lt;p&gt;&lt;i&gt;🥑 ArangoDB is a native multi-model database with flexible data models for documents, graphs, and key-values. Build high performance applications using a convenient SQL-like query language or JavaScript extensions.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/9e418784696d446e6262ef6f17692469a0ef95ec/68747470733a2f2f7777772e6172616e676f64622e636f6d2f646f63732f6173736574732f6172616e676f64625f6c6f676f5f323031365f696e7665727465642e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/9e418784696d446e6262ef6f17692469a0ef95ec/68747470733a2f2f7777772e6172616e676f64622e636f6d2f646f63732f6173736574732f6172616e676f64625f6c6f676f5f323031365f696e7665727465642e706e67" alt="ArangoDB-Logo" data-canonical-src="https://www.arangodb.com/docs/assets/arangodb_logo_2016_inverted.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-arangodb" class="anchor" aria-hidden="true" href="#arangodb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ArangoDB&lt;/h1&gt;
&lt;p&gt;Slack: &lt;a href="https://slack.arangodb.com" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/24f456f40a69964c235102cc16dfb16518a9328d/68747470733a2f2f736c61636b2e6172616e676f64622e636f6d2f62616467652e737667" alt="ArangoDB-Logo" data-canonical-src="https://slack.arangodb.com/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ArangoDB is a multi-model, open-source database with flexible data models for
documents, graphs, and key-values. Build high performance applications using a
convenient SQL-like query language or JavaScript extensions. Use ACID
transactions if you require them. Scale horizontally with a few mouse clicks.&lt;/p&gt;
&lt;p&gt;The supported data models can be mixed in queries and allow ArangoDB to be the
aggregation point for your data.&lt;/p&gt;
&lt;p&gt;Check out our &lt;a href="https://www.arangodb.com/arangodb-training-center/" rel="nofollow"&gt;training center&lt;/a&gt;
to get started and see the full &lt;a href="https://www.arangodb.com/docs/stable/" rel="nofollow"&gt;documentation&lt;/a&gt;
to dive deeper.&lt;/p&gt;
&lt;p&gt;For the impatient:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Start the ArangoDB Docker container&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -e ARANGO_ROOT_PASSWORD=test123 -p 8529:8529 -d arangodb/arangodb
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Alternatively, &lt;a href="https://www.arangodb.com/download" rel="nofollow"&gt;download&lt;/a&gt; and install ArangoDB.
Start the server &lt;code&gt;arangod&lt;/code&gt; if the installer did not do it for you.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Point your browser to &lt;code&gt;http://127.0.0.1:8529/&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-key-features-in-arangodb" class="anchor" aria-hidden="true" href="#key-features-in-arangodb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Key Features in ArangoDB&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multi-Model&lt;/strong&gt;: Documents, graphs and key-value pairs — model your data as
you see fit for your application.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Joins&lt;/strong&gt;: Conveniently join what belongs together for flexible ad-hoc
querying, less data redundancy.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transactions&lt;/strong&gt;: Easy application development keeping your data consistent
and safe. No hassle in your client.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is an AQL query that makes use of all those features:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/189b21a0744574f9f4cf94e60a8db8c8571c66a7/68747470733a2f2f7777772e6172616e676f64622e636f6d2f646f63732f6173736574732f61716c5f71756572795f776974685f74726176657273616c2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/189b21a0744574f9f4cf94e60a8db8c8571c66a7/68747470733a2f2f7777772e6172616e676f64622e636f6d2f646f63732f6173736574732f61716c5f71756572795f776974685f74726176657273616c2e706e67" alt="AQL Query Example" data-canonical-src="https://www.arangodb.com/docs/assets/aql_query_with_traversal.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Joins and transactions are key features for flexible, secure data designs,
widely used in relational databases but lacking in many NoSQL products. However,
there is no need to forgo them in ArangoDB. You decide how and when to use joins
and strong consistency guarantees, without sacrificing performance and scalability.&lt;/p&gt;
&lt;p&gt;Furthermore, ArangoDB offers a JavaScript framework called &lt;a href="https://www.arangodb.com/foxx" rel="nofollow"&gt;Foxx&lt;/a&gt;
that is executed in the database server with direct access to the data. Build your
own data-centric microservices with a few lines of code. By extending the HTTP API
with user code written in JavaScript, ArangoDB can be turned into a strict
schema-enforcing persistence engine.&lt;/p&gt;
&lt;p&gt;Other features of ArangoDB include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use a &lt;strong&gt;data-centric microservices&lt;/strong&gt; approach with ArangoDB Foxx and fuse your
application-logic and database together for maximal throughput&lt;/li&gt;
&lt;li&gt;JavaScript for all: &lt;strong&gt;no language zoo&lt;/strong&gt;, you can use one language from your
browser to your back-end&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flexible data modeling&lt;/strong&gt;: model your data as combination of key-value pairs,
documents or graphs - perfect for social relations&lt;/li&gt;
&lt;li&gt;Different &lt;strong&gt;storage engines&lt;/strong&gt;: ArangoDB provides a storage engine for mostly
in-memory operations and an alternative storage engine based on RocksDB which
handle datasets that are much bigger than RAM.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Powerful query language&lt;/strong&gt; (AQL) to retrieve and modify data&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transactions&lt;/strong&gt;: run queries on multiple documents or collections with
optional transactional consistency and isolation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Replication&lt;/strong&gt; and &lt;strong&gt;Sharding&lt;/strong&gt;: set up the database in a master-slave
configuration or spread bigger datasets across multiple servers&lt;/li&gt;
&lt;li&gt;Configurable &lt;strong&gt;durability&lt;/strong&gt;: let the application decide if it needs more
durability or more performance&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Schema-free schemata&lt;/strong&gt; let you combine the space efficiency of MySQL with the
performance power of NoSQL&lt;/li&gt;
&lt;li&gt;Free &lt;strong&gt;index choice&lt;/strong&gt;: use the correct index for your problem, be it a skiplist
or a fulltext search&lt;/li&gt;
&lt;li&gt;ArangoDB is &lt;strong&gt;multi-threaded&lt;/strong&gt; - exploit the power of all your cores&lt;/li&gt;
&lt;li&gt;It is &lt;strong&gt;open source&lt;/strong&gt; (Apache License 2.0)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more in-depth information read the
&lt;a href="https://www.arangodb.com/2012/03/avocadodbs-design-objectives/" rel="nofollow"&gt;design goals of ArangoDB&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-latest-release" class="anchor" aria-hidden="true" href="#latest-release"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latest Release&lt;/h2&gt;
&lt;p&gt;Packages for all supported platforms can be downloaded from
&lt;a href="https://www.arangodb.com/download/" rel="nofollow"&gt;https://www.arangodb.com/download&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Please also check &lt;a href="https://www.arangodb.com/docs/stable/release-notes.html" rel="nofollow"&gt;what's new in ArangoDB&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-more-information" class="anchor" aria-hidden="true" href="#more-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More Information&lt;/h2&gt;
&lt;p&gt;See our documentation for detailed
&lt;a href="https://www.arangodb.com/docs/stable/installation.html" rel="nofollow"&gt;installation &amp;amp; compilation instructions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There is an &lt;a href="https://www.arangodb.com/docs/stable/getting-started.html" rel="nofollow"&gt;introductory chapter&lt;/a&gt;
showing the basic operation of ArangoDB. To learn ArangoDB's query language check out the
&lt;a href="https://www.arangodb.com/docs/stable/aql/tutorial.html" rel="nofollow"&gt;AQL tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-stay-in-contact" class="anchor" aria-hidden="true" href="#stay-in-contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stay in Contact&lt;/h2&gt;
&lt;p&gt;We really appreciate feature requests and bug reports. Please use our Github
issue tracker for reporting them:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/arangodb/arangodb/issues"&gt;https://github.com/arangodb/arangodb/issues&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can use our Google group for improvements, feature requests, comments:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.arangodb.com/community" rel="nofollow"&gt;https://www.arangodb.com/community&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;StackOverflow is great for questions about AQL, usage scenarios etc.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://stackoverflow.com/questions/tagged/arangodb" rel="nofollow"&gt;https://stackoverflow.com/questions/tagged/arangodb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To chat with the community and the developers we offer a Slack chat:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://slack.arangodb.com/" rel="nofollow"&gt;https://slack.arangodb.com/&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>arangodb</author><guid isPermaLink="false">https://github.com/arangodb/arangodb</guid><pubDate>Sun, 05 Jan 2020 00:10:00 GMT</pubDate></item><item><title>apache/incubator-brpc #11 in C++, Today</title><link>https://github.com/apache/incubator-brpc</link><description>&lt;p&gt;&lt;i&gt;Industrial-grade RPC framework used throughout Baidu, with 1,000,000+ instances and thousands kinds of services, called "baidu-rpc" inside Baidu.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="README_cn.md"&gt;中文版&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/apache/incubator-brpc" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e88aa1ae483b2db6a86c8c0d5005f6d39613207b/68747470733a2f2f7472617669732d63692e6f72672f6170616368652f696e63756261746f722d627270632e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/apache/incubator-brpc.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="" class="anchor" aria-hidden="true" href="#"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a target="_blank" rel="noopener noreferrer" href="docs/images/logo.png"&gt;&lt;img src="docs/images/logo.png" alt="brpc" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;An industrial-grade RPC framework used throughout &lt;a href="http://ir.baidu.com/phoenix.zhtml?c=188488&amp;amp;p=irol-irhome" rel="nofollow"&gt;Baidu&lt;/a&gt;, with 1,000,000+ instances(not counting clients) and thousands kinds of services, called "&lt;strong&gt;baidu-rpc&lt;/strong&gt;" inside Baidu. Only C++ implementation is opensourced right now.&lt;/p&gt;
&lt;p&gt;You can use it to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Build a server that can talk in multiple protocols (&lt;strong&gt;on same port&lt;/strong&gt;), or access all sorts of services
&lt;ul&gt;
&lt;li&gt;restful http/https, &lt;a href="https://http2.github.io/http2-spec" rel="nofollow"&gt;h2&lt;/a&gt;/&lt;a href="https://grpc.io" rel="nofollow"&gt;gRPC&lt;/a&gt;. using http/h2 in brpc is much more friendly than &lt;a href="https://curl.haxx.se/libcurl/" rel="nofollow"&gt;libcurl&lt;/a&gt;. Access protobuf-based protocols with HTTP/h2+json, probably from another language.&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/redis_client.md"&gt;redis&lt;/a&gt; and &lt;a href="docs/en/memcache_client.md"&gt;memcached&lt;/a&gt;, thread-safe, more friendly and performant than the official clients.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/brpc/brpc/blob/master/src/brpc/rtmp.h"&gt;rtmp&lt;/a&gt;/&lt;a href="https://en.wikipedia.org/wiki/Flash_Video" rel="nofollow"&gt;flv&lt;/a&gt;/&lt;a href="https://en.wikipedia.org/wiki/HTTP_Live_Streaming" rel="nofollow"&gt;hls&lt;/a&gt;, for building &lt;a href="https://github.com/brpc/media-server"&gt;streaming services&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;hadoop_rpc (may be opensourced)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Remote_direct_memory_access" rel="nofollow"&gt;rdma&lt;/a&gt; support (will be opensourced)&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/thrift.md"&gt;thrift&lt;/a&gt; support,  thread-safe, more friendly and performant than the official clients.&lt;/li&gt;
&lt;li&gt;all sorts of protocols used in Baidu: &lt;a href="docs/cn/baidu_std.md"&gt;baidu_std&lt;/a&gt;, &lt;a href="docs/en/streaming_rpc.md"&gt;streaming_rpc&lt;/a&gt;, hulu_pbrpc, &lt;a href="https://github.com/baidu/sofa-pbrpc"&gt;sofa_pbrpc&lt;/a&gt;, nova_pbrpc, public_pbrpc, ubrpc and nshead-based ones.&lt;/li&gt;
&lt;li&gt;Build &lt;a href="https://en.wikipedia.org/wiki/High_availability" rel="nofollow"&gt;HA&lt;/a&gt; distributed services using an industrial-grade implementation of &lt;a href="https://raft.github.io" rel="nofollow"&gt;RAFT consensus algorithm&lt;/a&gt; which is opensourced at &lt;a href="https://github.com/brpc/braft"&gt;braft&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Servers can handle requests &lt;a href="docs/en/server.md"&gt;synchronously&lt;/a&gt; or &lt;a href="docs/en/server.md#asynchronous-service"&gt;asynchronously&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Clients can access servers &lt;a href="docs/en/client.md#synchronus-call"&gt;synchronously&lt;/a&gt;, &lt;a href="docs/en/client.md#asynchronous-call"&gt;asynchronously&lt;/a&gt;, &lt;a href="docs/en/client.md#semi-synchronous-call"&gt;semi-synchronously&lt;/a&gt;, or use &lt;a href="docs/en/combo_channel.md"&gt;combo channels&lt;/a&gt; to simplify sharded or parallel accesses declaratively.&lt;/li&gt;
&lt;li&gt;Debug services &lt;a href="docs/en/builtin_service.md"&gt;via http&lt;/a&gt;, and run  &lt;a href="docs/cn/cpu_profiler.md"&gt;cpu&lt;/a&gt;, &lt;a href="docs/cn/heap_profiler.md"&gt;heap&lt;/a&gt; and &lt;a href="docs/cn/contention_profiler.md"&gt;contention&lt;/a&gt; profilers.&lt;/li&gt;
&lt;li&gt;Get &lt;a href="docs/en/overview.md#better-latency-and-throughput"&gt;better latency and throughput&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/new_protocol.md"&gt;Extend brpc&lt;/a&gt; with the protocols used in your organization quickly, or customize components, including &lt;a href="docs/cn/load_balancing.md#%E5%91%BD%E5%90%8D%E6%9C%8D%E5%8A%A1"&gt;naming services&lt;/a&gt; (dns, zk, etcd), &lt;a href="docs/cn/load_balancing.md#%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1"&gt;load balancers&lt;/a&gt; (rr, random, consistent hashing)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-try-it" class="anchor" aria-hidden="true" href="#try-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Try it!&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Read &lt;a href="docs/en/overview.md"&gt;overview&lt;/a&gt; to know where brpc can be used and its advantages.&lt;/li&gt;
&lt;li&gt;Read &lt;a href="docs/cn/getting_started.md"&gt;getting started&lt;/a&gt; for building steps and play with &lt;a href="https://github.com/brpc/brpc/tree/master/example/"&gt;examples&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Docs:
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/cn/benchmark.md"&gt;Performance benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/bvar.md"&gt;bvar&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/cn/bvar_c++.md"&gt;bvar_c++&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/bthread.md"&gt;bthread&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/cn/bthread_or_not.md"&gt;bthread or not&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/thread_local.md"&gt;thread-local&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/execution_queue.md"&gt;Execution Queue&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Client
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/en/client.md"&gt;Basics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/error_code.md"&gt;Error code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/combo_channel.md"&gt;Combo channels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/http_client.md"&gt;Access http/h2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/http_derivatives.md#h2grpc"&gt;Access gRPC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/thrift.md#client-accesses-thrift-server"&gt;Access thrift&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/ub_client.md"&gt;Access UB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/streaming_rpc.md"&gt;Streaming RPC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/redis_client.md"&gt;Access redis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/memcache_client.md"&gt;Access memcached&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/backup_request.md"&gt;Backup request&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/dummy_server.md"&gt;Dummy server&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Server
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/en/server.md"&gt;Basics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/http_service.md"&gt;Serve http/h2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/http_derivatives.md#h2grpc"&gt;Serve gRPC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/thrift.md#server-processes-thrift-requests"&gt;Serve thrift&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/nshead_service.md"&gt;Serve Nshead&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/server_debugging.md"&gt;Debug server issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/server_push.md"&gt;Server push&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/avalanche.md"&gt;Avalanche&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/auto_concurrency_limiter.md"&gt;Auto ConcurrencyLimiter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/brpc/media-server"&gt;Media Server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/json2pb.md"&gt;json2pb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/builtin_service.md"&gt;Builtin Services&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/en/status.md"&gt;status&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/vars.md"&gt;vars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/connections.md"&gt;connections&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/flags.md"&gt;flags&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/rpcz.md"&gt;rpcz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/cpu_profiler.md"&gt;cpu_profiler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/heap_profiler.md"&gt;heap_profiler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/contention_profiler.md"&gt;contention_profiler&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tools
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/cn/rpc_press.md"&gt;rpc_press&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/rpc_replay.md"&gt;rpc_replay&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/rpc_view.md"&gt;rpc_view&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/benchmark_http.md"&gt;benchmark_http&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/parallel_http.md"&gt;parallel_http&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Others
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/en/iobuf.md"&gt;IOBuf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/streaming_log.md"&gt;Streaming Log&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/flatmap.md"&gt;FlatMap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/brpc_intro.pptx"&gt;brpc外功修炼宝典&lt;/a&gt;(training material)&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/tutorial_on_building_services.pptx"&gt;A tutorial on building large-scale services&lt;/a&gt;(training material)&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/brpc_internal.pptx"&gt;brpc internal&lt;/a&gt;(training material)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RPC in depth
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/en/new_protocol.md"&gt;New Protocol&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/atomic_instructions.md"&gt;Atomic instructions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/io.md"&gt;IO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en/threading_overview.md"&gt;Threading Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/load_balancing.md"&gt;Load Balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/lalb.md"&gt;Locality-aware&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/consistent_hashing.md"&gt;Consistent Hashing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/memory_management.md"&gt;Memory Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/timer_keeping.md"&gt;Timer keeping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/bthread_id.md"&gt;bthread_id&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use cases inside Baidu
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/cn/case_apicontrol.md"&gt;百度地图api入口&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/case_baidu_dsp.md"&gt;联盟DSP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/case_elf.md"&gt;ELF学习框架&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/cn/case_ubrpc.md"&gt;云平台代理服务&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-contribute-code" class="anchor" aria-hidden="true" href="#contribute-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribute code&lt;/h1&gt;
&lt;p&gt;Please refer to &lt;a href="CONTRIBUTING.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-feedback-and-getting-involved" class="anchor" aria-hidden="true" href="#feedback-and-getting-involved"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Feedback and Getting involved&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Report bugs, ask questions or give suggestions by &lt;a href="https://github.com/apache/incubator-brpc/issues"&gt;Github Issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Subscribe mailing list(&lt;a href="mailto:dev-subscribe@brpc.apache.org"&gt;dev-subscribe@brpc.apache.org&lt;/a&gt;) to get updated with the project&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>apache</author><guid isPermaLink="false">https://github.com/apache/incubator-brpc</guid><pubDate>Sun, 05 Jan 2020 00:11:00 GMT</pubDate></item><item><title>onnx/onnx-tensorrt #12 in C++, Today</title><link>https://github.com/onnx/onnx-tensorrt</link><description>&lt;p&gt;&lt;i&gt;ONNX-TensorRT: TensorRT backend for ONNX&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorrt-backend-for-onnx" class="anchor" aria-hidden="true" href="#tensorrt-backend-for-onnx"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorRT backend for ONNX&lt;/h1&gt;
&lt;p&gt;Parses ONNX models for execution with &lt;a href="https://developer.nvidia.com/tensorrt" rel="nofollow"&gt;TensorRT&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;See also the &lt;a href="https://docs.nvidia.com/deeplearning/sdk/#inference" rel="nofollow"&gt;TensorRT documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-supported-tensorrt-versions" class="anchor" aria-hidden="true" href="#supported-tensorrt-versions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Supported TensorRT Versions&lt;/h2&gt;
&lt;p&gt;Development on the Master branch is for the latest version of &lt;a href="https://developer.nvidia.com/nvidia-tensorrt-download" rel="nofollow"&gt;TensorRT 7.0&lt;/a&gt; with full-dimensions and dynamic shape support.&lt;/p&gt;
&lt;p&gt;For previous versions of TensorRT, refer to their respective branches.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-full-dimensions--dynamic-shapes" class="anchor" aria-hidden="true" href="#full-dimensions--dynamic-shapes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Full Dimensions + Dynamic Shapes&lt;/h2&gt;
&lt;p&gt;Building INetwork objects in full dimensions mode with dynamic shape support requires calling the following API:&lt;/p&gt;
&lt;p&gt;C++&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const auto explicitBatch = 1U &amp;lt;&amp;lt; static_cast&amp;lt;uint32_t&amp;gt;(nvinfer1::NetworkDefinitionCreationFlag::kEXPLICIT_BATCH);
builder-&amp;gt;createNetworkV2(explicitBatch)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Python&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import tensorrt
explicit_batch = 1 &amp;lt;&amp;lt; (int)(tensorrt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)
builder.create_network(explicit_batch)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For examples of usage of these APIs see:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/NVIDIA/TensorRT/tree/master/samples/opensource/sampleOnnxMNIST"&gt;sampleONNXMNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/NVIDIA/TensorRT/tree/master/samples/opensource/sampleDynamicReshape"&gt;sampleDynamicReshape&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-supported-operators" class="anchor" aria-hidden="true" href="#supported-operators"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Supported Operators&lt;/h2&gt;
&lt;p&gt;Current supported ONNX operators are found in the &lt;a href="operators.md"&gt;operator support matrix&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h1&gt;
&lt;h3&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/google/protobuf/releases"&gt;Protobuf &amp;gt;= 3.8.x&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.nvidia.com/tensorrt" rel="nofollow"&gt;TensorRT 7.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/NVIDIA/TensorRT/"&gt;TensorRT 7.0 open source libaries (master branch)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-building" class="anchor" aria-hidden="true" href="#building"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building&lt;/h3&gt;
&lt;p&gt;For building on master, we recommend following the instructions on the &lt;a href="https://github.com/NVIDIA/TensorRT/"&gt;master branch of TensorRT&lt;/a&gt; as there are new dependencies that were introduced to support these new features.&lt;/p&gt;
&lt;p&gt;To build on older branches refer to their respective READMEs.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-executable-usage" class="anchor" aria-hidden="true" href="#executable-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Executable usage&lt;/h2&gt;
&lt;p&gt;ONNX models can be converted to serialized TensorRT engines using the &lt;code&gt;onnx2trt&lt;/code&gt; executable:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;onnx2trt my_model.onnx -o my_engine.trt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ONNX models can also be converted to human-readable text:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;onnx2trt my_model.onnx -t my_model.onnx.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See more usage information by running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;onnx2trt -h
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-python-modules" class="anchor" aria-hidden="true" href="#python-modules"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python modules&lt;/h3&gt;
&lt;p&gt;Python bindings for the ONNX-TensorRT parser are packaged in the shipped &lt;code&gt;.whl&lt;/code&gt; files. Install them with&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install &amp;lt;tensorrt_install_dir&amp;gt;/python/tensorrt-7.x.x.x-cp27-none-linux_x86_64.whl
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;TensorRT 7.0 supports ONNX release 1.6.0. Install it with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install onnx==1.6.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-onnx-python-backend-usage" class="anchor" aria-hidden="true" href="#onnx-python-backend-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ONNX Python backend usage&lt;/h2&gt;
&lt;p&gt;The TensorRT backend for ONNX can be used in Python as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; onnx
&lt;span class="pl-k"&gt;import&lt;/span&gt; onnx_tensorrt.backend &lt;span class="pl-k"&gt;as&lt;/span&gt; backend
&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np

model &lt;span class="pl-k"&gt;=&lt;/span&gt; onnx.load(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;/path/to/model.onnx&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
engine &lt;span class="pl-k"&gt;=&lt;/span&gt; backend.prepare(model, &lt;span class="pl-v"&gt;device&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;CUDA:1&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
input_data &lt;span class="pl-k"&gt;=&lt;/span&gt; np.random.random(&lt;span class="pl-v"&gt;size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(&lt;span class="pl-c1"&gt;32&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-c1"&gt;224&lt;/span&gt;, &lt;span class="pl-c1"&gt;224&lt;/span&gt;)).astype(np.float32)
output_data &lt;span class="pl-k"&gt;=&lt;/span&gt; engine.run(input_data)[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]
&lt;span class="pl-c1"&gt;print&lt;/span&gt;(output_data)
&lt;span class="pl-c1"&gt;print&lt;/span&gt;(output_data.shape)&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-c-library-usage" class="anchor" aria-hidden="true" href="#c-library-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;C++ library usage&lt;/h2&gt;
&lt;p&gt;The model parser library, libnvonnxparser.so, has its C++ API declared in this header:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NvOnnxParser.h
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-docker-image" class="anchor" aria-hidden="true" href="#docker-image"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker image&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-tar-based-tensorrt" class="anchor" aria-hidden="true" href="#tar-based-tensorrt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tar-Based TensorRT&lt;/h4&gt;
&lt;p&gt;Build the onnx_tensorrt Docker image using tar-based TensorRT by running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone --recurse-submodules https://github.com/onnx/onnx-tensorrt.git
cd onnx-tensorrt
cp /path/to/TensorRT-7.x.x.tar.gz .
docker build -f docker/onnx-tensorrt-tar.Dockerfile --tag=onnx-tensorrt:7.x.x .
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-deb-based-tensorrt" class="anchor" aria-hidden="true" href="#deb-based-tensorrt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deb-Based TensorRT&lt;/h4&gt;
&lt;p&gt;Build the onnx_tensorrt Docker image using deb-based TensorRT by running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone --recurse-submodules https://github.com/onnx/onnx-tensorrt.git
cd onnx-tensorrt
cp /path/to/nv-tensorrt-repo-ubuntu1x04-cudax.x-trt7.x.x.x-ga-yyyymmdd_1-1_amd64.deb .
docker build -f docker/onnx-tensorrt-deb.Dockerfile --tag=onnx-tensorrt:7.x.x.x .
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-tests" class="anchor" aria-hidden="true" href="#tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tests&lt;/h3&gt;
&lt;p&gt;After installation (or inside the Docker container), ONNX backend tests can be run as follows:&lt;/p&gt;
&lt;p&gt;Real model tests only:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python onnx_backend_test.py OnnxBackendRealModelTest
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All tests:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python onnx_backend_test.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can use &lt;code&gt;-v&lt;/code&gt; flag to make output more verbose.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pre-trained-models" class="anchor" aria-hidden="true" href="#pre-trained-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pre-trained models&lt;/h2&gt;
&lt;p&gt;Pre-trained models in ONNX format can be found at the &lt;a href="https://github.com/onnx/models"&gt;ONNX Model Zoo&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>onnx</author><guid isPermaLink="false">https://github.com/onnx/onnx-tensorrt</guid><pubDate>Sun, 05 Jan 2020 00:12:00 GMT</pubDate></item><item><title>gperftools/gperftools #13 in C++, Today</title><link>https://github.com/gperftools/gperftools</link><description>&lt;p&gt;&lt;i&gt;Main gperftools repository&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="" data-path="README"&gt;&lt;div class="plain"&gt;&lt;pre style="white-space: pre-wrap"&gt;gperftools
----------
(originally Google Performance Tools)

The fastest malloc we’ve seen; works particularly well with threads
and STL. Also: thread-friendly heap-checker, heap-profiler, and
cpu-profiler.


OVERVIEW
---------

gperftools is a collection of a high-performance multi-threaded
malloc() implementation, plus some pretty nifty performance analysis
tools.

gperftools is distributed under the terms of the BSD License. Join our
mailing list at gperftools@googlegroups.com for updates:
&lt;a href="https://groups.google.com/forum/#!forum/gperftools" rel="nofollow"&gt;https://groups.google.com/forum/#!forum/gperftools&lt;/a&gt;

gperftools was original home for pprof program. But do note that
original pprof (which is still included with gperftools) is now
deprecated in favor of golang version at &lt;a href="https://github.com/google/pprof"&gt;https://github.com/google/pprof&lt;/a&gt;


TCMALLOC
--------
Just link in -ltcmalloc or -ltcmalloc_minimal to get the advantages of
tcmalloc -- a replacement for malloc and new.  See below for some
environment variables you can use with tcmalloc, as well.

tcmalloc functionality is available on all systems we've tested; see
INSTALL for more details.  See README_windows.txt for instructions on
using tcmalloc on Windows.

NOTE: When compiling with programs with gcc, that you plan to link
with libtcmalloc, it's safest to pass in the flags

 -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free

when compiling.  gcc makes some optimizations assuming it is using its
own, built-in malloc; that assumption obviously isn't true with
tcmalloc.  In practice, we haven't seen any problems with this, but
the expected risk is highest for users who register their own malloc
hooks with tcmalloc (using gperftools/malloc_hook.h).  The risk is
lowest for folks who use tcmalloc_minimal (or, of course, who pass in
the above flags :-) ).


HEAP PROFILER
-------------
See docs/heapprofile.html for information about how to use tcmalloc's
heap profiler and analyze its output.

As a quick-start, do the following after installing this package:

1) Link your executable with -ltcmalloc
2) Run your executable with the HEAPPROFILE environment var set:
     $ HEAPPROFILE=/tmp/heapprof &amp;lt;path/to/binary&amp;gt; [binary args]
3) Run pprof to analyze the heap usage
     $ pprof &amp;lt;path/to/binary&amp;gt; /tmp/heapprof.0045.heap  # run 'ls' to see options
     $ pprof --gv &amp;lt;path/to/binary&amp;gt; /tmp/heapprof.0045.heap

You can also use LD_PRELOAD to heap-profile an executable that you
didn't compile.

There are other environment variables, besides HEAPPROFILE, you can
set to adjust the heap-profiler behavior; c.f. "ENVIRONMENT VARIABLES"
below.

The heap profiler is available on all unix-based systems we've tested;
see INSTALL for more details.  It is not currently available on Windows.


HEAP CHECKER
------------
See docs/heap_checker.html for information about how to use tcmalloc's
heap checker.

In order to catch all heap leaks, tcmalloc must be linked *last* into
your executable.  The heap checker may mischaracterize some memory
accesses in libraries listed after it on the link line.  For instance,
it may report these libraries as leaking memory when they're not.
(See the source code for more details.)

Here's a quick-start for how to use:

As a quick-start, do the following after installing this package:

1) Link your executable with -ltcmalloc
2) Run your executable with the HEAPCHECK environment var set:
     $ HEAPCHECK=1 &amp;lt;path/to/binary&amp;gt; [binary args]

Other values for HEAPCHECK: normal (equivalent to "1"), strict, draconian

You can also use LD_PRELOAD to heap-check an executable that you
didn't compile.

The heap checker is only available on Linux at this time; see INSTALL
for more details.


CPU PROFILER
------------
See docs/cpuprofile.html for information about how to use the CPU
profiler and analyze its output.

As a quick-start, do the following after installing this package:

1) Link your executable with -lprofiler
2) Run your executable with the CPUPROFILE environment var set:
     $ CPUPROFILE=/tmp/prof.out &amp;lt;path/to/binary&amp;gt; [binary args]
3) Run pprof to analyze the CPU usage
     $ pprof &amp;lt;path/to/binary&amp;gt; /tmp/prof.out      # -pg-like text output
     $ pprof --gv &amp;lt;path/to/binary&amp;gt; /tmp/prof.out # really cool graphical output

There are other environment variables, besides CPUPROFILE, you can set
to adjust the cpu-profiler behavior; cf "ENVIRONMENT VARIABLES" below.

The CPU profiler is available on all unix-based systems we've tested;
see INSTALL for more details.  It is not currently available on Windows.

NOTE: CPU profiling doesn't work after fork (unless you immediately
      do an exec()-like call afterwards).  Furthermore, if you do
      fork, and the child calls exit(), it may corrupt the profile
      data.  You can use _exit() to work around this.  We hope to have
      a fix for both problems in the next release of perftools
      (hopefully perftools 1.2).


EVERYTHING IN ONE
-----------------
If you want the CPU profiler, heap profiler, and heap leak-checker to
all be available for your application, you can do:
   gcc -o myapp ... -lprofiler -ltcmalloc

However, if you have a reason to use the static versions of the
library, this two-library linking won't work:
   gcc -o myapp ... /usr/lib/libprofiler.a /usr/lib/libtcmalloc.a  # errors!

Instead, use the special libtcmalloc_and_profiler library, which we
make for just this purpose:
   gcc -o myapp ... /usr/lib/libtcmalloc_and_profiler.a


CONFIGURATION OPTIONS
---------------------
For advanced users, there are several flags you can pass to
'./configure' that tweak tcmalloc performance.  (These are in addition
to the environment variables you can set at runtime to affect
tcmalloc, described below.)  See the INSTALL file for details.


ENVIRONMENT VARIABLES
---------------------
The cpu profiler, heap checker, and heap profiler will lie dormant,
using no memory or CPU, until you turn them on.  (Thus, there's no
harm in linking -lprofiler into every application, and also -ltcmalloc
assuming you're ok using the non-libc malloc library.)

The easiest way to turn them on is by setting the appropriate
environment variables.  We have several variables that let you
enable/disable features as well as tweak parameters.

Here are some of the most important variables:

HEAPPROFILE=&amp;lt;pre&amp;gt; -- turns on heap profiling and dumps data using this prefix
HEAPCHECK=&amp;lt;type&amp;gt;  -- turns on heap checking with strictness 'type'
CPUPROFILE=&amp;lt;file&amp;gt; -- turns on cpu profiling and dumps data to this file.
PROFILESELECTED=1 -- if set, cpu-profiler will only profile regions of code
                     surrounded with ProfilerEnable()/ProfilerDisable().
CPUPROFILE_FREQUENCY=x-- how many interrupts/second the cpu-profiler samples.

PERFTOOLS_VERBOSE=&amp;lt;level&amp;gt; -- the higher level, the more messages malloc emits
MALLOCSTATS=&amp;lt;level&amp;gt;    -- prints memory-use stats at program-exit

For a full list of variables, see the documentation pages:
   docs/cpuprofile.html
   docs/heapprofile.html
   docs/heap_checker.html


COMPILING ON NON-LINUX SYSTEMS
------------------------------

Perftools was developed and tested on x86 Linux systems, and it works
in its full generality only on those systems.  However, we've
successfully ported much of the tcmalloc library to FreeBSD, Solaris
x86, and Darwin (Mac OS X) x86 and ppc; and we've ported the basic
functionality in tcmalloc_minimal to Windows.  See INSTALL for details.
See README_windows.txt for details on the Windows port.


PERFORMANCE
-----------

If you're interested in some third-party comparisons of tcmalloc to
other malloc libraries, here are a few web pages that have been
brought to our attention.  The first discusses the effect of using
various malloc libraries on OpenLDAP.  The second compares tcmalloc to
win32's malloc.
  &lt;a href="http://www.highlandsun.com/hyc/malloc/" rel="nofollow"&gt;http://www.highlandsun.com/hyc/malloc/&lt;/a&gt;
  &lt;a href="http://gaiacrtn.free.fr/articles/win32perftools.html" rel="nofollow"&gt;http://gaiacrtn.free.fr/articles/win32perftools.html&lt;/a&gt;

It's possible to build tcmalloc in a way that trades off faster
performance (particularly for deletes) at the cost of more memory
fragmentation (that is, more unusable memory on your system).  See the
INSTALL file for details.


OLD SYSTEM ISSUES
-----------------

When compiling perftools on some old systems, like RedHat 8, you may
get an error like this:
    ___tls_get_addr: symbol not found

This means that you have a system where some parts are updated enough
to support Thread Local Storage, but others are not.  The perftools
configure script can't always detect this kind of case, leading to
that error.  To fix it, just comment out (or delete) the line
   #define HAVE_TLS 1
in your config.h file before building.


64-BIT ISSUES
-------------

There are two issues that can cause program hangs or crashes on x86_64
64-bit systems, which use the libunwind library to get stack-traces.
Neither issue should affect the core tcmalloc library; they both
affect the perftools tools such as cpu-profiler, heap-checker, and
heap-profiler.

1) Some libc's -- at least glibc 2.4 on x86_64 -- have a bug where the
libc function dl_iterate_phdr() acquires its locks in the wrong
order.  This bug should not affect tcmalloc, but may cause occasional
deadlock with the cpu-profiler, heap-profiler, and heap-checker.
Its likeliness increases the more dlopen() commands an executable has.
Most executables don't have any, though several library routines like
getgrgid() call dlopen() behind the scenes.

2) On x86-64 64-bit systems, while tcmalloc itself works fine, the
cpu-profiler tool is unreliable: it will sometimes work, but sometimes
cause a segfault.  I'll explain the problem first, and then some
workarounds.

Note that this only affects the cpu-profiler, which is a
gperftools feature you must turn on manually by setting the
CPUPROFILE environment variable.  If you do not turn on cpu-profiling,
you shouldn't see any crashes due to perftools.

The gory details: The underlying problem is in the backtrace()
function, which is a built-in function in libc.
Backtracing is fairly straightforward in the normal case, but can run
into problems when having to backtrace across a signal frame.
Unfortunately, the cpu-profiler uses signals in order to register a
profiling event, so every backtrace that the profiler does crosses a
signal frame.

In our experience, the only time there is trouble is when the signal
fires in the middle of pthread_mutex_lock.  pthread_mutex_lock is
called quite a bit from system libraries, particularly at program
startup and when creating a new thread.

The solution: The dwarf debugging format has support for 'cfi
annotations', which make it easy to recognize a signal frame.  Some OS
distributions, such as Fedora and gentoo 2007.0, already have added
cfi annotations to their libc.  A future version of libunwind should
recognize these annotations; these systems should not see any
crashes.

Workarounds: If you see problems with crashes when running the
cpu-profiler, consider inserting ProfilerStart()/ProfilerStop() into
your code, rather than setting CPUPROFILE.  This will profile only
those sections of the codebase.  Though we haven't done much testing,
in theory this should reduce the chance of crashes by limiting the
signal generation to only a small part of the codebase.  Ideally, you
would not use ProfilerStart()/ProfilerStop() around code that spawns
new threads, or is otherwise likely to cause a call to
pthread_mutex_lock!

---
17 May 2011
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</description><author>gperftools</author><guid isPermaLink="false">https://github.com/gperftools/gperftools</guid><pubDate>Sun, 05 Jan 2020 00:13:00 GMT</pubDate></item><item><title>concerttttt/books #14 in C++, Today</title><link>https://github.com/concerttttt/books</link><description>&lt;p&gt;&lt;i&gt;book list&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-head-first-design-patterns" class="anchor" aria-hidden="true" href="#head-first-design-patterns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Head First Design Patterns&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-an-introduction-to-design-patterns-in-c-with-qt4" class="anchor" aria-hidden="true" href="#an-introduction-to-design-patterns-in-c-with-qt4"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;An Introduction to Design Patterns in C++ with Qt4&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-design-patterns-elements-of-reusable-object-oriented-software" class="anchor" aria-hidden="true" href="#design-patterns-elements-of-reusable-object-oriented-software"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Patterns: Elements of Reusable Object-Oriented Software&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-modern-c-design--generic-programming-and-design-patterns-applied" class="anchor" aria-hidden="true" href="#modern-c-design--generic-programming-and-design-patterns-applied"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Modern C++ Design--Generic Programming and Design Patterns Applied&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-an-introduction-to-design-patterns" class="anchor" aria-hidden="true" href="#an-introduction-to-design-patterns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;An Introduction to Design Patterns&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-design-patterns-by-example" class="anchor" aria-hidden="true" href="#design-patterns-by-example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Patterns by Example&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-operating-system-concepts-8th-edition" class="anchor" aria-hidden="true" href="#operating-system-concepts-8th-edition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Operating System Concepts 8th Edition&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-computer-system-a-programmers-perspective-2nd-edition" class="anchor" aria-hidden="true" href="#computer-system-a-programmers-perspective-2nd-edition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Computer System: A Programmer's Perspective 2nd Edition&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-modern-operating-systems-4th-edition" class="anchor" aria-hidden="true" href="#modern-operating-systems-4th-edition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Modern Operating Systems 4th Edition&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-pattern-recognition-and-machine-learning" class="anchor" aria-hidden="true" href="#pattern-recognition-and-machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pattern Recognition and Machine Learning&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-leetcode-cpp" class="anchor" aria-hidden="true" href="#leetcode-cpp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Leetcode-cpp&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-c-primer-5th-edition" class="anchor" aria-hidden="true" href="#c-primer-5th-edition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;C++ Primer 5th Edition&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-ivor-hortons-beginning-visual-c-2010" class="anchor" aria-hidden="true" href="#ivor-hortons-beginning-visual-c-2010"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ivor Horton's Beginning Visual C++ 2010&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-beginning-visual-c-2010" class="anchor" aria-hidden="true" href="#beginning-visual-c-2010"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Beginning Visual C# 2010&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-professional-c-2008" class="anchor" aria-hidden="true" href="#professional-c-2008"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Professional C# 2008&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-c-gui-programming-with-qt4-2nd-edition" class="anchor" aria-hidden="true" href="#c-gui-programming-with-qt4-2nd-edition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;C++ GUI Programming With Qt4 2nd Edition&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-the-c-standard-library-a-tutorial-and-reference" class="anchor" aria-hidden="true" href="#the-c-standard-library-a-tutorial-and-reference"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The C++ Standard Library: A Tutorial and Reference&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-professional-c" class="anchor" aria-hidden="true" href="#professional-c"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Professional C++&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-expert-c-programming-deep-secrets" class="anchor" aria-hidden="true" href="#expert-c-programming-deep-secrets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Expert C Programming: Deep Secrets&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-thinking-in-c" class="anchor" aria-hidden="true" href="#thinking-in-c"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Thinking in C++&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-effective-c" class="anchor" aria-hidden="true" href="#effective-c"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Effective C++&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-effective-stl" class="anchor" aria-hidden="true" href="#effective-stl"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Effective STL&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-moving-to-microsoft-visual-studio-2010" class="anchor" aria-hidden="true" href="#moving-to-microsoft-visual-studio-2010"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Moving to Microsoft Visual Studio 2010&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-dragon-book-compilers-principle-techniques-and-tools" class="anchor" aria-hidden="true" href="#dragon-book-compilers-principle-techniques-and-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dragon Book Compilers Principle Techniques and Tools&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-compiler-construction-principles-and-practice" class="anchor" aria-hidden="true" href="#compiler-construction-principles-and-practice"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Compiler Construction Principles and Practice&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-engineering-a-compiler-2nd-edition" class="anchor" aria-hidden="true" href="#engineering-a-compiler-2nd-edition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Engineering A Compiler 2nd Edition&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-parsing-techniques" class="anchor" aria-hidden="true" href="#parsing-techniques"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Parsing Techniques&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-algorithms-4th-edition-princeton-university" class="anchor" aria-hidden="true" href="#algorithms-4th-edition-princeton-university"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Algorithms 4th Edition Princeton University&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-digital-image-processing-gonzales" class="anchor" aria-hidden="true" href="#digital-image-processing-gonzales"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Digital Image Processing Gonzales&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-video-signal-processing" class="anchor" aria-hidden="true" href="#video-signal-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Video Signal Processing&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-image-analysis-and-pattern-recognition" class="anchor" aria-hidden="true" href="#image-analysis-and-pattern-recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image Analysis and Pattern Recognition&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-computer-vision-algorithms-and-applications" class="anchor" aria-hidden="true" href="#computer-vision-algorithms-and-applications"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Computer Vision Algorithms and Applications&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-computer-vision-a-modern-approach" class="anchor" aria-hidden="true" href="#computer-vision-a-modern-approach"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Computer Vision A Modern Approach&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-multiple-view-geometry-in-computer-vision" class="anchor" aria-hidden="true" href="#multiple-view-geometry-in-computer-vision"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Multiple View Geometry in Computer Vision&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-neural-networks-and-deep-learning" class="anchor" aria-hidden="true" href="#neural-networks-and-deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Neural Networks and Deep Learning&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-machine-learning" class="anchor" aria-hidden="true" href="#machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-统计学习方法" class="anchor" aria-hidden="true" href="#统计学习方法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;统计学习方法&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-c从入门到精通" class="anchor" aria-hidden="true" href="#c从入门到精通"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;C++从入门到精通&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-teach-yourself-java-in-21-days" class="anchor" aria-hidden="true" href="#teach-yourself-java-in-21-days"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Teach Yourself Java in 21 Days&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-beginning-java-7-jeff-frieson" class="anchor" aria-hidden="true" href="#beginning-java-7-jeff-frieson"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Beginning Java 7 Jeff Frieson&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-beginning-javascript-5th-edtion" class="anchor" aria-hidden="true" href="#beginning-javascript-5th-edtion"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Beginning JavaScript 5th Edtion&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-machine-learning-in-action" class="anchor" aria-hidden="true" href="#machine-learning-in-action"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning in Action&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-programming-collective-intelligence" class="anchor" aria-hidden="true" href="#programming-collective-intelligence"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Programming Collective Intelligence&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-artificial-intelligence-a-modern-approach" class="anchor" aria-hidden="true" href="#artificial-intelligence-a-modern-approach"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Artificial Intelligence A Modern Approach&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-the-elements-of-statistical-learning-data-mining-inference-and-prediction" class="anchor" aria-hidden="true" href="#the-elements-of-statistical-learning-data-mining-inference-and-prediction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Elements of Statistical Learning Data Mining Inference and Prediction&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-automate-the-boring-stuff-with-python" class="anchor" aria-hidden="true" href="#automate-the-boring-stuff-with-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Automate the boring stuff with python&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-机器学习-周志华" class="anchor" aria-hidden="true" href="#机器学习-周志华"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机器学习 周志华&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-cuda-c-programming-guide" class="anchor" aria-hidden="true" href="#cuda-c-programming-guide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;cuda c programming guide&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-cuda-by-example-an-introduction-to-general-purpose-gpu-programming" class="anchor" aria-hidden="true" href="#cuda-by-example-an-introduction-to-general-purpose-gpu-programming"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CUDA by example: an introduction to general purpose gpu programming&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-python-for-data-analysis" class="anchor" aria-hidden="true" href="#python-for-data-analysis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python for Data Analysis&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-the-pragmatic-programmer-from-journeyman-to-master" class="anchor" aria-hidden="true" href="#the-pragmatic-programmer-from-journeyman-to-master"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Pragmatic Programmer: From Journeyman to Master&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-code-complete" class="anchor" aria-hidden="true" href="#code-complete"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code Complete&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-introduction-to-algorithms-3rd-edition" class="anchor" aria-hidden="true" href="#introduction-to-algorithms-3rd-edition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction to Algorithms 3rd Edition&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-machine-learning-a-probabilistic-perspective" class="anchor" aria-hidden="true" href="#machine-learning-a-probabilistic-perspective"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning: A Probabilistic Perspective&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-python-network-programming" class="anchor" aria-hidden="true" href="#python-network-programming"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python Network Programming&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-python-cookbook" class="anchor" aria-hidden="true" href="#python-cookbook"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python Cookbook&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-core-python-programming" class="anchor" aria-hidden="true" href="#core-python-programming"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Core Python Programming&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-c-cookbook" class="anchor" aria-hidden="true" href="#c-cookbook"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;C++ Cookbook&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-the-art-of-computer-programming" class="anchor" aria-hidden="true" href="#the-art-of-computer-programming"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Art of Computer Programming&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-the-pragmatic-programmer" class="anchor" aria-hidden="true" href="#the-pragmatic-programmer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Pragmatic Programmer&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-the-aosa-book" class="anchor" aria-hidden="true" href="#the-aosa-book"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The aosa book&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-python-学习手册learning-python" class="anchor" aria-hidden="true" href="#python-学习手册learning-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python 学习手册(Learning Python)&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-structure-and-interpretation-of-computer-programs" class="anchor" aria-hidden="true" href="#structure-and-interpretation-of-computer-programs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Structure and Interpretation of Computer Programs&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-core-python-application-programming" class="anchor" aria-hidden="true" href="#core-python-application-programming"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Core Python Application Programming&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-c-标准库" class="anchor" aria-hidden="true" href="#c-标准库"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;C++ 标准库&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-windows-核心编程" class="anchor" aria-hidden="true" href="#windows-核心编程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;windows 核心编程&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-c-concurrency-in-action" class="anchor" aria-hidden="true" href="#c-concurrency-in-action"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;C++ concurrency in action&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-deep-learning-methods-and-applications" class="anchor" aria-hidden="true" href="#deep-learning-methods-and-applications"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning: Methods and Applications&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-machine-learning-1" class="anchor" aria-hidden="true" href="#machine-learning-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-machine-learning-an-algorithmic-perspective" class="anchor" aria-hidden="true" href="#machine-learning-an-algorithmic-perspective"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning An Algorithmic Perspective&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-speech-and-language-processing" class="anchor" aria-hidden="true" href="#speech-and-language-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speech and Language Processing&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-illustrated-c" class="anchor" aria-hidden="true" href="#illustrated-c"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Illustrated C#&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-beginning-microsoft-c" class="anchor" aria-hidden="true" href="#beginning-microsoft-c"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Beginning Microsoft C#&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-c-cookbook-1" class="anchor" aria-hidden="true" href="#c-cookbook-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;C# cookbook&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-database-principles-programming-and-performance" class="anchor" aria-hidden="true" href="#database-principles-programming-and-performance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database Principles Programming and Performance&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-stanford-cs231a-computer-vision-from-3d-reconstruction-to-recognition" class="anchor" aria-hidden="true" href="#stanford-cs231a-computer-vision-from-3d-reconstruction-to-recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stanford cs231a, computer vision, from 3d reconstruction to recognition&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-stanford-cs231b-the-cutting-edge-of-computer-vision" class="anchor" aria-hidden="true" href="#stanford-cs231b-the-cutting-edge-of-computer-vision"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stanford cs231b, the cutting edge of computer vision&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-stanford-cs231n-convolutional-neural-networks-for-visual-recognition" class="anchor" aria-hidden="true" href="#stanford-cs231n-convolutional-neural-networks-for-visual-recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stanford cs231n, convolutional neural networks for visual recognition&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-stanford-cs224-deep-learning-for-natural-language-processing" class="anchor" aria-hidden="true" href="#stanford-cs224-deep-learning-for-natural-language-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stanford cs224, deep learning for natural language processing&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-wwwdeeplearningbookorg-goodfellow" class="anchor" aria-hidden="true" href="#wwwdeeplearningbookorg-goodfellow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="http://www.deeplearningbook.org" rel="nofollow"&gt;www.deeplearningbook.org&lt;/a&gt;, Goodfellow.&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-httpwwwvisionbibcombibliographycontentshtml" class="anchor" aria-hidden="true" href="#httpwwwvisionbibcombibliographycontentshtml"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="http://www.visionbib.com/bibliography/contents.html" rel="nofollow"&gt;http://www.visionbib.com/bibliography/contents.html&lt;/a&gt;&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-computer-vision-models-learning-and-inferencehttpwwwcomputervisionmodelscom" class="anchor" aria-hidden="true" href="#computer-vision-models-learning-and-inferencehttpwwwcomputervisionmodelscom"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Computer vision: models, learning and inference:&lt;a href="http://www.computervisionmodels.com/" rel="nofollow"&gt;http://www.computervisionmodels.com/&lt;/a&gt;&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-learning-opencv" class="anchor" aria-hidden="true" href="#learning-opencv"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;learning opencv.&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-learning-cuda" class="anchor" aria-hidden="true" href="#learning-cuda"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;learning CUDA.&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-introduction-to-programming-using-java" class="anchor" aria-hidden="true" href="#introduction-to-programming-using-java"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;introduction to programming using java&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-learning-java" class="anchor" aria-hidden="true" href="#learning-java"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;learning java&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-learning-javascript" class="anchor" aria-hidden="true" href="#learning-javascript"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;learning javascript&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-the-boost-c-library" class="anchor" aria-hidden="true" href="#the-boost-c-library"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Boost C++ Library.&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-learning-opencv-3-httpwwwbogotobogocomcplusplusfilesoreilly20learning20opencvpdf" class="anchor" aria-hidden="true" href="#learning-opencv-3-httpwwwbogotobogocomcplusplusfilesoreilly20learning20opencvpdf"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;learning opencv 3 &lt;a href="http://www.bogotobogo.com/cplusplus/files/OReilly%20Learning%20OpenCV.pdf" rel="nofollow"&gt;http://www.bogotobogo.com/cplusplus/files/OReilly%20Learning%20OpenCV.pdf&lt;/a&gt;&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-beginning-c-6-programming-with-visual-studio-2015-professional-c-6-and-net-core-10-writing-high-performance-net-code-microsoft-netarchitecturing-applications-for-the-enterprise" class="anchor" aria-hidden="true" href="#beginning-c-6-programming-with-visual-studio-2015-professional-c-6-and-net-core-10-writing-high-performance-net-code-microsoft-netarchitecturing-applications-for-the-enterprise"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Beginning C# 6 Programming with Visual Studio 2015, Professional C# 6 and .Net Core 1.0, Writing High-Performance .Net Code. Microsoft .NET:Architecturing Applications for the Enterprise.&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-introduction-to-information-retrieval" class="anchor" aria-hidden="true" href="#introduction-to-information-retrieval"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction to information retrieval&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-neural-network-methods-for-natural-language-processing" class="anchor" aria-hidden="true" href="#neural-network-methods-for-natural-language-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Neural Network Methods for Natural Language Processing&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-deep-learning-with-keras" class="anchor" aria-hidden="true" href="#deep-learning-with-keras"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning With Keras&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-natural-language-processing-with-python" class="anchor" aria-hidden="true" href="#natural-language-processing-with-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Natural Language Processing With Python.&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-wwwacademiaedu" class="anchor" aria-hidden="true" href="#wwwacademiaedu"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="http://www.academia.edu" rel="nofollow"&gt;www.academia.edu&lt;/a&gt;&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-convex-optimization" class="anchor" aria-hidden="true" href="#convex-optimization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Convex optimization&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-introduction-to-operations-research" class="anchor" aria-hidden="true" href="#introduction-to-operations-research"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction to operations research&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-linear-programming" class="anchor" aria-hidden="true" href="#linear-programming"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linear programming&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-numerical-optimization" class="anchor" aria-hidden="true" href="#numerical-optimization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Numerical optimization&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-introduction-to-linear-optimization" class="anchor" aria-hidden="true" href="#introduction-to-linear-optimization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction to linear optimization&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-optimization-methods" class="anchor" aria-hidden="true" href="#optimization-methods"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Optimization methods&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-introduction-to-mathematical-programming" class="anchor" aria-hidden="true" href="#introduction-to-mathematical-programming"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction to mathematical programming&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-operations-research-an-introduciton" class="anchor" aria-hidden="true" href="#operations-research-an-introduciton"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Operations Research: An Introduciton&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-hands-on-machine-learning-with-scikit-learn-and-tensorflow-concept-tools-and-techniquies-to-build-intelligent-systems" class="anchor" aria-hidden="true" href="#hands-on-machine-learning-with-scikit-learn-and-tensorflow-concept-tools-and-techniquies-to-build-intelligent-systems"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hands on machine learning with scikit-learn and tensorflow: concept, tools and techniquies to build intelligent systems.&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-deep-learning-with-python-francois-chollet" class="anchor" aria-hidden="true" href="#deep-learning-with-python-francois-chollet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep learning with python, Francois Chollet&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-deep-learning-for-computer-vision" class="anchor" aria-hidden="true" href="#deep-learning-for-computer-vision"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning for Computer Vision&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-deep-learning-in-object-detection-and-recognition" class="anchor" aria-hidden="true" href="#deep-learning-in-object-detection-and-recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning in Object Detection and Recognition&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-domain-adaptation-in-computer-vision-applications" class="anchor" aria-hidden="true" href="#domain-adaptation-in-computer-vision-applications"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Domain Adaptation in Computer Vision Applications&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-computer-graphics-principles-and-practices" class="anchor" aria-hidden="true" href="#computer-graphics-principles-and-practices"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Computer Graphics Principles and Practices&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-fundamentals-of-computer-graphics" class="anchor" aria-hidden="true" href="#fundamentals-of-computer-graphics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fundamentals of Computer Graphics&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-opengl-coursera-computer-graphics" class="anchor" aria-hidden="true" href="#opengl-coursera-computer-graphics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;OpenGL, Coursera Computer Graphics&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-clean-architecure-a-craftsmans-guide-to-software-structure-and-design" class="anchor" aria-hidden="true" href="#clean-architecure-a-craftsmans-guide-to-software-structure-and-design"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Clean Architecure, A Craftsman's Guide To Software Structure And Design&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-design-data-insentive-applications" class="anchor" aria-hidden="true" href="#design-data-insentive-applications"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Data Insentive Applications&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-stanford-cs228-probalistic-graphical-modelsprinciples-and-techniques-cs229-machine-learning-cs229t-statistical-learning-theory" class="anchor" aria-hidden="true" href="#stanford-cs228-probalistic-graphical-modelsprinciples-and-techniques-cs229-machine-learning-cs229t-statistical-learning-theory"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stanford CS228, Probalistic Graphical Models:Principles and Techniques, CS229 Machine Learning, CS229T Statistical Learning Theory.&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-the-linux-command-line-the-linux-programming-interface" class="anchor" aria-hidden="true" href="#the-linux-command-line-the-linux-programming-interface"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Linux Command Line, The Linux Programming Interface&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-fluent-python" class="anchor" aria-hidden="true" href="#fluent-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fluent Python&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-probabilistic-graph-models-principles-and-techniques-coursera-specialization" class="anchor" aria-hidden="true" href="#probabilistic-graph-models-principles-and-techniques-coursera-specialization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Probabilistic Graph Models, Principles and Techniques, Coursera Specialization&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-cython-a-guide-for-programmers" class="anchor" aria-hidden="true" href="#cython-a-guide-for-programmers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cython A Guide for Programmers&lt;/h2&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>concerttttt</author><guid isPermaLink="false">https://github.com/concerttttt/books</guid><pubDate>Sun, 05 Jan 2020 00:14:00 GMT</pubDate></item><item><title>tesseract-ocr/tesseract #15 in C++, Today</title><link>https://github.com/tesseract-ocr/tesseract</link><description>&lt;p&gt;&lt;i&gt;Tesseract Open Source OCR Engine (main repository)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tesseract-ocr" class="anchor" aria-hidden="true" href="#tesseract-ocr"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tesseract OCR&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/tesseract-ocr/tesseract" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f977e557da0c774be0b7806b1a2e4dc438ac7e6f/68747470733a2f2f7472617669732d63692e6f72672f7465737365726163742d6f63722f7465737365726163742e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/tesseract-ocr/tesseract.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/zdenop/tesseract/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6fe400330c665a8a034c2910ae464ee9ff80d97b/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6d69616830696b667366306a333831392f6272616e63682f6d61737465723f7376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/miah0ikfsf0j3819/branch/master?svg=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="https://scan.coverity.com/projects/tesseract-ocr" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/636fdecb66629791150ed4b120fc958bed413583/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f7465737365726163742d6f63722f62616467652e737667" alt="Coverity Scan Build Status" data-canonical-src="https://scan.coverity.com/projects/tesseract-ocr/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/tesseract-ocr/tesseract/context:cpp" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2e984e6d985dd0ee49cc30e4d74674a065804e75/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f6370702f672f7465737365726163742d6f63722f7465737365726163742e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138" alt="Code Quality: Cpp" data-canonical-src="https://img.shields.io/lgtm/grade/cpp/g/tesseract-ocr/tesseract.svg?logo=lgtm&amp;amp;logoWidth=18" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/tesseract-ocr/tesseract/alerts" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/34d1fd3bea9f85c9b3e9c977881b500e8ed8b315/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f672f7465737365726163742d6f63722f7465737365726163742e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138" alt="Total Alerts" data-canonical-src="https://img.shields.io/lgtm/alerts/g/tesseract-ocr/tesseract.svg?logo=lgtm&amp;amp;logoWidth=18" style="max-width:100%;"&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="https://raw.githubusercontent.com/tesseract-ocr/tesseract/master/LICENSE" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3a4d3bc039085cffdfecbe3077ffe49c5fe23286/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4170616368652d2d322e302d626c75652e737667" alt="GitHub license" data-canonical-src="https://img.shields.io/badge/license-Apache--2.0-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/tesseract-ocr/tesseract/releases/"&gt;&lt;img src="https://camo.githubusercontent.com/75f3daa1bec0562b7a0df017704694b0424dc2e2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f776e6c6f61642d616c6c25323072656c65617365732d627269676874677265656e2e737667" alt="Downloads" data-canonical-src="https://img.shields.io/badge/download-all%20releases-brightgreen.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-about" class="anchor" aria-hidden="true" href="#about"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About&lt;/h2&gt;
&lt;p&gt;This package contains an &lt;strong&gt;OCR engine&lt;/strong&gt; - &lt;code&gt;libtesseract&lt;/code&gt; and a &lt;strong&gt;command line program&lt;/strong&gt; - &lt;code&gt;tesseract&lt;/code&gt;.
Tesseract 4 adds a new neural net (LSTM) based OCR engine which is focused
on line recognition, but also still supports the legacy Tesseract OCR engine of
Tesseract 3 which works by recognizing character patterns. Compatibility with
Tesseract 3 is enabled by using the Legacy OCR Engine mode (--oem 0).
It also needs traineddata files which support the legacy engine, for example
those from the tessdata repository.&lt;/p&gt;
&lt;p&gt;The lead developer is Ray Smith. The maintainer is Zdenko Podobny.
For a list of contributors see &lt;a href="https://github.com/tesseract-ocr/tesseract/blob/master/AUTHORS"&gt;AUTHORS&lt;/a&gt;
and GitHub's log of &lt;a href="https://github.com/tesseract-ocr/tesseract/graphs/contributors"&gt;contributors&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Tesseract has &lt;strong&gt;unicode (UTF-8) support&lt;/strong&gt;, and can &lt;strong&gt;recognize more than 100 languages&lt;/strong&gt; "out of the box".&lt;/p&gt;
&lt;p&gt;Tesseract supports &lt;strong&gt;various output formats&lt;/strong&gt;: plain text, hOCR (HTML), PDF, invisible-text-only PDF, TSV. The master branch also has experimental support for ALTO (XML) output.&lt;/p&gt;
&lt;p&gt;You should note that in many cases, in order to get better OCR results, you'll need to &lt;strong&gt;&lt;a href="https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality"&gt;improve the quality&lt;/a&gt; of the image&lt;/strong&gt; you are giving Tesseract.&lt;/p&gt;
&lt;p&gt;This project &lt;strong&gt;does not include a GUI application&lt;/strong&gt;. If you need one, please see the &lt;a href="https://github.com/tesseract-ocr/tesseract/wiki/User-Projects-%E2%80%93-3rdParty"&gt;3rdParty&lt;/a&gt; wiki page.&lt;/p&gt;
&lt;p&gt;Tesseract &lt;strong&gt;can be trained to recognize other languages&lt;/strong&gt;. See &lt;a href="https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract"&gt;Tesseract Training&lt;/a&gt; for more information.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-brief-history" class="anchor" aria-hidden="true" href="#brief-history"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Brief history&lt;/h2&gt;
&lt;p&gt;Tesseract was originally developed at Hewlett-Packard Laboratories Bristol and
at Hewlett-Packard Co, Greeley Colorado between 1985 and 1994, with some
more changes made in 1996 to port to Windows, and some C++izing in 1998.
In 2005 Tesseract was open sourced by HP. Since 2006 it is developed by Google.&lt;/p&gt;
&lt;p&gt;The latest (LSTM based) stable version is &lt;strong&gt;&lt;a href="https://github.com/tesseract-ocr/tesseract/releases/tag/4.1.0"&gt;4.1.0&lt;/a&gt;&lt;/strong&gt;, released on July 7, 2019. Latest source code is available from &lt;a href="https://github.com/tesseract-ocr/tesseract/tree/master"&gt;master branch on GitHub&lt;/a&gt;. Open issues can be found in &lt;a href="https://github.com/tesseract-ocr/tesseract/issues"&gt;issue tracker&lt;/a&gt;, and &lt;a href="https://github.com/tesseract-ocr/tesseract/wiki/Planning"&gt;Planning wiki&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The latest 3.5 version is &lt;strong&gt;&lt;a href="https://github.com/tesseract-ocr/tesseract/releases/tag/3.05.02"&gt;3.05.02&lt;/a&gt;&lt;/strong&gt;, released on June 19, 2018. Latest source code for 3.05 is available from &lt;a href="https://github.com/tesseract-ocr/tesseract/tree/3.05"&gt;3.05 branch on GitHub&lt;/a&gt;. There is no development for this version, but it can be used for special cases (e.g. see &lt;a href="https://github.com/tesseract-ocr/tesseract/wiki/Planning#regression-of-features-from-30x"&gt;Regression of features from 3.0x&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;See &lt;strong&gt;&lt;a href="https://github.com/tesseract-ocr/tesseract/wiki/ReleaseNotes"&gt;Release Notes&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://github.com/tesseract-ocr/tesseract/blob/master/ChangeLog"&gt;Change Log&lt;/a&gt;&lt;/strong&gt; for more details of the releases.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installing-tesseract" class="anchor" aria-hidden="true" href="#installing-tesseract"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing Tesseract&lt;/h2&gt;
&lt;p&gt;You can either &lt;a href="https://github.com/tesseract-ocr/tesseract/wiki"&gt;Install Tesseract via pre-built binary package&lt;/a&gt; or &lt;a href="https://github.com/tesseract-ocr/tesseract/wiki/Compiling"&gt;build it from source&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Supported Compilers are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GCC 4.8 and above&lt;/li&gt;
&lt;li&gt;Clang 3.4 and above&lt;/li&gt;
&lt;li&gt;MSVC 2015, 2017, 2019&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Other compilers might work, but are not officially supported.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-running-tesseract" class="anchor" aria-hidden="true" href="#running-tesseract"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running Tesseract&lt;/h2&gt;
&lt;p&gt;Basic &lt;strong&gt;&lt;a href="https://github.com/tesseract-ocr/tesseract/wiki/Command-Line-Usage"&gt;command line usage&lt;/a&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tesseract imagename outputbase [-l lang] [--oem ocrenginemode] [--psm pagesegmode] [configfiles...]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more information about the various command line options use &lt;code&gt;tesseract --help&lt;/code&gt; or &lt;code&gt;man tesseract&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Examples can be found in the &lt;a href="https://github.com/tesseract-ocr/tesseract/wiki/Command-Line-Usage#simplest-invocation-to-ocr-an-image"&gt;wiki&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-for-developers" class="anchor" aria-hidden="true" href="#for-developers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;For developers&lt;/h2&gt;
&lt;p&gt;Developers can use &lt;code&gt;libtesseract&lt;/code&gt; &lt;a href="https://github.com/tesseract-ocr/tesseract/blob/master/include/tesseract/capi.h"&gt;C&lt;/a&gt; or
&lt;a href="https://github.com/tesseract-ocr/tesseract/blob/master/include/tesseract/baseapi.h"&gt;C++&lt;/a&gt; API to build their own application.
If you need bindings to &lt;code&gt;libtesseract&lt;/code&gt; for other programming languages, please see the
&lt;a href="https://github.com/tesseract-ocr/tesseract/wiki/AddOns#tesseract-wrappers"&gt;wrapper&lt;/a&gt; section on AddOns wiki page.&lt;/p&gt;
&lt;p&gt;Documentation of Tesseract generated from source code by doxygen can be found on &lt;a href="https://tesseract-ocr.github.io/" rel="nofollow"&gt;tesseract-ocr.github.io&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-support" class="anchor" aria-hidden="true" href="#support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support&lt;/h2&gt;
&lt;p&gt;Before you submit an issue, please review &lt;strong&gt;&lt;a href="https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md"&gt;the guidelines for this repository&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;For support, first read the &lt;a href="https://github.com/tesseract-ocr/tesseract/wiki"&gt;Wiki&lt;/a&gt;, particularly the &lt;a href="https://github.com/tesseract-ocr/tesseract/wiki/FAQ"&gt;FAQ&lt;/a&gt; to see if your problem is addressed there. If not, search the &lt;a href="https://groups.google.com/d/forum/tesseract-ocr" rel="nofollow"&gt;Tesseract user forum&lt;/a&gt;, the &lt;a href="https://groups.google.com/d/forum/tesseract-dev" rel="nofollow"&gt;Tesseract developer forum&lt;/a&gt; and &lt;a href="https://github.com/tesseract-ocr/tesseract/issues"&gt;past issues&lt;/a&gt;, and if you still can't find what you need, ask for support in the mailing-lists.&lt;/p&gt;
&lt;p&gt;Mailing-lists:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://groups.google.com/d/forum/tesseract-ocr" rel="nofollow"&gt;tesseract-ocr&lt;/a&gt; - For tesseract users.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://groups.google.com/d/forum/tesseract-dev" rel="nofollow"&gt;tesseract-dev&lt;/a&gt; - For tesseract developers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please report an issue only for a &lt;strong&gt;bug&lt;/strong&gt;, not for asking questions.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;The code in this repository is licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: This software depends on other packages that may be licensed under different open source licenses.&lt;/p&gt;
&lt;p&gt;Tesseract uses &lt;a href="http://leptonica.com/" rel="nofollow"&gt;Leptonica library&lt;/a&gt; which essentially
uses a &lt;a href="http://leptonica.com/about-the-license.html" rel="nofollow"&gt;BSD 2-clause license&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h2&gt;
&lt;p&gt;Tesseract uses &lt;a href="https://github.com/DanBloomberg/leptonica"&gt;Leptonica library&lt;/a&gt;
for opening input images (e.g. not documents like pdf).
It is suggested to use leptonica with built-in support for &lt;a href="https://zlib.net" rel="nofollow"&gt;zlib&lt;/a&gt;,
&lt;a href="https://sourceforge.net/projects/libpng" rel="nofollow"&gt;png&lt;/a&gt; and
&lt;a href="http://www.simplesystems.org/libtiff" rel="nofollow"&gt;tiff&lt;/a&gt; (for w multipage tiff).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-latest-version-of-readme" class="anchor" aria-hidden="true" href="#latest-version-of-readme"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latest Version of README&lt;/h2&gt;
&lt;p&gt;For the latest online version of the README.md see:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/tesseract-ocr/tesseract/blob/master/README.md"&gt;https://github.com/tesseract-ocr/tesseract/blob/master/README.md&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>tesseract-ocr</author><guid isPermaLink="false">https://github.com/tesseract-ocr/tesseract</guid><pubDate>Sun, 05 Jan 2020 00:15:00 GMT</pubDate></item><item><title>catchorg/Catch2 #16 in C++, Today</title><link>https://github.com/catchorg/Catch2</link><description>&lt;p&gt;&lt;i&gt;A modern, C++-native, header-only, test framework for unit-tests, TDD and BDD - using C++11, C++14, C++17 and later (or C++03 on the Catch1.x branch)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a id="user-content-top"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="artwork/catch2-logo-small.png"&gt;&lt;img src="artwork/catch2-logo-small.png" alt="catch logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/catchorg/catch2/releases"&gt;&lt;img src="https://camo.githubusercontent.com/553e373b95168194513a4d45c7c10f51aa85dbfe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f63617463686f72672f6361746368322e737667" alt="Github Releases" data-canonical-src="https://img.shields.io/github/release/catchorg/catch2.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.org/catchorg/Catch2" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/567a401a42c52642ba89cd652b73ab8d8c698236/68747470733a2f2f7472617669732d63692e6f72672f63617463686f72672f4361746368322e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/catchorg/Catch2.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/catchorg/catch2" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/91ec0bec6cd9d46aeca513c07dc3a2411ea0f61e/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f63617463686f72672f4361746368323f7376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/catchorg/Catch2?svg=true" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/catchorg/Catch2" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9441c12cb0379b7d9dd83d2dc0e0474200cc63cb/68747470733a2f2f636f6465636f762e696f2f67682f63617463686f72672f4361746368322f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/catchorg/Catch2/branch/master/graph/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://wandbox.org/permlink/Fj98nizVNqgaWH3i" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/57993e2729bc1a6482ef48e7c2fc3676a2df9c06/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7472792d6f6e6c696e652d626c75652e737667" alt="Try online" data-canonical-src="https://img.shields.io/badge/try-online-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://discord.gg/4CWS9zD" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0ff47fc74292eec1884b1c79e26c078b3b3e8826/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d43686174212d627269676874677265656e2e737667" alt="Join the chat in Discord: https://discord.gg/4CWS9zD" data-canonical-src="https://img.shields.io/badge/Discord-Chat!-brightgreen.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/catchorg/Catch2/releases/download/v2.11.1/catch.hpp"&gt;The latest version of the single header can be downloaded directly using this link&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-catch2-is-released" class="anchor" aria-hidden="true" href="#catch2-is-released"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Catch2 is released!&lt;/h2&gt;
&lt;p&gt;If you've been using an earlier version of Catch, please see the
Breaking Changes section of &lt;a href="https://github.com/catchorg/Catch2/releases/tag/v2.0.1"&gt;the release notes&lt;/a&gt;
before moving to Catch2. You might also like to read &lt;a href="https://levelofindirection.com/blog/catch2-released.html" rel="nofollow"&gt;this blog post&lt;/a&gt; for more details.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-whats-the-catch" class="anchor" aria-hidden="true" href="#whats-the-catch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What's the Catch?&lt;/h2&gt;
&lt;p&gt;Catch2 is a multi-paradigm test framework for C++. which also supports
Objective-C (and maybe C).
It is primarily distributed as a single header file, although certain
extensions may require additional headers.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-use-it" class="anchor" aria-hidden="true" href="#how-to-use-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to use it&lt;/h2&gt;
&lt;p&gt;This documentation comprises these three parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/why-catch.md#top"&gt;Why do we need yet another C++ Test Framework?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/tutorial.md#top"&gt;Tutorial&lt;/a&gt; - getting started&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/Readme.md#top"&gt;Reference section&lt;/a&gt; - all the details&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-more" class="anchor" aria-hidden="true" href="#more"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Issues and bugs can be raised on the &lt;a href="https://github.com/catchorg/Catch2/issues"&gt;Issue tracker on GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;For discussion or questions please use &lt;a href="https://groups.google.com/forum/?fromgroups#!forum/catch-forum" rel="nofollow"&gt;the dedicated Google Groups forum&lt;/a&gt; or our &lt;a href="https://discord.gg/4CWS9zD" rel="nofollow"&gt;Discord&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;See &lt;a href="docs/opensource-users.md#top"&gt;who else is using Catch2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>catchorg</author><guid isPermaLink="false">https://github.com/catchorg/Catch2</guid><pubDate>Sun, 05 Jan 2020 00:16:00 GMT</pubDate></item><item><title>opencv/opencv #17 in C++, Today</title><link>https://github.com/opencv/opencv</link><description>&lt;p&gt;&lt;i&gt;Open Source Computer Vision Library&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-opencv-open-source-computer-vision-library" class="anchor" aria-hidden="true" href="#opencv-open-source-computer-vision-library"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;OpenCV: Open Source Computer Vision Library&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Homepage: &lt;a href="https://opencv.org" rel="nofollow"&gt;https://opencv.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Docs: &lt;a href="https://docs.opencv.org/master/" rel="nofollow"&gt;https://docs.opencv.org/master/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Q&amp;amp;A forum: &lt;a href="http://answers.opencv.org" rel="nofollow"&gt;http://answers.opencv.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Issue tracking: &lt;a href="https://github.com/opencv/opencv/issues"&gt;https://github.com/opencv/opencv/issues&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h3&gt;
&lt;p&gt;Please read the &lt;a href="https://github.com/opencv/opencv/wiki/How_to_contribute"&gt;contribution guidelines&lt;/a&gt; before starting work on a pull request.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-summary-of-the-guidelines" class="anchor" aria-hidden="true" href="#summary-of-the-guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Summary of the guidelines:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;One pull request per issue;&lt;/li&gt;
&lt;li&gt;Choose the right base branch;&lt;/li&gt;
&lt;li&gt;Include tests and documentation;&lt;/li&gt;
&lt;li&gt;Clean up "oops" commits before submitting;&lt;/li&gt;
&lt;li&gt;Follow the &lt;a href="https://github.com/opencv/opencv/wiki/Coding_Style_Guide"&gt;coding style guide&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>opencv</author><guid isPermaLink="false">https://github.com/opencv/opencv</guid><pubDate>Sun, 05 Jan 2020 00:17:00 GMT</pubDate></item><item><title>ssloy/tinyrenderer #18 in C++, Today</title><link>https://github.com/ssloy/tinyrenderer</link><description>&lt;p&gt;&lt;i&gt;A brief computer graphics / rendering course&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tiny-renderer-or-how-opengl-works-software-rendering-in-500-lines-of-code" class="anchor" aria-hidden="true" href="#tiny-renderer-or-how-opengl-works-software-rendering-in-500-lines-of-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tiny Renderer or how OpenGL works: software rendering in 500 lines of code&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Check &lt;a href="https://github.com/ssloy/tinyrenderer/wiki"&gt;the wiki&lt;/a&gt; for the detailed lessons. My source code is irrelevant. Read the wiki and implement your own renderer. Only when you suffer through all the tiny details you will learn what is going on.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this series of articles, I want to show the way OpenGL works by writing its clone (a much simplified one). Surprisingly enough, I often meet people who cannot overcome the initial hurdle of learning OpenGL / DirectX. Thus, I have prepared a short series of lectures, after which my students show quite good renderers.&lt;/p&gt;
&lt;p&gt;So, the task is formulated as follows: using no third-party libraries (especially graphic ones), get something like this picture:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/00-home/africanhead.png"&gt;&lt;img src="https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/00-home/africanhead.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Warning: this is a training material that will loosely repeat the structure of the OpenGL library. It will be a software renderer. &lt;strong&gt;I do not want to show how to write applications for OpenGL. I want to show how OpenGL works.&lt;/strong&gt; I am deeply convinced that it is impossible to write efficient applications using 3D libraries without understanding this.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I will try to make the final code about 500 lines. My students need 10 to 20 programming hours to begin making such renderers. At the input, we get a test file with a polygonal wire + pictures with textures. At the output, we’ll get a rendered model. No graphical interface, the program simply generates an image.&lt;/p&gt;
&lt;p&gt;Since the goal is to minimize external dependencies, I give my students just one class that allows working with &lt;a href="http://en.wikipedia.org/wiki/Truevision_TGA" rel="nofollow"&gt;TGA&lt;/a&gt; files. It’s one of the simplest formats that supports images in RGB/RGBA/black and white formats. So, as a starting point, we’ll obtain a simple way to work with pictures. You should note that the only functionality available at the very beginning (in addition to loading and saving images) is the capability to set the color of one pixel.&lt;/p&gt;
&lt;p&gt;There are no functions for drawing line segments and triangles. We’ll have to do all of this by hand. I provide my source code that I write in parallel with students. But I would not recommend using it, as this doesn’t make sense. The entire code is available on github, and &lt;a href="https://github.com/ssloy/tinyrenderer/tree/909fe20934ba5334144d2c748805690a1fa4c89f"&gt;here&lt;/a&gt; you will find the source code I give to my students.&lt;/p&gt;
&lt;div class="highlight highlight-source-c++"&gt;&lt;pre&gt;#&lt;span class="pl-k"&gt;include&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;tgaimage.h&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; TGAColor white = TGAColor(&lt;span class="pl-c1"&gt;255&lt;/span&gt;, &lt;span class="pl-c1"&gt;255&lt;/span&gt;, &lt;span class="pl-c1"&gt;255&lt;/span&gt;, &lt;span class="pl-c1"&gt;255&lt;/span&gt;);
&lt;span class="pl-k"&gt;const&lt;/span&gt; TGAColor red   = TGAColor(&lt;span class="pl-c1"&gt;255&lt;/span&gt;, &lt;span class="pl-c1"&gt;0&lt;/span&gt;,   &lt;span class="pl-c1"&gt;0&lt;/span&gt;,   &lt;span class="pl-c1"&gt;255&lt;/span&gt;);
&lt;span class="pl-k"&gt;int&lt;/span&gt; &lt;span class="pl-en"&gt;main&lt;/span&gt;(&lt;span class="pl-k"&gt;int&lt;/span&gt; argc, &lt;span class="pl-k"&gt;char&lt;/span&gt;** argv) {
        TGAImage &lt;span class="pl-smi"&gt;image&lt;/span&gt;(&lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-c1"&gt;100&lt;/span&gt;, TGAImage::RGB);
        image.&lt;span class="pl-c1"&gt;set&lt;/span&gt;(&lt;span class="pl-c1"&gt;52&lt;/span&gt;, &lt;span class="pl-c1"&gt;41&lt;/span&gt;, red);
        image.&lt;span class="pl-c1"&gt;flip_vertically&lt;/span&gt;(); &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; i want to have the origin at the left bottom corner of the image&lt;/span&gt;
        image.&lt;span class="pl-c1"&gt;write_tga_file&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;output.tga&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;);`
        &lt;span class="pl-k"&gt;return&lt;/span&gt; &lt;span class="pl-c1"&gt;0&lt;/span&gt;;
}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;output.tga should look something like this:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/00-home/reddot.png"&gt;&lt;img src="https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/00-home/reddot.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-teaser-few-examples-made-with-the-renderer" class="anchor" aria-hidden="true" href="#teaser-few-examples-made-with-the-renderer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Teaser: few examples made with the renderer&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/00-home/demon.png"&gt;&lt;img src="https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/00-home/demon.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/00-home/diablo-glow.png"&gt;&lt;img src="https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/00-home/diablo-glow.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/00-home/boggie.png"&gt;&lt;img src="https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/00-home/boggie.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/00-home/diablo-ssao.png"&gt;&lt;img src="https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/00-home/diablo-ssao.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ssloy</author><guid isPermaLink="false">https://github.com/ssloy/tinyrenderer</guid><pubDate>Sun, 05 Jan 2020 00:18:00 GMT</pubDate></item><item><title>PixarAnimationStudios/USD #19 in C++, Today</title><link>https://github.com/PixarAnimationStudios/USD</link><description>&lt;p&gt;&lt;i&gt;Universal Scene Description&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-universal-scene-description" class="anchor" aria-hidden="true" href="#universal-scene-description"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Universal Scene Description&lt;/h1&gt;
&lt;p&gt;Universal Scene Description (USD) is an efficient, scalable system for
authoring, reading, and streaming time-sampled scene description for
interchange between graphics applications.&lt;/p&gt;
&lt;p&gt;For more details, please visit the web site &lt;a href="http://openusd.org" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-build-status" class="anchor" aria-hidden="true" href="#build-status"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Build Status&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;master&lt;/th&gt;
&lt;th&gt;dev&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Linux/macOS&lt;/td&gt;
&lt;td&gt;&lt;a href="https://travis-ci.com/PixarAnimationStudios/USD" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/43b8c1208c750894ad6e5f376becb121026ac443/68747470733a2f2f7472617669732d63692e636f6d2f5069786172416e696d6174696f6e53747564696f732f5553442e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/PixarAnimationStudios/USD.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://travis-ci.com/PixarAnimationStudios/USD" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/05d5d60943d235eab5c662c9030d6f793f010f9a/68747470733a2f2f7472617669732d63692e636f6d2f5069786172416e696d6174696f6e53747564696f732f5553442e7376673f6272616e63683d646576" alt="Build Status" data-canonical-src="https://travis-ci.com/PixarAnimationStudios/USD.svg?branch=dev" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-additional-documentation" class="anchor" aria-hidden="true" href="#additional-documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Additional Documentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://openusd.org/docs/index.html" rel="nofollow"&gt;User Documentation and Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://openusd.org/docs/api/index.html" rel="nofollow"&gt;API Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="BUILDING.md"&gt;Advanced Build Configuration&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-getting-help" class="anchor" aria-hidden="true" href="#getting-help"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Help&lt;/h2&gt;
&lt;p&gt;Need help understanding certain concepts in USD? See
&lt;a href="http://openusd.org/docs/Getting-Help-with-USD.html" rel="nofollow"&gt;Getting Help with USD&lt;/a&gt; or
visit our &lt;a href="https://groups.google.com/forum/#!forum/usd-interest" rel="nofollow"&gt;forum&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are experiencing undocumented problems with the software, please
&lt;a href="https://github.com/PixarAnimationStudios/USD/issues/new"&gt;file a bug&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-supported-platforms" class="anchor" aria-hidden="true" href="#supported-platforms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Supported Platforms&lt;/h2&gt;
&lt;p&gt;USD is currently supported on Linux platforms and has been built and tested
on CentOS 7 and RHEL 7.&lt;/p&gt;
&lt;p&gt;We are actively working on porting USD to both Windows and Mac platforms.
Support for both platforms should be considered experimental at this time.
Currently, the tree will build on Mac and Windows, but only limited testing
has been done on these platforms.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h2&gt;
&lt;p&gt;The following dependencies are required:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C++ compiler&lt;/li&gt;
&lt;li&gt;C compiler&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cmake.org/documentation/" rel="nofollow"&gt;CMake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://boost.org" rel="nofollow"&gt;Boost&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.threadingbuildingblocks.org/" rel="nofollow"&gt;Intel TBB&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following dependencies are optional:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://python.org" rel="nofollow"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See &lt;a href="VERSIONS.md"&gt;3rd Party Library and Application Versions&lt;/a&gt; for version information.&lt;/p&gt;
&lt;p&gt;Additional dependencies are required for the following components. These
components may be disabled at build-time, for further details see
&lt;a href="BUILDING.md"&gt;Advanced Build Configuration&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Imaging and USD Imaging&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The following dependencies are required:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/PixarAnimationStudios/OpenSubdiv"&gt;OpenSubdiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following dependencies are optional:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://glew.sourceforge.net/" rel="nofollow"&gt;GLEW&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.openexr.com" rel="nofollow"&gt;OpenEXR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sites.google.com/site/openimageio/home" rel="nofollow"&gt;OpenImageIO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://opencolorio.org/" rel="nofollow"&gt;OpenColorIO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/imageworks/OpenShadingLanguage"&gt;OSL (OpenShadingLanguage)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ptex.us/" rel="nofollow"&gt;Ptex&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;usdview&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The following dependencies are required:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://wiki.qt.io/PySide" rel="nofollow"&gt;PySide&lt;/a&gt; or &lt;a href="http://wiki.qt.io/PySide2" rel="nofollow"&gt;PySide2&lt;/a&gt; (experimental)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pypi.python.org/pypi/PyOpenGL/" rel="nofollow"&gt;PyOpenGL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-getting-and-building-the-code" class="anchor" aria-hidden="true" href="#getting-and-building-the-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting and Building the Code&lt;/h2&gt;
&lt;p&gt;The simplest way to build USD is to run the supplied &lt;code&gt;build_usd.py&lt;/code&gt;
script. This script will download required dependencies and build
and install them along with USD in a given directory.&lt;/p&gt;
&lt;p&gt;Follow the instructions below to run the script with its default behavior,
which will build the USD core libraries, Imaging, and USD Imaging components.
For more options and documentation, run the script with the &lt;code&gt;--help&lt;/code&gt;
parameter.&lt;/p&gt;
&lt;p&gt;See &lt;a href="BUILDING.md"&gt;Advanced Build Configuration&lt;/a&gt; for examples and
additional documentation for running cmake directly.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-1-install-prerequisites-see-dependencies-for-required-versions" class="anchor" aria-hidden="true" href="#1-install-prerequisites-see-dependencies-for-required-versions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Install prerequisites (see &lt;a href="#dependencies"&gt;Dependencies&lt;/a&gt; for required versions)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Required:
&lt;ul&gt;
&lt;li&gt;C++ compiler:
&lt;ul&gt;
&lt;li&gt;gcc&lt;/li&gt;
&lt;li&gt;Xcode&lt;/li&gt;
&lt;li&gt;Microsoft Visual Studio&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NASM (required for Imaging on Windows)&lt;/li&gt;
&lt;li&gt;CMake&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Optional (Can be ignored by passing &lt;code&gt;--no-python&lt;/code&gt; as an argument to &lt;code&gt;build_usd.py&lt;/code&gt;)
&lt;ul&gt;
&lt;li&gt;Python (required for &lt;a href="BUILDING.md#python"&gt;bindings and tests&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;PyOpenGL (required for &lt;a href="BUILDING.md#usd-imaging"&gt;usdview&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;PySide or PySide2 (experimental) (required for &lt;a href="BUILDING.md#usd-imaging"&gt;usdview&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-2-download-the-usd-source-code" class="anchor" aria-hidden="true" href="#2-download-the-usd-source-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Download the USD source code&lt;/h4&gt;
&lt;p&gt;You can download source code archives from &lt;a href="https://www.github.com/PixarAnimationStudios/USD"&gt;GitHub&lt;/a&gt; or use &lt;code&gt;git&lt;/code&gt; to clone the repository.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; git clone https://github.com/PixarAnimationStudios/USD
Cloning into 'USD'...
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-3-run-the-script" class="anchor" aria-hidden="true" href="#3-run-the-script"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. Run the script&lt;/h4&gt;
&lt;h5&gt;&lt;a id="user-content-linux" class="anchor" aria-hidden="true" href="#linux"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linux:&lt;/h5&gt;
&lt;p&gt;For example, the following will download, build, and install USD's dependencies,
then build and install USD into &lt;code&gt;/usr/local/USD&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; python USD/build_scripts/build_usd.py /usr/local/USD
&lt;/code&gt;&lt;/pre&gt;
&lt;h5&gt;&lt;a id="user-content-macos" class="anchor" aria-hidden="true" href="#macos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MacOS:&lt;/h5&gt;
&lt;p&gt;In a terminal, run &lt;code&gt;xcode-select&lt;/code&gt; to ensure command line developer tools are
installed. Then run the script.&lt;/p&gt;
&lt;p&gt;For example, the following will download, build, and install USD's dependencies,
then build and install USD into &lt;code&gt;/opt/local/USD&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; python USD/build_scripts/build_usd.py /opt/local/USD
&lt;/code&gt;&lt;/pre&gt;
&lt;h5&gt;&lt;a id="user-content-windows" class="anchor" aria-hidden="true" href="#windows"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Windows:&lt;/h5&gt;
&lt;p&gt;Launch the "Developer Command Prompt" for your version of Visual Studio and
run the script in the opened shell. Make sure to use the 64-bit (x64) command
prompt and not the 32-bit (x86) command prompt.  (Note if you're trying to
build with Visual Studio 2017, use the "x86 Native Tools Command Prompt for VS
2017").&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://docs.microsoft.com/en-us/dotnet/framework/tools/developer-command-prompt-for-vs" rel="nofollow"&gt;https://docs.microsoft.com/en-us/dotnet/framework/tools/developer-command-prompt-for-vs&lt;/a&gt; for more details.&lt;/p&gt;
&lt;p&gt;For example, the following will download, build, and install USD's dependencies,
then build and install USD into &lt;code&gt;C:\Program Files\USD&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;C:\&amp;gt; python USD\build_scripts\build_usd.py "C:\Program Files\USD"
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-4-try-it-out" class="anchor" aria-hidden="true" href="#4-try-it-out"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4. Try it out&lt;/h4&gt;
&lt;p&gt;Set the environment variables specified by the script when it finishes and
launch &lt;code&gt;usdview&lt;/code&gt; with a sample asset.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; usdview extras/usd/tutorials/convertingLayerFormats/Sphere.usda
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;If you'd like to contribute to USD (and we appreciate the help!), please see
the &lt;a href="http://openusd.org/docs/Contributing-to-USD.html" rel="nofollow"&gt;Contributing&lt;/a&gt; page in the
documentation for more information.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>PixarAnimationStudios</author><guid isPermaLink="false">https://github.com/PixarAnimationStudios/USD</guid><pubDate>Sun, 05 Jan 2020 00:19:00 GMT</pubDate></item><item><title>ocornut/imgui #20 in C++, Today</title><link>https://github.com/ocornut/imgui</link><description>&lt;p&gt;&lt;i&gt;Dear ImGui: Bloat-free Immediate Mode Graphical User interface for C++ with minimal dependencies&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="docs/README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-dear-imgui" class="anchor" aria-hidden="true" href="#dear-imgui"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;dear imgui&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/ocornut/imgui/actions?workflow=build"&gt;&lt;img src="https://github.com/ocornut/imgui/workflows/build/badge.svg" alt="Build Status" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://scan.coverity.com/projects/4720" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/fd8d75b32a7b7529e474e3811c14a1ff3df9c541/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f343732302f62616467652e737667" alt="Coverity Status" data-canonical-src="https://scan.coverity.com/projects/4720/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;sub&gt;(This library is available under a free and permissive license, but needs financial support to sustain its continued improvements. In addition to maintenance and stability there are many desirable features yet to be added. If your company is using dear imgui, please consider reaching out. If you are an individual using dear imgui, please consider supporting the project via Patreon or PayPal.)&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;Businesses: support continued development via invoiced technical support, maintenance, sponsoring contracts:
&lt;br&gt;  &lt;em&gt;E-mail: contact @ dearimgui dot org&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Individuals/hobbyists: support continued maintenance and development via the monthly Patreon:
&lt;br&gt;  &lt;a href="http://www.patreon.com/imgui" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/wiki/ocornut/imgui/web/patreon_02.png" alt="Patreon" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Individuals/hobbyists: support continued maintenance and development via PayPal:
&lt;br&gt;  &lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=WGHNC6MBFLZ2S" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/bce14c8e2e39ba0464551b34602b4c60c182526b/68747470733a2f2f7777772e70617970616c6f626a656374732e636f6d2f656e5f55532f692f62746e2f62746e5f646f6e6174655f4c472e676966" alt="PayPal" data-canonical-src="https://www.paypalobjects.com/en_US/i/btn/btn_donate_LG.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Dear ImGui is a &lt;strong&gt;bloat-free graphical user interface library for C++&lt;/strong&gt;. It outputs optimized vertex buffers that you can render anytime in your 3D-pipeline enabled application. It is fast, portable, renderer agnostic and self-contained (no external dependencies).&lt;/p&gt;
&lt;p&gt;Dear ImGui is designed to &lt;strong&gt;enable fast iterations&lt;/strong&gt; and to &lt;strong&gt;empower programmers&lt;/strong&gt; to create &lt;strong&gt;content creation tools and visualization / debug tools&lt;/strong&gt; (as opposed to UI for the average end-user). It favors simplicity and productivity toward this goal, and lacks certain features normally found in more high-level libraries.&lt;/p&gt;
&lt;p&gt;Dear ImGui is particularly suited to integration in games engine (for tooling), real-time 3D applications, fullscreen applications, embedded applications, or any applications on consoles platforms where operating system features are non-standard.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="#usage"&gt;Usage&lt;/a&gt; - &lt;a href="#how-it-works"&gt;How it works&lt;/a&gt; - &lt;a href="#demo"&gt;Demo&lt;/a&gt; - &lt;a href="#integration"&gt;Integration&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="#upcoming-changes"&gt;Upcoming changes&lt;/a&gt; - &lt;a href="#gallery"&gt;Gallery&lt;/a&gt; - &lt;a href="#support-frequently-asked-questions-faq"&gt;Support, FAQ&lt;/a&gt; -  &lt;a href="#how-to-help"&gt;How to help&lt;/a&gt; - &lt;a href="#sponsors"&gt;Sponsors&lt;/a&gt; - &lt;a href="#credits"&gt;Credits&lt;/a&gt; - &lt;a href="#license"&gt;License&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/ocornut/imgui/wiki"&gt;Wiki&lt;/a&gt; - &lt;a href="https://github.com/ocornut/imgui/wiki/Bindings"&gt;Language &amp;amp; frameworks bindings&lt;/a&gt; - &lt;a href="https://github.com/ocornut/imgui/wiki/Software-using-dear-imgui"&gt;Software using Dear ImGui&lt;/a&gt; - &lt;a href="https://github.com/ocornut/imgui/wiki/Quotes"&gt;User quotes&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;The core of Dear ImGui is self-contained within a few platform-agnostic files&lt;/strong&gt; which you can easily copy and compile into your application/engine. They are all the files in the root folder of the repository (imgui.cpp, imgui.h, imgui_demo.cpp, imgui_draw.cpp etc.).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;No specific build process is required&lt;/strong&gt;. You can add the .cpp files to your existing project.&lt;/p&gt;
&lt;p&gt;You will need a backend to integrate Dear ImGui in your app. The backend passes mouse/keyboard/gamepad inputs and variety of settings to Dear ImGui, and is in charge of rendering the resulting vertices.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Backends for a variety of graphics api and rendering platforms&lt;/strong&gt; are provided in the &lt;a href="https://github.com/ocornut/imgui/tree/master/examples"&gt;examples/&lt;/a&gt; folder, along with example applications. See the &lt;a href="#integration"&gt;Integration&lt;/a&gt; section of this document for details. You may also create your own backend. Anywhere where you can render textured triangles, you can render Dear ImGui.&lt;/p&gt;
&lt;p&gt;After Dear ImGui is setup in your application, you can use it from _anywhere_ in your program loop:&lt;/p&gt;
&lt;p&gt;Code:&lt;/p&gt;
&lt;div class="highlight highlight-source-c++"&gt;&lt;pre&gt;&lt;span class="pl-en"&gt;ImGui::Text&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Hello, world %d&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;123&lt;/span&gt;);
&lt;span class="pl-k"&gt;if&lt;/span&gt; (ImGui::Button(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Save&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;))
    &lt;span class="pl-en"&gt;MySaveFunction&lt;/span&gt;();
&lt;span class="pl-en"&gt;ImGui::InputText&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;string&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, buf, IM_ARRAYSIZE(buf));
&lt;span class="pl-en"&gt;ImGui::SliderFloat&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;float&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &amp;amp;f, &lt;span class="pl-c1"&gt;0&lt;/span&gt;.&lt;span class="pl-c1"&gt;0f&lt;/span&gt;, &lt;span class="pl-c1"&gt;1&lt;/span&gt;.&lt;span class="pl-c1"&gt;0f&lt;/span&gt;);&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Result:
&lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v160/code_sample_02.png"&gt;&lt;img src="https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v160/code_sample_02.png" alt="sample code output" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;br&gt;&lt;em&gt;(settings: Dark style (left), Light style (right) / Font: Roboto-Medium, 16px / Rounding: 5)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Code:&lt;/p&gt;
&lt;div class="highlight highlight-source-c++"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Create a window called "My First Tool", with a menu bar.&lt;/span&gt;
&lt;span class="pl-en"&gt;ImGui::Begin&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;My First Tool&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &amp;amp;my_tool_active, ImGuiWindowFlags_MenuBar);
&lt;span class="pl-k"&gt;if&lt;/span&gt; (ImGui::BeginMenuBar())
{
    &lt;span class="pl-k"&gt;if&lt;/span&gt; (&lt;span class="pl-c1"&gt;ImGui::BeginMenu&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;File&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;))
    {
        &lt;span class="pl-k"&gt;if&lt;/span&gt; (&lt;span class="pl-c1"&gt;ImGui::MenuItem&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Open..&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Ctrl+O&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)) { &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;/*&lt;/span&gt; Do stuff &lt;span class="pl-c"&gt;*/&lt;/span&gt;&lt;/span&gt; }
        &lt;span class="pl-k"&gt;if&lt;/span&gt; (&lt;span class="pl-c1"&gt;ImGui::MenuItem&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Save&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Ctrl+S&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;))   { &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;/*&lt;/span&gt; Do stuff &lt;span class="pl-c"&gt;*/&lt;/span&gt;&lt;/span&gt; }
        &lt;span class="pl-k"&gt;if&lt;/span&gt; (&lt;span class="pl-c1"&gt;ImGui::MenuItem&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Close&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Ctrl+W&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;))  { my_tool_active = &lt;span class="pl-c1"&gt;false&lt;/span&gt;; }
        &lt;span class="pl-c1"&gt;ImGui::EndMenu&lt;/span&gt;();
    }
    &lt;span class="pl-c1"&gt;ImGui::EndMenuBar&lt;/span&gt;();
}

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Edit a color (stored as ~4 floats)&lt;/span&gt;
&lt;span class="pl-en"&gt;ImGui::ColorEdit4&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Color&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, my_color);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Plot some values&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-k"&gt;float&lt;/span&gt; my_values[] = { &lt;span class="pl-c1"&gt;0&lt;/span&gt;.&lt;span class="pl-c1"&gt;2f&lt;/span&gt;, &lt;span class="pl-c1"&gt;0&lt;/span&gt;.&lt;span class="pl-c1"&gt;1f&lt;/span&gt;, &lt;span class="pl-c1"&gt;1&lt;/span&gt;.&lt;span class="pl-c1"&gt;0f&lt;/span&gt;, &lt;span class="pl-c1"&gt;0&lt;/span&gt;.&lt;span class="pl-c1"&gt;5f&lt;/span&gt;, &lt;span class="pl-c1"&gt;0&lt;/span&gt;.&lt;span class="pl-c1"&gt;9f&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;.&lt;span class="pl-c1"&gt;2f&lt;/span&gt; };
&lt;span class="pl-en"&gt;ImGui::PlotLines&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Frame Times&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, my_values, IM_ARRAYSIZE(my_values));

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Display contents in a scrolling region&lt;/span&gt;
&lt;span class="pl-en"&gt;ImGui::TextColored&lt;/span&gt;(ImVec4(&lt;span class="pl-c1"&gt;1&lt;/span&gt;,&lt;span class="pl-c1"&gt;1&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;,&lt;span class="pl-c1"&gt;1&lt;/span&gt;), "Important Stuff");
&lt;span class="pl-en"&gt;ImGui::BeginChild&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Scrolling&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;);
&lt;span class="pl-k"&gt;for&lt;/span&gt; (&lt;span class="pl-k"&gt;int&lt;/span&gt; n = &lt;span class="pl-c1"&gt;0&lt;/span&gt;; n &amp;lt; &lt;span class="pl-c1"&gt;50&lt;/span&gt;; n++)
    &lt;span class="pl-en"&gt;ImGui::Text&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;%04d: Some text&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, n);
&lt;span class="pl-en"&gt;ImGui::EndChild&lt;/span&gt;();
&lt;span class="pl-en"&gt;ImGui::End&lt;/span&gt;();&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Result:
&lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v160/code_sample_03_color.gif"&gt;&lt;img src="https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v160/code_sample_03_color.gif" alt="sample code output" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dear ImGui allows you &lt;strong&gt;create elaborate tools&lt;/strong&gt; as well as very short-lived ones. On the extreme side of short-livedness: using the Edit&amp;amp;Continue (hot code reload) feature of modern compilers you can add a few widgets to tweaks variables while your application is running, and remove the code a minute later! Dear ImGui is not just for tweaking values. You can use it to trace a running algorithm by just emitting text commands. You can use it along with your own reflection data to browse your dataset live. You can use it to expose the internals of a subsystem in your engine, to create a logger, an inspection tool, a profiler, a debugger, an entire game making editor/framework, etc.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-how-it-works" class="anchor" aria-hidden="true" href="#how-it-works"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How it works&lt;/h3&gt;
&lt;p&gt;Check out the Wiki's &lt;a href="https://github.com/ocornut/imgui/wiki#About-the-IMGUI-paradigm"&gt;About the IMGUI paradigm&lt;/a&gt; section if you want to understand the core principles behind the IMGUI paradigm. An IMGUI tries to minimize superfluous state duplication, state synchronization and state retention from the user's point of view. It is less error prone (less code and less bugs) than traditional retained-mode interfaces, and lends itself to create dynamic user interfaces.&lt;/p&gt;
&lt;p&gt;Dear ImGui outputs vertex buffers and command lists that you can easily render in your application. The number of draw calls and state changes required to render them is fairly small. Because Dear ImGui doesn't know or touch graphics state directly, you can call its functions  anywhere in your code (e.g. in the middle of a running algorithm, or in the middle of your own rendering process). Refer to the sample applications in the examples/ folder for instructions on how to integrate dear imgui with your existing codebase.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A common misunderstanding is to mistake immediate mode gui for immediate mode rendering, which usually implies hammering your driver/GPU with a bunch of inefficient draw calls and state changes as the gui functions are called. This is NOT what Dear ImGui does. Dear ImGui outputs vertex buffers and a small list of draw calls batches. It never touches your GPU directly. The draw call batches are decently optimal and you can render them later, in your app or even remotely.&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-demo" class="anchor" aria-hidden="true" href="#demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Demo&lt;/h3&gt;
&lt;p&gt;Calling the &lt;code&gt;ImGui::ShowDemoWindow()&lt;/code&gt; function will create a demo window showcasing variety of features and examples. The code is always available for reference in &lt;code&gt;imgui_demo.cpp&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v167/v167-misc.png"&gt;&lt;img src="https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v167/v167-misc.png" alt="screenshot demo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You should be able to build the examples from sources (tested on Windows/Mac/Linux). If you don't, let me know! If you want to have a quick look at some Dear ImGui features, you can download Windows binaries of the demo app here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.dearimgui.org/binaries/imgui-demo-binaries-20190715.zip" rel="nofollow"&gt;imgui-demo-binaries-20190715.zip&lt;/a&gt; (Windows binaries, 1.72 WIP, built 2019/07/15, master branch, 5 executables)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The demo applications are not DPI aware so expect some blurriness on a 4K screen. For DPI awareness in your application, you can load/reload your font at different scale, and scale your style with &lt;code&gt;style.ScaleAllSizes()&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-integration" class="anchor" aria-hidden="true" href="#integration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Integration&lt;/h3&gt;
&lt;p&gt;On most platforms and when using C++, &lt;strong&gt;you should be able to use a combination of the &lt;a href="https://github.com/ocornut/imgui/tree/master/examples"&gt;imgui_impl_xxxx&lt;/a&gt; files without modification&lt;/strong&gt; (e.g. &lt;code&gt;imgui_impl_win32.cpp&lt;/code&gt; + &lt;code&gt;imgui_impl_dx11.cpp&lt;/code&gt;). If your engine supports multiple platforms, consider using more of the imgui_impl_xxxx files instead of rewriting them: this will be less work for you and you can get Dear ImGui running immediately. You can &lt;em&gt;later&lt;/em&gt; decide to rewrite a custom binding using your custom engine functions if you wish so.&lt;/p&gt;
&lt;p&gt;Integrating Dear ImGui within your custom engine is a matter of 1) wiring mouse/keyboard/gamepad inputs 2) uploading one texture to your GPU/render engine 3) providing a render function that can bind textures and render textured triangles. The &lt;a href="https://github.com/ocornut/imgui/tree/master/examples"&gt;examples/&lt;/a&gt; folder is populated with applications doing just that. If you are an experienced programmer at ease with those concepts, it should take you less than two hours to integrate Dear ImGui in your custom engine. &lt;strong&gt;Make sure to spend time reading the &lt;a href="https://www.dearimgui.org/faq" rel="nofollow"&gt;FAQ&lt;/a&gt;, comments, and some of the examples/ application!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Officially maintained bindings (in repository):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Renderers: DirectX9, DirectX10, DirectX11, DirectX12, OpenGL (legacy), OpenGL3/ES/ES2 (modern), Vulkan, Metal.&lt;/li&gt;
&lt;li&gt;Platforms: GLFW, SDL2, Win32, Glut, OSX.&lt;/li&gt;
&lt;li&gt;Frameworks: Emscripten, Allegro5, Marmalade.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Third-party bindings (see &lt;a href="https://github.com/ocornut/imgui/wiki/Bindings/"&gt;Bindings&lt;/a&gt; page):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Languages: C, C#/.Net, ChaiScript, D, Go, Haskell, Haxe/hxcpp, Java, JavaScript, Julia, Lua, Odin, Pascal, PureBasic, Python, Ruby, Rust, Swift...&lt;/li&gt;
&lt;li&gt;Frameworks: Amethyst, bsf, Cinder, Cocos2d-x, Diligent Engine, Flexium, GML/GameMakerStudio2, Irrlicht, Ogre, OpenFrameworks, OpenSceneGraph/OSG, ORX, px_render, LÖVE+Lua, Magnum, NanoRT, Qt, QtDirect3D, SFML, Software Rasterizers, Unreal Engine 4...&lt;/li&gt;
&lt;li&gt;Note that C bindings (&lt;a href="https://github.com/cimgui/cimgui"&gt;cimgui&lt;/a&gt;) are auto-generated, you can use its json/lua output to generate bindings for other languages.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also see &lt;a href="https://github.com/ocornut/imgui/wiki"&gt;Wiki&lt;/a&gt; for more links and ideas.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-upcoming-changes" class="anchor" aria-hidden="true" href="#upcoming-changes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Upcoming Changes&lt;/h3&gt;
&lt;p&gt;Some of the goals for 2019-2020 are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Finish work on docking, tabs. (see &lt;a href="https://github.com/ocornut/imgui/issues/2109"&gt;#2109&lt;/a&gt;, in public &lt;a href="https://github.com/ocornut/imgui/tree/docking"&gt;docking&lt;/a&gt; branch looking for feedback)&lt;/li&gt;
&lt;li&gt;Finish work on multiple viewports / multiple OS windows. (see &lt;a href="https://github.com/ocornut/imgui/issues/1542"&gt;#1542&lt;/a&gt;, in public &lt;a href="https://github.com/ocornut/imgui/tree/docking"&gt;docking&lt;/a&gt; branch looking for feedback)&lt;/li&gt;
&lt;li&gt;Finish work on gamepad/keyboard controls. (see &lt;a href="https://github.com/ocornut/imgui/issues/787"&gt;#787&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Add an automation and testing system, both to test the library and end-user apps. (see &lt;a href="https://github.com/ocornut/imgui/issues/435"&gt;#435&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Make Columns better. They are currently pretty terrible! New Tables API coming Q4 2019!&lt;/li&gt;
&lt;li&gt;Make the examples look better, improve styles, improve font support, make the examples hi-DPI and multi-DPI aware.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-gallery" class="anchor" aria-hidden="true" href="#gallery"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gallery&lt;/h3&gt;
&lt;p&gt;For more user-submitted screenshots of projects using Dear ImGui, check out the &lt;a href="https://github.com/ocornut/imgui/issues/2847"&gt;Gallery Threads&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Custom engine
&lt;a href="https://cloud.githubusercontent.com/assets/8225057/20628927/33e14cac-b329-11e6-80f6-9524e93b048a.png" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v149/gallery_TheDragonsTrap-01-thumb.jpg" alt="screenshot game" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Custom engine
&lt;a href="https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v160/editor_white.png" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v160/editor_white_preview.jpg" alt="screenshot tool" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://bitbucket.org/wolfpld/tracy" rel="nofollow"&gt;Tracy Profiler&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v173/tracy_profiler.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v173/tracy_profiler.jpg" alt="tracy profiler" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-support-frequently-asked-questions-faq" class="anchor" aria-hidden="true" href="#support-frequently-asked-questions-faq"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support, Frequently Asked Questions (FAQ)&lt;/h3&gt;
&lt;p&gt;Most common questions will be answered by the &lt;a href="https://github.com/ocornut/imgui/blob/master/docs/FAQ.md"&gt;Frequently Asked Questions (FAQ)&lt;/a&gt; page.&lt;/p&gt;
&lt;p&gt;See: &lt;a href="https://github.com/ocornut/imgui/wiki"&gt;Wiki&lt;/a&gt; for many links, references, articles.&lt;/p&gt;
&lt;p&gt;See: &lt;a href="https://github.com/ocornut/imgui/wiki#Articles-about-the-IMGUI-paradigm"&gt;Articles about the IMGUI paradigm&lt;/a&gt; to read/learn about the Immediate Mode GUI paradigm.&lt;/p&gt;
&lt;p&gt;If you are new to Dear ImGui and have issues with: compiling, linking, adding fonts, wiring inputs, running or displaying Dear ImGui: you can use &lt;a href="http://discord.dearimgui.org" rel="nofollow"&gt;Discord server&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Otherwise, for any other questions, bug reports, requests, feedback, you may post on &lt;a href="https://github.com/ocornut/imgui/issues"&gt;https://github.com/ocornut/imgui/issues&lt;/a&gt;. Please read and fill the New Issue template carefully.&lt;/p&gt;
&lt;p&gt;Paid private support is available for business customers (E-mail: &lt;em&gt;contact @ dearimgui dot org&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Which version should I get?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I occasionally tag &lt;a href="https://github.com/ocornut/imgui/releases"&gt;Releases&lt;/a&gt; but it is generally safe and recommended to sync to master/latest. The library is fairly stable and regressions tend to be fixed fast when reported.&lt;/p&gt;
&lt;p&gt;You may also peak at the &lt;a href="https://github.com/ocornut/imgui/issues/1542"&gt;Multi-Viewport&lt;/a&gt; and &lt;a href="https://github.com/ocornut/imgui/issues/2109"&gt;Docking&lt;/a&gt; features in the &lt;code&gt;docking&lt;/code&gt; branch. Many projects are using this branch and it is kept in sync with master regularly.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Who uses Dear ImGui?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;See the &lt;a href="https://github.com/ocornut/imgui/wiki/Quotes"&gt;Quotes&lt;/a&gt; and &lt;a href="https://github.com/ocornut/imgui/wiki/Software-using-dear-imgui"&gt;Software using dear imgui&lt;/a&gt; Wiki pages for a list of games/software which are publicly known to use dear imgui. Please add yours if you can! Also see the &lt;a href="https://github.com/ocornut/imgui/issues/2847"&gt;Gallery Threads&lt;/a&gt;!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-help" class="anchor" aria-hidden="true" href="#how-to-help"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to help&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;How can I help?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You may participate in the &lt;a href="http://discord.dearimgui.org" rel="nofollow"&gt;Discord server&lt;/a&gt;, &lt;a href="https://github.com/ocornut/imgui/issues"&gt;GitHub forum/issues&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;You may help with development and submit pull requests! Please understand that by submitting a PR you are also submitting a request for the maintainer to review your code and then take over its maintenance forever. PR should be crafted both in the interest in the end-users and also to ease the maintainer into understanding and accepting it.&lt;/li&gt;
&lt;li&gt;See &lt;a href="https://github.com/ocornut/imgui/wiki/Help-Wanted"&gt;Help wanted&lt;/a&gt; on the &lt;a href="https://github.com/ocornut/imgui/wiki/"&gt;Wiki&lt;/a&gt; for some more ideas.&lt;/li&gt;
&lt;li&gt;Have your company financially support this project.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;How can I help financing further development of Dear ImGui?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Your contributions are keeping this project alive. The library is available under a free and permissive license, but continued maintenance and development are a full-time endeavor and I would like to grow the team. In addition to maintenance and stability there are many desirable features yet to be added. If your company is using dear imgui, please consider reaching out for invoiced technical support and maintenance contracts. If you are an individual using dear imgui, please consider supporting the project via Patreon or PayPal. Thank you!&lt;/p&gt;
&lt;p&gt;Businesses: support continued development via invoiced technical support, maintenance, sponsoring contracts:
&lt;br&gt;  &lt;em&gt;E-mail: contact @ dearimgui dot org&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Individuals/hobbyists: support continued maintenance and development via the monthly Patreon:
&lt;br&gt;  &lt;a href="http://www.patreon.com/imgui" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/wiki/ocornut/imgui/web/patreon_02.png" alt="Patreon" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Individuals/hobbyists: support continued maintenance and development via PayPal:
&lt;br&gt;  &lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=WGHNC6MBFLZ2S" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/bce14c8e2e39ba0464551b34602b4c60c182526b/68747470733a2f2f7777772e70617970616c6f626a656374732e636f6d2f656e5f55532f692f62746e2f62746e5f646f6e6174655f4c472e676966" alt="PayPal" data-canonical-src="https://www.paypalobjects.com/en_US/i/btn/btn_donate_LG.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-sponsors" class="anchor" aria-hidden="true" href="#sponsors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sponsors&lt;/h3&gt;
&lt;p&gt;Ongoing Dear ImGui development is financially supported by users and private sponsors, recently:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Platinum-chocolate sponsors&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Blizzard Entertainment&lt;/li&gt;
&lt;li&gt;Google&lt;/li&gt;
&lt;li&gt;Ubisoft&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Double-chocolate sponsors&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Media Molecule, Mobigame, Aras Pranckevičius, Greggman, DotEmu, Nadeo, Supercell, Aiden Koss, Kylotonn.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Salty caramel supporters&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Remedy Entertainment, Next Level Games, Recognition Robotics, ikrima, Geoffrey Evans, Mercury Labs, Singularity Demo Group, Lionel Landwerlin, Ron Gilbert, Brandon Townsend, G3DVu, Cort Stratton, drudru, Harfang 3D, Jeff Roberts, Rainway inc, Ondra Voves, Mesh Consultants, Unit 2 Games, Neil Bickford, Bill Six, Graham Manders.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Caramel supporters&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jerome Lanquetot, Daniel Collin, Ctrl Alt Ninja, Neil Henning, Neil Blakey-Milner, Aleksei, NeiloGD, Eric, Game Atelier, Vincent Hamm, Morten Skaaning, Colin Riley, Sergio Gonzales, Andrew Berridge, Roy Eltham, Game Preservation Society, Josh Faust, Martin Donlon, Codecat, Doug McNabb, Emmanuel Julien, Guillaume Chereau, Jeffrey Slutter, Jeremiah Deckard, r-lyeh, Nekith, Joshua Fisher, Malte Hoffmann, Mustafa Karaalioglu, Merlyn Morgan-Graham, Per Vognsen, Fabian Giesen, Jan Staubach, Matt Hargett, John Shearer, Jesse Chounard, kingcoopa, Jonas Bernemann, Johan Andersson, Michael Labbe, Tomasz Golebiowski, Louis Schnellbach, Jimmy Andrews, Bojan Endrovski, Robin Berg Pettersen, Rachel Crawford, Andrew Johnson, Sean Hunter, Jordan Mellow, Nefarius Software Solutions, Laura Wieme, Robert Nix, Mick Honey, Steven Kah Hien Wong, Bartosz Bielecki, Oscar Penas, A M, Liam Moynihan, Artometa, Mark Lee, Dimitri Diakopoulos, Pete Goodwin, Johnathan Roatch, nyu lea, Oswald Hurlem, Semyon Smelyanskiy, Le Bach, Jeong MyeongSoo, Chris Matthews, Astrofra, Frederik De Bleser, Anticrisis, Matt Reyer.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And all other past and present supporters; THANK YOU!
(Please contact me if you would like to be added or removed from this list)&lt;/p&gt;
&lt;p&gt;Dear ImGui is using software and services kindly provided free of charge for open source projects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.viva64.com/en/b/0570/" rel="nofollow"&gt;PVS-Studio&lt;/a&gt; for static analysis.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/features/actions"&gt;GitHub actions&lt;/a&gt; for continuous integration systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credits&lt;/h2&gt;
&lt;p&gt;Developed by &lt;a href="http://www.miracleworld.net" rel="nofollow"&gt;Omar Cornut&lt;/a&gt; and every direct or indirect contributors to the GitHub. The early version of this library was developed with the support of &lt;a href="http://www.mediamolecule.com" rel="nofollow"&gt;Media Molecule&lt;/a&gt; and first used internally on the game &lt;a href="http://tearaway.mediamolecule.com" rel="nofollow"&gt;Tearaway&lt;/a&gt; (Vita).&lt;/p&gt;
&lt;p&gt;I first discovered the IMGUI paradigm at &lt;a href="http://www.q-games.com" rel="nofollow"&gt;Q-Games&lt;/a&gt; where Atman Binstock had dropped his own simple implementation in the codebase, which I spent quite some time improving and thinking about. It turned out that Atman was exposed to the concept directly by working with Casey. When I moved to Media Molecule I rewrote a new library trying to overcome the flaws and limitations of the first one I've worked with. It became this library and since then I have spent an unreasonable amount of time iterating and improving it.&lt;/p&gt;
&lt;p&gt;Embeds &lt;a href="http://upperbounds.net" rel="nofollow"&gt;ProggyClean.ttf&lt;/a&gt; font by Tristan Grimmer (MIT license).&lt;/p&gt;
&lt;p&gt;Embeds &lt;a href="https://github.com/nothings/stb/"&gt;stb_textedit.h, stb_truetype.h, stb_rect_pack.h&lt;/a&gt; by Sean Barrett (public domain).&lt;/p&gt;
&lt;p&gt;Inspiration, feedback, and testing for early versions: Casey Muratori, Atman Binstock, Mikko Mononen, Emmanuel Briney, Stefan Kamoda, Anton Mikhailov, Matt Willis. And everybody posting feedback, questions and patches on the GitHub.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Dear ImGui is licensed under the MIT License, see &lt;a href="https://github.com/ocornut/imgui/blob/master/LICENSE.txt"&gt;LICENSE.txt&lt;/a&gt; for more information.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ocornut</author><guid isPermaLink="false">https://github.com/ocornut/imgui</guid><pubDate>Sun, 05 Jan 2020 00:20:00 GMT</pubDate></item><item><title>versatica/mediasoup #21 in C++, Today</title><link>https://github.com/versatica/mediasoup</link><description>&lt;p&gt;&lt;i&gt;Cutting Edge WebRTC Video Conferencing&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-mediasoup-v3" class="anchor" aria-hidden="true" href="#mediasoup-v3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;mediasoup v3&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://mediasoup.org" rel="nofollow"&gt;&lt;img src="/art/mediasoup-banner.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://npmjs.org/package/mediasoup" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e7ef2c0575c359ddf57b43fef9d64cff4339f2fa/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f6d65646961736f75702e737667" alt="" data-canonical-src="https://img.shields.io/npm/v/mediasoup.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.com/versatica/mediasoup" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3cddc02d0f37512aa360b17ad6ed11666ad5da4e/68747470733a2f2f7472617669732d63692e636f6d2f7665727361746963612f6d65646961736f75702e7376673f6272616e63683d6d6173746572" alt="" data-canonical-src="https://travis-ci.com/versatica/mediasoup.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.codacy.com/app/versatica/mediasoup" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e8453c73248f3691000e3a2af1554f3d9af7362a/68747470733a2f2f696d672e736869656c64732e696f2f636f646163792f67726164652f33633862396566633833363734623631383937303761623431383863666232622e737667" alt="" data-canonical-src="https://img.shields.io/codacy/grade/3c8b9efc83674b6189707ab4188cfb2b.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opencollective.com/mediasoup/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a9cb896f5194295c91ec891f47744cd5e645ff01/68747470733a2f2f696d672e736869656c64732e696f2f6f70656e636f6c6c6563746976652f616c6c2f6d65646961736f75702e737667" alt="" data-canonical-src="https://img.shields.io/opencollective/all/mediasoup.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-website-and-documentation" class="anchor" aria-hidden="true" href="#website-and-documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Website and Documentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://mediasoup.org" rel="nofollow"&gt;mediasoup.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-support-forum" class="anchor" aria-hidden="true" href="#support-forum"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support Forum&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://mediasoup.discourse.group" rel="nofollow"&gt;mediasoup.discourse.group&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-design-goals" class="anchor" aria-hidden="true" href="#design-goals"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Goals&lt;/h2&gt;
&lt;p&gt;mediasoup and its client side libraries are designed to accomplish with the following goals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Be a &lt;a href="https://webrtcglossary.com/sfu/" rel="nofollow"&gt;SFU&lt;/a&gt; (Selective Forwarding Unit).&lt;/li&gt;
&lt;li&gt;Support both WebRTC and plain RTP input and output.&lt;/li&gt;
&lt;li&gt;Be a Node.js module in server side.&lt;/li&gt;
&lt;li&gt;Be a tiny JavaScript and C++ libraries in client side.&lt;/li&gt;
&lt;li&gt;Be minimalist: just handle the media layer.&lt;/li&gt;
&lt;li&gt;Be signaling agnostic: do not mandate any signaling protocol.&lt;/li&gt;
&lt;li&gt;Be super low level API.&lt;/li&gt;
&lt;li&gt;Support all existing WebRTC endpoints.&lt;/li&gt;
&lt;li&gt;Enable integration with well known multimedia libraries/tools.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-architecture" class="anchor" aria-hidden="true" href="#architecture"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Architecture&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/art/mediasoup-v3-architecture-01.svg"&gt;&lt;img src="/art/mediasoup-v3-architecture-01.svg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-use-cases" class="anchor" aria-hidden="true" href="#use-cases"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Use Cases&lt;/h2&gt;
&lt;p&gt;mediasoup and its client side libraries provide a super low level API. They are intended to enable different use cases and scenarios, without any constraint or assumption. Some of these use cases are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group video chat applications.&lt;/li&gt;
&lt;li&gt;One-to-many (or few-to-many) broadcasting applications in real-time.&lt;/li&gt;
&lt;li&gt;RTP streaming.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ECMAScript 6 low level API.&lt;/li&gt;
&lt;li&gt;Multi-stream: multiple audio/video streams over a single ICE + DTLS transport.&lt;/li&gt;
&lt;li&gt;IPv6 ready.&lt;/li&gt;
&lt;li&gt;ICE / DTLS / RTP / RTCP over UDP and TCP.&lt;/li&gt;
&lt;li&gt;Simulcast and SVC support.&lt;/li&gt;
&lt;li&gt;Congestion control.&lt;/li&gt;
&lt;li&gt;Sender and receiver bandwidth estimation with spatial/temporal layers distribution algorithm.&lt;/li&gt;
&lt;li&gt;SCTP support (WebRTC DataChannels and SCTP over plain UDP).&lt;/li&gt;
&lt;li&gt;Extremely powerful (media worker subprocess coded in C++ on top of &lt;a href="https://libuv.org" rel="nofollow"&gt;libuv&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-demo-online" class="anchor" aria-hidden="true" href="#demo-online"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Demo Online&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://v3demo.mediasoup.org" rel="nofollow"&gt;&lt;img src="/art/mediasoup-v3.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Try it at &lt;a href="https://v3demo.mediasoup.org" rel="nofollow"&gt;v3demo.mediasoup.org&lt;/a&gt; (&lt;a href="https://github.com/versatica/mediasoup-demo"&gt;source code&lt;/a&gt;).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Iñaki Baz Castillo [&lt;a href="https://inakibaz.me" rel="nofollow"&gt;website&lt;/a&gt;|&lt;a href="https://github.com/ibc/"&gt;github&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;José Luis Millán [&lt;a href="https://github.com/jmillan/"&gt;github&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-donate" class="anchor" aria-hidden="true" href="#donate"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Donate&lt;/h2&gt;
&lt;p&gt;You can support mediasoup by becoming a &lt;a href="https://mediasoup.org/sponsors/#become-a-sponsor" rel="nofollow"&gt;sponsor&lt;/a&gt; or making a &lt;a href="https://mediasoup.org/sponsors/#become-a-sponsor" rel="nofollow"&gt;donation&lt;/a&gt;. Thanks!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a href="./LICENSE"&gt;ISC&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>versatica</author><guid isPermaLink="false">https://github.com/versatica/mediasoup</guid><pubDate>Sun, 05 Jan 2020 00:21:00 GMT</pubDate></item><item><title>dresden-elektronik/deconz-rest-plugin #22 in C++, Today</title><link>https://github.com/dresden-elektronik/deconz-rest-plugin</link><description>&lt;p&gt;&lt;i&gt;REST API Plugin to control ZigBee lights like Philips Hue and dresden elektroniks wireless electronic ballasts&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The deCONZ REST plugin provides a REST-API to access Zigbee 3.0 (Z30), Zigbee Home Automation (ZHA) and Zigbee Light Link (ZLL) lights, switches and sensors from Xiaomi Aqara, IKEA TRÅDFRI, Philips Hue, innr, Samsung and many more vendors.&lt;/p&gt;
&lt;p&gt;A list of supported Zigbee devices can be found on the &lt;a href="https://github.com/dresden-elektronik/deconz-rest-plugin/wiki/Supported-Devices"&gt;Supported Devices&lt;/a&gt; page.&lt;/p&gt;
&lt;p&gt;As hardware the &lt;a href="https://phoscon.de/raspbee?ref=gh" rel="nofollow"&gt;RaspBee&lt;/a&gt; Zigbee Shield for Raspberry Pi, a &lt;a href="https://phoscon.de/conbee?ref=gh" rel="nofollow"&gt;ConBee&lt;/a&gt; or &lt;a href="https://phoscon.de/conbee2?ref=gh" rel="nofollow"&gt;ConBee II&lt;/a&gt; USB-dongle is used to communicate with Zigbee devices.&lt;/p&gt;
&lt;p&gt;To learn more about the REST-API itself please visit the &lt;a href="http://dresden-elektronik.github.io/deconz-rest-doc/" rel="nofollow"&gt;REST-API Documentation&lt;/a&gt; page.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-phoscon-app" class="anchor" aria-hidden="true" href="#phoscon-app"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Phoscon App&lt;/h3&gt;
&lt;p&gt;The Phoscon App is browser based and supports lights, sensors and switches. For more information and screenshots check out:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://phoscon.de/app/doc?ref=gh" rel="nofollow"&gt;Phoscon App Documentation&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h1&gt;
&lt;h5&gt;&lt;a id="user-content-supported-platforms" class="anchor" aria-hidden="true" href="#supported-platforms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Supported platforms&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Raspbian Jessie, Stretch and Buster&lt;/li&gt;
&lt;li&gt;Ubuntu Xenial and Bionic (AMD64)&lt;/li&gt;
&lt;li&gt;Windows 7 and 10&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-install-deconz" class="anchor" aria-hidden="true" href="#install-deconz"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install deCONZ&lt;/h3&gt;
&lt;p&gt;You find the instructions for your platform and device on the Phoscon website:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://phoscon.de/raspbee/install?ref=gh" rel="nofollow"&gt;RaspBee&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://phoscon.de/conbee/install?ref=gh" rel="nofollow"&gt;ConBee&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://phoscon.de/conbee2/install?ref=gh" rel="nofollow"&gt;ConBee II&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; If you're updating from a previous version &lt;strong&gt;always make sure to create an backup&lt;/strong&gt; in the Phoscon App and read the changelog first.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/dresden-elektronik/deconz-rest-plugin/releases"&gt;https://github.com/dresden-elektronik/deconz-rest-plugin/releases&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-install-deconz-development-package-optional-linux-only" class="anchor" aria-hidden="true" href="#install-deconz-development-package-optional-linux-only"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install deCONZ development package (optional, Linux only)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; The deCONZ package already contains the REST-API plugin, the development package is &lt;strong&gt;only&lt;/strong&gt; needed if you wan't to modify the plugin or try the latest commits from master branch.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt install deconz-dev
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-get-and-compile-the-plugin" class="anchor" aria-hidden="true" href="#get-and-compile-the-plugin"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Get and compile the plugin&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Checkout the repository&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; git clone https://github.com/dresden-elektronik/deconz-rest-plugin.git
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Checkout the latest version&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; cd deconz-rest-plugin
 git checkout -b mybranch HEAD
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compile the plugin&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; qmake &amp;amp;&amp;amp; make -j2
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; On Raspberry Pi 1 use &lt;code&gt;qmake &amp;amp;&amp;amp; make&lt;/code&gt;&lt;/p&gt;
&lt;ol start="4"&gt;
&lt;li&gt;
&lt;p&gt;Replace original plugin&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; sudo cp ../libde_rest_plugin.so /usr/share/deCONZ/plugins
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;&lt;a id="user-content-precompiled-deconz-packages-for-manual-installation" class="anchor" aria-hidden="true" href="#precompiled-deconz-packages-for-manual-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Precompiled deCONZ packages for manual installation&lt;/h1&gt;
&lt;p&gt;The deCONZ application packages are available for the following platforms and contain the main application and the pre-compiled REST-API plugin.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows  &lt;a href="http://deconz.dresden-elektronik.de/win/" rel="nofollow"&gt;http://deconz.dresden-elektronik.de/win/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Raspbian &lt;a href="http://deconz.dresden-elektronik.de/raspbian/beta/" rel="nofollow"&gt;http://deconz.dresden-elektronik.de/raspbian/beta/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ubuntu and Debian 64-bit &lt;a href="http://deconz.dresden-elektronik.de/ubuntu/beta/" rel="nofollow"&gt;http://deconz.dresden-elektronik.de/ubuntu/beta/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To manually install a Linux .deb package enter these commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo dpkg -i &amp;lt;package name&amp;gt;.deb
sudo apt-get install -f
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-headless-support-for-linux" class="anchor" aria-hidden="true" href="#headless-support-for-linux"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Headless support for Linux&lt;/h2&gt;
&lt;p&gt;The deCONZ package contains a systemd script, which allows deCONZ to run without a X11 server.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Enable the service at boot time&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ sudo systemctl &lt;span class="pl-c1"&gt;enable&lt;/span&gt; deconz&lt;/pre&gt;&lt;/div&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Disable deCONZ GUI autostart service&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The dresden elektronik sd-card image and default installation method autostarts deCONZ GUI.
The following commands disable the deCONZ GUI service:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ sudo systemctl disable deconz-gui
$ sudo systemctl stop deconz-gui&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-hardware-requirements" class="anchor" aria-hidden="true" href="#hardware-requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hardware requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Raspberry Pi 1, 2B, 3B, 3B+ or 4B&lt;/li&gt;
&lt;li&gt;&lt;a href="https://phoscon.de/raspbee?ref=gh" rel="nofollow"&gt;RaspBee&lt;/a&gt; Zigbee Shield for Raspberry Pi&lt;/li&gt;
&lt;li&gt;&lt;a href="https://phoscon.de/conbee?ref=gh" rel="nofollow"&gt;ConBee&lt;/a&gt; USB-dongle for Raspberry Pi and PC&lt;/li&gt;
&lt;li&gt;&lt;a href="https://phoscon.de/conbee2?ref=gh" rel="nofollow"&gt;ConBee II&lt;/a&gt; USB-dongle for Raspberry Pi and PC&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-3rd-party-libraries" class="anchor" aria-hidden="true" href="#3rd-party-libraries"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3rd party libraries&lt;/h2&gt;
&lt;p&gt;The following libraries are used by the plugin:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.sqlite.org" rel="nofollow"&gt;SQLite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lawand/droper/tree/master/qt-json"&gt;qt-json&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.getreuer.info/home/colorspace" rel="nofollow"&gt;colorspace&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h1&gt;
&lt;p&gt;The plugin is available as open source and licensed under the BSD (3-Clause) license.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dresden-elektronik</author><guid isPermaLink="false">https://github.com/dresden-elektronik/deconz-rest-plugin</guid><pubDate>Sun, 05 Jan 2020 00:22:00 GMT</pubDate></item><item><title>NVIDIA/VideoProcessingFramework #23 in C++, Today</title><link>https://github.com/NVIDIA/VideoProcessingFramework</link><description>&lt;p&gt;&lt;i&gt;Set of Python bindings to C++ libraries which provides full HW acceleration for video decoding, encoding and GPU-accelerated color space and pixel format conversions&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-videoprocessingframework" class="anchor" aria-hidden="true" href="#videoprocessingframework"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;VideoProcessingFramework&lt;/h1&gt;
&lt;p&gt;VPF stands for Video Processing Framework. It’s set of C++ libraries and Python bindings which provides full HW acceleration for video processing tasks such as decoding, encoding, transcoding and GPU-accelerated color space and pixel format conversions.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>NVIDIA</author><guid isPermaLink="false">https://github.com/NVIDIA/VideoProcessingFramework</guid><pubDate>Sun, 05 Jan 2020 00:23:00 GMT</pubDate></item><item><title>pytorch/glow #24 in C++, Today</title><link>https://github.com/pytorch/glow</link><description>&lt;p&gt;&lt;i&gt;Compiler for Neural Network hardware accelerators&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/logo.svg"&gt;&lt;img src="./docs/logo.svg" alt="Glow Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/pytorch/glow" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ab5432f3a6efed3daedc3a7276eed56477741eaf/68747470733a2f2f7472617669732d63692e6f72672f7079746f7263682f676c6f772e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/pytorch/glow.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://fb-glow-assets.s3.amazonaws.com/coverage/coverage-master/index.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/b829967413e253f65bf496caf09e653a181f22ee/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f7665726167652d6f70656e2d627269676874677265656e2e7376673f7374796c653d666c6174" alt="Code Coverage" data-canonical-src="https://img.shields.io/badge/coverage-open-brightgreen.svg?style=flat" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Glow is a machine learning compiler and execution engine for hardware
accelerators.  It is designed to be used as a backend for high-level machine
learning frameworks.  The compiler is designed to allow state of the art
compiler optimizations and code generation of neural network graphs. This
library is in active development. The project plan is described in the Github
issues section and in the
&lt;a href="https://github.com/pytorch/glow/wiki/Glow-Roadmap"&gt;Roadmap&lt;/a&gt; wiki page.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-partners" class="anchor" aria-hidden="true" href="#partners"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Partners&lt;/h2&gt;
&lt;p&gt;Contributions to Glow are welcomed and encouraged! Glow is developed in
collaboration with the following partners:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/partners/bitmain.png"&gt;&lt;img src="./docs/partners/bitmain.png" alt="Bitmain Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/partners/habana.png"&gt;&lt;img src="./docs/partners/habana.png" alt="Habana Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/partners/st.png"&gt;&lt;img src="./docs/partners/st.png" alt="ST Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/partners/cadence.png"&gt;&lt;img src="./docs/partners/cadence.png" alt="Cadence Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/partners/intel.png"&gt;&lt;img src="./docs/partners/intel.png" alt="Intel Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/partners/synopsys.png"&gt;&lt;img src="./docs/partners/synopsys.png" alt="Synopsys Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/partners/ceva.png"&gt;&lt;img src="./docs/partners/ceva.png" alt="CEVA Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/partners/marvell.png"&gt;&lt;img src="./docs/partners/marvell.png" alt="Marvell Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/partners/esperanto.png"&gt;&lt;img src="./docs/partners/esperanto.png" alt="Esperanto Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/partners/nxp.png"&gt;&lt;img src="./docs/partners/nxp.png" alt="NXP Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-how-does-it-work" class="anchor" aria-hidden="true" href="#how-does-it-work"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How does it work?&lt;/h2&gt;
&lt;p&gt;Glow lowers a traditional neural network dataflow graph into a two-phase
strongly-typed &lt;a href="./docs/IR.md"&gt;intermediate representation (IR)&lt;/a&gt;. The high-level
IR allows the optimizer to perform domain-specific optimizations. The
lower-level instruction-based address-only IR allows the compiler to perform
memory-related optimizations, such as instruction scheduling, static memory
allocation and copy elimination. At the lowest level, the optimizer performs
machine-specific code generation to take advantage of specialized hardware
features. Glow features a lowering phase which enables the compiler to support a
high number of input operators as well as a large number of hardware targets by
eliminating the need to implement all operators on all targets. The lowering
phase is designed to reduce the input space and allow new hardware backends to
focus on a small number of linear algebra primitives.
The design philosophy is described in an &lt;a href="https://arxiv.org/abs/1805.00907" rel="nofollow"&gt;arXiv paper&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/3LevelIR.png"&gt;&lt;img src="./docs/3LevelIR.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-system-requirements" class="anchor" aria-hidden="true" href="#system-requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;System Requirements&lt;/h3&gt;
&lt;p&gt;Glow builds and runs on macOS and Linux. The software depends on a modern C++
compiler that supports C++11, on CMake, LLVM, glog, protocol buffers, and
libpng.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-get-glow" class="anchor" aria-hidden="true" href="#get-glow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Get Glow!&lt;/h4&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone git@github.com:pytorch/glow.git  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; or: git clone https://github.com/pytorch/glow.git&lt;/span&gt;
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; glow&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-submodules" class="anchor" aria-hidden="true" href="#submodules"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Submodules&lt;/h4&gt;
&lt;p&gt;Glow depends on a few submodules: googletest, onnx, and a library
for FP16 conversions.&lt;/p&gt;
&lt;p&gt;To get them, from the glow directory, run:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git submodule update --init --recursive&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-macos" class="anchor" aria-hidden="true" href="#macos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;macOS&lt;/h4&gt;
&lt;p&gt;Install the required dependencies using either &lt;a href="https://brew.sh/" rel="nofollow"&gt;Homebrew&lt;/a&gt; or
&lt;a href="https://www.macports.org/" rel="nofollow"&gt;MacPorts&lt;/a&gt;. If using Homebrew, run:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;brew install cmake graphviz libpng ninja protobuf wget glog autopep8
brew install llvm@7&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If using MacPorts, run:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;port install cmake graphviz libpng ninja protobuf-cpp wget llvm-7.0 google-glog&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that LLVM is installed in a non-default location to avoid conflicts with
the system's LLVM --Homebrew usually installs LLVM in &lt;code&gt;/usr/local/opt/llvm/&lt;/code&gt;,
whereas MacPorts installs it in &lt;code&gt;/opt/local/libexec/llvm-7.0/&lt;/code&gt;. This means that
CMake will need to be told where to find LLVM when building; instructions on
that can be found &lt;a href="#building-with-dependencies-llvm"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Finally, create a symbolic link to the Homebrew- or MacPorts-installed
&lt;code&gt;clang-*&lt;/code&gt; tools so that the &lt;code&gt;utils/format.sh&lt;/code&gt; script is able to find them later
on. For a Homebrew-managed installation, run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ln -s "/usr/local/opt/llvm/bin/clang-format" "/usr/local/bin/clang-format"
ln -s "/usr/local/opt/llvm/bin/clang-tidy" "/usr/local/bin/clang-tidy"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For MacPorts, run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ln -s "/opt/local/libexec/llvm-7.0/bin/clang-format" "/usr/local/bin/clang-format"
ln -s "/opt/local/libexec/llvm-7.0/bin/clang-tidy" "/usr/local/bin/clang-tidy"
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; On newer versions of macOS, Xcode's command line tools come with a
non-traditional header layout. In order for Glow to build on newer macOS
versions, you might need to install &lt;code&gt;macOS_SDK_headers_for_macOS_10.14.pkg&lt;/code&gt;
manually. For example, on Mojave this package is located in
&lt;code&gt;/Library/Developer/CommandLineTools/Packages/&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-ubuntu" class="anchor" aria-hidden="true" href="#ubuntu"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ubuntu&lt;/h4&gt;
&lt;p&gt;[The following instructions have been tested on Ubuntu 16.04 and 18.04]&lt;/p&gt;
&lt;p&gt;In order to build Glow on Ubuntu it is necessary to install a few packages. The
following command should install the required dependencies:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo apt-get install clang clang-8 cmake graphviz libpng-dev \
    libprotobuf-dev llvm-8 llvm-8-dev ninja-build protobuf-compiler wget \
    opencl-headers libgoogle-glog-dev&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;[Note: Ubuntu 16.04 and 18.04 ship with llvm-6 and need to be upgraded before building Glow. Building Glow on Ubuntu 16.04 with llvm-7 fails because llvm-7 xenial distribution uses an older c++ ABI, however building Glow on Ubuntu 18.04 with llvm-7 has been tested and is successful]&lt;/p&gt;
&lt;p&gt;It may be desirable to use &lt;code&gt;update-alternatives&lt;/code&gt; to manage the version of
clang/clang++:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo update-alternatives --install /usr/bin/clang clang \
    /usr/lib/llvm-8/bin/clang 50
sudo update-alternatives --install /usr/bin/clang++ clang++ \
    /usr/lib/llvm-8/bin/clang++ 50&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Glow uses the system default C/C++ compiler (/usr/bin/c++), and so you may also
want to switch your default C/C++ compiler to clang:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo update-alternatives --config cc
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Select the option corresponding to /usr/bin/clang ...&lt;/span&gt;
sudo update-alternatives --config c++
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Select the option corresponding to /usr/bin/clang++ ...&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Glow &lt;em&gt;should&lt;/em&gt; build just fine with gcc (e.g. gcc 5.4), but we mostly use clang
and are more attentive to compatibility with clang.&lt;/p&gt;
&lt;p&gt;Finally, in order to support the ONNX net serialization format, Glow requires
&lt;code&gt;protobuf &amp;gt;= 2.6.1&lt;/code&gt;, but the above command may install older
version on older Ubuntu (e.g. 14.04). If this is the case, we suggest to look
at &lt;code&gt;utils/install_protobuf.sh&lt;/code&gt; to install a newer version from source.&lt;/p&gt;
&lt;p&gt;For details on installing OpenCL on Ubuntu please see
&lt;a href="docs/Building.md#opencl-on-ubuntu"&gt;these instructions&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-configure-and-build" class="anchor" aria-hidden="true" href="#configure-and-build"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configure and Build&lt;/h3&gt;
&lt;p&gt;To build the compiler, create a build directory and run cmake on the source
directory. It's a good idea to build two configurations (Release and Debug)
because some programs take a really long time to run in Debug mode. It's also a
good idea to build the project outside of the source directory.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;mkdir build_Debug
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; build_Debug
cmake -G Ninja -DCMAKE_BUILD_TYPE=Debug ../glow
ninja all&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It's possible to configure and build the compiler with any CMake generator,
like GNU Makefiles, Ninja and Xcode build.&lt;/p&gt;
&lt;p&gt;For platform-specific build instructions and advanced options, such as
building with Address-Sanitizers refer to this guide:
&lt;a href="docs/Building.md"&gt;Building the Compiler&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you're running Mac OS v10.14 (Mojave) and &lt;code&gt;ninja all&lt;/code&gt; fails because it can't
find headers (e.g. &lt;code&gt;string.h&lt;/code&gt;), run this command to fix it, and try again.
More information is available &lt;a href="https://developer.apple.com/documentation/xcode_release_notes/xcode_10_release_notes" rel="nofollow"&gt;here&lt;/a&gt;
under "Command Line Tools".&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;open /Library/Developer/CommandLineTools/Packages/macOS_SDK_headers_for_macOS_10.14.pkg
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-building-with-dependencies-llvm" class="anchor" aria-hidden="true" href="#building-with-dependencies-llvm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building with dependencies (LLVM)&lt;/h4&gt;
&lt;p&gt;By default, Glow will use a system provided LLVM.  Note that Glow requires LLVM
7.0 or later. If you have LLVM installed in a non-default location (for
example, if you installed it using Homebrew on macOS), you need to tell CMake
where to find llvm using &lt;code&gt;-DLLVM_DIR&lt;/code&gt;. For example, if LLVM were
installed in &lt;code&gt;/usr/local/opt&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;cmake -G Ninja ../glow \
    -DCMAKE_BUILD_TYPE=Debug \
    -DLLVM_DIR=/usr/local/opt/llvm@7/lib/cmake/llvm&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If LLVM is not available on your system you'll need to build it manually.  Run
the script '&lt;code&gt;/utils/build_llvm.sh&lt;/code&gt; to clone, build and install LLVM in a local
directory. You will need to configure Glow with the flag &lt;code&gt;-DLLVM_DIR&lt;/code&gt; to tell
the build system where to find LLVM given the local directory you installed it
in (e.g. &lt;code&gt;-DLLVM_DIR=/path/to/llvm_install/lib/cmake/llvm&lt;/code&gt; if using
&lt;code&gt;build_llvm.sh&lt;/code&gt;).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-testing-and-running" class="anchor" aria-hidden="true" href="#testing-and-running"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Testing and Running&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-unit-tests" class="anchor" aria-hidden="true" href="#unit-tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Unit tests&lt;/h3&gt;
&lt;p&gt;The project has a few unit tests in the tests/unittests subdirectory. To run all
of them, simply run &lt;code&gt;ninja test&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-c-api-examples" class="anchor" aria-hidden="true" href="#c-api-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;C++ API examples&lt;/h3&gt;
&lt;p&gt;A few test programs that use Glow's C++ API are found under the &lt;code&gt;examples/&lt;/code&gt;
subdirectory. The &lt;code&gt;mnist&lt;/code&gt;, &lt;code&gt;cifar10&lt;/code&gt;, &lt;code&gt;fr2en&lt;/code&gt; and &lt;code&gt;ptb&lt;/code&gt; programs train and run digit
recognition, image classification and language modeling benchmarks,
respectively.&lt;/p&gt;
&lt;p&gt;To run these programs, build Glow in Release mode, then run the following commands
to download the cifar10, mnist and ptb databases.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python ../glow/utils/download_datasets_and_models.py --all-datasets&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now run the examples. Note that the databases should be in the current working
directory.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;./bin/mnist
./bin/cifar10
./bin/fr2en
./bin/ptb
./bin/char-rnn&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If everything goes well you should see:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mnist&lt;/code&gt;: pictures from the mnist digits database&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cifar10&lt;/code&gt;: image classifications that steadily improve&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fr2en&lt;/code&gt;: an interactive French-to-English translator&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ptb&lt;/code&gt;: decreasing perplexity on the dataset as the network trains&lt;/li&gt;
&lt;li&gt;&lt;code&gt;char-rnn&lt;/code&gt;: generates random text based on some document&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that the default build mode is &lt;code&gt;Debug&lt;/code&gt;, which means that the compiler
itself is easy to debug because the binary contains debug info, lots of
assertions, and the optimizations are disabled. It also means that the compiler
and runtime are very slow, and the execution time can be hundreds of times
slower than that of release builds. If you wish to benchmark the compiler, run
long benchmarks, or release the product then you should compile the compiler in
Release mode. Check the main CMake file for more details.&lt;/p&gt;
&lt;p&gt;More details on testing and running Glow can be found in:
&lt;a href="docs/Testing.md"&gt;Testing the Glow Compiler&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-ahead-of-time-compilation" class="anchor" aria-hidden="true" href="#ahead-of-time-compilation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ahead-of-time Compilation&lt;/h3&gt;
&lt;p&gt;Glow can be used to compile neural networks into object files containing native
code.  We provide resnet50 (both quantized and non-quantized versions) as an
example of this capability in &lt;code&gt;examples/bundles/resnet50&lt;/code&gt;.  See &lt;a href="docs/AOT.md"&gt;Creating
Standalone Executable Bundles&lt;/a&gt; for more detail.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;To get started contributing, please refer to the following guides:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/CodingStandards.md"&gt;Coding Standards&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-communication" class="anchor" aria-hidden="true" href="#communication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Communication&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Forums: discuss implementations, research, etc: &lt;a href="https://discuss.pytorch.org/c/glow" rel="nofollow"&gt;https://discuss.pytorch.org/c/glow&lt;/a&gt;.
Make sure to label topic with the &lt;a href="https://discuss.pytorch.org/c/glow" rel="nofollow"&gt;"glow"&lt;/a&gt; category.&lt;/li&gt;
&lt;li&gt;GitHub issues: bug reports, feature requests, install issues, RFCs, thoughts, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Glow is licensed under the &lt;a href="LICENSE"&gt;Apache 2.0 License&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>pytorch</author><guid isPermaLink="false">https://github.com/pytorch/glow</guid><pubDate>Sun, 05 Jan 2020 00:24:00 GMT</pubDate></item><item><title>google/sentencepiece #25 in C++, Today</title><link>https://github.com/google/sentencepiece</link><description>&lt;p&gt;&lt;i&gt;Unsupervised text tokenizer for Neural Network-based text generation.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-sentencepiece" class="anchor" aria-hidden="true" href="#sentencepiece"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SentencePiece&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/google/sentencepiece" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6d48ea29533e6c2600104ad0d54e3a2203294f1e/68747470733a2f2f7472617669732d63692e6f72672f676f6f676c652f73656e74656e636570696563652e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/google/sentencepiece.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/taku910/sentencepiece" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e7f78e3918c96c26796bebbcffb10c6e7c083f50/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f76786f756233717834667770797379713f7376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/vxoub3qx4fwpysyq?svg=true" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://coveralls.io/github/google/sentencepiece?branch=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c96a0be76d9868c9fd34e31337db2b2fdfbad816/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f676f6f676c652f73656e74656e636570696563652f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/google/sentencepiece/badge.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/google/sentencepiece/issues"&gt;&lt;img src="https://camo.githubusercontent.com/2eb12e354288dafe03a955e4aca179f7a758a7f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f676f6f676c652f73656e74656e636570696563652e737667" alt="GitHub Issues" data-canonical-src="https://img.shields.io/github/issues/google/sentencepiece.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://app.codacy.com/app/taku910/sentencepiece?utm_source=github.com&amp;amp;utm_medium=referral&amp;amp;utm_content=google/sentencepiece&amp;amp;utm_campaign=Badge_Grade_Dashboard" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/06a6b607b848cee836b91b5029529215e9b99eb5/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f3538353139343566633534393437666339653936346637386333623662646661" alt="Codacy Badge" data-canonical-src="https://api.codacy.com/project/badge/Grade/5851945fc54947fc9e964f78c3b6bdfa" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://badge.fury.io/py/sentencepiece" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/01cd977b224a38194bdcc6f7e7ac726e354adba3/68747470733a2f2f62616467652e667572792e696f2f70792f73656e74656e636570696563652e737667" alt="PyPI version" data-canonical-src="https://badge.fury.io/py/sentencepiece.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="CONTRIBUTING.md"&gt;&lt;img src="https://camo.githubusercontent.com/8f697c48adc5026cc6d83dd45e42b9b93ee1803c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e747269627574696f6e732d77656c636f6d652d627269676874677265656e2e737667" alt="Contributions welcome" data-canonical-src="https://img.shields.io/badge/contributions-welcome-brightgreen.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opensource.org/licenses/Apache-2.0" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/dc5c93f4ddfa92aaed4ace74e89dbc075f7810c8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d627269676874677265656e2e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-brightgreen.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;SentencePiece is an unsupervised text tokenizer and detokenizer mainly for
Neural Network-based text generation systems where the vocabulary size
is predetermined prior to the neural model training. SentencePiece implements
&lt;strong&gt;subword units&lt;/strong&gt; (e.g., &lt;strong&gt;byte-pair-encoding (BPE)&lt;/strong&gt; [&lt;a href="http://www.aclweb.org/anthology/P16-1162" rel="nofollow"&gt;Sennrich et al.&lt;/a&gt;]) and
&lt;strong&gt;unigram language model&lt;/strong&gt; [&lt;a href="https://arxiv.org/abs/1804.10959" rel="nofollow"&gt;Kudo.&lt;/a&gt;])
with the extension of direct training from raw sentences. SentencePiece allows us to make a purely end-to-end system that does not depend on language-specific pre/postprocessing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This is not an official Google product.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-technical-highlights" class="anchor" aria-hidden="true" href="#technical-highlights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Technical highlights&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Purely data driven&lt;/strong&gt;: SentencePiece trains tokenization and detokenization
models from sentences. Pre-tokenization (&lt;a href="https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/tokenizer.perl"&gt;Moses tokenizer&lt;/a&gt;/&lt;a href="http://taku910.github.io/mecab/" rel="nofollow"&gt;MeCab&lt;/a&gt;/&lt;a href="http://www.phontron.com/kytea/" rel="nofollow"&gt;KyTea&lt;/a&gt;) is not always required.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Language independent&lt;/strong&gt;: SentencePiece treats the sentences just as sequences of Unicode characters. There is no language-dependent logic.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multiple subword algorithms&lt;/strong&gt;: &lt;strong&gt;BPE&lt;/strong&gt;  [&lt;a href="http://www.aclweb.org/anthology/P16-1162" rel="nofollow"&gt;Sennrich et al.&lt;/a&gt;] and &lt;strong&gt;unigram language model&lt;/strong&gt; [&lt;a href="https://arxiv.org/abs/1804.10959" rel="nofollow"&gt;Kudo.&lt;/a&gt;] are supported.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Subword regularization&lt;/strong&gt;: SentencePiece implements subword sampling for &lt;a href="https://arxiv.org/abs/1804.10959" rel="nofollow"&gt;subword regularization&lt;/a&gt; which helps to improve the robustness and accuracy of NMT models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fast and lightweight&lt;/strong&gt;: Segmentation speed is around 50k sentences/sec, and memory footprint is around 6MB.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Self-contained&lt;/strong&gt;: The same tokenization/detokenization is obtained as long as the same model file is used.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Direct vocabulary id generation&lt;/strong&gt;: SentencePiece manages vocabulary to id mapping and can directly generate vocabulary id sequences from raw sentences.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NFKC-based normalization&lt;/strong&gt;: SentencePiece performs NFKC-based text normalization.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-comparisons-with-other-implementations" class="anchor" aria-hidden="true" href="#comparisons-with-other-implementations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Comparisons with other implementations&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Feature&lt;/th&gt;
&lt;th align="center"&gt;SentencePiece&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://github.com/rsennrich/subword-nmt"&gt;subword-nmt&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://arxiv.org/pdf/1609.08144.pdf" rel="nofollow"&gt;WordPiece&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;Supported algorithm&lt;/td&gt;
&lt;td align="center"&gt;BPE, unigram, char, word&lt;/td&gt;
&lt;td align="center"&gt;BPE&lt;/td&gt;
&lt;td align="center"&gt;BPE*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;OSS?&lt;/td&gt;
&lt;td align="center"&gt;Yes&lt;/td&gt;
&lt;td align="center"&gt;Yes&lt;/td&gt;
&lt;td align="center"&gt;Google internal&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;Subword regularization&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#subword-regularization"&gt;Yes&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;No&lt;/td&gt;
&lt;td align="center"&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;Python Library (pip)&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="python/README.md"&gt;Yes&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;No&lt;/td&gt;
&lt;td align="center"&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;C++ Library&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="doc/api.md"&gt;Yes&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;No&lt;/td&gt;
&lt;td align="center"&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;Pre-segmentation required?&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#whitespace-is-treated-as-a-basic-symbol"&gt;No&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Yes&lt;/td&gt;
&lt;td align="center"&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;Customizable normalization (e.g., NFKC)&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="doc/normalization.md"&gt;Yes&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;No&lt;/td&gt;
&lt;td align="center"&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;Direct id generation&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="#end-to-end-example"&gt;Yes&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;No&lt;/td&gt;
&lt;td align="center"&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note that BPE algorithm used in WordPiece is slightly different from the original BPE.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overview&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-what-is-sentencepiece" class="anchor" aria-hidden="true" href="#what-is-sentencepiece"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is SentencePiece?&lt;/h3&gt;
&lt;p&gt;SentencePiece is a re-implementation of &lt;strong&gt;sub-word units&lt;/strong&gt;, an effective way to alleviate the open vocabulary
problems in neural machine translation. SentencePiece supports two segmentation algorithms, &lt;strong&gt;byte-pair-encoding (BPE)&lt;/strong&gt; [&lt;a href="http://www.aclweb.org/anthology/P16-1162" rel="nofollow"&gt;Sennrich et al.&lt;/a&gt;] and &lt;strong&gt;unigram language model&lt;/strong&gt; [&lt;a href="https://arxiv.org/abs/1804.10959" rel="nofollow"&gt;Kudo.&lt;/a&gt;]. Here are the high level differences from other implementations.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-the-number-of-unique-tokens-is-predetermined" class="anchor" aria-hidden="true" href="#the-number-of-unique-tokens-is-predetermined"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The number of unique tokens is predetermined&lt;/h4&gt;
&lt;p&gt;Neural Machine Translation models typically operate with a fixed
vocabulary. Unlike most unsupervised word segmentation algorithms, which
assume an infinite vocabulary, SentencePiece trains the segmentation model such
that the final vocabulary size is fixed, e.g., 8k, 16k, or 32k.&lt;/p&gt;
&lt;p&gt;Note that SentencePiece specifies the final vocabulary size for training, which is different from
&lt;a href="https://github.com/rsennrich/subword-nmt"&gt;subword-nmt&lt;/a&gt; that uses the number of merge operations.
The number of merge operations is a BPE-specific parameter and not applicable to other segmentation algorithms, including unigram, word and character.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-trains-from-raw-sentences" class="anchor" aria-hidden="true" href="#trains-from-raw-sentences"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Trains from raw sentences&lt;/h4&gt;
&lt;p&gt;Previous sub-word implementations assume that the input sentences are pre-tokenized. This constraint was required for efficient training, but makes the preprocessing complicated as we have to run language dependent tokenizers in advance.
The implementation of SentencePiece is fast enough to train the model from raw sentences. This is useful for training the tokenizer and detokenizer for Chinese and Japanese where no explicit spaces exist between words.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-whitespace-is-treated-as-a-basic-symbol" class="anchor" aria-hidden="true" href="#whitespace-is-treated-as-a-basic-symbol"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Whitespace is treated as a basic symbol&lt;/h4&gt;
&lt;p&gt;The first step of Natural Language processing is text tokenization. For
example, a standard English tokenizer would segment the text "Hello world." into the
following three tokens.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[Hello] [World] [.]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One observation is that the original input and tokenized sequence are &lt;strong&gt;NOT
reversibly convertible&lt;/strong&gt;. For instance, the information that is no space between
“World” and “.” is dropped from the tokenized sequence, since e.g., &lt;code&gt;Tokenize(“World.”) == Tokenize(“World .”)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;SentencePiece treats the input text just as a sequence of Unicode characters. Whitespace is also handled as a normal symbol. To handle the whitespace as a basic token explicitly, SentencePiece first escapes the whitespace with a meta symbol "▁" (U+2581) as follows.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hello▁World.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Then, this text is segmented into small pieces, for example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[Hello] [▁Wor] [ld] [.]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since the whitespace is preserved in the segmented text, we can detokenize the text without any ambiguities.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  detokenized = ''.join(pieces).replace('_', ' ')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This feature makes it possible to perform detokenization without relying on language-specific resources.&lt;/p&gt;
&lt;p&gt;Note that we cannot apply the same lossless conversions when splitting the
sentence with standard word segmenters, since they treat the whitespace as a
special symbol. Tokenized sequences do not preserve the necessary information to restore the original sentence.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(en) Hello world.   → [Hello] [World] [.]   (A space between Hello and World)&lt;/li&gt;
&lt;li&gt;(ja) こんにちは世界。  → [こんにちは] [世界] [。] (No space between こんにちは and 世界)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-subword-regularization" class="anchor" aria-hidden="true" href="#subword-regularization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Subword regularization&lt;/h4&gt;
&lt;p&gt;Subword regularization [&lt;a href="https://arxiv.org/abs/1804.10959" rel="nofollow"&gt;Kudo.&lt;/a&gt;] is a simple regularization method
that virtually augments training data with on-the-fly subword sampling, which helps to improve the accuracy as well as robustness of NMT models.&lt;/p&gt;
&lt;p&gt;To enable subword regularization, you would like to integrate SentencePiece library
(&lt;a href="doc/api.md#sampling-subword-regularization"&gt;C++&lt;/a&gt;/&lt;a href="python/README.md"&gt;Python&lt;/a&gt;) into the NMT system to sample one segmentation for each parameter update, which is different from the standard off-line data preparations. Here's the example of &lt;a href="python/README.md"&gt;Python library&lt;/a&gt;. You can find that 'New York' is segmented differently on each &lt;code&gt;SampleEncode&lt;/code&gt; call. The details of sampling parameters are found in &lt;a href="src/sentencepiece_processor.h"&gt;sentencepiece_processor.h&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import sentencepiece as spm
&amp;gt;&amp;gt;&amp;gt; s = spm.SentencePieceProcessor()
&amp;gt;&amp;gt;&amp;gt; s.Load('spm.model')
&amp;gt;&amp;gt;&amp;gt; for n in range(5):
...     s.SampleEncodeAsPieces('New York', -1, 0.1)
... 
['▁', 'N', 'e', 'w', '▁York']
['▁', 'New', '▁York']
['▁', 'New', '▁Y', 'o', 'r', 'k']
['▁', 'New', '▁York']
['▁', 'New', '▁York']
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-python-module" class="anchor" aria-hidden="true" href="#python-module"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python module&lt;/h3&gt;
&lt;p&gt;SentencePiece provides Python wrapper that supports both SentencePiece training and segmentation.
You can install Python binary package of SentencePiece with.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% pip install sentencepiece
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more detail, see &lt;a href="python/README.md"&gt;Python module&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-c-from-source" class="anchor" aria-hidden="true" href="#c-from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;C++ (from source)&lt;/h3&gt;
&lt;p&gt;The following tools and libraries are required to build SentencePiece:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cmake.org/" rel="nofollow"&gt;cmake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;C++11 compiler&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gperftools/gperftools"&gt;gperftools&lt;/a&gt; library (optional, 10-40% performance improvement can be obtained.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On Ubuntu, the build tools can be installed with apt-get:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% sudo apt-get install cmake build-essential pkg-config libgoogle-perftools-dev
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-build-and-install-sentencepiece" class="anchor" aria-hidden="true" href="#build-and-install-sentencepiece"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Build and Install SentencePiece&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;% cd /path/to/sentencepiece
% mkdir build
% cd build
% cmake ..
% make -j $(nproc)
% sudo make install
% sudo ldconfig -v
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On OSX/macOS, replace the last command with &lt;code&gt;sudo update_dyld_shared_cache&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-tensorflow-module" class="anchor" aria-hidden="true" href="#tensorflow-module"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow module&lt;/h3&gt;
&lt;p&gt;See &lt;a href="tensorflow/README.md"&gt;tensorflow/README.md&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-usage-instructions" class="anchor" aria-hidden="true" href="#usage-instructions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage instructions&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-train-sentencepiece-model" class="anchor" aria-hidden="true" href="#train-sentencepiece-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train SentencePiece Model&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;% spm_train --input=&amp;lt;input&amp;gt; --model_prefix=&amp;lt;model_name&amp;gt; --vocab_size=8000 --character_coverage=1.0 --model_type=&amp;lt;type&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--input&lt;/code&gt;: one-sentence-per-line &lt;strong&gt;raw&lt;/strong&gt; corpus file. No need to run
tokenizer, normalizer or preprocessor. By default, SentencePiece normalizes
the input with Unicode NFKC. You can pass a comma-separated list of files.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--model_prefix&lt;/code&gt;: output model name prefix. &lt;code&gt;&amp;lt;model_name&amp;gt;.model&lt;/code&gt; and &lt;code&gt;&amp;lt;model_name&amp;gt;.vocab&lt;/code&gt; are generated.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--vocab_size&lt;/code&gt;: vocabulary size, e.g., 8000, 16000, or 32000&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--character_coverage&lt;/code&gt;: amount of characters covered by the model, good defaults are: &lt;code&gt;0.9995&lt;/code&gt; for languages with rich character set like Japanse or Chinese and &lt;code&gt;1.0&lt;/code&gt; for other languages with small character set.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--model_type&lt;/code&gt;: model type. Choose from &lt;code&gt;unigram&lt;/code&gt; (default), &lt;code&gt;bpe&lt;/code&gt;, &lt;code&gt;char&lt;/code&gt;, or &lt;code&gt;word&lt;/code&gt;. The input sentence must be pretokenized when using &lt;code&gt;word&lt;/code&gt; type.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use &lt;code&gt;--help&lt;/code&gt; flag to display all parameters for training.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-encode-raw-text-into-sentence-piecesids" class="anchor" aria-hidden="true" href="#encode-raw-text-into-sentence-piecesids"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Encode raw text into sentence pieces/ids&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;% spm_encode --model=&amp;lt;model_file&amp;gt; --output_format=piece &amp;lt; input &amp;gt; output
% spm_encode --model=&amp;lt;model_file&amp;gt; --output_format=id &amp;lt; input &amp;gt; output
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use &lt;code&gt;--extra_options&lt;/code&gt; flag to insert the BOS/EOS markers or reverse the input sequence.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% spm_encode --extra_options=eos (add &amp;lt;/s&amp;gt; only)
% spm_encode --extra_options=bos:eos (add &amp;lt;s&amp;gt; and &amp;lt;/s&amp;gt;)
% spm_encode --extra_options=reverse:bos:eos (reverse input and add &amp;lt;s&amp;gt; and &amp;lt;/s&amp;gt;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;SentencePiece supports nbest segmentation and segmentation sampling with &lt;code&gt;--output_format=(nbest|sample)_(piece|id)&lt;/code&gt; flags.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% spm_encode --model=&amp;lt;model_file&amp;gt; --output_format=sample_piece --nbest_size=-1 --alpha=0.5 &amp;lt; input &amp;gt; output
% spm_encode --model=&amp;lt;model_file&amp;gt; --output_format=nbest_id --nbest_size=10 &amp;lt; input &amp;gt; output
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-decode-sentence-piecesids-into-raw-text" class="anchor" aria-hidden="true" href="#decode-sentence-piecesids-into-raw-text"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Decode sentence pieces/ids into raw text&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;% spm_decode --model=&amp;lt;model_file&amp;gt; --input_format=piece &amp;lt; input &amp;gt; output
% spm_decode --model=&amp;lt;model_file&amp;gt; --input_format=id &amp;lt; input &amp;gt; output
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use &lt;code&gt;--extra_options&lt;/code&gt; flag to decode the text in reverse order.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% spm_decode --extra_options=reverse &amp;lt; input &amp;gt; output
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-end-to-end-example" class="anchor" aria-hidden="true" href="#end-to-end-example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;End-to-End Example&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;% spm_train --input=data/botchan.txt --model_prefix=m --vocab_size=1000
unigram_model_trainer.cc(494) LOG(INFO) Starts training with :
input: "../data/botchan.txt"
... &amp;lt;snip&amp;gt;
unigram_model_trainer.cc(529) LOG(INFO) EM sub_iter=1 size=1100 obj=10.4973 num_tokens=37630 num_tokens/piece=34.2091
trainer_interface.cc(272) LOG(INFO) Saving model: m.model
trainer_interface.cc(281) LOG(INFO) Saving vocabs: m.vocab

% echo "I saw a girl with a telescope." | spm_encode --model=m.model
▁I ▁saw ▁a ▁girl ▁with ▁a ▁ te le s c o pe .

% echo "I saw a girl with a telescope." | spm_encode --model=m.model --output_format=id
9 459 11 939 44 11 4 142 82 8 28 21 132 6

% echo "9 459 11 939 44 11 4 142 82 8 28 21 132 6" | spm_decode --model=m.model --input_format=id
I saw a girl with a telescope.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can find that the original input sentence is restored from the vocabulary id sequence.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-export-vocabulary-list" class="anchor" aria-hidden="true" href="#export-vocabulary-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Export vocabulary list&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;% spm_export_vocab --model=&amp;lt;model_file&amp;gt; --output=&amp;lt;output file&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;&amp;lt;output file&amp;gt;&lt;/code&gt; stores a list of vocabulary and emission log probabilities. The vocabulary id corresponds to the line number in this file.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-redefine-special-meta-tokens" class="anchor" aria-hidden="true" href="#redefine-special-meta-tokens"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Redefine special meta tokens&lt;/h3&gt;
&lt;p&gt;By default, SentencePiece uses Unknown (&amp;lt;unk&amp;gt;), BOS (&amp;lt;s&amp;gt;) and EOS (&amp;lt;/s&amp;gt;) tokens which have the ids of 0, 1, and 2 respectively. We can redefine this mapping in the training phase as follows.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% spm_train --bos_id=0 --eos_id=1 --unk_id=5 --input=... --model_prefix=... --character_coverage=... 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When setting -1 id e.g., &lt;code&gt;bos_id=-1&lt;/code&gt;, this special token is disabled. Note that the unknow id cannot be disabled.  We can define an id for padding (&amp;lt;pad&amp;gt;) as &lt;code&gt;--pad_id=3&lt;/code&gt;.  &lt;/p&gt;
&lt;p&gt;If you want to assign another special tokens, please see &lt;a href="doc/special_symbols.md"&gt;Use custom symbols&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-vocabulary-restriction" class="anchor" aria-hidden="true" href="#vocabulary-restriction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Vocabulary restriction&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;spm_encode&lt;/code&gt; accepts a &lt;code&gt;--vocabulary&lt;/code&gt; and a &lt;code&gt;--vocabulary_threshold&lt;/code&gt; option so that &lt;code&gt;spm_encode&lt;/code&gt; will only produce symbols which also appear in the vocabulary (with at least some frequency). The background of this feature is described in &lt;a href="https://github.com/rsennrich/subword-nmt#best-practice-advice-for-byte-pair-encoding-in-nmt"&gt;subword-nmt page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The usage is basically the same as that of &lt;code&gt;subword-nmt&lt;/code&gt;. Assuming that L1 and L2 are the two languages (source/target languages), train the shared spm model, and get resulting vocabulary for each:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% cat {train_file}.L1 {train_file}.L2 | shuffle &amp;gt; train
% spm_train --input=train --model_prefix=spm --vocab_size=8000 --character_coverage=0.9995
% spm_encode --model=spm.model --generate_vocabulary &amp;lt; {train_file}.L1 &amp;gt; {vocab_file}.L1
% spm_encode --model=spm.model --generate_vocabulary &amp;lt; {train_file}.L2 &amp;gt; {vocab_file}.L2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;shuffle&lt;/code&gt; command is used just in case because &lt;code&gt;spm_train&lt;/code&gt; loads the first 10M lines of corpus by default.&lt;/p&gt;
&lt;p&gt;Then segment train/test corpus with &lt;code&gt;--vocabulary&lt;/code&gt; option&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% spm_encode --model=spm.model --vocabulary={vocab_file}.L1 --vocabulary_threshold=50 &amp;lt; {test_file}.L1 &amp;gt; {test_file}.seg.L1
% spm_encode --model=spm.model --vocabulary={vocab_file}.L2 --vocabulary_threshold=50 &amp;lt; {test_file}.L2 &amp;gt; {test_file}.seg.L2
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-advanced-topics" class="anchor" aria-hidden="true" href="#advanced-topics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Advanced topics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="doc/experiments.md"&gt;SentencePiece Experiments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/api.md"&gt;SentencePieceProcessor C++ API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/normalization.md"&gt;Use custom text normalization rules&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/special_symbols.md"&gt;Use custom symbols&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="python/README.md"&gt;Python Module&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="tensorflow/README.md"&gt;TensorFlow Module&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Segmentation and training algorithms in detail]&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>google</author><guid isPermaLink="false">https://github.com/google/sentencepiece</guid><pubDate>Sun, 05 Jan 2020 00:25:00 GMT</pubDate></item></channel></rss>