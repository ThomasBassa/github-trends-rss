<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: MATLAB, Today</title><link>https://github.com/trending/matlab?since=daily</link><description>The top repositories on GitHub for matlab, measured daily</description><pubDate>Tue, 29 Oct 2019 03:38:11 GMT</pubDate><lastBuildDate>Tue, 29 Oct 2019 03:38:11 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>1400</ttl><item><title>everpeace/ml-class-assignments #1 in MATLAB, Today</title><link>https://github.com/everpeace/ml-class-assignments</link><description>&lt;p&gt;&lt;i&gt;Programming Exercises on http://ml-class.org&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-what-is-this" class="anchor" aria-hidden="true" href="#what-is-this"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is this?&lt;/h1&gt;
&lt;p&gt;This repo contains my solution of assignment in &lt;a href="http://www.ml-class.org" rel="nofollow"&gt;2011 Stanford Machine Learning Class&lt;/a&gt;.
If you are taking the class, fork my repo and puth different solutions in a different branch.
HOWEVER, please DO NOT refer any code in my repo before the due date and NEVER post any code in my repo according to "Stanford Honer Code" below.
Questions or pointing out is always welcome, please send me a mail.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-stanford-honor-code" class="anchor" aria-hidden="true" href="#stanford-honor-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stanford Honor Code&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;"We strongly encourage students to form study groups,  and discuss the lecture videos (including in-video questions). We also encourage you to get together with friends to watch the videos together as a group. However,  the answers that you submit for the review questions should be your own work. For the programming exercises,  you are welcome to discuss them with other students,  discuss specific algorithms,  properties of algorithms,  etc.; we ask only that you not look at any source code written by a different student,  nor show your solution code to other students."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;All Solutions licensed under MIT License. See LICENSE.txt for further details.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-copyright" class="anchor" aria-hidden="true" href="#copyright"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Copyright&lt;/h2&gt;
&lt;p&gt;Copyright (c) 2011 &lt;a href="http://twitter.com/everpeace" rel="nofollow"&gt;everpeace&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-other-notable-open-source-ml-class-sources" class="anchor" aria-hidden="true" href="#other-notable-open-source-ml-class-sources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other Notable Open Source ml-class Sources&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/schneems/Octave"&gt;https://github.com/schneems/Octave&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/joewandy/Stanford-Machine-Learning"&gt;https://github.com/joewandy/Stanford-Machine-Learning&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>everpeace</author><guid isPermaLink="false">https://github.com/everpeace/ml-class-assignments</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>ShaoqingRen/faster_rcnn #2 in MATLAB, Today</title><link>https://github.com/ShaoqingRen/faster_rcnn</link><description>&lt;p&gt;&lt;i&gt;Faster R-CNN&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-this-repo-has-been-deprecated-please-see-detectron-which-includes-an-implementation-of-mask-r-cnn" class="anchor" aria-hidden="true" href="#this-repo-has-been-deprecated-please-see-detectron-which-includes-an-implementation-of-mask-r-cnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;This repo has been deprecated. Please see &lt;a href="https://github.com/facebookresearch/Detectron"&gt;Detectron&lt;/a&gt;, which includes an implementation of &lt;a href="https://arxiv.org/abs/1703.06870" rel="nofollow"&gt;Mask R-CNN&lt;/a&gt;.&lt;/h2&gt;
&lt;h1&gt;&lt;a id="user-content-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks" class="anchor" aria-hidden="true" href="#faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;em&gt;Faster&lt;/em&gt; R-CNN: Towards Real-Time Object Detection with Region Proposal Networks&lt;/h1&gt;
&lt;p&gt;By Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun at Microsoft Research&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Faster&lt;/strong&gt; R-CNN is an object detection framework based on deep convolutional networks, which includes a Region Proposal Network (RPN) and an Object Detection Network. Both networks are trained for sharing convolutional layers for fast testing.&lt;/p&gt;
&lt;p&gt;Faster R-CNN was initially described in an &lt;a href="http://arxiv.org/abs/1506.01497" rel="nofollow"&gt;arXiv tech report&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This repo contains a MATLAB re-implementation of Fast R-CNN. Details about Fast R-CNN are in: &lt;a href="https://github.com/rbgirshick/fast-rcnn"&gt;rbgirshick/fast-rcnn&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This code has been tested on Windows 7/8 64-bit, Windows Server 2012 R2, and Linux, and on MATLAB 2014a.&lt;/p&gt;
&lt;p&gt;Python version is available at &lt;a href="https://github.com/rbgirshick/py-faster-rcnn"&gt;py-faster-rcnn&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h3&gt;
&lt;p&gt;Faster R-CNN is released under the MIT License (refer to the LICENSE file for details).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-citing-faster-r-cnn" class="anchor" aria-hidden="true" href="#citing-faster-r-cnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citing Faster R-CNN&lt;/h3&gt;
&lt;p&gt;If you find Faster R-CNN useful in your research, please consider citing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{ren15fasterrcnn,
    Author = {Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun},
    Title = {{Faster R-CNN}: Towards Real-Time Object Detection with Region Proposal Networks},
    Journal = {arXiv preprint arXiv:1506.01497},
    Year = {2015}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-main-results" class="anchor" aria-hidden="true" href="#main-results"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Main Results&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align="center"&gt;training data&lt;/th&gt;
&lt;th align="center"&gt;test data&lt;/th&gt;
&lt;th align="center"&gt;mAP&lt;/th&gt;
&lt;th align="center"&gt;time/img&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Faster RCNN, VGG-16&lt;/td&gt;
&lt;td align="center"&gt;VOC 2007 trainval&lt;/td&gt;
&lt;td align="center"&gt;VOC 2007 test&lt;/td&gt;
&lt;td align="center"&gt;69.9%&lt;/td&gt;
&lt;td align="center"&gt;198ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Faster RCNN, VGG-16&lt;/td&gt;
&lt;td align="center"&gt;VOC 2007 trainval + 2012 trainval&lt;/td&gt;
&lt;td align="center"&gt;VOC 2007 test&lt;/td&gt;
&lt;td align="center"&gt;73.2%&lt;/td&gt;
&lt;td align="center"&gt;198ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Faster RCNN, VGG-16&lt;/td&gt;
&lt;td align="center"&gt;VOC 2012 trainval&lt;/td&gt;
&lt;td align="center"&gt;VOC 2012 test&lt;/td&gt;
&lt;td align="center"&gt;67.0%&lt;/td&gt;
&lt;td align="center"&gt;198ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Faster RCNN, VGG-16&lt;/td&gt;
&lt;td align="center"&gt;VOC 2007 trainval&amp;amp;test + 2012 trainval&lt;/td&gt;
&lt;td align="center"&gt;VOC 2012 test&lt;/td&gt;
&lt;td align="center"&gt;70.4%&lt;/td&gt;
&lt;td align="center"&gt;198ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The mAP results are subject to random variations. We have run 5 times independently for ZF net, and the mAPs are 59.9 (as in the paper), 60.4, 59.5, 60.1, and 59.5, with a mean of 59.88 and std 0.39.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h3&gt;
&lt;ol start="0"&gt;
&lt;li&gt;&lt;a href="#requirements-software"&gt;Requirements: software&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#requirements-hardware"&gt;Requirements: hardware&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#preparation-for-testing"&gt;Preparation for Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#testing-demo"&gt;Testing Demo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#preparation-for-training"&gt;Preparation for Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#training"&gt;Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#resources"&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-requirements-software" class="anchor" aria-hidden="true" href="#requirements-software"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements: software&lt;/h3&gt;
&lt;ol start="0"&gt;
&lt;li&gt;&lt;code&gt;Caffe&lt;/code&gt; build for Faster R-CNN (included in this repository, see &lt;code&gt;external/caffe&lt;/code&gt;)
&lt;ul&gt;
&lt;li&gt;If you are using Windows, you may download a compiled mex file by running &lt;code&gt;fetch_data/fetch_caffe_mex_windows_vs2013_cuda65.m&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;If you are using Linux or you want to compile for Windows, please follow the &lt;a href="https://github.com/ShaoqingRen/caffe/tree/faster-R-CNN"&gt;instructions&lt;/a&gt; on our Caffe branch.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MATLAB&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-requirements-hardware" class="anchor" aria-hidden="true" href="#requirements-hardware"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements: hardware&lt;/h3&gt;
&lt;p&gt;GPU: Titan, Titan Black, Titan X, K20, K40, K80.&lt;/p&gt;
&lt;ol start="0"&gt;
&lt;li&gt;Region Proposal Network (RPN)
&lt;ul&gt;
&lt;li&gt;2GB GPU memory for ZF net&lt;/li&gt;
&lt;li&gt;5GB GPU memory for VGG-16 net&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Object Detection Network (Fast R-CNN)
&lt;ul&gt;
&lt;li&gt;3GB GPU memory for ZF net&lt;/li&gt;
&lt;li&gt;8GB GPU memory for VGG-16 net&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-preparation-for-testing" class="anchor" aria-hidden="true" href="#preparation-for-testing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preparation for Testing:&lt;/h3&gt;
&lt;ol start="0"&gt;
&lt;li&gt;Run &lt;code&gt;fetch_data/fetch_caffe_mex_windows_vs2013_cuda65.m&lt;/code&gt; to download a compiled Caffe mex (for Windows only).&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;faster_rcnn_build.m&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;startup.m&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-testing-demo" class="anchor" aria-hidden="true" href="#testing-demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Testing Demo:&lt;/h3&gt;
&lt;ol start="0"&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;fetch_data/fetch_faster_rcnn_final_model.m&lt;/code&gt; to download our trained models.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;experiments/script_faster_rcnn_demo.m&lt;/code&gt; to test a single demo image.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You will see the timing information as below. We get the following running time on K40 @ 875 MHz and Intel Xeon CPU E5-2650 v2 @ 2.60GHz for the demo images with VGG-16:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;001763.jpg (500x375): &lt;span class="pl-k"&gt;time&lt;/span&gt; 0.201s (resize+conv+proposal: 0.150s, nms+regionwise: 0.052s)
004545.jpg (500x375): &lt;span class="pl-k"&gt;time&lt;/span&gt; 0.201s (resize+conv+proposal: 0.151s, nms+regionwise: 0.050s)
000542.jpg (500x375): &lt;span class="pl-k"&gt;time&lt;/span&gt; 0.192s (resize+conv+proposal: 0.151s, nms+regionwise: 0.041s)
000456.jpg (500x375): &lt;span class="pl-k"&gt;time&lt;/span&gt; 0.202s (resize+conv+proposal: 0.152s, nms+regionwise: 0.050s)
001150.jpg (500x375): &lt;span class="pl-k"&gt;time&lt;/span&gt; 0.194s (resize+conv+proposal: 0.151s, nms+regionwise: 0.043s)
mean time: 0.198s&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and with ZF net:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;001763.jpg (500x375): &lt;span class="pl-k"&gt;time&lt;/span&gt; 0.061s (resize+conv+proposal: 0.032s, nms+regionwise: 0.029s)
004545.jpg (500x375): &lt;span class="pl-k"&gt;time&lt;/span&gt; 0.063s (resize+conv+proposal: 0.034s, nms+regionwise: 0.029s)
000542.jpg (500x375): &lt;span class="pl-k"&gt;time&lt;/span&gt; 0.052s (resize+conv+proposal: 0.034s, nms+regionwise: 0.018s)
000456.jpg (500x375): &lt;span class="pl-k"&gt;time&lt;/span&gt; 0.062s (resize+conv+proposal: 0.034s, nms+regionwise: 0.028s)
001150.jpg (500x375): &lt;span class="pl-k"&gt;time&lt;/span&gt; 0.058s (resize+conv+proposal: 0.034s, nms+regionwise: 0.023s)
mean time: 0.059s&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;The visual results might be different from those in the paper due to numerical variations.&lt;/li&gt;
&lt;li&gt;Running time on other GPUs&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;GPU / mean time&lt;/th&gt;
&lt;th align="center"&gt;VGG-16&lt;/th&gt;
&lt;th align="center"&gt;ZF&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;K40&lt;/td&gt;
&lt;td align="center"&gt;198ms&lt;/td&gt;
&lt;td align="center"&gt;59ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Titan Black&lt;/td&gt;
&lt;td align="center"&gt;174ms&lt;/td&gt;
&lt;td align="center"&gt;56ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Titan X&lt;/td&gt;
&lt;td align="center"&gt;151ms&lt;/td&gt;
&lt;td align="center"&gt;59ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-preparation-for-training" class="anchor" aria-hidden="true" href="#preparation-for-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preparation for Training:&lt;/h3&gt;
&lt;ol start="0"&gt;
&lt;li&gt;Run &lt;code&gt;fetch_data/fetch_model_ZF.m&lt;/code&gt; to download an ImageNet-pre-trained ZF net.&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;fetch_data/fetch_model_VGG16.m&lt;/code&gt; to download an ImageNet-pre-trained VGG-16 net.&lt;/li&gt;
&lt;li&gt;Download VOC 2007 and 2012 data to ./datasets&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-training" class="anchor" aria-hidden="true" href="#training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training:&lt;/h3&gt;
&lt;ol start="0"&gt;
&lt;li&gt;Run &lt;code&gt;experiments/script_faster_rcnn_VOC2007_ZF.m&lt;/code&gt; to train a model with ZF net. It runs four steps as follows:
&lt;ul&gt;
&lt;li&gt;Train RPN with conv layers tuned; compute RPN results on the train/test sets.&lt;/li&gt;
&lt;li&gt;Train Fast R-CNN with conv layers tuned using step-1 RPN proposals; evaluate detection mAP.&lt;/li&gt;
&lt;li&gt;Train RPN with conv layers fixed; compute RPN results on the train/test sets.&lt;/li&gt;
&lt;li&gt;Train Fast R-CNN with conv layers fixed using step-3 RPN proposals; evaluate detection mAP.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: the entire training time is ~12 hours on K40.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;experiments/script_faster_rcnn_VOC2007_VGG16.m&lt;/code&gt; to train a model with VGG net.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: the entire training time is ~2 days on K40.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Check other scripts in &lt;code&gt;./experiments&lt;/code&gt; for more settings.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This documentation may contain links to third party websites, which are provided for your convenience only. Such third party websites are not under Microsoft’s control. Microsoft does not endorse or make any representation, guarantee or assurance regarding any third party website, content, service or product. Third party websites may be subject to the third party’s terms, conditions, and privacy statements.&lt;/p&gt;
&lt;ol start="0"&gt;
&lt;li&gt;Experiment logs: &lt;a href="https://onedrive.live.com/download?resid=36FEC490FBC32F1A!110&amp;amp;authkey=!ACpgYZR2MmfklwI&amp;amp;ithint=file%2czip" rel="nofollow"&gt;OneDrive&lt;/a&gt;, &lt;a href="https://www.dropbox.com/s/wu841r7zmebjp6r/faster_rcnn_logs.zip?dl=0" rel="nofollow"&gt;DropBox&lt;/a&gt;, &lt;a href="http://pan.baidu.com/s/1ntJ3dLv" rel="nofollow"&gt;BaiduYun&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Regions proposals of our trained RPN:
&lt;ul&gt;
&lt;li&gt;ZF net trained on VOC 07 trainval &lt;a href="https://onedrive.live.com/download?resid=36FEC490FBC32F1A!115&amp;amp;authkey=!AJJMrFJHKLXIg5c&amp;amp;ithint=file%2czip" rel="nofollow"&gt;OneDrive&lt;/a&gt;, &lt;a href="http://pan.baidu.com/s/1pKGBDyz" rel="nofollow"&gt;BaiduYun&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ZF net trained on VOC 07/12 trainval &lt;a href="https://onedrive.live.com/download?resid=36FEC490FBC32F1A!117&amp;amp;authkey=!AJiy5F6Cum1iosI&amp;amp;ithint=file%2czip" rel="nofollow"&gt;OneDrive&lt;/a&gt;, &lt;a href="http://pan.baidu.com/s/1jGAgkZW" rel="nofollow"&gt;BaiduYun&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;VGG net trained on VOC 07 trainval &lt;a href="https://onedrive.live.com/download?resid=36FEC490FBC32F1A!116&amp;amp;authkey=!AH4Zi_KAaun7MhQ&amp;amp;ithint=file%2czip" rel="nofollow"&gt;OneDrive&lt;/a&gt;, &lt;a href="http://pan.baidu.com/s/1qWHv4JU" rel="nofollow"&gt;BaiduYun&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;VGG net trained on VOC 07/12 trainval &lt;a href="https://onedrive.live.com/download?resid=36FEC490FBC32F1A!118&amp;amp;authkey=!AB_lKk3dbGyr1-I&amp;amp;ithint=file%2czip" rel="nofollow"&gt;OneDrive&lt;/a&gt;, &lt;a href="http://pan.baidu.com/s/1c0fQpqg" rel="nofollow"&gt;BaiduYun&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: the proposals are in the format of [left, top, right, bottom, confidence]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If the automatic "fetch_data" fails, you may manually download resouces from:&lt;/p&gt;
&lt;ol start="0"&gt;
&lt;li&gt;Pre-complied caffe mex:
&lt;ul&gt;
&lt;li&gt;Windows-based mex complied with VS2013 and Cuda6.5: &lt;a href="https://onedrive.live.com/download?resid=36FEC490FBC32F1A!111&amp;amp;authkey=!AFVWFGTbViiX5tg&amp;amp;ithint=file%2czip" rel="nofollow"&gt;OneDrive&lt;/a&gt;, &lt;a href="https://www.dropbox.com/s/m6sg347tiaqpcwy/caffe_mex.zip?dl=0" rel="nofollow"&gt;DropBox&lt;/a&gt;, &lt;a href="http://pan.baidu.com/s/1i3m0i0H" rel="nofollow"&gt;BaiduYun&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ImageNet-pretrained networks:
&lt;ul&gt;
&lt;li&gt;Zeiler &amp;amp; Fergus (ZF) net &lt;a href="https://onedrive.live.com/download?resid=36FEC490FBC32F1A!113&amp;amp;authkey=!AIzdm0sD_SmhUQ4&amp;amp;ithint=file%2czip" rel="nofollow"&gt;OneDrive&lt;/a&gt;, &lt;a href="https://www.dropbox.com/s/sw58b2froihzwyf/model_ZF.zip?dl=0" rel="nofollow"&gt;DropBox&lt;/a&gt;, &lt;a href="http://pan.baidu.com/s/1o6zipPS" rel="nofollow"&gt;BaiduYun&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;VGG-16 net &lt;a href="https://onedrive.live.com/download?resid=36FEC490FBC32F1A!114&amp;amp;authkey=!AE8uV9B07dREbhM&amp;amp;ithint=file%2czip" rel="nofollow"&gt;OneDrive&lt;/a&gt;, &lt;a href="https://www.dropbox.com/s/z5rrji25uskha73/model_VGG16.zip?dl=0" rel="nofollow"&gt;DropBox&lt;/a&gt;, &lt;a href="http://pan.baidu.com/s/1mgzSnI4" rel="nofollow"&gt;BaiduYun&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Final RPN+FastRCNN models: &lt;a href="https://onedrive.live.com/download?resid=D7AF52BADBA8A4BC!114&amp;amp;authkey=!AERHoxZ-iAx_j34&amp;amp;ithint=file%2czip" rel="nofollow"&gt;OneDrive&lt;/a&gt;, &lt;a href="https://www.dropbox.com/s/jswrnkaln47clg2/faster_rcnn_final_model.zip?dl=0" rel="nofollow"&gt;DropBox&lt;/a&gt;, &lt;a href="http://pan.baidu.com/s/1hsFKmeK" rel="nofollow"&gt;BaiduYun&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ShaoqingRen</author><guid isPermaLink="false">https://github.com/ShaoqingRen/faster_rcnn</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>rasmusbergpalm/DeepLearnToolbox #3 in MATLAB, Today</title><link>https://github.com/rasmusbergpalm/DeepLearnToolbox</link><description>&lt;p&gt;&lt;i&gt;Matlab/Octave toolbox for deep learning. Includes Deep Belief Nets, Stacked Autoencoders, Convolutional Neural Nets, Convolutional Autoencoders and vanilla Neural Nets. Each method has examples to get you started.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-deprecation-notice" class="anchor" aria-hidden="true" href="#deprecation-notice"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deprecation notice.&lt;/h2&gt;
&lt;p&gt;This toolbox is outdated and no longer maintained.&lt;/p&gt;
&lt;p&gt;There are much better tools available for deep learning than this toolbox, e.g. &lt;a href="http://deeplearning.net/software/theano/" rel="nofollow"&gt;Theano&lt;/a&gt;, &lt;a href="http://torch.ch/" rel="nofollow"&gt;torch&lt;/a&gt; or &lt;a href="http://www.tensorflow.org/" rel="nofollow"&gt;tensorflow&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I would suggest you use one of the tools mentioned above rather than use this toolbox.&lt;/p&gt;
&lt;p&gt;Best, Rasmus.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-deeplearntoolbox" class="anchor" aria-hidden="true" href="#deeplearntoolbox"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DeepLearnToolbox&lt;/h1&gt;
&lt;p&gt;A Matlab toolbox for Deep Learning.&lt;/p&gt;
&lt;p&gt;Deep Learning is a new subfield of machine learning that focuses on learning deep hierarchical models of data.
It is inspired by the human brain's apparent deep (layered, hierarchical) architecture.
A good overview of the theory of Deep Learning theory is
&lt;a href="http://www.iro.umontreal.ca/~bengioy/papers/ftml_book.pdf" rel="nofollow"&gt;Learning Deep Architectures for AI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For a more informal introduction, see the following videos by Geoffrey Hinton and Andrew Ng.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.youtube.com/watch?v=AyzOUbkUf3M" rel="nofollow"&gt;The Next Generation of Neural Networks&lt;/a&gt; (Hinton, 2007)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.youtube.com/watch?v=VdIURAu1-aU" rel="nofollow"&gt;Recent Developments in Deep Learning&lt;/a&gt; (Hinton, 2010)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.youtube.com/watch?v=ZmNOAtZIgIk" rel="nofollow"&gt;Unsupervised Feature Learning and Deep Learning&lt;/a&gt; (Ng, 2011)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you use this toolbox in your research please cite &lt;a href="http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6284" rel="nofollow"&gt;Prediction as a candidate for learning deep hierarchical models of data&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@MASTERSTHESIS\{IMM2012-06284,
    author       = "R. B. Palm",
    title        = "Prediction as a candidate for learning deep hierarchical models of data",
    year         = "2012",
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Contact: rasmusbergpalm at gmail dot com&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-directories-included-in-the-toolbox" class="anchor" aria-hidden="true" href="#directories-included-in-the-toolbox"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Directories included in the toolbox&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;NN/&lt;/code&gt;   - A library for Feedforward Backpropagation Neural Networks&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CNN/&lt;/code&gt;  - A library for Convolutional Neural Networks&lt;/p&gt;
&lt;p&gt;&lt;code&gt;DBN/&lt;/code&gt;  - A library for Deep Belief Networks&lt;/p&gt;
&lt;p&gt;&lt;code&gt;SAE/&lt;/code&gt;  - A library for Stacked Auto-Encoders&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CAE/&lt;/code&gt; - A library for Convolutional Auto-Encoders&lt;/p&gt;
&lt;p&gt;&lt;code&gt;util/&lt;/code&gt; - Utility functions used by the libraries&lt;/p&gt;
&lt;p&gt;&lt;code&gt;data/&lt;/code&gt; - Data used by the examples&lt;/p&gt;
&lt;p&gt;&lt;code&gt;tests/&lt;/code&gt; - unit tests to verify toolbox is working&lt;/p&gt;
&lt;p&gt;For references on each library check REFS.md&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Download.&lt;/li&gt;
&lt;li&gt;addpath(genpath('DeepLearnToolbox'));&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-example-deep-belief-network" class="anchor" aria-hidden="true" href="#example-deep-belief-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example: Deep Belief Network&lt;/h2&gt;
&lt;div class="highlight highlight-source-matlab"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;function&lt;/span&gt; &lt;span class="pl-en"&gt;test_example_DBN&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;span class="pl-smi"&gt;load&lt;/span&gt; mnist_uint8;&lt;/span&gt;

train_x = double(train_x) &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255&lt;/span&gt;;
test_x  = double(test_x)  &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255&lt;/span&gt;;
train_y = double(train_y);
test_y  = double(test_y);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt;  ex1 train a 100 hidden unit RBM and visualize its weights&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
dbn.sizes = [&lt;span class="pl-c1"&gt;100&lt;/span&gt;];
opts.numepochs =   &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;
opts.momentum  =   &lt;span class="pl-c1"&gt;0&lt;/span&gt;;
opts.alpha     =   &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
dbn = dbnsetup(dbn, train_x, opts);
dbn = dbntrain(dbn, train_x, opts);
figure; visualize(dbn.rbm{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}.&lt;span class="pl-k"&gt;W'&lt;/span&gt;);   &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Visualize the RBM weights&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt;  ex2 train a 100-100 hidden unit DBN and use its weights to initialize a NN&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;train dbn&lt;/span&gt;
dbn.sizes = [&lt;span class="pl-c1"&gt;100&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt;];
opts.numepochs =   &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;
opts.momentum  =   &lt;span class="pl-c1"&gt;0&lt;/span&gt;;
opts.alpha     =   &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
dbn = dbnsetup(dbn, train_x, opts);
dbn = dbntrain(dbn, train_x, opts);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;unfold dbn to nn&lt;/span&gt;
nn = dbnunfoldtonn(dbn, &lt;span class="pl-c1"&gt;10&lt;/span&gt;);
nn.activation_function = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sigm&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;train nn&lt;/span&gt;
opts.numepochs =  &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;
nn = nntrain(nn, train_x, train_y, opts);
[er, bad] = nntest(nn, test_x, test_y);

assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.10&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-example-stacked-auto-encoders" class="anchor" aria-hidden="true" href="#example-stacked-auto-encoders"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example: Stacked Auto-Encoders&lt;/h2&gt;
&lt;div class="highlight highlight-source-matlab"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;function&lt;/span&gt; &lt;span class="pl-en"&gt;test_example_SAE&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;span class="pl-smi"&gt;load&lt;/span&gt; mnist_uint8;&lt;/span&gt;

train_x = double(train_x)/&lt;span class="pl-c1"&gt;255&lt;/span&gt;;
test_x  = double(test_x)/&lt;span class="pl-c1"&gt;255&lt;/span&gt;;
train_y = double(train_y);
test_y  = double(test_y);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt;  ex1 train a 100 hidden unit SDAE and use it to initialize a FFNN&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Setup and train a stacked denoising autoencoder (SDAE)&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
sae = saesetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt;]);
sae.ae{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}.activation_function       = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sigm&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;
sae.ae{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}.learningRate              = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
sae.ae{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}.inputZeroMaskedFraction   = &lt;span class="pl-c1"&gt;0.5&lt;/span&gt;;
opts.numepochs =   &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;
sae = saetrain(sae, train_x, opts);
visualize(sae.ae{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}.W{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}(:,&lt;span class="pl-c1"&gt;2&lt;/span&gt;:&lt;span class="pl-k"&gt;end&lt;/span&gt;)&lt;span class="pl-k"&gt;'&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt; Use the SDAE to initialize a FFNN&lt;/span&gt;
nn = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);
nn.activation_function              = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sigm&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;
nn.learningRate                     = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
nn.W{&lt;span class="pl-c1"&gt;1&lt;/span&gt;} = sae.ae{&lt;span class="pl-c1"&gt;1&lt;/span&gt;}.W{&lt;span class="pl-c1"&gt;1&lt;/span&gt;};

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt; Train the FFNN&lt;/span&gt;
opts.numepochs =   &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;
nn = nntrain(nn, train_x, train_y, opts);
[er, bad] = nntest(nn, test_x, test_y);
assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.16&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-example-convolutional-neural-nets" class="anchor" aria-hidden="true" href="#example-convolutional-neural-nets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example: Convolutional Neural Nets&lt;/h2&gt;
&lt;div class="highlight highlight-source-matlab"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;function&lt;/span&gt; &lt;span class="pl-en"&gt;test_example_CNN&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;span class="pl-smi"&gt;load&lt;/span&gt; mnist_uint8;&lt;/span&gt;

train_x = double(reshape(&lt;span class="pl-k"&gt;train_x'&lt;/span&gt;,&lt;span class="pl-c1"&gt;28&lt;/span&gt;,&lt;span class="pl-c1"&gt;28&lt;/span&gt;,&lt;span class="pl-c1"&gt;60000&lt;/span&gt;))/&lt;span class="pl-c1"&gt;255&lt;/span&gt;;
test_x = double(reshape(&lt;span class="pl-k"&gt;test_x'&lt;/span&gt;,&lt;span class="pl-c1"&gt;28&lt;/span&gt;,&lt;span class="pl-c1"&gt;28&lt;/span&gt;,&lt;span class="pl-c1"&gt;10000&lt;/span&gt;))/&lt;span class="pl-c1"&gt;255&lt;/span&gt;;
train_y = double(&lt;span class="pl-k"&gt;train_y'&lt;/span&gt;);
test_y = double(&lt;span class="pl-k"&gt;test_y'&lt;/span&gt;);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex1 Train a 6c-2s-12c-2s Convolutional neural network &lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;will run 1 epoch in about 200 second and get around 11% error. &lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;With 100 epochs you'll get around 1.2% error&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
cnn.layers = {
    struct(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;type&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;i&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;input layer&lt;/span&gt;
    struct(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;type&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;c&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;outputmaps&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;6&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kernelsize&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;5&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;convolution layer&lt;/span&gt;
    struct(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;type&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;s&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;scale&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;sub sampling layer&lt;/span&gt;
    struct(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;type&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;c&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;outputmaps&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;12&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;kernelsize&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;5&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;convolution layer&lt;/span&gt;
    struct(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;type&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;s&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;scale&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;subsampling layer&lt;/span&gt;
};
cnn = cnnsetup(cnn, train_x, train_y);

opts.alpha = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;
opts.batchsize = &lt;span class="pl-c1"&gt;50&lt;/span&gt;;
opts.numepochs = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;

cnn = cnntrain(cnn, train_x, train_y, opts);

[er, bad] = cnntest(cnn, test_x, test_y);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;plot mean squared error&lt;/span&gt;
figure; plot(cnn.rL);

assert(er&amp;lt;0.12, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-example-neural-networks" class="anchor" aria-hidden="true" href="#example-neural-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example: Neural Networks&lt;/h2&gt;
&lt;div class="highlight highlight-source-matlab"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;function&lt;/span&gt; &lt;span class="pl-en"&gt;test_example_NN&lt;/span&gt;
&lt;span class="pl-s"&gt;&lt;span class="pl-smi"&gt;load&lt;/span&gt; mnist_uint8;&lt;/span&gt;

train_x = double(train_x) &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255&lt;/span&gt;;
test_x  = double(test_x)  &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;255&lt;/span&gt;;
train_y = double(train_y);
test_y  = double(test_y);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt; normalize&lt;/span&gt;
[train_x, mu, sigma] = zscore(train_x);
test_x = normalize(test_x, mu, sigma);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex1 vanilla neural net&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
nn = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);
opts.numepochs =  &lt;span class="pl-c1"&gt;1&lt;/span&gt;;   &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Number of full sweeps through data&lt;/span&gt;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Take a mean gradient step over this many samples&lt;/span&gt;
[nn, L] = nntrain(nn, train_x, train_y, opts);

[er, bad] = nntest(nn, test_x, test_y);

assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.08&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex2 neural net with L2 weight decay&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
nn = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);

nn.weightPenaltyL2 = &lt;span class="pl-c1"&gt;1e-4&lt;/span&gt;;  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  L2 weight decay&lt;/span&gt;
opts.numepochs =  &lt;span class="pl-c1"&gt;1&lt;/span&gt;;        &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Number of full sweeps through data&lt;/span&gt;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;       &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Take a mean gradient step over this many samples&lt;/span&gt;

nn = nntrain(nn, train_x, train_y, opts);

[er, bad] = nntest(nn, test_x, test_y);
assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.1&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);


&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex3 neural net with dropout&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
nn = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);

nn.dropoutFraction = &lt;span class="pl-c1"&gt;0.5&lt;/span&gt;;   &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Dropout fraction &lt;/span&gt;
opts.numepochs =  &lt;span class="pl-c1"&gt;1&lt;/span&gt;;        &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Number of full sweeps through data&lt;/span&gt;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;       &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Take a mean gradient step over this many samples&lt;/span&gt;

nn = nntrain(nn, train_x, train_y, opts);

[er, bad] = nntest(nn, test_x, test_y);
assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.1&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex4 neural net with sigmoid activation function&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
nn = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);

nn.activation_function = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;sigm&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Sigmoid activation function&lt;/span&gt;
nn.learningRate = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;                &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Sigm require a lower learning rate&lt;/span&gt;
opts.numepochs =  &lt;span class="pl-c1"&gt;1&lt;/span&gt;;                &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Number of full sweeps through data&lt;/span&gt;
opts.batchsize = &lt;span class="pl-c1"&gt;100&lt;/span&gt;;               &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Take a mean gradient step over this many samples&lt;/span&gt;

nn = nntrain(nn, train_x, train_y, opts);

[er, bad] = nntest(nn, test_x, test_y);
assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.1&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex5 plotting functionality&lt;/span&gt;
rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
nn = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;20&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);
opts.numepochs         = &lt;span class="pl-c1"&gt;5&lt;/span&gt;;            &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Number of full sweeps through data&lt;/span&gt;
nn.output              = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;softmax&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  use softmax output&lt;/span&gt;
opts.batchsize         = &lt;span class="pl-c1"&gt;1000&lt;/span&gt;;         &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Take a mean gradient step over this many samples&lt;/span&gt;
opts.plot              = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;            &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  enable plotting&lt;/span&gt;

nn = nntrain(nn, train_x, train_y, opts);

[er, bad] = nntest(nn, test_x, test_y);
assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.1&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%%&lt;/span&gt; ex6 neural net with sigmoid activation and plotting of validation and training error&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt; split training data into training and validation data&lt;/span&gt;
vx   = train_x(&lt;span class="pl-c1"&gt;1&lt;/span&gt;:&lt;span class="pl-c1"&gt;10000&lt;/span&gt;,:);
tx = train_x(&lt;span class="pl-c1"&gt;10001&lt;/span&gt;:&lt;span class="pl-k"&gt;end&lt;/span&gt;,:);
vy   = train_y(&lt;span class="pl-c1"&gt;1&lt;/span&gt;:&lt;span class="pl-c1"&gt;10000&lt;/span&gt;,:);
ty = train_y(&lt;span class="pl-c1"&gt;10001&lt;/span&gt;:&lt;span class="pl-k"&gt;end&lt;/span&gt;,:);

rand(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;state&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,&lt;span class="pl-c1"&gt;0&lt;/span&gt;)
nn                      = nnsetup([&lt;span class="pl-c1"&gt;784&lt;/span&gt; &lt;span class="pl-c1"&gt;20&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;]);     
nn.output               = &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;softmax&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;                   &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  use softmax output&lt;/span&gt;
opts.numepochs          = &lt;span class="pl-c1"&gt;5&lt;/span&gt;;                           &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Number of full sweeps through data&lt;/span&gt;
opts.batchsize          = &lt;span class="pl-c1"&gt;1000&lt;/span&gt;;                        &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  Take a mean gradient step over this many samples&lt;/span&gt;
opts.plot               = &lt;span class="pl-c1"&gt;1&lt;/span&gt;;                           &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  enable plotting&lt;/span&gt;
nn = nntrain(nn, tx, ty, opts, vx, vy);                &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt;  nntrain takes validation set as last two arguments (optionally)&lt;/span&gt;

[er, bad] = nntest(nn, test_x, test_y);
assert(er &lt;span class="pl-k"&gt;&amp;lt;&lt;/span&gt; &lt;span class="pl-c1"&gt;0.1&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Too big error&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://bitdeli.com/free" title="Bitdeli Badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/00e5bbbe78ce5418547b4672181b673cccc1c89c/68747470733a2f2f64327765637a68766c38323376302e636c6f756466726f6e742e6e65742f7261736d75736265726770616c6d2f646565706c6561726e746f6f6c626f782f7472656e642e706e67" alt="Bitdeli Badge" data-canonical-src="https://d2weczhvl823v0.cloudfront.net/rasmusbergpalm/deeplearntoolbox/trend.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>rasmusbergpalm</author><guid isPermaLink="false">https://github.com/rasmusbergpalm/DeepLearnToolbox</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>atinesh-s/Coursera-Machine-Learning-Stanford #4 in MATLAB, Today</title><link>https://github.com/atinesh-s/Coursera-Machine-Learning-Stanford</link><description>&lt;p&gt;&lt;i&gt;Machine learning-Stanford University&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-coursera" class="anchor" aria-hidden="true" href="#machine-learning-coursera"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning (Coursera)&lt;/h1&gt;
&lt;p&gt;This is my solution to all the programming assignments and quizzes of Machine-Learning (Coursera) taught by Andrew Ng. After completing this course you will get a broad idea of Machine learning algorithms. Try to solve all the assignments by yourself first, but if you get stuck somewhere then feel free to browse the code.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Lectures Slides&lt;/li&gt;
&lt;li&gt;Solution to programming assignment&lt;/li&gt;
&lt;li&gt;Solution to Quizzes&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-certificate" class="anchor" aria-hidden="true" href="#certificate"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Certificate&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/account/accomplishments/certificate/GDDBFB572MUQ" rel="nofollow"&gt;Verified Certificate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-references" class="anchor" aria-hidden="true" href="#references"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.coursera.org/learn/machine-learning" rel="nofollow"&gt;[1] Machine Learning - Stanford University&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>atinesh-s</author><guid isPermaLink="false">https://github.com/atinesh-s/Coursera-Machine-Learning-Stanford</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>Borye/machine-learning-coursera-1 #5 in MATLAB, Today</title><link>https://github.com/Borye/machine-learning-coursera-1</link><description>&lt;p&gt;&lt;i&gt;This repo is specially created for all the work done my me as a part of Coursera's Machine Learning Course.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-coursera" class="anchor" aria-hidden="true" href="#machine-learning-coursera"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;machine-learning-coursera&lt;/h1&gt;
&lt;p&gt;This repo is specially created for all the work done my me as a part of Coursera's Machine Learning Course.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Borye</author><guid isPermaLink="false">https://github.com/Borye/machine-learning-coursera-1</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item><item><title>schneems/Octave #6 in MATLAB, Today</title><link>https://github.com/schneems/Octave</link><description>&lt;p&gt;&lt;i&gt;my octave exercises for 2011 stanford machine learning class, posted after the due date of course&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="readme.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;blockquote&gt;
&lt;p&gt;I took this class 5+ years ago. Please don't open any issues or pull requests. All examples come as is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;&lt;a id="user-content-octave" class="anchor" aria-hidden="true" href="#octave"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Octave&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://www.gnu.org/software/octave/" rel="nofollow"&gt;Octave&lt;/a&gt; is a high level (open source) programming language similar to Matlab. I'm using it for the &lt;a href="http://www.ml-class.org" rel="nofollow"&gt;2011 Stanford Machine Learning Class&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-do-androids-sing-electric-operas" class="anchor" aria-hidden="true" href="#do-androids-sing-electric-operas"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Do Androids Sing Electric Operas?&lt;/h2&gt;
&lt;p&gt;This repo contains my Octave homework assigned that I have completed. If you are taking the class please fork the project and put different solutions in a different branch. However please do not post
any code before the due date (homework is due every sunday). I will not post solutions before the due date, so please don't ask.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-other-notable-open-source-machine-learning-sources" class="anchor" aria-hidden="true" href="#other-notable-open-source-machine-learning-sources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other Notable Open Source Machine Learning Sources&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/everpeace/ml-class-assignments"&gt;https://github.com/everpeace/ml-class-assignments&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/joewandy/Stanford-Machine-Learning"&gt;https://github.com/joewandy/Stanford-Machine-Learning&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-development" class="anchor" aria-hidden="true" href="#development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development&lt;/h2&gt;
&lt;p&gt;To get Textmate Highlighting check out the &lt;a href="https://github.com/textmate/matlab.tmbundle"&gt;Octave Bundle&lt;/a&gt; Just download and change the extension to &lt;code&gt;.tmbundle&lt;/code&gt; and double click. After that go to Bundles &amp;gt;&amp;gt; Bundle Editor &amp;gt;&amp;gt; Reload Bundles.&lt;/p&gt;
&lt;p&gt;Select 'Matlab' as the file type when working with octave files&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-stanford-honor-code" class="anchor" aria-hidden="true" href="#stanford-honor-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stanford Honor Code&lt;/h2&gt;
&lt;p&gt;"We strongly encourage students to form study groups, and discuss the lecture videos (including in-video questions). We also encourage you to get together with friends to watch the videos together as a group. However, the answers that you submit for the review questions should be your own work. For the programming exercises, you are welcome to discuss them with other students, discuss specific algorithms, properties of algorithms, etc.; we ask only that you not look at any source code written by a different student, nor show your solution code to other students."&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;            .
          .MM
         .MMMM                MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM
         MM   M                 I     MZDDDM,    7DNDDMN     M8DDDM     ?     ZM8DD
         M    M                 ?     MZD88M.    7DDDDMN     M88DDM     +     $M8D8
        M7    M+                I     M$DDNM,    7DNDNMN     M8NNNM     =     $MODN
        M    ?M?                I     M$MMMM.    7DNMMMN     MOMMMM     =     $MZMM
        M    MM                 I     MOMMMM,    $DMMMMN     MMMMMM     =     7MNMM
        M  MMMM                 I     MOMMMM,    $DMMMMN     MMMMMM     =     7MMMM
        ~ MMMM                  I     MOMMMM.    $DMMMMN     MMMMMM     ~     $MNMM
        MMMMM                   I     MOMMMM.    $DMMMMN     MMMMMM     ~     7MNMM
      DMMMMM                    I     MZMMMM.    7DMMMMN     MMMMMM     ~     $MNMM
    MMMMMM                      I     MZMMMM.    $DMMMMN     MMMMMM     :     7MNMM
   8MMMM7 ?                     I     MOMMMM.    ZDMMMMN     MMMMMM     :     $MNMM
  DMMMM   M                     I     MZMMMM.    O8MMMMN     MMMMMM     :     7MDMM
 NMMM     $                     I     MD8DDM.    ZO88D8N    .MD8DOM     :     7MD8D
MMMM      M                     ?     MMMMMM     IMMMMMZ     MMMMMM     ,     ~MMMM
NMM    MMMMMMMMMM               ?         M         M         M         ,         7
MMM   MMM  M   MMM              ?         D         M         D         ,         ?
MM$   MD    =   MM              ?         8         N         D         ,         +
MMM   MM         MM             ?         8         N         8         .         +
  M    $M   O   M~              ?         O         N         8         .         +
   MM          M.               ?         O         N         8         .         =
     :M:::=--M.                 ?         O         N         8         .         =
              M                 ?         Z         N         8         .         =
              :                 ?         Z         N         O         .         ~
     MMMM     M                 ?         Z         N         O         .         ~
    MMMMMM    M                 +         $         M         O         .         =
    MMMMMM   ~,                OM.       ~M.       ,M        .M=        M7        M
     MMM    M                 DDDDDNNNNNNNMNDNNNNNNNMMMMMMMNMMMMMMMMMMMMMMMMMMMMMMM
       7MO.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Solutions licensed under MIT License
Copyright (c) 2011 &lt;a href="http://twitter.com/schneems" rel="nofollow"&gt;Schneems&lt;/a&gt;. See LICENSE.txt for
further details.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>schneems</author><guid isPermaLink="false">https://github.com/schneems/Octave</guid><pubDate>Tue, 29 Oct 2019 00:00:00 GMT</pubDate></item></channel></rss>