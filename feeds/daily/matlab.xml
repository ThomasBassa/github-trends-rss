<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: MATLAB, Today</title><link>https://github.com/trending/matlab?since=daily</link><description>The top repositories on GitHub for matlab, measured daily</description><pubDate>Sun, 01 Dec 2019 01:05:56 GMT</pubDate><lastBuildDate>Sun, 01 Dec 2019 01:05:56 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>kpzhang93/MTCNN_face_detection_alignment #1 in MATLAB, Today</title><link>https://github.com/kpzhang93/MTCNN_face_detection_alignment</link><description>&lt;p&gt;&lt;i&gt;Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Neural Networks&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-mtcnn_face_detection_alignment" class="anchor" aria-hidden="true" href="#mtcnn_face_detection_alignment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MTCNN_face_detection_alignment&lt;/h1&gt;
&lt;p&gt;Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Neural Networks&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-requirement" class="anchor" aria-hidden="true" href="#requirement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirement&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Caffe: Linux OS: &lt;a href="https://github.com/BVLC/caffe"&gt;https://github.com/BVLC/caffe&lt;/a&gt;. Windows OS: &lt;a href="https://github.com/BVLC/caffe/tree/windows"&gt;https://github.com/BVLC/caffe/tree/windows&lt;/a&gt; or &lt;a href="https://github.com/happynear/caffe-windows"&gt;https://github.com/happynear/caffe-windows&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Pdollar toolbox: &lt;a href="https://github.com/pdollar/toolbox"&gt;https://github.com/pdollar/toolbox&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Matlab 2014b or later&lt;/li&gt;
&lt;li&gt;Cuda (if use nvidia gpu)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-results" class="anchor" aria-hidden="true" href="#results"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Results&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/208be02edd9ecf8cfc02c7bf00f2d879c662f84e/68747470733a2f2f6b707a68616e6739332e6769746875622e696f2f4d54434e4e5f666163655f646574656374696f6e5f616c69676e6d656e742f70617065722f6578616d706c65732e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/208be02edd9ecf8cfc02c7bf00f2d879c662f84e/68747470733a2f2f6b707a68616e6739332e6769746875622e696f2f4d54434e4e5f666163655f646574656374696f6e5f616c69676e6d656e742f70617065722f6578616d706c65732e706e67" alt="image" data-canonical-src="https://kpzhang93.github.io/MTCNN_face_detection_alignment/paper/examples.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6df79feec086599240cce920195b85aa4ce6e0b5/68747470733a2f2f6b707a68616e6739332e6769746875622e696f2f4d54434e4e5f666163655f646574656374696f6e5f616c69676e6d656e742f70617065722f726573756c742e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/6df79feec086599240cce920195b85aa4ce6e0b5/68747470733a2f2f6b707a68616e6739332e6769746875622e696f2f4d54434e4e5f666163655f646574656374696f6e5f616c69676e6d656e742f70617065722f726573756c742e706e67" alt="image" data-canonical-src="https://kpzhang93.github.io/MTCNN_face_detection_alignment/paper/result.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-other-implementation" class="anchor" aria-hidden="true" href="#other-implementation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other implementation&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/happynear/MTCNN_face_detection_alignment"&gt;C++ &amp;amp; caffe &lt;/a&gt; (strongly recommend)&lt;br&gt;
&lt;a href="https://github.com/pangyupo/mxnet_mtcnn_face_detection"&gt;Python &amp;amp; mxnet&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/DuinoDu/mtcnn"&gt;Python &amp;amp; caffe&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-face-recognition" class="anchor" aria-hidden="true" href="#face-recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Face Recognition&lt;/h3&gt;
&lt;p&gt;Here we strongly recommend &lt;a href="https://github.com/ydwen/caffe-face"&gt;Center Face&lt;/a&gt;, which is an effective and efficient open-source tool for face recognition.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;@article{7553523,
    author={K. Zhang and Z. Zhang and Z. Li and Y. Qiao}, 
    journal={IEEE Signal Processing Letters}, 
    title={Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks}, 
    year={2016}, 
    volume={23}, 
    number={10}, 
    pages={1499-1503}, 
    keywords={Benchmark testing;Computer architecture;Convolution;Detectors;Face;Face detection;Training;Cascaded convolutional neural network (CNN);face alignment;face detection}, 
    doi={10.1109/LSP.2016.2603342}, 
    ISSN={1070-9908}, 
    month={Oct}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h3&gt;
&lt;p&gt;This code is distributed under MIT LICENSE&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h3&gt;
&lt;p&gt;Yu Qiao
&lt;a href="mailto:yu.qiao@siat.ac.cn"&gt;yu.qiao@siat.ac.cn&lt;/a&gt;&lt;br&gt;
Kaipeng Zhang
&lt;a href="mailto:kpzhang@cmlab.csie.ntu.edu.tw"&gt;kpzhang@cmlab.csie.ntu.edu.tw&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>kpzhang93</author><guid isPermaLink="false">https://github.com/kpzhang93/MTCNN_face_detection_alignment</guid><pubDate>Sun, 01 Dec 2019 00:01:00 GMT</pubDate></item><item><title>Zzh-tju/DIoU #2 in MATLAB, Today</title><link>https://github.com/Zzh-tju/DIoU</link><description>&lt;p&gt;&lt;i&gt;Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression (AAAI 2020)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-distance-iou-loss-faster-and-better-learning-for-bounding-box-regression" class="anchor" aria-hidden="true" href="#distance-iou-loss-faster-and-better-learning-for-bounding-box-regression"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression&lt;/h2&gt;
&lt;p&gt;[&lt;a href="https://arxiv.org/abs/1911.08287" rel="nofollow"&gt;arxiv&lt;/a&gt;] [&lt;a href="https://csdwren.github.io/papers/2020_aaai_DIoU.pdf" rel="nofollow"&gt;pdf&lt;/a&gt;]&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@inproceedings{zheng2020distance,
  author    = {Zhaohui Zheng, Ping Wang, Wei Liu, Jinze Li, Rongguang Ye, Dongwei Ren},
  title     = {Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression},
  booktitle = {The AAAI Conference on Artificial Intelligence (AAAI)},
   year      = {2020},
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Bounding box regression is the crucial step in object detection. In existing methods, while $\ell_n$-norm loss is widely adopted for bounding box regression, it is not tailored to the evaluation metric, i.e., Intersection over Union (IoU). Recently, IoU loss and generalized IoU (GIoU) loss have been proposed to benefit the IoU metric, but still suffer from the problems of slow convergence and inaccurate regression. In this paper, we propose a Distance-IoU (DIoU) loss by incorporating the normalized distance between the predicted box and the target box, which converges much faster in training than IoU and GIoU losses. Furthermore, this paper summarizes three geometric factors in bounding box regression, i.e., overlap area, central point distance and aspect ratio, based on which a Complete IoU (CIoU) loss is proposed, thereby leading to faster convergence and better performance. By incorporating DIoU and CIoU losses into state-of-the-art object detection algorithms, e.g., YOLO v3, SSD and Faster RCNN, we achieve notable performance gains in terms of not only IoU metric but also GIoU metric. Moreover, DIoU can be easily adopted into non-maximum suppression (NMS) to act as the criterion, further boosting performance improvement.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-1-diou-and-ciou-losses-into-detection-algorithms" class="anchor" aria-hidden="true" href="#1-diou-and-ciou-losses-into-detection-algorithms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1) DIoU and CIoU losses into Detection Algorithms&lt;/h3&gt;
&lt;p&gt;DIoU and CIoU losses are incorporated into state-of-the-art detection algorithms, including YOLO v3, SSD and Faster R-CNN.
The details of implementation and comparison can be respectively found in the following links.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;YOLO v3 &lt;a href="https://github.com/Zzh-tju/DIoU-darknet"&gt;https://github.com/Zzh-tju/DIoU-darknet&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SSD &lt;a href="https://github.com/Zzh-tju/DIoU-SSD-pytorch"&gt;https://github.com/Zzh-tju/DIoU-SSD-pytorch&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Faster R-CNN &lt;a href="https://github.com/Zzh-tju/DIoU-pytorch-detectron"&gt;https://github.com/Zzh-tju/DIoU-pytorch-detectron&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-2-simulation-experiments" class="anchor" aria-hidden="true" href="#2-simulation-experiments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2) Simulation Experiments&lt;/h3&gt;
&lt;p&gt;We provide simulation experiments to analyze the performance given a loss function in controlled settings.&lt;/p&gt;
&lt;p&gt;Download simulation experiment files, you can run it on Matlab. Our matlab version is MATLAB 2017a.&lt;/p&gt;
&lt;p&gt;There are two modes that we provide. One is &lt;code&gt;test_1715k.m&lt;/code&gt; and the other is &lt;code&gt;simple_test.m&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;test_1715k.m&lt;/code&gt; provides a large regression samples, for the details of its settings, please refer to our paper.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;simple_test.m&lt;/code&gt; provides a simple toy simulation. You can modify the options &lt;code&gt;gt&lt;/code&gt; and &lt;code&gt;pred&lt;/code&gt; to whatever you want.&lt;/p&gt;
&lt;p&gt;This is a convenient and intutive way to see how IoU based loss works. All the gradients of these four IoU based losses are calculated consistent with our DIoU-Darknet (YOLO v3). Note that the IoU term is necessary, otherwise the comparison will be meaningless. If you find some other forms of loss functions, you can run this simulation to see its convergence, about how fast it is or how much error it has. And these performance will appear in high probability in benchmark training which is our original idea about the simulation.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="simulation_examples/regression_error.jpg"&gt;&lt;img src="simulation_examples/regression_error.jpg" width="800px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We note that the basins in (a) and (b) correspond to good regression cases. One can see that IoU loss has large errors for non-overlapping cases, GIoU loss has large errors for horizontal and vertical cases, and our DIoU loss leads to very small regression errors everywhere.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-simulation-examples" class="anchor" aria-hidden="true" href="#simulation-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Simulation Examples&lt;/h2&gt;
&lt;p&gt;We further provide three typical cases in simulation experiments.&lt;/p&gt;
&lt;p&gt;First, the anchor box is set at diagonal orientation.
GIoU loss generally increases the size of predicted box to overlap with target box, while DIoU loss directly minimizes normalized distance of central points.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="simulation_examples/diag.jpg"&gt;&lt;img src="simulation_examples/diag.jpg" width="600px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Second, the anchor box is set at horizontal orientation. GIoU loss broadens the right edge of prediction box, while the
central point of prediction box only moves slightly towards target box. And then when there is overlap between prediction and
target boxes, the IoU term in GIoU loss would make better match. From the final result at T = 400, one can see that target box
has been included into prediction box, where GIoU loss has totally degraded to IoU loss.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="simulation_examples/horizontal.jpg"&gt;&lt;img src="simulation_examples/horizontal.jpg" width="800px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Third, the anchor box is set at
vertical orientation. Similarly, GIoU loss broadens the bottom edge of prediction box, and these two boxes do not match in the
final iteration. In comparison, our DIoU loss converges to good matches in only a few dozen iterations.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="simulation_examples/vertical.jpg"&gt;&lt;img src="simulation_examples/vertical.jpg" width="800px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/article&gt;&lt;/div&gt;</description><author>Zzh-tju</author><guid isPermaLink="false">https://github.com/Zzh-tju/DIoU</guid><pubDate>Sun, 01 Dec 2019 00:02:00 GMT</pubDate></item></channel></rss>