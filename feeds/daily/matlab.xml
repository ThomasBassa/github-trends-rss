<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: MATLAB, Today</title><link>https://github.com/trending/matlab?since=daily</link><description>The top repositories on GitHub for matlab, measured daily</description><pubDate>Thu, 02 Jan 2020 01:10:45 GMT</pubDate><lastBuildDate>Thu, 02 Jan 2020 01:10:45 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>luanfujun/deep-photo-styletransfer #1 in MATLAB, Today</title><link>https://github.com/luanfujun/deep-photo-styletransfer</link><description>&lt;p&gt;&lt;i&gt;Code and data for paper "Deep Photo Style Transfer": https://arxiv.org/abs/1703.07511 &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deep-photo-styletransfer" class="anchor" aria-hidden="true" href="#deep-photo-styletransfer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;deep-photo-styletransfer&lt;/h1&gt;
&lt;p&gt;Code and data for paper "&lt;a href="https://arxiv.org/abs/1703.07511" rel="nofollow"&gt;Deep Photo Style Transfer&lt;/a&gt;"&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;This software is published for academic and non-commercial use only.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h2&gt;
&lt;p&gt;This code is based on torch. It has been tested on Ubuntu 14.04 LTS.&lt;/p&gt;
&lt;p&gt;Dependencies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/torch/torch7"&gt;Torch&lt;/a&gt; (with &lt;a href="https://github.com/soumith/matio-ffi.torch"&gt;matio-ffi&lt;/a&gt; and &lt;a href="https://github.com/szagoruyko/loadcaffe"&gt;loadcaffe&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mathworks.com/" rel="nofollow"&gt;Matlab&lt;/a&gt; or &lt;a href="https://www.gnu.org/software/octave/" rel="nofollow"&gt;Octave&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CUDA backend:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://developer.nvidia.com/cuda-downloads" rel="nofollow"&gt;CUDA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.nvidia.com/cudnn" rel="nofollow"&gt;cudnn&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Download VGG-19:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sh models/download_models.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compile &lt;code&gt;cuda_utils.cu&lt;/code&gt; (Adjust &lt;code&gt;PREFIX&lt;/code&gt; and &lt;code&gt;NVCC_PREFIX&lt;/code&gt; in &lt;code&gt;makefile&lt;/code&gt; for your machine):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;make clean &amp;amp;&amp;amp; make
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick start&lt;/h3&gt;
&lt;p&gt;To generate all results (in &lt;code&gt;examples/&lt;/code&gt;) using the provided scripts, simply run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;run('gen_laplacian/gen_laplacian.m')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in Matlab or Octave and then&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python gen_all.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in Python. The final output will be in &lt;code&gt;examples/final_results/&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Basic usage&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Given input and style images with semantic segmentation masks, put them in &lt;code&gt;examples/&lt;/code&gt; respectively. They will have the following filename form: &lt;code&gt;examples/input/in&amp;lt;id&amp;gt;.png&lt;/code&gt;, &lt;code&gt;examples/style/tar&amp;lt;id&amp;gt;.png&lt;/code&gt; and &lt;code&gt;examples/segmentation/in&amp;lt;id&amp;gt;.png&lt;/code&gt;, &lt;code&gt;examples/segmentation/tar&amp;lt;id&amp;gt;.png&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;Compute the matting Laplacian matrix using &lt;code&gt;gen_laplacian/gen_laplacian.m&lt;/code&gt; in Matlab. The output matrix will have the following filename form: &lt;code&gt;gen_laplacian/Input_Laplacian_3x3_1e-7_CSR&amp;lt;id&amp;gt;.mat&lt;/code&gt;;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Note: Please make sure that the content image resolution is consistent for Matting Laplacian computation in Matlab and style transfer in Torch, otherwise the result won't be correct.&lt;/strong&gt;&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Run the following script to generate segmented intermediate result:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;th neuralstyle_seg.lua -content_image &amp;lt;input&amp;gt; -style_image &amp;lt;style&amp;gt; -content_seg &amp;lt;inputMask&amp;gt; -style_seg &amp;lt;styleMask&amp;gt; -index &amp;lt;id&amp;gt; -serial &amp;lt;intermediate_folder&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="4"&gt;
&lt;li&gt;Run the following script to generate final result:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;th deepmatting_seg.lua -content_image &amp;lt;input&amp;gt; -style_image &amp;lt;style&amp;gt; -content_seg &amp;lt;inputMask&amp;gt; -style_seg &amp;lt;styleMask&amp;gt; -index &amp;lt;id&amp;gt; -init_image &amp;lt;intermediate_folder/out&amp;lt;id&amp;gt;_t_1000.png&amp;gt; -serial &amp;lt;final_folder&amp;gt; -f_radius 15 -f_edge 0.01
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can pass &lt;code&gt;-backend cudnn&lt;/code&gt; and &lt;code&gt;-cudnn_autotune&lt;/code&gt; to both Lua scripts (step 3.
and 4.) to potentially improve speed and memory usage. &lt;code&gt;libcudnn.so&lt;/code&gt; must be in
your &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt;. This requires &lt;a href="https://github.com/soumith/cudnn.torch"&gt;cudnn.torch&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-image-segmentation" class="anchor" aria-hidden="true" href="#image-segmentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image segmentation&lt;/h3&gt;
&lt;p&gt;Note: In the main paper we generate all comparison results using automatic scene segmentation algorithm modified from &lt;a href="https://arxiv.org/abs/1606.00915" rel="nofollow"&gt;DilatedNet&lt;/a&gt;. Manual segmentation enables more diverse tasks hence we provide the masks in &lt;code&gt;examples/segmentation/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The mask colors we used (you could add more colors in &lt;code&gt;ExtractMask&lt;/code&gt; function in two &lt;code&gt;*.lua&lt;/code&gt; files):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Color variable&lt;/th&gt;
&lt;th&gt;RGB Value&lt;/th&gt;
&lt;th&gt;Hex Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;blue&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0 0 255&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0000ff&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;green&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0 255 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;00ff00&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;black&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0 0 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;000000&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;white&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;255 255 255&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ffffff&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;red&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;255 0 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ff0000&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;yellow&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;255 255 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ffff00&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;grey&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;128 128 128&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;808080&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;lightblue&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0 255 255&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;00ffff&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;purple&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;255 0 255&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ff00ff &lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here are some automatic and manual tools for creating a segmentation mask for a photo image:&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-automatic" class="anchor" aria-hidden="true" href="#automatic"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Automatic:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://sceneparsing.csail.mit.edu/" rel="nofollow"&gt;MIT Scene Parsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.unc.edu/~jtighe/Papers/ECCV10/" rel="nofollow"&gt;SuperParsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://people.csail.mit.edu/celiu/LabelTransfer/" rel="nofollow"&gt;Nonparametric Scene Parsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html" rel="nofollow"&gt;Berkeley Contour Detection and Image Segmentation Resources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/torrvision/crfasrnn"&gt;CRF-RNN for Semantic Image Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/belltailjp/selective_search_py"&gt;Selective Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DrSleep/tensorflow-deeplab-lfov"&gt;DeepLab-TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-manual" class="anchor" aria-hidden="true" href="#manual"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Manual:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://helpx.adobe.com/photoshop/using/making-quick-selections.html" rel="nofollow"&gt;Photoshop Quick Selection Tool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.gimp.org/en/gimp-tools-selection.html" rel="nofollow"&gt;GIMP Selection Tool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://gmic.eu/gimp.shtml" rel="nofollow"&gt;GIMP G'MIC Interactive Foreground Extraction tool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;p&gt;Here are some results from our algorithm (from left to right are input, style and our output):&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in3.png"&gt;&lt;img src="examples/input/in3.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar3.png"&gt;&lt;img src="examples/style/tar3.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_3.png"&gt;&lt;img src="examples/refine_posterization/refine_3.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in4.png"&gt;&lt;img src="examples/input/in4.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar4.png"&gt;&lt;img src="examples/style/tar4.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_4.png"&gt;&lt;img src="examples/refine_posterization/refine_4.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in13.png"&gt;&lt;img src="examples/input/in13.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar13.png"&gt;&lt;img src="examples/style/tar13.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_13.png"&gt;&lt;img src="examples/refine_posterization/refine_13.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in9.png"&gt;&lt;img src="examples/input/in9.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar9.png"&gt;&lt;img src="examples/style/tar9.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_9.png"&gt;&lt;img src="examples/refine_posterization/refine_9.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in20.png"&gt;&lt;img src="examples/input/in20.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar20.png"&gt;&lt;img src="examples/style/tar20.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_20.png"&gt;&lt;img src="examples/refine_posterization/refine_20.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in1.png"&gt;&lt;img src="examples/input/in1.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar1.png"&gt;&lt;img src="examples/style/tar1.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_1.png"&gt;&lt;img src="examples/refine_posterization/refine_1.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in39.png"&gt;&lt;img src="examples/input/in39.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar39.png"&gt;&lt;img src="examples/style/tar39.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_39.png"&gt;&lt;img src="examples/refine_posterization/refine_39.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in57.png"&gt;&lt;img src="examples/input/in57.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar57.png"&gt;&lt;img src="examples/style/tar57.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_57.png"&gt;&lt;img src="examples/refine_posterization/refine_57.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in47.png"&gt;&lt;img src="examples/input/in47.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar47.png"&gt;&lt;img src="examples/style/tar47.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_47.png"&gt;&lt;img src="examples/refine_posterization/refine_47.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in58.png"&gt;&lt;img src="examples/input/in58.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar58.png"&gt;&lt;img src="examples/style/tar58.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_58.png"&gt;&lt;img src="examples/refine_posterization/refine_58.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in51.png"&gt;&lt;img src="examples/input/in51.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar51.png"&gt;&lt;img src="examples/style/tar51.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_51.png"&gt;&lt;img src="examples/refine_posterization/refine_51.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in7.png"&gt;&lt;img src="examples/input/in7.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar7.png"&gt;&lt;img src="examples/style/tar7.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_7.png"&gt;&lt;img src="examples/refine_posterization/refine_7.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in23.png"&gt;&lt;img src="examples/input/in23.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in23.png"&gt;&lt;img src="examples/input/in23.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/final_results/best23_t_1000.png"&gt;&lt;img src="examples/final_results/best23_t_1000.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in16.png"&gt;&lt;img src="examples/input/in16.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar16.png"&gt;&lt;img src="examples/style/tar16.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_16.png"&gt;&lt;img src="examples/refine_posterization/refine_16.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in30.png"&gt;&lt;img src="examples/input/in30.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar30.png"&gt;&lt;img src="examples/style/tar30.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_30.png"&gt;&lt;img src="examples/refine_posterization/refine_30.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in2.png"&gt;&lt;img src="examples/input/in2.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar2.png"&gt;&lt;img src="examples/style/tar2.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/final_results/best2_t_1000.png"&gt;&lt;img src="examples/final_results/best2_t_1000.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in11.png"&gt;&lt;img src="examples/input/in11.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar11.png"&gt;&lt;img src="examples/style/tar11.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_11.png"&gt;&lt;img src="examples/refine_posterization/refine_11.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgement" class="anchor" aria-hidden="true" href="#acknowledgement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgement&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Our torch implementation is based on Justin Johnson's &lt;a href="https://github.com/jcjohnson/neural-style"&gt;code&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;We use Anat Levin's Matlab &lt;a href="http://www.wisdom.weizmann.ac.il/~levina/matting.tar.gz" rel="nofollow"&gt;code&lt;/a&gt; to compute the matting Laplacian matrix.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you find this work useful for your research, please cite:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{luan2017deep,
  title={Deep Photo Style Transfer},
  author={Luan, Fujun and Paris, Sylvain and Shechtman, Eli and Bala, Kavita},
  journal={arXiv preprint arXiv:1703.07511},
  year={2017}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h2&gt;
&lt;p&gt;Feel free to contact me if there is any question (Fujun Luan &lt;a href="mailto:fl356@cornell.edu"&gt;fl356@cornell.edu&lt;/a&gt;).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>luanfujun</author><guid isPermaLink="false">https://github.com/luanfujun/deep-photo-styletransfer</guid><pubDate>Thu, 02 Jan 2020 00:01:00 GMT</pubDate></item><item><title>shenshikexmu/IMUCalibration-Gesture #2 in MATLAB, Today</title><link>https://github.com/shenshikexmu/IMUCalibration-Gesture</link><description>&lt;p&gt;&lt;i&gt;calibration for Imu and show gesture&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-imucalibration-gesture" class="anchor" aria-hidden="true" href="#imucalibration-gesture"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;IMUCalibration-Gesture&lt;/h1&gt;
&lt;p&gt;calibration for Imu and show gesture&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-0相关博客" class="anchor" aria-hidden="true" href="#0相关博客"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;0.相关博客:&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/shenshikexmu/article/details/80013444" rel="nofollow"&gt;https://blog.csdn.net/shenshikexmu/article/details/80013444&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-1读入数据" class="anchor" aria-hidden="true" href="#1读入数据"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.读入数据&lt;/h4&gt;
&lt;p&gt;load('calfata.mat')&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-2运行校正算法" class="anchor" aria-hidden="true" href="#2运行校正算法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2.运行校正算法&lt;/h4&gt;
&lt;p&gt;[Ta,Ka,Ba,Tg,Kg,Bg,Tm2a,Bm,Vm,mag_strength]=ImuCalibration_Gesture(cal_data)&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-3校正部分" class="anchor" aria-hidden="true" href="#3校正部分"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3.校正部分&lt;/h4&gt;
&lt;h5&gt;&lt;a id="user-content-加速度角速度" class="anchor" aria-hidden="true" href="#加速度角速度"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;加速度、角速度&lt;/h5&gt;
&lt;p&gt;conference  &lt;strong&gt;A Robust and Easy to implement method for imu calibration without External Equipments&lt;/strong&gt;&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-磁力计" class="anchor" aria-hidden="true" href="#磁力计"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;磁力计&lt;/h5&gt;
&lt;p&gt;算法mag2acc_matrix假设重力与磁向量的夹角不变，算法Cal_mag4acc_frame利用不同姿态下传感器感受的磁通向量的变化与姿态变化的相关性，计算参数。&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-4参数部分" class="anchor" aria-hidden="true" href="#4参数部分"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4.参数部分&lt;/h4&gt;
&lt;h5&gt;&lt;a id="user-content-cal_acctakaraw_accba" class="anchor" aria-hidden="true" href="#cal_acctakaraw_accba"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;cal_acc=Ta&lt;em&gt;Ka&lt;/em&gt;(raw_acc+Ba)&lt;/h5&gt;
&lt;h5&gt;&lt;a id="user-content-cal_gyrotgkgraw_gyrobg" class="anchor" aria-hidden="true" href="#cal_gyrotgkgraw_gyrobg"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;cal_gyro=Tg&lt;em&gt;Kg&lt;/em&gt;(raw_gyro+Bg)&lt;/h5&gt;
&lt;h5&gt;&lt;a id="user-content-cal_magtm2araw_magbm" class="anchor" aria-hidden="true" href="#cal_magtm2araw_magbm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;cal_mag=Tm2a*(raw_mag+Bm)&lt;/h5&gt;
&lt;h4&gt;&lt;a id="user-content-5姿态部分" class="anchor" aria-hidden="true" href="#5姿态部分"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;5.姿态部分&lt;/h4&gt;
&lt;h5&gt;&lt;a id="user-content-mahony-filter" class="anchor" aria-hidden="true" href="#mahony-filter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Mahony filter&lt;/h5&gt;
&lt;p&gt;conference &lt;strong&gt;Nonlinear Complementery Filters on the Special Orthogonal Group&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;inspired by    &lt;a href="http://blog.csdn.net/luoshi006/article/details/51513580" rel="nofollow"&gt;http://blog.csdn.net/luoshi006/article/details/51513580&lt;/a&gt;&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-ekf" class="anchor" aria-hidden="true" href="#ekf"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;EKF&lt;/h5&gt;
&lt;p&gt;derivation &lt;strong&gt;A Double-Stage Kalman Filter for Orientation Tracking with an Integrated Processor in 9-D IMU&lt;/strong&gt;&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-high-low-pass" class="anchor" aria-hidden="true" href="#high-low-pass"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;high low pass&lt;/h5&gt;
&lt;p&gt;high and low pass filter to Gyro atitude with Accelerate &amp;amp; Magnetic&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-eskf" class="anchor" aria-hidden="true" href="#eskf"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ESKF&lt;/h5&gt;
&lt;p&gt;conference &lt;strong&gt;Quaternion kinematics for the error-state Kalman filter&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;inspired by &lt;a href="https://github.com/yuzhou42/ESKF-Attitude-Estimation/blob/master/ESKF%20Attitude%20Algorithm.pdf"&gt;https://github.com/yuzhou42/ESKF-Attitude-Estimation/blob/master/ESKF%20Attitude%20Algorithm.pdf&lt;/a&gt;&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-滤波后的四元数" class="anchor" aria-hidden="true" href="#滤波后的四元数"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;滤波后的四元数&lt;/h5&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6f0e20bef0ec15167047d5767850ea987f596f29/68747470733a2f2f696d672d626c6f672e6373646e2e6e65742f32303138303630363132303732323833333f77617465726d61726b2f322f746578742f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c334e6f5a57357a61476c725a58687464513d3d2f666f6e742f3561364c354c32542f666f6e7473697a652f3430302f66696c6c2f49304a42516b46434d413d3d2f646973736f6c76652f3130"&gt;&lt;img src="https://camo.githubusercontent.com/6f0e20bef0ec15167047d5767850ea987f596f29/68747470733a2f2f696d672d626c6f672e6373646e2e6e65742f32303138303630363132303732323833333f77617465726d61726b2f322f746578742f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c334e6f5a57357a61476c725a58687464513d3d2f666f6e742f3561364c354c32542f666f6e7473697a652f3430302f66696c6c2f49304a42516b46434d413d3d2f646973736f6c76652f3130" alt="滤波结果" data-canonical-src="https://img-blog.csdn.net/20180606120722833?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5zaGlrZXhtdQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/10" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-算法视频" class="anchor" aria-hidden="true" href="#算法视频"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;算法视频&lt;/h5&gt;
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/av78142069/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9dc759fa17c42bacbc118c32b7f0ac16eb7558e4/68747470733a2f2f75706f732d766964656f636f766572732e616367766964656f2e636f6d2f6d3139313230357773336a763432736b34396664336233313937623539326e385f303031302e6a7067" alt="视频" data-canonical-src="https://upos-videocovers.acgvideo.com/m191205ws3jv42sk49fd3b3197b592n8_0010.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>shenshikexmu</author><guid isPermaLink="false">https://github.com/shenshikexmu/IMUCalibration-Gesture</guid><pubDate>Thu, 02 Jan 2020 00:02:00 GMT</pubDate></item><item><title>AvaisP/machine-learning-programming-assignments-coursera-andrew-ng #3 in MATLAB, Today</title><link>https://github.com/AvaisP/machine-learning-programming-assignments-coursera-andrew-ng</link><description>&lt;p&gt;&lt;i&gt;Solutions to Andrew NG's machine learning course on Coursera&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-programming-assignments-coursera-andrew-ng" class="anchor" aria-hidden="true" href="#machine-learning-programming-assignments-coursera-andrew-ng"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;machine-learning-programming-assignments-coursera-andrew-ng&lt;/h1&gt;
&lt;p&gt;Solutions to Andrew NG's machine learning course on Coursera&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>AvaisP</author><guid isPermaLink="false">https://github.com/AvaisP/machine-learning-programming-assignments-coursera-andrew-ng</guid><pubDate>Thu, 02 Jan 2020 00:03:00 GMT</pubDate></item><item><title>hhping/LDPC_en-decoder #4 in MATLAB, Today</title><link>https://github.com/hhping/LDPC_en-decoder</link><description>&lt;p&gt;&lt;i&gt;LDPC编码解码matlab代码和Verilog代码及资料&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;This repo does not have a README.&lt;/i&gt;&lt;/p&gt;</description><author>hhping</author><guid isPermaLink="false">https://github.com/hhping/LDPC_en-decoder</guid><pubDate>Thu, 02 Jan 2020 00:04:00 GMT</pubDate></item></channel></rss>