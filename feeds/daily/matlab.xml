<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: MATLAB, Today</title><link>https://github.com/trending/matlab?since=daily</link><description>The top repositories on GitHub for matlab, measured daily</description><pubDate>Sun, 17 Nov 2019 01:07:49 GMT</pubDate><lastBuildDate>Sun, 17 Nov 2019 01:07:49 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>TadasBaltrusaitis/OpenFace #1 in MATLAB, Today</title><link>https://github.com/TadasBaltrusaitis/OpenFace</link><description>&lt;p&gt;&lt;i&gt;OpenFace – a state-of-the art tool intended for facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-openface-220-a-facial-behavior-analysis-toolkit" class="anchor" aria-hidden="true" href="#openface-220-a-facial-behavior-analysis-toolkit"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;OpenFace 2.2.0: a facial behavior analysis toolkit&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/TadasBaltrusaitis/OpenFace" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/4243d567083c3a651ecbadc77c77a00ba697fb40/68747470733a2f2f7472617669732d63692e6f72672f546164617342616c7472757361697469732f4f70656e466163652e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/TadasBaltrusaitis/OpenFace.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/TadasBaltrusaitis/openface/branch/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8c6fb6db38385292d352f1b17205f42469d06fda/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f386d73696b6c786662686c6e736d78702f6272616e63682f6d61737465723f7376673d74727565" alt="Build status" data-canonical-src="https://ci.appveyor.com/api/projects/status/8msiklxfbhlnsmxp/branch/master?svg=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Over the past few years, there has been an increased interest in automatic facial behavior analysis
and understanding. We present OpenFace – a tool intended for computer vision and machine learning
researchers, affective computing community and people interested in building interactive
applications based on facial behavior analysis. OpenFace is the ﬁrst toolkit capable of facial
landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation
with available source code for both running and training the models. The computer vision algorithms
which represent the core of OpenFace demonstrate state-of-the-art results in all of the above
mentioned tasks. Furthermore, our tool is capable of real-time performance and is able to run from a
simple webcam without any specialist hardware.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/muticomp_logo_black.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/muticomp_logo_black.png" alt="Multicomp logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;OpenFace was originally developed by Tadas Baltrušaitis in collaboration with CMU MultiComp Lab led by Prof. Louis-Philippe Morency. Some of the original algorithms were created while at Rainbow Group, Cambridge University. The OpenFace library is still actively developed at the CMU MultiComp Lab in collaboration with Tadas Baltršaitis. Special thanks to researcher who helped developing, implementing and testing the algorithms present in OpenFace: Amir Zadeh and Yao Chong Lim on work on the CE-CLM model and Erroll Wood for the gaze estimation work.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-wiki" class="anchor" aria-hidden="true" href="#wiki"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WIKI&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;For instructions of how to install/compile/use the project please see &lt;a href="https://github.com/TadasBaltrusaitis/OpenFace/wiki"&gt;WIKI&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-functionality" class="anchor" aria-hidden="true" href="#functionality"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Functionality&lt;/h2&gt;
&lt;p&gt;The system is capable of performing a number of facial analysis tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facial Landmark Detection&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/multi_face_img.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/multi_face_img.png" alt="Sample facial landmark detection image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facial Landmark and head pose tracking (links to YouTube videos)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=V7rV0uy7heQ" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/861e54570c553cb53c797dd8bc57a24f29152655/687474703a2f2f696d672e796f75747562652e636f6d2f76692f56377256307579376865512f302e6a7067" alt="Multiple Face Tracking" width="240" height="180" border="10" data-canonical-src="http://img.youtube.com/vi/V7rV0uy7heQ/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.youtube.com/watch?v=vYOa8Pif5lY" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a9137826a1740e8df2125ef9b76541445e32957e/687474703a2f2f696d672e796f75747562652e636f6d2f76692f76594f6138506966356c592f302e6a7067" alt="Multiple Face Tracking" width="240" height="180" border="10" data-canonical-src="http://img.youtube.com/vi/vYOa8Pif5lY/0.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facial Action Unit Recognition&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/au_sample.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/au_sample.png" height="280" width="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gaze tracking (image of it in action)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/gaze_ex.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/gaze_ex.png" height="182" width="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facial Feature Extraction (aligned faces and HOG features)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/TadasBaltrusaitis/OpenFace/blob/master/imgs/appearance.png"&gt;&lt;img src="https://github.com/TadasBaltrusaitis/OpenFace/raw/master/imgs/appearance.png" alt="Sample aligned face and HOG image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you use any of the resources provided on this page in any of your publications we ask you to cite the following work and the work for a relevant submodule you used.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-overall-system" class="anchor" aria-hidden="true" href="#overall-system"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overall system&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;OpenFace 2.0: Facial Behavior Analysis Toolkit&lt;/strong&gt;
Tadas Baltrušaitis, Amir Zadeh, Yao Chong Lim, and Louis-Philippe Morency,
&lt;em&gt;IEEE International Conference on Automatic Face and Gesture Recognition&lt;/em&gt;, 2018&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-facial-landmark-detection-and-tracking" class="anchor" aria-hidden="true" href="#facial-landmark-detection-and-tracking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Facial landmark detection and tracking&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Convolutional experts constrained local model for facial landmark detection&lt;/strong&gt;
A. Zadeh, T. Baltrušaitis, and Louis-Philippe Morency.
&lt;em&gt;Computer Vision and Pattern Recognition Workshops&lt;/em&gt;, 2017&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Constrained Local Neural Fields for robust facial landmark detection in the wild&lt;/strong&gt;
Tadas Baltrušaitis, Peter Robinson, and Louis-Philippe Morency.
in IEEE Int. &lt;em&gt;Conference on Computer Vision Workshops, 300 Faces in-the-Wild Challenge&lt;/em&gt;, 2013.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-eye-gaze-tracking" class="anchor" aria-hidden="true" href="#eye-gaze-tracking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Eye gaze tracking&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Rendering of Eyes for Eye-Shape Registration and Gaze Estimation&lt;/strong&gt;
Erroll Wood, Tadas Baltrušaitis, Xucong Zhang, Yusuke Sugano, Peter Robinson, and Andreas Bulling
in &lt;em&gt;IEEE International Conference on Computer Vision (ICCV)&lt;/em&gt;, 2015&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-facial-action-unit-detection" class="anchor" aria-hidden="true" href="#facial-action-unit-detection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Facial Action Unit detection&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Cross-dataset learning and person-specific normalisation for automatic Action Unit detection&lt;/strong&gt;
Tadas Baltrušaitis, Marwa Mahmoud, and Peter Robinson
in &lt;em&gt;Facial Expression Recognition and Analysis Challenge&lt;/em&gt;,
&lt;em&gt;IEEE International Conference on Automatic Face and Gesture Recognition&lt;/em&gt;, 2015&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-commercial-license" class="anchor" aria-hidden="true" href="#commercial-license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Commercial license&lt;/h1&gt;
&lt;p&gt;For inquiries about the commercial licensing of the OpenFace toolkit please visit &lt;a href="https://www.flintbox.com/public/project/50632/" rel="nofollow"&gt;https://www.flintbox.com/public/project/50632/&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-final-remarks" class="anchor" aria-hidden="true" href="#final-remarks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Final remarks&lt;/h1&gt;
&lt;p&gt;I did my best to make sure that the code runs out of the box but there are always issues and I would be grateful for your understanding that this is research code and a research project. If you encounter any problems/bugs/issues please contact me on github or by emailing me at &lt;a href="mailto:tadyla@gmail.com"&gt;tadyla@gmail.com&lt;/a&gt; for any bug reports/questions/suggestions. I prefer questions and bug reports on github as that provides visibility to others who might be encountering same issues or who have the same questions.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-copyright" class="anchor" aria-hidden="true" href="#copyright"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Copyright&lt;/h1&gt;
&lt;p&gt;Copyright can be found in the Copyright.txt&lt;/p&gt;
&lt;p&gt;You have to respect dlib, OpenBLAS, and OpenCV licenses.&lt;/p&gt;
&lt;p&gt;Furthermore you have to respect the licenses of the datasets used for model training - &lt;a href="https://github.com/TadasBaltrusaitis/OpenFace/wiki/Datasets"&gt;https://github.com/TadasBaltrusaitis/OpenFace/wiki/Datasets&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>TadasBaltrusaitis</author><guid isPermaLink="false">https://github.com/TadasBaltrusaitis/OpenFace</guid><pubDate>Sun, 17 Nov 2019 00:01:00 GMT</pubDate></item><item><title>kpzhang93/MTCNN_face_detection_alignment #2 in MATLAB, Today</title><link>https://github.com/kpzhang93/MTCNN_face_detection_alignment</link><description>&lt;p&gt;&lt;i&gt;Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Neural Networks&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-mtcnn_face_detection_alignment" class="anchor" aria-hidden="true" href="#mtcnn_face_detection_alignment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MTCNN_face_detection_alignment&lt;/h1&gt;
&lt;p&gt;Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Neural Networks&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-requirement" class="anchor" aria-hidden="true" href="#requirement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirement&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Caffe: Linux OS: &lt;a href="https://github.com/BVLC/caffe"&gt;https://github.com/BVLC/caffe&lt;/a&gt;. Windows OS: &lt;a href="https://github.com/BVLC/caffe/tree/windows"&gt;https://github.com/BVLC/caffe/tree/windows&lt;/a&gt; or &lt;a href="https://github.com/happynear/caffe-windows"&gt;https://github.com/happynear/caffe-windows&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Pdollar toolbox: &lt;a href="https://github.com/pdollar/toolbox"&gt;https://github.com/pdollar/toolbox&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Matlab 2014b or later&lt;/li&gt;
&lt;li&gt;Cuda (if use nvidia gpu)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-results" class="anchor" aria-hidden="true" href="#results"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Results&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/208be02edd9ecf8cfc02c7bf00f2d879c662f84e/68747470733a2f2f6b707a68616e6739332e6769746875622e696f2f4d54434e4e5f666163655f646574656374696f6e5f616c69676e6d656e742f70617065722f6578616d706c65732e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/208be02edd9ecf8cfc02c7bf00f2d879c662f84e/68747470733a2f2f6b707a68616e6739332e6769746875622e696f2f4d54434e4e5f666163655f646574656374696f6e5f616c69676e6d656e742f70617065722f6578616d706c65732e706e67" alt="image" data-canonical-src="https://kpzhang93.github.io/MTCNN_face_detection_alignment/paper/examples.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6df79feec086599240cce920195b85aa4ce6e0b5/68747470733a2f2f6b707a68616e6739332e6769746875622e696f2f4d54434e4e5f666163655f646574656374696f6e5f616c69676e6d656e742f70617065722f726573756c742e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/6df79feec086599240cce920195b85aa4ce6e0b5/68747470733a2f2f6b707a68616e6739332e6769746875622e696f2f4d54434e4e5f666163655f646574656374696f6e5f616c69676e6d656e742f70617065722f726573756c742e706e67" alt="image" data-canonical-src="https://kpzhang93.github.io/MTCNN_face_detection_alignment/paper/result.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-other-implementation" class="anchor" aria-hidden="true" href="#other-implementation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other implementation&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/happynear/MTCNN_face_detection_alignment"&gt;C++ &amp;amp; caffe &lt;/a&gt; (strongly recommend)&lt;br&gt;
&lt;a href="https://github.com/pangyupo/mxnet_mtcnn_face_detection"&gt;Python &amp;amp; mxnet&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/DuinoDu/mtcnn"&gt;Python &amp;amp; caffe&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-face-recognition" class="anchor" aria-hidden="true" href="#face-recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Face Recognition&lt;/h3&gt;
&lt;p&gt;Here we strongly recommend &lt;a href="https://github.com/ydwen/caffe-face"&gt;Center Face&lt;/a&gt;, which is an effective and efficient open-source tool for face recognition.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;@article{7553523,
    author={K. Zhang and Z. Zhang and Z. Li and Y. Qiao}, 
    journal={IEEE Signal Processing Letters}, 
    title={Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks}, 
    year={2016}, 
    volume={23}, 
    number={10}, 
    pages={1499-1503}, 
    keywords={Benchmark testing;Computer architecture;Convolution;Detectors;Face;Face detection;Training;Cascaded convolutional neural network (CNN);face alignment;face detection}, 
    doi={10.1109/LSP.2016.2603342}, 
    ISSN={1070-9908}, 
    month={Oct}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h3&gt;
&lt;p&gt;This code is distributed under MIT LICENSE&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h3&gt;
&lt;p&gt;Yu Qiao
&lt;a href="mailto:yu.qiao@siat.ac.cn"&gt;yu.qiao@siat.ac.cn&lt;/a&gt;&lt;br&gt;
Kaipeng Zhang
&lt;a href="mailto:kpzhang@cmlab.csie.ntu.edu.tw"&gt;kpzhang@cmlab.csie.ntu.edu.tw&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>kpzhang93</author><guid isPermaLink="false">https://github.com/kpzhang93/MTCNN_face_detection_alignment</guid><pubDate>Sun, 17 Nov 2019 00:02:00 GMT</pubDate></item></channel></rss>