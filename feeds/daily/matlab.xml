<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: MATLAB, Today</title><link>https://github.com/trending/matlab?since=daily</link><description>The top repositories on GitHub for matlab, measured daily</description><pubDate>Sun, 09 Feb 2020 01:09:42 GMT</pubDate><lastBuildDate>Sun, 09 Feb 2020 01:09:42 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>luanfujun/deep-photo-styletransfer #1 in MATLAB, Today</title><link>https://github.com/luanfujun/deep-photo-styletransfer</link><description>&lt;p&gt;&lt;i&gt;Code and data for paper "Deep Photo Style Transfer": https://arxiv.org/abs/1703.07511 &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deep-photo-styletransfer" class="anchor" aria-hidden="true" href="#deep-photo-styletransfer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;deep-photo-styletransfer&lt;/h1&gt;
&lt;p&gt;Code and data for paper "&lt;a href="https://arxiv.org/abs/1703.07511" rel="nofollow"&gt;Deep Photo Style Transfer&lt;/a&gt;"&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;This software is published for academic and non-commercial use only.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h2&gt;
&lt;p&gt;This code is based on torch. It has been tested on Ubuntu 14.04 LTS.&lt;/p&gt;
&lt;p&gt;Dependencies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/torch/torch7"&gt;Torch&lt;/a&gt; (with &lt;a href="https://github.com/soumith/matio-ffi.torch"&gt;matio-ffi&lt;/a&gt; and &lt;a href="https://github.com/szagoruyko/loadcaffe"&gt;loadcaffe&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mathworks.com/" rel="nofollow"&gt;Matlab&lt;/a&gt; or &lt;a href="https://www.gnu.org/software/octave/" rel="nofollow"&gt;Octave&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CUDA backend:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://developer.nvidia.com/cuda-downloads" rel="nofollow"&gt;CUDA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.nvidia.com/cudnn" rel="nofollow"&gt;cudnn&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Download VGG-19:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sh models/download_models.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compile &lt;code&gt;cuda_utils.cu&lt;/code&gt; (Adjust &lt;code&gt;PREFIX&lt;/code&gt; and &lt;code&gt;NVCC_PREFIX&lt;/code&gt; in &lt;code&gt;makefile&lt;/code&gt; for your machine):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;make clean &amp;amp;&amp;amp; make
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick start&lt;/h3&gt;
&lt;p&gt;To generate all results (in &lt;code&gt;examples/&lt;/code&gt;) using the provided scripts, simply run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;run('gen_laplacian/gen_laplacian.m')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in Matlab or Octave and then&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python gen_all.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in Python. The final output will be in &lt;code&gt;examples/final_results/&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-basic-usage" class="anchor" aria-hidden="true" href="#basic-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Basic usage&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Given input and style images with semantic segmentation masks, put them in &lt;code&gt;examples/&lt;/code&gt; respectively. They will have the following filename form: &lt;code&gt;examples/input/in&amp;lt;id&amp;gt;.png&lt;/code&gt;, &lt;code&gt;examples/style/tar&amp;lt;id&amp;gt;.png&lt;/code&gt; and &lt;code&gt;examples/segmentation/in&amp;lt;id&amp;gt;.png&lt;/code&gt;, &lt;code&gt;examples/segmentation/tar&amp;lt;id&amp;gt;.png&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;Compute the matting Laplacian matrix using &lt;code&gt;gen_laplacian/gen_laplacian.m&lt;/code&gt; in Matlab. The output matrix will have the following filename form: &lt;code&gt;gen_laplacian/Input_Laplacian_3x3_1e-7_CSR&amp;lt;id&amp;gt;.mat&lt;/code&gt;;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Note: Please make sure that the content image resolution is consistent for Matting Laplacian computation in Matlab and style transfer in Torch, otherwise the result won't be correct.&lt;/strong&gt;&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Run the following script to generate segmented intermediate result:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;th neuralstyle_seg.lua -content_image &amp;lt;input&amp;gt; -style_image &amp;lt;style&amp;gt; -content_seg &amp;lt;inputMask&amp;gt; -style_seg &amp;lt;styleMask&amp;gt; -index &amp;lt;id&amp;gt; -serial &amp;lt;intermediate_folder&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="4"&gt;
&lt;li&gt;Run the following script to generate final result:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;th deepmatting_seg.lua -content_image &amp;lt;input&amp;gt; -style_image &amp;lt;style&amp;gt; -content_seg &amp;lt;inputMask&amp;gt; -style_seg &amp;lt;styleMask&amp;gt; -index &amp;lt;id&amp;gt; -init_image &amp;lt;intermediate_folder/out&amp;lt;id&amp;gt;_t_1000.png&amp;gt; -serial &amp;lt;final_folder&amp;gt; -f_radius 15 -f_edge 0.01
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can pass &lt;code&gt;-backend cudnn&lt;/code&gt; and &lt;code&gt;-cudnn_autotune&lt;/code&gt; to both Lua scripts (step 3.
and 4.) to potentially improve speed and memory usage. &lt;code&gt;libcudnn.so&lt;/code&gt; must be in
your &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt;. This requires &lt;a href="https://github.com/soumith/cudnn.torch"&gt;cudnn.torch&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-image-segmentation" class="anchor" aria-hidden="true" href="#image-segmentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image segmentation&lt;/h3&gt;
&lt;p&gt;Note: In the main paper we generate all comparison results using automatic scene segmentation algorithm modified from &lt;a href="https://arxiv.org/abs/1606.00915" rel="nofollow"&gt;DilatedNet&lt;/a&gt;. Manual segmentation enables more diverse tasks hence we provide the masks in &lt;code&gt;examples/segmentation/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The mask colors we used (you could add more colors in &lt;code&gt;ExtractMask&lt;/code&gt; function in two &lt;code&gt;*.lua&lt;/code&gt; files):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Color variable&lt;/th&gt;
&lt;th&gt;RGB Value&lt;/th&gt;
&lt;th&gt;Hex Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;blue&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0 0 255&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0000ff&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;green&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0 255 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;00ff00&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;black&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0 0 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;000000&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;white&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;255 255 255&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ffffff&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;red&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;255 0 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ff0000&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;yellow&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;255 255 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ffff00&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;grey&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;128 128 128&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;808080&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;lightblue&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0 255 255&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;00ffff&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;purple&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;255 0 255&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ff00ff &lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here are some automatic and manual tools for creating a segmentation mask for a photo image:&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-automatic" class="anchor" aria-hidden="true" href="#automatic"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Automatic:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://sceneparsing.csail.mit.edu/" rel="nofollow"&gt;MIT Scene Parsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.unc.edu/~jtighe/Papers/ECCV10/" rel="nofollow"&gt;SuperParsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://people.csail.mit.edu/celiu/LabelTransfer/" rel="nofollow"&gt;Nonparametric Scene Parsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html" rel="nofollow"&gt;Berkeley Contour Detection and Image Segmentation Resources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/torrvision/crfasrnn"&gt;CRF-RNN for Semantic Image Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/belltailjp/selective_search_py"&gt;Selective Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DrSleep/tensorflow-deeplab-lfov"&gt;DeepLab-TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-manual" class="anchor" aria-hidden="true" href="#manual"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Manual:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://helpx.adobe.com/photoshop/using/making-quick-selections.html" rel="nofollow"&gt;Photoshop Quick Selection Tool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.gimp.org/en/gimp-tools-selection.html" rel="nofollow"&gt;GIMP Selection Tool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://gmic.eu/gimp.shtml" rel="nofollow"&gt;GIMP G'MIC Interactive Foreground Extraction tool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;p&gt;Here are some results from our algorithm (from left to right are input, style and our output):&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in3.png"&gt;&lt;img src="examples/input/in3.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar3.png"&gt;&lt;img src="examples/style/tar3.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_3.png"&gt;&lt;img src="examples/refine_posterization/refine_3.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in4.png"&gt;&lt;img src="examples/input/in4.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar4.png"&gt;&lt;img src="examples/style/tar4.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_4.png"&gt;&lt;img src="examples/refine_posterization/refine_4.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in13.png"&gt;&lt;img src="examples/input/in13.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar13.png"&gt;&lt;img src="examples/style/tar13.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_13.png"&gt;&lt;img src="examples/refine_posterization/refine_13.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in9.png"&gt;&lt;img src="examples/input/in9.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar9.png"&gt;&lt;img src="examples/style/tar9.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_9.png"&gt;&lt;img src="examples/refine_posterization/refine_9.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in20.png"&gt;&lt;img src="examples/input/in20.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar20.png"&gt;&lt;img src="examples/style/tar20.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_20.png"&gt;&lt;img src="examples/refine_posterization/refine_20.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in1.png"&gt;&lt;img src="examples/input/in1.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar1.png"&gt;&lt;img src="examples/style/tar1.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_1.png"&gt;&lt;img src="examples/refine_posterization/refine_1.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in39.png"&gt;&lt;img src="examples/input/in39.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar39.png"&gt;&lt;img src="examples/style/tar39.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_39.png"&gt;&lt;img src="examples/refine_posterization/refine_39.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in57.png"&gt;&lt;img src="examples/input/in57.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar57.png"&gt;&lt;img src="examples/style/tar57.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_57.png"&gt;&lt;img src="examples/refine_posterization/refine_57.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in47.png"&gt;&lt;img src="examples/input/in47.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar47.png"&gt;&lt;img src="examples/style/tar47.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_47.png"&gt;&lt;img src="examples/refine_posterization/refine_47.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in58.png"&gt;&lt;img src="examples/input/in58.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar58.png"&gt;&lt;img src="examples/style/tar58.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_58.png"&gt;&lt;img src="examples/refine_posterization/refine_58.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in51.png"&gt;&lt;img src="examples/input/in51.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar51.png"&gt;&lt;img src="examples/style/tar51.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_51.png"&gt;&lt;img src="examples/refine_posterization/refine_51.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in7.png"&gt;&lt;img src="examples/input/in7.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar7.png"&gt;&lt;img src="examples/style/tar7.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_7.png"&gt;&lt;img src="examples/refine_posterization/refine_7.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in23.png"&gt;&lt;img src="examples/input/in23.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in23.png"&gt;&lt;img src="examples/input/in23.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/final_results/best23_t_1000.png"&gt;&lt;img src="examples/final_results/best23_t_1000.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in16.png"&gt;&lt;img src="examples/input/in16.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar16.png"&gt;&lt;img src="examples/style/tar16.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_16.png"&gt;&lt;img src="examples/refine_posterization/refine_16.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in30.png"&gt;&lt;img src="examples/input/in30.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar30.png"&gt;&lt;img src="examples/style/tar30.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_30.png"&gt;&lt;img src="examples/refine_posterization/refine_30.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in2.png"&gt;&lt;img src="examples/input/in2.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar2.png"&gt;&lt;img src="examples/style/tar2.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/final_results/best2_t_1000.png"&gt;&lt;img src="examples/final_results/best2_t_1000.png" height="194" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/input/in11.png"&gt;&lt;img src="examples/input/in11.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/style/tar11.png"&gt;&lt;img src="examples/style/tar11.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="examples/refine_posterization/refine_11.png"&gt;&lt;img src="examples/refine_posterization/refine_11.png" width="290" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgement" class="anchor" aria-hidden="true" href="#acknowledgement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgement&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Our torch implementation is based on Justin Johnson's &lt;a href="https://github.com/jcjohnson/neural-style"&gt;code&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;We use Anat Levin's Matlab &lt;a href="http://www.wisdom.weizmann.ac.il/~levina/matting.tar.gz" rel="nofollow"&gt;code&lt;/a&gt; to compute the matting Laplacian matrix.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you find this work useful for your research, please cite:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{luan2017deep,
  title={Deep Photo Style Transfer},
  author={Luan, Fujun and Paris, Sylvain and Shechtman, Eli and Bala, Kavita},
  journal={arXiv preprint arXiv:1703.07511},
  year={2017}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h2&gt;
&lt;p&gt;Feel free to contact me if there is any question (Fujun Luan &lt;a href="mailto:fl356@cornell.edu"&gt;fl356@cornell.edu&lt;/a&gt;).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>luanfujun</author><guid isPermaLink="false">https://github.com/luanfujun/deep-photo-styletransfer</guid><pubDate>Sun, 09 Feb 2020 00:01:00 GMT</pubDate></item><item><title>1274085042/Sugarcane_borers_detect #2 in MATLAB, Today</title><link>https://github.com/1274085042/Sugarcane_borers_detect</link><description>&lt;p&gt;&lt;i&gt;螟虫检测&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-sugarcane-borers-detection" class="anchor" aria-hidden="true" href="#sugarcane-borers-detection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sugarcane borers detection&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-package-contents" class="anchor" aria-hidden="true" href="#package-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Package contents&lt;/h2&gt;
&lt;p&gt;The project runs in MATLAB and uses
&lt;a href="http://www.vlfeat.org/matconvnet" rel="nofollow"&gt;MatConvNet&lt;/a&gt; and
&lt;a href="http://www.vlfeat.org" rel="nofollow"&gt;VLFeat&lt;/a&gt;. This package contains the following
MATLAB functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;boxinclusion.m&lt;/code&gt;: compute the inclusion of bounding boxes.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;boxoverlap.m&lt;/code&gt;: compute the overlap of bounding boxes.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;boxsuppress.m&lt;/code&gt;: non-maxima box suppression.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;detect.m&lt;/code&gt;: sliding window detector.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;detectAtMultipleScales.m&lt;/code&gt;: an intermediate example detector.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;evalDetections.m&lt;/code&gt;: evaluate detections using the PASCAL VOC criterion.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;evaluateModel.m&lt;/code&gt;: evaluate a detector against a database of images.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;extract.m&lt;/code&gt;: extract HOG features from bounding boxes.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;loadData.m&lt;/code&gt;: load practical data.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;setup.m&lt;/code&gt;: setup MATLAB environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-appendix-installing-from-scratch" class="anchor" aria-hidden="true" href="#appendix-installing-from-scratch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Appendix: Installing from scratch&lt;/h2&gt;
&lt;p&gt;The project requires both VLFeat and MatConvNet. VLFeat comes with
pre-built binaries, but MatConvNet does not.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;From Bash, run &lt;code&gt;./extras/download.sh&lt;/code&gt;. This will download VLFeat.&lt;/li&gt;
&lt;li&gt;From MATLAB, run &lt;code&gt;addpath extras ; prepareLabData.m&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-visualization" class="anchor" aria-hidden="true" href="#visualization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Visualization&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/1274085042/Sugarcane_borers_detect/blob/master/visualization/picture1.png"&gt;&lt;img src="https://github.com/1274085042/Sugarcane_borers_detect/raw/master/visualization/picture1.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;br&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/1274085042/Sugarcane_borers_detect/blob/master/visualization/picture3.png"&gt;&lt;img src="https://github.com/1274085042/Sugarcane_borers_detect/raw/master/visualization/picture3.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-problem" class="anchor" aria-hidden="true" href="#problem"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Problem&lt;/h2&gt;
&lt;p&gt;When selecting a positive sample,which of the following should be selected?&lt;br&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/1274085042/Sugarcane_borers_detect/blob/master/visualization/picture2.png"&gt;&lt;img src="https://github.com/1274085042/Sugarcane_borers_detect/raw/master/visualization/picture2.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-changes" class="anchor" aria-hidden="true" href="#changes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Changes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;2014a&lt;/em&gt; - Initial edition&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>1274085042</author><guid isPermaLink="false">https://github.com/1274085042/Sugarcane_borers_detect</guid><pubDate>Sun, 09 Feb 2020 00:02:00 GMT</pubDate></item></channel></rss>