<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: TSQL, Today</title><link>https://github.com/trending/tsql?since=daily</link><description>The top repositories on GitHub for tsql, measured daily</description><pubDate>Fri, 07 Feb 2020 01:04:32 GMT</pubDate><lastBuildDate>Fri, 07 Feb 2020 01:04:32 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>confluentinc/examples #1 in TSQL, Today</title><link>https://github.com/confluentinc/examples</link><description>&lt;p&gt;&lt;i&gt;Apache Kafka and Confluent Platform examples and demos&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/confluent-logo-300-2.png"&gt;&lt;img src="images/confluent-logo-300-2.png" alt="image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#demos"&gt;Demos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#build-your-own"&gt;Build Your Own&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#prerequisites"&gt;Prerequisities&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-demos" class="anchor" aria-hidden="true" href="#demos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Demos&lt;/h1&gt;
&lt;p&gt;This is a curated list of demos that showcase Apache KafkaÂ® event stream processing on the Confluent Platform, an event stream processing platform that enables you to process, organize, and manage massive amounts of streaming data across cloud, on-prem, and serverless deployments.&lt;/p&gt;
&lt;p align="center"&gt;
&lt;a href="http://www.youtube.com/watch?v=muQBd6gry0U" rel="nofollow"&gt;&lt;img src="images/examples-video-thumbnail.jpg" width="360" height="270" border="10" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-where-to-start" class="anchor" aria-hidden="true" href="#where-to-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Where to start&lt;/h2&gt;
&lt;p&gt;The best demo to start with is &lt;a href="https://github.com/confluentinc/cp-demo"&gt;cp-demo&lt;/a&gt; which spins up a Kafka event streaming application using KSQL for stream processing, with many security features enabled, in an end-to-end streaming ETL pipeline with a source connector pulling from live IRC channels and a sink connector connecting to Elasticsearch and Kibana for visualizations.
&lt;code&gt;cp-demo&lt;/code&gt; also comes with a playbook and is a great configuration reference for Confluent Platform.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-full-demo-list" class="anchor" aria-hidden="true" href="#full-demo-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Full demo list&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#confluent-cloud"&gt;Confluent Cloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#stream-processing"&gt;Stream Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data-pipelines"&gt;Data Pipelines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#confluent-platform"&gt;Confluent Platform&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-confluent-cloud" class="anchor" aria-hidden="true" href="#confluent-cloud"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Confluent Cloud&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Demo&lt;/th&gt;
&lt;th&gt;Local&lt;/th&gt;
&lt;th&gt;Docker&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="ccloud/beginner-cloud/README.md"&gt;Beginner Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Fully scripted demo that shows how to interact with your Confluent Cloud cluster and set ACLs using the CLI &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="clients/cloud/images/confluent-cloud.jpeg"&gt;&lt;img src="clients/cloud/images/confluent-cloud.jpeg" width="400" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="clients/cloud/README.md"&gt;Clients to Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="clients/cloud/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Client applications in different programming languages connecting to &lt;a href="https://www.confluent.io/confluent-cloud/?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Cloud&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="clients/cloud/images/clients-all.png"&gt;&lt;img src="clients/cloud/images/clients-all.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/gcp-pipeline/README.adoc"&gt;GCP pipeline&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/gcp-pipeline/README.adoc"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Work with &lt;a href="https://www.confluent.io/confluent-cloud/?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Cloud&lt;/a&gt; to build cool pipelines into Google Cloud Platform (GCP) &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/confluentinc/demo-scene/blob/master/gcp-pipeline/images/env-data-arch-01.png"&gt;&lt;img src="https://github.com/confluentinc/demo-scene/raw/master/gcp-pipeline/images/env-data-arch-01.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="kinesis-cloud/README.md"&gt;Kinesis to Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="kinesis-cloud/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;AWS Kinesis -&amp;gt; Confluent Cloud -&amp;gt; Google Cloud Storage pipeline &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="kinesis-cloud/images/topology.jpg"&gt;&lt;img src="kinesis-cloud/images/topology.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="ccloud/README.md"&gt;On-Prem Kafka to Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="ccloud/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="ccloud/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;This more advanced demo showcases an on-prem Kafka cluster and &lt;a href="https://www.confluent.io/confluent-cloud/?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Cloud&lt;/a&gt; cluster, and data copied between them with Confluent Replicator &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="ccloud/docs/images/schema-registry-local.jpg"&gt;&lt;img src="ccloud/docs/images/schema-registry-local.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="kubernetes/replicator-gke-cc/README.md"&gt;GKE to Cloud&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="kubernetes/replicator-gke-cc/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Uses Google Kubernetes Engine, &lt;a href="https://www.confluent.io/confluent-cloud/?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Cloud&lt;/a&gt;, and &lt;a href="https://www.confluent.io/confluent-replicator/?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Replicator&lt;/a&gt; to explore a multicloud deployment &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="kubernetes/replicator-gke-cc/docs/images/operator-demo-phase-2.png"&gt;&lt;img src="kubernetes/replicator-gke-cc/docs/images/operator-demo-phase-2.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-stream-processing" class="anchor" aria-hidden="true" href="#stream-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stream Processing&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Demo&lt;/th&gt;
&lt;th&gt;Local&lt;/th&gt;
&lt;th&gt;Docker&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="clickstream/README.md"&gt;Clickstream&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="clickstream/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.confluent.io/current/ksql/docs/tutorials/clickstream-docker.html#ksql-clickstream-docker?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Automated version of the &lt;a href="https://docs.confluent.io/current/ksql/docs/tutorials/clickstream-docker.html#ksql-clickstream-docker?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;KSQL clickstream demo&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/28e9212ca11ed82e4015367f81b89bec3e61f107/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f67726166616e612d737563636573732e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/28e9212ca11ed82e4015367f81b89bec3e61f107/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f67726166616e612d737563636573732e706e67" width="450" data-canonical-src="https://docs.confluent.io/current/_images/grafana-success.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://kafka-tutorials.confluent.io?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Kafka Tutorials&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://kafka-tutorials.confluent.io?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://kafka-tutorials.confluent.io?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Collection of common event streaming use cases, with each tutorial featuring an example scenario and several complete code solutions &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a8588b0e07ad402e01e0e1f355a840c3717fb7cd/68747470733a2f2f63646e2e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f4b61666b612d5475746f7269616c732d333530783139352e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/a8588b0e07ad402e01e0e1f355a840c3717fb7cd/68747470733a2f2f63646e2e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f4b61666b612d5475746f7269616c732d333530783139352e6a7067" width="350" data-canonical-src="https://cdn.confluent.io/wp-content/uploads/Kafka-Tutorials-350x195.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/ksql-udf-advanced-example/README.md?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top"&gt;KSQL UDF&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/ksql-udf-advanced-example/README.md?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Advanced &lt;a href="https://www.confluent.io/blog/build-udf-udaf-ksql-5-0?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;KSQL User-Defined Function (UDF)&lt;/a&gt; use case for connected cars &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fcb649b2d1a60911f393cc63738cdcb5c0710d73/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f4b53514c2d312d333530783139352e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/fcb649b2d1a60911f393cc63738cdcb5c0710d73/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f4b53514c2d312d333530783139352e706e67" width="350" data-canonical-src="https://www.confluent.io/wp-content/uploads/KSQL-1-350x195.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/ksql-workshop/"&gt;KSQL workshop&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/ksql-workshop/"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;showcases Kafka event stream processing using KSQL and can run self-guided as a KSQL workshop &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/confluentinc/demo-scene/blob/master/ksql-workshop/images/ksql_workshop_01.png"&gt;&lt;img src="https://github.com/confluentinc/demo-scene/raw/master/ksql-workshop/images/ksql_workshop_01.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="microservices-orders/README.md"&gt;Microservices ecosystem&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="microservices-orders/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/kafka-streams-examples/tree/5.2.2-post/src/main/java/io/confluent/examples/streams/microservices"&gt;Microservices orders Demo Application&lt;/a&gt; integrated into the Confluent Platform &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="microservices-orders/docs/images/microservices-demo.jpg"&gt;&lt;img src="microservices-orders/docs/images/microservices-demo.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="music/README.md"&gt;Music demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="music/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="music/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;KSQL version of the &lt;a href="https://docs.confluent.io/current/streams/kafka-streams-examples/docs/index.html?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Kafka Streams Demo Application&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="music/images/ksql-music-demo-overview.jpg"&gt;&lt;img src="music/images/ksql-music-demo-overview.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-data-pipelines" class="anchor" aria-hidden="true" href="#data-pipelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Pipelines&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Demo&lt;/th&gt;
&lt;th&gt;Local&lt;/th&gt;
&lt;th&gt;Docker&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/no-more-silos/demo_no-more-silos.adoc"&gt;CDC with MySQL&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/no-more-silos/demo_no-more-silos.adoc"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Self-paced steps to set up a change data capture (CDC) pipeline &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b9dbae7351f1813eb87dac08d7726b9554b891a2/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6b61666b615f636f6e6e6563742d312e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/b9dbae7351f1813eb87dac08d7726b9554b891a2/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6b61666b615f636f6e6e6563742d312e706e67" width="450" data-canonical-src="https://www.confluent.io/wp-content/uploads/kafka_connect-1.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="postgres-debezium-ksql-elasticsearch/README.md"&gt;CDC with Postgres&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="postgres-debezium-ksql-elasticsearch/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Enrich event stream data with CDC data from Postgres and then stream into Elasticsearch &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="postgres-debezium-ksql-elasticsearch/images/ksql-debezium-es.png"&gt;&lt;img src="postgres-debezium-ksql-elasticsearch/images/ksql-debezium-es.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="connect-streams-pipeline/README.md"&gt;Connect and Kafka Streams&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="connect-streams-pipeline/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Demonstrate various ways, with and without Kafka Connect, to get data into Kafka topics and then loaded for use by the Kafka Streams API &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="connect-streams-pipeline/images/blog_connect_streams_diag.jpg"&gt;&lt;img src="connect-streams-pipeline/images/blog_connect_streams_diag.jpg" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/mqtt-connect-connector-demo/README.md"&gt;MQTT&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/blob/master/mqtt-connect-connector-demo/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Internet of Things (IoT) integration example using Apache Kafka + Kafka Connect + MQTT Connector + Sensor Data &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/80c360e482a98ae2311869d0cedc5ef984821eee/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6477675f4d5154542e737667"&gt;&lt;img src="https://camo.githubusercontent.com/80c360e482a98ae2311869d0cedc5ef984821eee/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6477675f4d5154542e737667" width="450" data-canonical-src="https://www.confluent.io/wp-content/uploads/dwg_MQTT.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="mysql-debezium/README.md"&gt;MySQL and Debezium&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="mysql-debezium/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/tree/master/build-a-streaming-pipeline"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;End-to-end streaming ETL with KSQL for stream processing using the &lt;a href="http://debezium.io/docs/connectors/mysql/" rel="nofollow"&gt;Debezium Connector for MySQL&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="mysql-debezium/images/ksql-debezium-es.png"&gt;&lt;img src="mysql-debezium/images/ksql-debezium-es.png" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/demo-scene/tree/master/syslog"&gt;Syslog&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Real-time syslog processing with Apache Kafka and KSQL: filtering logs, event-driven alerting, and enriching events &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6436ef9d9bca4eaa9d300c713fee0e4be6db8ee6/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6b73716c5f7379736c6f6730312d31303234783235382e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/6436ef9d9bca4eaa9d300c713fee0e4be6db8ee6/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6b73716c5f7379736c6f6730312d31303234783235382e706e67" width="450" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-confluent-platform" class="anchor" aria-hidden="true" href="#confluent-platform"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Confluent Platform&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Demo&lt;/th&gt;
&lt;th&gt;Local&lt;/th&gt;
&lt;th&gt;Docker&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="clients/README.md"&gt;Avro&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="clients/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Client applications using Avro and Confluent Schema Registry &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/92ad363b0e5811b5935c9dc81c37845d9273a0b7/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6477675f536368656d615265675f686f776974776f726b732e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/92ad363b0e5811b5935c9dc81c37845d9273a0b7/68747470733a2f2f7777772e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f6477675f536368656d615265675f686f776974776f726b732e706e67" width="420" data-canonical-src="https://www.confluent.io/wp-content/uploads/dwg_SchemaReg_howitworks.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="wikipedia/README.md"&gt;CP Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="wikipedia/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/confluentinc/cp-demo"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.confluent.io/current/tutorials/cp-demo/docs/index.html?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Platform demo&lt;/a&gt; with a playbook for Kafka event streaming ETL deployments &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/confluentinc/cp-demo/blob/5.4.0-post/docs/images/drawing.png"&gt;&lt;img src="https://github.com/confluentinc/cp-demo/raw/5.4.0-post/docs/images/drawing.png" width="420" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="kubernetes/README.md"&gt;Kubernetes&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="kubernetes/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Demonstrations of Confluent Platform deployments using the  &lt;a href="https://docs.confluent.io/current/installation/operator/index.html?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Operator&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="kubernetes/gke-base/docs/images/operator.png"&gt;&lt;img src="kubernetes/gke-base/docs/images/operator.png" width="420" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="multi-datacenter/README.md"&gt;Multi Datacenter&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="multi-datacenter/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Active-active multi-datacenter design with two instances of Confluent Replicator copying data bidirectionally between the datacenters &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/c0090d428178db34693591175b730b27450002ad/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f6d64632d6c6576656c2d312e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/c0090d428178db34693591175b730b27450002ad/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f6d64632d6c6576656c2d312e706e67" width="420" data-canonical-src="https://docs.confluent.io/current/_images/mdc-level-1.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="multiregion/README.md"&gt;Multi Region Replication&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="multiregion/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Multi-region replication with follower fetching, observers, and replica placement&lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="multiregion/images/multi-region-topic-replicas-v2.png"&gt;&lt;img src="multiregion/images/multi-region-topic-replicas-v2.png" width="420" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="cp-quickstart/README.md"&gt;Quickstart&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="cp-quickstart/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.confluent.io/current/quickstart/ce-docker-quickstart.html#ce-docker-quickstart?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Automated version of the &lt;a href="https://docs.confluent.io/current/quickstart.html?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Platform Quickstart&lt;/a&gt; &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/494b6bf1a80993311d29232f17064ab180ebe677/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f636f6e666c75656e74506c6174666f726d2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/494b6bf1a80993311d29232f17064ab180ebe677/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f636f6e666c75656e74506c6174666f726d2e706e67" width="420" data-canonical-src="https://docs.confluent.io/current/_images/confluentPlatform.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="security/rbac/README.md"&gt;Role-Based Access Control&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Role-based Access Control (RBAC) provides granular privileges for users and service accounts &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/33dd1276d7e43660810d10a9d0997502fe22a623/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f726261632d6f766572766965772e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/33dd1276d7e43660810d10a9d0997502fe22a623/68747470733a2f2f646f63732e636f6e666c75656e742e696f2f63757272656e742f5f696d616765732f726261632d6f766572766965772e706e67" width="450" data-canonical-src="https://docs.confluent.io/current/_images/rbac-overview.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="security/secret-protection/README.adoc"&gt;Secret Protection&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Secret Protection feature encrypts secrets in configuration files &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/90888c033d0e611f7b73c5df261a109ead6858a1/68747470733a2f2f63646e2e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f5365637265745f50726f74656374696f6e5f466561747572652e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/90888c033d0e611f7b73c5df261a109ead6858a1/68747470733a2f2f63646e2e636f6e666c75656e742e696f2f77702d636f6e74656e742f75706c6f6164732f5365637265745f50726f74656374696f6e5f466561747572652e6a7067" width="400" data-canonical-src="https://cdn.confluent.io/wp-content/uploads/Secret_Protection_Feature.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="replicator-security/README.md"&gt;Replicator Security&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;a href="replicator-security/README.md"&gt;Y&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Demos of various security configurations supported by Confluent Replicator and examples of how to implement them &lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/replicator-security.png"&gt;&lt;img src="images/replicator-security.png" width="300" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-build-your-own" class="anchor" aria-hidden="true" href="#build-your-own"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Build Your Own&lt;/h1&gt;
&lt;p&gt;As a next step, you may want to build your own custom demo or test environment.
We have several resources that launch just the services in Confluent Platform with no pre-configured connectors, data sources, topics, schemas, etc.
Using these as a foundation, you can then add any connectors or applications.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="cp-all-in-one/README.md"&gt;cp-all-in-one&lt;/a&gt;: This Docker Compose file launches all services in Confluent Platform, and runs them in containers in your local host.&lt;/li&gt;
&lt;li&gt;&lt;a href="cp-all-in-one-community/README.md"&gt;cp-all-in-one-community&lt;/a&gt;: This Docker Compose file launches only the community services in Confluent Platform, and runs them in containers in your local host.&lt;/li&gt;
&lt;li&gt;&lt;a href="cp-all-in-one-cloud/README.md"&gt;cp-all-in-one-cloud&lt;/a&gt;: Use this with your pre-configured Confluent Cloud instance. This Docker Compose file launches all services in Confluent Platform (except for the Kafka brokers), runs them in containers in your local host, and automatically configures them to connect to Confluent Cloud.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.confluent.io/current/cli/index.html?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent CLI&lt;/a&gt;: For local, non-Docker installs of Confluent Platform. Using this CLI, you can launch all services in Confluent Platform with just one command &lt;code&gt;confluent local start&lt;/code&gt;, and they will all run on your local host.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.confluent.io/blog/easy-ways-generate-test-data-kafka?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Generate test data&lt;/a&gt;: "Hello, World!" for launching Confluent Platform, plus different ways to generate more interesting test data for your topics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additional documentation: &lt;a href="https://docs.confluent.io/current/getting-started.html?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Getting Started&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prerequisites&lt;/h1&gt;
&lt;p&gt;For local installs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download &lt;a href="https://www.confluent.io/download/?utm_source=github&amp;amp;utm_medium=demo&amp;amp;utm_campaign=ch.examples_type.community_content.top" rel="nofollow"&gt;Confluent Platform 5.4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Env var &lt;code&gt;CONFLUENT_HOME=/path/to/confluentplatform&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Env var &lt;code&gt;PATH&lt;/code&gt; includes &lt;code&gt;$CONFLUENT_HOME/bin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Each demo has its own set of prerequisites as well, documented individually in each demo&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For Docker: demos have been validated with&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.docker.com/install/" rel="nofollow"&gt;Docker&lt;/a&gt; version 17.06.1-ce&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.docker.com/compose/install/" rel="nofollow"&gt;Docker Compose&lt;/a&gt; version 1.14.0 with Docker Compose file format 2.1&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>confluentinc</author><guid isPermaLink="false">https://github.com/confluentinc/examples</guid><pubDate>Fri, 07 Feb 2020 00:01:00 GMT</pubDate></item><item><title>jOOQ/jOOQ #2 in TSQL, Today</title><link>https://github.com/jOOQ/jOOQ</link><description>&lt;p&gt;&lt;i&gt;jOOQ is the best way to write SQL in Java&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-jooqs-reason-for-being---compared-to-jpa" class="anchor" aria-hidden="true" href="#jooqs-reason-for-being---compared-to-jpa"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;jOOQ's reason for being - compared to JPA&lt;/h1&gt;
&lt;p&gt;Java and SQL have come a long way. SQL is an "ancient", yet established and well-understood technology. Java is a legacy too, although its platform JVM allows for many new and contemporary languages built on top of it. Yet, after all these years, libraries dealing with the interface between SQL and Java have come and gone, leaving JPA to be a standard that is accepted only with doubts, short of any surviving options.&lt;/p&gt;
&lt;p&gt;So far, there had been only few database abstraction frameworks or libraries, that truly respected SQL as a first class citizen among languages. Most frameworks, including the industry standards JPA, EJB, Hibernate, JDO, Criteria Query, and many others try to hide SQL itself, minimising its scope to things called JPQL, HQL, JDOQL and various other inferior query languages&lt;/p&gt;
&lt;p&gt;jOOQ has come to fill this gap.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-jooqs-reason-of-being---compared-to-linq" class="anchor" aria-hidden="true" href="#jooqs-reason-of-being---compared-to-linq"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;jOOQ's reason of being - compared to LINQ&lt;/h1&gt;
&lt;p&gt;Other platforms incorporate ideas such as LINQ (with LINQ-to-SQL), or Scala's SLICK, or also Java's QueryDSL to better integrate querying as a concept into their respective language. By querying, they understand querying of arbitrary targets, such as SQL, XML, Collections and other heterogeneous data stores. jOOQ claims that this is going the wrong way too.&lt;/p&gt;
&lt;p&gt;In more advanced querying use-cases (more than simple CRUD and the occasional JOIN), people will want to profit from the expressivity of SQL. Due to the relational nature of SQL, this is quite different from what object-oriented and partially functional languages such as C#, Scala, or Java can offer.&lt;/p&gt;
&lt;p&gt;It is very hard to formally express and validate joins and the ad-hoc table expression types they create. It gets even harder when you want support for more advanced table expressions, such as pivot tables, unnested cursors, or just arbitrary projections from derived tables. With a very strong object-oriented typing model, these features will probably stay out of scope.&lt;/p&gt;
&lt;p&gt;In essence, the decision of creating an API that looks like SQL or one that looks like C#, Scala, Java is a definite decision in favour of one or the other platform. While it will be easier to evolve SLICK in similar ways as LINQ (or QueryDSL in the Java world), SQL feature scope that clearly communicates its underlying intent will be very hard to add, later on (e.g. how would you model Oracle's partitioned outer join syntax? How would you model ANSI/ISO SQL:1999 grouping sets? How can you support scalar subquery caching? etc...).&lt;/p&gt;
&lt;p&gt;jOOQ has come to fill this gap.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-jooq-is-different" class="anchor" aria-hidden="true" href="#jooq-is-different"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;jOOQ is different&lt;/h1&gt;
&lt;p&gt;SQL was never meant to be abstracted. To be confined in the narrow boundaries of heavy mappers, hiding the beauty and simplicity of relational data. SQL was never meant to be object-oriented. SQL was never meant to be anything other than... SQL!&lt;/p&gt;
&lt;p&gt;For more details please visit &lt;a href="https://www.jooq.org" rel="nofollow"&gt;jooq.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Follow jOOQ on &lt;a href="https://twitter.com/JavaOOQ" rel="nofollow"&gt;Twitter&lt;/a&gt; and &lt;a href="https://blog.jooq.org" rel="nofollow"&gt;the jOOQ blog&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jOOQ</author><guid isPermaLink="false">https://github.com/jOOQ/jOOQ</guid><pubDate>Fri, 07 Feb 2020 00:02:00 GMT</pubDate></item><item><title>hortonworks/hive-testbench #3 in TSQL, Today</title><link>https://github.com/hortonworks/hive-testbench</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-hive-testbench" class="anchor" aria-hidden="true" href="#hive-testbench"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;hive-testbench&lt;/h1&gt;
&lt;p&gt;A testbench for experimenting with Apache Hive at any data scale.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overview&lt;/h1&gt;
&lt;p&gt;The hive-testbench is a data generator and set of queries that lets you experiment with Apache Hive at scale. The testbench allows you to experience base Hive performance on large datasets, and gives an easy way to see the impact of Hive tuning parameters and advanced settings.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prerequisites&lt;/h1&gt;
&lt;p&gt;You will need:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hadoop 2.2 or later cluster or Sandbox.&lt;/li&gt;
&lt;li&gt;Apache Hive.&lt;/li&gt;
&lt;li&gt;Between 15 minutes and 2 days to generate data (depending on the Scale Factor you choose and available hardware).&lt;/li&gt;
&lt;li&gt;If you plan to generate 1TB or more of data, using Apache Hive 13+ to generate the data is STRONGLY suggested.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-install-and-setup" class="anchor" aria-hidden="true" href="#install-and-setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install and Setup&lt;/h1&gt;
&lt;p&gt;All of these steps should be carried out on your Hadoop cluster.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Step 1: Prepare your environment.&lt;/p&gt;
&lt;p&gt;In addition to Hadoop and Hive, before you begin ensure &lt;code&gt;gcc&lt;/code&gt; is installed and available on your system path. If you system does not have it, install it using yum or apt-get.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 2: Decide which test suite(s) you want to use.&lt;/p&gt;
&lt;p&gt;hive-testbench comes with data generators and sample queries based on both the TPC-DS and TPC-H benchmarks. You can choose to use either or both of these benchmarks for experiementation. More information about these benchmarks can be found at the Transaction Processing Council homepage.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 3: Compile and package the appropriate data generator.&lt;/p&gt;
&lt;p&gt;For TPC-DS, &lt;code&gt;./tpcds-build.sh&lt;/code&gt; downloads, compiles and packages the TPC-DS data generator.
For TPC-H, &lt;code&gt;./tpch-build.sh&lt;/code&gt; downloads, compiles and packages the TPC-H data generator.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 4: Decide how much data you want to generate.&lt;/p&gt;
&lt;p&gt;You need to decide on a "Scale Factor" which represents how much data you will generate. Scale Factor roughly translates to gigabytes, so a Scale Factor of 100 is about 100 gigabytes and one terabyte is Scale Factor 1000. Decide how much data you want and keep it in mind for the next step. If you have a cluster of 4-10 nodes or just want to experiment at a smaller scale, scale 1000 (1 TB) of data is a good starting point. If you have a large cluster, you may want to choose Scale 10000 (10 TB) or more. The notion of scale factor is similar between TPC-DS and TPC-H.&lt;/p&gt;
&lt;p&gt;If you want to generate a large amount of data, you should use Hive 13 or later. Hive 13 introduced an optimization that allows far more scalable data partitioning. Hive 12 and lower will likely crash if you generate more than a few hundred GB of data and tuning around the problem is difficult. You can generate text or RCFile data in Hive 13 and use it in multiple versions of Hive.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 5: Generate and load the data.&lt;/p&gt;
&lt;p&gt;The scripts &lt;code&gt;tpcds-setup.sh&lt;/code&gt; and &lt;code&gt;tpch-setup.sh&lt;/code&gt; generate and load data for TPC-DS and TPC-H, respectively. General usage is &lt;code&gt;tpcds-setup.sh scale_factor [directory]&lt;/code&gt; or &lt;code&gt;tpch-setup.sh scale_factor [directory]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Some examples:&lt;/p&gt;
&lt;p&gt;Build 1 TB of TPC-DS data: &lt;code&gt;./tpcds-setup.sh 1000&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Build 1 TB of TPC-H data: &lt;code&gt;./tpch-setup.sh 1000&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Build 100 TB of TPC-DS data: &lt;code&gt;./tpcds-setup.sh 100000&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Build 30 TB of text formatted TPC-DS data: &lt;code&gt;FORMAT=textfile ./tpcds-setup 30000&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Build 30 TB of RCFile formatted TPC-DS data: &lt;code&gt;FORMAT=rcfile ./tpcds-setup 30000&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Also check other parameters in setup scripts important one is BUCKET_DATA.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 6: Run queries.&lt;/p&gt;
&lt;p&gt;More than 50 sample TPC-DS queries and all TPC-H queries are included for you to try. You can use &lt;code&gt;hive&lt;/code&gt;, &lt;code&gt;beeline&lt;/code&gt; or the SQL tool of your choice. The testbench also includes a set of suggested settings.&lt;/p&gt;
&lt;p&gt;This example assumes you have generated 1 TB of TPC-DS data during Step 5:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; cd sample-queries-tpcds
 hive -i testbench.settings
 hive&amp;gt; use tpcds_bin_partitioned_orc_1000;
 hive&amp;gt; source query55.sql;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the database is named based on the Data Scale chosen in step 3. At Data Scale 10000, your database will be named tpcds_bin_partitioned_orc_10000. At Data Scale 1000 it would be named tpch_flat_orc_1000. You can always &lt;code&gt;show databases&lt;/code&gt; to get a list of available databases.&lt;/p&gt;
&lt;p&gt;Similarly, if you generated 1 TB of TPC-H data during Step 5:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; cd sample-queries-tpch
 hive -i testbench.settings
 hive&amp;gt; use tpch_flat_orc_1000;
 hive&amp;gt; source tpch_query1.sql;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-feedback" class="anchor" aria-hidden="true" href="#feedback"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Feedback&lt;/h1&gt;
&lt;p&gt;If you have questions, comments or problems, visit the &lt;a href="http://hortonworks.com/community/forums/forum/hive/" rel="nofollow"&gt;Hortonworks Hive forum&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have improvements, pull requests are accepted.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>hortonworks</author><guid isPermaLink="false">https://github.com/hortonworks/hive-testbench</guid><pubDate>Fri, 07 Feb 2020 00:03:00 GMT</pubDate></item></channel></rss>